<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 9]
- [cs.CV](#cs.CV) [Total: 12]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Evaluating LLMs' Reasoning Over Ordered Procedural Steps](https://arxiv.org/abs/2511.04688)
*Adrita Anika,Md Messal Monem Miah*

Main category: cs.CL

> 研究通过零样本和少量样本设置评估大语言模型在重建从打乱的步骤中恢复全局有序序列的能力，特别是在食谱领域，并提出评价框架。结果显示模型性能随序列长度增加和步骤位移增加而下降，反映出当前LLM在程序推理方面的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 评估大语言模型在重建从打乱的步骤中恢复全局有序序列的能力，尤其关注食谱领域正确顺序的重要性，发现当前模型在此类任务中的局限性。

**Method:** 使用一个经过筛选的食谱数据集，评估几个大语言模型在零样本和少量样本设置下的性能，并提出了一种全面的评价框架，采用Kendall's Tau, Normalized Longest Common Subsequence (NLCS), 和Normalized Edit Distance (NED) 来衡量结果的有序性。

**Result:** 分析显示，模型性能随着序列长度的增加而降低，并且输入中的步骤位移越严重，排序质量越差。结果揭示了当前LLM在处理长序列和高混乱输入时的程序推理能力的限制。

**Conclusion:** 当前的大语言模型在处理长序列任务时能力有限，尤其是在任务步骤被严重打乱的情况下其程序推理能力尤其受限。

**Abstract:** Reasoning over procedural sequences, where the order of steps directly
impacts outcomes, is a critical capability for large language models (LLMs). In
this work, we study the task of reconstructing globally ordered sequences from
shuffled procedural steps, using a curated dataset of food recipes, a domain
where correct sequencing is essential for task success. We evaluate several
LLMs under zero-shot and few-shot settings and present a comprehensive
evaluation framework that adapts established metrics from ranking and sequence
alignment. These include Kendall's Tau, Normalized Longest Common Subsequence
(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects
of ordering quality. Our analysis shows that model performance declines with
increasing sequence length, reflecting the added complexity of longer
procedures. We also find that greater step displacement in the input,
corresponding to more severe shuffling, leads to further degradation. These
findings highlight the limitations of current LLMs in procedural reasoning,
especially with longer and more disordered inputs.

</details>


### [2] [Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks](https://arxiv.org/abs/2511.04689)
*Peiyu Li,Xiuxiu Tang,Si Chen,Ying Cheng,Ronald Metoyer,Ting Hua,Nitesh V. Chawla*

Main category: cs.CL

> ATLAS is an adaptive evaluation framework for large language models using IRT, achieving 90% item reduction while maintaining precision. It significantly reduces the number of benchmark items needed for testing and reveals discrepancies in model ranking between IRT and accuracy-based metrics.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for ATLAS is to address the inefficiencies of current evaluation methods for large language models. Traditional methods are expensive, slow, and do not differentiate the quality and informativeness of benchmark items, which can lead to inaccuracies in evaluation.

**Method:** ATLAS is an adaptive testing framework using Item Response Theory (IRT) to estimate model ability through Fisher information-guided item selection. It selects items dynamically to reduce the number of items needed for accurate evaluation compared to traditional methods that use fixed item sets.

**Result:** ATLAS can reduce the number of items required for evaluation by 90% while maintaining precision. On the HellaSwag benchmark, ATLAS achieves comparable accuracy estimates with just 42 items out of the original 5,608. Additionally, it maintains low item exposure and test overlap rates, providing a fairer evaluation across different tested models.

**Conclusion:** The ATLAS framework provides a more efficient and accurate evaluation method for large language models compared to traditional static benchmarks. It addresses the issue of negative discriminatory items and ranking shifts between IRT scores and accuracy scores, promising a more nuanced understanding of model abilities.

**Abstract:** Large language model evaluation requires thousands of benchmark items, making
evaluations expensive and slow. Existing methods compute average accuracy
across fixed item sets, treating all items equally despite varying quality and
informativeness. We present ATLAS an adaptive testing framework using Item
Response Theory (IRT) to estimate model ability through Fisher
information-guided item selection. Our analysis of five major benchmarks
reveals that 3-6% of items exhibit negative discrimination, indicating
annotation errors that corrupt static evaluation. ATLAS achieves 90% item
reduction while maintaining measurement precision: on HellaSwag (5,608 items),
we match full-benchmark estimates using only 42 items with 0.154 MAE. Our
framework maintains item exposure rates below 10% and test overlap at 16-27%,
compared to static benchmarks where every model sees all items (100% exposure).
Among 4,000+ tested models, IRT ranks differ from accuracy ranks: models with
the same accuracy get different IRT scores, and 23-31% of all models shift by
more than 10 rank positions. Code and calibrated item banks are available at
https://github.com/Peiyu-Georgia-Li/ATLAS.git.

</details>


### [3] [SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection](https://arxiv.org/abs/2511.04692)
*Jingqing Wang,Jiaxing Shang,Rong Xu,Fei Hao,Tianjin Huang,Geyong Min*

Main category: cs.CL

> 本文提出SARC框架，通过情感增强的深度聚类来识别用户角色，提升了假新闻检测效果。

<details>
  <summary>Details</summary>

**Motivation:** 研究表明，融合新闻内容和用户评论的情感信息可以提升假新闻检测性能。然而，现有方法通常将情感特征作为辅助信号，忽略了角色区分，限制了它们捕捉复杂模式的能力。为解决这一问题，研究人员提出了SARC框架。

**Method:** 该论文提出了SARC框架，结合情感增强的深度聚类来识别用户角色，提升假新闻检测效果。首先，通过联合评论文本表示（使用BiGRU和注意力机制）和情感编码生成用户特征。接着，构建了一个可微分的深度聚类模块来自动分类用户角色。最后，提出了一种联合优化目标，结合角色聚类和假新闻检测，进一步提升模型性能。

**Result:** 实验结果显示，SARC框架在RumourEval-19和Weibo-comp两个基准数据集上，相较于基线模型，在所有指标上都实现了更优的性能。

**Conclusion:** 通过提出定制化的角色聚类和情感融合适应，SARC框架能够更有效地识别用户角色，从而提升了假新闻的检测性能。

**Abstract:** Fake news detection has been a long-standing research focus in social
networks. Recent studies suggest that incorporating sentiment information from
both news content and user comments can enhance detection performance. However,
existing approaches typically treat sentiment features as auxiliary signals,
overlooking role differentiation, that is, the same sentiment polarity may
originate from users with distinct roles, thereby limiting their ability to
capture nuanced patterns for effective detection. To address this issue, we
propose SARC, a Sentiment-Augmented Role Clustering framework which utilizes
sentiment-enhanced deep clustering to identify user roles for improved fake
news detection. The framework first generates user features through joint
comment text representation (with BiGRU and Attention mechanism) and sentiment
encoding. It then constructs a differentiable deep clustering module to
automatically categorize user roles. Finally, unlike existing approaches which
take fake news label as the unique supervision signal, we propose a joint
optimization objective integrating role clustering and fake news detection to
further improve the model performance. Experimental results on two benchmark
datasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior
performance across all metrics compared to baseline models. The code is
available at: https://github.com/jxshang/SARC.

</details>


### [4] [Reasoning Up the Instruction Ladder for Controllable Language Models](https://arxiv.org/abs/2511.04694)
*Zishuo Zheng,Vidhisha Balachandran,Chan Young Park,Faeze Brahman,Sachin Kumar*

Main category: cs.CL

> 将LLM的指令层级解析为推理任务，构建VerIH数据集并通过轻量级强化学习训练来提升模型在指令遵循和安全问题上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 随着LLM在现实世界决策中的角色愈发重要，必须能够协调来自多个来源（如模型开发人员、用户和工具）的高竞争性指令，从而在单一提示上下文中执行指令层级结构，以保证LLM的可靠性和可控性。

**Method:** 本研究将指令层级结构的解析重新定义为一个推理任务，即模型需要首先“思考”给定用户提示和优先级较高的系统指令之间的关系，然后生成响应。为此，研究构建了VerIH数据集，其中包括遵守约束任务的指令层级结构，具备可验证答案。该数据集涵盖了与用户指令一致和冲突的系统指令。通过使用VerIH进行轻量级的强化学习训练，研究展示了模型可以将一般推理能力转移到指令优先级的处理上。

**Result:** 细化后的模型在指令遵循和指令层级基准上取得了持续的改进。模型的推理能力还能推广到训练分布之外的安全关键设置中，例如通过将安全问题视为解决对抗用户输入与预先定义的高优先级策略之间冲突的方式，来增强抵御越狱和注入攻击的稳健性。

**Conclusion:** 研究结果证明，通过推理来处理指令层级结构为实现可靠的LLM提供了一条实用路径。对系统提示的更新可以导致模型行为的可控性和稳健性变化。

**Abstract:** As large language model (LLM) based systems take on high-stakes roles in
real-world decision-making, they must reconcile competing instructions from
multiple sources (e.g., model developers, users, and tools) within a single
prompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where
higher-level directives override lower-priority requests, is critical for the
reliability and controllability of LLMs. In this work, we reframe instruction
hierarchy resolution as a reasoning task. Specifically, the model must first
"think" about the relationship between a given user prompt and higher-priority
(system) instructions before generating a response. To enable this capability
via training, we construct VerIH, an instruction hierarchy dataset of
constraint-following tasks with verifiable answers. This dataset comprises both
aligned and conflicting system-user instructions. We show that lightweight
reinforcement learning with VerIH effectively transfers general reasoning
capabilities of models to instruction prioritization. Our finetuned models
achieve consistent improvements on instruction following and instruction
hierarchy benchmarks. This reasoning ability also generalizes to
safety-critical settings beyond the training distribution. By treating safety
issues as resolving conflicts between adversarial user inputs and predefined
higher-priority policies, our trained model enhances robustness against
jailbreak and prompt injection attacks. These results demonstrate that
reasoning over instruction hierarchies provides a practical path to reliable
LLMs, where updates to system prompts yield controllable and robust changes in
model behavior.

</details>


### [5] [EncouRAGe: Evaluating RAG Local, Fast, and Reliable](https://arxiv.org/abs/2511.04696)
*Jan Strich,Adeline Scharfenberg,Chris Biemann,Martin Semmann*

Main category: cs.CL

> 本研究介绍了EncouRAGe框架，用于简化RAG系统的开发和评估。实验结果表明，尽管Hybrid BM25在测试的多个数据集中表现最好，但RAG的表现仍不及Oracle Context。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机是解决RAG系统在科研领域的易用性和可复现性问题，尤其是希望为研究人员提供一个工具，以便他们更有效地评估RAG流程中的数据集。

**Method:** 文中提出了EncouRAGe，这是一个用来简化基于Large Language Models (LLMs) 和 Embedding Models的Retrieval-Augmented Generation (RAG)系统开发与评估的Python框架。该框架由类型表示、RAG工厂、推理、向量存储和度量五个模块构成，旨在提供灵活的实验和可扩展的开发环境。

**Result:** 实验结果显示，RAG的表现仍然不如Oracle Context。另外，Hybrid BM25在四个数据集中表现最好。此外，重新排序对性能的提升有限，并伴随响应延迟的增加。

**Conclusion:** 研究得出的结论是，虽然RAG仍然是一个有潜力的研究方向，但当前的表现仍然存在局限性。Hybrid BM25的方法在测试的多个数据集上表现最佳。此外，重新排序的效果有限。

**Abstract:** We introduce EncouRAGe, a comprehensive Python framework designed to
streamline the development and evaluation of Retrieval-Augmented Generation
(RAG) systems using Large Language Models (LLMs) and Embedding Models.
EncouRAGe comprises five modular and extensible components: Type Manifest, RAG
Factory, Inference, Vector Store, and Metrics, facilitating flexible
experimentation and extensible development. The framework emphasizes scientific
reproducibility, diverse evaluation metrics, and local deployment, enabling
researchers to efficiently assess datasets within RAG workflows. This paper
presents implementation details and an extensive evaluation across multiple
benchmark datasets, including 25k QA pairs and over 51k documents. Our results
show that RAG still underperforms compared to the Oracle Context, while Hybrid
BM25 consistently achieves the best results across all four datasets. We
further examine the effects of reranking, observing only marginal performance
improvements accompanied by higher response latency.

</details>


### [6] [multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder](https://arxiv.org/abs/2511.04698)
*K M Sajjadul Islam,John Fields,Praveen Madiraju*

Main category: cs.CL

> 研究提出了一种名为multiMentalRoBERTa的微型优化RoBERTa模型，用于从社交媒体文本中检测六种心理健康状况，其表现优于其他模型，并且提供了解释性。

<details>
  <summary>Details</summary>

**Motivation:** 早期检测心理健康情况对于提供及时支持、风险评估和推荐适当资源至关重要。

**Method:** 此研究介绍了multiMentalRoBERTa模型，该模型是针对常见心理健康状况的多分类问题进行微调的RoBERTa模型，该模型使用多分类别，包括压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀意念和中立话语。此外，研究还包括传统机器学习方法、领域特定的transformer模型以及基于提示的大语言模型的对比实验。

**Result:** 实验结果显示，multiMentalRoBERTa在六分类设置中达到了0.839的宏F1值，在五分类设置中（排除压力）达到了0.870，比微调的MentalBERT和其他基准分类器表现更好。

**Conclusion:** 研究强调了微调的transformer模型在敏感情境下可靠和可解释的检测中表现出的有效性，同时也强调了公平性、偏见缓解和人机协作安全协议的重要性。

**Abstract:** The early detection of mental health disorders from social media text is
critical for enabling timely support, risk assessment, and referral to
appropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned
RoBERTa model designed for multiclass classification of common mental health
conditions, including stress, anxiety, depression, post-traumatic stress
disorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple
curated datasets, data exploration is conducted to analyze class overlaps,
revealing strong correlations between depression and suicidal ideation as well
as anxiety and PTSD, while stress emerges as a broad, overlapping category.
Comparative experiments with traditional machine learning methods,
domain-specific transformers, and prompting-based large language models
demonstrate that multiMentalRoBERTa achieves superior performance, with macro
F1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup
(excluding stress), outperforming both fine-tuned MentalBERT and baseline
classifiers. Beyond predictive accuracy, explainability methods, including
Layer Integrated Gradients and KeyBERT, are applied to identify lexical cues
that drive classification, with a particular focus on distinguishing depression
from suicidal ideation. The findings emphasize the effectiveness of fine-tuned
transformers for reliable and interpretable detection in sensitive contexts,
while also underscoring the importance of fairness, bias mitigation, and
human-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as
a lightweight, robust, and deployable solution for enhancing support in mental
health platforms.

</details>


### [7] [Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding](https://arxiv.org/abs/2511.04699)
*Haneen Al-Homoud,Asma Ibrahim,Murtadha Al-Jubran,Fahad Al-Otaibi,Yazeed Al-Harbi,Daulet Toibazar,Kesen Wang,Pedro J. Moreno*

Main category: cs.CL

> This paper introduces Cross-Lingual SynthDocs, a large synthetic corpus for Arabic OCR and DU, which improves WER, CER, TEDS, and CharTeX when Qwen-2.5-VL is finetuned on it.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the scarcity of Arabic resources for OCR and DU by creating a comprehensive synthetic dataset.

**Method:** The method involves generating a large-scale synthetic corpus, Cross-Lingual SynthDocs, for Arabic documents to enhance OCR and DU. This includes using authentic scanned backgrounds, bilingual layouts, and diacritic-aware fonts, with a corpus containing over 2.5 million samples of various types such as texts, fully annotated tables, and charts with real data.

**Result:** The results show consistent improvements in WER and CER for OCR, and improvements in TEDS and CharTeX for other modalities when finetuning Qwen-2.5-VL on SynthDocs.

**Conclusion:** The conclusion is that SynthDocs, a scalable and visually realistic corpus, effectively advances research in multilingual document analysis for Arabic language resources.

**Abstract:** Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address
the scarcity of Arabic resources for Optical Character Recognition (OCR) and
Document Understanding (DU). The dataset comprises over 2.5 million of samples,
including 1.5 million textual data, 270K fully annotated tables, and hundred
thousands of real data based charts. Our pipeline leverages authentic scanned
backgrounds, bilingual layouts, and diacritic aware fonts to capture the
typographic and structural complexity of Arabic documents. In addition to text,
the corpus includes variety of rendered styles for charts and tables.
Finetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word
Error Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple
public Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart
Extraction Score (CharTeX) improved as well in other modalities. SynthDocs
provides a scalable, visually realistic resource for advancing research in
multilingual document analysis.

</details>


### [8] [Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation](https://arxiv.org/abs/2511.04700)
*Song Wang,Zihan Chen,Peng Wang,Zhepei Wei,Zhen Tan,Yu Meng,Cong Shen,Jundong Li*

Main category: cs.CL

> WinnowRAG是一种新的检索增强生成框架，通过系统地过滤噪声文档，提高大型语言模型检索相关信息的准确性。实验表明，WinnowRAG在多个真实数据集上优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 文章的主要动机是解决大型语言模型在获取最新或专业信息方面的局限性，通过增加检索文档的数量可能会引入大量无关或误导性信息从而降低响应准确性的挑战。

**Method:** WinnowRAG框架分两个阶段操作：第一阶段进行基于查询的聚类形成不同主题的集群并由LLM生成答案；第二阶段由评鉴LLM评估多个LLM生成的输出并进行有用文档和噪音文档的迭代分离。提出两种策略性合并技术，确保仅使用相关知识生成最终响应。

**Result:** 大量的实验在各种现实数据集上展示了WinnowRAG相对于最先进的基线方法的有效性。

**Conclusion:** WinnowRAG作为一个模型不可知的技术，不需对模型进行微调，很容易适应不同的任务，有效提高了响应的准确性。

**Abstract:** Retrieval-augmented generation (RAG) enhances large language models (LLMs) by
integrating external knowledge sources to address their limitations in
accessing up-to-date or specialized information. A natural strategy to increase
the likelihood of retrieving relevant information is to expand the number of
retrieved documents. However, involving more documents could introduce
significant noise, as many documents may be irrelevant or misleading, thereby
reducing the overall accuracy of the generated responses. To overcome the
challenge associated with handling a larger number of documents, we propose
WinnowRAG, a novel RAG framework designed to systematically filter out noisy
documents while preserving valuable content -- a process we refer to as
winnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware
clustering to group similar documents and form distinct topic clusters. Each
cluster is assigned to an LLM agent for generating a unique answer. In Stage
II, we perform winnowing, wherein a critic LLM evaluates the outputs of
multiple agents and iteratively separates useful documents from noisy ones. To
retain useful documents when discarding agents, we propose two strategic
merging techniques to ensure that only relevant knowledge is used for
generating the final response. Crucially, WinnowRAG is model-agnostic and does
not require any model fine-tuning, making it easily adaptable to various tasks.
Extensive experiments on various realistic datasets demonstrate the
effectiveness of WinnowRAG over state-of-the-art baselines.

</details>


### [9] [Measuring what Matters: Construct Validity in Large Language Model Benchmarks](https://arxiv.org/abs/2511.04703)
*Andrew M. Bean,Ryan Othniel Kearns,Angelika Romanou,Franziska Sofia Hafner,Harry Mayne,Jan Batzner,Negar Foroutan,Chris Schmitz,Karolina Korgul,Hunar Batra,Oishi Deb,Emma Beharry,Cornelius Emde,Thomas Foster,Anna Gausen,María Grandury,Simeng Han,Valentin Hofmann,Lujain Ibrahim,Hazel Kim,Hannah Rose Kirk,Fangru Lin,Gabrielle Kaili-May Liu,Lennart Luettgau,Jabez Magomere,Jonathan Rystrøm,Anna Sotnikova,Yushi Yang,Yilun Zhao,Adel Bibi,Antoine Bosselut,Ronald Clark,Arman Cohan,Jakob Foerster,Yarin Gal,Scott A. Hale,Inioluwa Deborah Raji,Christopher Summerfield,Philip H. S. Torr,Cozmin Ududec,Luc Rocher,Adam Mahdi*

Main category: cs.CL

> 研究团队审查了顶级会议中关于大型语言模型的基准，发现了一些能够影响其有效性的模式，并提出了改进LLM基准开发的具体建议。

<details>
  <summary>Details</summary>

**Motivation:** 对大型语言模型进行可靠的评估对于评估其能力并在部署前识别安全或鲁棒性问题至关重要。这项研究旨在提高度量标准的构建效度，即确保度量标准能够准确反映相关现象。

**Method:** 通过29位专家评审者对来自自然语言处理和机器学习顶级会议的445个大型语言模型（LLM）基准进行系统的审查，以评估这些模型的能力并找出安全或鲁棒性问题。

**Result:** 审查发现，测量现象、任务和评分标准等方面存在一些模式，这些问题削弱了相关主张的有效性。

**Conclusion:** 为了应对这些问题，提出了八个关键建议和详细的行动指南，以供研究人员和从业人员在开发LLM基准时参考。

**Abstract:** Evaluating large language models (LLMs) is crucial for both assessing their
capabilities and identifying safety or robustness issues prior to deployment.
Reliably measuring abstract and complex phenomena such as 'safety' and
'robustness' requires strong construct validity, that is, having measures that
represent what matters to the phenomenon. With a team of 29 expert reviewers,
we conduct a systematic review of 445 LLM benchmarks from leading conferences
in natural language processing and machine learning. Across the reviewed
articles, we find patterns related to the measured phenomena, tasks, and
scoring metrics which undermine the validity of the resulting claims. To
address these shortcomings, we provide eight key recommendations and detailed
actionable guidance to researchers and practitioners in developing LLM
benchmarks.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [10] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

> Introduces IndicVisionBench, a large-scale benchmark for evaluating VLMs in diverse cultural and linguistic settings focused on the Indian subcontinent, highlighting performance gaps across cultures.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the Western-centric bias in current evaluation benchmarks for vision-language models and to explore their performance in culturally diverse and multilingual environments.

**Method:** Content covers the introduction of a new benchmark named IndicVisionBench, designed to evaluate vision-language models in culturally and linguistically diverse settings centered on the Indian subcontinent, covering 10 Indian languages and English.

**Result:** The evaluation of 8 models across the benchmark revealed significant performance gaps, demonstrating the limitations of current VLMs when faced with culturally diverse and multilingual challenges.

**Conclusion:** IndicVisionBench sets a new standard for evaluating VLMs in multicultural contexts, laying the groundwork for more inclusive multimodal research.

**Abstract:** Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [11] [Knowledge-based anomaly detection for identifying network-induced shape artifacts](https://arxiv.org/abs/2511.04729)
*Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki*

Main category: cs.CV

> A novel two-stage method for detecting shape artifacts in synthetic images effectively identifies network-induced distortions, validated by quantitative and human reader studies, improving synthetic dataset quality.

<details>
  <summary>Details</summary>

**Motivation:** The paper aims to address the quality issues related to synthetic data used in training machine learning models, focusing on detecting artifacts, distortions, and unrealistic features that these datasets introduce.

**Method:** A two-stage framework is introduced for detecting network-induced shape artifacts in synthetic images. The method includes a feature extractor that analyzes the per-image distribution of angle gradients along anatomical boundaries and an isolation forest-based anomaly detector.

**Result:** The method achieves high AUROC values (0.97 and 0.91) for localizing artifacts in two synthetic mammography datasets, and there is notable agreement (66% and 68%) between the method’s identification of artifacts and human assessments.

**Conclusion:** The proposed anomaly detection method represents a significant contribution to the evaluation and improvement of the quality of synthetic datasets, enhancing their utility in clinical applications.

**Abstract:** Synthetic data provides a promising approach to address data scarcity for
training machine learning models; however, adoption without proper quality
assessments may introduce artifacts, distortions, and unrealistic features that
compromise model performance and clinical utility. This work introduces a novel
knowledge-based anomaly detection method for detecting network-induced shape
artifacts in synthetic images. The introduced method utilizes a two-stage
framework comprising (i) a novel feature extractor that constructs a
specialized feature space by analyzing the per-image distribution of angle
gradients along anatomical boundaries, and (ii) an isolation forest-based
anomaly detector. We demonstrate the effectiveness of the method for
identifying network-induced shape artifacts in two synthetic mammography
datasets from models trained on CSAW-M and VinDr-Mammo patient datasets
respectively. Quantitative evaluation shows that the method successfully
concentrates artifacts in the most anomalous partition (1st percentile), with
AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study
involving three imaging scientists confirmed that images identified by the
method as containing network-induced shape artifacts were also flagged by human
readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the
most anomalous partition, approximately 1.5-2 times higher than the least
anomalous partition. Kendall-Tau correlations between algorithmic and human
rankings were 0.45 and 0.43 for the two datasets, indicating reasonable
agreement despite the challenging nature of subtle artifact detection. This
method is a step forward in the responsible use of synthetic data, as it allows
developers to evaluate synthetic images for known anatomic constraints and
pinpoint and address specific issues to improve the overall quality of a
synthetic dataset.

</details>


### [12] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

> 本文提出了条件偏好优化（CPO）方法，以改善文本到图像生成的可控性，并在多个实验中展示了其相对于State-of-the-art ControlNet++的优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服Direct Preference Optimization (DPO)中难以保持图像对比度和质量一致性的问题，同时减少训练计算和存储资源的需求。

**Method:** 本文提出了条件偏好优化（CPO）的方法，以提高文本到图像生成的可控性，该方法通过在控制信号而非生成的图像上进行偏好学习来训练模型，以减少不确定性和复杂性。

**Result:** 实验表明，CPO方法在不同的控制类型（包括分割、人体姿态、边缘和深度图）上显著提高了可控性，错误率降低超过10%。

**Conclusion:** 通过使用条件偏好优化（CPO），可以有效减少训练过程中的对比损失方差，同时减少计算和存储资源的消耗，显著提升了生成图像的可控性。

**Abstract:** To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [13] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

> 本文提出了DARN，一种新的解码器架构，旨在解决基础模型（FMs）在地理空间分析中的应用挑战。DARN展示了超越现有方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 标准的微调方法或者高效的冻结骨干方法通常使用具有固定正则化策略的解码器，无法处理卫星图像中的显著异质性。

**Method:** DARN整合了三个关键创新：(1) 任务复杂度预测器（TCP），用于估计每个样本的难度；(2) 适应性dropout调制（ADM），根据预测的复杂度从0.1到0.5动态调整dropout率；(3) 动态容量门控（DCG），调节通道激活。

**Result:** DARN在全微调（非冻结骨干）方式中达到了新的最先进水平，在GeoBench多任务基准测试中达到86.66%的mIoU（比之前的最先进水平提高了5.56个百分点）。在高效适应（冻结骨干）方式中，DARN达到了与最先进水平相当的准确度（在Sen1Floods11上达到90.5%的mIoU），同时提供了实质性的优势，包括更好的OOD泛化（在AI4SmallFarms上增加了9.5个百分点的mIoU）、增强的鲁棒性（相对降低了17%的损坏误差）和改善了少数类别的表现。

**Conclusion:** DARN提供了一种更智能、更稳健且更高效的利用基础模型的方法，特别是在关键的地理空间应用程序中。

**Abstract:** Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [14] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

> 本研究介绍了一种新型的框架，该框架基于预训练-微调管道，可以将2D卫星图像转换为与TC相关的3D云图，首次实现了全球瞬时3D云图的创建，提升了对TC加强及其预测的理解。

<details>
  <summary>Details</summary>

**Motivation:** 由于TC结构的卫星观测有限，难以解析与TC加强相关的云特性，准确预测TC仍然是一个挑战。现有的方法已经被限制在TC不常见的区域，并且对于强烈的风暴验证不足。

**Method:** 我们引入了一个新的框架，基于预训练-微调管道，该框架可以从多个具有全球覆盖范围的卫星学习，将2D卫星图像转换为与TC结构相关的3D云图。

**Result:** 我们能够首次创建全球瞬时3D云图，并且准确地重建强烈风暴的3D结构。

**Conclusion:** 该模型不仅扩展了现有的卫星观测，还可以在观测缺失时提供估算值，这对于深化我们对TC加强的理解和提高预测至关重要。

**Abstract:** Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [15] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

> 本文介绍了一个名为EETnet的卷积神经网络，其能在低资源设备上进行基于事件数据的眼动追踪，提出两种模型版本，并提供了一套包括量化在内的完整工作流程。

<details>
  <summary>Details</summary>

**Motivation:** 由于基于事件的数据稀疏且异步的特性，基于事件的相机可以在微秒范围内提供低功耗和低延迟的眼动追踪，但现有的许多解决方案仅限于在强大的GPU上进行验证，没有在真正的嵌入式设备上进行部署。本论文旨在降低资源需求，实现在资源受限的硬件上运行。

**Method:** 此论文介绍了EETnet，一种专为使用基于事件的数据进行眼动追踪设计的卷积神经网络，能够在资源有限的微控制器上运行。作者还提出了一种使用公开数据集训练、评估和量化网络的方法。该架构包含两个版本：一种是在原图上叠加的网格上检测瞳孔的分类模型，另一种是像素级别的回归模型。

**Result:** 论文没有提供具体的结果数据，但描述了提出的方法和技术的潜力，旨在满足眼动追踪技术在低资源设备上的需求。

**Conclusion:** 该论文提出了EETnet，一种可以在资源有限的微控制器上运行的卷积神经网络，用于基于事件数据的眼动追踪，并提出了两种模型版本：网格上的分类模型和像素级别的回归模型，为眼动追踪技术在嵌入式设备上的应用提供了可能性。

**Abstract:** Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [16] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

> 提出了一种基于3D高斯混合体的显式点嵌入方法，旨在提高3D识别任务中的参数效率和计算速度，并展示了优于PointNet的性能。

<details>
  <summary>Details</summary>

**Motivation:** 旨在创建一个显式的几何表示方法，以替代3D识别任务中广泛使用的隐式表示方法，从而提高参数效率和计算速度。

**Method:** 提出3D高斯点编码器，这是一种基于学习的3D高斯混合体的显式点嵌入表示，用于3D识别任务，区别于传统的隐式表示如PointNet。为了学习3D高斯编码器，开发了基于自然梯度和点云预训练模型迁移的学习优化技术。

**Result:** 新的3D高斯点编码器比传统的PointNets更快，参数效率更高，通过利用计算几何的方法将速度提升至2.7倍，且维持类似的精度，同时分别减少了46%的内存和88%的FLOP。在Mamba3D中的应用展示了1.27倍的速度提升，以及内存和FLOP的显著减少。

**Conclusion:** 该研究确认了3D高斯点编码器作为显式表示的有效性和优越性，并将之作为Mamba3D的一部分应用，展示了更高的计算效率和参数效率。这种轻量级的架构能够实现CPU设备上的高帧率。

**Abstract:** In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [17] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

> 本研究通过Cellpose模型系统分析了生物医学图像分割中的数据冗余和跨领域转移对模型保持性能的影响，发现使用最少注释训练是很有可能的，且数据重用策略能改善多阶段模型迁移。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在系统地分析跨多种成像方式和细胞类型应用的生物医学图像分割模型（如Cellpose）面临的两个挑战：训练数据冗余的程度和跨领域转移对模型保持性能的影响。

**Method:** 该研究使用Cellpose模型作为研究案例，首先提出了一种简单的数据集量化（DQ）策略来构建紧凑且多样的训练子集，以评估数据冗余。其次，通过跨领域微调实验考察了灾难性遗忘问题。

**Result:** 实验表明，使用Cyto数据集进行的图像分割性能在仅使用10%的数据时就可以达到饱和，展示了大量的数据冗余和使用最少注释进行训练的潜力。此外，选择性DQ基础上的回忆（重新引入5-10%的源数据）有效恢复了源性能，而完全回忆可能会阻碍目标适应。训练域排序能够改善泛化并减少多阶段转移中的遗忘。

**Conclusion:** 研究结果强调了在生物医学图像分割中的数据为中心的设计的重要性，提示有效的训练不仅需要紧凑的数据子集，还需要考虑保持性能的学习策略和知情的域排序。

**Abstract:** Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [18] [An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention](https://arxiv.org/abs/2511.04811)
*Shuo Zhao,Yu Zhou,Jianxu Chen*

Main category: cs.CV

> 本文提出了结合主动学习和伪标签的生物医学图像分割方法，减少人工标注需求，维持高性能，解决了现有模型的一些局限性。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于解决现有模型（如nnU-Net）在少有标注数据的情况下效果不佳的问题以及大型基础模型未能在特定数据集上表现出色的局限性。

**Method:** 本文提出了一种基于数据的人工智能工作流，结合主动学习和伪标签技术，利用传统的神经网络和大型基础模型的优势，尽可能减少人为干预。流程首先利用基础模型生成伪标签，然后用于nnU-Net的自我配置。接着选取代表性核心集进行最小化的人工标注，以便对nnU-Net模型进行有效微调。

**Result:** 该方法在减少人工标注需求的同时保持了优秀的性能。

**Conclusion:** 这种方法显著减少了人工标注的需求，同时保持了竞争性的性能，为生物医学研究人员提供了一种可行的解决方案，使其能够应用最先进的AI技术进行分割任务。

**Abstract:** Biomedical image segmentation is critical for precise structure delineation
and downstream analysis. Traditional methods often struggle with noisy data,
while deep learning models such as U-Net have set new benchmarks in
segmentation performance. nnU-Net further automates model configuration, making
it adaptable across datasets without extensive tuning. However, it requires a
substantial amount of annotated data for cross-validation, posing a challenge
when only raw images but no labels are available. Large foundation models offer
zero-shot generalizability, but may underperform on specific datasets with
unique characteristics, limiting their direct use for analysis. This work
addresses these bottlenecks by proposing a data-centric AI workflow that
leverages active learning and pseudo-labeling to combine the strengths of
traditional neural networks and large foundation models while minimizing human
intervention. The pipeline starts by generating pseudo-labels from a foundation
model, which are then used for nnU-Net's self-configuration. Subsequently, a
representative core-set is selected for minimal manual annotation, enabling
effective fine-tuning of the nnU-Net model. This approach significantly reduces
the need for manual annotations while maintaining competitive performance,
providing an accessible solution for biomedical researchers to apply
state-of-the-art AI techniques in their segmentation tasks. The code is
available at https://github.com/MMV-Lab/AL_BioMed_img_seg.

</details>


### [19] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

> 本文提出了一种新的几何去噪方法，该方法通过使用表面法线向量的先验知识，基于总变差项进行正则化，并利用分裂Bregman方法求解优化问题。这种方法能够更有效地去除几何噪声。

<details>
  <summary>Details</summary>

**Motivation:** 面对几何噪声问题，传统的去噪方法可能无法充分保留几何表面的本质特征，本文旨在采用新的方法，利用先验的法线向量信息来提高去噪效果。

**Method:** 本文提出了一种新的几何去噪范式，利用表面法线向量的先验知识。这些先验知识以一组优选的法线向量（称为标签向量）的形式存在。去噪过程中嵌入了一个基于法线向量与标签向量集合中元素相似性的分割问题。通过总变差项实现了正则化。本文采用了分裂Bregman（ADMM）方法来求解优化问题，顶点更新步骤基于二阶形状微积分。

**Result:** 未提供具体结果，但可以推测出该方法能有效地去除几何噪声，同时保持几何表面的本质特征。

**Conclusion:** 研究得出，通过使用法线向量的先验知识和有效的优化方法，可以更有效地去除几何噪声。

**Abstract:** We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [20] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

> 本文提出了一种基于隐式自先验方法来从点云中恢复高质量表面的技术，利用交叉注意力机制进行训练，并通过隐式移动最小二乘方法将提取的密集点云积分，实现了比传统方法更高的细节保留和运行稳健性。

<details>
  <summary>Details</summary>

**Motivation:** 从不规则点云中恢复高质量表面是一个困难的问题，除非有强烈的几何学先验知识。本文的动机是引入一种无需外部训练数据的方法，以生成高保真度表面和保持几何细节的鲁棒性。

**Method:** 本文提出了一种隐式自先验方法，该方法直接从输入点云中提取形状特定的先验，并将其嵌入到隐式神经表示中。通过联合训练一个可学习嵌入的小词典和一个隐式距离场来实现这一目标。在每个查询位置，字段通过交叉注意力机制与词典交互，使网络能够捕捉并重复使用固有的重复结构和长距离关联。

**Result:** 实验表明，该方法在生成高保真表面时，在细节保留和对常见数据降级的鲁棒性方面都优于经典方法和基于学习的方法。

**Conclusion:** 通过自我监督的点云重建损失进行优化，本方法不需要外部训练数据，展现出在处理稀疏区域时利用学习到的先验进行正则化的有效性。

**Abstract:** Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [21] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

> 本文提出了一种名为Clinical-ComBAT的新方法，旨在解决ComBAT方法在临床应用中的局限性，这种方法提高了扩散MRI数据在多种临床场景中的标准化和应用效果。

<details>
  <summary>Details</summary>

**Motivation:** 扩散加权MRI派生的标量图可以有效评估神经退行性疾病和大脑各种条件下白质的微观结构属性。然而，DW-MRI在多数据采集点的数据组合上遇到了困难，这是在没有标准化以减轻特定扫描仪偏差的情况下。虽然广泛使用的ComBAT方法在研究中减少了站点效应，但其依赖线性协变量关系、同质人群、固定数量的站点和超额填满站点的限制，使得其在临床使用上受到约束。

**Method:** 我们提出了一种名为Clinical-ComBAT的方法来克服这些问题。Clinical-ComBAT独立地对每个站点进行标准化，允许在引入新的数据和诊所时具有灵活性。它采用了非线性多项式数据模型，并根据一个规范站点进行站点特定的标准化。该方法还包括适应小队列的方差先验估计、超参数调整和用于评估标准化质量的良好拟合指标。

**Result:** 我们在模拟数据和真实数据上展示了其有效性，表明扩散指标更好地对齐并且在规范建模中具有更强的应用性。

**Conclusion:** 临床实战证明，Clinical-ComBAT方法不仅可以有效对齐扩散指标，还增强了其在特定神经退行性疾病分析中的应用能力。

**Abstract:** Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>
