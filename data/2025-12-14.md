<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 26]
- [cs.CV](#cs.CV) [Total: 23]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi,Jessica Morley,Claudio Novelli,David Watson*

Main category: cs.CL

> A summary of large language models (LLMs) operating on token completion approach, focusing on their stochastic nature and similarity to human abductive reasoning. But these LLMs generate text based on learned patterns rather than true abductive reasoning.

<details>
  <summary>Details</summary>

**Motivation:** 该\u6587\u7ae0\u7684\u7531\u5f02\u662f\u5207\u5206\u770b \u5f53\u524dLLMs\u7684\u4e2d\u7684\u70b9\u4e18\u8fc7\u7a0b\u8fd0\u4f5c\u60c5\u51b5\u4f5c\u51fa\u5206\u6790\u3002\u901a\u8fc7\u5bf9\u6362\u8bd5\u7a0b\u5b50\u7b26\u5b50\u6a21\u578b\u7684\u7279\u70b9\u7684\u5206\u6790\uff0c\u6765\u6d4b\u8bd5\u5b83\u662f\u5426\u53ef\u4ee5\u4e00\u76f4\u76f8\u5f53\u4e8e\u4e2a\u4eba\u7684\u6389\u51b3\u7406\u8bba\u8fc7\u7a0b\u3002

**Method:** 该\u6587\u7ae0\u4f7f\u7528\u4e86\u4f8b\u5b50\uff0c\u8be5\u65b9\u6cd5\u5bf9\u786e\u5b9e\u4e0d\u8f6c\u5b9e\u8df5\u6210\u547d\u7406\u8bba\u8fc7\u7a0b\uff0c\u4e3b\u8981\u5c06\u6a21\u578b\u7b26\u5b50\u60c5\u51b5\u4e0b\u7684\u6362\u8bd5\u7a0b\u5b50\u7b26\u6a21\u5b9e\u6f14\u51fa\u6765\u4e00\u4e9b\u8d70\u9053\u6027\u7684\u7406\u8bba\u5143\u7d20\u3002

**Result:** {"tldr": "\u8be5\u6587\u7ae0\u6839\u636e\u7f16\u7801\u5b8c\u6210\u65b9\u5f0f\u603b\u7ed3\u4e86\u5f53\u524d\u5927\u89c4\u6a21\u578b\u8bed\u8a00\u6a21\u578b(LLMs)\u4e2d\u7684\u70b9\u4e18\u8fc7\u7a0b\u8fd0\u4f5c\uff0c\u5e76\u5bf9\u7279\u522b\u662f\u8be5\u65b9\u5f0f\u4e0e\u4e2a\u4eba\u7684\u6389\u51b3\u7406\u8bba\u76f8\u540c\u7684\u7279\u70b9\u8fdb\u884c\u4e86\u5207\u5206\u3002\u6587\u7ae0\u8ba8\u8bba\u524d\u7684\u6362\u8bd5\u7a0b\u5b50\u7b26\u56ea\u5b50\u6a21\u578b\u4e0d\u4e00\u Able to perform true abductive reasoning, only mimic human reasoning patterns based on training data.

**Conclusion:** 理\u8bba\u5143\u7d20\u8fde\u63a5\u76f8\u5173\u7684\u7a0b\u53e6\u4e00\u4e2a\u7ed3\u8bba\u8981\u70b9\u662f\u8be5\u65b9\u6cd5\u91c7\u7528\u7684\u6b63\u786e\u65b9\u5f0f\u53ca\u7ed3\u679c\u5bf9\u4e8e\u5b66\u4e60\u5f53\u524d\u7684\u5927\u89c4\u6a21\u578b\u6a21\u7684\u5b9e\u9a8c\u4e0e\u7528\u4e8e\u4eba\u5de5\u60c5\u51b5\u4e2d\u7684\u5b9e\u9645\u5bf9\u7279\u522b\u4e00\u5207\u3002

**Abstract:** This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [2] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei,John Stamper,Paulo F. Carvalho*

Main category: cs.CL

> 本研究通过一种新提出的'生成-验证'策略，利用小型语言模型（SLM）的文本生成和概率推理能力，成功地生成了高质量的问题。

<details>
  <summary>Details</summary>

**Motivation:** 由于大规模语言模型在学习分析研究中的广泛应用，本研究旨在探索小规模语言模型在自动生成问题方面的潜在价值，以作为一种补充。

**Method:** 研究提出了一种新颖的问题生成管道，该管道首先通过扩展生成生成大量候选问题，然后通过基于新颖的概率推理的选择性验证进行细化。

**Result:** 进行了两项评估研究，一项由七位人类专家进行，另一项由大型语言模型进行，以评估生成问题的质量。大多数评委认为生成问题有明确的答案，总体上与预期的学习目标相符合。

**Conclusion:** 研究发现表明，通过精心设计的依赖于其自身特性的工作流程指导，小规模语言模型可以有效地生成高质量的问题。

**Abstract:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [3] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

Main category: cs.CL

> This paper presents the DeepNews Framework, addressing the inability of current LLMs to achieve simultaneous low hallucination, deep logical coherence, and personalized expression in expert-level financial reporting by tackling the Statistical Smoothing Trap. The framework leads to improved generation quality, evidenced by successful blind testing against a state-of-the-art model.

<details>
  <summary>Details</summary>

**Motivation:** The paper aims to tackle the limitations of current LLMs in achieving low hallucination, deep logical coherence, and personalized expression simultaneously, particularly in expert-level vertical domains such as long-form financial journalism. It positions these challenges within the context of the Statistical Smoothing Trap.

**Method:** The DeepNews Framework is introduced, consisting of three modules: dual-granularity retrieval with a 10:1 information input ratio to reduce hallucinations, schema-guided strategic planning to create a logical skeleton, and adversarial constraint prompting to disrupt the smoothness of model-generated text.

**Result:** Experimental outcomes demonstrate a Knowledge Cliff in deep financial reporting where truthfulness declines with insufficient context under 15,000 characters, but improves with higher redundancy above 30,000 characters, achieving an HFR over 85%. Ecological validity testing resulted in a 25% acceptance rate for DeepNews-generated submissions, compared to 0% for a SOTA model.

**Conclusion:** The study concludes that the DeepNews Framework effectively combats the Statistical Smoothing Trap, significantly improving the quality of financial reporting content generated by machine learning models.

**Abstract:** Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [4] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park,Jeongseok Yun,Bohyung Kim*

Main category: cs.CL

> The paper proposes a two-stage prompting framework for generating personalized reviews in scenarios with limited user data. This method boosts relevance and personalization of automated responses in food delivery platforms without additional model fine-tuning.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of generic responses produced by large language models due to insufficient contextual user data, which negatively impacts engagement and effectiveness.

**Method:** Proposes a two-stage prompting framework that first infers explicit and implicit personas from short review texts, then uses these inferred personas to enhance response generation prompts. Adjusts decoding temperature during inference to promote diverse yet faithful responses.

**Result:** The method was evaluated using a real-world dataset from a Korean food delivery app, showing improvements in response relevance, personalization, precision, diversity, and semantic consistency.

**Conclusion:** Persona-augmented prompting is effective in enhancing personalized automated responses in situations with limited user data, without the need for further model fine-tuning.

**Abstract:** Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [5] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum,Hani Itani,Hasan Abed Al Kader Hammoud,Philip Torr,Adel Bibi,Bernard Ghanem*

Main category: cs.CL

> 本论文探讨了大规模语言模型在适应新任务时安全性能退化的问题，并发现持续学习方法能够有效解决这一问题，特别是在多种任务和模型上都能得到验证。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模语言模型的普及，对其进行安全校准变得越来越重要。为此，我们研究了在对大规模语言模型进行适应新任务时，安全性能的退化问题。

**Method:** 我们探讨了在大规模语言模型(LLMs)由于灾难性遗忘而在适应新任务时安全性的下降问题，并将保持安全视为持续学习(CL)问题。在用户将数据上传至服务提供商以获得定制化模型的场景中，我们采用了基于正则化、记忆和模型融合的方法，对安全性的下降进行系统的评估。

**Result:** 结果表明，与标准的微调方法相比，持续学习方法大体上能够实现较低的攻击成功率。特别是在使用数据未被篡改和数据遭到篡改这两种情况下，DER在保持任务效用的同时表现超越了其他方法和现有的保持安全性的基线。这些发现跨越了三种下游任务(GSM8K, SST2, Code)和三种模型家族(LLaMA2-7B, Mistral-7B, Gemma-2B)。

**Conclusion:** 这表明持续学习作为一种实用的方法可以帮助保持大规模语言模型的安全性。

**Abstract:** The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [6] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim*

Main category: cs.CL

> 本文提出了AutoMedic，用于多轮次临床对话中LLM的自动化评估，旨在解决现有评估框架未能覆盖的多方面评估策略。

<details>
  <summary>Details</summary>

**Motivation:** 考虑到在动态互动临床多轮对话场景中评估LLM的有效性以及识别出超越简单准确性的多方面评估策略，仍然是一个未被充分研究的领域。因此，作者设计了AutoMedic框架来解决这一问题。

**Method:** 本文介绍了AutoMedic，这是一个多代理模拟框架，用于自动化评估LLMs作为临床对话代理的表现。AutoMedic将现有的标准化QA数据集转化为虚拟患者档案，从而在真实临床上实现多轮次的医患对话模拟。

**Result:** 基于CARE指标，AutoMedic系统评估了几个临床对话代理的表现，其有效性和鲁棒性被人类专家验证。

**Conclusion:** 研究结论表明，AutoMedic作为临床对话代理的自动化评估框架是有效的，并为在对话医疗应用中有效开发LLM提供了实用指南。

**Abstract:** Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


### [7] [Multilingual VLM Training: Adapting an English-Trained VLM to French](https://arxiv.org/abs/2512.10336)
*Jules Lahmi,Alexis Roger*

Main category: cs.CL

> The paper evaluates different strategies for adapting vision-language models from English to multiple languages, emphasizing the importance of data quality for model performance across languages.

<details>
  <summary>Details</summary>

**Motivation:** The research aims to make advancements in artificial intelligence, particularly in Vision-Language Models, more accessible to non-English speakers by addressing language-specific barriers.

**Method:** This paper explores various methods for adapting an English-trained Vision-Language Model (VLM) to different languages including a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy.

**Result:** The study reveals that the quality and availability of translated datasets present significant challenges for the performance of multilingual VLMs.

**Conclusion:** Future work on multilingual VLMs should prioritize the collection of native-language datasets and refine translation strategies to overcome the current bottlenecks in performance.

**Abstract:** Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.

</details>


### [8] [Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale](https://arxiv.org/abs/2512.10398)
*Zhaodong Wang,Zhenting Qi,Sherman Wong,Nathan Hu,Samuel Lin,Jun Ge,Erwin Gao,Yining Yang,Ben Maurer,Wenlin Chen,David Recordon,Yilun Du,Minlan Yu,Ying Zhang*

Main category: cs.CL

> 本文介绍了一个名为Confucius Code Agent (CCA)的开源AI软件工程师，它能够在工业规模上操作，以解决现有编码代理的局限性，并提供透明度、可扩展性和可重现性，从而将研究原型与生产级系统联系起来。

<details>
  <summary>Details</summary>

**Motivation:** 现实世界的人工智能软件工程需要编码代理能够处理大规模知识库，并且能够跨长时间会话保持持久记忆以及进行复杂工具链的稳健协调。现有的开源编码代理在工业规模的工作负载中通常表现不佳，而专有的编码代理在实践性能上表现良好但缺乏扩展性、可解释性和可控性。为了填补这一空白，作者提出了Confucius Code Agent (CCA)。

**Method:** CCA使用Confucius SDK构建，该平台支持Agent Experience (AX)、User Experience (UX) 和 Developer Experience (DX)三个视角，提供了统一的协调器、层次化的工作记忆、持久的笔记系统、以及用于稳健工具使用的模块化扩展模块，以支持大规模的软件工程任务处理能力。此外，一个元代理自动化了代理配置的合成、评估和改进，通过构建-测试-改进的循环，实现了新任务、环境和工具栈上的快速代理开发。

**Result:** 在SWE-Bench-Pro基准测试上，CCA达到了解决方案的第一位(Resolve@1)的性能，达到54.3%的新高，超过以前的编码代理。

**Conclusion:** Confucius SDK和CCA为AI代理提供了一个透明、可扩展且可重现的基础，缩小了研究原型和生产级系统之间的差距，并支持工业规模的代理开发和部署。

**Abstract:** Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.

</details>


### [9] [Sliding Window Attention Adaptation](https://arxiv.org/abs/2512.10411)
*Yijiong Yu,Jiale Liu,Qingyun Wu,Huazheng Wang,Ji Pei*

Main category: cs.CL

> 文章研究如何让FA预训练的大语言模型适配SWA，提出了一套包括五个策略的适应方法，并分析了不同配置的性能和效率权衡。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于解决全注意力（FA）预训练的语言模型在推理时完全启用滑动窗口注意力（SWA）会导致长期上下文性能严重下降的问题。

**Method:** 方法包括五个适应滑动窗口注意力（SWA）的策略：仅在预填充期间应用SWA；保留“sink”标记；交错使用全注意力（FA）和SWA层；组合思维链（CoT）；微调。

**Result:** 实验表明，没有单独的方法足以适应SWA，但特定的策略组合可以有效恢复原始的长期上下文性能。

**Conclusion:** 结论是FA预训练的语言模型可以通过特定的策略组合有效地适应SWA，恢复原本的长期上下文性能，但我们需要在性能和效率之间权衡。

**Abstract:** The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation

</details>


### [10] [Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers](https://arxiv.org/abs/2512.10422)
*Youmin Ko,Sungjong Seo,Hyunjoon Kim*

Main category: cs.CL

> CoopRAG, a new framework for question answering, addresses the shortcomings of current retrieval-augmented generation methods by fostering cooperative interactions between a retriever and a large language model to improve factual accuracy.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to enhance RAG systems which, despite addressing some of the issues with LLMs, still suffer from inaccuracies such as incorrect retrieval and hallucinations. CoopRAG is proposed to improve the reliability and factual accuracy of answers generated by these models.

**Method:** This paper introduces CoopRAG, a new retrieval-augmented generation (RAG) framework for question answering that facilitates cooperative exchanges between a retriever and a large language model (LLM). The retriever and LLM work together in four main steps: unrolling the question into sub-questions and a reasoning chain with masked uncertain positions, retrieving relevant documents augmented with the chain, reranking using the retriever's layers, and reconstructing the chain using the LLM.

**Result:** The experimental results show that CoopRAG outperforms current top-tier QA models across both simple and multi-hop QA datasets, demonstrating enhanced performance in both retrieval and question-answering metrics.

**Conclusion:** The conclusion is that by using a cooperative framework between a retriever and a LLM, CoopRAG achieves considerable improvements in mitigating errors and enhancing the accuracy of QA tasks compared to current state-of-the-art methodologies.

**Abstract:** Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

</details>


### [11] [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)
*Dmitrii Stoianov,Danil Taranets,Olga Tsymboi,Ramil Latypov,Almaz Dautov,Vladislav Kruglikov,Nikita Surkov,German Abramov,Pavel Gein,Dmitry Abulkhanov,Mikhail Gashkov,Viktor Zelenkovskiy,Artem Batalov,Aleksandr Medvedev,Anatolii Potapov*

Main category: cs.CL

> T-pro 2.0是一款开源的俄罗斯语言模型，旨在支持混合推理和高效推断，具备直接回答和生成推理轨迹功能，发布了一系列资源便于研究和应用。

<details>
  <summary>Details</summary>

**Motivation:** 为了促进可重复的和可扩展的研究，作者发布了模型权重、T-Wix 500k指令语料库、T-Math推理基准测试和EAGLE权重，可供研究俄罗斯语言推理或模型及其推理管道的扩展或调整。

**Method:** 本文介绍了T-pro 2.0模型，该模型支持直接回答和生成推理轨迹的功能，并使用了Cyrillic稠密标记器和改编的EAGLE推测性解码管道来减少延迟。

**Result:** 该模型说明了如何使用这些资源来研究俄罗斯语言推理和调整或扩展模型及其推断管道，并提供了一个公共资源演示推理和非推理模式，展示跨领域通过推断栈获得的速度提升。

**Conclusion:** T-pro 2.0为构建和评估高效实用的俄罗斯LLM应用提供了可访问的开放系统。

**Abstract:** We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.

</details>


### [12] [Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring "Tortured Phrases" in Scientific Literature](https://arxiv.org/abs/2512.10435)
*Agniva Maiti,Prajwal Panth,Suresh Chandra Satapathy*

Main category: cs.CL

> The paper introduces SRAP, a novel framework for detecting and reconstructing the original phrasing in plagiarized scientific texts, achieving a 23.67% restoration accuracy.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of detecting and recovering original terminology from plagiarism-obfuscated scientific text using advanced paraphrasing techniques.

**Method:** Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework that includes a two-stage architecture: (1) statistical anomaly detection using SciBERT, (2) source-based semantic reconstruction using FAISS and SBERT.

**Result:** Experiments show SRAP achieves 23.67% restoration accuracy, significantly outperforming baseline methods that fail completely.

**Conclusion:** SRAP enhances the detection and restoration process of the original terminology in scientific texts, providing forensic analysis by linking obfuscated expressions to their probable source documents.

**Abstract:** The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate "tortured phrases", statistically improbable synonyms (e.g. "counterfeit consciousness" for "artificial intelligence"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.

</details>


### [13] [Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT](https://arxiv.org/abs/2512.10440)
*Nour El Houda Ben Chaabene,Hamza Hammami*

Main category: cs.CL

> The paper discusses the integration of Knowledge Graphs with LLMs using KG-BERT, leading to significant improvements in knowledge-intensive tasks and enhancing factual reliability.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of factual inconsistencies in LLMs by grounding them with structured knowledge from KGs.

**Method:** This paper integrates Knowledge Graphs (KGs) via KG-BERT to enhance the factual consistency and reasoning capabilities of Large Language Models (LLMs).

**Result:** Experiments demonstrate significant improvements in knowledge-intensive tasks such as question answering and entity linking, thus enhancing the factual reliability of LLMs.

**Conclusion:** This approach can lead to more context-aware and factually reliable next-generation LLMs.

**Abstract:** Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.

</details>


### [14] [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)
*Nour El Houda Ben Chaabene,Hamza Hammami,Laid Kahloul*

Main category: cs.CL

> 本文介绍了一种新型的教育心理意识对话系统，结合语义推理、多模态融合和时间建模，能够在教育环境中增强学习表现和情感健康，研究结果表明该系统能够提高学生动机，减少压力并带来适度的学术进步。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在通过对话系统增强教育环境中的学习表现和情感健康。当前教育情境中多模态融合和时间建模的研究表明了提供适应性、以学生为中心的教育干预措施的巨大潜力。

**Method:** 该论文提出了一种结合大型语言模型（LLMs）、知识图谱增强的BERT（KG-BERT）和具有注意力机制的双向长短期记忆网络（LSTM），用于实时分类学生的认知和情感状态的教育情境心理意识对话系统。系统利用文本语义、韵律语音特征和时间行为趋势等多模态数据来推断学生的参与度、压力和概念理解情况，区别于只能提供教学或情感支持的以往聊天机器人。

**Result:** 试点研究中，对比基准方法，研究表明这种结合了语义推理、多模态融合和时间建模的方法，能够显著提高学生的动机，减少学生的压力，并且在学术上有适度的进步。

**Conclusion:** 这些结果显示出通过整合语义推理、多模态融合和时间建模来支持适应性、以学生为中心的教育干预措施的作用。

**Abstract:** This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.

</details>


### [15] [Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs](https://arxiv.org/abs/2512.10453)
*Lars G. B. Johnsen*

Main category: cs.CL

> 研究通过评估大型语言模型对主谓倒装和寄生间隙现象的敏感性，证明这些模型能够从表面形式训练中生成结构化的一般化知识，这表明它们对句法结构具有功能上的敏感性，而不仅仅是线性顺序的理解。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探究传统的生成语法中作为句法结构证据的系统性语法差异，如主谓倒装和寄生间隙的捕捉，是否能在仅基于表面形式训练的大型语言模型中得以再现。

**Method:** 本研究利用大型语言模型（如GPT-4和LLaMA-3）来评估这些模型是否能够通过表面形式的训练来识别和区分语法结构，通过测试主谓倒装和寄生间隙现象的接受度评分。

**Result:** 结果显示，这些语言模型能够可靠地区分主谓倒装和寄生间隙中的语法结构，表明它们不仅能够理解线性顺序，也能对句法结构敏感。

**Conclusion:** 研究结论指出，大型语言模型能够通过表面形式训练获取的结构化一般化知识，表明它们在句法结构方面具有功能上的敏感性，尽管没有进行明确的编码。

**Abstract:** What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.

</details>


### [16] [XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](https://arxiv.org/abs/2512.10545)
*Iñaki Lacunza,José Javier Saiz,Alexander Shvets,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

> 优化多语言大型语言模型训练，平衡资源分布，发布新的IberianLLM-7B-Instruct。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有多语言大模型过分依赖高资源语言的局限性，提出新的训练方法以提升低资源语言的处理能力。

**Method:** 优化语言分布：通过在领域重加权DoGE算法扩展至多语言环境下的XDoGE算法训练一个小型代理模型，并重新调整数据集，使用确立的语言权重进行全尺寸模型训练（从头开始或在持续预训练阶段）。目标语言包括英语、西班牙语（高资源），葡萄牙语、加泰罗尼亚语（中等资源），加利西亚语、巴斯克语（低资源）。

实验采用Salamandra-2b模型，探讨小语种数据重复和主导语言欠采样的影响，并利用IberoBench框架进行量化评估。

最终发布了一个新的专注于伊比利亚语言和英语的IberianLLM-7B-Instruct模型，该模型从头开始预训练，并使用XDoGE权重通过CPT进一步改进。

**Result:** 通过使用XDoGE权重训练了优化后的语言模型，并在IberoBench上验证了方法的有效性，提高了多种资源等级下的语言性能。

**Conclusion:** 通过优化语言训练权重及数据重复方法，成功提高了多资源等级语言模型的性能，尤其是低资源语言的处理效果。

**Abstract:** Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.

</details>


### [17] [Causal Reasoning Favors Encoders: On The Limits of Decoder-Only Models](https://arxiv.org/abs/2512.10561)
*Amartya Roy,Elamparithy M,Kripabandhu Ghosh,Ponnurangam Kumaraguru,Adrian de Wynter*

Main category: cs.CL

> 研究表明，因果推理需要更加细致的多跳逻辑，目前的ICL方法在应对复杂因果问题时效果不佳。为了实现更有效的因果推理，应当应用带微调的编码器或编码器-解码器模型。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于，由于因果推理需要多跳组合和严格的合取控制，仅依赖输入中的虚假词项关系可能会导致误导性的结果。编码器和编码器-解码器架构由于其能够将输入投射到潜在空间中，因而可能更适合上述多跳合取推理，相对于仅有解码器的模型来说。

**Method:** 通过对比所有上述架构的微调版本（包括编码器、编码器-解码器架构以及仅有解码器的模型）在零样本和少量样本的ICL（在自然语言和非自然语言场景下），来验证研究假设。

**Result:** 研究结果表明，ICL单独使用时不足以实现可靠的因果推理，经常过度关注输入中的不相关特征。尤其是仅有解码器的模型对分布变化特别脆弱，而微调后的编码器和编码器-解码器模型则能更鲁棒地推广到我们的测试中，包括非自然语言的一部分。但两种架构在大规模下仅与仅有解码器模型的表现持平或略逊一筹。

**Conclusion:** 研究结论指出，为了实现成本效益和短期稳健的因果推理，带有针对性微调的编码器或编码器-解码器架构是更优的选择。

**Abstract:** In context learning (ICL) underpins recent advances in large language models (LLMs), although its role and performance in causal reasoning remains unclear. Causal reasoning demands multihop composition and strict conjunctive control, and reliance on spurious lexical relations of the input could provide misleading results. We hypothesize that, due to their ability to project the input into a latent space, encoder and encoder decoder architectures are better suited for said multihop conjunctive reasoning versus decoder only models. To do this, we compare fine-tuned versions of all the aforementioned architectures with zero and few shot ICL in both natural language and non natural language scenarios. We find that ICL alone is insufficient for reliable causal reasoning, often overfocusing on irrelevant input features. In particular, decoder only models are noticeably brittle to distributional shifts, while finetuned encoder and encoder decoder models can generalize more robustly across our tests, including the non natural language split. Both architectures are only matched or surpassed by decoder only architectures at large scales. We conclude by noting that for cost effective, short horizon robust causal reasoning, encoder or encoder decoder architectures with targeted finetuning are preferable.

</details>


### [18] [RoleRMBench & RoleRM: Towards Reward Modeling for Profile-Based Role Play in Dialogue Systems](https://arxiv.org/abs/2512.10575)
*Hang Ding,Qiming Feng,Dongqi Liu,Qi Zhao,Tao Yao,Shuo Wang,Dongsheng Chen,Jian Li,Zhenye Gan,Jiangning Zhang,Chengjie Wang,Yabiao Wang*

Main category: cs.CL

> 本研究针对角色扮演对话奖励模型评估的空白，提出了RoleRMBench基准测试，并开发了RoleRM模型，该模型在叙事连贯性和风格保真度上有重大进步。

<details>
  <summary>Details</summary>

**Motivation:** 已有的奖励模型在处理如角色扮演这样主观且开放性领域时表现出显著性能下降，难以捕捉到细致入微且基于角色的人类判断。因此，我们提出了一种专门针对角色扮演对话中奖励模型的基准测试RoleRMBench。

**Method:** 我们提出了RoleRM，这是一种基于连续隐含偏好（CIP）训练的奖励模型，该模型重新定义了主观评估，通过多种结构策略提供连续一致的成对监督。

**Result:** 实验结果显示，RoleRM在叙事连贯性和风格保真度方面优于开源和闭源奖励模型，平均高出24%以上。

**Conclusion:** 研究结果强调了连续偏好表示和标注一致性的重大意义，并为建立以人为中心的对话系统中的主观对齐奠定了基础。

**Abstract:** Reward modeling has become a cornerstone of aligning large language models (LLMs) with human preferences. Yet, when extended to subjective and open-ended domains such as role play, existing reward models exhibit severe degradation, struggling to capture nuanced and persona-grounded human judgments. To address this gap, we introduce RoleRMBench, the first systematic benchmark for reward modeling in role-playing dialogue, covering seven fine-grained capabilities from narrative management to role consistency and engagement. Evaluation on RoleRMBench reveals large and consistent gaps between general-purpose reward models and human judgment, particularly in narrative and stylistic dimensions. We further propose RoleRM, a reward model trained with Continuous Implicit Preferences (CIP), which reformulates subjective evaluation as continuous consistent pairwise supervision under multiple structuring strategies. Comprehensive experiments show that RoleRM surpasses strong open- and closed-source reward models by over 24% on average, demonstrating substantial gains in narrative coherence and stylistic fidelity. Our findings highlight the importance of continuous preference representation and annotation consistency, establishing a foundation for subjective alignment in human-centered dialogue systems.

</details>


### [19] [AgriGPT-Omni: A Unified Speech-Vision-Text Framework for Multilingual Agricultural Intelligence](https://arxiv.org/abs/2512.10624)
*Bo Yang,Lanfei Feng,Yunkui Chen,Yu Zhang,Jianyu Zhang,Xiao Xu,Nueraili Aierken,Shijian Li*

Main category: cs.CL

> 本文介绍了AgriGPT-Omni框架，它通过构建大规模农业数据集和采用三阶段训练方法，解决了农业应用中的多模态和多语言挑战，显著提升了多模态理解和推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型取得了迅速进展，但在农业应用中仍受限于多语言语音数据的缺乏，统一的多模态架构，以及全面的评估基准。为了解决这些问题，我们提出了AgriGPT-Omni框架。

**Method:** 文中提出了一种名为AgriGPT-Omni的农业多模态框架，该框架结合了语音、视觉和文本的统一。首先，作者构建了一个可扩展的数据合成和收集管道，将农业文本和图像转换为训练数据，生成迄今为止最大的农业语音数据集，包含六种语言的492000个合成语音样本和1400个真实语音样本。其次，基于此数据集，作者通过三阶段范式训练了首个农业多模态模型：文本知识注入，逐步多模态对齐和基于GRPO的强化学习，实现跨语言和模态的统一推理。

**Result:** 通过使用构建的数据集和多阶段训练方法，AgriGPT-Omni在多模态推理和多语言理解任务上展示出了显著的进步，并取得了优于通用基准模型的表现。

**Conclusion:** 实验表明，AgriGPT-Omni在多语言和多模态推理以及真实世界语音理解方面显著优于通用基线模型。所有模型、数据、基准测试和代码将被公开以促进可重复的研究，包容性的农业智能以及低资源地区的可持续AI发展。

**Abstract:** Despite rapid advances in multimodal large language models, agricultural applications remain constrained by the lack of multilingual speech data, unified multimodal architectures, and comprehensive evaluation benchmarks. To address these challenges, we present AgriGPT-Omni, an agricultural omni-framework that integrates speech, vision, and text in a unified framework. First, we construct a scalable data synthesis and collection pipeline that converts agricultural texts and images into training data, resulting in the largest agricultural speech dataset to date, including 492K synthetic and 1.4K real speech samples across six languages. Second, based on this, we train the first agricultural omni-model via a three-stage paradigm: textual knowledge injection, progressive multimodal alignment, and GRPO-based reinforcement learning, enabling unified reasoning across languages and modalities. Third, we propose AgriBench-Omni-2K, the first tri-modal benchmark for agriculture, covering diverse speech-vision-text tasks and multilingual slices, with standardized protocols and reproducible tools. Experiments show that AgriGPT-Omni significantly outperforms general-purpose baselines on multilingual and multimodal reasoning as well as real-world speech understanding. All models, data, benchmarks, and code will be released to promote reproducible research, inclusive agricultural intelligence, and sustainable AI development for low-resource regions.

</details>


### [20] [From Data Scarcity to Data Care: Reimagining Language Technologies for Serbian and other Low-Resource Languages](https://arxiv.org/abs/2512.10630)
*Smiljana Antonijevic Ubois*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Large language models are commonly trained on dominant languages like English, and their representation of low resource languages typically reflects cultural and linguistic biases present in the source language materials. Using the Serbian language as a case, this study examines the structural, historical, and sociotechnical factors shaping language technology development for low resource languages in the AI age. Drawing on semi structured interviews with ten scholars and practitioners, including linguists, digital humanists, and AI developers, it traces challenges rooted in historical destruction of Serbian textual heritage, intensified by contemporary issues that drive reductive, engineering first approaches prioritizing functionality over linguistic nuance. These include superficial transliteration, reliance on English-trained models, data bias, and dataset curation lacking cultural specificity. To address these challenges, the study proposes Data Care, a framework grounded in CARE principles (Collective Benefit, Authority to Control, Responsibility, and Ethics), that reframes bias mitigation from a post hoc technical fix to an integral component of corpus design, annotation, and governance, and positions Data Care as a replicable model for building inclusive, sustainable, and culturally grounded language technologies in contexts where traditional LLM development reproduces existing power imbalances and cultural blind spots.

</details>


### [21] [Textual Data Bias Detection and Mitigation - An Extensible Pipeline with Experimental Evaluation](https://arxiv.org/abs/2512.10734)
*Rebekka Görge,Sujan Sai Gannamaneni,Tabea Naeven,Hammam Abdelwahab,Héctor Allende-Cid,Armin B. Cremers,Lennard Helmer,Michael Mock,Anna Schmitz,Songkai Xue,Elif Yildirir,Maximilian Poretschkin,Stefan Wrobel*

Main category: cs.CL

> 提出了一种包含四个组件的数据偏差检测和缓解管道，以处理数据表示偏差和（显式的）刻板印象。通过人类验证和偏差基准测试等手段评估了该管道的有效性和影响。评估结果表明成功减少了偏见，但暴露了当前评估方法的问题，表明需要更有针对性的数据操作来解决模型的偏差问题。

<details>
  <summary>Details</summary>

**Motivation:** 文本数据中存在的多方面的偏见问题，包括有害语言和种族分布不均等，尤其是在训练大规模语言模型时。 欧盟的人工智能法案等监管要求识别并缓解数据中的偏见，以防止不公平的模型输出。然而，实际上缺乏实践指导和操作化方法。因此，我们提出了一个数据偏差检测和缓解管道。

**Method:** 我们提出了一套全面的数据偏差检测和缓解管道，包含四个部分，分别针对两种数据偏差类型，即表示偏差和（显式的）刻板印象，针对可配置的敏感属性。第一，我们利用基于质量标准生成的LLM词汇列表来检测相关群体标签。第二，使用人口代表得分来量化表示偏差。第三，利用社会语言学信息进行过滤来检测和缓解刻板印象。第四，通过语法和上下文感知的反事实数据增强来补偿表示偏差。

**Result:** 我们在性别、宗教和年龄的例子中进行了两方面的评估。首先，通过人类验证和基线比较来评估每个单独组件在数据去偏上的有效性。结果显示，我们成功地减少了文本数据中的表示偏差和（显式的）刻板印象。其次，通过偏差基准测试评估去偏数据对模型偏见减少的影响，发现虽然基于去偏数据的LLM没有在偏差基准测试上始终表现出更好的性能，但暴露了当前评估方法论中的关键缺口，凸显了针对出现的模型偏差进行有针对性的数据操作的必要性。

**Conclusion:** 本研究提出的数据偏差检测和缓解管道有效识别和缓解了数据中的表示偏差和（显式的）刻板印象。但是评估模型偏见时发现，去偏的数据并没有使模型在偏见基准测试上始终表现出更好的性能，这揭示了当前评估方法论中的问题，说明解决模型偏见需要更具体的针对性数据操作。

**Abstract:** Textual data used to train large language models (LLMs) exhibits multifaceted bias manifestations encompassing harmful language and skewed demographic distributions. Regulations such as the European AI Act require identifying and mitigating biases against protected groups in data, with the ultimate goal of preventing unfair model outputs. However, practical guidance and operationalization are lacking. We propose a comprehensive data bias detection and mitigation pipeline comprising four components that address two data bias types, namely representation bias and (explicit) stereotypes for a configurable sensitive attribute. First, we leverage LLM-generated word lists created based on quality criteria to detect relevant group labels. Second, representation bias is quantified using the Demographic Representation Score. Third, we detect and mitigate stereotypes using sociolinguistically informed filtering. Finally, we compensate representation bias through Grammar- and Context-Aware Counterfactual Data Augmentation. We conduct a two-fold evaluation using the examples of gender, religion and age. First, the effectiveness of each individual component on data debiasing is evaluated through human validation and baseline comparison. The findings demonstrate that we successfully reduce representation bias and (explicit) stereotypes in a text dataset. Second, the effect of data debiasing on model bias reduction is evaluated by bias benchmarking of several models (0.6B-8B parameters), fine-tuned on the debiased text dataset. This evaluation reveals that LLMs fine-tuned on debiased data do not consistently show improved performance on bias benchmarks, exposing critical gaps in current evaluation methodologies and highlighting the need for targeted data manipulation to address manifested model bias.

</details>


### [22] [Long-horizon Reasoning Agent for Olympiad-Level Mathematical Problem Solving](https://arxiv.org/abs/2512.10739)
*Songyang Gao,Yuzhe Gu,Zijian Wu,Lingkai Kong,Wenwei Zhang,Zhongrui Cai,Fan Zheng,Tianyou Ma,Junhao Shen,Haiteng Zhao,Duanyang Zhang,Huilun Zhang,Kuikun Liu,Chengqi Lyu,Yanhui Duan,Chiyu Chen,Ningsheng Ma,Jianfei Gao,Han Lyu,Dahua Lin,Kai Chen*

Main category: cs.CL

> 研究提出了一种新的验证方法OPV，解决了现有方法在复杂推理过程验证准确性和效率问题，并展示了通过迭代主动学习和少样本标注能在多个基准测试中达到或超越已有大型模型的效果。

<details>
  <summary>Details</summary>

**Motivation:** 目前基于结果的验证器无法检测长推理链中初级阶段的不可靠步骤，而基于过程的验证器在检测复杂长推理链中的错误时存在困难，主要受限于高质量标注数据的缺乏。为此，提出了一种新型的验证方法，以解决这些不足。

**Method:** 本研究提出了一个基于结果的过程验证器（OPV），通过总结长推理链中的结果来验证其过程，从而实现准确且高效的验证，并支持大规模标注。为了提升此验证器的能力，研究采用了一种迭代主动学习框架，利用专家标注逐步提高OPV的验证能力，减少标注成本。每一轮迭代中，当前最不确定的案例将被标注并用于训练新的OPV，通过拒绝细调（RFT）和强化学习可验证奖励（RLVR）进行提升。

**Result:** 实验显示OPV在多个测试中表现优越，特别是在我们的保留基准测试中取得了83.1的F1分数，超越了其他开源模型如Qwen3-Max-Preview的76.3分。同时，OPV能有效检测到合成数据集中的错误，并与专家评估结果一致。在与策略模型协同工作中，OPV显著提高了DeepSeek-R1-Distill-Qwen-32B的准确性。

**Conclusion:** OPV作为一种新的推理验证技术，展示了高效准确的验证能力和广泛的适用性，特别是在长推理链的验证领域。通过迭代主动学习框架和专家标注，OPV能够在减少标注成本的同时，持续提升其验证效果，并在实践中展现了协同工作能力，显著提升模型性能。

**Abstract:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the \textbf{O}utcome-based \textbf{P}rocess \textbf{V}erifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out \textsc{\thisbench}, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2\% to 73.3\% on AIME2025 as the compute budget scales.

</details>


### [23] [TRIDENT: A Redundant Architecture for Caribbean-Accented Emergency Speech Triage](https://arxiv.org/abs/2512.10741)
*Elroy Galbraith,Chadwick Sutherland,Donahue Morgan*

Main category: cs.CL

> TRIDENT系统设计用于优化紧急呼叫信息处理，尤其在自动语音识别失败时为调度员提供支持，确保加勒比地区紧急服务的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 解决紧急语音识别系统在非标准英语方言上的性能下降问题，特别是加勒比地区的方言，使得这些地区的紧急服务能够更有效地运行。

**Method:** TRIDENT系统包括三个层次：加勒比口音优化的ASR、通过大型语言模型进行本地实体抽取以及生物声波应激检测，旨在为调度员提供三种互补信息：转录信心度、结构化临床实体和声音压力指标。

**Result:** 该系统设计方案已建立完毕，理论基础也依托于应激诱导的语码转换心理学研究。未来工作将包括在加勒比紧急电话上的实际验证。

**Conclusion:** TRIDENT为抗口音紧急人工智系统建立了一个框架，确保加勒比地区的居民能够平等地接受国家级别的紧急处理规程。

**Abstract:** Emergency speech recognition systems exhibit systematic performance degradation on non-standard English varieties, creating a critical gap in services for Caribbean populations. We present TRIDENT (Transcription and Routing Intelligence for Dispatcher-Empowered National Triage), a three-layer dispatcher-support architecture designed to structure emergency call inputs for human application of established triage protocols (the ESI for routine operations and START for mass casualty events), even when automatic speech recognition fails.
  The system combines Caribbean-accent-tuned ASR, local entity extraction via large language models, and bio-acoustic distress detection to provide dispatchers with three complementary signals: transcription confidence, structured clinical entities, and vocal stress indicators. Our key insight is that low ASR confidence, rather than representing system failure, serves as a valuable queue prioritization signal -- particularly when combined with elevated vocal distress markers indicating a caller in crisis whose speech may have shifted toward basilectal registers. A complementary insight drives the entity extraction layer: trained responders and composed bystanders may report life-threatening emergencies without elevated vocal stress, requiring semantic analysis to capture clinical indicators that paralinguistic features miss.
  We describe the architectural design, theoretical grounding in psycholinguistic research on stress-induced code-switching, and deployment considerations for offline operation during disaster scenarios. This work establishes a framework for accent-resilient emergency AI that ensures Caribbean voices receive equitable access to established national triage protocols. Empirical validation on Caribbean emergency calls remains future work.

</details>


### [24] [OPV: Outcome-based Process Verifier for Efficient Long Chain-of-Thought Verification](https://arxiv.org/abs/2512.10756)
*Zijian Wu,Lingkai Kong,Wenwei Zhang,Songyang Gao,Yuzhe Gu,Zhongrui Cai,Tianyou Ma,Yuhong Liu,Zhi Wang,Runyuan Ma,Guangyu Wang,Wei Li,Conghui He,Dahua Lin,Kai Chen*

Main category: cs.CL

> 本文提出OPV，通过有迭代的主动学习框架，使用更少的标注成本来验证长推理链，有效提升验证效率和精度，实验结果表明OPV具备广泛适用性和优越性。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是解决现有基于结果的验证器（OVs）无法检查长期推理链中不确定性中间步骤，以及基于过程的验证器（PVs）由于高质量标注数据稀缺，难以可靠检测复杂长期推理链错误的问题。

**Method:** 本文提出了Outcome-based Process Verifier (OPV)方法，该方法通过验证长链推理（CoTs）总结结果的合理性来实现准确且高效的验证，并支持大规模标注。为了提升OPV的验证能力，作者采用了迭代的主动学习框架，在每一轮迭代中，根据当前最优OPV的不确定性情况选取最不确定的案例进行专家标注，并通过拒绝微调（RFT）和强化学习（RLVR）进行模型训练从而迭代优化。

**Result:** 实验结果表明，OPV在OPV-Bench数据集上达到了新的SOTA性能，其中OPV的F1分数为83.1，优于开源模型Qwen3-Max-Preview的76.3。同时，OPV在合成数据集中有效检测误报，与专家评估结果相符。此外，当与策略模型协作时，OPV仍然能表现出性能提升，例如，在计算预算增加的情况下，使DeepSeek-R1-Distill-Qwen-32B在AIME2025数据集上的准确率从55.2%提升到73.3%。

**Conclusion:** 本文提出了一种新的验证方法OPV，其通过迭代的主动学习框架和低标注成本实现高效、准确的验证，同时证明了OPV在各种实验和数据集下的广泛适用性和优越性能。

**Abstract:** Large language models (LLMs) have achieved significant progress in solving complex reasoning tasks by Reinforcement Learning with Verifiable Rewards (RLVR). This advancement is also inseparable from the oversight automated by reliable verifiers. However, current outcome-based verifiers (OVs) are unable to inspect the unreliable intermediate steps in the long reasoning chains of thought (CoTs). Meanwhile, current process-based verifiers (PVs) have difficulties in reliably detecting errors in the complex long CoTs, limited by the scarcity of high-quality annotations due to the prohibitive costs of human annotations. Therefore, we propose the Outcome-based Process Verifier (OPV), which verifies the rationale process of summarized outcomes from long CoTs to achieve both accurate and efficient verification and enable large-scale annotation. To empower the proposed verifier, we adopt an iterative active learning framework with expert annotations to progressively improve the verification capability of OPV with fewer annotation costs. Specifically, in each iteration, the most uncertain cases of the current best OPV are annotated and then subsequently used to train a new OPV through Rejection Fine-Tuning (RFT) and RLVR for the next round. Extensive experiments demonstrate OPV's superior performance and broad applicability. It achieves new state-of-the-art results on our held-out OPV-Bench, outperforming much larger open-source models such as Qwen3-Max-Preview with an F1 score of 83.1 compared to 76.3. Furthermore, OPV effectively detects false positives within synthetic dataset, closely align with expert assessment. When collaborating with policy models, OPV consistently yields performance gains, e.g., raising the accuracy of DeepSeek-R1-Distill-Qwen-32B from 55.2% to 73.3% on AIME2025 as the compute budget scales.

</details>


### [25] [Grow Up and Merge: Scaling Strategies for Efficient Language Adaptation](https://arxiv.org/abs/2512.10772)
*Kevin Glocker,Kätriin Kukk,Romina Oji,Marcel Bollmann,Marco Kuhlmann,Jenny Kunz*

Main category: cs.CL

> 研究结果表明，扩大模型规模是一种有效策略，可以提高预训练模型对于新语言的适应能力，并且在多语言模型合并方面也表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 实现包括中等资源和较低资源语言在内的高性能语言模型仍然是一项挑战。大规模多语言模型仍然表现不佳，尤其是在较小模型规模下。

**Method:** 通过全面的缩放消融实验，我们测试了扩大一个英文基础模型是否能够比标准的继续预训练更有效地适应新的目标语言。

**Result:** 我们发现，一旦接触到足够数量的目标语言数据，更大的扩展模型可以达到甚至超过在大量数据上进行更多继续预训练的小模型的性能。

**Conclusion:** 缩小模型规模有助于保留基础模型在英语上的能力，从而减少灾难性遗忘。此外，虽然合并方法不如联合多语言训练有效，但是扩大规模后的合并方法比小规模的合并方法表现更好。

**Abstract:** Achieving high-performing language models which include medium- and lower-resource languages remains a challenge. Massively multilingual models still underperform compared to language-specific adaptations, especially at smaller model scales. In this work, we investigate scaling as an efficient strategy for adapting pretrained models to new target languages. Through comprehensive scaling ablations with approximately FLOP-matched models, we test whether upscaling an English base model enables more effective and resource-efficient adaptation than standard continued pretraining. We find that, once exposed to sufficient target-language data, larger upscaled models can match or surpass the performance of smaller models continually pretrained on much more data, demonstrating the benefits of scaling for data efficiency. Scaling also helps preserve the base model's capabilities in English, thus reducing catastrophic forgetting. Finally, we explore whether such scaled, language-specific models can be merged to construct modular and flexible multilingual systems. We find that while merging remains less effective than joint multilingual training, upscaled merges perform better than smaller ones. We observe large performance differences across merging methods, suggesting potential for improvement through merging approaches specialized for language-level integration.

</details>


### [26] [Script Gap: Evaluating LLM Triage on Indian Languages in Native vs Roman Scripts in a Real World Setting](https://arxiv.org/abs/2512.10780)
*Manurag Khullar,Utkarsh Desai,Poorva Malviya,Aman Dalmia,Zheyuan Ryan Shi*

Main category: cs.CL

> 论文基于真实世界数据评估了大型语言模型在印度语言的罗马化文本上的表现，发现这些模型可能理解罗马化输入内容，但在分类输出上缺乏可靠性，这在关键的健康护理领域中构成安全隐患。

<details>
  <summary>Details</summary>

**Motivation:** 现有的研究很少使用真实数据来评估印度语言的罗马化文本。这项研究的动机在于探索罗马化文本在关键健康护理领域中对大型语言模型可靠性的影响。

**Method:** 研究通过在一个现实世界的母性和新生儿健康筛选数据集上，评估大型语言模型对印度五种语言和尼泊尔语罗马化文本的表现，以探讨罗马化文本对大型语言模型可靠性的影响。

**Result:** 研究结果揭示，对于罗马化信息，大型语言模型的表现一致性有所下降，F1分数相比原生脚本低了5-12分。

**Conclusion:** 这项研究指出在其合作伙伴印度的母性健康组织上，这种脚本表现差距可能会导致大约2百万的错误筛选。尽管LLMs经常能正确推断罗马化查询的语义意图，然而，其最终分类输出仍然在面对罗马化输入中的正字法噪声时非常脆弱。这些发现突出了LLM健康系统中的一个关键安全盲点：模型可能看似理解罗马化输入，但仍可能在这种输入上不可靠。

**Abstract:** Large Language Models (LLMs) are increasingly deployed in high-stakes clinical applications in India. In many such settings, speakers of Indian languages frequently communicate using romanized text rather than native scripts, yet existing research rarely evaluates this orthographic variation using real-world data. We investigate how romanization impacts the reliability of LLMs in a critical domain: maternal and newborn healthcare triage. We benchmark leading LLMs on a real-world dataset of user-generated queries spanning five Indian languages and Nepali. Our results reveal consistent degradation in performance for romanized messages, with F1 scores trailing those of native scripts by 5-12 points. At our partner maternal health organization in India, this gap could cause nearly 2 million excess errors in triage. Crucially, this performance gap by scripts is not due to a failure in clinical reasoning. We demonstrate that LLMs often correctly infer the semantic intent of romanized queries. Nevertheless, their final classification outputs remain brittle in the presence of orthographic noise in romanized inputs. Our findings highlight a critical safety blind spot in LLM-based health systems: models that appear to understand romanized input may still fail to act on it reliably.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [27] [Neuromorphic Eye Tracking for Low-Latency Pupil Detection](https://arxiv.org/abs/2512.09969)
*Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes*

Main category: cs.CV

> 本研究提出一种基于SNN的眼球追踪模型，通过替换单元模块并简化复杂性，实现了在减少计算需求和提高能效的同时保持眼部追踪精度。

<details>
  <summary>Details</summary>

**Motivation:** 当前帧基管道难以满足可穿戴系统中眼动追踪的低延迟和低功耗要求，因此本研究旨在通过拟议的方法提高性能，尤其是在AR/VR等新兴技术中的应用。

**Method:** 采用轻量级LIF层替换了现有顶级事件驱动眼球追踪模型中的循环和注意力模块，并利用深度可分离卷积减少模型复杂度。

**Result:** 所提出模型获得3.7-4.1像素的平均误差，接近特定应用的仿生系统Retina的精度（3.24像素），同时将模型大小减少20倍，理论计算量减少850倍。

**Conclusion:** 结果表明，可以将高性能事件驱动眼球追踪架构重新设计为SNN，从而在保持实时可穿戴部署精度的同时实现显著的效率提升。

**Abstract:** Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.

</details>


### [28] [ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects](https://arxiv.org/abs/2512.10031)
*Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim*

Main category: cs.CV

> The paper presents ABBSPO, a new method for WS-OOD, that utilizes adaptive scaling and symmetry priors for enhanced performance, overcoming the limitations of prior techniques.

<details>
  <summary>Details</summary>

**Motivation:** to address the limitations of previous HBox-supervised OOD methods, which result in inaccurate scale estimation and learning collapse, and to achieve state-of-the-art performance in WS-OOD.

**Method:** adaptive bounding box scaling (ABBS) and a symmetric prior angle (SPA) loss, forming the ABBSPO framework, to improve accuracy in weakly supervised oriented object detection (WS-OOD).

**Result:** ABBSPO achieves state-of-the-art performance, demonstrating higher accuracy than existing methods in WS-OOD.

**Conclusion:** the proposed ABBSPO method effectively improves WS-OOD, providing more accurate orientation and scale predictions compared to previous techniques.

**Abstract:** Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.

</details>


### [29] [Diffusion Is Your Friend in Show, Suggest and Tell](https://arxiv.org/abs/2512.10038)
*Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi*

Main category: cs.CV

> 文章采用了一种新的方法，将扩散模型用于辅助自回归生成，通过这种方法在COCO数据集上实现了最佳结果，展现了一个未充分利用但有潜力的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 扩散去噪模型在生成计算机视觉任务中表现出色，但在离散域中仍无法超越传统的自回归解决方案。为此，提出了一个新的研究方向，试图优化现有模型。

**Method:** 提出了一种新的范式，即将扩散模型用于提供自回归生成的建议，而不是直接替代它们。从而结合了扩散模型的双向和细化能力以及自回归模型提供的强大语言结构。

**Result:** 展示了提出方法的有效性，通过Show, Suggest and Tell (SST) 在COCO数据集上实现了最佳结果，特别是没有使用强化学习的情况下在COCO数据集上实现了125.1的CIDEr-D得分，分别超越了自回归和扩散模型的最新结果1.5和2.5分。

**Conclusion:** 研究结果表明，建议模块对于提升描述质量具有积极影响，这指示了一个目前未充分利用但有潜力的研究方向。

**Abstract:** Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: https://github.com/jchenghu/show\_suggest\_tell.

</details>


### [30] [MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata](https://arxiv.org/abs/2512.10041)
*Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman*

Main category: cs.CV

> MetaVoxel框架通过学习单一扩散过程覆盖所有变量来建模医疗成像数据和元数据，统一了多个任务，并展示了广泛的临床应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 大多数当前的方法都是训练来建模由特定预测方向和特定输入变量集定义的条件分布。而MetaVoxel旨在统一通常需要单独的条件模型的任务，并支持使用任意输入子集进行灵活的零样本推理，而无需特定任务的再训练。

**Method:** 引入了MetaVoxel，这是一种生成性联合扩散建模框架，通过学习单一扩散过程来覆盖所有变量，从而建模成像数据和临床元数据的联合分布。

**Result:** 使用超过10,000个T1加权MRI扫描图像与临床元数据的9个数据集，显示单个MetaVoxel模型可以实现图像生成、年龄估计和性别预测，性能与现有特定任务的基线相当。

**Conclusion:** 这些发现共同表明，联合多模态扩散为统一医疗AI模型和实现更广泛的临床应用提供了一个有前途的方向。

**Abstract:** Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible inference.Together, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

</details>


### [31] [Independent Density Estimation](https://arxiv.org/abs/2512.10067)
*Jiahao Liu*

Main category: cs.CV

> 研究提出一种新的名为独立密度估计（IDE）的方法，以改善视觉语言模型的组合泛化能力，并展示了在不同数据集上的较好表现。

<details>
  <summary>Details</summary>

**Motivation:** 大范围视觉语言模型在图像描述和条件图像生成等许多领域取得了显著成果。然而，这些模型在实现人类般的组合泛化方面仍面临困难。该研究旨在通过提出IDE方法解决这个问题。

**Method:** 本研究提出了一种名为独立密度估计（IDE）的新方法，旨在学习句子中的单个词与图像中相应特征之间的关联，以实现组合泛化。我们构建了两个基于IDE理念的模型：第一个模型使用完全解耦的视觉表征作为输入，第二个模型则利用变分自编码器从原始图像中获取部分解耦的功能。此外，我们还提出了一种基于熵的组合推理方法来结合句子中每个词的预测。

**Result:** 模型在未见过的组合上比当前的模型表现出更好的泛化能力。

**Conclusion:** 我们的模型在评估的各种数据集中，展示出对比现有模型有超然的在未见过的句子组合泛化能力。

**Abstract:** Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Nevertheless, these models still encounter difficulties in achieving human-like compositional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connection between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy-based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.

</details>


### [32] [TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing](https://arxiv.org/abs/2512.10095)
*Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan*

Main category: cs.CV

> TraceFlow is a novel framework for high-fidelity rendering of dynamic specular scenes, achieving physically accurate reflections using advanced rendering techniques and an improved training strategy.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the challenges of precise reflection direction estimation and physically accurate reflection modeling in dynamic scenes for high-fidelity rendering.

**Method:** We propose a Residual Material-Augmented 2D Gaussian Splatting representation to model dynamic geometry and material properties, allowing accurate reflection ray computation. A Dynamic Environment Gaussian and a hybrid rendering pipeline are introduced to decompose rendering into diffuse and specular components, and a coarse-to-fine training strategy is devised to improve optimization stability.

**Result:** Experiments on dynamic scene benchmarks show that TraceFlow outperforms the prior methods with sharper and more realistic specular reflections.

**Conclusion:** TraceFlow is effective, outperforming prior methods both quantitatively and qualitatively in producing sharper and more realistic specular reflections in complex dynamic environments.

**Abstract:** We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.

</details>


### [33] [Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information](https://arxiv.org/abs/2512.10102)
*Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari*

Main category: cs.CV

> 提出了层次实例追踪任务及相应的基准数据集，证明了该任务具有挑战性。

<details>
  <summary>Details</summary>

**Motivation:** 此研究旨在引入一种新型的任务，即层次实例追踪，以解决现有追踪技术在处理复杂视频内容时面临的挑战，并提供一个用于评估和推进相关技术的基准数据集。

**Method:** 我们提出了一个名为层次实例追踪的新任务，该任务要求追踪预定义类别中的所有对象和部件实例，并维持这些实例之间的层次关系。为此任务，我们还引入了第一个基准数据集，包括2765个独特的实体，这些实体在552个视频中被追踪，并且属于40个类别（涵盖对象和部件）。

**Result:** 对四种模型的七种变体进行评估后，表明新的数据集具有挑战性。

**Conclusion:** 我们创建的数据集证明了该任务对于研究和改进实例层次追踪算法的价值，并为未来的研究指明了方向。

**Abstract:** We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/

</details>


### [34] [Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization](https://arxiv.org/abs/2512.10151)
*Charles Fanning,Mehmet Emin Aktas*

Main category: cs.CV

> 研究提出一种基于持久同调和小波变换的方法提高乳腺癌影像识别的准确率，通过实验表明在有限训练数据集情形下，添加该方法可显著提升模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺癌是全球女性中诊断最常见癌症，也是癌症死亡的主要原因之一。尽管筛查性乳房X线摄影可以降低死亡率，但误诊率仍较高。对外部不同成像设备、成像方式和患者群体中的模型准确度下降的问题，本研究旨在提出一种新的方法来提高其性能。

**Method:** 本研究提出了一种基于小波变换的持久同调向量化条件信号，用以改进在外部性能的表现。通过拓扑数据分析，图像的结构特征在不同强度阈值下被总结，并转换成稳定的空间多尺度图谱，这些图谱在输入级别上通过通道级联的方法整合进两阶段的检测管道中。

**Result:** 在受限制的训练预算下，向ConvNeXt Tiny添加小波持续性通道后，在INbreast数据集上的患者级别AUC从0.55提升到了0.75。

**Conclusion:** 该研究表明，提出的基于拓扑数据的多尺度图谱在深度学习模型中作为辅助特征，可以在有限训练数据情况下提升乳腺癌检测的准确性。

**Abstract:** Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.

</details>


### [35] [Feature Coding for Scalable Machine Vision](https://arxiv.org/abs/2512.10209)
*Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

> 本文介绍了由MPEG发起的FCM标准及其在压缩中间特征方面的性能成果，平均减少了85.14%的比特率，提供了高效的、适用于带宽受限和隐私敏感的消费者应用的智能特征部署。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络(DNNs)驱动现代机器视觉，但在边缘设备上部署具有高计算需求。传统的在设备上运行整个模型或卸载到云端的方法在延迟、带宽和隐私方面存在权衡。将推理工作负载在边缘和云端之间分配是一种解决方案，但传输中间特征以实现这种分配带来了新的带宽挑战。

**Method:** 介绍了Moving Picture Experts Group (MPEG) 开始的Feature Coding for Machines (FCM) 标准，设计了Feature Coding Test Model (FCTM)，通过压缩中间特征实现了显著的比特率减少，平均减少85.14%，同时保持精度。

**Result:** 论文展示了Feature Coding Test Model (FCTM) 的设计和性能，在多个视觉任务中实现了平均85.14%的比特率减少，同时保持高精度。

**Conclusion:** FCM提供了一个可扩展的途径，以高效且可互操作的方式部署智能特征，适合带宽受限和隐私敏感的消费类应用。

**Abstract:** Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.

</details>


### [36] [Latent Chain-of-Thought World Modeling for End-to-End Driving](https://arxiv.org/abs/2512.10226)
*Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic*

Main category: cs.CV

> 研究提出了一种新的自动驾驶模型LCDrive，使用潜在语言而非自然语言来实现链式决策过程，表现出更快的推理速度和更好的轨迹质量。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的目标是改进自动驾驶性能和安全性，提出了一种更有效的推理表现形式，以期超越基于文本的推理方式的效率。

**Method:** 本研究提出了一种名为Latent-CoT-Drive（LCDrive）的模型，该模型利用潜在语言来表述决策链（CoT），而不是用自然语言。该方法通过使用动作提案令牌和世界模型令牌在与动作对齐的潜在空间中统一了CoT推理和决策，这些令牌能够表达所考虑动作的可能结果。

**Result:** 在大规模端到端驾驶基准测试中，LCDrive相比于不基于推理和基于文本推理的模型，展示了更快的推理速度，更高质量的轨迹以及更具互动性的强化学习收益。

**Conclusion:** 该研究证明了通过潜在语言表述决策链（CoT）的方法能够显著提升自动驾驶模型在推理速度和轨迹质量方面的性能，同时改进了强化学习的效果。

**Abstract:** Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

</details>


### [37] [Emerging Standards for Machine-to-Machine Video Coding](https://arxiv.org/abs/2512.10230)
*Md Eimran Hossain Eimon,Velibor Adzic,Hari Kalva,Borko Furht*

Main category: cs.CV

> The study proposes redesigning video data transfer for machine-to-machine communication, focusing on FCM and VCM methods to improve bitrate efficiency and privacy, while demonstrating that HEVC can serve current needs without impacting performance.

<details>
  <summary>Details</summary>

**Motivation:** The primary motivation for the research is to address the limitations of current machine-to-machine communication systems in terms of bandwidth efficiency, scalability, and privacy violation due to the reliance on human-optimized video codecs for transmitting raw visual data.

**Method:** The study redesigns the machine-to-machine communication pipeline for visual data using two methods: Video Coding for Machines (VCM) which applies task-aware coding tools in the pixel domain and Feature Coding for Machines (FCM) which compresses intermediate neural features.

**Result:** Experiments indicate that FCM can maintain accuracy similar to edge inference while significantly lowering bitrate. Additionally, VCM and FCM are analyzed with H.26X codecs where it's found that HEVC and VVC perform almost identically, though HEVC slightly outperforms VVC in tracking tasks compared to AVC.

**Conclusion:** The research concludes that redesigned codecs such as FCM and VCM can effectively reduce bitrates and support task performance without significant loss of accuracy, paving the way for more efficient, scalable, and private machine-to-machine communication systems. Moreover, it highlights that existing codecs like HEVC can support these tasks adequately, possibly avoiding the need for new hardware deployment.

**Abstract:** Machines are increasingly becoming the primary consumers of visual data, yet most deployments of machine-to-machine systems still rely on remote inference where pixel-based video is streamed using codecs optimized for human perception. Consequently, this paradigm is bandwidth intensive, scales poorly, and exposes raw images to third parties. Recent efforts in the Moving Picture Experts Group (MPEG) redesigned the pipeline for machine-to-machine communication: Video Coding for Machines (VCM) is designed to apply task-aware coding tools in the pixel domain, and Feature Coding for Machines (FCM) is designed to compress intermediate neural features to reduce bitrate, preserve privacy, and support compute offload. Experiments show that FCM is capable of maintaining accuracy close to edge inference while significantly reducing bitrate. Additional analysis of H.26X codecs used as inner codecs in FCM reveals that H.265/High Efficiency Video Coding (HEVC) and H.266/Versatile Video Coding (VVC) achieve almost identical machine task performance, with an average BD-Rate increase of 1.39% when VVC is replaced with HEVC. In contrast, H.264/Advanced Video Coding (AVC) yields an average BD-Rate increase of 32.28% compared to VVC. However, for the tracking task, the impact of codec choice is minimal, with HEVC outperforming VVC and achieving BD Rate of -1.81% and 8.79% for AVC, indicating that existing hardware for already deployed codecs can support machine-to-machine communication without degrading performance.

</details>


### [38] [Multi-dimensional Preference Alignment by Conditioning Reward Itself](https://arxiv.org/abs/2512.10237)
*Jiho Jang,Jinyoung Kim,Kyungjune Baek,Nojun Kwak*

Main category: cs.CV

> MCDPO is proposed to address the limitations of the standard DPO formulation, significantly improving performance by disentangling reward axes.

<details>
  <summary>Details</summary>

**Motivation:** To solve the reward conflict issue in standard DPO formulation, where the model unlearns desirable features due to scalar aggregation.

**Method:** Multi Reward Conditional DPO (MCDPO) resolves reward conflicts by disentangling the Bradley-Terry objective and injecting a preference outcome vector as a condition during training, enabling independent learning of each reward axis within a single network.

**Result:** Experiments on Stable Diffusion 1.5 and SDXL showed MCDPO achieves superior performance on benchmarks. The conditional framework also allows dynamic and multiple-axis control at inference.

**Conclusion:** MCDPO demonstrates superior performance and flexibility in managing multiple reward dimensions without additional training, making it a more robust and versatile learning framework.

**Abstract:** Reinforcement Learning from Human Feedback has emerged as a standard for aligning diffusion models. However, we identify a fundamental limitation in the standard DPO formulation because it relies on the Bradley-Terry model to aggregate diverse evaluation axes like aesthetic quality and semantic alignment into a single scalar reward. This aggregation creates a reward conflict where the model is forced to unlearn desirable features of a specific dimension if they appear in a globally non-preferred sample. To address this issue, we propose Multi Reward Conditional DPO (MCDPO). This method resolves reward conflicts by introducing a disentangled Bradley-Terry objective. MCDPO explicitly injects a preference outcome vector as a condition during training, which allows the model to learn the correct optimization direction for each reward axis independently within a single network. We further introduce dimensional reward dropout to ensure balanced optimization across dimensions. Extensive experiments on Stable Diffusion 1.5 and SDXL demonstrate that MCDPO achieves superior performance on benchmarks. Notably, our conditional framework enables dynamic and multiple-axis control at inference time using Classifier Free Guidance to amplify specific reward dimensions without additional training or external reward models.

</details>


### [39] [Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective](https://arxiv.org/abs/2512.10244)
*Tian Liu,Anwesha Basu,James Caverlee,Shu Kong*

Main category: cs.CV

> 本研究针对半监督少样本学习（SSFSL）中的视觉语言模型（VLM）进行了分析，提出了SWIFT方法来优化模型的性能，并在多个SSFSL基准测试上展示了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管有强大的开源视觉语言模型（VLM）及其预训练数据，SSFSL领域对该资源的利用较少，而相关的少样本学习（FSL）领域已经利用这些资源来提升性能。为了实现自动标注等实际应用，SSFSL应该更好地利用开源资源。

**Method:** 本研究提出了一种称为分阶段精细调整与温度调整（SWIFT）的方法，通过简单技术如分类器初始化和温度调整，解决了视觉语言模型（VLM）在半监督少样本学习（SSFSL）中的softmax概率分布平坦问题，提高了未标记数据的利用率和监督信号强度。

**Result:** 通过SWIFT方法能使现有的SSL方法在有限的标记数据、大量的未标记数据和从VLM预训练集中检索的任务相关但有噪声的数据上有效精细调整VLM。在五个SSFSL基准测试上，SWIFT方法的性能优于最近的FSL和SSL方法。

**Conclusion:** 实验结果表明，与最近的FSL和SSL方法相比，SWIFT方法能够提升大约5个百分点的精度，甚至接近监督学习方法的表现，其中未标记数据被地面真实标签进行标注。

**Abstract:** Semi-supervised few-shot learning (SSFSL) formulates real-world applications like ''auto-annotation'', as it aims to learn a model over a few labeled and abundant unlabeled examples to annotate the unlabeled ones. Despite the availability of powerful open-source Vision-Language Models (VLMs) and their pretraining data, the SSFSL literature largely neglects these open-source resources. In contrast, the related area few-shot learning (FSL) has already exploited them to boost performance. Arguably, to achieve auto-annotation in the real world, SSFSL should leverage such open-source resources. To this end, we start by applying established SSL methods to finetune a VLM. Counterintuitively, they significantly underperform FSL baselines. Our in-depth analysis reveals the root cause: VLMs produce rather ''flat'' distributions of softmax probabilities. This results in zero utilization of unlabeled data and weak supervision signals. We address this issue with embarrassingly simple techniques: classifier initialization and temperature tuning. They jointly increase the confidence scores of pseudo-labels, improving the utilization rate of unlabeled data, and strengthening supervision signals. Building on this, we propose: Stage-Wise Finetuning with Temperature Tuning (SWIFT), which enables existing SSL methods to effectively finetune a VLM on limited labeled data, abundant unlabeled data, and task-relevant but noisy data retrieved from the VLM's pretraining set. Extensive experiments on five SSFSL benchmarks show that SWIFT outperforms recent FSL and SSL methods by $\sim$5 accuracy points. SWIFT even rivals supervised learning, which finetunes VLMs with the unlabeled data being labeled with ground truth!

</details>


### [40] [RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection](https://arxiv.org/abs/2512.10248)
*Zhuo Wang,Xiliang Liu,Ligang Sun*

Main category: cs.CV

> 本文提出了RobustSora基准测试，用于评估数字水印在AI生成视频检测中的鲁棒性，通过实验表明检测模型在水印操作下的性能变化，指出部分模型依赖水印，并强调需要水印感知的训练策略。

<details>
  <summary>Details</summary>

**Motivation:** 此论文的动机在于评估当前生成模型嵌入数字水印对AI生成视频检测的影响，发现并解决检测器部分依赖于这些水印模式的问题。

**Method:** 我们通过构建包含6,500个视频的数据集来评估数字水印对AI生成视频检测的影响，这些视频分为四类：真品-无水印（A-C）、真品-假水印（A-S）、生成-带水印（G-W）和生成-去水印（G-DeW）。这项基准测试包括两个评估任务：任务I测试对去水印AI视频的性能，任务II评估在带假水印的真品视频中的误报率。

**Result:** 实验测试了包括专门的AIGC检测器、Transformer架构和MLLM方法在内的十种模型，发现水印操作后性能变化范围在2-8个百分点之间，其中Transformer模型表现出6-8个百分点的依赖，而MLLM模型则表现出更广泛的变化模式。

**Conclusion:** 研究结果显示，不同模型对水印的依赖程度不同，指出AI生成视频检测器可能依赖于水印，从而强调了开发水印感知训练方法的必要性。

**Abstract:** The proliferation of AI-generated video technologies poses challenges to information integrity. While recent benchmarks advance AIGC video detection, they overlook a critical factor: many state-of-the-art generative models embed digital watermarks in outputs, and detectors may partially rely on these patterns. To evaluate this influence, we present RobustSora, the benchmark designed to assess watermark robustness in AIGC video detection. We systematically construct a dataset of 6,500 videos comprising four types: Authentic-Clean (A-C), Authentic-Spoofed with fake watermarks (A-S), Generated-Watermarked (G-W), and Generated-DeWatermarked (G-DeW). Our benchmark introduces two evaluation tasks: Task-I tests performance on watermark-removed AI videos, while Task-II assesses false alarm rates on authentic videos with fake watermarks. Experiments with ten models spanning specialized AIGC detectors, transformer architectures, and MLLM approaches reveal performance variations of 2-8pp under watermark manipulation. Transformer-based models show consistent moderate dependency (6-8pp), while MLLMs exhibit diverse patterns (2-8pp). These findings indicate partial watermark dependency and highlight the need for watermark-aware training strategies. RobustSora provides essential tools to advance robust AIGC detection research.

</details>


### [41] [THE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose](https://arxiv.org/abs/2512.10251)
*Eunho Lee,Chaehyeon Song,Seunghoon Jeong,Ayoung Kim*

Main category: cs.CV

> THE-Pose 是一种新的类别级别6D姿态估计框架，通过表面嵌入和混合图融合技术有效克服了现有3D-GC方法的局限性。该方法能够稳定地估计未见过的或复杂的物体姿态，即使是被严重遮挡的情况下。在REAL275数据集上相较于基线方法有显著提高。

<details>
  <summary>Details</summary>

**Motivation:** 现有的3D-GC方法侧重于局部几何和深度信息，对复杂物体和视觉歧义具有脆弱性。THE-Pose旨在通过引入拓扑先验，提高在类别级别的姿态估计的鲁棒性。

**Method:** THE-Pose框架利用表面嵌入提取具有不变性的图像域拓扑特征，并使用Hybrid Graph Fusion (HGF)模块自适应地结合图案特征与点云特征。

**Result:** 在REAL275数据集上，THE-Pose相比3D-GC基线方法HS-Pose提升了35.8%，且在所有关键指标上超越了先前的最佳结果。

**Conclusion:** THE-Pose框架证明了在类别级别的6D姿态估计中，结合2D图像上下文和3D几何结构的拓扑特征的有效性。该技术在处理复杂和遮挡物体时展现出强大的稳定性。

**Abstract:** Category-level object pose estimation requires both global context and local structure to ensure robustness against intra-class variations. However, 3D graph convolution (3D-GC) methods only focus on local geometry and depth information, making them vulnerable to complex objects and visual ambiguities. To address this, we present THE-Pose, a novel category-level 6D pose estimation framework that leverages a topological prior via surface embedding and hybrid graph fusion. Specifically, we extract consistent and invariant topological features from the image domain, effectively overcoming the limitations inherent in existing 3D-GC based methods. Our Hybrid Graph Fusion (HGF) module adaptively integrates the topological features with point-cloud features, seamlessly bridging 2D image context and 3D geometric structure. These fused features ensure stability for unseen or complicated objects, even under significant occlusions. Extensive experiments on the REAL275 dataset show that THE-Pose achieves a 35.8% improvement over the 3D-GC baseline (HS-Pose) and surpasses the previous state-of-the-art by 7.2% across all key metrics. The code is avaialbe on https://github.com/EHxxx/THE-Pose

</details>


### [42] [GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule](https://arxiv.org/abs/2512.10252)
*Rui Wang,Yimu Sun,Jingxing Guo,Huisi Wu,Jing Qin*

Main category: cs.CV

> This paper introduces GDKVM, which achieves high segmentation accuracy and robustness in echocardiography video while maintaining real-time performance through innovative methods like LKVA, GDR, and KPFF.

<details>
  <summary>Details</summary>

**Motivation:** The challenges in echocardiography imaging, such as noise, artifacts, and the heart's motion, affect the accuracy of cardiac chamber segmentation which is important for the analysis of cardiac function.

**Method:** The model employs Linear Key-Value Association (LKVA) to effectively model inter-frame correlations, and introduces Gated Delta Rule (GDR) to efficiently store intermediate memory states. Key-Pixel Feature Fusion (KPFF) module is designed to integrate local and global features at multiple scales.

**Result:** GDKVM was validated on the CAMUS and EchoNet-Dynamic datasets, demonstrating superior segmentation accuracy and robustness compared to other state-of-the-art methods.

**Conclusion:** GDKVM outperforms existing approaches in terms of segmentation accuracy and robustness while ensuring real-time performance on echocardiography video datasets.

**Abstract:** Accurate segmentation of cardiac chambers in echocardiography sequences is crucial for the quantitative analysis of cardiac function, aiding in clinical diagnosis and treatment. The imaging noise, artifacts, and the deformation and motion of the heart pose challenges to segmentation algorithms. While existing methods based on convolutional neural networks, Transformers, and space-time memory networks have improved segmentation accuracy, they often struggle with the trade-off between capturing long-range spatiotemporal dependencies and maintaining computational efficiency with fine-grained feature representation. In this paper, we introduce GDKVM, a novel architecture for echocardiography video segmentation. The model employs Linear Key-Value Association (LKVA) to effectively model inter-frame correlations, and introduces Gated Delta Rule (GDR) to efficiently store intermediate memory states. Key-Pixel Feature Fusion (KPFF) module is designed to integrate local and global features at multiple scales, enhancing robustness against boundary blurring and noise interference. We validated GDKVM on two mainstream echocardiography video datasets (CAMUS and EchoNet-Dynamic) and compared it with various state-of-the-art methods. Experimental results show that GDKVM outperforms existing approaches in terms of segmentation accuracy and robustness, while ensuring real-time performance. Code is available at https://github.com/wangrui2025/GDKVM.

</details>


### [43] [VLM-NCD:Novel Class Discovery with Vision-Based Large Language Models](https://arxiv.org/abs/2512.10262)
*Yuetong Su,Baoguo Wei,Xinyu Wang,Xu Li,Lixin Li*

Main category: cs.CV

> 提出了一种用于新颖类别发现（NCD）的多模态框架LLM-NCD，该框架通过融合视觉-文本语义克服了现有方法中的特征区分度不足和数据长尾分布等问题，并在实验中展示了优越的分类性能，特别是对长尾分布问题的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的NCD方法主要依赖于视觉特征，这些方法存在特征区分度不足和数据长尾分布等问题。

**Method:** LLM-NCD, 一个通过融合视觉和文本语义以及原型引导聚类来突破现有瓶颈的多模态框架。该框架的创新点在于通过联合优化已知类别图像和文本特征来建模聚类中心和语义原型，并采用两阶段发现机制，通过语义亲和度阈值和自适应聚类来动态分离已知或新颖样本。

**Result:** 实验结果表明，在CIFAR-100数据集上，该方法对未知类别的准确性提高了高达25.3%，并且是首个在NCD文献中显示出对长尾分布独特鲁棒性的方法。

**Conclusion:** 实验表明，LLM-NCD方法对未知类别的准确率有了显著提高，并且第一次在NCD文献中显示出对长尾数据分布的独特鲁棒性。

**Abstract:** Novel Class Discovery aims to utilise prior knowledge of known classes to classify and discover unknown classes from unlabelled data. Existing NCD methods for images primarily rely on visual features, which suffer from limitations such as insufficient feature discriminability and the long-tail distribution of data. We propose LLM-NCD, a multimodal framework that breaks this bottleneck by fusing visual-textual semantics and prototype guided clustering. Our key innovation lies in modelling cluster centres and semantic prototypes of known classes by jointly optimising known class image and text features, and a dualphase discovery mechanism that dynamically separates known or novel samples via semantic affinity thresholds and adaptive clustering. Experiments on the CIFAR-100 dataset show that compared to the current methods, this method achieves up to 25.3% improvement in accuracy for unknown classes. Notably, our method shows unique resilience to long tail distributions, a first in NCD literature.

</details>


### [44] [Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction](https://arxiv.org/abs/2512.10267)
*Chen Ziwen,Hao Tan,Peng Wang,Zexiang Xu,Li Fuxin*

Main category: cs.CV

> Long-LRM++结合半显式场景表示和轻量解码器技术，实现了高质量且实时的场景重建与渲染，克服了现有方法的精度和速度问题。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在解决现有方法在高精度重建时易出错和实时渲染不可行的问题。具体来说，直接预测高数量的高斯参数容易出现模糊，而基于隐式表示的方法由于需要逐帧解压缩，无法实现实时渲染。

**Method:** 该论文提出了Long-LRM++模型，采用半显式场景表示方法结合轻量级解码器，旨在保持隐式表示的优点同时实现实时渲染。

**Result:** Long-LRM++在DL3DV数据集上的渲染质量与LaCT相当，同时在A100 GPU上实现了14 FPS的实时渲染。此外，它还能在ScanNetv2数据集上提供优于直接使用高斯渲染的新型视图深度预测。

**Conclusion:** 通过结合半显式场景表示和轻量级解码器，Long-LRM++克服了先前隐式方法的速度限制，实现了高质量的实时渲染，并验证了该框架各组件的有效性。

**Abstract:** Recent advances in generalizable Gaussian splatting (GS) have enabled feed-forward reconstruction of scenes from tens of input views. Long-LRM notably scales this paradigm to 32 input images at $950\times540$ resolution, achieving 360° scene-level reconstruction in a single forward pass. However, directly predicting millions of Gaussian parameters at once remains highly error-sensitive: small inaccuracies in positions or other attributes lead to noticeable blurring, particularly in fine structures such as text. In parallel, implicit representation methods such as LVSM and LaCT have demonstrated significantly higher rendering fidelity by compressing scene information into model weights rather than explicit Gaussians, and decoding RGB frames using the full transformer or TTT backbone. However, this computationally intensive decompression process for every rendered frame makes real-time rendering infeasible. These observations raise key questions: Is the deep, sequential "decompression" process necessary? Can we retain the benefits of implicit representations while enabling real-time performance? We address these questions with Long-LRM++, a model that adopts a semi-explicit scene representation combined with a lightweight decoder. Long-LRM++ matches the rendering quality of LaCT on DL3DV while achieving real-time 14 FPS rendering on an A100 GPU, overcoming the speed limitations of prior implicit methods. Our design also scales to 64 input views at the $950\times540$ resolution, demonstrating strong generalization to increased input lengths. Additionally, Long-LRM++ delivers superior novel-view depth prediction on ScanNetv2 compared to direct depth rendering from Gaussians. Extensive ablation studies validate the effectiveness of each component in the proposed framework.

</details>


### [45] [Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation](https://arxiv.org/abs/2512.10275)
*Hongsin Lee,Hye Won Chung*

Main category: cs.CV

> 提出了一种新的方法，样本自适应对抗蒸馏（SAAD），用于改善模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的工作往往忽略采用最先进的鲁棒教师模型。通过对大量分析发现，更强的教师模型并不一定产生更鲁棒的学生模型，这一现象称为鲁棒饱和现象。通常归因于模型容量差距，但我们发现这种解释并不完整。

**Method:** 通过重新加权训练样本（根据其测量的对抗传输能力）而不增加计算成本，提出了样本自适应对抗蒸馏（SAAD）方法。

**Result:** 在CIFAR-10、CIFAR-100和Tiny-ImageNet上的实验显示，与之前的方法相比，SAAD在AutoAttack鲁棒性方面表现更优。

**Conclusion:** 对抗传输能力是成功的鲁棒性转移的关键因素，SAAD方法通过重新加权训练样本提升了模型对抗攻击的鲁棒性。

**Abstract:** Adversarial distillation in the standard min-max adversarial training framework aims to transfer adversarial robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students-a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability-the fraction of student-crafted adversarial examples that remain effective against the teacher-as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods. Our code is available at https://github.com/HongsinLee/saad.

</details>


### [46] [MotionEdit: Benchmarking and Learning Motion-Centric Image Editing](https://arxiv.org/abs/2512.10284)
*Yixin Wan,Lei Ke,Wenhao Yu,Kai-Wei Chang,Dong Yu*

Main category: cs.CV

> 本文介绍了一个新的数据集MotionEdit用于动作为中心的图像编辑，并提出了一种名为MotionNFT的方法来改善现有模型在该任务上的表现。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对现有图像编辑数据集在处理动作和互动编辑时存在的不足，提出了MotionEdit数据集和MotionEdit-Bench评估基准，目的是解决在保持身份、结构和物理合理性的同时修改动作的问题。

**Method:** 介绍的MotionNFT方法是一种基于运动指导的负样本感知微调框架，通过计算输入图像与模型编辑后的图像之间的运动流匹配度来指导模型进行准确的运动转换。

**Result:** 实验结果表明，MotionNFT框架能够显著提升FLUX.1、Kontext和Qwen-Image-Edit模型在运动编辑任务中的编辑质量和运动保真度，而不会降低其一般编辑能力。

**Conclusion:** MotionNFT作为后训练框架，在多个模型上验证了其在保持一般编辑能力的同时，提升运动编辑质量和保真度的有效性。

**Abstract:** We introduce MotionEdit, a novel dataset for motion-centric image editing-the task of modifying subject actions and interactions while preserving identity, structure, and physical plausibility. Unlike existing image editing datasets that focus on static appearance changes or contain only sparse, low-quality motion edits, MotionEdit provides high-fidelity image pairs depicting realistic motion transformations extracted and verified from continuous videos. This new task is not only scientifically challenging but also practically significant, powering downstream applications such as frame-controlled video synthesis and animation.
  To evaluate model performance on the novel task, we introduce MotionEdit-Bench, a benchmark that challenges models on motion-centric edits and measures model performance with generative, discriminative, and preference-based metrics. Benchmark results reveal that motion editing remains highly challenging for existing state-of-the-art diffusion-based editing models. To address this gap, we propose MotionNFT (Motion-guided Negative-aware Fine Tuning), a post-training framework that computes motion alignment rewards based on how well the motion flow between input and model-edited images matches the ground-truth motion, guiding models toward accurate motion transformations. Extensive experiments on FLUX.1 Kontext and Qwen-Image-Edit show that MotionNFT consistently improves editing quality and motion fidelity of both base models on the motion editing task without sacrificing general editing ability, demonstrating its effectiveness.

</details>


### [47] [ShotDirector: Directorially Controllable Multi-Shot Video Generation with Cinematographic Transitions](https://arxiv.org/abs/2512.10286)
*Xiaoxue Wu,Xinyuan Chen,Yaohui Wang,Yu Qiao*

Main category: cs.CV

> 提出了一个名为ShotDirector的框架，该框架通过结合参数级的相机控制和高层次的编辑模式感知提示，实现了类似电影效果的多镜头间可控过渡。

<details>
  <summary>Details</summary>

**Motivation:** 镜头过渡在多镜头视频生成中起着关键作用，而近期的研究进展主要集中在镜头间的低层次视觉一致性上，忽略了过渡设计和电影语言如何贡献于连贯叙事表达的问题。导致了大多数只是简单地顺序改变镜头，而没有有意的电影编辑模式。.

**Method:** 提出了ShotDirector框架，该框架集成了参数级相机控制和层次编辑模式感知提示。具体来说，采用了一个包含6-DoF姿态和内在设置的相机控制模块，以实现精确的相机信息注入。此外，还采用了基于专业编辑模式的层次提示机制，以实现对镜头内容的精细控制。通过这种设计，该框架有效地结合了参数级条件和高层语义指导，实现了类似电影的可控镜头过渡。为了促进训练和评估，构建了包含40k样本的ShotWeaver40K数据集，并开发了一套用于可控多镜头视频生成的评估指标。

**Result:** 广泛的实验表明，该框架是有效的，实现了类似电影的可控镜头过渡。

**Conclusion:** ShotDirector框架通过结合参数级相机控制和层次编辑模式感知提示，能够实现更加连贯、具有电影效果的多镜头视频内容生成，并且提供了相关的数据集和评估指标。

**Abstract:** Shot transitions play a pivotal role in multi-shot video generation, as they determine the overall narrative expression and the directorial design of visual storytelling. However, recent progress has primarily focused on low-level visual consistency across shots, neglecting how transitions are designed and how cinematographic language contributes to coherent narrative expression. This often leads to mere sequential shot changes without intentional film-editing patterns. To address this limitation, we propose ShotDirector, an efficient framework that integrates parameter-level camera control and hierarchical editing-pattern-aware prompting. Specifically, we adopt a camera control module that incorporates 6-DoF poses and intrinsic settings to enable precise camera information injection. In addition, a shot-aware mask mechanism is employed to introduce hierarchical prompts aware of professional editing patterns, allowing fine-grained control over shot content. Through this design, our framework effectively combines parameter-level conditions with high-level semantic guidance, achieving film-like controllable shot transitions. To facilitate training and evaluation, we construct ShotWeaver40K, a dataset that captures the priors of film-like editing patterns, and develop a set of evaluation metrics for controllable multi-shot video generation. Extensive experiments demonstrate the effectiveness of our framework.

</details>


### [48] [Physically Aware 360$^\circ$ View Generation from a Single Image using Disentangled Scene Embeddings](https://arxiv.org/abs/2512.10293)
*Karthikeya KV,Narendra Bandaru*

Main category: cs.CV

> 提出Disentangled360技术，实现了高效、真实的360°视图合成，在多个数据集上表现出色，适用于交互式应用，提升了医学和自然场景重建的质量。

<details>
  <summary>Details</summary>

**Motivation:** 当前技术要么过度简化各向异性光行为，要么缺乏跨多种场景的通用性，而这两种问题导致了现有方法的局限性。

**Method:** 引入了Disentangled360，这是一种创新的3D感知技术，结合了方向解耦体积渲染的优势和单图360°独特视图合成，应用于医学成像和自然场景重建。该框架通过使用高斯撒点法主干网络，将各向同性和各向异性光行为区分开。采用双分支条件框架，一个针对体积数据中的CT强度驱动散射进行优化，另一个通过归一化的摄像机嵌入为真实的RGB场景优化。为解决尺度模糊问题并保持结构真实性，提出了一种混合姿态无关锚点方法，自适应地采样场景深度和材质转换。设计将术前放射模拟和消费者级360°渲染整合到一个推理管道中，支持快速、逼真的视图合成，具有内在的方向性。

**Result:** 在Mip-NeRF 360，RealEstate10K和DeepDRR数据集上的评估表明，SSIM和LPIPS性能优于其他方法，运行时间评估也表明其适用于交互式应用。

**Conclusion:** Disentangled360技术为混合现实医疗监督、机器人感知和沉浸式内容创作提供了便利，无需场景特化微调或昂贵的光子模拟。

**Abstract:** We introduce Disentangled360, an innovative 3D-aware technology that integrates the advantages of direction disentangled volume rendering with single-image 360° unique view synthesis for applications in medical imaging and natural scene reconstruction. In contrast to current techniques that either oversimplify anisotropic light behavior or lack generalizability across various contexts, our framework distinctly differentiates between isotropic and anisotropic contributions inside a Gaussian Splatting backbone. We implement a dual-branch conditioning framework, one optimized for CT intensity driven scattering in volumetric data and the other for real-world RGB scenes through normalized camera embeddings. To address scale ambiguity and maintain structural realism, we present a hybrid pose agnostic anchoring method that adaptively samples scene depth and material transitions, functioning as stable pivots during scene distillation. Our design integrates preoperative radiography simulation and consumer-grade 360° rendering into a singular inference pipeline, facilitating rapid, photorealistic view synthesis with inherent directionality. Evaluations on the Mip-NeRF 360, RealEstate10K, and DeepDRR datasets indicate superior SSIM and LPIPS performance, while runtime assessments confirm its viability for interactive applications. Disentangled360 facilitates mixed-reality medical supervision, robotic perception, and immersive content creation, eliminating the necessity for scene-specific finetuning or expensive photon simulations.

</details>


### [49] [Efficient-VLN: A Training-Efficient Vision-Language Navigation Model](https://arxiv.org/abs/2512.10310)
*Duo Zheng,Shijia Huang,Yanyang Li,Liwei Wang*

Main category: cs.CV

> Efficient-VLN, addressing computational burdens and balancing exploration, achieves state-of-the-art performance with reduced GPU hours.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to reduce the substantial training overhead of multimodal large language models (MLLMs) in Vision-Language Navigation (VLN), caused by the quadratic computational burden and exploration-efficiency trade-off.

**Method:** The paper proposes Efficient-VLN, which includes two efficient memory mechanisms, a progressive memory and a learnable recursive memory, to handle the computational burden and a dynamic mixed policy to balance the exploration-efficiency trade-off.

**Result:** Efficient-VLN achieves the best performance on R2R-CE (64.2% SR) and RxR-CE (67.0% SR) while significantly reducing training overhead to just 282 H800 GPU hours.

**Conclusion:** The proposed Efficient-VLN model addresses the computational and exploration challenges effectively, establishing state-of-the-art performance with notable efficiency gains.

**Abstract:** Multimodal large language models (MLLMs) have shown promising potential in Vision-Language Navigation (VLN). However, their practical development is severely hindered by the substantial training overhead. We recognize two key issues that contribute to the overhead: (1) the quadratic computational burden from processing long-horizon historical observations as massive sequences of tokens, and (2) the exploration-efficiency trade-off in DAgger, i.e., a data aggregation process of collecting agent-explored trajectories. While more exploration yields effective error-recovery trajectories for handling test-time distribution shifts, it comes at the cost of longer trajectory lengths for both training and inference. To address these challenges, we propose Efficient-VLN, a training-efficient VLN model. Specifically, to mitigate the token processing burden, we design two efficient memory mechanisms: a progressive memory that dynamically allocates more tokens to recent observations, and a learnable recursive memory that utilizes the key-value cache of learnable tokens as the memory state. Moreover, we introduce a dynamic mixed policy to balance the exploration-efficiency trade-off. Extensive experiments show that Efficient-VLN achieves state-of-the-art performance on R2R-CE (64.2% SR) and RxR-CE (67.0% SR). Critically, our model consumes merely 282 H800 GPU hours, demonstrating a dramatic reduction in training overhead compared to state-of-the-art methods.

</details>
