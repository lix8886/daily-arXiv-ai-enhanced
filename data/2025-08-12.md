<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 19]
- [cs.CV](#cs.CV) [Total: 15]
- [eess.IV](#eess.IV) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Semi-automated Fact-checking in Portuguese: Corpora Enrichment using Retrieval with Claim extraction](https://arxiv.org/abs/2508.06495)
*Juliana Resplande Sant'anna Gomes,Arlindo Rodrigues Galvão Filho*

Main category: cs.CL

> 论文提出了一个在葡萄牙语背景下使用大型语言模型和搜索引擎API提取外部证据来增强新闻语料库的方法，以解决现有资源仅基于文本特征分类的问题，从而推动半自动事实检查系统的发展。

<details>
  <summary>Details</summary>

**Motivation:** 因为手动事实核查的能力赶不上虚假信息的快速传播，特别在葡萄牙语环境中缺乏整合外部证据的公开数据集，需要开发有效的半自动事实核查系统。

**Method:** 采用大型语言模型(Gemini 1.5 Flash)从文本中提取主要声明，同时使用搜索引擎API(如Google Search API)检索相关的外部文档作为证据，并引入一个数据验证和预处理框架来提高基础语料库的质量。

**Result:** 本研究开发了一种方法论，用于通过模拟用户的验证过程来增强葡萄牙语新闻语料库(Fake.Br, COVID19.BR, MuMiN-PT)，整合外部证据以支持更加强大的事实核查系统开发。

**Conclusion:** 研究开发的方法有效地解决了葡萄牙语新闻语料库缺乏外部证据这一问题，为建立健全的半自动事实核查系统奠定了基础。

**Abstract:** The accelerated dissemination of disinformation often outpaces the capacity
for manual fact-checking, highlighting the urgent need for Semi-Automated
Fact-Checking (SAFC) systems. Within the Portuguese language context, there is
a noted scarcity of publicly available datasets that integrate external
evidence, an essential component for developing robust AFC systems, as many
existing resources focus solely on classification based on intrinsic text
features. This dissertation addresses this gap by developing, applying, and
analyzing a methodology to enrich Portuguese news corpora (Fake.Br, COVID19.BR,
MuMiN-PT) with external evidence. The approach simulates a user's verification
process, employing Large Language Models (LLMs, specifically Gemini 1.5 Flash)
to extract the main claim from texts and search engine APIs (Google Search API,
Google FactCheck Claims Search API) to retrieve relevant external documents
(evidence). Additionally, a data validation and preprocessing framework,
including near-duplicate detection, is introduced to enhance the quality of the
base corpora.

</details>


### [2] [Retrieval augmented generation based dynamic prompting for few-shot biomedical named entity recognition using large language models](https://arxiv.org/abs/2508.06504)
*Yao Ge,Sudeshna Das,Yuting Guo,Abeed Sarker*

Main category: cs.CL

> 本文研究通过检索增强生成的动态提示策略来提高大型语言模型在少样本生物医学命名实体识别中的性能。

<details>
  <summary>Details</summary>

**Motivation:** 生物医学命名实体识别在自然语言处理中是一项非常有用的NLP任务，大型语言模型在少样本场景中显示出潜力。然而，这些模型在少样本生物医学命名实体识别中的性能仍有待提高。

**Method:** 通过研究涉及检索增强生成（RAG）的动态提示策略来解决LLM在少样本生物医学命名实体识别中的性能挑战。在该方法中，基于与输入文本的相似度选择标注的上下文学习示例，并在推理过程中为每个实例动态更新提示。实现了静态和动态提示工程技术，并在五个生物医学命名实体识别数据集上进行了评估。

**Result:** 结构化组件的静态提示法使GPT-4和GPT-3.5及LLaMA 3-70B的平均F1分数分别提高了12%和11%。动态提示法进一步提升了性能，TF-IDF和SBERT检索方法分别在5-shot和10-shot设置中使平均F1分数提高了7.3%和5.6%。

**Conclusion:** 这些发现突显了通过RAG实现的上下文适应性提示在生物医学命名实体识别中的效用。

**Abstract:** Biomedical named entity recognition (NER) is a high-utility natural language
processing (NLP) task, and large language models (LLMs) show promise
particularly in few-shot settings (i.e., limited training data). In this
article, we address the performance challenges of LLMs for few-shot biomedical
NER by investigating a dynamic prompting strategy involving retrieval-augmented
generation (RAG). In our approach, the annotated in-context learning examples
are selected based on their similarities with the input texts, and the prompt
is dynamically updated for each instance during inference. We implemented and
optimized static and dynamic prompt engineering techniques and evaluated them
on five biomedical NER datasets. Static prompting with structured components
increased average F1-scores by 12% for GPT-4, and 11% for GPT-3.5 and LLaMA
3-70B, relative to basic static prompting. Dynamic prompting further improved
performance, with TF-IDF and SBERT retrieval methods yielding the best results,
improving average F1-scores by 7.3% and 5.6% in 5-shot and 10-shot settings,
respectively. These findings highlight the utility of contextually adaptive
prompts via RAG for biomedical NER.

</details>


### [3] [CarbonScaling: Extending Neural Scaling Laws for Carbon Footprint in Large Language Models](https://arxiv.org/abs/2508.06524)
*Lei Jiang,Fan Chen*

Main category: cs.CL

> 本文提出了CarbonScaling框架，该框架将神经缩放定律应用于考虑LLM训练中的碳排放，量化了模型准确性与碳足迹之间的关系。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于当前的神经缩放定律仅关注准确性改进与参数量、数据集大小和计算能力的增长之间的关联，但忽略了碳排放的显著增加问题，因此作者提出该框架以填补这一研究空白。

**Method:** 本论文提出了一种名为CarbonScaling的分析框架，该框架扩展了神经缩放定律，将操作碳和LLM训练中的物质化碳纳入考虑。通过整合神经缩放模型、GPU硬件进化、并行优化及碳估算模型，CarbonScaling定量地将模型准确性与碳足迹联系起来。

**Result:** 研究表明，尽管准确性与碳之间存在幂律关系，但实际存在的低效会显著增加碳排放。对于极大规模的LLM，硬件技术缩放减少碳排放的效果逐渐减弱，主要是由于通信开销和未充分利用的GPU。

**Conclusion:** CarbonScaling框架为训练更加可持续和碳效率更高的LLM提供了关键洞见。

**Abstract:** Neural scaling laws have driven the development of increasingly large
language models (LLMs) by linking accuracy improvements to growth in parameter
count, dataset size, and compute. However, these laws overlook the carbon
emissions that scale exponentially with LLM size. This paper presents
\textit{CarbonScaling}, an analytical framework that extends neural scaling
laws to incorporate both operational and embodied carbon in LLM training. By
integrating models for neural scaling, GPU hardware evolution, parallelism
optimization, and carbon estimation, \textit{CarbonScaling} quantitatively
connects model accuracy to carbon footprint. Results show that while a
power-law relationship between accuracy and carbon holds, real-world
inefficiencies significantly increase the scaling factor. Hardware technology
scaling reduces carbon emissions for small to mid-sized models, but offers
diminishing returns for extremely large LLMs due to communication overhead and
underutilized GPUs. Training optimizations-especially aggressive critical batch
size scaling-help alleviate this inefficiency. \textit{CarbonScaling} offers
key insights for training more sustainable and carbon-efficient LLMs.

</details>


### [4] [The Art of Breaking Words: Rethinking Multilingual Tokenizer Design](https://arxiv.org/abs/2508.06533)
*Aamod Thakur,Ajay Nagpal,Atharva Savarkar,Kundeshwar Pundalik,Siddhesh Dosi,Piyush Sawarkar,Viraj Thakur,Rohit Saluja,Maunendra Sankar Desarkar,Ganesh Ramakrishnan*

Main category: cs.CL

> 本研究侧重于多语言语境内的分词技术，提出了一种新的数据组合算法来平衡用于训练分词器的多语言数据，改善了分词效率和模型性能，降低了推理时间。

<details>
  <summary>Details</summary>

**Motivation:** 由于现有的分词器往往会导致较高的分词到词汇比率，不高效的上下文长度使用以及较慢的推理速度，本论文旨在研究分词化，特别是多语言背景下的分词化，作为大规模语言模型开发中的一个较未被重视的方面。

**Method:** 本论文提出了一种新的数据组合算法，该算法在训练分词器时平衡多语言数据，并探讨了词汇大小、预分词规则和训练语料库组成如何影响分词到词汇的效率和模型质量。

**Result:** 经过研究，论文提出的数据组合算法与传统随机化方法相比，将平均分词到词汇比率降低了约6%，并在多语言印度语模型中平均分词到词汇比率方面实现了40%以上的改进。

**Conclusion:** 研究结果表明，分词化是一种有效的手段，能够改进训练目标和模型架构，用于构建高效、可扩展的多语言大规模语言模型。

**Abstract:** While model architecture and training objectives are well-studied,
tokenization, particularly in multilingual contexts, remains a relatively
neglected aspect of Large Language Model (LLM) development. Existing tokenizers
often exhibit high token-to-word ratios, inefficient use of context length, and
slower inference. We present a systematic study that links vocabulary size,
pre-tokenization rules, and training-corpus composition to both token-to-word
efficiency and model quality. To ground our analysis in a linguistically
diverse context, we conduct extensive experiments on Indic scripts, which
present unique challenges due to their high script diversity and orthographic
complexity. Drawing on the insights from these analyses, we propose a novel
algorithm for data composition that balances multilingual data for tokenizer
training. Our observations on pretokenization strategies significantly improve
model performance, and our data composition algorithm reduces the average
token-to-word ratio by approximately 6% with respect to the conventional data
randomization approach. Our tokenizer achieves more than 40% improvement on
average token-to-word ratio against stateof-the-art multilingual Indic models.
This improvement yields measurable gains in both model performance and
inference speed. This highlights tokenization alongside architecture and
training objectives as a critical lever for building efficient, scalable
multilingual LLMs

</details>


### [5] [Factor Augmented Supervised Learning with Text Embeddings](https://arxiv.org/abs/2508.06548)
*Zhanye Luo,Yuefeng Han,Xiufan Yu*

Main category: cs.CL

> 提出了一种新的框架AEALT，它直接在预训练语言模型中集成了维度减少，通过学习低维、任务相关的潜在因子来提高模型在不同类型任务上的性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型生成的文本嵌入具有高维度，这阻碍了下游任务的效率并导致计算成本增加。为解决此问题，提出AEALT框架。

**Method:** 我们提出了一种名为AutoEncoder-Augmented Learning with Text (AEALT)的监督框架，该框架在预训练语言模型的流程中直接集成了维度减少。该方法先从文本文档中提取嵌入，然后通过监督增强的自编码器学习低维、任务相关的潜在因子。

**Result:** 实验验证了AEALT在分类、异常检测和预测等多种任务上的广泛适用性，结果表明AEALT相比原始嵌入和几种标准维度减少方法有显著优势。

**Conclusion:** AEALT通过高效地使用监督增强的自编码器在任务相关维度上进行学习，在多种任务上展现出了优于传统方法的性能。

**Abstract:** Large language models (LLMs) generate text embeddings from text data,
producing vector representations that capture the semantic meaning and
contextual relationships of words. However, the high dimensionality of these
embeddings often impedes efficiency and drives up computational cost in
downstream tasks. To address this, we propose AutoEncoder-Augmented Learning
with Text (AEALT), a supervised, factor-augmented framework that incorporates
dimension reduction directly into pre-trained LLM workflows. First, we extract
embeddings from text documents; next, we pass them through a supervised
augmented autoencoder to learn low-dimensional, task-relevant latent factors.
By modeling the nonlinear structure of complex embeddings, AEALT outperforms
conventional deep-learning approaches that rely on raw embeddings. We validate
its broad applicability with extensive experiments on classification, anomaly
detection, and prediction tasks using multiple real-world public datasets.
Numerical results demonstrate that AEALT yields substantial gains over both
vanilla embeddings and several standard dimension reduction methods.

</details>


### [6] [Discerning minds or generic tutors? Evaluating instructional guidance capabilities in Socratic LLMs](https://arxiv.org/abs/2508.06583)
*Ying Liu,Can Li,Ting Zhang,Mei Wang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

> 研究探讨了大型语言模型作为适应性导师的能力，强调了根据学习者的认知状态提供指导的重要性，并提出了一种新的评估基准GuideEval和一种提升性能的微调策略。

<details>
  <summary>Details</summary>

**Motivation:** 以往的研究主要集中在大型语言模型的苏格拉底提问能力上，而忽略了根据学习者的认知状态进行适应性引导这一关键方面。这项研究旨在探讨语言模型是否能像专家导师那样根据学习者的理解动态调整策略。

**Method:** 该研究提出了GuideEval基准，该基准基于真实的教育对话，通过三阶段行为框架评估教学指导能力：感知（推断学习者状态）、编排（调整教学策略）和激发（促进适当反思）。研究采用行为引导的微调策略，利用行为提示的教学对话，显著提高了指导性能。

**Result:** 实证结果表明，现有的大型语言模型在学习者表现出困惑或需要引导时，常常无法提供有效的适应性支持。通过引入基于行为的微调策略，显著增强了语言模型的指导性能。

**Conclusion:** 通过从单独的内容评估转向以学习者为中心的互动，这项工作推广了一种更对话式的评价苏格拉底语言模型的范式，强调了适应性教学指导的重要性。

**Abstract:** The conversational capabilities of large language models hold significant
promise for enabling scalable and interactive tutoring. While prior research
has primarily examined their capacity for Socratic questioning, it often
overlooks a critical dimension: adaptively guiding learners based on their
cognitive states. This study shifts focus from mere question generation to the
broader instructional guidance capability. We ask: Can LLMs emulate expert
tutors who dynamically adjust strategies in response to learners'
understanding? To investigate this, we propose GuideEval, a benchmark grounded
in authentic educational dialogues that evaluates pedagogical guidance through
a three-phase behavioral framework: (1) Perception, inferring learner states;
(2) Orchestration, adapting instructional strategies; and (3) Elicitation,
stimulating proper reflections. Empirical findings reveal that existing LLMs
frequently fail to provide effective adaptive scaffolding when learners exhibit
confusion or require redirection. Furthermore, we introduce a behavior-guided
finetuning strategy that leverages behavior-prompted instructional dialogues,
significantly enhancing guidance performance. By shifting the focus from
isolated content evaluation to learner-centered interaction, our work advocates
a more dialogic paradigm for evaluating Socratic LLMs.

</details>


### [7] [LLM Unlearning Without an Expert Curated Dataset](https://arxiv.org/abs/2508.06595)
*Xiaoyuan Zhu,Muru Zhang,Ollie Liu,Robin Jia,Willie Neiswanger*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Modern large language models often encode sensitive, harmful, or copyrighted
knowledge, raising the need for post-hoc unlearning-the ability to remove
specific domains of knowledge from a model without full retraining. A major
bottleneck in current unlearning pipelines is constructing effective forget
sets-datasets that approximate the target domain and guide the model to forget
it. In this work, we introduce a scalable, automated approach to generate
high-quality forget sets using language models themselves. Our method
synthesizes textbook-style data through a structured prompting pipeline,
requiring only a domain name as input. Through experiments on unlearning
biosecurity, cybersecurity, and Harry Potter novels, we show that our synthetic
datasets consistently outperform the baseline synthetic alternatives and are
comparable to the expert-curated ones. Additionally, ablation studies reveal
that the multi-step generation pipeline significantly boosts data diversity,
which in turn improves unlearning utility. Overall, our findings suggest that
synthetic datasets offer a promising path toward practical, scalable unlearning
for a wide range of emerging domains without the need for manual intervention.
We release our code and dataset at
https://github.com/xyzhu123/Synthetic_Textbook.

</details>


### [8] [BrowseComp-Plus: A More Fair and Transparent Evaluation Benchmark of Deep-Research Agent](https://arxiv.org/abs/2508.06600)
*Zijian Chen,Xueguang Ma,Shengyao Zhuang,Ping Nie,Kai Zou,Andrew Liu,Joshua Green,Kshama Patel,Ruoxi Meng,Mingyi Su,Sahel Sharifymoghaddam,Yanxi Li,Haoran Hong,Xinyu Shi,Xuye Liu,Nandan Thakur,Crystina Zhang,Luyu Gao,Wenhu Chen,Jimmy Lin*

Main category: cs.CL

> 该论文介绍了一个新的基准测试BrowseComp-Plus，它利用静态且仔细策划的语料库，以解决先前基准测试的局限性，提高对深度研究系统性能和组成的分析能力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的基准测试存在公平性和透明度的局限性，这阻碍了对深度研究方法公平比较和其可重复性。因此，该研究旨在设计一个更有效的基准测试，提供对底层深度研究LLM能力的深入见解。

**Method:** 该论文提出了一个名为BrowseComp-Plus的新基准，它是从BrowseComp衍生而来的，使用了一个静态且仔细策划的语料库，以解决以前基准测试的局限性。这个新基准包含人工验证的支持文档和挖掘具有挑战性的负样本，从而支持更受控的实验。

**Result:** 实验结果显示，BrowseComp-Plus能够有效地区分深度研究系统的性能。例如，开源模型Search-R1与BM25检索器结合时，准确率仅为3.86%，而GPT-5的准确率为55.9%，与Qwen3-Embedding-8B检索器相结合时，准确率提升至70.1%，同时减少了搜索调用次数。

**Conclusion:** BrowseComp-Plus基准测试证明了它可以更好地控制实验，从而提供深入的见解，包括检索有效性、引文准确性以及深度研究系统中的上下文工程。这为评估和分析深研究代理和检索方法提供了新的途径。

**Abstract:** Deep-Research agents, which integrate large language models (LLMs) with
search tools, have shown success in improving the effectiveness of handling
complex queries that require iterative search planning and reasoning over
search results. Evaluations on current benchmarks like BrowseComp relies on
black-box live web search APIs, have notable limitations in (1) fairness:
dynamic and opaque web APIs hinder fair comparisons and reproducibility of deep
research methods; (2) transparency: lack of control over the document corpus
makes it difficult to isolate retriever contributions. In other words, the
current evaluations may compare a complete deep research system at a given
time, but they do not foster well-controlled experiments to provide insights
into the capability of underlying deep research LLMs. To address these
challenges, we introduce BrowseComp-Plus, a benchmark derived from BrowseComp,
employing a fixed, carefully curated corpus. Each query in BrowseComp-Plus
includes human-verified supporting documents and mined challenging negatives,
enabling controlled experimentation. The benchmark is shown to be effective in
distinguishing the performance of deep research systems. For instance, the
open-source model Search-R1, when paired with the BM25 retriever, achieves
3.86% accuracy, whereas the GPT-5 achieves 55.9%. Integrating the GPT-5 with
the Qwen3-Embedding-8B retriever further enhances its accuracy to 70.1% with
fewer search calls. This benchmark allows comprehensive evaluation and
disentangled analysis of deep research agents and retrieval methods, fostering
insights into retrieval effectiveness, citation accuracy, and context
engineering in Deep-Research system.

</details>


### [9] [Train It and Forget It: Merge Lists are Unnecessary for BPE Inference in Language Models](https://arxiv.org/abs/2508.06621)
*Tomohiro Sawada,Kartik Goyal*

Main category: cs.CL

> 本文探讨了不依赖于BPE训练过程中使用的合并列表的BPE推理算法的下游影响，结果显示一些算法不影响性能，为更简单的分词方案提供了可能。

<details>
  <summary>Details</summary>

**Motivation:** 标准的字节对编码（BPE）分词通过学习的词汇表和详细的合并列表压缩文本。研究表明，合并列表存在潜在的攻击面，可能泄露语言模型训练数据的信息。本文旨在探讨不依赖于合并列表的BPE推理算法对下游任务的影响。

**Method:** 本文研究了两种BPE推断方案：一种是针对合并列表的偏差，包括随机合并顺序和删除/截断等合并列表的多种篡改；另一种是非针对性的BPE推理算法，它们不依赖于合并列表，而是专注于通过贪婪或精确的方式压缩文本。

**Result:** 实验结果显示，在准确性问答基准测试、机器翻译和开放生成等语言模型任务中，对合并列表的针对性偏差显著降低了语言模型的性能，而非针对性的不使用合并列表的推理算法对下游性能的影响最小，远低于预期。

**Conclusion:** 研究结果为可能更加隐私保护的简化分词方案铺平了道路，这些方案不会严重损害模型性能。

**Abstract:** Standard Byte-Pair Encoding (BPE) tokenization compresses text by pairing a
learned token vocabulary with a detailed merge list. Recent work has shown that
this merge list exposes a potential attack surface for extracting information
about language model's training data. In this paper, we explore the downstream
impact of BPE inference algorithms that do not rely on this merge list at all,
and hence differ from the encoding process during BPE training. To address this
question, we investigate two broad classes of BPE inference schemes that differ
from BPE application during training: a) targeted deviation from merge-lists
including random merge orders, and various corruptions of merge list involving
deletion/truncation, and b) non-targeted BPE inference algorithms that do not
depend on the merge list but focus on compressing the text either greedily or
exactly. Extensive experiments across diverse language modeling tasks like
accuracy-based QA benchmarks, machine translation, and open-ended generation
reveal that while targeted deviation from the merge lists exhibits significant
degradation in language model performance, the non-targeted merge-list-free
inference algorithms result in minimal impact on downstream performance that is
often much smaller than expected. These findings pave way for simpler and
potentially more privacy-preserving tokenization schemes that do not
catastrophically compromise model performance.

</details>


### [10] [Measuring Stereotype and Deviation Biases in Large Language Models](https://arxiv.org/abs/2508.06649)
*Daniel Wang,Eli Brignac,Minjia Mao,Xiao Fang*

Main category: cs.CL

> 研究发现，四款高级语言模型在生成内容时表现出显著的刻板印象和偏差偏差，表明语言模型在推断用户属性时存在偏见，可能产生负面后果。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型（LLMs）在各个领域得到广泛应用，引发了对其局限性和潜在风险的担忧。研究目的是调查语言模型可能表现出的两种偏差：刻板印象偏差和偏差偏差。

**Method:** 本研究通过让四款高级语言模型（LLMs）生成个人资料，来考察不同人口统计群体与政治倾向、宗教信仰和性取向等属性之间的关联。

**Result:** 实验结果表明，所有被检查的语言模型都展现在多种群体上的显著刻板印象偏差和偏差偏差。

**Conclusion:** 研究发现揭示了LLMs在推断用户属性时出现的偏差，指出了LLMs生成内容可能带来的潜在危害。

**Abstract:** Large language models (LLMs) are widely applied across diverse domains,
raising concerns about their limitations and potential risks. In this study, we
investigate two types of bias that LLMs may display: stereotype bias and
deviation bias. Stereotype bias refers to when LLMs consistently associate
specific traits with a particular demographic group. Deviation bias reflects
the disparity between the demographic distributions extracted from
LLM-generated content and real-world demographic distributions. By asking four
advanced LLMs to generate profiles of individuals, we examine the associations
between each demographic group and attributes such as political affiliation,
religion, and sexual orientation. Our experimental results show that all
examined LLMs exhibit both significant stereotype bias and deviation bias
towards multiple groups. Our findings uncover the biases that occur when LLMs
infer user attributes and shed light on the potential harms of LLM-generated
outputs.

</details>


### [11] [Testing the Limits of Machine Translation from One Book](https://arxiv.org/abs/2508.06665)
*Jonathan Shaw,Dillon Mee,Timothy Khouw,Zackary Leech,Daniel Wilson*

Main category: cs.CL

> 研究通过提供不同组合的语言资源来评估大语言模型（LLMs）在Kanuri语言上的翻译效果，发现双语句子是最有效资源，且仅提供语法规则不足以产生优质的领域特定翻译。

<details>
  <summary>Details</summary>

**Motivation:** 一些具有大量使用者的语言，因为数字资源匮乏，面临翻译挑战。研究主要集中在Kanuri语言上，探究特定领域的任务如何影响LLMs的翻译质量。

**Method:** 通过提供不同组合的语言资源（如语法规则、词典和双语句子）来评估大语言模型（LLMs）的翻译效果，并将结果与母语者的翻译和语言学家的表现进行对比。评估方法包括自动度量和母语者对流利度和准确性的评估。

**Result:** 双语句子是最有效的数据来源，在人类评估和自动度量中都优于其他方法。虽然使用语法规则可以提升非零样本的翻译效果，但它单独使用并不能达到效果。人类评估表明，LLMs在提高翻译准确性上优于流利度。

**Conclusion:** 对于大语言模型的翻译评估，除了简单的准确性度量外，还需要多维度的评估方法，且单凭语法规则无法为有效领域特定翻译提供足够的上下文。

**Abstract:** Current state-of-the-art models demonstrate capacity to leverage in-context
learning to translate into previously unseen language contexts. Tanzer et al.
[2024] utilize language materials (e.g. a grammar) to improve translation
quality for Kalamang using large language models (LLMs). We focus on Kanuri, a
language that, despite having substantial speaker population, has minimal
digital resources. We design two datasets for evaluation: one focused on health
and humanitarian terms, and another containing generalized terminology,
investigating how domain-specific tasks impact LLM translation quality.
  By providing different combinations of language resources (grammar,
dictionary, and parallel sentences), we measure LLM translation effectiveness,
comparing results to native speaker translations and human linguist
performance. We evaluate using both automatic metrics and native speaker
assessments of fluency and accuracy.
  Results demonstrate that parallel sentences remain the most effective data
source, outperforming other methods in human evaluations and automatic metrics.
While incorporating grammar improves over zero-shot translation, it fails as an
effective standalone data source. Human evaluations reveal that LLMs achieve
accuracy (meaning) more effectively than fluency (grammaticality).
  These findings suggest LLM translation evaluation benefits from
multidimensional assessment beyond simple accuracy metrics, and that grammar
alone, without parallel sentences, does not provide sufficient context for
effective domain-specific translation.

</details>


### [12] [Do Biased Models Have Biased Thoughts?](https://arxiv.org/abs/2508.06671)
*Swati Rajwal,Shivank Garg,Reem Abdel-Salam,Abdelrahman Zayed*

Main category: cs.CL

> 研究表明，尽管语言模型可能输出带有偏见的结果，但是模型的思考过程并不总是带有偏见。

<details>
  <summary>Details</summary>

**Motivation:** 由于语言模型存在性别、种族、社会经济地位、身体特征和性取向等方面的偏见，这使得部署语言模型变得具有挑战性。研究目的是探讨带有偏见的语言模型的思考过程中是否存在偏见。

**Method:** 该研究使用了链式思考提示方法，对5个流行的大型语言模型进行了实验，以量化模型思考过程和输出中的11种不同偏见。

**Result:** 研究结果表明，思考过程中的偏见与输出偏见之间的相关性并不很高（大多数情况下相关系数小于0.6，p值小于0.001）。

**Conclusion:** 与人类不同，实验测试的具有偏见决策的模型并不总是存在偏见思考。

**Abstract:** The impressive performance of language models is undeniable. However, the
presence of biases based on gender, race, socio-economic status, physical
appearance, and sexual orientation makes the deployment of language models
challenging. This paper studies the effect of chain-of-thought prompting, a
recent approach that studies the steps followed by the model before it
responds, on fairness. More specifically, we ask the following question:
\textit{Do biased models have biased thoughts}? To answer our question, we
conduct experiments on $5$ popular large language models using fairness metrics
to quantify $11$ different biases in the model's thoughts and output. Our
results show that the bias in the thinking steps is not highly correlated with
the output bias (less than $0.6$ correlation with a $p$-value smaller than
$0.001$ in most cases). In other words, unlike human beings, the tested models
with biased decisions do not always possess biased thoughts.

</details>


### [13] [Play Favorites: A Statistical Method to Measure Self-Bias in LLM-as-a-Judge](https://arxiv.org/abs/2508.06709)
*Evangelia Spiliopoulou,Riccardo Fogliato,Hanna Burnsky,Tamer Soliman,Jie Ma,Graham Horwood,Miguel Ballesteros*

Main category: cs.CL

> 该研究通过统计框架识别和估计大型语言模型（LLMs）评分中的自我偏见，并通过独立第三方的评分进行调整，以区分真实性能差异和偏见。测试发现某些模型存在对自己和其他同族模型评分偏高的现象，提供了减少这种偏见的实际指导建议。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有的LMM自我评分研究中混淆真正质量差异与偏见的问题，明确地形式化识别自我偏见的前提，并通过大量的数据集验证这些偏见现象。

**Method:** 提出一个统计框架，明确形式化了识别和估计自我偏见的假设；通过模型自身的评分和第三方评分（如人类评分）之间的差异来量化自我偏见，并在考虑不同模型能力差异的情况下隔离和量化这部分偏见。

**Result:** 在包含专家人工标注和9个不同LLM评分的大型数据集上进行实证分析，发现部分模型如GPT-4o和Claude 3.5 Sonnet会对自己的和同家族模型的输出给出较高评分，展示了在这种情况下使用LLM评分的潜在缺陷。

**Conclusion:** 研究结果揭示了利用LLM作为评分者时出现自我偏见和家族偏见的问题，并提供了减少这些偏见和更准确解读自动评估的实际建议。

**Abstract:** Large language models (LLMs) can serve as judges that offer rapid and
reliable assessments of other LLM outputs. However, models may systematically
assign overly favorable ratings to their own outputs, a phenomenon known as
self-bias, which can distort evaluations of true model performance. Previous
studies often conflate genuine differences in model quality with bias or
incorrectly assume that evaluations from LLMs and humans follow the same rating
distributions. In this work, we present a statistical framework that explicitly
formalizes assumptions under which self-bias can be identified and estimated.
Our method models the difference in the scoring distribution that
LLM-as-a-judge assigns to its own completions compared to other models, while
accounting for the underlying quality of the completions provided by an
independent, third-party judge (e.g., humans). Our method reliably isolates and
quantifies self-bias, even when models vary in ability, ensuring that genuine
performance differences are not mistaken for self-bias. We conduct an empirical
analysis of self-bias on a large dataset (>5000 prompt-completion pairs)
consisting of expert human annotations and judgments from nine different LLM
judges. We find that some models, such as GPT-4o and Claude 3.5 Sonnet,
systematically assign higher scores to their own outputs. These models also
display family-bias; systematically assigning higher ratings to outputs
produced by other models of the same family. Our findings highlight potential
pitfalls of using LLM judges and offer practical guidance to mitigate biases
when interpreting automated evaluations.

</details>


### [14] [Large Language Models for Oral History Understanding with Text Classification and Sentiment Analysis](https://arxiv.org/abs/2508.06729)
*Komala Subramanyam Cherukuri,Pranav Abishai Moses,Aisa Sakata,Jiangping Chen,Haihua Chen*

Main category: cs.CL

> 本文提出了一种使用LLMs自动标注日本裔美国人监禁口述历史数据的情感和语义的新框架，展示了在大规模分析中有效应用。

<details>
  <summary>Details</summary>

**Motivation:** 由于大规模分析口述历史档案面临结构化差、情感复杂及标注成本高等困难，本文旨在展示如何通过LLMs进行有效的语义和情感标注，提升这些档案的访问和理解。

**Method:** 本文介绍了一个可扩展的框架，用于自动语义和情感注释日本裔美国人监禁口述历史。该框架使用了LLMs，通过专家标注、指令设计和LLM评估（使用ChatGPT、Llama和Qwen）来构造高质量的数据集，并评估多个模型及测试指令工程策略。

**Result:** 在语义分类中，ChatGPT获得了最高的F1分数为88.71%，其次是Llama的84.99%和Qwen的83.72%。在情感分析中，Llama略胜一筹，其次是Qwen和ChatGPT。最终，使用最佳指令配置标注了92,191个句子，来自1,002次访谈。

**Conclusion:** 研究证明，通过精心设计的指令，LLMs能够有效地对大型口述历史收藏进行语义和情感标注，这为在文化和伦理敏感的档案分析中应用LLMs提供了再利用注释流水线和实用指导。

**Abstract:** Oral histories are vital records of lived experience, particularly within
communities affected by systemic injustice and historical erasure. Effective
and efficient analysis of their oral history archives can promote access and
understanding of the oral histories. However, Large-scale analysis of these
archives remains limited due to their unstructured format, emotional
complexity, and high annotation costs. This paper presents a scalable framework
to automate semantic and sentiment annotation for Japanese American
Incarceration Oral History. Using LLMs, we construct a high-quality dataset,
evaluate multiple models, and test prompt engineering strategies in
historically sensitive contexts. Our multiphase approach combines expert
annotation, prompt design, and LLM evaluation with ChatGPT, Llama, and Qwen. We
labeled 558 sentences from 15 narrators for sentiment and semantic
classification, then evaluated zero-shot, few-shot, and RAG strategies. For
semantic classification, ChatGPT achieved the highest F1 score (88.71%),
followed by Llama (84.99%) and Qwen (83.72%). For sentiment analysis, Llama
slightly outperformed Qwen (82.66%) and ChatGPT (82.29%), with all models
showing comparable results. The best prompt configurations were used to
annotate 92,191 sentences from 1,002 interviews in the JAIOH collection. Our
findings show that LLMs can effectively perform semantic and sentiment
annotation across large oral history collections when guided by well-designed
prompts. This study provides a reusable annotation pipeline and practical
guidance for applying LLMs in culturally sensitive archival analysis. By
bridging archival ethics with scalable NLP techniques, this work lays the
groundwork for responsible use of artificial intelligence in digital humanities
and preservation of collective memory. GitHub:
https://github.com/kc6699c/LLM4OralHistoryAnalysis.

</details>


### [15] [Many-Turn Jailbreaking](https://arxiv.org/abs/2508.06755)
*Xianjun Yang,Liqiang Xiao,Shiyang Li,Faisal Ladhak,Hyokun Yun,Linda Ruth Petzold,Yi Xu,William Yang Wang*

Main category: cs.CL

> 该研究构建了一个用于评估语言模型在多轮对话中越狱行为的基准测试MTJ-Bench，揭示了新安全威胁，强调了社区共建更安全语言模型的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的针对大语言模型的越狱研究仅关注单轮特定查询的不当输出，但先进的语言模型可以处理长上下文和多轮对话，这促使研究人员探索更为复杂的多轮越狱威胁。

**Method:** 提出多轮越狱（multi-turn jailbreaking）的概念，构建了一个名为Multi-Turn Jailbreak Benchmark (MTJ-Bench)的基准测试框架，用于评估开源和闭源模型在多轮对话中的越狱行为。

**Result:** 通过MTJ-Bench，揭示了一种新的安全威胁——用户在多轮对话中可能会不断追问越狱细节，或者违规的第一轮回答迫使语言模型在后续的无关问题中做出一致的违规响应。

**Conclusion:** 希望这一研究能够引起社群重视，促进更加安全的语言模型的开发，并推动对其变异和应对策略的深入理解。

**Abstract:** Current jailbreaking work on large language models (LLMs) aims to elicit
unsafe outputs from given prompts. However, it only focuses on single-turn
jailbreaking targeting one specific query. On the contrary, the advanced LLMs
are designed to handle extremely long contexts and can thus conduct multi-turn
conversations. So, we propose exploring multi-turn jailbreaking, in which the
jailbroken LLMs are continuously tested on more than the first-turn
conversation or a single target query. This is an even more serious threat
because 1) it is common for users to continue asking relevant follow-up
questions to clarify certain jailbroken details, and 2) it is also possible
that the initial round of jailbreaking causes the LLMs to respond to additional
irrelevant questions consistently. As the first step (First draft done at June
2024) in exploring multi-turn jailbreaking, we construct a Multi-Turn Jailbreak
Benchmark (MTJ-Bench) for benchmarking this setting on a series of open- and
closed-source models and provide novel insights into this new safety threat. By
revealing this new vulnerability, we aim to call for community efforts to build
safer LLMs and pave the way for a more in-depth understanding of jailbreaking
LLMs.

</details>


### [16] [SEVADE: Self-Evolving Multi-Agent Analysis with Decoupled Evaluation for Hallucination-Resistant Irony Detection](https://arxiv.org/abs/2508.06803)
*Ziqi Liu,Yangbin Chen,Ziyang Zhou,Yilin Li,Mingxuan Hu,Yushan Pan,Zhijie Xu*

Main category: cs.CL

> The paper introduces SEVADE, a novel multi-agent analysis framework with decoupled evaluation for more accurate and reliable sarcasm detection in complex ironic rhetoric, achieving state-of-the-art results.

<details>
  <summary>Details</summary>

**Motivation:** Existing models for sarcasm detection are often limited by single-perspective analysis, static reasoning pathways, and can produce incorrect outputs (hallucinations) when dealing with complex sarcasm, leading to reduced accuracy and reliability.

**Method:** SEVADE, a multi-agent analysis framework with decoupled evaluation, is proposed. The core component is the Dynamic Agentive Reasoning Engine (DARE) which uses a team of linguistic theory-based agents to analyze the text and form a reasoning chain. A separate lightweight rationale adjudicator then uses this chain to classify the text, aiming to prevent hallucination.

**Result:** Experiments on four benchmark datasets show that the SEVADE framework outperforms existing models with average improvements of 6.75% in Accuracy and 6.29% in Macro-F1 score.

**Conclusion:** SEVADE is an effective approach to improving sarcasm detection by reducing the risk of hallucination and providing more structured reasoning pathways.

**Abstract:** Sarcasm detection is a crucial yet challenging Natural Language Processing
task. Existing Large Language Model methods are often limited by
single-perspective analysis, static reasoning pathways, and a susceptibility to
hallucination when processing complex ironic rhetoric, which impacts their
accuracy and reliability. To address these challenges, we propose **SEVADE**, a
novel **S**elf-**Ev**olving multi-agent **A**nalysis framework with
**D**ecoupled **E**valuation for hallucination-resistant sarcasm detection. The
core of our framework is a Dynamic Agentive Reasoning Engine (DARE), which
utilizes a team of specialized agents grounded in linguistic theory to perform
a multifaceted deconstruction of the text and generate a structured reasoning
chain. Subsequently, a separate lightweight rationale adjudicator (RA) performs
the final classification based solely on this reasoning chain. This decoupled
architecture is designed to mitigate the risk of hallucination by separating
complex reasoning from the final judgment. Extensive experiments on four
benchmark datasets demonstrate that our framework achieves state-of-the-art
performance, with average improvements of **6.75%** in Accuracy and **6.29%**
in Macro-F1 score.

</details>


### [17] [Annotating Errors in English Learners' Written Language Production: Advancing Automated Written Feedback Systems](https://arxiv.org/abs/2508.06810)
*Steven Coyne,Diana Galvan-Sosa,Ryan Spring,Camélia Guerraoui,Michael Zock,Keisuke Sakaguchi,Kentaro Inui*

Main category: cs.CL

> 本文介绍了一种注释框架，用于为语言学习中的语法错误生成更适合学习者需求的反馈。该框架首先对错误进行分类并收集带有注释的数据集，然后评估了不同的反馈生成方法。

<details>
  <summary>Details</summary>

**Motivation:** 当前的自动写作评分(AWE)系统在纠正语法错误方面有效，但它们并非特别针对语言学习进行优化。这些系统通常提供直接纠正的功能，而忽视了考虑改正的原因。对于学习者来说，某些类型的错误可能更适合简单的解释或战略性间接提示。

**Method:** 本文提出了一种注释框架，用于根据错误类型和可推广性对错误进行建模。该框架包括错误类型分类和针对学习者知识缺口的特定语法模式的推断。在此基础上，收集了注释的错误数据集和相应的人类编写的反馈注释，每个注释被标记为直接修正或提示。

**Result:** 本研究收集了带有注释的学习者错误数据集与人类编写的反馈注释，并使用大型语言模型（LLMs）评估了关键词引导、非关键词引导和模板引导的反馈生成方法。教师对每个系统的输出进行了评估，包括相关性、事实性和可理解性。

**Conclusion:** 研究展示了发展此类数据集的进展以及所调查系统的性能对比。这有助于改善针对语言学习的自动写作评分系统，使其能提供更适合学习者需求的反馈。

**Abstract:** Recent advances in natural language processing (NLP) have contributed to the
development of automated writing evaluation (AWE) systems that can correct
grammatical errors. However, while these systems are effective at improving
text, they are not optimally designed for language learning. They favor direct
revisions, often with a click-to-fix functionality that can be applied without
considering the reason for the correction. Meanwhile, depending on the error
type, learners may benefit most from simple explanations and strategically
indirect hints, especially on generalizable grammatical rules. To support the
generation of such feedback, we introduce an annotation framework that models
each error's error type and generalizability. For error type classification, we
introduce a typology focused on inferring learners' knowledge gaps by
connecting their errors to specific grammatical patterns. Following this
framework, we collect a dataset of annotated learner errors and corresponding
human-written feedback comments, each labeled as a direct correction or hint.
With this data, we evaluate keyword-guided, keyword-free, and template-guided
methods of generating feedback using large language models (LLMs). Human
teachers examined each system's outputs, assessing them on grounds including
relevance, factuality, and comprehensibility. We report on the development of
the dataset and the comparative performance of the systems investigated.

</details>


### [18] [Text to Speech System for Meitei Mayek Script](https://arxiv.org/abs/2508.06870)
*Gangular Singh Irengbam,Nirvash Singh Wahengbam,Lanthoiba Meitei Khumanthem,Paikhomba Oinam*

Main category: cs.CL

> 本文推出了一个基于Meitei Mayek脚本的Manipuri语言的文本到语音系统，采用Tacotron 2和HiFi-GAN技术，为语言保护和技术包容提供了基础。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发一种用于Manipuri语言的文本到语音系统，该系统使用Meitei Mayek脚本，并为语言保护和技术包容性奠定基础。

**Method:** 基于Tacotron 2和HiFi-GAN开发了一种适用于支持声调语音学和资源匮乏语言环境的神经文本到语音系统。为Meitei Mayek到ARPAbet开发了一个音素映射，创建了一个单说话人数据集，并通过主观和客观指标验证了语音合成的可理解和自然性。

**Result:** 该系统能够生成清晰和自然的语音，这已在主观和客观评估中得到验证。

**Conclusion:** 该神经TTS系统为Manipuri语言的技术包括和语言保护提供了坚实的基础。

**Abstract:** This paper presents the development of a Text-to-Speech (TTS) system for the
Manipuri language using the Meitei Mayek script. Leveraging Tacotron 2 and
HiFi-GAN, we introduce a neural TTS architecture adapted to support tonal
phonology and under-resourced linguistic environments. We develop a phoneme
mapping for Meitei Mayek to ARPAbet, curate a single-speaker dataset, and
demonstrate intelligible and natural speech synthesis, validated through
subjective and objective metrics. This system lays the groundwork for
linguistic preservation and technological inclusion of Manipuri.

</details>


### [19] [ESNERA: Empirical and semantic named entity alignment for named entity dataset merging](https://arxiv.org/abs/2508.06877)
*Xiaobo Zhang,Congqing He,Ying He,Jian Peng,Dajie Fu,Tien-Ping Tan*

Main category: cs.CL

> 该文开发了一种自动化的标签对齐方法，用于合并多个NER数据集，同时提升了特定领域识别性能。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于构建高质量标注数据集成本高昂且耗时，限制了进一步研究，而现有的数据集合并方法在可解释性和可扩展性方面不足，因此提议了一种新方法来解决这个问题。

**Method:** 该论文提出了一种基于标签相似性的自动标签对齐方法，结合了经验相似性和语义相似性，并采用了一种贪心的两两合并策略来统一不同数据集的标签空间。

**Result:** 实验分为两个阶段，第一阶段将三个现有的NER数据集合并成一个统一的语料库，对NER性能的影响极小；第二阶段将合并的语料库与一个小规模的自建金融领域数据集整合。结果显示，该方法能够实现有效的数据集合并，并提升了金融领域低资源环境下的NER性能。

**Conclusion:** 本研究提出了一种高效、可解释且可扩展的多源NER语料库整合方案。

**Abstract:** Named Entity Recognition (NER) is a fundamental task in natural language
processing. It remains a research hotspot due to its wide applicability across
domains. Although recent advances in deep learning have significantly improved
NER performance, they rely heavily on large, high-quality annotated datasets.
However, building these datasets is expensive and time-consuming, posing a
major bottleneck for further research. Current dataset merging approaches
mainly focus on strategies like manual label mapping or constructing label
graphs, which lack interpretability and scalability. To address this, we
propose an automatic label alignment method based on label similarity. The
method combines empirical and semantic similarities, using a greedy pairwise
merging strategy to unify label spaces across different datasets. Experiments
are conducted in two stages: first, merging three existing NER datasets into a
unified corpus with minimal impact on NER performance; second, integrating this
corpus with a small-scale, self-built dataset in the financial domain. The
results show that our method enables effective dataset merging and enhances NER
performance in the low-resource financial domain. This study presents an
efficient, interpretable, and scalable solution for integrating multi-source
NER corpora.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [20] [Med-GRIM: Enhanced Zero-Shot Medical VQA using prompt-embedded Multimodal Graph RAG](https://arxiv.org/abs/2508.06496)
*Rakesh Raj Madavan,Akshat Kaimal,Hashim Faisal,Chandrakala S*

Main category: cs.CV

> BIND通过改进联合嵌入空间，Med-GRIM采用小语言模型和基于提示的检索实现高效、准确的医学问答，同时提出了医学图像数据集DermaGraph。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多模态模型在复杂的、特定领域应用如医疗问答中难以生成所需的详细而精确的回答，故提出改进模型。

**Method:** BIND：一种扩展了先前多模态工作的表示模型，通过密集聚合查询令牌编码改进联合嵌入空间，受到对比预训练技术的启发。Med-GRIM：该模型专门针对医学问答任务，通过图形查询和提示工程整合领域特定知识。采用小语言模型实现低计算量且模块化的管线，利用基于提示的检索动态注入相关知识，确保其响应的准确性和鲁棒性。

**Result:** Med-GRIM以远低于大型语言模型的计算成本实现高效性能，且DermaGraph数据集支撑了在零样本多模态医疗应用中的可扩展研究。

**Conclusion:** 新的模型和数据集为零样本多模态医疗应用的研究提供了支持。

**Abstract:** An ensemble of trained multimodal encoders and vision-language models (VLMs)
has become a standard approach for visual question answering (VQA) tasks.
However, such models often fail to produce responses with the detailed
precision necessary for complex, domain-specific applications such as medical
VQA. Our representation model, BIND: BLIVA Integrated with Dense Encoding,
extends prior multimodal work by refining the joint embedding space through
dense, query-token-based encodings inspired by contrastive pretraining
techniques. This refined encoder powers Med-GRIM, a model designed for medical
VQA tasks that leverages graph-based retrieval and prompt engineering to
integrate domain-specific knowledge. Rather than relying on compute-heavy
fine-tuning of vision and language models on specific datasets, Med-GRIM
applies a low-compute, modular workflow with small language models (SLMs) for
efficiency. Med-GRIM employs prompt-based retrieval to dynamically inject
relevant knowledge, ensuring both accuracy and robustness in its responses. By
assigning distinct roles to each agent within the VQA system, Med-GRIM achieves
large language model performance at a fraction of the computational cost.
Additionally, to support scalable research in zero-shot multimodal medical
applications, we introduce DermaGraph, a novel Graph-RAG dataset comprising
diverse dermatological conditions. This dataset facilitates both multimodal and
unimodal querying. The code and dataset are available at:
https://github.com/Rakesh-123-cryp/Med-GRIM.git

</details>


### [21] [DiTalker: A Unified DiT-based Framework for High-Quality and Speaking Styles Controllable Portrait Animation](https://arxiv.org/abs/2508.06511)
*He Feng,Yongjia Ma,Donglin Di,Lei Fan,Tonghua Su,Xiangqian Wu*

Main category: cs.CV

> 提出了一种新的框架DiTalker，用于生成说话风格可控的肖像动画，该框架能够处理动态风格，同时提高了唇同步效果，并在大量的实验中展示了优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于扩散模型的肖像动画方法主要关注唇部同步或静态情绪转换，往往忽略了像头部移动这样的动态风格。此外，大多数这些方法依赖于双U-Net架构，这虽然保持了身份的一致性，但也带来了额外的计算开销。因此，我们提出了DiTalker，以解决上述问题。

**Method:** 我们提出了一种基于DiT的统一框架DiTalker，用于支持说话风格可控的肖像动画。该框架设计了一个风格情感编码模块，其中包括两个不同的分支——用于提取身份特定风格信息（如头部姿势和动作）的风格分支和用于提取身份无关情感特征的情感分支。此外，我们还引入了一个音频风格融合模块，通过两个并行的交叉注意力层来分离音频和说话风格，并使用这些特征引导动画过程。为了提高结果质量，我们采用了两种优化约束：一种用于提高唇同步效果，另一种用于保持精细的身份和背景细节。

**Result:** 大量的实验表明，DiTalker在唇部同步和说话风格可控性上都表现出色。

**Conclusion:** 总之，DiTalker提供了一种创新的方法来生成高质量且风格可控的肖像动画，极大地改善了唇同步效果和动态风格的再现。

**Abstract:** Portrait animation aims to synthesize talking videos from a static reference
face, conditioned on audio and style frame cues (e.g., emotion and head poses),
while ensuring precise lip synchronization and faithful reproduction of
speaking styles. Existing diffusion-based portrait animation methods primarily
focus on lip synchronization or static emotion transformation, often
overlooking dynamic styles such as head movements. Moreover, most of these
methods rely on a dual U-Net architecture, which preserves identity consistency
but incurs additional computational overhead. To this end, we propose DiTalker,
a unified DiT-based framework for speaking style-controllable portrait
animation. We design a Style-Emotion Encoding Module that employs two separate
branches: a style branch extracting identity-specific style information (e.g.,
head poses and movements), and an emotion branch extracting identity-agnostic
emotion features. We further introduce an Audio-Style Fusion Module that
decouples audio and speaking styles via two parallel cross-attention layers,
using these features to guide the animation process. To enhance the quality of
results, we adopt and modify two optimization constraints: one to improve lip
synchronization and the other to preserve fine-grained identity and background
details. Extensive experiments demonstrate the superiority of DiTalker in terms
of lip synchronization and speaking style controllability. Project Page:
https://thenameishope.github.io/DiTalker/

</details>


### [22] [BigTokDetect: A Clinically-Informed Vision-Language Model Framework for Detecting Pro-Bigorexia Videos on TikTok](https://arxiv.org/abs/2508.06515)
*Minh Duc Chu,Kshitij Pawar,Zihao He,Roxanna Sharifi,Ross Sonnenblick,Magdalayna Curry,Laura D'Adamo,Lindsay Young,Stuart B Murray,Kristina Lerman*

Main category: cs.CV

> 提出BigTokDetect框架和BigTok数据集，用于检测TikTok上影响青少年男性的大肌肉畸形症内容，借助多模态处理，实现高精度的类目分类。

<details>
  <summary>Details</summary>

**Motivation:** 由于现有的文本基础检测系统无法有效检测大肌肉畸形症内容，该研究旨在解决这个问题，这些内容常常伪装成合法的健身内容，主要影响青少年男性。

**Method:** 提出了一种名为BigTokDetect的临床知情检测框架，用于识别TikTok上的大肌肉畸形症内容。该框架使用了一个称为BigTok的独特专家注释的多模态数据集，包括超过2,200个TikTok视频，这些视频由临床心理学家和精神病学家根据五个主要类别（包括身体形象、营养、锻炼、补充剂和男子气概）进行标注。

**Result:** 通过全面评估最先进的视觉语言模型，实现了主要类目分类82.9%的精度以及子类目检测69.0%的精度。实验还表明，多模态融合比文本方法提高了5-10%的性能，尤其是视频特征，提供了最多的判别信号。

**Conclusion:** 研究结果建立了一个新的多模态有害内容检测基准，并提供了计算工具和方法论框架，以实现具有专门心理健康领域针对性的可扩展内容审核。

**Abstract:** Social media platforms increasingly struggle to detect harmful content that
promotes muscle dysmorphic behaviors, particularly pro-bigorexia content that
disproportionately affects adolescent males. Unlike traditional eating disorder
detection focused on the "thin ideal," pro-bigorexia material masquerades as
legitimate fitness content through complex multimodal combinations of visual
displays, coded language, and motivational messaging that evade text-based
detection systems. We address this challenge by developing BigTokDetect, a
clinically-informed detection framework for identifying pro-bigorexia content
on TikTok. We introduce BigTok, the first expert-annotated multimodal dataset
of over 2,200 TikTok videos labeled by clinical psychologists and psychiatrists
across five primary categories spanning body image, nutrition, exercise,
supplements, and masculinity. Through a comprehensive evaluation of
state-of-the-art vision language models, we achieve 0.829% accuracy on primary
category classification and 0.690% on subcategory detection via domain-specific
finetuning. Our ablation studies demonstrate that multimodal fusion improves
performance by 5-10% over text-only approaches, with video features providing
the most discriminative signals. These findings establish new benchmarks for
multimodal harmful content detection and provide both the computational tools
and methodological framework needed for scalable content moderation in
specialized mental health domains.

</details>


### [23] [Frequency Prior Guided Matching: A Data Augmentation Approach for Generalizable Semi-Supervised Polyp Segmentation](https://arxiv.org/abs/2508.06517)
*Haoran Xi,Chen Liu,Xiaolin Li*

Main category: cs.CV

> FPGM improves generalization and robustness in polyp segmentation by leveraging the consistent frequency signature of polyp edges, outperforming existing methods in a semi-supervised learning setting with limited data and achieving state-of-the-art results.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve generalization in automated polyp segmentation across different imaging centers and devices, leveraging semi-supervised learning while addressing the issues of limited annotated data and poor generalization under domain shift.

**Method:** Frequency Prior Guided Matching (FPGM) is introduced as a novel augmentation framework for polyp segmentation. It relies on the discovery that polyp edges have a consistent frequency signature. FPGM operates in two stages: firstly, it learns a domain-invariant frequency prior from labeled polyp edges. Secondly, it applies spectral perturbations to unlabeled images to align their amplitude spectra with the learned prior, while preserving the phase to maintain structural integrity.

**Result:** FPGM establishes a new state-of-the-art in polyp segmentation on six public datasets, outperforming ten competing methods. It shows exceptional zero-shot generalization capabilities and achieves over 10% absolute gain in Dice score in scenarios with limited data.

**Conclusion:** FPGM provides enhanced cross-domain robustness for polyp segmentation, making it a suitable solution for clinical deployment under limited supervision.

**Abstract:** Automated polyp segmentation is essential for early diagnosis of colorectal
cancer, yet developing robust models remains challenging due to limited
annotated data and significant performance degradation under domain shift.
Although semi-supervised learning (SSL) reduces annotation requirements,
existing methods rely on generic augmentations that ignore polyp-specific
structural properties, resulting in poor generalization to new imaging centers
and devices. To address this, we introduce Frequency Prior Guided Matching
(FPGM), a novel augmentation framework built on a key discovery: polyp edges
exhibit a remarkably consistent frequency signature across diverse datasets.
FPGM leverages this intrinsic regularity in a two-stage process. It first
learns a domain-invariant frequency prior from the edge regions of labeled
polyps. Then, it performs principled spectral perturbations on unlabeled
images, aligning their amplitude spectra with this learned prior while
preserving phase information to maintain structural integrity. This targeted
alignment normalizes domain-specific textural variations, thereby compelling
the model to learn the underlying, generalizable anatomical structure.
Validated on six public datasets, FPGM establishes a new state-of-the-art
against ten competing methods. It demonstrates exceptional zero-shot
generalization capabilities, achieving over 10% absolute gain in Dice score in
data-scarce scenarios. By significantly enhancing cross-domain robustness, FPGM
presents a powerful solution for clinically deployable polyp segmentation under
limited supervision.

</details>


### [24] [Large Language Models Facilitate Vision Reflection in Image Classification](https://arxiv.org/abs/2508.06525)
*Guoyuan An,JaeYoon Kim,SungEui Yoon*

Main category: cs.CV

> 研究发现，在没有使用大规模视觉模型的情况下，通过视觉反射机制提升了LMMs在图像识别任务上的准确率，揭示了视觉语言模型的工作原理和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是探索在多模态模型中视觉反思的潜在能力，特别是在不需要进行大量训练的情况下提升识别准确性和增强模型的解释性。

**Method:** 此论文展示了通过一种名为视觉反思的方法提升大型多模态模型（LMMs）预测准确性的可能性。研究分为三个方面：1）将LMM用于验证专门的视觉模型预测，以提高图像识别准确率；2）分析视觉语言连接器如何将视觉特征转换为文本概念，从而增强常识推理能力；3）无需训练即可通过连接器提升LMM在细粒度识别任务上的性能。

**Result:** 研究发现LMMs可以通过视觉反思提高在ImageNet等基准测试上的表现，即使其原始性能通常低于专业的视觉编码器；发现视觉-语言连接器将视觉特征转化为明确的文本概念，可以使语言模型通过常识进行预测合理性判断；少量文本标记替换大量视觉标记也能使模型产生接近的答案，表明LMMs可能主要依赖于一套精简的文本表示而不是原始视觉特征；无需广泛特征对齐训练即可增强模型在细粒度识别任务上的表现。

**Conclusion:** 该研究提供了对视觉-语言模型可解释性的新见解，并表明视觉反思是实现稳健和可解释视觉识别的有前途的策略。

**Abstract:** This paper presents several novel findings on the explainability of vision
reflection in large multimodal models (LMMs). First, we show that prompting an
LMM to verify the prediction of a specialized vision model can improve
recognition accuracy, even on benchmarks like ImageNet, despite prior evidence
that LMMs typically underperform dedicated vision encoders. Second, we analyze
the internal behavior of vision reflection and find that the vision-language
connector maps visual features into explicit textual concepts, allowing the
language model to reason about prediction plausibility using commonsense
knowledge. We further observe that replacing a large number of vision tokens
with only a few text tokens still enables LLaVA to generate similar answers,
suggesting that LMMs may rely primarily on a compact set of distilled textual
representations rather than raw vision features. Third, we show that a
training-free connector can enhance LMM performance in fine-grained recognition
tasks, without extensive feature-alignment training. Together, these findings
offer new insights into the explainability of vision-language models and
suggest that vision reflection is a promising strategy for achieving robust and
interpretable visual recognition.

</details>


### [25] [A Framework Combining 3D CNN and Transformer for Video-Based Behavior Recognition](https://arxiv.org/abs/2508.06528)
*Xiuliang Zhang,Tadiwa Elisha Nyamasvisva,Chuntao Liu*

Main category: cs.CV

> This paper introduces a new hybrid framework that merges 3D CNN and Transformer architectures to improve video-based behavior recognition by combining their unique strengths, achieving better results and lower computational complexity compared to using either architecture alone.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to enhance behavior recognition in videos by addressing the limitations of 3D CNNs in capturing long-range dependencies and the high computational demands of Transformers.

**Method:** The paper proposes a hybrid framework that combines 3D CNN and Transformer architectures. The 3D CNN module captures low-level spatiotemporal features while the Transformer module focuses on long-range temporal dependencies. A fusion mechanism integrates both representations to enhance overall performance.

**Result:** The proposed hybrid model outperforms traditional 3D CNNs and standalone Transformers in video-based behavior recognition tasks in terms of accuracy and computational efficiency.

**Conclusion:** The study concludes that integrating 3D CNN and Transformer within a hybrid framework offers a scalable and effective solution for video-based behavior recognition, validated by ablation studies that confirm the added value of each module.

**Abstract:** Video-based behavior recognition is essential in fields such as public
safety, intelligent surveillance, and human-computer interaction. Traditional
3D Convolutional Neural Network (3D CNN) effectively capture local
spatiotemporal features but struggle with modeling long-range dependencies.
Conversely, Transformers excel at learning global contextual information but
face challenges with high computational costs. To address these limitations, we
propose a hybrid framework combining 3D CNN and Transformer architectures. The
3D CNN module extracts low-level spatiotemporal features, while the Transformer
module captures long-range temporal dependencies, with a fusion mechanism
integrating both representations. Evaluated on benchmark datasets, the proposed
model outperforms traditional 3D CNN and standalone Transformers, achieving
higher recognition accuracy with manageable complexity. Ablation studies
further validate the complementary strengths of the two modules. This hybrid
framework offers an effective and scalable solution for video-based behavior
recognition.

</details>


### [26] [RMT-PPAD: Real-time Multi-task Learning for Panoptic Perception in Autonomous Driving](https://arxiv.org/abs/2508.06529)
*Jiayuan Wang,Q. M. Jonathan Wu,Katsuya Suto,Ning Zhang*

Main category: cs.CV

> 该研究提出了RMT-PPAD，一个实时且基于变压器的多任务模型，用于对象检测、可行驶区域分割以及车道线分割，其结构和模块设计致力于提高性能并解决任务训练和测试的标签一致性问题，实验证明其在BDD100K数据集上表现出色，具有实时性高、精度高的优点。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在开发一个能够同时执行对象检测、可行驶区域分割及车道线分割并达到实时性能和高精度的模型，从而改进自动驾驶系统的全景驾驶感知。

**Method:** RMT-PPAD模型利用了一个轻量级模块进行特征融合，并设计了自适应分割解码器来自动学习多尺度特征的权重，减少任务特定结构的手动设计需求。同时解决车道线分割任务中的训练与测试标签不一致问题。

**Result:** 实验结果表明，RMT-PPAD在BDD100K数据集上表现出色，提供了高精度的结果（对象检测mAP50达84.9%、召回率为95.4%；可行驶区域分割mIoU达92.6%；车道线分割IoU为56.8%，准确率为84.7%）并实现了32.6 FPS的推理速度。

**Conclusion:** 基于实验和实际场景测试的表现，RMT-PPAD可稳定地提供高性能结果，适合用于改进自动驾驶系统的全景驾驶感知能力，促进其实际应用。

**Abstract:** Autonomous driving systems rely on panoptic driving perception that requires
both precision and real-time performance. In this work, we propose RMT-PPAD, a
real-time, transformer-based multi-task model that jointly performs object
detection, drivable area segmentation, and lane line segmentation. We introduce
a lightweight module, a gate control with an adapter to adaptively fuse shared
and task-specific features, effectively alleviating negative transfer between
tasks. Additionally, we design an adaptive segmentation decoder to learn the
weights over multi-scale features automatically during the training stage. This
avoids the manual design of task-specific structures for different segmentation
tasks. We also identify and resolve the inconsistency between training and
testing labels in lane line segmentation. This allows fairer evaluation.
Experiments on the BDD100K dataset demonstrate that RMT-PPAD achieves
state-of-the-art results with mAP50 of 84.9% and Recall of 95.4% for object
detection, mIoU of 92.6% for drivable area segmentation, and IoU of 56.8% and
accuracy of 84.7% for lane line segmentation. The inference speed reaches 32.6
FPS. Moreover, we introduce real-world scenarios to evaluate RMT-PPAD
performance in practice. The results show that RMT-PPAD consistently delivers
stable performance. The source codes and pre-trained models are released at
https://github.com/JiayuanWang-JW/RMT-PPAD.

</details>


### [27] [What Makes "Good" Distractors for Object Hallucination Evaluation in Large Vision-Language Models?](https://arxiv.org/abs/2508.06530)
*Ming-Kun Xie,Jia-Hao Xiao,Gang Niu,Lei Feng,Zhiqiang Kou,Min-Ling Zhang,Masashi Sugiyama*

Main category: cs.CV

> 本文提出了HOPE基准测试，用于更严格评估LVLMs的幻觉免疫力，通过更精细的干扰项生成方法，实验结果显示HOPE在揭示幻觉漏洞方面显著优于POPE。

<details>
  <summary>Details</summary>

**Motivation:** 现有基于抽样的对象探测评估（POPE）基准测试已显示出评估对象幻觉的有效性在下降，原因是使用了忽视图像特定信息的简单抽样策略。

**Method:** 提出了基于幻觉搜索的对象探测评估（HOPE）基准测试，通过利用内容感知幻觉搜索和基于描述的幻觉搜索来生成更具误导性的干扰项，以更严格地评估LVLMs的幻觉免疫力。内容感知幻觉搜索使用CLIP来选择预测可能性最高的负对象作为干扰项，而基于描述的幻觉搜索则通过将真实对象与错误描述配对来构造高度误导的干扰项。

**Result:** 实验结果表明，HOPE导致各种最先进的LVLMs的精度下降至少9%，最高达23%，显著优于POPE在揭示幻觉漏洞方面的表现。

**Conclusion:** HOPE基准测试通过引入更精确的干扰项生成方法，显著提升了对LVLMs幻觉问题检测的严格性和有效性。

**Abstract:** Large Vision-Language Models (LVLMs), empowered by the success of Large
Language Models (LLMs), have achieved impressive performance across domains.
Despite the great advances in LVLMs, they still suffer from the unavailable
object hallucination issue, which tends to generate objects inconsistent with
the image content. The most commonly used Polling-based Object Probing
Evaluation (POPE) benchmark evaluates this issue by sampling negative
categories according to category-level statistics, \textit{e.g.}, category
frequencies and co-occurrence. However, with the continuous advancement of
LVLMs, the POPE benchmark has shown diminishing effectiveness in assessing
object hallucination, as it employs a simplistic sampling strategy that
overlooks image-specific information and restricts distractors to negative
object categories only. In this paper, we introduce the Hallucination
searching-based Object Probing Evaluation (HOPE) benchmark, aiming to generate
the most misleading distractors (\textit{i.e.}, non-existent objects or
incorrect image descriptions) that can trigger hallucination in LVLMs, which
serves as a means to more rigorously assess their immunity to hallucination. To
explore the image-specific information, the content-aware hallucination
searching leverages Contrastive Language-Image Pre-Training (CLIP) to
approximate the predictive behavior of LVLMs by selecting negative objects with
the highest predicted likelihood as distractors. To expand the scope of
hallucination assessment, the description-based hallucination searching
constructs highly misleading distractors by pairing true objects with false
descriptions. Experimental results show that HOPE leads to a precision drop of
at least 9\% and up to 23\% across various state-of-the-art LVLMs,
significantly outperforming POPE in exposing hallucination vulnerabilities. The
code is available at https://github.com/xiemk/HOPE.

</details>


### [28] [Benchmarking Deep Learning-Based Object Detection Models on Feature Deficient Astrophotography Imagery Dataset](https://arxiv.org/abs/2508.06537)
*Shantanusinh Parmar*

Main category: cs.CV

> 文章研究了目标检测模型在稀疏夜空图像上的表现，指出了其在特征不足条件下的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的目标检测模型训练数据集如ImageNet, COCO, 和 PASCAL VOC 主要聚焦于日常物体，缺乏非商业化领域的信号稀疏性。为了填补这一空缺，本文引入了针对稀疏夜空图像的MobilTelesco数据集。

**Method:** 本文通过使用MobilTelesco智能手机天文摄影数据集来评估几种目标检测模型，该数据集专注于稀疏的夜空图像，填补了现有数据集在非商业领域信号稀疏性的不足。

**Result:** 研究表明，在特征不足条件下，目标检测模型面临着显著的挑战。

**Conclusion:** 通过在MobilTelesco数据集上进行基准测试，本文阐明了在稀疏信号和特征不足的条件下，目标检测模型可能遇到的问题和挑战。

**Abstract:** Object detection models are typically trained on datasets like ImageNet,
COCO, and PASCAL VOC, which focus on everyday objects. However, these lack
signal sparsity found in non-commercial domains. MobilTelesco, a
smartphone-based astrophotography dataset, addresses this by providing sparse
night-sky images. We benchmark several detection models on it, highlighting
challenges under feature-deficient conditions.

</details>


### [29] [MILD: Multi-Layer Diffusion Strategy for Complex and Precise Multi-IP Aware Human Erasing](https://arxiv.org/abs/2508.06543)
*Jinghan Yu,Zhiyuan Ma,Yue Ma,Kaiqi Liu,Yuhan Wang,Jianjun Li*

Main category: cs.CV

> A new dataset and the Multi-Layer Diffusion (MILD) method are introduced to improve human erasing in complex multi-IP scenarios.

<details>
  <summary>Details</summary>

**Motivation:** The motivation arises from the challenges faced by previous works when dealing with human-human occlusions, human-object entanglements, and background interferences. These issues are mainly due to dataset limitations and the inability to spatially decouple foreground instances from the background.

**Method:** A high-quality multi-IP human erasing dataset is introduced with diverse pose variations and complex backgrounds. The Multi-Layer Diffusion (MILD) strategy is proposed, which separates generation into pathways for each instance and the background. The approach also includes Human Morphology Guidance for better human-centric understanding and Spatially-Modulated Attention for improved attention flow.

**Result:** Extensive experiments demonstrate that MILD surpasses state-of-the-art methods on challenging human erasing benchmarks.

**Conclusion:** The proposed approach effectively addresses the limitation of existing methods in handling complex occlusions and interactions, outperforming current state-of-the-art techniques in human erasing.

**Abstract:** Recent years have witnessed the success of diffusion models in
image-customized tasks. Prior works have achieved notable progress on
human-oriented erasing using explicit mask guidance and semantic-aware
inpainting. However, they struggle under complex multi-IP scenarios involving
human-human occlusions, human-object entanglements, and background
interferences. These challenges are mainly due to: 1) Dataset limitations, as
existing datasets rarely cover dense occlusions, camouflaged backgrounds, and
diverse interactions; 2) Lack of spatial decoupling, where foreground instances
cannot be effectively disentangled, limiting clean background restoration. In
this work, we introduce a high-quality multi-IP human erasing dataset with
diverse pose variations and complex backgrounds. We then propose Multi-Layer
Diffusion (MILD), a novel strategy that decomposes generation into semantically
separated pathways for each instance and the background. To enhance
human-centric understanding, we introduce Human Morphology Guidance,
integrating pose, parsing, and spatial relations. We further present
Spatially-Modulated Attention to better guide attention flow. Extensive
experiments show that MILD outperforms state-of-the-art methods on challenging
human erasing benchmarks.

</details>


### [30] [Statistical Confidence Rescoring for Robust 3D Scene Graph Generation from Multi-View Images](https://arxiv.org/abs/2508.06546)
*Qi Xun Yeo,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

> 本文提出一种新方法，通过多视角图像分析，即使在没有3D注释的情况下，也能生成高质量的3D语义场景图。

<details>
  <summary>Details</summary>

**Motivation:** 当前3D语义场景图估计方法依赖于地面实况3D注释。本文探索仅使用多视角RGB图像进行3D语义场景图估计。

**Method:** 利用多视角RGB图像和从预测深度图中获得的伪点基几何结构来增强节点和边的特征，结合邻近节点信息和统计先验知识来提高场景图估计的鲁棒性。

**Result:** 实验表明我们的方法在仅使用多视角图像作为初始输入的情况下优于当前方法。

**Conclusion:** 研究展示了仅通过多视角图像输入，设计的方法能够在没有精确的3D注释的情况下，仍生成高质量的3D语义场景图。

**Abstract:** Modern 3D semantic scene graph estimation methods utilize ground truth 3D
annotations to accurately predict target objects, predicates, and
relationships. In the absence of given 3D ground truth representations, we
explore leveraging only multi-view RGB images to tackle this task. To attain
robust features for accurate scene graph estimation, we must overcome the noisy
reconstructed pseudo point-based geometry from predicted depth maps and reduce
the amount of background noise present in multi-view image features. The key is
to enrich node and edge features with accurate semantic and spatial information
and through neighboring relations. We obtain semantic masks to guide feature
aggregation to filter background features and design a novel method to
incorporate neighboring node information to aid robustness of our scene graph
estimates. Furthermore, we leverage on explicit statistical priors calculated
from the training summary statistics to refine node and edge predictions based
on their one-hop neighborhood. Our experiments show that our method outperforms
current methods purely using multi-view images as the initial input. Our
project page is available at https://qixun1.github.io/projects/SCRSSG.

</details>


### [31] [Slice or the Whole Pie? Utility Control for AI Models](https://arxiv.org/abs/2508.06551)
*Ye Tao*

Main category: cs.CV

> 本文提出了一种新型的工具控制机制——NNObfuscator，允许AI模型根据预定义条件动态调整性能，从而支持单一模型的自适应性能层次结构，有利于优化资源分配，减少不必要的计算，并支持AI部署中的可持续商业模式。

<details>
  <summary>Details</summary>

**Motivation:** 训练深度神经网络已成为一个资源密集型任务，且需要大量的标注数据、显著计算能力和大量的调优努力才能在不同应用场景中取得最优性能。当单一模型需要支持具有不同性能要求的应用程序时，这种挑战会变得更加复杂。传统的解决方案是训练多个模型版本以满足不同需求，这通常是低效且难以维护的。

**Method:** 本研究提出了一种名为NNObfuscator的新工具控制机制，该机制可用于让AI模型根据预定义条件动态调整其性能，从而替代传统需要为每个用户训练不同模型的方法。

**Result:** 实验结果验证了NNObfuscator的有效性，其能够使单一训练的模型适应广泛的任务，而无需进行大量更改。

**Conclusion:** NNObfuscator作为一种创新的方法，能够使AI模型的性能根据用户需求进行实时自适应调整，有效减少了资源消耗，提高了单一训练模型的适应性和效率，从而支持了AI部署中的可持续性商业模式。

**Abstract:** Training deep neural networks (DNNs) has become an increasingly
resource-intensive task, requiring large volumes of labeled data, substantial
computational power, and considerable fine-tuning efforts to achieve optimal
performance across diverse use cases. Although pre-trained models offer a
useful starting point, adapting them to meet specific user needs often demands
extensive customization, and infrastructure overhead. This challenge grows when
a single model must support diverse appli-cations with differing requirements
for performance. Traditional solutions often involve training multiple model
versions to meet varying requirements, which can be inefficient and difficult
to maintain. In order to overcome this challenge, we propose NNObfuscator, a
novel utility control mechanism that enables AI models to dynamically modify
their performance according to predefined conditions. It is different from
traditional methods that need separate models for each user. Instead,
NNObfuscator allows a single model to be adapted in real time, giving you
controlled access to multiple levels of performance. This mechanism enables
model owners set up tiered access, ensuring that free-tier users receive a
baseline level of performance while premium users benefit from enhanced
capabilities. The approach improves resource allocation, reduces unnecessary
computation, and supports sustainable business models in AI deployment. To
validate our approach, we conducted experiments on multiple tasks, including
image classification, semantic segmentation, and text to image generation,
using well-established models such as ResNet, DeepLab, VGG16, FCN and Stable
Diffusion. Experimental results show that NNObfuscator successfully makes model
more adaptable, so that a single trained model can handle a broad range of
tasks without requiring a lot of changes.

</details>


### [32] [Age-Diverse Deepfake Dataset: Bridging the Age Gap in Deepfake Detection](https://arxiv.org/abs/2508.06552)
*Unisha Joshi*

Main category: cs.CV

> 研究关注deepfake数据集中的年龄偏见问题，构建了年龄多样化数据集并改进了公平性的deepfake检测模型，提高了模型的准确性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 随着技术的进步和deepfake视频与图像的流行，deepfake检测面临挑战明显增加。尽管已存在大量检测模型，deepfake数据集中的人口统计性偏差（尤其是年龄偏见）仍未得到充分关注。为了提高年龄群体间的公平性，作者引入了年龄多样化的deepfake数据集。

**Method:** 通过融合Celeb-DF、FaceForensics++和UTKFace数据集，并生成合成数据来填补年龄分布缺口，构建了一个年龄多样化的deepfake数据集，旨在减轻deepfake数据集中的年龄偏向性问题。使用了三种deepfake检测模型进行评估：XceptionNet、EfficientNet和LipForensics。

**Result:** 评估结果表明，基于年龄多样化数据集训练的模型在各年龄群体中的表现更为公平，整体准确性提高，且在不同数据集间具有更高的泛化能力。

**Conclusion:** 本文贡献了一个可复现且具有公平意识的deepfake数据集和模型流水线，可作为未来公平deepfake检测研究的基础。相应的完整数据集和实现代码可见于https://github.com/unishajoshi/age-diverse-deepfake-detection。

**Abstract:** The challenges associated with deepfake detection are increasing
significantly with the latest advancements in technology and the growing
popularity of deepfake videos and images. Despite the presence of numerous
detection models, demographic bias in the deepfake dataset remains largely
unaddressed. This paper focuses on the mitigation of age-specific bias in the
deepfake dataset by introducing an age-diverse deepfake dataset that will
improve fairness across age groups. The dataset is constructed through a
modular pipeline incorporating the existing deepfake datasets Celeb-DF,
FaceForensics++, and UTKFace datasets, and the creation of synthetic data to
fill the age distribution gaps. The effectiveness and generalizability of this
dataset are evaluated using three deepfake detection models: XceptionNet,
EfficientNet, and LipForensics. Evaluation metrics, including AUC, pAUC, and
EER, revealed that models trained on the age-diverse dataset demonstrated
fairer performance across age groups, improved overall accuracy, and higher
generalization across datasets. This study contributes a reproducible,
fairness-aware deepfake dataset and model pipeline that can serve as a
foundation for future research in fairer deepfake detection. The complete
dataset and implementation code are available at
https://github.com/unishajoshi/age-diverse-deepfake-detection.

</details>


### [33] [Static and Plugged: Make Embodied Evaluation Simple](https://arxiv.org/abs/2508.06553)
*Jiahao Xiao,Jianbo Zhang,BoWen Yan,Shengyu Guo,Tongrui Ye,Kaiwei Zhang,Zicheng Zhang,Xiaohong Liu,Zhengxue Cheng,Lei Fan,Chuyi Li,Guangtao Zhai*

Main category: cs.CV

> 文章介绍并评估了一个新的插拔式基准测试StaticEmbodiedBench，它通过使用静态场景表示实现了统一、可扩展且全面的评估。

<details>
  <summary>Details</summary>

**Motivation:** 当前的基准测试依赖于交互式模拟环境或现实世界设置，这些方法成本高、碎片化且难以扩展，因此提出了StaticEmbodiedBench这种插拔式基准测试来解决这些问题。

**Method:** 介绍了一种名为StaticEmbodiedBench的新基准测试，它使用静态场景表示来进行统一评估，覆盖了42个多样化的场景和8个核心维度，通过一个简单的接口支持可扩展性和全面性评估。

**Result:** 评估了19个视觉-语言模型（VLMs）和11个视觉-语言-动作模型（VLAs），建立了首个针对具身智能的统一静态排行榜，并发布了一个包含200个样本的子集以加速具身智能的发展。

**Conclusion:** 通过引入StaticEmbodiedBench，提供了对具身智能模型的统一、可扩展且全面的评估方法，并促进了该领域的研究与发展。

**Abstract:** Embodied intelligence is advancing rapidly, driving the need for efficient
evaluation. Current benchmarks typically rely on interactive simulated
environments or real-world setups, which are costly, fragmented, and hard to
scale. To address this, we introduce StaticEmbodiedBench, a plug-and-play
benchmark that enables unified evaluation using static scene representations.
Covering 42 diverse scenarios and 8 core dimensions, it supports scalable and
comprehensive assessment through a simple interface. Furthermore, we evaluate
19 Vision-Language Models (VLMs) and 11 Vision-Language-Action models (VLAs),
establishing the first unified static leaderboard for Embodied intelligence.
Moreover, we release a subset of 200 samples from our benchmark to accelerate
the development of embodied intelligence.

</details>


### [34] [StyleTailor: Towards Personalized Fashion Styling via Hierarchical Negative Feedback](https://arxiv.org/abs/2508.06555)
*Hongbo Ma,Fei Shen,Hongbin Xu,Xiaoce Wang,Gang Xu,Jinkai Zheng,Liangqiong Qu,Ming Li*

Main category: cs.CV

> 本文探讨了时尚风格定制的智能解决方案，提出名为StyleTailor的协作代理框架，通过多层次负面反馈机制提升个性化服饰推荐的质量。

<details>
  <summary>Details</summary>

**Motivation:** 尽管智能代理在解决多个领域的问题上取得了进展，但个性化的时尚穿搭解决方案仍少有人问津，这充满潜力地促进了购物体验。

**Method:** 本文提出了StyleTailor，这是一种创新的协作代理框架，它将个性化服装设计、购物推荐、虚拟试穿和系统的评估整合为一个整体工作流。此框架引入了基于多层次负面反馈的迭代视觉细化范式，以实现对用户的自适应和精准对齐。

**Result:** 实验结果表明，StyleTailor在提供个性化设计和推荐方面表现出色，超越了没有负面反馈的强基线模型，确立了智能时尚系统的新的基准。

**Conclusion:** 通过引入多层次负面反馈机制和全面的评估套件，StyleTailor证明了其在智能时尚系统中的卓越性能，展现出其在消费者购物体验方面的巨大潜力。

**Abstract:** The advancement of intelligent agents has revolutionized problem-solving
across diverse domains, yet solutions for personalized fashion styling remain
underexplored, which holds immense promise for promoting shopping experiences.
In this work, we present StyleTailor, the first collaborative agent framework
that seamlessly unifies personalized apparel design, shopping recommendation,
virtual try-on, and systematic evaluation into a cohesive workflow. To this
end, StyleTailor pioneers an iterative visual refinement paradigm driven by
multi-level negative feedback, enabling adaptive and precise user alignment.
Specifically, our framework features two core agents, i.e., Designer for
personalized garment selection and Consultant for virtual try-on, whose outputs
are progressively refined via hierarchical vision-language model feedback
spanning individual items, complete outfits, and try-on efficacy.
Counterexamples are aggregated into negative prompts, forming a closed-loop
mechanism that enhances recommendation quality.To assess the performance, we
introduce a comprehensive evaluation suite encompassing style consistency,
visual quality, face similarity, and artistic appraisal. Extensive experiments
demonstrate StyleTailor's superior performance in delivering personalized
designs and recommendations, outperforming strong baselines without negative
feedback and establishing a new benchmark for intelligent fashion systems.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [35] [Transfer Learning with EfficientNet for Accurate Leukemia Cell Classification](https://arxiv.org/abs/2508.06535)
*Faisal Ahmed*

Main category: eess.IV

> The study utilizes transfer learning and data augmentation to improve ALL classification accuracy, with EfficientNet-B3 delivering top performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the diagnostic performance of Acute Lymphoblastic Leukemia (ALL) classification from peripheral blood smear images for early diagnosis and effective treatment planning.

**Method:** This study uses transfer learning with pre-trained CNNs and applies extensive data augmentation to address class imbalance in the dataset, evaluating models such as ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3.

**Result:** EfficientNet-B3 achieved the best results with an F1-score of 94.30%, accuracy of 92.02%, and AUC of 94.79%, outperforming previously reported methods in the C-NMC Challenge.

**Conclusion:** The findings demonstrate the effectiveness of combining data augmentation with advanced transfer learning models, especially EfficientNet-B3, in developing accurate and robust diagnostic tools for hematologic malignancy detection.

**Abstract:** Accurate classification of Acute Lymphoblastic Leukemia (ALL) from peripheral
blood smear images is essential for early diagnosis and effective treatment
planning. This study investigates the use of transfer learning with pretrained
convolutional neural networks (CNNs) to improve diagnostic performance. To
address the class imbalance in the dataset of 3,631 Hematologic and 7,644 ALL
images, we applied extensive data augmentation techniques to create a balanced
training set of 10,000 images per class. We evaluated several models, including
ResNet50, ResNet101, and EfficientNet variants B0, B1, and B3. EfficientNet-B3
achieved the best results, with an F1-score of 94.30%, accuracy of 92.02%,
andAUCof94.79%,outperformingpreviouslyreported methods in the C-NMCChallenge.
Thesefindings demonstrate the effectiveness of combining data augmentation with
advanced transfer learning models, particularly EfficientNet-B3, in developing
accurate and robust diagnostic tools for hematologic malignancy detection.

</details>
