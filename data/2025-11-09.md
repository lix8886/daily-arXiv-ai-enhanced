<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 4]
- [cs.CV](#cs.CV) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Activation-Space Personality Steering: Hybrid Layer Selection for Stable Trait Control in LLMs](https://arxiv.org/abs/2511.03738)
*Pranav Bhandari,Nicolas Fay,Sanjeevan Selvaganapathy,Amitava Datta,Usman Naseem,Mehwish Nasim*

Main category: cs.CL

> 该研究通过提取变压器层的隐藏状态激活并应用低秩子空间发现方法，识别出不同模型架构中人格特质相关的最佳层。这种方法能够为人格特质的稳健注入提供基础，使参与者能够精准控制大型语言模型（LLM）输出中的人格特质表达。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在其生成中表现出隐性人格特质，但可靠地控制或调整这些特质以满足特定需求仍然是一个开放挑战。需要有效机制来在生成过程中控制模型的行为。

**Method:** 提出一种新流程，利用Big Five人格特质框架，从变压器层提取隐藏状态激活，应用低秩子空间发现方法，识别不同模型架构中特质特定的最佳层，以实现稳健注入。通过一个灵活的引导框架与动态层选择，实现对LLM输出中特质表达的精确控制。

**Result:** 研究发现，人格特质占据了一个低秩共享子空间，这些潜在结构可以通过仔细调整转化为有效的引导机制，而不影响流畅度、变异性及总体能力。

**Conclusion:** 该研究有助于填补心理理论和实用模型对齐之间的空白，为人格特质在语言模型中的有效利用提供了新思路。

**Abstract:** Large Language Models exhibit implicit personalities in their generation, but
reliably controlling or aligning these traits to meet specific needs remains an
open challenge. The need for effective mechanisms for behavioural manipulation
of the model during generation is a critical gap in the literature that needs
to be fulfilled. Personality-aware LLMs hold a promising direction towards this
objective. However, the relationship between these psychological constructs and
their representations within LLMs remains underexplored and requires further
investigation. Moreover, it is intriguing to understand and study the use of
these representations to steer the models' behaviour. We propose a novel
pipeline that extracts hidden state activations from transformer layers using
the Big Five Personality Traits (Openness, Conscientiousness, Extraversion,
Agreeableness and Neuroticism), which is a comprehensive and empirically
validated framework to model human personality applies low-rank subspace
discovery methods, and identifies trait-specific optimal layers across
different model architectures for robust injection. The resulting
personality-aligned directions are then operationalised through a flexible
steering framework with dynamic layer selection, enabling precise control of
trait expression in LLM outputs. Our findings reveal that personality traits
occupy a low-rank shared subspace, and that these latent structures can be
transformed into actionable mechanisms for effective steering through careful
perturbations without impacting the fluency, variance and general capabilities,
helping to bridge the gap between psychological theory and practical model
alignment.

</details>


### [2] [TextualVerifier: Verify TextGrad Step-by-Step](https://arxiv.org/abs/2511.03739)
*Eugenius Mario Situmorang,Adila Alfa Krisnadhi,Ari Wibisono*

Main category: cs.CL

> Research introduces TextualVerifier to fill the verification gap for TextGrad, yielding significant improvements in reasoning validity without numerical gradients.

<details>
  <summary>Details</summary>

**Motivation:** To address the lack of self-verification mechanisms in TextGrad that ensure the reasoning validity in text-based decision making.

**Method:** TextualVerifier, a verification framework that leverages chain-of-thought reasoning and majority voting with large language models, is introduced. It includes four stages: chain-of-thought decomposition, variant generation, majority voting, and consensus aggregation. It integrates with TextGrad at the loss function and optimization result verification stages.

**Result:** Experimental evaluation shows TextualVerifier achieves up to a 29 percent improvement in reasoning validity and a 2.2 percentage point gain in TextGrad's performance with a moderate overhead.

**Conclusion:** TextualVerifier is the first self-verification framework for TextGrad, allowing more reliable reasoning and opening new possibilities for verification in text-based optimization.

**Abstract:** TextGrad is a novel approach to text-based automatic differentiation that
enables composite AI systems to perform optimization without explicit numerical
equations. However, it currently lacks self-verification mechanisms that ensure
reasoning validity in text-based decision making. This research introduces
TextualVerifier, a verification framework that leverages chain-of-thought
reasoning and majority voting with large language models to address this
verification gap. TextualVerifier implements a four-stage workflow:
chain-of-thought decomposition, variant generation, majority voting, and
consensus aggregation. It integrates non-invasively with TextGrad at both the
loss function and optimization result verification stages. Experimental
evaluation using the Gemini 1.5 Pro model is conducted in two phases: (1)
standalone evaluation on PRM800K, and (2) integrated evaluation with TextGrad
on GPQA-Diamond, MMLU-ML, and MMLU-CP benchmarks. Results show statistically
significant improvements (p < 0.001). In phase one, TextualVerifier improves
the validity of reasoning steps by 29 percent. In phase two, integration into
TextGrad loss function yields a 2.2 percentage point gain from 68.2 to 70.4
percent with a moderate overhead of 5.9 LLM calls on average. Further
evaluations of TextualVerifier versioning yield 8.08, 10.71, and 3.92
percentage point improvements on GPQA, MMLU-ML, and MMLU-CP respectively.
TextualVerifier thus presents the first self-verification framework for
TextGrad through LLM-based techniques without requiring numerical gradients,
enabling more reliable reasoning and opening new directions for verification in
text-based optimization.

</details>


### [3] [GRDD+: An Extended Greek Dialectal Dataset with Cross-Architecture Fine-tuning Evaluation](https://arxiv.org/abs/2511.03772)
*Stergios Chatzikyriakidis,Dimitris Papadakis,Sevasti-Ioanna Papaioannou,Erofili Psaltaki*

Main category: cs.CL

> 创建了一个含 10 种希腊语变体的扩展方言数据集（GRDD+），并用于微调实验，测试其对多个语言模型的效应。

<details>
  <summary>Details</summary>

**Motivation:** 补充现有的希腊方言数据集，创建一个更大的数据集，包含多种变体，以便研究高质量方言数据对多种大型语言模型的影响。

**Method:** 构建了一个名为扩展希腊方言数据集（GRDD+）的数据集，增加了克里特岛、塞浦路斯、Pontic 和北希腊方言的数据，并新增了 Greco-Corsican、Griko（南意大利希腊语）、Maniot、Heptanesian、Tsakonian 和 Katharevusa 希腊语六种新变体。

**Result:** 结果是一个包含 6,374,939 个词汇和 10 种变体的数据集，这是首个具有如此变异程度和规模的数据集。

**Conclusion:** 在三个模型架构（Llama-3-8B、Llama-3.1-8B、Krikri-8B）上进行了微调实验，并将结果与前沿模型（Claude-3.7-Sonnet、Gemini-2.5、ChatGPT-5）进行比较。

**Abstract:** We present an extended Greek Dialectal Dataset (GRDD+) 1that complements the
existing GRDD dataset with more data from Cretan, Cypriot, Pontic and Northern
Greek, while we add six new varieties: Greco-Corsican, Griko (Southern Italian
Greek), Maniot, Heptanesian, Tsakonian, and Katharevusa Greek. The result is a
dataset with total size 6,374,939 words and 10 varieties. This is the first
dataset with such variation and size to date. We conduct a number of
fine-tuning experiments to see the effect of good quality dialectal data on a
number of LLMs. We fine-tune three model architectures (Llama-3-8B,
Llama-3.1-8B, Krikri-8B) and compare the results to frontier models
(Claude-3.7-Sonnet, Gemini-2.5, ChatGPT-5).

</details>


### [4] [PLLuM: A Family of Polish Large Language Models](https://arxiv.org/abs/2511.03823)
*Jan Kocoń,Maciej Piasecki,Arkadiusz Janz,Teddy Ferdinan,Łukasz Radliński,Bartłomiej Koptyra,Marcin Oleksy,Stanisław Woźniak,Paweł Walkowiak,Konrad Wojtasik,Julia Moska,Tomasz Naskręt,Bartosz Walkowiak,Mateusz Gniewkowski,Kamil Szyc,Dawid Motyka,Dawid Banach,Jonatan Dalasiński,Ewa Rudnicka,Bartłomiej Alberski,Tomasz Walkowiak,Aleksander Szczęsny,Maciej Markiewicz,Tomasz Bernaś,Hubert Mazur,Kamil Żyta,Mateusz Tykierko,Grzegorz Chodak,Tomasz Kajdanowicz,Przemysław Kazienko,Agnieszka Karlińska,Karolina Seweryn,Anna Kołos,Maciej Chrabąszcz,Katarzyna Lorenc,Aleksandra Krasnodębska,Artur Wilczek,Katarzyna Dziewulska,Paula Betscher,Zofia Cieślińska,Katarzyna Kowol,Daria Mikoś,Maciej Trzciński,Dawid Krutul,Marek Kozłowski,Sławomir Dadas,Rafał Poświata,Michał Perełkiewicz,Małgorzata Grębowiec,Maciej Kazuła,Marcin Białas,Roman Roszko,Danuta Roszko,Jurgita Vaičenonienė,Andrius Utka,Paweł Levchuk,Paweł Kowalski,Irena Prawdzic-Jankowska,Maciej Ogrodniczuk,Monika Borys,Anna Bulińska,Wiktoria Gumienna,Witold Kieraś,Dorota Komosińska,Katarzyna Krasnowska-Kieraś,Łukasz Kobyliński,Martyna Lewandowska,Marek Łaziński,Mikołaj Łątkowski,Dawid Mastalerz,Beata Milewicz,Agnieszka Anna Mykowiecka,Angelika Peljak-Łapińska,Sandra Penno,Zuzanna Przybysz,Michał Rudolf,Piotr Rybak,Karolina Saputa,Aleksandra Tomaszewska,Aleksander Wawer,Marcin Woliński,Joanna Wołoszyn,Alina Wróblewska,Bartosz Żuk,Filip Żarnecki,Konrad Kaczyński,Anna Cichosz,Zuzanna Deckert,Monika Garnys,Izabela Grabarczyk,Wojciech Janowski,Sylwia Karasińska,Aleksandra Kujawiak,Piotr Misztela,Maria Szymańska,Karolina Walkusz,Igor Siek,Jakub Kwiatkowski,Piotr Pęzik*

Main category: cs.CL

> PLLuM 是一个专门为波兰语设计的大规模公开源代码语言模型家族，由波兰的主要研究机构开发，旨在增强波兰语本土人工智能技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** PLLuM 的开发动机是针对目前大规模语言模型主要集中在英语上，而忽视了其他语言。该项目旨在弥补这一不足，尤其是在英语中心化的商业环境中开发高质量、透明且文化相关性高的语言模型。

**Method:** PLLuM 是一个针对波兰语的大规模语言模型家族，该项目由多个波兰研究机构联合开发，旨在解决除了以英语为主之外的多语言模型支持。PLLuM 使用了新的 1400 亿个波兰语标记的数据集进行预训练，77K 自定义指令数据集和 100K 偏好优化数据集。其核心组件是一个负责任的人工智能框架，包括严格的数据治理和一个用于输出校正和安全筛选的混合模块。

**Result:** 模型的架构、训练程序及其对基础和指教调整变体的对齐技术已被详细叙述，并在公共管理的下游任务中展示了其效用。

**Conclusion:** 通过公开这些模型，PLLuM 目的是推动开放研究并加强波兰的主权人工智能技术。

**Abstract:** Large Language Models (LLMs) play a central role in modern artificial
intelligence, yet their development has been primarily focused on English,
resulting in limited support for other languages. We present PLLuM (Polish
Large Language Model), the largest open-source family of foundation models
tailored specifically for the Polish language. Developed by a consortium of
major Polish research institutions, PLLuM addresses the need for high-quality,
transparent, and culturally relevant language models beyond the English-centric
commercial landscape. We describe the development process, including the
construction of a new 140-billion-token Polish text corpus for pre-training, a
77k custom instructions dataset, and a 100k preference optimization dataset. A
key component is a Responsible AI framework that incorporates strict data
governance and a hybrid module for output correction and safety filtering. We
detail the models' architecture, training procedures, and alignment techniques
for both base and instruction-tuned variants, and demonstrate their utility in
a downstream task within public administration. By releasing these models
publicly, PLLuM aims to foster open research and strengthen sovereign AI
technologies in Poland.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [5] [LoRA-Edge: Tensor-Train-Assisted LoRA for Practical CNN Fine-Tuning on Edge Devices](https://arxiv.org/abs/2511.03765)
*Hyunseok Kwak,Kyeongwon Lee,Jae-Jin Lee,Woojoo Lee*

Main category: cs.CV

> 本文提出了LoRA-Edge，一种有效的卷积神经网络参数微调方法，减少了训练参数数量，能在严格的资源限制下实现HAR等边缘应用中的性能优化。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决设备内存、计算和能源预算有限的问题，实现边缘应用（例如人类活动识别HAR）中的卷积神经网络（CNN）的高效微调。

**Method:** 本文提出了LoRA-Edge方法，基于低秩适应（LoRA）并以张量列车辅助，包括(i) 对预训练卷积层应用张量列车奇异值分解（TT-SVD），(ii)选择性更新输出侧核心，通过零初始化来开启辅助路径，并(iii)将更新融合回密集核中，保持推理成本不变。

**Result:** 跨不同的HAR数据集和CNN骨干网络，LoRA-Edge的精度达到了全参数微调水平的95.3%，同时只更新至多1.49%的参数，并且比先前参数有效的基线方法表现更好，且在Jetson Orin Nano上收敛速度达到了1.4-3.8倍的提升。

**Conclusion:** LoRA-Edge能够实现在相似预算下对卷积神经网络进行结构一致和参数有效的现场调整，相较于全参数微调，保持高精度的同时仅更新极少部分参数，并在Jetson Orin Nano平台上达到更快的目标F1收敛。

**Abstract:** On-device fine-tuning of CNNs is essential to withstand domain shift in edge
applications such as Human Activity Recognition (HAR), yet full fine-tuning is
infeasible under strict memory, compute, and energy budgets. We present
LoRA-Edge, a parameter-efficient fine-tuning (PEFT) method that builds on
Low-Rank Adaptation (LoRA) with tensor-train assistance. LoRA-Edge (i) applies
Tensor-Train Singular Value Decomposition (TT-SVD) to pre-trained convolutional
layers, (ii) selectively updates only the output-side core with
zero-initialization to keep the auxiliary path inactive at the start, and (iii)
fuses the update back into dense kernels, leaving inference cost unchanged.
This design preserves convolutional structure and reduces the number of
trainable parameters by up to two orders of magnitude compared to full
fine-tuning. Across diverse HAR datasets and CNN backbones, LoRA-Edge achieves
accuracy within 4.7% of full fine-tuning while updating at most 1.49% of
parameters, consistently outperforming prior parameter-efficient baselines
under similar budgets. On a Jetson Orin Nano, TT-SVD initialization and
selective-core training yield 1.4-3.8x faster convergence to target F1.
LoRA-Edge thus makes structure-aligned, parameter-efficient on-device CNN
adaptation practical for edge platforms.

</details>


### [6] [SILVI: Simple Interface for Labeling Video Interactions](https://arxiv.org/abs/2511.03819)
*Ozan Kanbertay,Richard Vogg,Elif Karakoc,Peter M. Kappeler,Claudia Fichtel,Alexander S. Ecker*

Main category: cs.CV

> 提出了 SILVI，一种结合行为与互动标注和定位功能的开源标注软件，旨在帮助自动分析动物行为并推广到更广的应用场景中。

<details>
  <summary>Details</summary>

**Motivation:** 现有的开源标注工具要么支持无个体定位的行为标注，要么支持无法捕捉互动的定位，而本文旨在填补这一空白。

**Method:** SILVI, 一种开源标注软件，结合行为标注和定位功能，能够在视频数据中直接标注行为和互动，生成适合训练和验证计算机视觉模型的结构化输出。

**Result:** SILVI 软件的开发促进了将行为生态学与计算机视觉相结合，推动了自动精细化行为分析方法的发展，也可用于标注其他需要提取动态场景图的视频中的人类互动。

**Conclusion:** SILVI 软件及其文档和下载说明可在指定网址获取。

**Abstract:** Computer vision methods are increasingly used for the automated analysis of
large volumes of video data collected through camera traps, drones, or direct
observations of animals in the wild. While recent advances have focused
primarily on detecting individual actions, much less work has addressed the
detection and annotation of interactions -- a crucial aspect for understanding
social and individualized animal behavior. Existing open-source annotation
tools support either behavioral labeling without localization of individuals,
or localization without the capacity to capture interactions. To bridge this
gap, we present SILVI, an open-source labeling software that integrates both
functionalities. SILVI enables researchers to annotate behaviors and
interactions directly within video data, generating structured outputs suitable
for training and validating computer vision models. By linking behavioral
ecology with computer vision, SILVI facilitates the development of automated
approaches for fine-grained behavioral analyses. Although developed primarily
in the context of animal behavior, SILVI could be useful more broadly to
annotate human interactions in other videos that require extracting dynamic
scene graphs. The software, along with documentation and download instructions,
is available at: https://gitlab.gwdg.de/kanbertay/interaction-labelling-app.

</details>


### [7] [Noise Injection: Improving Out-of-Distribution Generalization for Limited Size Datasets](https://arxiv.org/abs/2511.03855)
*Duong Mai,Lawrence Hall*

Main category: cs.CV

> 通过在训练过程中引入基本的噪声注入技术（如高斯噪声、斑点噪声、泊松噪声和椒盐噪声），研究提高了从胸部X光片（CXR）检测COVID-19的深度学习模型的鲁棒性，大大缩小了训练分布内（ID）和分布外（OOD）数据的性能差距。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在解决深度学习模型在不同设备和人群上无法泛化的难题，特别是在对新的临床数据来源泛化能力不足的问题。

**Method:** Structure

**Result:** {
  "tldr": "通过在训练过程中引入基本的噪声注入技术（如高斯噪声、斑点噪声、泊松噪声和椒盐噪声），研究提高了从胸部X光片（CXR）检测COVID-19的深度学习模型的鲁棒性，大大缩小了训练分布内（ID）和分布外（OOD）数据的性能差距。",
  "motivation": "研究旨在解决深度学习模型在不同设备和人群上无法泛化的难题，特别是在对新的临床数据来源泛化能力不足的问题。",
  "method": "研究采用核心噪声注入技术，在模型训练过程中引入不同的噪声类型，以实现模型对分布变化的鲁棒性。",
  "result": "实验结果表明，这种技术能够显著降低ID和OOD数据集上的性能差异，提高了模型对新的临床数据源的适应性和泛化能力。",
  "conclusion": "通过在训练过程中加入噪声，能够提高深度学习模型在胸部X光片（CXR）检测COVID-19时的泛化能力，特别是对OOD数据的表现提升明显。这表明噪声注入是提高模型泛化性能的一种有效手段。研究的源代码可以在https://github.com/Duongmai127/Noisy-ood获取。 "
}

**Conclusion:** 通过在训练过程中加入噪声，能够提高深度学习模型在胸部X光片（CXR）检测COVID-19时的泛化能力，特别是对OOD数据的表现提升明显。这表明噪声注入是提高模型泛化性能的一种有效手段。研究的源代码可以在https://github.com/Duongmai127/Noisy-ood获取。

**Abstract:** Deep learned (DL) models for image recognition have been shown to fail to
generalize to data from different devices, populations, etc. COVID-19 detection
from Chest X-rays (CXRs), in particular, has been shown to fail to generalize
to out-of-distribution (OOD) data from new clinical sources not covered in the
training set. This occurs because models learn to exploit shortcuts -
source-specific artifacts that do not translate to new distributions - rather
than reasonable biomarkers to maximize performance on in-distribution (ID)
data. Rendering the models more robust to distribution shifts, our study
investigates the use of fundamental noise injection techniques (Gaussian,
Speckle, Poisson, and Salt and Pepper) during training. Our empirical results
demonstrate that this technique can significantly reduce the performance gap
between ID and OOD evaluation from 0.10-0.20 to 0.01-0.06, based on results
averaged over ten random seeds across key metrics such as AUC, F1, accuracy,
recall and specificity. Our source code is publicly available at
https://github.com/Duongmai127/Noisy-ood

</details>


### [8] [Investigating Robot Control Policy Learning for Autonomous X-ray-guided Spine Procedures](https://arxiv.org/abs/2511.03882)
*Florence Klitzner,Blanca Inigo,Benjamin D. Killeen,Lalithkumar Seenivasan,Michelle Song,Axel Krieger,Mathias Unberath*

Main category: cs.CV

> 本文研究了通过模仿学习开发用于X光引导手术的机器人控制策略，成功率为68.5%，但也发现了局限性，特别是入口点的精度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于模仿学习的机器人控制策略在基于视频的机器人领域受到越来越多的关注，但这种策略是否适用于X光引导的程序（如脊柱植入）仍然不清楚。因此，我们研究了模仿策略学习在双平面引导下的针头插入的机会和挑战。

**Method:** 我们开发了一个仿真的沙盒，用于对X光引导的脊柱手术进行可扩展和自动化的现实模拟。我们收集了一个由正确的轨迹及其对应的双平面X光序列组成的数据库，这些数据仿照了操作者的逐步对齐过程。然后，我们训练了基于模仿学习的策略，该策略基于视觉信息迭代地对齐针头。

**Result:** 我们的策略在68.5%的案例中首次尝试就成功了，并在整个椎骨水平上保持了安全的皮内轨迹。该策略能够推广到复杂的解剖结构，包括骨折，并对不同的初始化保持了鲁棒性。在真实双平面X射线上的回滚进一步表明，尽管仅在仿真中训练，但该模型能够产生合理的轨迹。

**Conclusion:** 初步结果是很有前景的，但也指出了局限性，特别是在入口点精度方面。完全闭环控制将需要进一步考虑如何提供足够频繁的反馈。随着更强大的先验知识和领域知识，这样的模型为未来开发轻量级和无CT的机器人手术导航提供了一个基础。

**Abstract:** Imitation learning-based robot control policies are enjoying renewed interest
in video-based robotics. However, it remains unclear whether this approach
applies to X-ray-guided procedures, such as spine instrumentation. This is
because interpretation of multi-view X-rays is complex. We examine
opportunities and challenges for imitation policy learning in bi-plane-guided
cannula insertion. We develop an in silico sandbox for scalable, automated
simulation of X-ray-guided spine procedures with a high degree of realism. We
curate a dataset of correct trajectories and corresponding bi-planar X-ray
sequences that emulate the stepwise alignment of providers. We then train
imitation learning policies for planning and open-loop control that iteratively
align a cannula solely based on visual information. This precisely controlled
setup offers insights into limitations and capabilities of this method. Our
policy succeeded on the first attempt in 68.5% of cases, maintaining safe
intra-pedicular trajectories across diverse vertebral levels. The policy
generalized to complex anatomy, including fractures, and remained robust to
varied initializations. Rollouts on real bi-planar X-rays further suggest that
the model can produce plausible trajectories, despite training exclusively in
simulation. While these preliminary results are promising, we also identify
limitations, especially in entry point precision. Full closed-look control will
require additional considerations around how to provide sufficiently frequent
feedback. With more robust priors and domain knowledge, such models may provide
a foundation for future efforts toward lightweight and CT-free robotic
intra-operative spinal navigation.

</details>


### [9] [Desert Waste Detection and Classification Using Data-Based and Model-Based Enhanced YOLOv12 DL Model](https://arxiv.org/abs/2511.03888)
*Abdulmumin Sa'ad,Sulaimon Oyeniyi Adebayo,Abdul Jabbar Siddiqui*

Main category: cs.CV

> 本文提出了一种改进的实时物体检测框架，专门针对沙漠等极端环境下的废物检测。通过结合自我对抗训练和专门的数据增强策略，我们的模型在DroneTrashNet数据集上显示出优异的表现。

<details>
  <summary>Details</summary>

**Motivation:** 面对全球废物危机加剧，特别是那些传统废物收集方法在偏远或恶劣环境中效率低下、耗时甚至危险的问题，我们旨在开发适用于这些环境的有效废物检测系统。

**Method:** 我们提出了一个基于YOLOv12的精简版对象检测框架，并结合了自我对抗训练（SAT）和专门的数据增强策略。

**Result:** 使用DroneTrashNet数据集，我们的模型在准确性（precision）、召回率（recall）和平均精度均值（mAP）方面有显著提升，并且实现了低延迟和较小的模型尺寸，适用于资源受限的空中无人机部署。

**Conclusion:** 我们的实验结果证实了结合数据驱动和模型驱动增强对于在沙漠环境中实现准确和有效的废物检测是有效的。

**Abstract:** The global waste crisis is escalating, with solid waste generation expected
to increase by 70% by 2050. Traditional waste collection methods, particularly
in remote or harsh environments like deserts, are labor-intensive, inefficient,
and often hazardous. Recent advances in computer vision and deep learning have
opened the door to automated waste detection systems, yet most research focuses
on urban environments and recyclable materials, overlooking organic and
hazardous waste and underexplored terrains such as deserts. In this work, we
propose an enhanced real-time object detection framework based on a pruned,
lightweight version of YOLOv12 integrated with Self-Adversarial Training (SAT)
and specialized data augmentation strategies. Using the DroneTrashNet dataset,
we demonstrate significant improvements in precision, recall, and mean average
precision (mAP), while achieving low latency and compact model size suitable
for deployment on resource-constrained aerial drones. Benchmarking our model
against state-of-the-art lightweight YOLO variants further highlights its
optimal balance of accuracy and efficiency. Our results validate the
effectiveness of combining data-centric and model-centric enhancements for
robust, real-time waste detection in desert environments.

</details>


### [10] [Improving Diagnostic Performance on Small and Imbalanced Datasets Using Class-Based Input Image Composition](https://arxiv.org/abs/2511.03891)
*Hlali Azzeddine,Majid Ben Yakhlef,Soulaiman El Hazzat*

Main category: cs.CV

> The paper proposes Class-Based Image Composition to enhance training inputs and improve model performance on imbalanced, small-sized datasets, significantly increasing diagnostic accuracy on the OCTDL dataset.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of high false prediction rates due to small, imbalanced datasets and poor input image quality in deep learning models.

**Method:** Class-Based Image Composition, which fuses multiple images of the same class into Composite Input Images (CoImg) to increase intra-class variance and enhance valuable information density per training sample.

**Result:** The method generated near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996) on the Co-OCTDL dataset, compared to a baseline model.

**Conclusion:** Class-Based Image Composition is effective in improving diagnostic results even with challenging, imbalanced datasets, showing significant reduction in false prediction rates and better handling of weak datasets.

**Abstract:** Small, imbalanced datasets and poor input image quality can lead to high
false predictions rates with deep learning models. This paper introduces
Class-Based Image Composition, an approach that allows us to reformulate
training inputs through a fusion of multiple images of the same class into
combined visual composites, named Composite Input Images (CoImg). That enhances
the intra-class variance and improves the valuable information density per
training sample and increases the ability of the model to distinguish between
subtle disease patterns. Our method was evaluated on the Optical Coherence
Tomography Dataset for Image-Based Deep Learning Methods (OCTDL) (Kulyabin et
al., 2024), which contains 2,064 high-resolution optical coherence tomography
(OCT) scans of the human retina, representing seven distinct diseases with a
significant class imbalance. We constructed a perfectly class-balanced version
of this dataset, named Co-OCTDL, where each scan is resented as a 3x1 layout
composite image. To assess the effectiveness of this new representation, we
conducted a comparative analysis between the original dataset and its variant
using a VGG16 model. A fair comparison was ensured by utilizing the identical
model architecture and hyperparameters for all experiments. The proposed
approach markedly improved diagnostic results.The enhanced Dataset achieved
near-perfect accuracy (99.6%) with F1-score (0.995) and AUC (0.9996), compared
to a baseline model trained on raw dataset. The false prediction rate was also
significantly lower, this demonstrates that the method can producehigh-quality
predictions even for weak datasets affected by class imbalance or small sample
size.

</details>


### [11] [I Detect What I Don't Know: Incremental Anomaly Learning with Stochastic Weight Averaging-Gaussian for Oracle-Free Medical Imaging](https://arxiv.org/abs/2511.03912)
*Nand Kumar Yadav,Rodrigue Rizk,William CW Chen,KC Santosh*

Main category: cs.CV

> 本文提出一种无需异常标签的无监督异常检测框架，通过轻量级适配器更新和基于不确定性的样本准入，提升了多种医疗影像异常检测的任务性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于标注异常样本的稀缺以及专家监督成本高昂，医学影像中未知异常检测依旧是基础性挑战。

**Method:** 提出了一种无监督的、无需专家干预的异常检测框架，通过增量扩展可信的正常样本集合。从一小部分已验证的正常影像开始，方法交替进行轻量级适配器更新和基于不确定性的样本准入。将预训练视觉骨干网络通过小卷积适配器增强，迅速进行领域适应且计算开销极低。提取的嵌入存储在一个紧凑的coreset中，实现高效的k-NN异常评分。通过双概率门机制确保增量扩展的安全性，样本在满足与现有coreset距离的校准z-score阈值及基于SWAG的本体不确定性下限后才能进入正常内存。这种机制在不依赖生成式重建或重放缓冲器的情况下防止漂移和错误包含。

**Result:** 实验证明，随着无标签数据的流入，系统逐步精化正常性的认知，性能显著超越基线模型。在COVID-CXR上，ROC-AUC从0.9489提升至0.9982（F1从0.8048提升至0.9746）；在肺炎CXR上，ROC-AUC从0.6834增至0.8968；在脑MRI ND-5上，ROC-AUC从0.6041提升至0.7269，PR-AUC从0.7539提升至0.8211。

**Conclusion:** 这些结果显示了所提出框架在真实世界标签稀缺的医学影像应用中的有效性和高效性。

**Abstract:** Unknown anomaly detection in medical imaging remains a fundamental challenge
due to the scarcity of labeled anomalies and the high cost of expert
supervision. We introduce an unsupervised, oracle-free framework that
incrementally expands a trusted set of normal samples without any anomaly
labels. Starting from a small, verified seed of normal images, our method
alternates between lightweight adapter updates and uncertainty-gated sample
admission. A frozen pretrained vision backbone is augmented with tiny
convolutional adapters, ensuring rapid domain adaptation with negligible
computational overhead. Extracted embeddings are stored in a compact coreset
enabling efficient k-nearest neighbor anomaly (k-NN) scoring. Safety during
incremental expansion is enforced by dual probabilistic gates, a sample is
admitted into the normal memory only if its distance to the existing coreset
lies within a calibrated z-score threshold, and its SWAG-based epistemic
uncertainty remains below a seed-calibrated bound. This mechanism prevents
drift and false inclusions without relying on generative reconstruction or
replay buffers. Empirically, our system steadily refines the notion of
normality as unlabeled data arrive, producing substantial gains over baselines.
On COVID-CXR, ROC-AUC improves from 0.9489 to 0.9982 (F1: 0.8048 to 0.9746); on
Pneumonia CXR, ROC-AUC rises from 0.6834 to 0.8968; and on Brain MRI ND-5,
ROC-AUC increases from 0.6041 to 0.7269 and PR-AUC from 0.7539 to 0.8211. These
results highlight the effectiveness and efficiency of the proposed framework
for real-world, label-scarce medical imaging applications.

</details>


### [12] [Adaptive Temporal Refinement: Continuous Depth Allocation and Distance Regression for Efficient Action Localization](https://arxiv.org/abs/2511.03943)
*Ibne Farabi Shihab,Sanjeda Akter,Anuj Sharma*

Main category: cs.CV

> 本文提出边界距离回归和自适应时间细化两种方法，用于提升时间动作定位的边界检测能力，适用于不同复杂度边界检测。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法应用的均匀计算并不适应边界检测难度的变化，因此作者提出改进以提高定位精度。

**Method:** 论文提出了两种方法：一是边界距离回归（BDR），通过有符号距离回归改进边界峰值；二是自适应时间细化（ATR），利用连续深度选择来分配计算。

**Result:** 该论文提出两种互补的方法来改进时间动作定位的边界检测。第一，边界距离回归（BDR）提供了一种信息论最优的定位方式，通过有符号距离回归而非分类，边界峰值提高43%。BDR可以轻松集成到现有方法中，用大约50行代码，跨不同架构提高1.8%到3.1% mAP@0.7。第二，自适应时间细化（ATR）通过连续深度选择 $	au \in [0,1]$ 来分配计算，使优化变得可微分且无需强化学习。在THUMOS14数据集上，ATR实现了56.5% mAP@0.7，计算强度为162G FLOPs，相较于之前53.6% mAP@0.7，虽计算量减少18%，性能反而提高了2.9%。这些改进在边界异质性较大的情况下降尤为明显。实验结果在四个基准上进行了严格的统计检验。

**Conclusion:** 本文的两种方法能够显著提高时间动作定位精确度，并能在不同程度上减少计算量。

**Abstract:** Temporal action localization requires precise boundary detection; however,
current methods apply uniform computation despite significant variations in
difficulty across boundaries. We present two complementary contributions.
First, Boundary Distance Regression (BDR) provides information-theoretically
optimal localization through signed-distance regression rather than
classification, achieving 43\% sharper boundary peaks. BDR retrofits to
existing methods with approximately 50 lines of code, yielding consistent 1.8
to 3.1\% mAP@0.7 improvements across diverse architectures. Second, Adaptive
Temporal Refinement (ATR) allocates computation via continuous depth selection
$\tau \in [0,1]$, enabling end-to-end differentiable optimization without
reinforcement learning. On THUMOS14, ATR achieves 56.5\% mAP@0.7 at 162G FLOPs,
compared to 53.6\% at 198G for uniform processing, providing a 2.9\%
improvement with 18\% less compute. Gains scale with boundary heterogeneity,
showing 4.2\% improvement on short actions. Training cost is mitigated via
knowledge distillation, with lightweight students retaining 99\% performance at
baseline cost. Results are validated across four benchmarks with rigorous
statistical testing.

</details>
