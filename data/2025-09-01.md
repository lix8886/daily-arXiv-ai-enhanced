<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [CoBA: Counterbias Text Augmentation for Mitigating Various Spurious Correlations via Semantic Triples](https://arxiv.org/abs/2508.21083)
*Kyohoon Jin,Juhwan Choi,Jungmin Yun,Junho Lee,Soojin Jang,Youngbin Kim*

Main category: cs.CL

> CoBA框架通过在语义三元组层面打乱非因果关系生成counterbias数据，改善了模型在分布外数据上的鲁棒性并减少了偏见。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于解决深度学习模型在训练数据中过度依赖非目标特征导致的性能退化和外部数据泛化能力弱的问题。

**Method:** 方法是引入counterbias数据扩充，提出了CoBA框架，通过在语义三元组层面操作来打乱非因果关系，生成counterbias数据，以减少偏见并增强模型对分布外数据的鲁棒性。

**Result:** 研究通过引入一种更通用的反事实数据扩充形式——counterbias数据扩充，以解决模型过度依赖训练数据中的非目标特征（如性别偏见、简单性偏见）导致的表现下降和泛化能力弱的问题。研究提出的CoBA框架，在语义三元组（主语-谓语-宾语）层面操作，通过分解文本、修改三元组来打乱非因果关系，并重建文本以生成counterbias数据，从而减轻了模型对非因果关系的依赖，增强了模型在分布外数据上的鲁棒性。实验表明，CoBA不仅提高了下游任务性能，还有效减少了偏见，增强了分布外的韧性。

**Conclusion:** 结论是CoBA不仅提高了下游任务性能，还有效减少了偏见，增强了分布外的韧性，提供了一个对抗非因果关系挑战的灵活和健壮的解决方案。

**Abstract:** Deep learning models often learn and exploit spurious correlations in
training data, using these non-target features to inform their predictions.
Such reliance leads to performance degradation and poor generalization on
unseen data. To address these limitations, we introduce a more general form of
counterfactual data augmentation, termed counterbias data augmentation, which
simultaneously tackles multiple biases (e.g., gender bias, simplicity bias) and
enhances out-of-distribution robustness. We present CoBA: CounterBias
Augmentation, a unified framework that operates at the semantic triple level:
first decomposing text into subject-predicate-object triples, then selectively
modifying these triples to disrupt spurious correlations. By reconstructing the
text from these adjusted triples, CoBA generates counterbias data that
mitigates spurious patterns. Through extensive experiments, we demonstrate that
CoBA not only improves downstream task performance, but also effectively
reduces biases and strengthens out-of-distribution resilience, offering a
versatile and robust solution to the challenges posed by spurious correlations.

</details>


### [2] [Mapping Toxic Comments Across Demographics: A Dataset from German Public Broadcasting](https://arxiv.org/abs/2508.21084)
*Jan Fillies,Michael Peter Hoffmann,Rebecca Reichel,Roman Salzwedel,Sven Bodemer,Adrian Paschke*

Main category: cs.CL

> 本研究创建了首个注释了毒言论并包含年龄估计的大型德语数据集，揭示了年龄相关的毒言论模式差异，并支持开发更加公平的年龄意识内容审核系统。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在填补现有毒言论数据集在不同年龄段用户在线沟通的理解上存在的空白。

**Method:** 本研究与德国公共服务内容网络funk合作，创建了首个大规模注释毒性并附带年龄估计的大数据集，以解决现有毒言论数据集缺乏人口统计背景的问题。数据集包括从Instagram、TikTok和YouTube平台上收集的3,024条人工注释和30,024条语言模型注释的匿名评论。通过预定义的毒性关键词筛选评论，得到16.7%的评论被标记为有问题。注释流程结合了人类专业知识和最先进的语言模型，识别出诸如侮辱、虚假信息和对广播费用的批评等关键类别。

**Result:** 该数据集揭示了基于年龄的毒言论模式差异：年轻用户倾向于使用更多表达性语言，而年长用户则更可能参与传播虚假信息和贬低。

**Conclusion:** 该资源为跨人口统计学的语用变异研究提供了新的机会，并支持了开发更加公平和年龄意识的内容审核系统。

**Abstract:** A lack of demographic context in existing toxic speech datasets limits our
understanding of how different age groups communicate online. In collaboration
with funk, a German public service content network, this research introduces
the first large-scale German dataset annotated for toxicity and enriched with
platform-provided age estimates. The dataset includes 3,024 human-annotated and
30,024 LLM-annotated anonymized comments from Instagram, TikTok, and YouTube.
To ensure relevance, comments were consolidated using predefined toxic
keywords, resulting in 16.7\% labeled as problematic. The annotation pipeline
combined human expertise with state-of-the-art language models, identifying key
categories such as insults, disinformation, and criticism of broadcasting fees.
The dataset reveals age-based differences in toxic speech patterns, with
younger users favoring expressive language and older users more often engaging
in disinformation and devaluation. This resource provides new opportunities for
studying linguistic variation across demographics and supports the development
of more equitable and age-aware content moderation systems.

</details>


### [3] [Granite Embedding R2 Models](https://arxiv.org/abs/2508.21085)
*Parul Awasthy,Aashka Trivedi,Yulong Li,Meet Doshi,Riyaz Bhat,Vignesh P,Vishwajeet Kumar,Yushu Yang,Bhavani Iyer,Abraham Daniels,Rudra Murthy,Ken Barker,Martin Franz,Madison Lee,Todd Ward,Salim Roukos,David Cox,Luis Lastras,Jaydeep Sen,Radu Florian*

Main category: cs.CL

> 摘要提取中...请稍等。

<details>
  <summary>Details</summary>

**Motivation:** 动机分析中...请稍等。

**Method:** 正在提取关键内容。

**Result:** 结构分析中...请稍等。

**Conclusion:** 结论分析中...请稍等。

**Abstract:** We introduce the Granite Embedding R2 models, a comprehensive family of
high-performance English encoder-based embedding models engineered for
enterprise-scale dense retrieval applications. Building upon our
first-generation release, these models deliver substantial improvements,
including 16x expanded context length (8,192 tokens), state-of-the-art
performance across diverse retrieval domains - text, code, long-document
search, multi-turn conversational, and tabular data - and measurable speed
advantages of 19-44\% over leading competitors while maintaining superior
accuracy. Our release encompasses both bi-encoder and cross-encoder
architectures, featuring a highly effective 22-layer retriever model and its
efficient 12-layer counterpart, alongside a high-quality reranker model, all
trained exclusively on enterprise-appropriate data with comprehensive
governance oversight. The models demonstrate exceptional versatility across
standard benchmarks, IBM-developed evaluation suites, and real-world enterprise
use cases, establishing new performance standards for open-source embedding
models. In an era where retrieval speed and accuracy are paramount for
competitive advantage, the Granite R2 models deliver a compelling combination
of cutting-edge performance, enterprise-ready licensing, and transparent data
provenance that organizations require for mission-critical deployments. All
models are publicly available under the Apache 2.0 license at
https://huggingface.co/collections/ibm-granite, enabling unrestricted research
and commercial use.

</details>


### [4] [TrInk: Ink Generation with Transformer Network](https://arxiv.org/abs/2508.21098)
*Zezhong Jin,Shubhang Desai,Xu Chen,Biyi Fang,Zhuoyi Huang,Zhe Li,Chong-Xin Gan,Xiao Tu,Man-Wai Mak,Yan Lu,Shujie Liu*

Main category: cs.CL

> 提出TrInk模型，改进墨水生成，通过新的编码和掩码增强模型性能，显著降低错误率。

<details>
  <summary>Details</summary>

**Motivation:** 开发一个能够更准确生成手写体的模型，并提高生成手写体的质量。

**Method:** 提出TrInk，一种基于Transformer的墨水生成模型，有效捕捉全局依赖。通过引入缩放位置编码和交叉注意力模块中的高斯记忆掩码来更好地对齐输入文本和生成的笔画点。设计了包括主观和客观评价流程来全面评估生成手写体的可读性和风格一致性。

**Result:** 实验表明，在IAM-OnDB数据集上，基于Transformer的方法相比之前的模型分别降低了35.56%的字符错误率(CER)和29.66%的单词错误率(WER)。

**Conclusion:** TrInk通过创新技术有效提高了手写体生成的质量和一致性，降低错误率，表明其在生成高质量手写体方面更具优势。

**Abstract:** In this paper, we propose TrInk, a Transformer-based model for ink
generation, which effectively captures global dependencies. To better
facilitate the alignment between the input text and generated stroke points, we
introduce scaled positional embeddings and a Gaussian memory mask in the
cross-attention module. Additionally, we design both subjective and objective
evaluation pipelines to comprehensively assess the legibility and style
consistency of the generated handwriting. Experiments demonstrate that our
Transformer-based model achieves a 35.56\% reduction in character error rate
(CER) and an 29.66% reduction in word error rate (WER) on the IAM-OnDB dataset
compared to previous methods. We provide an demo page with handwriting samples
from TrInk and baseline models at: https://akahello-a11y.github.io/trink-demo/

</details>


### [5] [How Does Cognitive Bias Affect Large Language Models? A Case Study on the Anchoring Effect in Price Negotiation Simulations](https://arxiv.org/abs/2508.21137)
*Yoshiki Takenami,Yin Jou Huang,Yugo Murawaki,Chenhui Chu*

Main category: cs.CL

> 研究发现LLM在价格谈判中受锚定效应的影响，类似于人类。推理模型较不易受此效应影响，而人格特质与此效应无关。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于探究LLM在实际应用中是否受认知偏差影响，尤其是锚定效应，这对于确保LLM安全和负责任地应用于社会至关重要。

**Method:** 本研究通过指示卖方LLM代理应用锚定效应，并使用客观和主观指标来评估谈判结果，调查了在LLM驱动的价格谈判中的锚定效应。

**Result:** 实验结果显示出LLM受锚定效应影响与人类相似，并且发现推理模型对锚定效应的敏感度较低，暗示长链式思考能减轻此效应。此外，未发现人格特质与易受锚定效应影响之间有显著相关性。

**Conclusion:** 这些发现加深了对LLM中认知偏差的理解，有助于实现LLM在社会中的安全与负责应用。

**Abstract:** Cognitive biases, well-studied in humans, can also be observed in LLMs,
affecting their reliability in real-world applications. This paper investigates
the anchoring effect in LLM-driven price negotiations. To this end, we
instructed seller LLM agents to apply the anchoring effect and evaluated
negotiations using not only an objective metric but also a subjective metric.
Experimental results show that LLMs are influenced by the anchoring effect like
humans. Additionally, we investigated the relationship between the anchoring
effect and factors such as reasoning and personality. It was shown that
reasoning models are less prone to the anchoring effect, suggesting that the
long chain of thought mitigates the effect. However, we found no significant
correlation between personality traits and susceptibility to the anchoring
effect. These findings contribute to a deeper understanding of cognitive biases
in LLMs and to the realization of safe and responsible application of LLMs in
society.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [2COOOL: 2nd Workshop on the Challenge Of Out-Of-Label Hazards in Autonomous Driving](https://arxiv.org/abs/2508.21080)
*Ali K. AlShami,Ryan Rabinowitz,Maged Shoman,Jianwu Fang,Lukas Picek,Shao-Yuan Lo,Steve Cruz,Khang Nhut Lam,Nachiket Kamod,Lei-Lei Li,Jugal Kalita,Terrance E. Boult*

Main category: cs.CV

> The 2nd Workshop on the Challenge of Out-of-Label Hazards in Autonomous Driving aims to advance the state-of-the-art in novelty handling, particularly regarding out-of-distribution hazard detection.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the barriers to real-world deployment of autonomous driving technologies, particularly the issue of handling novel and unexpected scenarios.

**Method:** This workshop focuses on the development of new algorithms and systems for hazard avoidance by integrating ideas from anomaly detection, open-set recognition, open-vocabulary modeling, and domain adaptation.

**Result:** The workshop will serve as a platform for academic and industry experts to collaborate and share knowledge towards overcoming the challenges of developing safe autonomous vehicles.

**Conclusion:** The workshop aims to inspire the development of safe autonomous driving practices and new methodologies for handling novel scenarios and hazards.

**Abstract:** As the computer vision community advances autonomous driving algorithms,
integrating vision-based insights with sensor data remains essential for
improving perception, decision making, planning, prediction, simulation, and
control. Yet we must ask: Why don't we have entirely safe self-driving cars
yet? A key part of the answer lies in addressing novel scenarios, one of the
most critical barriers to real-world deployment. Our 2COOOL workshop provides a
dedicated forum for researchers and industry experts to push the state of the
art in novelty handling, including out-of-distribution hazard detection,
vision-language models for hazard understanding, new benchmarking and
methodologies, and safe autonomous driving practices. The 2nd Workshop on the
Challenge of Out-of-Label Hazards in Autonomous Driving (2COOOL) will be held
at the International Conference on Computer Vision (ICCV) 2025 in Honolulu,
Hawaii, on October 19, 2025. We aim to inspire the development of new
algorithms and systems for hazard avoidance, drawing on ideas from anomaly
detection, open-set recognition, open-vocabulary modeling, domain adaptation,
and related fields. Building on the success of its inaugural edition at the
Winter Conference on Applications of Computer Vision (WACV) 2025, the workshop
will feature a mix of academic and industry participation.

</details>


### [7] [Advanced Deep Learning Techniques for Classifying Dental Conditions Using Panoramic X-Ray Images](https://arxiv.org/abs/2508.21088)
*Alireza Golkarieh,Kiana Kiashemshaki,Sajjad Rezvani Boroujeni*

Main category: cs.CV

> This study evaluates deep learning methods for classifying dental conditions in panoramic X-rays, with a hybrid CNN Random Forest model achieving the best performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this study is to explore deep learning methods for the automated classification of dental conditions in panoramic X-ray images to provide an efficient and reliable diagnostic support.

**Method:** This study uses three approaches: a custom CNN, hybrid models (CNN feature extraction with traditional classifiers), and fine-tuned pre-trained architectures like VGG16 for classifying dental conditions in panoramic X-ray images.

**Result:** The hybrid CNN Random Forest model achieved the highest accuracy of 85.4%, surpassing the custom CNN at 74.3%. Among pre-trained models, VGG16 performed the best at 82.3% accuracy.

**Conclusion:** Combining CNN-based feature extraction with ensemble classifiers such as Random Forest provides a practical path for automated dental diagnostic support, although larger datasets and further clinical validation are needed.

**Abstract:** This study investigates deep learning methods for automated classification of
dental conditions in panoramic X-ray images. A dataset of 1,512 radiographs
with 11,137 expert-verified annotations across four conditions fillings,
cavities, implants, and impacted teeth was used. After preprocessing and class
balancing, three approaches were evaluated: a custom convolutional neural
network (CNN), hybrid models combining CNN feature extraction with traditional
classifiers, and fine-tuned pre-trained architectures. Experiments employed 5
fold cross validation with accuracy, precision, recall, and F1 score as
evaluation metrics. The hybrid CNN Random Forest model achieved the highest
performance with 85.4% accuracy, surpassing the custom CNN baseline of 74.3%.
Among pre-trained models, VGG16 performed best at 82.3% accuracy, followed by
Xception and ResNet50. Results show that hybrid models improve discrimination
of morphologically similar conditions and provide efficient, reliable
performance. These findings suggest that combining CNN-based feature extraction
with ensemble classifiers offers a practical path toward automated dental
diagnostic support, while also highlighting the need for larger datasets and
further clinical validation.

</details>
