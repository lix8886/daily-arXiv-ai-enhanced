<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 41]
- [cs.CV](#cs.CV) [Total: 38]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Omnilingual ASR: Open-Source Multilingual Speech Recognition for 1600+ Languages](https://arxiv.org/abs/2511.09690)
*Omnilingual ASR team,Gil Keren,Artyom Kozhevnikov,Yen Meng,Christophe Ropers,Matthew Setzler,Skyler Wang,Ife Adebara,Michael Auli,Can Balioglu,Kevin Chan,Chierh Cheng,Joe Chuang,Caley Droof,Mark Duppenthaler,Paul-Ambroise Duquenne,Alexander Erben,Cynthia Gao,Gabriel Mejia Gonzalez,Kehan Lyu,Sagar Miglani,Vineel Pratap,Kaushik Ram Sadagopan,Safiyyah Saleem,Arina Turkatenko,Albert Ventayol-Boada,Zheng-Xin Yong,Yu-An Chung,Jean Maillard,Rashel Moritz,Alexandre Mourachko,Mary Williamson,Shireen Yates*

Main category: cs.CL

> Omnilingual ASR项目旨在通过大规模的无监督学习引入一个跨语言的语音识别系统，能够通过少量数据样本来学习并支持新增语言。

<details>
  <summary>Details</summary>

**Motivation:** 大多数世界语言目前不受支持，传统架构限制了语言扩展能力，并涉及到伦理问题。通过Omnilingual ASR，我们提出了一个扩展性良好的大规模ASR系统。

**Method:** 引入了Omnilingual ASR系统，该系统通过70亿参数的无监督预训练和LLM启发的编码器-解码器架构来学习鲁棒的语音表示，从而支持扩展到多种未服务语言。

**Result:** 该系统在超过1,600种语言中进行了评估，取得了显著的性能提升，尤其是在低资源语言中，并展示了强大的泛化能力。

**Conclusion:** Omnilingual ASR系统被作为从低功耗设备到高精度需求的模型家族发布。强调了开源模型和工具在社会影响和伦理考量中的作用，鼓励社会各方面的参与。

**Abstract:** Automatic speech recognition (ASR) has advanced in high-resource languages, but most of the world's 7,000+ languages remain unsupported, leaving thousands of long-tail languages behind. Expanding ASR coverage has been costly and limited by architectures that restrict language support, making extension inaccessible to most--all while entangled with ethical concerns when pursued without community collaboration. To transcend these limitations, we introduce Omnilingual ASR, the first large-scale ASR system designed for extensibility. Omnilingual ASR enables communities to introduce unserved languages with only a handful of data samples. It scales self-supervised pre-training to 7B parameters to learn robust speech representations and introduces an encoder-decoder architecture designed for zero-shot generalization, leveraging a LLM-inspired decoder. This capability is grounded in a massive and diverse training corpus; by combining breadth of coverage with linguistic variety, the model learns representations robust enough to adapt to unseen languages. Incorporating public resources with community-sourced recordings gathered through compensated local partnerships, Omnilingual ASR expands coverage to over 1,600 languages, the largest such effort to date--including over 500 never before served by ASR. Automatic evaluations show substantial gains over prior systems, especially in low-resource conditions, and strong generalization. We release Omnilingual ASR as a family of models, from 300M variants for low-power devices to 7B for maximum accuracy. We reflect on the ethical considerations shaping this design and conclude by discussing its societal impact. In particular, we highlight how open-sourcing models and tools can lower barriers for researchers and communities, inviting new forms of participation. Open-source artifacts are available at https://github.com/facebookresearch/omnilingual-asr.

</details>


### [2] [Order Matters: Rethinking Prompt Construction in In-Context Learning](https://arxiv.org/abs/2511.09700)
*Warren Li,Yiqian Wang,Zihan Wang,Jingbo Shang*

Main category: cs.CL

> 该研究对ICL中的假设进行了重新评估，发现示例排序对性能的影响与选择示例同样重要，强调在提示设计中需要同等关注。

<details>
  <summary>Details</summary>

**Motivation:** 重新审视了关于示例选择和排序对性能影响的假设，发现示例排序对性能的影响并不亚于示例选择的影响。

**Method:** 通过在分类和生成任务上的受控实验，使用多个开源模型系列（0.5B到27B参数）和GPT-5，系统地比较了选择和排序对性能的影响。

**Result:** 研究发现，由于不同示例排序导致的性能差异与使用完全不同的示例集一样显著。同时表明，通过开发集可以识别出强大的排序方式，达到接近于根据测试标签选择最佳排序的性能。

**Conclusion:** 强调了示例选择和排序在提示设计中同等重要的地位，呼吁重新审视ICL中所持有的假设。

**Abstract:** In-context learning (ICL) enables large language models to perform new tasks by conditioning on a sequence of examples. Most prior work reasonably and intuitively assumes that which examples are chosen has a far greater effect on performance than how those examples are ordered, leading to a focus on example selection. We revisit this assumption and conduct a systematic comparison between the effect of selection and ordering. Through controlled experiments on both classification and generation tasks, using multiple open-source model families (0.5B to 27B parameters) and GPT-5, we find that the variance in performance due to different example orderings is comparable to that from using entirely different example sets. Furthermore, we show that strong orderings can be identified using only a development set, achieving performance close to an oracle that selects the best ordering based on test labels. Our findings highlight the equal and intertwined importance of example selection and ordering in prompt design, calling for a reexamination of the assumptions held in ICL.

</details>


### [3] [Contextual morphologically-guided tokenization for Latin encoder models](https://arxiv.org/abs/2511.09709)
*Marisa Hudspeth,Patrick J. Burns,Brendan O'Connor*

Main category: cs.CL

> 本研究针对中等预训练数据资源和丰富词法资源的形态学丰富语言拉丁语进行了形态学感知的分词方法的研究，结果表明这种方法能够提升下游任务的性能并增强模型的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的分词方法往往偏向于高压缩和低繁育率的信息论目标，而非语言学目标，比如形态学对齐。对于形态学丰富的语言来说，标准分词方法的这些缺点在下游性能上有所体现，尤其是在低资源语言的建模中。

**Method:** 我们研究了针对形态学丰富的拉丁语进行形态学感知分词的方法。这个工作考虑了拉丁语在预训练数据方面的中等资源状态和在精心策划的词法资源方面的丰富状态，这些资源在讨论低资源语言建模时经常被忽视但至关重要的因素。

**Result:** 我们发现，基于形态学指导的分词方法在四个下游任务上提升了整体性能。特别是在领域外文本上的表现提升最为明显，这表明我们的模型拥有更好的泛化能力。

**Conclusion:** 我们的研究展示了词法资源在提升形态学复杂语言的建模性能方面的效用。对于缺乏大规模预训练数据的低资源语言而言，开发和使用语言学资源可以作为提高语言模型性能的可行替代方案。

**Abstract:** Tokenization is a critical component of language model pretraining, yet standard tokenization methods often prioritize information-theoretical goals like high compression and low fertility rather than linguistic goals like morphological alignment. In fact, they have been shown to be suboptimal for morphologically rich languages, where tokenization quality directly impacts downstream performance. In this work, we investigate morphologically-aware tokenization for Latin, a morphologically rich language that is medium-resource in terms of pretraining data, but high-resource in terms of curated lexical resources -- a distinction that is often overlooked but critical in discussions of low-resource language modeling. We find that morphologically-guided tokenization improves overall performance on four downstream tasks. Performance gains are most pronounced for out of domain texts, highlighting our models' improved generalization ability. Our findings demonstrate the utility of linguistic resources to improve language modeling for morphologically complex languages. For low-resource languages that lack large-scale pretraining data, the development and incorporation of linguistic resources can serve as a feasible alternative to improve LM performance.

</details>


### [4] [Assessing the Applicability of Natural Language Processing to Traditional Social Science Methodology: A Case Study in Identifying Strategic Signaling Patterns in Presidential Directives](https://arxiv.org/abs/2511.09738)
*C. LeMay,A. Lane,J. Seales,M. Winstead,S. Baty*

Main category: cs.CL

> 研究显示了NLP在从文本数据中提取重大项目方面的潜力，但也强调了进一步评估NLP有效性的重要性。所使用的AI工具可能已经过时。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是探索NLP在处理大规模文本数据上的应用潜力，以及它能为复杂、详细的文档集合，如总统指令，提供信号主题识别的能力。

**Method:** 本研究调查了自然语言处理（NLP）如何从更大的书面数据集中提取主要话题，具体应用于从里根到克林顿时期的总统指令（PDs）中识别信号主题的案例。分析师和NLP都识别出相关文档，展示了NLP在涉及大量书面语料的研究中的潜在效用。

**Result:** 研究展示了NLP的潜力同时也揭示了NLP与人类标注结果之间的差异，这意味着需要更多的研究来评估NLP在这种情境下的有效性。

**Conclusion:** 这项研究采用了2023年的工具进行，虽然显示了NLP应用于新兴的社会科学领域的基本能力，但也意味着所用的AI工具可能已经过时，而AI领域正迅速发展，新工具不断涌现。

**Abstract:** Our research investigates how Natural Language Processing (NLP) can be used to extract main topics from a larger corpus of written data, as applied to the case of identifying signaling themes in Presidential Directives (PDs) from the Reagan through Clinton administrations. Analysts and NLP both identified relevant documents, demonstrating the potential utility of NLPs in research involving large written corpuses. However, we also identified discrepancies between NLP and human-labeled results that indicate a need for more research to assess the validity of NLP in this use case. The research was conducted in 2023, and the rapidly evolving landscape of AIML means existing tools have improved and new tools have been developed; this research displays the inherent capabilities of a potentially dated AI tool in emerging social science applications.

</details>


### [5] [How Small Can You Go? Compact Language Models for On-Device Critical Error Detection in Machine Translation](https://arxiv.org/abs/2511.09748)
*Muskaan Chopra,Lorenz Sparrenberg,Sarthak Khanna,Rafet Sifa*

Main category: cs.CL

> None Provided

<details>
  <summary>Details</summary>

**Motivation:** None Provided

**Method:** Structure

**Result:** {
  "tldr": "文章探讨了在边缘设备和隐私敏感工作流程中，小型化语言模型在检测意义改变的翻译错误方面的效果。通过多个小于20亿参数的模型在不同数据集上的基准测试，研究发现10亿参数左右的模型提供最佳的质量-效率平衡。",
  "motivation": "大规模语言模型虽然在评估机器翻译方面表现出色，但由于规模和成本的原因，难以部署在边缘设备和需要保护隐私的场景中。因此，作者希望探索在保持检测意义改变翻译错误能力的前提下，语言模型可以小到什么程度。",
  "method": "研究聚焦于英德之间的关键错误检测（CED），使用多个小于20亿参数的模型（如LFM2-350M、Qwen-3-0.6B/1.7B、Llama-3.2-1B-Instruct、Gemma-3-1B）在WMT21、WMT22和SynCED-EnDe-2025数据集上进行基准测试。采用了标准化提示、轻量级logit偏差校准和多数投票的方法，并报告了语义质量（MCC，F1-ERR/F1-NOT）和计算指标（VRAM，延迟，吞吐量）。",
  "result": "研究结果显示，大约10亿参数的模型提供了最佳的质量与效率平衡。特别是Gemma-3-1B模型经过合并权重微调后，在SynCED-EnDe-2025数据集上达到了MCC=0.77和F1-ERR=0.98的优秀结果，并且在MacBook Pro M4 Pro（24 GB VRAM）上单样本延迟仅为400 ms。相比之下，更大规模的模型虽然能提供更高的绝对MCC值，但计算成本更高，超小型模型尽管可用，但对实体和数字错误检测不足。",
  "conclusion": "通过增加轻量级校准和少量样本监督，小型化的指令调优语言模型可以在边缘设备上提供可靠的错误检测，使得能在实际翻译管道中以较低成本实现私有的错误筛查。",
  "paper": "None Provided", 
  "reference_text": "None Provided" 
}

**Conclusion:** None Provided

**Abstract:** Large Language Models (LLMs) excel at evaluating machine translation (MT), but their scale and cost hinder deployment on edge devices and in privacy-sensitive workflows. We ask: how small can you get while still detecting meaning-altering translation errors? Focusing on English->German Critical Error Detection (CED), we benchmark sub-2B models (LFM2-350M, Qwen-3-0.6B/1.7B, Llama-3.2-1B-Instruct, Gemma-3-1B) across WMT21, WMT22, and SynCED-EnDe-2025. Our framework standardizes prompts, applies lightweight logit-bias calibration and majority voting, and reports both semantic quality (MCC, F1-ERR/F1-NOT) and compute metrics (VRAM, latency, throughput). Results reveal a clear sweet spot around one billion parameters: Gemma-3-1B provides the best quality-efficiency trade-off, reaching MCC=0.77 with F1-ERR=0.98 on SynCED-EnDe-2025 after merged-weights fine-tuning, while maintaining 400 ms single-sample latency on a MacBook Pro M4 Pro (24 GB). At larger scale, Qwen-3-1.7B attains the highest absolute MCC (+0.11 over Gemma) but with higher compute cost. In contrast, ultra-small models (0.6B) remain usable with few-shot calibration yet under-detect entity and number errors. Overall, compact, instruction-tuned LLMs augmented with lightweight calibration and small-sample supervision can deliver trustworthy, on-device CED for MT, enabling private, low-cost error screening in real-world translation pipelines. All datasets, prompts, and scripts are publicly available at our GitHub repository.

</details>


### [6] [Predicate-Argument Structure Divergences in Chinese and English Parallel Sentences and their Impact on Language Transfer](https://arxiv.org/abs/2511.09796)
*Rocco Tripodi,Xiaoyu Liu*

Main category: cs.CL

> 本文分析了中文和英文在述谓结构上的相似性与差异，指出了在跨语言NLP中源语言选择上的重要性和潜在的不对称性。

<details>
  <summary>Details</summary>

**Motivation:** 研究目的是分析跨语言自然语言处理中不同语言之间的结构差异，特别是如何利用源语言向目标语言进行标注投影时不同语言间的不对称性。

**Method:** 本文通过对比平行的中文和英文句子的述谓结构，探讨并分析了述谓标注的对齐与错位，提出了结构差异的分类。

**Result:** 研究结果表明跨语言的标注投影是不对称的，即不同的源语言在投影到目标语言时结果会有所不同。

**Conclusion:** 此研究强调了在跨语言NLP应用中选择源语言时的考虑，证明在做出任何科学论断之前，需要考虑语言之间的不对称性。

**Abstract:** Cross-lingual Natural Language Processing (NLP) has gained significant traction in recent years, offering practical solutions in low-resource settings by transferring linguistic knowledge from resource-rich to low-resource languages. This field leverages techniques like annotation projection and model transfer for language adaptation, supported by multilingual pre-trained language models. However, linguistic divergences hinder language transfer, especially among typologically distant languages. In this paper, we present an analysis of predicate-argument structures in parallel Chinese and English sentences. We explore the alignment and misalignment of predicate annotations, inspecting similarities and differences and proposing a categorization of structural divergences. The analysis and the categorization are supported by a qualitative and quantitative analysis of the results of an annotation projection experiment, in which, in turn, one of the two languages has been used as source language to project annotations into the corresponding parallel sentences. The results of this analysis show clearly that language transfer is asymmetric. An aspect that requires attention when it comes to selecting the source language in transfer learning applications and that needs to be investigated before any scientific claim about cross-lingual NLP is proposed.

</details>


### [7] [TARG: Training-Free Adaptive Retrieval Gating for Efficient RAG](https://arxiv.org/abs/2511.09803)
*Yufeng Wang,Lu wei,Haibin Ling*

Main category: cs.CL

> TARG是一种仅依赖于基础模型生成简短草稿不需上下文的检索门控策略，能够在提升效率及减少计算开销的同时优化检索增强生成的效果。

<details>
  <summary>Details</summary>

**Motivation:** 检索增强生成（RAG）虽然能提升事实准确性，但每次查询都进行检索往往会对质量造成损害，同时增加标记和延迟。为了优化这一过程，提出了TARG方法。

**Method:** 我们提出了无训练适应性检索门控（Training-free Adaptive Retrieval Gating，TARG），这是一项单次决策策略，它基于基础模型生成的无上下文简短草稿来决定是否进行检索。通过草稿前缀的潜在对数（logits），TARG计算出轻量级的不确定性得分：平均标记熵、源自前两位对数差距的边缘信号通过单调联系得到，或者一个小N标记集合之间的方差，并仅在得分超过某个阈值时触发检索。

**Result:** 在NQ-Open、TriviaQA和PopQA数据集上，相比于Always-RAG，TARG在持平或提升EM/F1得分的同时，减少了70-90%的检索需求并降低了端到端延迟。并且与Never-RAG相比，TARG在计算开销方面保持相近。

**Conclusion:** 研究表明，在现代指令调优的LLM下，边缘信号是一个稳定的默认选择，当模型的核心变得更加精确时，熵值会被压缩，而小N方差提供了一个保守且首要考虑预算的替代选项。

**Abstract:** Retrieval-Augmented Generation (RAG) improves factuality but retrieving for every query often hurts quality while inflating tokens and latency. We propose Training-free Adaptive Retrieval Gating (TARG), a single-shot policy that decides when to retrieve using only a short, no-context draft from the base model. From the draft's prefix logits, TARG computes lightweight uncertainty scores: mean token entropy, a margin signal derived from the top-1/top-2 logit gap via a monotone link, or small-N variance across a handful of stochastic prefixes, and triggers retrieval only when the score exceeds a threshold. The gate is model agnostic, adds only tens to hundreds of draft tokens, and requires no additional training or auxiliary heads. On NQ-Open, TriviaQA, and PopQA, TARG consistently shifts the accuracy-efficiency frontier: compared with Always-RAG, TARG matches or improves EM/F1 while reducing retrieval by 70-90% and cutting end-to-end latency, and it remains close to Never-RAG in overhead. A central empirical finding is that under modern instruction-tuned LLMs the margin signal is a robust default (entropy compresses as backbones sharpen), with small-N variance offering a conservative, budget-first alternative. We provide ablations over gate type and prefix length and use a delta-latency view to make budget trade-offs explicit.

</details>


### [8] [Khmer Spellchecking: A Holistic Approach](https://arxiv.org/abs/2511.09812)
*Marry Kong,Rina Buoy,Sovisal Chenda,Nguonly Taing*

Main category: cs.CL

> 本文提出了一种整合高棉语子词分割、NER、G2P转换和语言模型的方法来解决高棉语拼写检查的挑战，并取得了高达94.4%的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的解决方案无法充分解决高棉语拼写检查所面临的挑战，例如词典与词汇分割模型之间的不匹配，高棉语单词的多种书写形式，以及高棉语复合词的形成和识别问题。

**Method:** 本研究通过整合高棉语子词分割、高棉语命名实体识别（NER）、高棉语字符到音素（G2P）转换以及高棉语语言模型来解决高棉语拼写检查的问题。

**Result:** 实验结果显示，所提出的方法达到了迄今为止最先进的高棉语拼写检查准确率，高达94.4%，优于现有的解决方案。

**Conclusion:** 这种方法有效地提高了高棉语拼写检查的准确率，并为将来的工作提供了基准数据集。

**Abstract:** Compared to English and other high-resource languages, spellchecking for Khmer remains an unresolved problem due to several challenges. First, there are misalignments between words in the lexicon and the word segmentation model. Second, a Khmer word can be written in different forms. Third, Khmer compound words are often loosely and easily formed, and these compound words are not always found in the lexicon. Fourth, some proper nouns may be flagged as misspellings due to the absence of a Khmer named-entity recognition (NER) model. Unfortunately, existing solutions do not adequately address these challenges. This paper proposes a holistic approach to the Khmer spellchecking problem by integrating Khmer subword segmentation, Khmer NER, Khmer grapheme-to-phoneme (G2P) conversion, and a Khmer language model to tackle these challenges, identify potential correction candidates, and rank the most suitable candidate. Experimental results show that the proposed approach achieves a state-of-the-art Khmer spellchecking accuracy of up to 94.4%, compared to existing solutions. The benchmark datasets for Khmer spellchecking and NER tasks in this study will be made publicly available.

</details>


### [9] [Improving Graduate Outcomes by Identifying Skills Gaps and Recommending Courses Based on Career Interests](https://arxiv.org/abs/2511.09819)
*Rahul Soni,Basem Suleiman,Sonit Singh*

Main category: cs.CL

> 论文提出了一种利用数据分析技术和机器学习算法来推荐课程的系统，旨在结合行业趋势和需求，为学生提供定制的课程建议。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决为学生选择相关课程的挑战，通过设计和开发课程推荐系统来应对这一挑战。

**Method:** 该研究设计并实现了一个综合算法框架，结合机器学习方法、用户偏好和学术标准来推荐课程。该系统使用数据挖掘和协同过滤技术分析过去的课程和个别职业目标以提供课程推荐。

**Result:** 通过用户反馈的集成，优化和改进了该系统，确保它有效满足目标用户的需求和偏好。

**Conclusion:** 所提出的课程推荐系统可以成为促进终身学习和职业进步的有用工具，有助于填补大学学习和行业期望之间的差距。

**Abstract:** This paper aims to address the challenge of selecting relevant courses for students by proposing the design and development of a course recommendation system. The course recommendation system utilises a combination of data analytics techniques and machine learning algorithms to recommend courses that align with current industry trends and requirements. In order to provide customised suggestions, the study entails the design and implementation of an extensive algorithmic framework that combines machine learning methods, user preferences, and academic criteria. The system employs data mining and collaborative filtering techniques to examine past courses and individual career goals in order to provide course recommendations. Moreover, to improve the accessibility and usefulness of the recommendation system, special attention is given to the development of an easy-to-use front-end interface. The front-end design prioritises visual clarity, interaction, and simplicity through iterative prototyping and user input revisions, guaranteeing a smooth and captivating user experience. We refined and optimised the proposed system by incorporating user feedback, ensuring that it effectively meets the needs and preferences of its target users. The proposed course recommendation system could be a useful tool for students, instructors, and career advisers to use in promoting lifelong learning and professional progression as it fills the gap between university learning and industry expectations. We hope that the proposed course recommendation system will help university students in making data-drive and industry-informed course decisions, in turn, improving graduate outcomes for the university sector.

</details>


### [10] [Answering Students' Questions on Course Forums Using Multiple Chain-of-Thought Reasoning and Finetuning RAG-Enabled LLM](https://arxiv.org/abs/2511.09831)
*Neo Wang,Sonit Singh*

Main category: cs.CL

> 本研究提出了一种基于检索增强生成（RAG）方法的大型语言模型（LLM）问答系统，旨在解决课程论坛中学生问题响应延迟与重复问题频发的问题。

<details>
  <summary>Details</summary>

**Motivation:** 课程论坛对促进学生讨论及解答问题扮演着重要角色，但随着学生数量增加，难免出现延迟响应和重复问题。

**Method:** 研究设计了一个基于开源大型语言模型（LLM）的问答系统，并在其上进行特定课程数据微调。结合本地知识库，运用RAG方法检索相关文档，同时采用多链式思维推理减少LLM的幻觉问题。

**Result:** 实验在HotpotQA数据集上的效果显示，微调后的LLM结合RAG方法在问答任务表现优异。

**Conclusion:** 研究提出的方法显著提高了课程论坛中的问答效率及准确性，解决了学生延迟响应与重复问题的挑战。

**Abstract:** The course forums are increasingly significant and play vital role in facilitating student discussions and answering their questions related to the course. It provides a platform for students to post their questions related to the content and admin issues related to the course. However, there are several challenges due to the increase in the number of students enrolled in the course. The primary challenge is that students' queries cannot be responded immediately and the instructors have to face lots of repetitive questions. To mitigate these issues, we propose a question answering system based on large language model with retrieval augmented generation (RAG) method. This work focuses on designing a question answering system with open source Large Language Model (LLM) and fine-tuning it on the relevant course dataset. To further improve the performance, we use a local knowledge base and applied RAG method to retrieve relevant documents relevant to students' queries, where the local knowledge base contains all the course content. To mitigate the hallucination of LLMs, We also integrate it with multi chain-of-thought reasoning to overcome the challenge of hallucination in LLMs. In this work, we experiment fine-tuned LLM with RAG method on the HotpotQA dataset. The experimental results demonstrate that the fine-tuned LLM with RAG method has a strong performance on question answering task.

</details>


### [11] [TermGPT: Multi-Level Contrastive Fine-Tuning for Terminology Adaptation in Legal and Financial Domain](https://arxiv.org/abs/2511.09854)
*Yidan Sun,Mengying Zhu,Feiyue Chen,Yangyang Wu,Xiaolei Dan,Mengyuan Yang,Xiaolin Zheng,Shenglin Ben*

Main category: cs.CL

> 我们提出TermGPT，一种多级对比微调框架，用以解决大规模语言模型的各向同性问题，特别是在法律和金融领域中的术语区分问题。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型（LLMs）的嵌入空间经常遭受各向同性问题的影响，这会导致在法律和金融环境中特定术语的区分度变差，这对法律判断预测和金融风险分析等下游任务产生了严重的限制。

**Method:** 我们提出了一种多级对比微调框架TermGPT，用于术语适应。首先，我们构建了一个句子图来捕捉语义和结构关系，并基于上下文和拓扑线索生成语义一致但具有区分性的正负样本。然后，我们设计了一种在句子和词汇级别上的多级对比学习方法，增强了全局上下文理解和细粒度术语区分。

**Result:** 实验表明，TermGPT在金融和法律领域的术语区分任务中优于现有的基线模型。

**Conclusion:** TermGPT通过多级对比学习增强了术语在特定领域的区分度，这对于提高下游任务的性能至关重要。

**Abstract:** Large language models (LLMs) have demonstrated impressive performance in text generation tasks; however, their embedding spaces often suffer from the isotropy problem, resulting in poor discrimination of domain-specific terminology, particularly in legal and financial contexts. This weakness in terminology-level representation can severely hinder downstream tasks such as legal judgment prediction or financial risk analysis, where subtle semantic distinctions are critical. To address this problem, we propose TermGPT, a multi-level contrastive fine-tuning framework designed for terminology adaptation. We first construct a sentence graph to capture semantic and structural relations, and generate semantically consistent yet discriminative positive and negative samples based on contextual and topological cues. We then devise a multi-level contrastive learning approach at both the sentence and token levels, enhancing global contextual understanding and fine-grained terminology discrimination. To support robust evaluation, we construct the first financial terminology dataset derived from official regulatory documents. Experiments show that TermGPT outperforms existing baselines in term discrimination tasks within the finance and legal domains.

</details>


### [12] [In-Token Rationality Optimization: Towards Accurate and Concise LLM Reasoning via Self-Feedback](https://arxiv.org/abs/2511.09865)
*Mingye Zhu,Yi Liu,Zheren Fu,Quan Wang,Yongdong Zhang*

Main category: cs.CL

> 提出InTRO框架，改进大语言模型链式思维推理，提高准确性和简洁性，实现跨领域任务迁移。

<details>
  <summary>Details</summary>

**Motivation:** 解决监督微调在单一“正确”逻辑上的过度惩罚问题以及强化学习因奖赏分配困难和计算成本过高而导致的推理任务训练挑战。

**Method:** InTRO (In-Token Rationality Optimization)框架，通过token级别的探索和自我反馈，实现了准确且简洁的推理。它利用校正因子—生成策略与其答案条件化对应策略之间的信息差异估计的token级重要权重，来进行信息量大的下一个token的选择。

**Result:** 在六个数学推理基准测试中，InTRO始终优于其他基线模型，将解决方案的准确性提高了最多20%。其推理链也更为简洁，减少了冗长的表述，并且支持跨领域迁移，成功适应数学以外的推理任务。

**Conclusion:** InTRO框架有效解决了大型语言模型在链式思维推理中的挑战，提高了推理质量和简洁性，并证明了其具备跨领域的泛化能力。

**Abstract:** Training Large Language Models (LLMs) for chain-of-thought reasoning presents a significant challenge: supervised fine-tuning on a single "golden" rationale hurts generalization as it penalizes equally valid alternatives, whereas reinforcement learning with verifiable rewards struggles with credit assignment and prohibitive computational cost. To tackle these limitations, we introduce InTRO (In-Token Rationality Optimization), a new framework that enables both token-level exploration and self-feedback for accurate and concise reasoning. Instead of directly optimizing an intractable objective over all valid reasoning paths, InTRO leverages correction factors-token-wise importance weights estimated by the information discrepancy between the generative policy and its answer-conditioned counterpart, for informative next token selection. This approach allows the model to perform token-level exploration and receive self-generated feedback within a single forward pass, ultimately encouraging accurate and concise rationales. Across six math-reasoning benchmarks, InTRO consistently outperforms other baselines, raising solution accuracy by up to 20% relative to the base model. Its chains of thought are also notably more concise, exhibiting reduced verbosity. Beyond this, InTRO enables cross-domain transfer, successfully adapting to out-of-domain reasoning tasks that extend beyond the realm of mathematics, demonstrating robust generalization.

</details>


### [13] [HierRouter: Coordinated Routing of Specialized Large Language Models via Reinforcement Learning](https://arxiv.org/abs/2511.09873)
*Nikunj Gupta,Bill Guo,Rajgopal Kannan,Viktor K. Prasanna*

Main category: cs.CL

> 本文提出了HierRouter，一种通过动态组合轻量级语言模型来提高性能并降低成本的分层路由方法。实验表明，与单独使用LLMs相比，HierRouter在质量上提升了2.4倍，同时额外开销极低。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在许多任务中表现出最先进的性能，但它们带来了高昂的计算和内存成本，限制了它们在资源受限或实时环境中的部署。为了应对这一挑战，作者提出了HierRouter。

**Method:** 本文提出了HierRouter，这是一种分层路由方法，它将推断管道动态地从一组专业的轻量级语言模型池中组装起来。该方法被表述为一个有限时域的马尔可夫决策过程（MDP），并通过使用基于PPO的强化学习代理来训练，该代理可以在多跳推理的每个阶段迭代地选择调用哪些模型。代理根据不断演变的上下文和累计成本做出上下文感知的路由决策。

**Result:** 实验结果表明，在六个基准测试中，包括问答、代码生成和数学推理，与单独使用单个模型相比，HierRouter将答案质量提高了高达2.4倍，同时平均仅产生最小的额外推理成本。

**Conclusion:** 这些结果表明，分层路由方法在成本效益和高性能的LLM推理方面显示出巨大的潜力。

**Abstract:** Large Language Models (LLMs) deliver state-of-the-art performance across many tasks but impose high computational and memory costs, limiting their deployment in resource-constrained or real-time settings. To address this, we propose HierRouter, a hierarchical routing approach that dynamically assembles inference pipelines from a pool of specialized, lightweight language models. Formulated as a finite-horizon Markov Decision Process (MDP), our approach trains a Proximal Policy Optimization (PPO)-based reinforcement learning agent to iteratively select which models to invoke at each stage of multi-hop inference. The agent conditions on the evolving context and accumulated cost to make context-aware routing decisions. Experiments with three open-source candidate LLMs across six benchmarks, including QA, code generation, and mathematical reasoning, show that HierRouter improves response quality by up to 2.4x compared to using individual models independently, while incurring only a minimal additional inference cost on average. These results highlight the promise of hierarchical routing for cost-efficient, high-performance LLM inference. All codes can be found here https://github.com/ Nikunj-Gupta/hierouter.

</details>


### [14] [EnchTable: Unified Safety Alignment Transfer in Fine-tuned Large Language Models](https://arxiv.org/abs/2511.09880)
*Jialin Wu,Kecen Li,Zhicong Huang,Xinfeng Li,Xiaofeng Wang,Cheng Hong*

Main category: cs.CL

> EnchTable is a framework that maintains safety alignment in fine-tuned large language models (LLMs) without extensive retraining, improving ethical guidelines compliance and reducing harmful output risks.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of safety degradation in LLMs after fine-tuning, while ensuring that these models remain effective in specific task domains.

**Method:** EnchTable uses a Neural Tangent Kernel (NTK)-based safety vector distillation technique to decouple safety constraints from task-specific reasoning, and interference-aware merging for balancing safety with utility.

**Result:** EnchTable significantly reduces unsafe output, enhances utility scores, and showcases resilience against jailbreaking attacks compared to vendor safety models in diverse application scenarios.

**Conclusion:** EnchTable achieves a balance between safe and useful outputs in various LLM applications without compromising performance, and can be efficiently integrated into existing deployment pipelines.

**Abstract:** Many machine learning models are fine-tuned from large language models (LLMs) to achieve high performance in specialized domains like code generation, biomedical analysis, and mathematical problem solving. However, this fine-tuning process often introduces a critical vulnerability: the systematic degradation of safety alignment, undermining ethical guidelines and increasing the risk of harmful outputs. Addressing this challenge, we introduce EnchTable, a novel framework designed to transfer and maintain safety alignment in downstream LLMs without requiring extensive retraining. EnchTable leverages a Neural Tangent Kernel (NTK)-based safety vector distillation method to decouple safety constraints from task-specific reasoning, ensuring compatibility across diverse model architectures and sizes. Additionally, our interference-aware merging technique effectively balances safety and utility, minimizing performance compromises across various task domains. We implemented a fully functional prototype of EnchTable on three different task domains and three distinct LLM architectures, and evaluated its performance through extensive experiments on eleven diverse datasets, assessing both utility and model safety. Our evaluations include LLMs from different vendors, demonstrating EnchTable's generalization capability. Furthermore, EnchTable exhibits robust resistance to static and dynamic jailbreaking attacks, outperforming vendor-released safety models in mitigating adversarial prompts. Comparative analyses with six parameter modification methods and two inference-time alignment baselines reveal that EnchTable achieves a significantly lower unsafe rate, higher utility score, and universal applicability across different task domains. Additionally, we validate EnchTable can be seamlessly integrated into various deployment pipelines without significant overhead.

</details>


### [15] [HI-TransPA: Hearing Impairments Translation Personal Assistant](https://arxiv.org/abs/2511.09915)
*Zhiming Ma,Shiyu Gan,Junhao Zhao,Xianming Li,Qingyun Pan,Peidong Wang,Mingjun Pan,Yuhao Mo,Jiajie Cheng,Chengxin Chen,Zhonglun Cao,Chonghan Liu,Shi Cheng*

Main category: cs.CL

> 通过将Omni-Model应用于辅助技术，开发了HI-TransPA，这是一种结合高帧率唇部动态和模糊语音的音频-视觉翻译和对话助手。实验结果显示其性能领先。

<details>
  <summary>Details</summary>

**Motivation:** 为了提供给听力障碍人士一种统一且灵活的日常沟通解决方案。

**Method:** 我们通过将Omni-Model范式引入辅助技术，开发了HI-TransPA，这是一种基于指令的音频-视觉个人助手。该模型融合了模糊语音和高帧率唇部动态，实现了单一多模态框架内的翻译和对话。我们建立了一个全面的预处理和整理管道，用于检测面部特征点、隔离和稳定唇部区域，并量化评估多模态样本的质量。此外，我们还采用SigLIP编码器结合Unified 3D-Resampler，有效编码高帧率唇部动作。

**Result:** 实验表明，基于我们建立的HI-Dialogue数据集，HI-TransPA在文字准确性和语义保真性上都达到了最先进的性能。

**Conclusion:** 本研究为将Omni-Model应用于辅助通讯技术奠定了基础，提供了一个端到端的建模框架和重要的处理工具，为未来的研究奠定了基础。

**Abstract:** To provide a unified and flexible solution for daily communication among hearing-impaired individuals, we introduce the Omni-Model paradigm into assistive technology and present HI-TransPA, an instruction-driven audio-visual personal assistant. The model fuses indistinct speech with high-frame-rate lip dynamics, enabling both translation and dialogue within a single multimodal framework. To tackle the challenges of noisy and heterogeneous raw data and the limited adaptability of existing Omni-Models to hearing-impaired speech, we construct a comprehensive preprocessing and curation pipeline that detects facial landmarks, isolates and stabilizes the lip region, and quantitatively assesses multimodal sample quality. These quality scores guide a curriculum learning strategy that first trains on clean, high-confidence samples and progressively incorporates harder cases to strengthen model robustness. We further adopt a SigLIP encoder combined with a Unified 3D-Resampler to efficiently encode high-frame-rate lip motion. Experiments on our purpose-built HI-Dialogue dataset show that HI-TransPA achieves state-of-the-art performance in both literal accuracy and semantic fidelity. This work establishes a foundation for applying Omni-Models to assistive communication technology, providing an end-to-end modeling framework and essential processing tools for future research.

</details>


### [16] [MINDS: A Cross-cultural Dialogue Corpus for Social Norm Classification and Adherence Detection](https://arxiv.org/abs/2511.09918)
*Pritish Sahu,Anirudh Som,Dimitra Vergyri,Ajay Divakaran*

Main category: cs.CL

> A framework named Norm-RAG is developed for social norm inference in multi-turn dialogues, enhancing the performance of culturally adaptive and socially intelligent dialogue systems.

<details>
  <summary>Details</summary>

**Motivation:** Prior works have limitations in capturing nuanced, multi-turn nature of real-world conversations. The new method aims to address this gap by enabling interpretable and context-aware reasoning about norm adherence and violation across languages.

**Method:** Norm-RAG, a retrieval-augmented, agentic framework, is introduced for nuanced social norm inference in multi-turn dialogues. It models utterance-level attributes and grounds them in structured normative documentation using a novel Semantic Chunking approach.

**Result:** Norm-RAG improves norm detection and generalization in culturally adaptive and socially intelligent dialogue systems.

**Conclusion:** The introduction of Norm-RAG and MINDS dataset demonstrates significant improvement in norm detection and generalization, showing potential for better understanding and application of social norms in multilingual dialogues.

**Abstract:** Social norms are implicit, culturally grounded expectations that guide interpersonal communication. Unlike factual commonsense, norm reasoning is subjective, context-dependent, and varies across cultures, posing challenges for computational models. Prior works provide valuable normative annotations but mostly target isolated utterances or synthetic dialogues, limiting their ability to capture the fluid, multi-turn nature of real-world conversations. In this work, we present Norm-RAG, a retrieval-augmented, agentic framework for nuanced social norm inference in multi-turn dialogues. Norm-RAG models utterance-level attributes including communicative intent, speaker roles, interpersonal framing, and linguistic cues and grounds them in structured normative documentation retrieved via a novel Semantic Chunking approach. This enables interpretable and context-aware reasoning about norm adherence and violation across multilingual dialogues. We further introduce MINDS (Multilingual Interactions with Norm-Driven Speech), a bilingual dataset comprising 31 multi-turn Mandarin-English and Spanish-English conversations. Each turn is annotated for norm category and adherence status using multi-annotator consensus, reflecting cross-cultural and realistic norm expression. Our experiments show that Norm-RAG improves norm detection and generalization, demonstrates improved performance for culturally adaptive and socially intelligent dialogue systems.

</details>


### [17] [Leveraging Large Language Models for Identifying Knowledge Components](https://arxiv.org/abs/2511.09935)
*Canwen Wang,Jionghao Lin,Kenneth R. Koedinger*

Main category: cs.CL

> The study explores the automation of Knowledge Component identification using scaled LLM prompting strategies, develops a semantic merging technique to reduce redundancy, and demonstrates its effectiveness in improving model performance.

<details>
  <summary>Details</summary>

**Motivation:** To overcome the limitations in manual KC identification and redundant KC labels generated by LLMs, the study aims to scale the LLM prompting strategy and reduce the number of KCs through semantic merging.

**Method:** The study uses a 'simulated textbook' LLM prompting strategy with GPT-4o-mini on 646 multiple-choice questions and evaluates a new method for merging semantically similar KCs based on cosine similarity.

**Result:** The initial approach had poor performance compared to an expert-designed model and produced many KCs. However, by using a cosine similarity threshold of 0.8, the number of KCs was reduced to 428 and the RMSE was improved to 0.4259.

**Conclusion:** Scaling LLM generation alone for KC identification is not effective, but combining it with semantic merging techniques shows promise for automating and refining KC identification.

**Abstract:** Knowledge Components (KCs) are foundational to adaptive learning systems, but their manual identification by domain experts is a significant bottleneck. While Large Language Models (LLMs) offer a promising avenue for automating this process, prior research has been limited to small datasets and has been shown to produce superfluous, redundant KC labels. This study addresses these limitations by first scaling a "simulated textbook" LLM prompting strategy (using GPT-4o-mini) to a larger dataset of 646 multiple-choice questions. We found that this initial automated approach performed significantly worse than an expert-designed KC model (RMSE 0.4285 vs. 0.4206) and generated an excessive number of KCs (569 vs. 101). To address the issue of redundancy, we proposed and evaluated a novel method for merging semantically similar KC labels based on their cosine similarity. This merging strategy significantly improved the model's performance; a model using a cosine similarity threshold of 0.8 achieved the best result, reducing the KC count to 428 and improving the RMSE to 0.4259. This demonstrates that while scaled LLM generation alone is insufficient, combining it with a semantic merging technique offers a viable path toward automating and refining KC identification.

</details>


### [18] [REAP: Enhancing RAG with Recursive Evaluation and Adaptive Planning for Multi-Hop Question Answering](https://arxiv.org/abs/2511.09966)
*Yijie Zhu,Haojie Zhou,Wanting Hong,Tailin Liu,Ning Wang*

Main category: cs.CL

> The paper proposes REAP, a method for improving multi-hop reasoning in LLMs using SP and FE modules, which enhances global planning and utilizes retrieved content to improve reasoning accuracy.

<details>
  <summary>Details</summary>

**Motivation:** To address the shortcomings of existing RAG methods in multi-hop reasoning tasks, specifically the lack of global planning and the underutilization of retrieved content which can lead to reasoning obstacles.

**Method:** Recursive Evaluation and Adaptive Planning (REAP) is proposed, which includes the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains global planning and evaluates task states based on FE's outcomes for dynamic optimization. FE conducts a detailed analysis of retrieved content to extract reliable answers and clues.

**Result:** Experiments on various multi-hop datasets show that REAP outperforms existing RAG methods, proving its effectiveness for complex reasoning tasks.

**Conclusion:** REAP effectively mitigates the limitations of current RAG methods in multi-hop reasoning, providing a robust solution that performs well across different tasks and datasets.

**Abstract:** Retrieval-augmented generation (RAG) has been extensively employed to mitigate hallucinations in large language models (LLMs). However, existing methods for multi-hop reasoning tasks often lack global planning, increasing the risk of falling into local reasoning impasses. Insufficient exploitation of retrieved content and the neglect of latent clues fail to ensure the accuracy of reasoning outcomes. To overcome these limitations, we propose Recursive Evaluation and Adaptive Planning (REAP), whose core idea is to explicitly maintain structured sub-tasks and facts related to the current task through the Sub-task Planner (SP) and Fact Extractor (FE) modules. SP maintains a global perspective, guiding the overall reasoning direction and evaluating the task state based on the outcomes of FE, enabling dynamic optimization of the task-solving trajectory. FE performs fine-grained analysis over retrieved content to extract reliable answers and clues. These two modules incrementally enrich a logically coherent representation of global knowledge, enhancing the reliability and the traceability of the reasoning process. Furthermore, we propose a unified task paradigm design that enables effective multi-task fine-tuning, significantly enhancing SP's performance on complex, data-scarce tasks. We conduct extensive experiments on multiple public multi-hop datasets, and the results demonstrate that our method significantly outperforms existing RAG methods in both in-domain and out-of-domain settings, validating its effectiveness in complex multi-hop reasoning tasks.

</details>


### [19] [NumPert: Numerical Perturbations to Probe Language Models for Veracity Prediction](https://arxiv.org/abs/2511.09971)
*Peter Røysland Aarnes,Vinay Setty*

Main category: cs.CL

> 研究发现大型语言模型在处理数值性推理任务时存在较大局限，即使顶级系统在特定扰动下也会出现高达62%的准确性下降。研究还发现，增加上下文长度通常会降低精度，但如果增加的上下文包括了扰动后的演示，大多数模型的精度能显著恢复。这些结果表明，对于目前的语言模型来说，数值性事实验证的健壮性仍然是一个开放的问题。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在知识密集型任务上表现强劲，但它们在数值推理方面的表现欠佳。因此，该研究旨在通过可控扰动（包括标签翻转探针）系统性地评估这些模型在数值性命题验证上的准确性，以测试它们的鲁棒性。

**Method:** 研究人员对最先进的模型进行了系统评估，利用受控perturbations（包括标签翻转探针）来测试它们在数值性命题验证上的准确性。

**Result:** 研究结果揭示，即使顶级的专有系统在某些扰动下也会出现最高达62%的准确性下降。没有一种模型能够在所有条件下做到坚固。此外，研究人员还发现增加上下文长度通常会降低精度，但如果增加的上下文包含了扰动后的演示，大多数模型的精度会显著地恢复。

**Conclusion:** 该研究强调了现有语言模型在数值性事实验证方面的关键局限，并指出对于当前的语言模型而言，验证的健壮性还是一个悬而未决的挑战。

**Abstract:** Large language models show strong performance on knowledge intensive tasks such as fact-checking and question answering, yet they often struggle with numerical reasoning. We present a systematic evaluation of state-of-the-art models for veracity prediction on numerical claims and evidence pairs using controlled perturbations, including label-flipping probes, to test robustness. Our results indicate that even leading proprietary systems experience accuracy drops of up to 62\% under certain perturbations. No model proves to be robust across all conditions. We further find that increasing context length generally reduces accuracy, but when extended context is enriched with perturbed demonstrations, most models substantially recover. These findings highlight critical limitations in numerical fact-checking and suggest that robustness remains an open challenge for current language models.

</details>


### [20] [Modeling Uncertainty Trends for Timely Retrieval in Dynamic RAG](https://arxiv.org/abs/2511.09980)
*Bo Li,Tian Tian,Zhenghua Xu,Hao Cheng,Shikun Zhang,Wei Ye*

Main category: cs.CL

> 本文提出了一种新的方法Entropy-Trend Constraint (ETC)，用于动态优化大型语言模型的检索时机，实验结果显示出优于现有方法的表现。

<details>
  <summary>Details</summary>

**Motivation:** 动态检索增强生成方法允许大型语言模型根据需要获取外部知识，但要确定最佳检索时机仍然是一个挑战。现有方法通常基于低置信度的词汇级别回放检索，可能导致错误传播后才进行干预。

**Method:** 我们引入了Entropy-Trend Constraint (ETC)，这是一种无需训练的方法，通过对熵序列的一阶和二阶差分建模来检测不确定性趋势，从而确定最佳检索时机。这使得检索时机更早更准确。

**Result:** 实验结果表明，ETC在六项问答基准测试中和三种大型语言模型框架下始终优于强大的基线方法，并降低了检索频率。特别是在特定领域中，ETC表现出了强大的泛化能力。消融研究和定性分析进一步确认了基于趋势的不确定性建模能够更有效地确定检索时机。

**Conclusion:** ETC是一个即插即用的，模型不可知的方法，可以轻松集成到现有的解码管道中。本文提供了一种新的方法来优化动态检索增强生成的检索时机，并在多种不同环境下验证了其有效性。

**Abstract:** Dynamic retrieval-augmented generation (RAG) allows large language models (LLMs) to fetch external knowledge on demand, offering greater adaptability than static RAG. A central challenge in this setting lies in determining the optimal timing for retrieval. Existing methods often trigger retrieval based on low token-level confidence, which may lead to delayed intervention after errors have already propagated. We introduce Entropy-Trend Constraint (ETC), a training-free method that determines optimal retrieval timing by modeling the dynamics of token-level uncertainty. Specifically, ETC utilizes first- and second-order differences of the entropy sequence to detect emerging uncertainty trends, enabling earlier and more precise retrieval. Experiments on six QA benchmarks with three LLM backbones demonstrate that ETC consistently outperforms strong baselines while reducing retrieval frequency. ETC is particularly effective in domain-specific scenarios, exhibiting robust generalization capabilities. Ablation studies and qualitative analyses further confirm that trend-aware uncertainty modeling yields more effective retrieval timing. The method is plug-and-play, model-agnostic, and readily integrable into existing decoding pipelines. Implementation code is included in the supplementary materials.

</details>


### [21] [Language Drift in Multilingual Retrieval-Augmented Generation: Characterization and Decoding-Time Mitigation](https://arxiv.org/abs/2511.09984)
*Bo Li,Zhenghua Xu,Rui Xie*

Main category: cs.CL

> 本研究针对多语言检索增强生成(RAG)过程中的语言漂移现象，提出了Soft Constrained Decoding (SCD)策略以缓解这一问题。实验表明SCD能够有效提高语言对齐性能，并在不同语言和模型上具有良好的泛化性能。

<details>
  <summary>Details</summary>

**Motivation:** 研究多语言检索增强生成(RAG)过程中，当检索的证据文档语言与用户查询和上下文示例的语言不同时，模型常会出现语言漂移现象，生成意外语言的响应。特别是在推理密集型解码（如链式思维生成）中，由于中间步骤引入了更多的语言不稳定因素，这一现象更为明显。

**Method:** 研究中提出了Soft Constrained Decoding (SCD)，这是一种轻量级、无需训练的解码策略，通过惩罚非目标语言的单词来温和地引导生成朝向目标语言。SCD是模型不可知的，可以应用于任何生成算法，无需修改架构或需要额外的数据。

**Result:** 研究揭示了语言漂移不是由于理解故障，而是由于解码器级别的崩溃，其中主导的单词分布和高频的英语模式支配了预期生成语言。进一步的观察表明，在跨语言条件下，英语作为一种语义吸引子出现了，既是最强的干扰源也是最常见的回退语言。

**Conclusion:** 实验结果表明，在三个多语言数据集和多个类型学多样性语言上，SCD一致改善了语言对齐和任务表现，提供了一种有效且泛化的解决方案。

**Abstract:** Multilingual Retrieval-Augmented Generation (RAG) enables large language models (LLMs) to perform knowledge-intensive tasks in multilingual settings by leveraging retrieved documents as external evidence. However, when the retrieved evidence differs in language from the user query and in-context exemplars, the model often exhibits language drift by generating responses in an unintended language. This phenomenon is especially pronounced during reasoning-intensive decoding, such as Chain-of-Thought (CoT) generation, where intermediate steps introduce further language instability. In this paper, we systematically study output language drift in multilingual RAG across multiple datasets, languages, and LLM backbones. Our controlled experiments reveal that the drift results not from comprehension failure but from decoder-level collapse, where dominant token distributions and high-frequency English patterns dominate the intended generation language. We further observe that English serves as a semantic attractor under cross-lingual conditions, emerging as both the strongest interference source and the most frequent fallback language.
  To mitigate this, we propose Soft Constrained Decoding (SCD), a lightweight, training-free decoding strategy that gently steers generation toward the target language by penalizing non-target-language tokens. SCD is model-agnostic and can be applied to any generation algorithm without modifying the architecture or requiring additional data. Experiments across three multilingual datasets and multiple typologically diverse languages show that SCD consistently improves language alignment and task performance, providing an effective and generalizable solution in multilingual RAG.

</details>


### [22] [FinNuE: Exposing the Risks of Using BERTScore for Numerical Semantic Evaluation in Finance](https://arxiv.org/abs/2511.09997)
*Yu-Shiang Huang,Yun-Yu Lee,Tzu-Hsin Chou,Che Lin,Chuan-Ju Wang*

Main category: cs.CL

> 我们引入了FinNuE，一个通过数值扰动构建的诊断数据集，展示了BERTScore在金融文本相似度评估中的限制，特别是在数值变化上的低敏感度。

<details>
  <summary>Details</summary>

**Motivation:** 我们的动机在于识别并强调BERTScore对数值变化低敏感度的关键限制，这是金融领域中的一个重大弱点，因为在金融中数值精度直接关系到文本的意义。

**Method:** 我们构建了一个名为FinNuE的诊断数据集，该数据集通过对收益电话会议、监管文件、社交媒体和新闻文章中数值进行受控扰动来建立。通过FinNuE数据集，我们展示了BERTScore在区分语义上关键的数值差异方面的失败，经常为金融上差异显著的文本对分配高相似度分数。

**Result:** 结果显示，BERTScore无法区分金融文本中语义上关键的数值差异，这对金融领域的自然语言处理评估框架提出了挑战。

**Conclusion:** 我们的研究揭示了基于嵌入的度量方法在金融文本评估中的根本限制，并促使对金融自然语言处理提出数值感知的评估框架。

**Abstract:** BERTScore has become a widely adopted metric for evaluating semantic similarity between natural language sentences. However, we identify a critical limitation: BERTScore exhibits low sensitivity to numerical variation, a significant weakness in finance where numerical precision directly affects meaning (e.g., distinguishing a 2% gain from a 20% loss). We introduce FinNuE, a diagnostic dataset constructed with controlled numerical perturbations across earnings calls, regulatory filings, social media, and news articles. Using FinNuE, demonstrate that BERTScore fails to distinguish semantically critical numerical differences, often assigning high similarity scores to financially divergent text pairs. Our findings reveal fundamental limitations of embedding-based metrics for finance and motivate numerically-aware evaluation frameworks for financial NLP.

</details>


### [23] [PustakAI: Curriculum-Aligned and Interactive Textbooks Using Large Language Models](https://arxiv.org/abs/2511.10002)
*Shivam Sharma,Riya Naik,Tejas Gawas,Heramb Patil,Kunal Korgaonkar*

Main category: cs.CL

> 本文介绍了PustakAI框架，用于设计和评估与印度NCERT课程相关的新型问答数据集NCERT-QA。研究还分析了开源自有的大型语言模型和高端语言模型在正式教育系统中的优缺点。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型在理解与生成人类语言方面的突出表现，它们在教育领域的潜力逐渐显现。尤其在教育资源有限的地区，这种潜力更加明显。然而，将这些模型灵活应用到特定课程内容中，例如印度的NCERT课程，面临着准确性、一致性以及教育相关性等方面的挑战。

**Method:** 研究团队设计并评估了与英语和科学课程科目对齐的NCERT-QA问答数据集。将提取的问答对分类为事实型、推断型和其他类型（评估和推理型）。研究使用的评估技术包括元提示、少样本学习提示和CoT风格提示。

**Result:** 通过对不同类型的语言模型使用多种评估指标进行比较，研究发现某些提示技术更有效地满足课程结构和需求。此外，研究还探讨了开源与高端大型语言模型在教育领域的适用性、优势和局限。

**Conclusion:** 研究表明，PustakAI框架和NCERT-QA数据集为提升印度教育资源不足地区的学生学习体验提供了潜在的解决方案。研究还强调了在正式教育系统中使用大型语言模型的优缺点。

**Abstract:** Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and generating human-like content. This has revolutionized various sectors such as healthcare, software development, and education. In education, LLMs offer potential for personalized and interactive learning experiences, especially in regions with limited teaching resources. However, adapting these models effectively to curriculum-specific content, such as the National Council of Educational Research and Training (NCERT) syllabus in India, presents unique challenges in terms of accuracy, alignment, and pedagogical relevance. In this paper, we present the framework "PustakAI"\footnote{Pustak means `book' in many Indian languages.} for the design and evaluation of a novel question-answering dataset "NCERT-QA" aligned with the NCERT curriculum for English and Science subjects of grades 6 to 8. We classify the curated QA pairs as Factoid, Inferential, and Others (evaluative and reasoning). We evaluate the dataset with various prompting techniques, such as meta-prompt, few-shot, and CoT-style prompting, using diverse evaluation metrics to understand which approach aligns more efficiently with the structure and demands of the curriculum. Along with the usability of the dataset, we analyze the strengths and limitations of current open-source LLMs (Gemma3:1b, Llama3.2:3b, and Nemotron-mini:4b) and high-end LLMs (Llama-4-Scout-17B and Deepseek-r1-70B) as AI-based learning tools in formal education systems.

</details>


### [24] [ScaleFormer: Span Representation Cumulation for Long-Context Transformer](https://arxiv.org/abs/2511.10029)
*Jiangshu Du,Wenpeng Yin,Philip Yu*

Main category: cs.CL

> ScaleFormer是一种高效的即插即用框架，用于处理长序列任务，它可以提高现有预训练模型的性能，同时保持线性复杂度和不需要额外的数据检索机制，且在长文档摘要任务中具有竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 传统自注意力机制的二次复杂度限制了Transformer模型在长序列任务中的应用，尽管存在高效的Transformer变体，但它们通常需要架构改动和耗时的从头预训练。ScaleFormer旨在不改变架构的情况下适应预训练的编解码模型来处理长序列。

**Method:** ScaleFormer提出了一种简单的即插即用框架，通过将长输入分割成重叠的块，并生成压缩的上下文感知表示供解码器使用。核心是一个新颖的、无参数的融合机制，为每个块的表示提供结构感知的位置信息，通过用来自所有先前和后继块的累积上下文向量丰富每个块边界表示来实现。

**Result:** 实验结果表明，ScaleFormer在长文档摘要任务上具有高度竞争力，往往优于最先进的方法，并且不需要架构修改或外部检索机制。

**Conclusion:** 通过一个新颖的、无参数的融合机制，ScaleFormer能够有效地处理长序列问题，并保持线性复杂度，同时避免了昂贵的从头预训练过程。这种方法使得现有的预训练模型能够更有效地处理长文本。

**Abstract:** The quadratic complexity of standard self-attention severely limits the application of Transformer-based models to long-context tasks. While efficient Transformer variants exist, they often require architectural changes and costly pre-training from scratch. To circumvent this, we propose ScaleFormer(Span Representation Cumulation for Long-Context Transformer) - a simple and effective plug-and-play framework that adapts off-the-shelf pre-trained encoder-decoder models to process long sequences without requiring architectural modifications. Our approach segments long inputs into overlapping chunks and generates a compressed, context-aware representation for the decoder. The core of our method is a novel, parameter-free fusion mechanism that endows each chunk's representation with structural awareness of its position within the document. It achieves this by enriching each chunk's boundary representations with cumulative context vectors from all preceding and succeeding chunks. This strategy provides the model with a strong signal of the document's narrative flow, achieves linear complexity, and enables pre-trained models to reason effectively over long-form text. Experiments on long-document summarization show that our method is highly competitive with and often outperforms state-of-the-art approaches without requiring architectural modifications or external retrieval mechanisms.

</details>


### [25] [Do Language Models Associate Sound with Meaning? A Multimodal Study of Sound Symbolism](https://arxiv.org/abs/2511.10045)
*Jinhong Jeong,Sunghyun Lee,Jaeyoung Lee,Seonah Han,Youngjae Yu*

Main category: cs.CL

> 研究了多模态大语言模型在处理文本和音频形式输入时的音素象征现象，证明了模型与现有语言学研究的一致性。

<details>
  <summary>Details</summary>

**Motivation:** 探讨多模态大语言模型（MLLMs）如何解释人类语言中的听觉信息，特别是音素与意义之间非任意关联的音素象征主义。

**Method:** 使用了LEX-ICON数据集，该数据集包含四种自然语言（英语、法语、日语和韩语）的8,052个词语和2,930个系统构建的伪词，并在文本和音频模式中都标注了语义特征。通过测量音位级别的注意力分数来观察模型各层的信息处理过程。

**Result:** 发现MLLMs的音素直觉与多维度的现有语言学研究一致，并突出显示了模型对象征性音素的关注。

**Conclusion:** 这些结果连接了人工智能和认知语言学领域，进行了关于MLLMs的可解释性的首次大规模定量分析。

**Abstract:** Sound symbolism is a linguistic concept that refers to non-arbitrary associations between phonetic forms and their meanings. We suggest that this can be a compelling probe into how Multimodal Large Language Models (MLLMs) interpret auditory information in human languages. We investigate MLLMs' performance on phonetic iconicity across textual (orthographic and IPA) and auditory forms of inputs with up to 25 semantic dimensions (e.g., sharp vs. round), observing models' layer-wise information processing by measuring phoneme-level attention fraction scores. To this end, we present LEX-ICON, an extensive mimetic word dataset consisting of 8,052 words from four natural languages (English, French, Japanese, and Korean) and 2,930 systematically constructed pseudo-words, annotated with semantic features applied across both text and audio modalities. Our key findings demonstrate (1) MLLMs' phonetic intuitions that align with existing linguistic research across multiple semantic dimensions and (2) phonosemantic attention patterns that highlight models' focus on iconic phonemes. These results bridge domains of artificial intelligence and cognitive linguistics, providing the first large-scale, quantitative analyses of phonetic iconicity in terms of MLLMs' interpretability.

</details>


### [26] [GraphIF: Enhancing Multi-Turn Instruction Following for Large Language Models with Relation Graph Prompt](https://arxiv.org/abs/2511.10051)
*Zhenhe Li,Can Lin,Ling Zheng,Wen-Da Wei,Junli Liang,Qi Song*

Main category: cs.CL

> GraphIF 是一种新的框架，通过将多轮对话建模为图结构并使用图提示来提高大语言模型的多轮指令跟随能力，在两个长多轮对话数据集上取得显著效果。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决现有方法在多轮指令跟随中的不足，这些方法主要依赖大规模多轮对话数据的收集或生成来微调大语言模型，但未能充分考虑多轮指令跟随的特性。通过图结构建模对话关系，可以更好地处理多轮对话中的复杂长距离约束。

**Method:** GraphIF 是一个即插即用的框架，将多轮对话建模为有向关系图，并通过图提示增强大语言模型的指令跟随能力。该框架包括三个关键组件：基于代理的关系提取模块、关系图提示生成模块和响应重写模块。

**Result:** 实验结果表明，GraphIF 可以无缝集成到经过指令调优的大语言模型中，并在所有四个多轮指令跟随评估指标上带来显著改进。

**Conclusion:** GraphIF 框架通过图结构建模多轮对话，有效提高了大语言模型在多轮指令跟随任务上的性能。

**Abstract:** Multi-turn instruction following is essential for building intelligent conversational systems that can consistently adhere to instructions across dialogue turns. However, existing approaches to enhancing multi-turn instruction following primarily rely on collecting or generating large-scale multi-turn dialogue datasets to fine-tune large language models (LLMs), which treat each response generation as an isolated task and fail to explicitly incorporate multi-turn instruction following into the optimization objectives. As a result, instruction-tuned LLMs often struggle with complex long-distance constraints. In multi-turn dialogues, relational constraints across turns can be naturally modeled as labeled directed edges, making graph structures particularly suitable for modeling multi-turn instruction following. Despite this potential, leveraging graph structures to enhance the multi-turn instruction following capabilities of LLMs remains unexplored. To bridge this gap, we propose GraphIF, a plug-and-play framework that models multi-turn dialogues as directed relation graphs and leverages graph prompts to enhance the instruction following capabilities of LLMs. GraphIF comprises three key components: (1) an agent-based relation extraction module that captures inter-turn semantic relations via action-triggered mechanisms to construct structured graphs; (2) a relation graph prompt generation module that converts structured graph information into natural language prompts; and (3) a response rewriting module that refines initial LLM outputs using the generated graph prompts. Extensive experiments on two long multi-turn dialogue datasets demonstrate that GraphIF can be seamlessly integrated into instruction-tuned LLMs and leads to significant improvements across all four multi-turn instruction-following evaluation metrics.

</details>


### [27] [ADI-20: Arabic Dialect Identification dataset and models](https://arxiv.org/abs/2511.10070)
*Haroun Elleuch,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

> ADI-20扩展了之前的ADI-17数据集，包含了19种阿拉伯方言以及现代标准阿拉伯语，总计3,556小时的语音数据。研究使用了精细调整的ECAPA-TDNN和Whisper模型进行方言识别，并探讨了训练数据量及模型参数数量对识别性能的影响，发现在使用30%的数据集时F1分数值略有下降。

<details>
  <summary>Details</summary>

**Motivation:** 为了提升和扩展阿拉伯方言识别技术，需要一个覆盖更多阿拉伯方言的数据集，并对现有模型进行改进和测试。

**Method:** 使用ADI-20数据集训练和评估了多种先进的方言识别系统，包括对ECAPA-TDNN和Whisper模型的精细调整。

**Result:** 研究发现在使用30%的原始训练数据时，F1分数值略有下降。

**Conclusion:** 研究结果表明，扩大数据集并优化模型可以提升方言识别的性能，作者开放了研究中使用的数据集和训练模型来支持其他研究工作。

**Abstract:** We present ADI-20, an extension of the previously published ADI-17 Arabic Dialect Identification (ADI) dataset. ADI-20 covers all Arabic-speaking countries' dialects. It comprises 3,556 hours from 19 Arabic dialects in addition to Modern Standard Arabic (MSA). We used this dataset to train and evaluate various state-of-the-art ADI systems. We explored fine-tuning pre-trained ECAPA-TDNN-based models, as well as Whisper encoder blocks coupled with an attention pooling layer and a classification dense layer. We investigated the effect of (i) training data size and (ii) the model's number of parameters on identification performance. Our results show a small decrease in F1 score while using only 30% of the original training data. We open-source our collected data and trained models to enable the reproduction of our work, as well as support further research in ADI.

</details>


### [28] [Format Matters: The Robustness of Multimodal LLMs in Reviewing Evidence from Tables and Charts](https://arxiv.org/abs/2511.10075)
*Xanh Ho,Yun-Ang Wu,Sunisth Kumar,Florian Boudin,Atsuhiro Takasu,Akiko Aizawa*

Main category: cs.CL

> 本研究评估了多模态LLM在验证科学主张时使用表格和图表作为证据的能力，发现模型在表格上的表现更好，在图表上的表现较弱，建议未来提高模型的图表理解能力。

<details>
  <summary>Details</summary>

**Motivation:** 随着提交的科学论文数量的增加，需要系统来帮助审稿人评估研究主张。实验结果是科学研究的核心部分，通常以不同的格式如表格或图表呈现。但是，目前对于多模态大型语言模型如何在不同证据格式下验证科学主张的能力仍然少有研究。

**Method:** 设计并执行了一系列实验以评估多模态大型语言模型（multimodal LLMs）在使用表格和图表作为证据验证科学主张的能力。为此，我们对两个现有的科学论文数据集进行了调整，加入了必要的注释和结构以适应多模态的主张验证任务。

**Result:** 使用调整过后的数据集，评估了12个多模态LLM，发现当前模型在基于表格的证据上表现更好，在基于图表的证据上表现较弱。进一步的人类评估显示人类在两种格式上的表现都很强，而模型则不然。此外，分析显示，较小的多模态LLM（小于8B）在表格和图表任务之间的表现几乎没有相关性，表明它们的跨模态泛化能力有限。

**Conclusion:** 研究结果突显了当前模型多模态推理能力中的一个关键差距。建议未来的多模态LLM应更多地关注改进图表理解，以更好地支持科学主张的验证。

**Abstract:** With the growing number of submitted scientific papers, there is an increasing demand for systems that can assist reviewers in evaluating research claims. Experimental results are a core component of scientific work, often presented in varying formats such as tables or charts. Understanding how robust current multimodal large language models (multimodal LLMs) are at verifying scientific claims across different evidence formats remains an important and underexplored challenge. In this paper, we design and conduct a series of experiments to assess the ability of multimodal LLMs to verify scientific claims using both tables and charts as evidence. To enable this evaluation, we adapt two existing datasets of scientific papers by incorporating annotations and structures necessary for a multimodal claim verification task. Using this adapted dataset, we evaluate 12 multimodal LLMs and find that current models perform better with table-based evidence while struggling with chart-based evidence. We further conduct human evaluations and observe that humans maintain strong performance across both formats, unlike the models. Our analysis also reveals that smaller multimodal LLMs (under 8B) show weak correlation in performance between table-based and chart-based tasks, indicating limited cross-modal generalization. These findings highlight a critical gap in current models' multimodal reasoning capabilities. We suggest that future multimodal LLMs should place greater emphasis on improving chart understanding to better support scientific claim verification.

</details>


### [29] [ELYADATA & LIA at NADI 2025: ASR and ADI Subtasks](https://arxiv.org/abs/2511.10090)
*Haroun Elleuch,Youssef Saidi,Salima Mdhaffar,Yannick Estève,Fethi Bougares*

Main category: cs.CL

> Elyadata & LIA submitted solutions to the NADI Arabic speech processing tasks, achieving top rankings. Their ADI system used a fine-tuned Whisper model, while the ASR system utilized separately fine-tuned SeamlessM4T models for each Arabic dialect.

<details>
  <summary>Details</summary>

**Motivation:** The motivation of the paper is to showcase the effectiveness of pre-trained speech models in handling Arabic speech tasks, particularly ADI and ASR, by demonstrating the state-of-the-art performance on a competitive benchmark.

**Method:** The solutions involved fine-tuning two pre-trained models, Whisper for dialect identification and SeamlessM4T for ASR, with data augmentation applied for the identification task.

**Result:** The ADI model achieved an accuracy of 79.83%, ranking first. The ASR model achieved an average WER of 38.54% and CER of 14.53%, ranking second.

**Conclusion:** The study concludes that large pre-trained models can be effectively fine-tuned for Arabic speech processing, leading to significant performance improvements when compared to prior models.

**Abstract:** This paper describes Elyadata \& LIA's joint submission to the NADI multi-dialectal Arabic Speech Processing 2025. We participated in the Spoken Arabic Dialect Identification (ADI) and multi-dialectal Arabic ASR subtasks. Our submission ranked first for the ADI subtask and second for the multi-dialectal Arabic ASR subtask among all participants. Our ADI system is a fine-tuned Whisper-large-v3 encoder with data augmentation. This system obtained the highest ADI accuracy score of \textbf{79.83\%} on the official test set. For multi-dialectal Arabic ASR, we fine-tuned SeamlessM4T-v2 Large (Egyptian variant) separately for each of the eight considered dialects. Overall, we obtained an average WER and CER of \textbf{38.54\%} and \textbf{14.53\%}, respectively, on the test set. Our results demonstrate the effectiveness of large pre-trained speech models with targeted fine-tuning for Arabic speech processing.

</details>


### [30] [On the Military Applications of Large Language Models](https://arxiv.org/abs/2511.10093)
*Satu Johansson,Taneli Riihonen*

Main category: cs.CL

> 研究了基于GPT的语言模型在军事应用中的潜力，评估了商用云服务构建这些应用的可行性，并得出结论：这些模型在大量应用中具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 探讨自然语言处理和大型语言模型在军事领域的应用，特别是随着GPT和OpenAI为ChatGPT等进行广泛基础模型预训练后，这些模型受到广泛关注。

**Method:** 通过质询基于GPT的语言模型（如Microsoft Copilot）来揭示其在军事应用方面的潜在知识，然后对其进行批判性评估。接着，研究商用云服务（如Microsoft Azure）如何快速构建此类应用，并评估这些应用的可行性。

**Result:** 总结和生成文本的特性直接促进了大量应用的实现，而其他特性也可能具有特定用途。

**Conclusion:** 总结和生成文本的特性直接促进了大量军事应用的实现，而其他特性也可能具有特定军事用途。

**Abstract:** In this paper, military use cases or applications and implementation thereof are considered for natural language processing and large language models, which have broken into fame with the invention of the generative pre-trained transformer (GPT) and the extensive foundation model pretraining done by OpenAI for ChatGPT and others. First, we interrogate a GPT-based language model (viz. Microsoft Copilot) to make it reveal its own knowledge about their potential military applications and then critically assess the information. Second, we study how commercial cloud services (viz. Microsoft Azure) could be used readily to build such applications and assess which of them are feasible. We conclude that the summarization and generative properties of language models directly facilitate many applications at large and other features may find particular uses.

</details>


### [31] [Generalizing to Unseen Disaster Events: A Causal View](https://arxiv.org/abs/2511.10120)
*Philipp Seeberger,Steffen Freisinger,Tobias Bocklet,Korbinian Riedhammer*

Main category: cs.CL

> The paper presents a method to improve the accuracy of disaster event information extraction from social media by reducing bias through causal learning, achieving up to +1.9% F1 improvement.

<details>
  <summary>Details</summary>

**Motivation:** The rapid growth of social media platforms has made them crucial for disaster event monitoring, but the existing systems face the challenge of event-related biases limiting their generalization to new events.

**Method:** The paper proposes a bias mitigation method based on causal learning to enhance the generalization of disaster event information extraction from social media.

**Result:** The proposed method performs better than multiple baselines by up to +1.9% F1 score, and significantly improves a PLM-based classifier across three disaster classification tasks.

**Conclusion:** The study demonstrates the effectiveness of causal learning in mitigating biases in disaster event information extraction from social media, leading to better generalization and more accurate classification.

**Abstract:** Due to the rapid growth of social media platforms, these tools have become essential for monitoring information during ongoing disaster events. However, extracting valuable insights requires real-time processing of vast amounts of data. A major challenge in existing systems is their exposure to event-related biases, which negatively affects their ability to generalize to emerging events. While recent advancements in debiasing and causal learning offer promising solutions, they remain underexplored in the disaster event domain. In this work, we approach bias mitigation through a causal lens and propose a method to reduce event- and domain-related biases, enhancing generalization to future events. Our approach outperforms multiple baselines by up to +1.9% F1 and significantly improves a PLM-based classifier across three disaster classification tasks.

</details>


### [32] [Beyond the Black Box: Demystifying Multi-Turn LLM Reasoning with VISTA](https://arxiv.org/abs/2511.10182)
*Yiran Zhang,Mingyang Lin,Mark Dras,Usman Naseem*

Main category: cs.CL

> 本文介绍了一个名为VISTA的新工具，旨在解决分析大型语言模型多轮次推理过程的复杂性问题，提供了自动解析会话生成依赖树的功能。

<details>
  <summary>Details</summary>

**Motivation:** 近年来的研究越来越关注大型语言模型（LLMs）在多轮次交互中的推理能力，这些场景更接近于现实世界的问题解决。然而，由于复杂的上下文依赖关系以及缺乏专门的可视化工具，分析这些交互中的复杂推理过程是一个巨大的挑战，给研究人员带来了高认知负荷。为了填补这一空白，研究者们推出了VISTA。

**Method:** 通过开发VISTA，这是一个基于网络的用于文本分析的可视化交互系统，专注于多轮次推理任务。VISTA允许用户可视化上下文对模型决策的影响，并可以交互式地修改对话历史进行“假设”分析。此外，该平台可以自动解析会话并生成推理依赖树，提供模型逐步逻辑路径的透明视图。

**Result:** 通过提供统一和交互的框架，VISTA显著减少了分析推理链的复杂性，从而促进了对当前LLMs能力及限制的更深入理解。

**Conclusion:** VISTA平台开源，支持定制基准和本地模型的简单集成，为研究人员提供了分析LLMs推理能力的有力工具。

**Abstract:** Recent research has increasingly focused on the reasoning capabilities of Large Language Models (LLMs) in multi-turn interactions, as these scenarios more closely mirror real-world problem-solving. However, analyzing the intricate reasoning processes within these interactions presents a significant challenge due to complex contextual dependencies and a lack of specialized visualization tools, leading to a high cognitive load for researchers. To address this gap, we present VISTA, an web-based Visual Interactive System for Textual Analytics in multi-turn reasoning tasks. VISTA allows users to visualize the influence of context on model decisions and interactively modify conversation histories to conduct "what-if" analyses across different models. Furthermore, the platform can automatically parse a session and generate a reasoning dependency tree, offering a transparent view of the model's step-by-step logical path. By providing a unified and interactive framework, VISTA significantly reduces the complexity of analyzing reasoning chains, thereby facilitating a deeper understanding of the capabilities and limitations of current LLMs. The platform is open-source and supports easy integration of custom benchmarks and local models.

</details>


### [33] [Text2SQL-Flow: A Robust SQL-Aware Data Augmentation Framework for Text-to-SQL](https://arxiv.org/abs/2511.10192)
*Qifeng Cai,Hao Liang,Chang Xu,Tao Xie,Wentao Zhang,Bin Cui*

Main category: cs.CL

> 研究提出了一种SQL感知的数据增强框架Text2SQL-Flow，用于生成高质量Text-to-SQL数据集SQLFlow，该数据集可显著提升LLMs的性能。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于解决AI领域的Text-to-SQL任务中由于数据稀缺、简单以及多样性不足导致的性能限制。

**Method:** 该研究提出了Text2SQL-Flow，一种SQL感知的数据增强框架，能够从少量种子数据生成大规模、语义有效且结构多元的Text-to-SQL对。

**Result:** 实验表明，该框架生成的高质量数据集SQLFlow能够有效提升基于开源以及闭源的LLMs的性能，尤其是在结构感知的示例匹配方面表现优于现有方法。

**Conclusion:** 研究强调了高质量结构化数据在现代AI中的关键作用，并为Text-to-SQL系统的进步奠定了一个可扩展的数据中心基础。

**Abstract:** The data-centric paradigm has become pivotal in AI, especially for Text-to-SQL, where performance is limited by scarce, simplistic, and low-diversity datasets. To address this, we propose Text2SQL-Flow, a SQL-aware data augmentation framework that generates large-scale, semantically valid, and structurally diverse Text-to-SQL pairs from minimal seed data. It operates across six augmentation dimensions and integrates an end-to-end pipeline featuring SQL execution verification, natural language question generation, chain-of-thought reasoning traces, and data classification. A modular Database Manager ensures cross-database compatibility and scalability. Using this framework, we build SQLFlow, a high-quality dataset of 89,544 annotated examples. We evaluate SQLFlow in two settings: (1) For open-source LLMs, fine-tuning on SQLFlow consistently improves performance across benchmarks under the same data budget. (2) For closed-source LLMs, we introduce a masked alignment retrieval method that treats SQLFlow as both knowledge base and training data for the retriever. This enables structure-aware example matching by modeling fine-grained alignments between questions and SQL queries. Experiments show our retrieval strategy outperforms existing methods, underscoring the value of SQLFlow's high-fidelity data and our novel technique. Our work establishes a scalable, data-centric foundation for advancing Text-to-SQL systems and highlights the critical role of high-quality structured data in modern AI.

</details>


### [34] [EffiReason-Bench: A Unified Benchmark for Evaluating and Advancing Efficient Reasoning in Large Language Models](https://arxiv.org/abs/2511.10201)
*Junquan Huang,Haotian Wu,Yubo Gao,Yibo Yan,Junyan Zhang,Yonghua Hei,Song Dai,Jie Zhang,Puay Siew Tan,Xuming Hu*

Main category: cs.CL

> 介绍EffiReason-Bench，一种统一的高效推理方法基准，通过评估展示了没有一种方法能对所有模型和任务都优胜。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)使用Chain-of-Thought(CoT)提示可以实现强大的推理，但往往产生不必要的长解释，这会增加成本并有时降低准确性。

**Method:** 提出了EffiReason-Bench，这是一个统一的基准，用于严格跨范式评估高效推理方法。通过构建标准化推理结构、全面选项分析和人类验证的管道，为CommonsenseQA和LogiQA创建了验证的CoT注释。

**Result:** 在四个数据集上对六种公开源代码的LLM(1B-70B)进行了七种方法的评估，提出了E3-Score，这是一种由经济贸易模型启发的原则性度量标准，能够平稳、稳定地评估，没有不连续性或对启发式的依赖。

**Conclusion:** 研究表明，没有单一的方法能够普遍主导；最优策略取决于模型规模、任务复杂度和架构。

**Abstract:** Large language models (LLMs) with Chain-of-Thought (CoT) prompting achieve strong reasoning but often produce unnecessarily long explanations, increasing cost and sometimes reducing accuracy. Fair comparison of efficiency-oriented approaches is hindered by fragmented evaluation practices. We introduce EffiReason-Bench, a unified benchmark for rigorous cross-paradigm evaluation of efficient reasoning methods across three categories: Reasoning Blueprints, Dynamic Execution, and Post-hoc Refinement. To enable step-by-step evaluation, we construct verified CoT annotations for CommonsenseQA and LogiQA via a pipeline that enforces standardized reasoning structures, comprehensive option-wise analysis, and human verification. We evaluate 7 methods across 6 open-source LLMs (1B-70B) on 4 datasets spanning mathematics, commonsense, and logic, and propose the E3-Score, a principled metric inspired by economic trade-off modeling that provides smooth, stable evaluation without discontinuities or heavy reliance on heuristics. Experiments show that no single method universally dominates; optimal strategies depend on backbone scale, task complexity, and architecture.

</details>


### [35] [Persona-Aware Alignment Framework for Personalized Dialogue Generation](https://arxiv.org/abs/2511.10215)
*Guanrong Li,Xinyu Liu,Zhen Wu,Xinyu Dai*

Main category: cs.CL

> Proposes a new framework (PAL) to enhance persona relevance in dialogue generation, improving over existing methods.

<details>
  <summary>Details</summary>

**Motivation:** address the issue that mainstream models tend to neglect the given personas and generate generic responses

**Method:** Persona-Aware Alignment Framework (PAL), two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate

**Result:** outperforms many state-of-the-art personalized dialogue methods and large language models

**Conclusion:** PAL improves persona sensitivity and generates more persona-relevant responses at the semantics level

**Abstract:** Personalized dialogue generation aims to leverage persona profiles and dialogue history to generate persona-relevant and consistent responses. Mainstream models typically rely on token-level language model training with persona dialogue data, such as Next Token Prediction, to implicitly achieve personalization, making these methods tend to neglect the given personas and generate generic responses. To address this issue, we propose a novel Persona-Aware Alignment Framework (PAL), which directly treats persona alignment as the training objective of dialogue generation. Specifically, PAL employs a two-stage training method including Persona-aware Learning and Persona Alignment, equipped with an easy-to-use inference strategy Select then Generate, to improve persona sensitivity and generate more persona-relevant responses at the semantics level. Through extensive experiments, we demonstrate that our framework outperforms many state-of-the-art personalized dialogue methods and large language models.

</details>


### [36] [LangGPS: Language Separability Guided Data Pre-Selection for Joint Multilingual Instruction Tuning](https://arxiv.org/abs/2511.10229)
*Yangfan Ye,Xiaocheng Feng,Xiachong Feng,Lei Huang,Weitao Ma,Qichen Hong,Yunfei Lu,Duyu Tang,Dandan Tu,Bing Qin*

Main category: cs.CL

> 本文提出了LangGPS框架，通过引入语言可分离性提高了多语言数据选择方法的有效性和理解任务及低资源语言的表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多语言数据选择方法往往忽视数据内在的语言结构，因此作者希望通过引入语言可分离性来改进数据选择方法，提高LLMs的多语言理解和适应能力。

**Method:** 我们提出了LangGPS，一个基于语言可分离性的双阶段预选框架。LangGPS首先根据可分离分数过滤训练数据，再使用现有的选择方法细化子集。

**Result:** 在六个基准和22种语言上的广泛实验表明，LangGPS能够改善现有选择方法的有效性和普遍性，特别是在理解任务和低资源语言方面。

**Conclusion:** LangGPS不仅提供了一个新的视角来评估多语言上下文中数据的有效性，还支持更加语言学背景丰富的LLMs的发展。

**Abstract:** Joint multilingual instruction tuning is a widely adopted approach to improve the multilingual instruction-following ability and downstream performance of large language models (LLMs), but the resulting multilingual capability remains highly sensitive to the composition and selection of the training data. Existing selection methods, often based on features like text quality, diversity, or task relevance, typically overlook the intrinsic linguistic structure of multilingual data. In this paper, we propose LangGPS, a lightweight two-stage pre-selection framework guided by language separability which quantifies how well samples in different languages can be distinguished in the model's representation space. LangGPS first filters training data based on separability scores and then refines the subset using existing selection methods. Extensive experiments across six benchmarks and 22 languages demonstrate that applying LangGPS on top of existing selection methods improves their effectiveness and generalizability in multilingual training, especially for understanding tasks and low-resource languages. Further analysis reveals that highly separable samples facilitate the formation of clearer language boundaries and support faster adaptation, while low-separability samples tend to function as bridges for cross-lingual alignment. Besides, we also find that language separability can serve as an effective signal for multilingual curriculum learning, where interleaving samples with diverse separability levels yields stable and generalizable gains. Together, we hope our work offers a new perspective on data utility in multilingual contexts and support the development of more linguistically informed LLMs.

</details>


### [37] [VocalNet-M2: Advancing Low-Latency Spoken Language Modeling via Integrated Multi-Codebook Tokenization and Multi-Token Prediction](https://arxiv.org/abs/2511.10232)
*Yuhao Wang,Ziyang Cheng,Heyang Liu,Ronghua Wu,Qunshan Gu,Yanfeng Wang,Yu Wang*

Main category: cs.CL

> 本文介绍了VocalNet-M2，一种新的低延迟语音语言模型，通过使用多词典标记器和MTP策略，将其延迟从725ms减少到350ms。

<details>
  <summary>Details</summary>

**Motivation:** 当前的端到端语音语言模型在响应延迟方面存在问题，这主要是由于语音令牌的自回归生成和对复杂流匹配模型的依赖。

**Method:** VocalNet-M2采用了多词典标记器和多令牌预测(MTP)策略，直接生成多词典语音令牌，消除了需要延迟的流匹配模型。

**Result:** 实验表明，VocalNet-M2将首个分块延迟从大约725ms减少到350ms，同时在主流的SLM中保持竞争力。

**Conclusion:** 该工作还提供了单一词典和多词典策略的全面比较，为开发高效的实时互动语音语言模型提供了有价值的见解。

**Abstract:** Current end-to-end spoken language models (SLMs) have made notable progress, yet they still encounter considerable response latency. This delay primarily arises from the autoregressive generation of speech tokens and the reliance on complex flow-matching models for speech synthesis. To overcome this, we introduce VocalNet-M2, a novel low-latency SLM that integrates a multi-codebook tokenizer and a multi-token prediction (MTP) strategy. Our model directly generates multi-codebook speech tokens, thus eliminating the need for a latency-inducing flow-matching model. Furthermore, our MTP strategy enhances generation efficiency and improves overall performance. Extensive experiments demonstrate that VocalNet-M2 achieves a substantial reduction in first chunk latency (from approximately 725ms to 350ms) while maintaining competitive performance across mainstream SLMs. This work also provides a comprehensive comparison of single-codebook and multi-codebook strategies, offering valuable insights for developing efficient and high-performance SLMs for real-time interactive applications.

</details>


### [38] [MTR-DuplexBench: Towards a Comprehensive Evaluation of Multi-Round Conversations for Full-Duplex Speech Language Models](https://arxiv.org/abs/2511.10262)
*He Zhang,Wenqian Cui,Haoning Xu,Xiaohui Li,Lei Zhu,Shaohua Ma,Irwin King*

Main category: cs.CL

> The paper presents MTR-DuplexBench, a new benchmark designed to evaluate Full-Duplex Speech Language Models (FD-SLMs) in multi-round dialogue settings, focusing on dialogue quality, conversational dynamics, instruction following, and safety.

<details>
  <summary>Details</summary>

**Motivation:** To address the limitations of existing benchmarks that neglect the evaluation of FD-SLMs in multi-round communication settings and important capabilities including safety and instruction following.

**Method:** Development of the MTR-DuplexBench benchmark which segments continuous full-duplex dialogues into discrete turns for a comprehensive turn-by-turn assessment of FD-SLMs.

**Result:** Current FD-SLMs show varying performance across multiple rounds and different evaluation dimensions, indicating areas for improvement and validating the need for and usefulness of MTR-DuplexBench.

**Conclusion:** The proposed benchmark, MTR-DuplexBench, effectively evaluates and highlights the performance gaps of FD-SLMs in multi-round dialogue scenarios, emphasizing the necessity for further research in this area.

**Abstract:** Full-Duplex Speech Language Models (FD-SLMs) enable real-time, overlapping conversational interactions, offering a more dynamic user experience compared to traditional half-duplex models. However, existing benchmarks primarily focus on evaluating single-round interactions and conversational features, neglecting the complexities of multi-round communication and critical capabilities such as instruction following and safety. Evaluating FD-SLMs in multi-round settings poses significant challenges, including blurred turn boundaries in communication and context inconsistency during model inference. To address these gaps, we introduce MTR-DuplexBench, a novel benchmark that segments continuous full-duplex dialogues into discrete turns, enabling comprehensive, turn-by-turn evaluation of FD-SLMs across dialogue quality, conversational dynamics, instruction following, and safety. Experimental results reveal that current FD-SLMs face difficulties in maintaining consistent performance across multiple rounds and evaluation dimensions, highlighting the necessity and effectiveness of our proposed benchmark. The benchmark and code will be available in the future.

</details>


### [39] [Local Hybrid Retrieval-Augmented Document QA](https://arxiv.org/abs/2511.10297)
*Paolo Astrino*

Main category: cs.CL

> 该论文提出了一种问答系统，它利用语义理解和关键词精度相结合的方法，在没有互联网连接的本地基础设施上运行，实现了高精度的答案检索，适用于法律、科学和对话文件，同时保证数据安全。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决企业组织在使用基于云的AI系统提供强大的问答功能但会牺牲数据隐私，和使用本地处理系统确保安全性但准确性较差之间的困境。

**Method:** 结合语义理解和关键词精度的方法，在仅使用消费者级硬件加速和不依赖互联网连接的本地基础设施上运行问答系统。

**Result:** 此系统在处理复杂的查询时实现了具有竞争力的准确性，同时保持极低的错误率，并适用于多个行业。

**Conclusion:** 证明了在企业AI部署中，保障数据隐私和保证系统性能并非互相排斥。

**Abstract:** Organizations handling sensitive documents face a critical dilemma: adopt cloud-based AI systems that offer powerful question-answering capabilities but compromise data privacy, or maintain local processing that ensures security but delivers poor accuracy. We present a question-answering system that resolves this trade-off by combining semantic understanding with keyword precision, operating entirely on local infrastructure without internet access. Our approach demonstrates that organizations can achieve competitive accuracy on complex queries across legal, scientific, and conversational documents while keeping all data on their machines. By balancing two complementary retrieval strategies and using consumer-grade hardware acceleration, the system delivers reliable answers with minimal errors, letting banks, hospitals, and law firms adopt conversational document AI without transmitting proprietary information to external providers. This work establishes that privacy and performance need not be mutually exclusive in enterprise AI deployment.

</details>


### [40] [Rectify Evaluation Preference: Improving LLMs' Critique on Math Reasoning via Perplexity-aware Reinforcement Learning](https://arxiv.org/abs/2511.10303)
*Changyuan Tian,Zhicong Lu,Shuang Qian,Nayu Liu,Peiguang Li,Li Jin,Leiyi Hu,Zhizhao Zeng,Sirui Wang,Ke Zeng,Zhi Guo*

Main category: cs.CL

> 通过探究大语言模型在多步数学推理中的评价偏好问题，提出了一种基于困惑度感知的强化学习算法，以提升其错误评判能力，并通过实验验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 改进大语言模型在多步数学推理中的评判能力，解释了现有方法在提升评判能力上的不足，特别是对模型评判表现不佳的根源探究不足，提出了不平衡的评价偏好问题。

**Method:** 建立了一种新的One-to-many问题-解决方案基准，对大语言模型在评判自身和他人生成的解决方案时的行为差异进行统计偏好分析；提出了一种新的基于困惑度感知的强化学习算法来处理不平衡的评价偏好问题。

**Result:** 实验结果表明，基于困惑度感知的强化学习算法可以有效地纠正不平衡的评价偏好，提升模型评判能力，验证了所提方法的有效性。

**Conclusion:** 研究揭示了大语言模型在评判多步数学推理能力时存在不平衡评价偏好这一现象，并通过算法优化提升了评判能力。

**Abstract:** To improve Multi-step Mathematical Reasoning (MsMR) of Large Language Models (LLMs), it is crucial to obtain scalable supervision from the corpus by automatically critiquing mistakes in the reasoning process of MsMR and rendering a final verdict of the problem-solution. Most existing methods rely on crafting high-quality supervised fine-tuning demonstrations for critiquing capability enhancement and pay little attention to delving into the underlying reason for the poor critiquing performance of LLMs. In this paper, we orthogonally quantify and investigate the potential reason -- imbalanced evaluation preference, and conduct a statistical preference analysis. Motivated by the analysis of the reason, a novel perplexity-aware reinforcement learning algorithm is proposed to rectify the evaluation preference, elevating the critiquing capability. Specifically, to probe into LLMs' critiquing characteristics, a One-to-many Problem-Solution (OPS) benchmark is meticulously constructed to quantify the behavior difference of LLMs when evaluating the problem solutions generated by itself and others. Then, to investigate the behavior difference in depth, we conduct a statistical preference analysis oriented on perplexity and find an intriguing phenomenon -- ``LLMs incline to judge solutions with lower perplexity as correct'', which is dubbed as \textit{imbalanced evaluation preference}. To rectify this preference, we regard perplexity as the baton in the algorithm of Group Relative Policy Optimization, supporting the LLMs to explore trajectories that judge lower perplexity as wrong and higher perplexity as correct. Extensive experimental results on our built OPS and existing available critic benchmarks demonstrate the validity of our method.

</details>


### [41] [BhashaKritika: Building Synthetic Pretraining Data at Scale for Indic Languages](https://arxiv.org/abs/2511.10338)
*Guduru Manoj,Neel Prabhanjan Rachamalla,Ashish Kulkarni,Gautam Rajeev,Jay Piplodiya,Arul Menezes,Shaharukh Khan,Souvik Rana,Manya Sah,Chandra Khatri,Shubham Agarwal*

Main category: cs.CL

> 本研究通过生成和评估大型合成数据集BhashaKritika，系统地研究了用于印度语言的合成多语言预训练数据，提供了质量和控制策略，适用于多种脚本和语言环境。

<details>
  <summary>Details</summary>

**Motivation:** 在大型语言模型的预训练背景下，合成数据成为生成高质量预训练数据的可选方案，特别在资源稀缺的语言环境中，可以帮助跨越语言的分布不均衡问题。因此，开展了这项研究。

**Method:** 本研究提出了一个系统的关于印度语言合成多语言预训练数据生成和评估的研究。构建了一个包含540B令牌的大型合成数据集BhashaKritika，涵盖了10种语言，使用了5种不同的技术进行了研究。同时，探讨了生成过程中的文档、角色和主题引导的影响，并分析了语言选择（包括提示指令和文档引导中）对数据质量的影响。还比较了英语内容的翻译与印度语言原生生成之间的差异。

**Result:** 研究结果揭示了生成策略中的关键权衡，并提出了构建有效的多语言语料库的最佳实践。

**Conclusion:** 该研究为合成数据的生成和评估提供了一个模快化的质量评估流水线，支持规模化和语言敏感性的评估，并成功地进行了一系列模型实验，体现了框架在多种脚本和语言环境下的强健质量控制。

**Abstract:** In the context of pretraining of Large Language Models (LLMs), synthetic data has emerged as an alternative for generating high-quality pretraining data at scale. This is particularly beneficial in low-resource language settings where the benefits of recent LLMs have been unevenly distributed across languages. In this work, we present a systematic study on the generation and evaluation of synthetic multilingual pretraining data for Indic languages, where we construct a large-scale synthetic dataset BhashaKritika, comprising 540B tokens using 5 different techniques for 10 languages. We explore the impact of grounding generation in documents, personas, and topics. We analyze how language choice, both in the prompt instructions and document grounding, affects data quality, and we compare translations of English content with native generation in Indic languages. To support scalable and language-sensitive evaluation, we introduce a modular quality evaluation pipeline that integrates script and language detection, metadata consistency checks, n-gram repetition analysis, and perplexity-based filtering using KenLM models. Our framework enables robust quality control across diverse scripts and linguistic contexts. Empirical results through model runs reveal key trade-offs in generation strategies and highlight best practices for constructing effective multilingual corpora.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [42] [FedeCouple: Fine-Grained Balancing of Global-Generalization and Local-Adaptability in Federated Learning](https://arxiv.org/abs/2511.09599)
*Ming Yang,Dongrun Li,Xin Wang,Feng Li,Lisheng Fan,Chunxiao Wang,Xiaoming Wu,Peng Cheng*

Main category: cs.CV

> FedeCouple improves federated learning by enhancing coordination between global generalization and local adaptability, leading to better performance across multiple criteria compared to baselines.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of insufficient coordination and weak coupling between feature extractors and classifiers in existing personalized federated learning methods, which degrades overall model performance.

**Method:** FedeCouple, a federated learning method that balances global generalization and local adaptability through joint learning of global and local feature representations, dynamic knowledge distillation, and the introduction of anchors to refine the feature space.

**Result:** FedeCouple consistently outperforms nine baseline methods in effectiveness, stability, scalability, and security, with a significant improvement of 4.3% in experiments evaluating effectiveness.

**Conclusion:** The proposed FedeCouple achieves better model performance by balancing global and local aspects of federated learning, supported by theoretical analysis and experimental validation.

**Abstract:** In privacy-preserving mobile network transmission scenarios with heterogeneous client data, personalized federated learning methods that decouple feature extractors and classifiers have demonstrated notable advantages in enhancing learning capability. However, many existing approaches primarily focus on feature space consistency and classification personalization during local training, often neglecting the local adaptability of the extractor and the global generalization of the classifier. This oversight results in insufficient coordination and weak coupling between the components, ultimately degrading the overall model performance. To address this challenge, we propose FedeCouple, a federated learning method that balances global generalization and local adaptability at a fine-grained level. Our approach jointly learns global and local feature representations while employing dynamic knowledge distillation to enhance the generalization of personalized classifiers. We further introduce anchors to refine the feature space; their strict locality and non-transmission inherently preserve privacy and reduce communication overhead. Furthermore, we provide a theoretical analysis proving that FedeCouple converges for nonconvex objectives, with iterates approaching a stationary point as the number of communication rounds increases. Extensive experiments conducted on five image-classification datasets demonstrate that FedeCouple consistently outperforms nine baseline methods in effectiveness, stability, scalability, and security. Notably, in experiments evaluating effectiveness, FedeCouple surpasses the best baseline by a significant margin of 4.3%.

</details>


### [43] [MMaDA-Parallel: Multimodal Large Diffusion Language Models for Thinking-Aware Editing and Generation](https://arxiv.org/abs/2511.09611)
*Ye Tian,Ling Yang,Jiongfan Yang,Anran Wang,Yu Tian,Jiani Zheng,Haochen Wang,Zhiyang Teng,Zhuochen Wang,Yinjie Wang,Yunhai Tong,Mengdi Wang,Xiangtai Li*

Main category: cs.CV

> 研究聚焦于复杂任务中的思考生成过程，指出现有方法可能导致性能下降的问题，并提出了一个新的基准ParaBench和优化方案MMaDA-Parallel，解决跨模态对齐问题。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决现有顺序自回归方法在复杂任务中可能因错误传播而恶化性能的问题，特别关注生成推理与最终图像对齐不佳的现象。

**Method:** 提出了一个名为ParaBench的新基准，用于评估文本和图像输出模态。通过这种方法，揭示了在复杂任务中生成的推理与最终图像之间对齐不佳的问题。为解决此问题，提出了一种并行的多模态扩散框架MMaDA-Parallel，它在整个去噪过程中能够实现文本和图像之间的持续双向交互。MMaDA-Parallel采用监督微调训练，并通过Parallel Reinforcement Learning (ParaRL)进行进一步优化，该策略采用语义奖励以沿轨迹强制执行跨模态一致性。

**Result:** 实验表明，该模型显著提高了跨模态对齐和语义一致性，在ParaBench上的输出对齐性能比最先进的模型Bagel提升了6.9%。

**Conclusion:** 提出的方法建立了更为稳健的思考感知图像合成范式，方法的有效性已在实验中得到了证实。代码开源。

**Abstract:** While thinking-aware generation aims to improve performance on complex tasks, we identify a critical failure mode where existing sequential, autoregressive approaches can paradoxically degrade performance due to error propagation. To systematically analyze this issue, we propose ParaBench, a new benchmark designed to evaluate both text and image output modalities. Our analysis using ParaBench reveals that this performance degradation is strongly correlated with poor alignment between the generated reasoning and the final image. To resolve this, we propose a parallel multimodal diffusion framework, MMaDA-Parallel, that enables continuous, bidirectional interaction between text and images throughout the entire denoising trajectory. MMaDA-Parallel is trained with supervised finetuning and then further optimized by Parallel Reinforcement Learning (ParaRL), a novel strategy that applies semantic rewards along the trajectory to enforce cross-modal consistency. Experiments validate that our model significantly improves cross-modal alignment and semantic consistency, achieving a 6.9\% improvement in Output Alignment on ParaBench compared to the state-of-the-art model, Bagel, establishing a more robust paradigm for thinking-aware image synthesis. Our code is open-sourced at https://github.com/tyfeld/MMaDA-Parallel

</details>


### [44] [PriVi: Towards A General-Purpose Video Model For Primate Behavior In The Wild](https://arxiv.org/abs/2511.09675)
*Felix B. Mueller,Jan F. Meier,Timo Lueddecke,Richard Vogg,Roger L. Freixanet,Valentin Hassler,Tiffany Bosshard,Elif Karakoc,William J. O'Hearn,Sofia M. Pereira,Sandro Sehner,Kaja Wierucka,Judith Burkart,Claudia Fichtel,Julia Fischer,Alexander Gail,Catherine Hobaiter,Julia Ostner,Liran Samuni,Oliver Schülke,Neda Shahidi,Erin G. Wessling,Alexander S. Ecker*

Main category: cs.CV

> 本文提出了一种以非人灵长类为中心的视频预训练数据集PriVi，通过预训练模型V-JEPA学习特定的非人灵长类表示，并展示了在四个基准数据集上的优越表现。

<details>
  <summary>Details</summary>

**Motivation:** 分析非人灵长类的行为对认知、进化和保护研究至关重要。计算机视觉可以极大地帮助这项研究，但现有的方法往往依赖于以人类为中心的预训练模型，并且专注于单一数据集，这限制了泛化能力。

**Method:** 通过从模型为中心转向数据为中心的方法，引入了一个大型的以非人灵长类为中心的视频预训练数据集PriVi。PriVi包含424小时的精选视频，其中174小时来自11个不同环境下的行为研究，250小时来自网络上的多样视频，通过可扩展的数据整理管道进行组装。

**Result:** 在四个基准数据集上，该方法始终优于此前的工作，包括完全微调的基线模型，并且在较少标注的情况下也有良好的扩展性。这些结果展示了以非人灵长类为中心的预训练可以大大提升数据效率和泛化性能。

**Conclusion:** 基于以非人灵长类为中心的预训练方法可以提高数据效率和泛化能力，为低标注应用提供了一个有前途的方向。

**Abstract:** Non-human primates are our closest living relatives, and analyzing their behavior is central to research in cognition, evolution, and conservation. Computer vision could greatly aid this research, but existing methods often rely on human-centric pretrained models and focus on single datasets, which limits generalization. We address this limitation by shifting from a model-centric to a data-centric approach and introduce PriVi, a large-scale primate-centric video pretraining dataset. PriVi contains 424 hours of curated video, combining 174 hours from behavioral research across 11 settings with 250 hours of diverse web-sourced footage, assembled through a scalable data curation pipeline. We pretrain V-JEPA on PriVi to learn primate-specific representations and evaluate it using a lightweight frozen classifier. Across four benchmark datasets, ChimpACT, BaboonLand, PanAf500, and ChimpBehave, our approach consistently outperforms prior work, including fully finetuned baselines, and scales favorably with fewer labels. These results demonstrate that primate-centric pretraining substantially improves data efficiency and generalization, making it a promising approach for low-label applications. Code, models, and the majority of the dataset will be made available.

</details>


### [45] [Classifying Phonotrauma Severity from Vocal Fold Images with Soft Ordinal Regression](https://arxiv.org/abs/2511.09702)
*Katie Matton,Purvaja Balaji,Hamzeh Ghasemzadeh,Jameson C. Cooper,Daryush D. Mehta,Jarrad H. Van Stan,Robert E. Hillman,Rosalind Picard,John Guttag,S. Mazdak Abulnaga*

Main category: cs.CV

> 提出了一种自动分类声创严重程度的方法，使用软序回归处理标签不确定性，并表现出接近临床专家的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的评估严重程度的方法依赖于临床专家的主观判断，这既昂贵又具有很高的可靠性变异性。为了应对这一挑战，本文提出了一种自动分类声带图像中的声创严重程度的方法。

**Method:** 采用了一种广泛使用的序回归框架来处理标签的顺序性质，并提出了一种新颖的序回归损失函数修改方案，该方案能够处理反映标注者评分分布的软标签，以此来应对标签的不确定性。

**Result:** 所提出的软序回归方法实现了接近临床专家的预测性能，并能产生良好的不确定性估计。

**Conclusion:** 通过提供一种自动化的声创严重程度评估工具，这项工作可以促进声创的大规模研究，最终提高临床理解和患者护理。

**Abstract:** Phonotrauma refers to vocal fold tissue damage resulting from exposure to forces during voicing. It occurs on a continuum from mild to severe, and treatment options can vary based on severity. Assessment of severity involves a clinician's expert judgment, which is costly and can vary widely in reliability. In this work, we present the first method for automatically classifying phonotrauma severity from vocal fold images. To account for the ordinal nature of the labels, we adopt a widely used ordinal regression framework. To account for label uncertainty, we propose a novel modification to ordinal regression loss functions that enables them to operate on soft labels reflecting annotator rating distributions. Our proposed soft ordinal regression method achieves predictive performance approaching that of clinical experts, while producing well-calibrated uncertainty estimates. By providing an automated tool for phonotrauma severity assessment, our work can enable large-scale studies of phonotrauma, ultimately leading to improved clinical understanding and patient care.

</details>


### [46] [SliderEdit: Continuous Image Editing with Fine-Grained Instruction Control](https://arxiv.org/abs/2511.09715)
*Arman Zarei,Samyadeep Basu,Mobina Pournemat,Sayan Nag,Ryan Rossi,Soheil Feizi*

Main category: cs.CV

> SliderEdit enables better control over image edits by providing adjustable sliders for each instruction, improving controllability and consistency.

<details>
  <summary>Details</summary>

**Motivation:** To overcome the limitation of fixed strength application of each instruction in multi-instruction image editing and to enhance the user’s ability to precisely control the strength of individual edits.

**Method:** SliderEdit, a framework that enables continuous and fine-grained control over the intensity of individual instructions in multi-instruction image editing by using globally trained sliders for each instruction.

**Result:** Continuous interpolation along individual edit dimensions while preserving spatial locality and global semantic consistency in image editing models like FLUX-Kontext and Qwen-Image-Edit.

**Conclusion:** SliderEdit offers a novel approach to achieve greater controllability, visual consistency, and user steerability in image editing, marking a first in continuous, fine-grained instruction control.

**Abstract:** Instruction-based image editing models have recently achieved impressive performance, enabling complex edits to an input image from a multi-instruction prompt. However, these models apply each instruction in the prompt with a fixed strength, limiting the user's ability to precisely and continuously control the intensity of individual edits. We introduce SliderEdit, a framework for continuous image editing with fine-grained, interpretable instruction control. Given a multi-part edit instruction, SliderEdit disentangles the individual instructions and exposes each as a globally trained slider, allowing smooth adjustment of its strength. Unlike prior works that introduced slider-based attribute controls in text-to-image generation, typically requiring separate training or fine-tuning for each attribute or concept, our method learns a single set of low-rank adaptation matrices that generalize across diverse edits, attributes, and compositional instructions. This enables continuous interpolation along individual edit dimensions while preserving both spatial locality and global semantic consistency. We apply SliderEdit to state-of-the-art image editing models, including FLUX-Kontext and Qwen-Image-Edit, and observe substantial improvements in edit controllability, visual consistency, and user steerability. To the best of our knowledge, we are the first to explore and propose a framework for continuous, fine-grained instruction control in instruction-based image editing models. Our results pave the way for interactive, instruction-driven image manipulation with continuous and compositional control.

</details>


### [47] [Density Estimation and Crowd Counting](https://arxiv.org/abs/2511.09723)
*Balachandra Devarangadi Sunil,Rakshith Venkatesh,Shantanu Todmal*

Main category: cs.CV

> 该研究改进了一个基于图像的人群密度估计算法，使其适用于基于视频的场景。通过引入一个去噪概率模型、使用扩散过程生成高质量的人群密度图。采用细化的高斯核并融合回归分支和多重密度图来提高精度。结合使用事件驱动的采样技术和Farneback光流算法以减少处理和存储开销，并通过多种评估方法验证了该模型的有效性，适用于实时人群监控等场景。

<details>
  <summary>Details</summary>

**Motivation:** 传统的人群密度估计方法在图像分析中表现良好，但当应用到视频分析中时，数据量和时间连续性带来了新的挑战。本文旨在通过改进现有方法来有效地解决视频场景下的人群密度估计问题。

**Method:** 提出的方法集成了去噪概率模型，利用扩散过程生成人群密度图，并使用细化的高斯核和回归分支来提高准确性。此外，采用事件驱动的采样技术，结合Farneback光流算法来减少计算和存储需求。

**Result:** 通过定性和定量评估，包括叠加图和平均绝对误差（MAE），表明该模型能够有效地捕捉人群动态，并且其高效的采样方法在减少帧数的同时保持了关键人群事件。

**Conclusion:** 本文的工作提供了一个在时间挑战方面具有创新性的视频分析框架，适用于大规模和实时的人群监控场景，如公共安全和灾害响应。

**Abstract:** This study enhances a crowd density estimation algorithm originally designed for image-based analysis by adapting it for video-based scenarios. The proposed method integrates a denoising probabilistic model that utilizes diffusion processes to generate high-quality crowd density maps. To improve accuracy, narrow Gaussian kernels are employed, and multiple density map outputs are generated. A regression branch is incorporated into the model for precise feature extraction, while a consolidation mechanism combines these maps based on similarity scores to produce a robust final result. An event-driven sampling technique, utilizing the Farneback optical flow algorithm, is introduced to selectively capture frames showing significant crowd movements, reducing computational load and storage by focusing on critical crowd dynamics. Through qualitative and quantitative evaluations, including overlay plots and Mean Absolute Error (MAE), the model demonstrates its ability to effectively capture crowd dynamics in both dense and sparse settings. The efficiency of the sampling method is further assessed, showcasing its capability to decrease frame counts while maintaining essential crowd events. By addressing the temporal challenges unique to video analysis, this work offers a scalable and efficient framework for real-time crowd monitoring in applications such as public safety, disaster response, and event management.

</details>


### [48] [PALMS+: Modular Image-Based Floor Plan Localization Leveraging Depth Foundation Model](https://arxiv.org/abs/2511.09724)
*Yunqian Cheng,Benjamin Princen,Roberto Manduchi*

Main category: cs.CV

> PALMS+ 是一种模块化、基于图像的系统，用于解决室内定位问题，特别是在 GPS 信号不稳定的环境中。该系统通过利用深度预测模型从带有位置信息的 RGB 图像中重建 3D 点云，并通过几何布局匹配与楼层平面图进行比较，实现了更高的定位精度。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决传统 PALMS 系统由于手机 LiDAR 距离短和室内布局不确定性导致的局限性，提高 GPS 信号弱环境下的室内定位精度。

**Method:** 利用深度预测模型从带有位置信息的 RGB 图像中重建 3D 点云，并通过几何布局匹配与楼层平面图进行比较，输出位置和方向的概率分布。

**Result:** 在 Structured3D 和定制的校园数据集上，PALMS+ 在静态定位置精度上优于 PALMS 和 F3Loc，并且在真实世界轨迹上的连续定位误差也低于其他方法。

**Conclusion:** PALMS+ 展现了强大的性能，无须任何训练即可实现高精度的定位，并展示了无基础设施定位应用的潜力。

**Abstract:** Indoor localization in GPS-denied environments is crucial for applications like emergency response and assistive navigation. Vision-based methods such as PALMS enable infrastructure-free localization using only a floor plan and a stationary scan, but are limited by the short range of smartphone LiDAR and ambiguity in indoor layouts. We propose PALMS$+$, a modular, image-based system that addresses these challenges by reconstructing scale-aligned 3D point clouds from posed RGB images using a foundation monocular depth estimation model (Depth Pro), followed by geometric layout matching via convolution with the floor plan. PALMS$+$ outputs a posterior over the location and orientation, usable for direct or sequential localization. Evaluated on the Structured3D and a custom campus dataset consisting of 80 observations across four large campus buildings, PALMS$+$ outperforms PALMS and F3Loc in stationary localization accuracy -- without requiring any training. Furthermore, when integrated with a particle filter for sequential localization on 33 real-world trajectories, PALMS$+$ achieved lower localization errors compared to other methods, demonstrating robustness for camera-free tracking and its potential for infrastructure-free applications. Code and data are available at https://github.com/Head-inthe-Cloud/PALMS-Plane-based-Accessible-Indoor-Localization-Using-Mobile-Smartphones

</details>


### [49] [Social LSTM with Dynamic Occupancy Modeling for Realistic Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.09735)
*Ahmed Alia,Mohcine Chraibi,Armin Seyfried*

Main category: cs.CV

> 该论文通过在Social LSTM模型中引入一个新的动态占用空间损失函数，解决了忽略行人实际占据空间的问题，从而提高了轨迹预测的碰撞率和位移准确性。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于，现有的基于深度学习的行人轨迹预测模型大多将行人视为点实体，忽略了每个行人所占据的空间。这种忽略导致模型在预测行人轨迹时无法有效地规避碰撞，特别是在动态和拥挤的环境中。

**Method:** 该论文提出了一个基于Social LSTM的新型深度学习模型，并引入了新的动态占用空间损失函数，以解决现有模型忽略个体尺寸的问题，从而学习避免现实碰撞的方法，同时不会增加在不同人群密度下的位移误差。

**Result:** 实验结果表明，该模型在四个方面优于基线模型：1. 碰撞率降低31%；2. 平均位移误差减少5%；3. 终位移误差减少6%；4. 在大多数测试集中优于其他先进的深度学习模型。

**Conclusion:** 该论文的结论是，所提出的模型通过引入动态占用空间损失函数有效降低了碰撞率，并在不同人群密度下提高了位移预测的准确性。

**Abstract:** In dynamic and crowded environments, realistic pedestrian trajectory prediction remains a challenging task due to the complex nature of human motion and the mutual influences among individuals. Deep learning models have recently achieved promising results by implicitly learning such patterns from 2D trajectory data. However, most approaches treat pedestrians as point entities, ignoring the physical space that each person occupies. To address these limitations, this paper proposes a novel deep learning model that enhances the Social LSTM with a new Dynamic Occupied Space loss function. This loss function guides Social LSTM in learning to avoid realistic collisions without increasing displacement error across different crowd densities, ranging from low to high, in both homogeneous and heterogeneous density settings. Such a function achieves this by combining the average displacement error with a new collision penalty that is sensitive to scene density and individual spatial occupancy. For efficient training and evaluation, five datasets were generated from real pedestrian trajectories recorded during the Festival of Lights in Lyon 2022. Four datasets represent homogeneous crowd conditions -- low, medium, high, and very high density -- while the fifth corresponds to a heterogeneous density distribution. The experimental findings indicate that the proposed model not only lowers collision rates but also enhances displacement prediction accuracy in each dataset. Specifically, the model achieves up to a 31% reduction in the collision rate and reduces the average displacement error and the final displacement error by 5% and 6%, respectively, on average across all datasets compared to the baseline. Moreover, the proposed model consistently outperforms several state-of-the-art deep learning models across most test sets.

</details>


### [50] [Soiling detection for Advanced Driver Assistance Systems](https://arxiv.org/abs/2511.09740)
*Filip Beránek,Václav Diviš,Ivan Gruber*

Main category: cs.CV

> 文章提出将汽车摄像头的污垢检测问题作为分割问题来解决，并在Woodscape数据集上展示了分割方法的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 为了提高高级驾驶辅助系统对外界条件的鲁棒性，如天气、灰尘等，研究关注于汽车摄像头的污垢检测。

**Method:** Structure

**Result:** 通过详细比较不同分割方法并修正Woodscape数据集中的问题，研究展示了分割方法优于拼图级别的分类方法，并创建了一个更小但足够有效的数据子集，减少了训练时间。

**Conclusion:** 所有的代码和数据集划分均可在https://github.com/filipberanek/woodscape_revision获取，这表明研究提供了一种高效的数据子集和成功的分割方法。

**Abstract:** Soiling detection for automotive cameras is a crucial part of advanced driver assistance systems to make them more robust to external conditions like weather, dust, etc. In this paper, we regard the soiling detection as a semantic segmentation problem. We provide a comprehensive comparison of popular segmentation methods and show their superiority in performance while comparing them to tile-level classification approaches. Moreover, we present an extensive analysis of the Woodscape dataset showing that the original dataset contains a data-leakage and imprecise annotations. To address these problems, we create a new data subset, which, despite being much smaller, provides enough information for the segmentation method to reach comparable results in a much shorter time. All our codes and dataset splits are available at https://github.com/filipberanek/woodscape_revision.

</details>


### [51] [Feature Quality and Adaptability of Medical Foundation Models: A Comparative Evaluation for Radiographic Classification and Segmentation](https://arxiv.org/abs/2511.09742)
*Frank Li,Theo Dapamede,Mohammadreza Chavoshi,Young Seok Jeon,Bardia Khosravi,Abdulhameed Dere,Beatrice Brown-Mulry,Rohan Satya Isaac,Aawez Mansuri,Chiratidzo Sanyika,Janice Newsome,Saptarshi Purkayastha,Imon Banerjee,Hari Trivedi,Judy Gichoya*

Main category: cs.CV

> 本文评估了不同领域的基础模型在医学图像分析中的作用，发现医学预训练优于通用预训练，但对于细微疾病定位任务，基础模型仍需显著微调，甚至是监督学习模型表现更好。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探讨预训练领域（医学vs.通用）、范式（例如，文本指导）和架构如何影响嵌入质量，以此来选择最适合特定放射学任务的最优编码器。

**Method:** 本文评估了八个医学和通用领域的基础模型的视觉编码器在胸部X光图像分析中的表现，包括分类（气胸、心脏扩大）和分割（气胸、心脏边界）任务。采用线性探测和微调两种方式进行了基准测试。

**Result:** 结果显示，领域特定的预训练提供了显着的优势；医学基础模型在线性探测中一致优于通用领域模型，显示出初始特征质量更优。然而，特征的实用性高度依赖于任务。预训练嵌入对于全局分类和分割显着解剖结构（如心脏）表现良好。但是，对于分割复杂、微妙的病理特征（如气胸）时，所有基础模型在没有显著微调的情况下表现都很差，显示出在定位微妙疾病上的重大差距。

**Conclusion:** 研究表明，尽管医学预训练是有益的，但架构选择（例如多尺度）至关重要，并且预训练特征不是普遍有效的，特别是在复杂的定位任务中，监督学习模型仍是一个强大的选择。

**Abstract:** Foundation models (FMs) promise to generalize medical imaging, but their effectiveness varies. It remains unclear how pre-training domain (medical vs. general), paradigm (e.g., text-guided), and architecture influence embedding quality, hindering the selection of optimal encoders for specific radiology tasks. To address this, we evaluate vision encoders from eight medical and general-domain FMs for chest X-ray analysis. We benchmark classification (pneumothorax, cardiomegaly) and segmentation (pneumothorax, cardiac boundary) using linear probing and fine-tuning. Our results show that domain-specific pre-training provides a significant advantage; medical FMs consistently outperformed general-domain models in linear probing, establishing superior initial feature quality. However, feature utility is highly task-dependent. Pre-trained embeddings were strong for global classification and segmenting salient anatomy (e.g., heart). In contrast, for segmenting complex, subtle pathologies (e.g., pneumothorax), all FMs performed poorly without significant fine-tuning, revealing a critical gap in localizing subtle disease. Subgroup analysis showed FMs use confounding shortcuts (e.g., chest tubes for pneumothorax) for classification, a strategy that fails for precise segmentation. We also found that expensive text-image alignment is not a prerequisite; image-only (RAD-DINO) and label-supervised (Ark+) FMs were among top performers. Notably, a supervised, end-to-end baseline remained highly competitive, matching or exceeding the best FMs on segmentation tasks. These findings show that while medical pre-training is beneficial, architectural choices (e.g., multi-scale) are critical, and pre-trained features are not universally effective, especially for complex localization tasks where supervised models remain a strong alternative.

</details>


### [52] [Gradient-Guided Exploration of Generative Model's Latent Space for Controlled Iris Image Augmentations](https://arxiv.org/abs/2511.09749)
*Mahsa Mitcheff,Siamul Karim Khan,Adam Czajka*

Main category: cs.CV

> 本文提出一种新的虹膜图像增强策略，使用生成模型的隐空间来控制和生成同一身份虹膜图像的特定属性，同时保持身份不变。该方法高度灵活，可用于增强虹膜识别和防伪检测系统。

<details>
  <summary>Details</summary>

**Motivation:** 开发可靠的虹膜识别和防伪检测方法需要多种数据集，以捕捉虹膜特征的真实变化和广泛的异常情况。然而，由于虹膜图像的丰富纹理，生成同一身份的虹膜图像同时控制特定属性仍然是一项挑战。因此，本文提出了一种新的方法来克服这一挑战。

**Method:** 本文提出了一种新的虹膜图像增强策略，通过遍历生成模型的隐空间来生成同一身份但具有特定虹膜图像属性的样本。这种遍历由特定几何、纹理或质量相关虹膜图像特征（如清晰度、瞳孔大小、虹膜大小或瞳孔与虹膜的比例）的梯度指导，同时保留图像的身份特征。

**Result:** 该方法可以轻松扩展到任何可以通过制定可微分损失项来操作的属性，并且可以利用预训练的GAN模型生成的随机图像或是现实世界的虹膜图像。此外，还可以使用GAN反转技术将任意给定的虹膜图像投影到隐空间中并获得相应的隐代码。

**Conclusion:** 该研究成功展示了基于生成模型的隐空间遍历技术在虹膜图像合成方面的有效性，这一技术能够生成具有特定属性的同一身份的虹膜图像，这对于虹膜识别和防伪检测系统的开发具有重要意义。

**Abstract:** Developing reliable iris recognition and presentation attack detection methods requires diverse datasets that capture realistic variations in iris features and a wide spectrum of anomalies. Because of the rich texture of iris images, which spans a wide range of spatial frequencies, synthesizing same-identity iris images while controlling specific attributes remains challenging. In this work, we introduce a new iris image augmentation strategy by traversing a generative model's latent space toward latent codes that represent same-identity samples but with some desired iris image properties manipulated. The latent space traversal is guided by a gradient of specific geometrical, textural, or quality-related iris image features (e.g., sharpness, pupil size, iris size, or pupil-to-iris ratio) and preserves the identity represented by the image being manipulated. The proposed approach can be easily extended to manipulate any attribute for which a differentiable loss term can be formulated. Additionally, our approach can use either randomly generated images using either a pre-train GAN model or real-world iris images. We can utilize GAN inversion to project any given iris image into the latent space and obtain its corresponding latent code.

</details>


### [53] [STORM: Segment, Track, and Object Re-Localization from a Single 3D Model](https://arxiv.org/abs/2511.09771)
*Yu Deng,Teng Cao,Hikaru Shindo,Jiahong Xue,Quentin Delfosse,Kristian Kersting*

Main category: cs.CV

> STORM is a real-time, annotation-free 6D pose estimation system that uses a three-stage pipeline and automatic re-registration to achieve high accuracy under challenging conditions.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for STORM is to address the labor-intensive nature of manual annotation and the performance degradation caused by occlusions or rapid movement in existing 6D pose estimation systems.

**Method:** STORM employs a novel three-stage pipeline mixing vision-language understanding with self-supervised feature matching and uses an automatic re-registration mechanism to detect and recover from tracking failures.

**Result:** STORM achieves state-of-the-art accuracy on challenging datasets featuring multi-object occlusions, high-speed motion, and varying illumination while operating in real-time.

**Conclusion:** The proposed system, STORM, provides a practical solution for modern applications such as flexible manufacturing and intelligent quality control by reducing deployment overhead and improving performance even during occlusions or rapid motion.

**Abstract:** Accurate 6D pose estimation and tracking are fundamental capabilities for physical AI systems such as robots. However, existing approaches typically rely on a manually annotated segmentation mask of the target in the first frame, which is labor-intensive and leads to reduced performance when faced with occlusions or rapid movement. To address these limi- tations, we propose STORM (Segment, Track, and Object Re-localization from a single 3D Model), an open-source robust real-time 6D pose estimation system that requires no manual annotation. STORM employs a novel three-stage pipeline combining vision-language understanding with self-supervised feature matching: contextual object descriptions guide localization, self-cross-attention mechanisms identify candidate regions, and a segmentation model produces precise masks for accurate pose estimation. Another key innovation is our automatic re-registration mechanism that detects tracking failures through feature similarity monitoring and recovers from severe occlusions or rapid motion. STORM achieves state-of-the-art accuracy on challenging industrial datasets featuring multi-object occlusions, high-speed motion, and varying illumination, while operating at real-time speeds without additional training. This annotation-free approach significantly reduces deployment overhead, providing a practical solution for modern applications, such as flexible manufacturing and intelligent quality control.

</details>


### [54] [PANDA - Patch And Distribution-Aware Augmentation for Long-Tailed Exemplar-Free Continual Learning](https://arxiv.org/abs/2511.09791)
*Siddeshwar Raghavan,Jiangpeng He,Fengqing Zhu*

Main category: cs.CV

> PANDA, a Patch-and-Distribution-Aware Augmentation framework, addresses the issue of data imbalance in Exemplar-Free Continual Learning (EFCL), improving accuracy and reducing catastrophic forgetting.

<details>
  <summary>Details</summary>

**Motivation:** The paper aims to tackle the significant problem of dataset-level and intra-task imbalances that current EFCL systems are unable to fully resolve, especially when utilizing pre-trained models.

**Method:** PANDA leverages a CLIP encoder to identify key regions in underrepresented classes and integrates them into samples of overrepresented classes within tasks. It also employs an adaptive balancing approach based on prior task distributions to alleviate imbalances across tasks.

**Result:** Experimental and ablation analyses show that PANDA effectively works with PTM-based EFCL methods, resulting in better accuracy and reduced harmful forgetting.

**Conclusion:** The study concludes that PANDA successfully mitigates the data imbalance problem in EFCL systems, leading to enhanced performance and a more equitable learning across different tasks.

**Abstract:** Exemplar-Free Continual Learning (EFCL) restricts the storage of previous task data and is highly susceptible to catastrophic forgetting. While pre-trained models (PTMs) are increasingly leveraged for EFCL, existing methods often overlook the inherent imbalance of real-world data distributions. We discovered that real-world data streams commonly exhibit dual-level imbalances, dataset-level distributions combined with extreme or reversed skews within individual tasks, creating both intra-task and inter-task disparities that hinder effective learning and generalization. To address these challenges, we propose PANDA, a Patch-and-Distribution-Aware Augmentation framework that integrates seamlessly with existing PTM-based EFCL methods. PANDA amplifies low-frequency classes by using a CLIP encoder to identify representative regions and transplanting those into frequent-class samples within each task. Furthermore, PANDA incorporates an adaptive balancing strategy that leverages prior task distributions to smooth inter-task imbalances, reducing the overall gap between average samples across tasks and enabling fairer learning with frozen PTMs. Extensive experiments and ablation studies demonstrate PANDA's capability to work with existing PTM-based CL methods, improving accuracy and reducing catastrophic forgetting.

</details>


### [55] [Test-Time Spectrum-Aware Latent Steering for Zero-Shot Generalization in Vision-Language Models](https://arxiv.org/abs/2511.09809)
*Konstantinos M. Dafnis,Dimitris N. Metaxas*

Main category: cs.CV

> STS: a lightweight, efficient method for test-time adaptation of Vision-Language Models that improves performance under domain shifts without modifying model weights.

<details>
  <summary>Details</summary>

**Motivation:** To improve Vision-Language Models' performance under test-time domain shifts without requiring backpropagation through large encoder weights or altering core model components.

**Method:** Spectrum-Aware Test-Time Steering (STS), a lightweight framework that extracts a spectral subspace from textual embeddings and adapts a small number of per-sample shift parameters to steer latent representations spectrum-awarely in the latent space without modifying the frozen encoders.

**Result:** STS outperforms or compares favorably to state-of-the-art test-time adaptation methods, with minimal additional parameters and significantly faster inference speeds.

**Conclusion:** STS is an efficient, lightweight method for adapting Vision-Language Models to new domains at test time, achieving better performance with minimal computational overhead.

**Abstract:** Vision-Language Models (VLMs) excel at zero-shot inference but often degrade under test-time domain shifts. For this reason, episodic test-time adaptation strategies have recently emerged as powerful techniques for adapting VLMs to a single unlabeled image. However, existing adaptation strategies, such as test-time prompt tuning, typically require backpropagating through large encoder weights or altering core model components. In this work, we introduce Spectrum-Aware Test-Time Steering (STS), a lightweight adaptation framework that extracts a spectral subspace from the textual embeddings to define principal semantic directions and learns to steer latent representations in a spectrum-aware manner by adapting a small number of per-sample shift parameters to minimize entropy across augmented views. STS operates entirely at inference in the latent space, without backpropagation through or modification of the frozen encoders. Building on standard evaluation protocols, our comprehensive experiments demonstrate that STS largely surpasses or compares favorably against state-of-the-art test-time adaptation methods, while introducing only a handful of additional parameters and achieving inference speeds up to 8x faster with a 12x smaller memory footprint than conventional test-time prompt tuning. The code is available at https://github.com/kdafnis/STS.

</details>


### [56] [Lumos3D: A Single-Forward Framework for Low-Light 3D Scene Restoration](https://arxiv.org/abs/2511.09818)
*Hanzhou Liu,Peng Jiang,Jia Huang,Mi Lu*

Main category: cs.CV

> Lumos3D是一个可泛化的姿态无关框架，用于3D低光场景恢复，无需场景特训或优化即可从无姿态的低光多视角图像恢复光照和结构。

<details>
  <summary>Details</summary>

**Motivation:** Lumos3D旨在解决现有方法依赖预先计算的相机姿态和场景特定优化，这极大限制了它们在动态真实世界环境中的可扩展性。

**Method:** Lumos3D采用了基于几何的骨干构建方法，使用了一种跨光照蒸馏方案进行训练，并引入了Lumos损失来促进重建3D空间的光度一致性。

**Result:** 实验表明Lumos3D在真实世界数据集上达到了高保真的低光照3D场景恢复，具有准确的几何图形和对未见案例的强大泛化能力。

**Conclusion:** 该框架展示了处理多种照明恢复任务的灵活性，并可自然扩展用于过曝校正。

**Abstract:** Restoring 3D scenes captured under low-light con- ditions remains a fundamental yet challenging problem. Most existing approaches depend on precomputed camera poses and scene-specific optimization, which greatly restricts their scala- bility to dynamic real-world environments. To overcome these limitations, we introduce Lumos3D, a generalizable pose-free framework for 3D low-light scene restoration. Trained once on a single dataset, Lumos3D performs inference in a purely feed- forward manner, directly restoring illumination and structure from unposed, low-light multi-view images without any per- scene training or optimization. Built upon a geometry-grounded backbone, Lumos3D reconstructs a normal-light 3D Gaussian representation that restores illumination while faithfully pre- serving structural details. During training, a cross-illumination distillation scheme is employed, where the teacher network is distilled on normal-light ground truth to transfer accurate geometric information, such as depth, to the student model. A dedicated Lumos loss is further introduced to promote photomet- ric consistency within the reconstructed 3D space. Experiments on real-world datasets demonstrate that Lumos3D achieves high- fidelity low-light 3D scene restoration with accurate geometry and strong generalization to unseen cases. Furthermore, the framework naturally extends to handle over-exposure correction, highlighting its versatility for diverse lighting restoration tasks.

</details>


### [57] [From Street to Orbit: Training-Free Cross-View Retrieval via Location Semantics and LLM Guidance](https://arxiv.org/abs/2511.09820)
*Jeongho Min,Dongyoung Kim,Jaehyup Lee*

Main category: cs.CV

> 本文提出了一种通过预先训练的视觉编码器和大型语言模型在零样本设置下实现街景到卫星图像匹配的方法，显示出比现有学习方法更好的性能，并能够自动构建相关数据集。

<details>
  <summary>Details</summary>

**Motivation:** 当前的方法通常需要监督训练和特定数据集，并依赖于全景或无人机图像，这些限制了它们在实际环境中的部署。本研究旨在提出一种简单而有效的跨视角图像检索框架，它不需要额外的训练。

**Method:** 通过预先训练的视觉编码器和大规模语言模型（LLM），该方法首先通过网络图像搜索和基于LLM的位置推理从单目街景图像中提取地理线索，然后通过地理编码API生成卫星图像查询，并使用预先训练的视觉编码器（如DINOv2）和PCA特征白化来检索匹配的图像瓦片。

**Result:** 尽管没有使用地面真值监督或微调，该方法在基准数据集的零样本设置下优于现有的学习方法。此外，该方法还能够自动构建语义对齐的街景到卫星图像数据集，提供了一个可扩展且经济高效的替代手动注释的方案。

**Conclusion:** 该研究展示了跨视角图像检索的新可能性，尤其是街景到卫星图像匹配，提供了一种简单有效的零样本解决方案，并开放源码以便进一步研究。

**Abstract:** Cross-view image retrieval, particularly street-to-satellite matching, is a critical task for applications such as autonomous navigation, urban planning, and localization in GPS-denied environments. However, existing approaches often require supervised training on curated datasets and rely on panoramic or UAV-based images, which limits real-world deployment. In this paper, we present a simple yet effective cross-view image retrieval framework that leverages a pretrained vision encoder and a large language model (LLM), requiring no additional training. Given a monocular street-view image, our method extracts geographic cues through web-based image search and LLM-based location inference, generates a satellite query via geocoding API, and retrieves matching tiles using a pretrained vision encoder (e.g., DINOv2) with PCA-based whitening feature refinement. Despite using no ground-truth supervision or finetuning, our proposed method outperforms prior learning-based approaches on the benchmark dataset under zero-shot settings. Moreover, our pipeline enables automatic construction of semantically aligned street-to-satellite datasets, which is offering a scalable and cost-efficient alternative to manual annotation. All source codes will be made publicly available at https://jeonghomin.github.io/street2orbit.github.io/.

</details>


### [58] [AHA! Animating Human Avatars in Diverse Scenes with Gaussian Splatting](https://arxiv.org/abs/2511.09827)
*Aymen Mir,Jian Wang,Riza Alp Guler,Chuan Guo,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

> 研究利用3D高斯散射（3DGS）提出了一种创新的3D场景中人体动画的方法，破解了传统方法在处理人体与场景交互时的限制，实现了视点一致的渲染，为未来单目视频中的人体动画提供了新的思路。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机在于当前用于3D场景中的人体动画的神经场景表示方法尚未完全被探索，3D高斯散射（3DGS）技术虽然在3D场景的新型视角合成中取得了显著的视觉效果，但在整个人体动画领域仍然有待进一步的研究和应用推广。

**Method:** 我们提出了一种使用3D高斯散射（3DGS）来为3D场景中的人体进行动画制作的新框架。该方法不同于现有的使用网格或点云作为3D表示的动画管线，而是引入3DGS作为3D表示。通过将人体和场景表示为高斯分布，我们的方法实现了人体与3D场景交互时的视点一致的自由视角渲染。我们的关键见解是，渲染可以与运动合成解耦，并独立地解决每个子问题，无需配对的人体场景数据。我们的方法核心在于一个高斯对准的运动模块，该模块可以使用不透明度线索和投影的高斯结构来引导人体放置和姿态对齐。为了确保自然交互，我们还提出了一种人体场景高斯优化来强制执行真实的接触和导航。

**Result:** 我们在Scannet++和SuperSplat库中以及从稀疏和密集的多视图人体捕捉中重建的头像上评估了我们的方法。结果显示，我们的框架可以用于一些新颖的应用程序，如几何一致的自由视角渲染编辑的单目RGB视频中的新动画人物，展示了3DGS在单目视频人体动画领域的独特优势。

**Conclusion:** 综上所述，我们的创新方法和实验结果证明了3D高斯散射在实现人体与3D场景交互的几何一致的自由视角渲染方面的能力。这种新颖的方法不仅提高了渲染效果的真实感，也为单目视频中的人体动画提供了更为广泛的应用前景。

**Abstract:** We present a novel framework for animating humans in 3D scenes using 3D Gaussian Splatting (3DGS), a neural scene representation that has recently achieved state-of-the-art photorealistic results for novel-view synthesis but remains under-explored for human-scene animation and interaction. Unlike existing animation pipelines that use meshes or point clouds as the underlying 3D representation, our approach introduces the use of 3DGS as the 3D representation to the problem of animating humans in scenes. By representing humans and scenes as Gaussians, our approach allows for geometry-consistent free-viewpoint rendering of humans interacting with 3D scenes. Our key insight is that the rendering can be decoupled from the motion synthesis and each sub-problem can be addressed independently, without the need for paired human-scene data. Central to our method is a Gaussian-aligned motion module that synthesizes motion without explicit scene geometry, using opacity-based cues and projected Gaussian structures to guide human placement and pose alignment. To ensure natural interactions, we further propose a human-scene Gaussian refinement optimization that enforces realistic contact and navigation. We evaluate our approach on scenes from Scannet++ and the SuperSplat library, and on avatars reconstructed from sparse and dense multi-view human capture. Finally, we demonstrate that our framework allows for novel applications such as geometry-consistent free-viewpoint rendering of edited monocular RGB videos with new animated humans, showcasing the unique advantage of 3DGS for monocular video-based human animation.

</details>


### [59] [CertMask: Certifiable Defense Against Adversarial Patches via Theoretically Optimal Mask Coverage](https://arxiv.org/abs/2511.09834)
*Xuntao Lyu,Ching-Chi Lin,Abdullah Al Arafat,Georg von der Brüggen,Jian-Jia Chen,Zhishan Guo*

Main category: cs.CV

> 本文提出的CertMask方法可通过构建一个可以证明有效的二进制掩码集，高效且稳健地应对图像中的局部对抗攻击。

<details>
  <summary>Details</summary>

**Motivation:** 由于对抗样本能在图像中注入局部扰动从而误导深度视觉模型，并且能在现实中部署，对实际应用造成了严重风险，本文旨在提出一种理论上稳健的防御策略。

**Method:** 本文提出了一种名为CertMask的防御方法，它通过构建一组二进制掩码来中和图像中局部对抗样本的影响，从而保护深度视觉模型。CertMask使用了一种数学上严格的覆盖策略，确保了每个可能的对抗样本位置至少被覆盖了k次。

**Result:** 实验结果展示了CertMask相对于PatchCleanser提升了最多+13.4%的认证鲁棒准确率，同时保持几乎与原始模型相同的准确率。

**Conclusion:** CertMask通过一组经过数学严格认证的掩码来保护图像，不仅提升了鲁棒性，而且比PatchCleanser更加高效。

**Abstract:** Adversarial patch attacks inject localized perturbations into images to mislead deep vision models. These attacks can be physically deployed, posing serious risks to real-world applications. In this paper, we propose CertMask, a certifiably robust defense that constructs a provably sufficient set of binary masks to neutralize patch effects with strong theoretical guarantees. While the state-of-the-art approach (PatchCleanser) requires two rounds of masking and incurs $O(n^2)$ inference cost, CertMask performs only a single round of masking with $O(n)$ time complexity, where $n$ is the cardinality of the mask set to cover an input image. Our proposed mask set is computed using a mathematically rigorous coverage strategy that ensures each possible patch location is covered at least $k$ times, providing both efficiency and robustness. We offer a theoretical analysis of the coverage condition and prove its sufficiency for certification. Experiments on ImageNet, ImageNette, and CIFAR-10 show that CertMask improves certified robust accuracy by up to +13.4\% over PatchCleanser, while maintaining clean accuracy nearly identical to the vanilla model.

</details>


### [60] [CORONA-Fields: Leveraging Foundation Models for Classification of Solar Wind Phenomena](https://arxiv.org/abs/2511.09843)
*Daniela Martin,Jinsu Hong,Connor O'Brien,Valmir P Moraes Filho,Jasmine R. Kobayashi,Evangelia Samara,Joseph Gallego*

Main category: cs.CV

> 研究显示，通过调整最初训练于太阳动力观测站图像的基础模型来分析太阳风结构是可行的，这对未来改进空间天气预测具有支持作用。

<details>
  <summary>Details</summary>

**Motivation:** 随着太阳活动对地球附近卫星以及关键地面基础设施的影响日益增加，太阳风和日冕物质抛射的自动化分类具有挑战性。本研究旨在解决这一挑战。

**Method:** 本研究将原始训练于太阳动力观测站图像的基础模型应用于太阳风结构分析，通过嵌入与航天器位置及太阳磁场连接度结合生成基于神经场的模型。该深度学习架构通过结合遥感和原位观测进行了微调，并利用帕克太阳探测器的测量值作为标签。

**Result:** 研究显示，尽管整体分类性能一般，但证明了利用基础模型嵌入进行太阳风原位任务的可行性。

**Conclusion:** 该研究作为首次概念验证，为未来改进更可靠空间天气预测奠定了基础。

**Abstract:** Space weather at Earth, driven by the solar activity, poses growing risks to satellites around our planet as well as to critical ground-based technological infrastructure. Major space weather contributors are the solar wind and coronal mass ejections whose variable density, speed, temperature, and magnetic field make the automated classification of those structures challenging. In this work, we adapt a foundation model for solar physics, originally trained on Solar Dynamics Observatory imagery, to create embeddings suitable for solar wind structure analysis. These embeddings are concatenated with the spacecraft position and solar magnetic connectivity encoded using Fourier features which generates a neural field-based model. The full deep learning architecture is fine-tuned bridging the gap between remote sensing and in situ observations. Labels are derived from Parker Solar Probe measurements, forming a downstream classification task that maps plasma properties to solar wind structures. Although overall classification performance is modest, likely due to coarse labeling, class imbalance, and limited transferability of the pretrained model, this study demonstrates the feasibility of leveraging foundation model embeddings for in situ solar wind tasks. As a first proof-of-concept, it lays the groundwork for future improvements toward more reliable space weather predictions. The code and configuration files used in this study are publicly available to support reproducibility.

</details>


### [61] [IPCD: Intrinsic Point-Cloud Decomposition](https://arxiv.org/abs/2511.09866)
*Shogo Sato,Takuhiro Kaneko,Shoichiro Takeda,Tomoyasu Shimada,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida,Akisato Kimura*

Main category: cs.CV

> 该研究解决了点云反照率和阴影分解的难题，通过引入IPCD-Net和PLD，提高了在不同光照条件下的点云处理效果。

<details>
  <summary>Details</summary>

**Motivation:** 点云的非网格结构使得传统基于图像的分解模型无法有效处理，同时点云模型未考虑全局光照方向的问题，导致阴影分解不准确。该研究旨在解决这些问题，提高点云在真实感可视化中的应用效果。

**Method:** 该论文提出了Intrinsic Point-Cloud Decomposition (IPCD)方法，用于将彩色点云直接分解为反照率和阴影。为了克服点云非网格结构的问题，提出了IPCD-Net，其扩展了基于图像的模型，实现非网格数据的处理。此外，为了捕捉全局光照信息，引入了基于投影的亮度分布(PLD)，通过多视角投影进行分层特征优化。

**Result:** 实验结果表明，IPCD-Net可以减少反照率中投射的阴影，并提高了阴影中颜色的准确性。应用方面，该方法广泛应用于纹理编辑、重光照和受不同光照影响的点云配准。

**Conclusion:** IPCD和IPCD-Net为点云的反照率和阴影分解提供了一个有效的方法，解决了点云非网格结构和全局光照方向捕捉的问题，并通过实验验证了其在实际应用中的有效性。

**Abstract:** Point clouds are widely used in various fields, including augmented reality (AR) and robotics, where relighting and texture editing are crucial for realistic visualization. Achieving these tasks requires accurately separating albedo from shade. However, performing this separation on point clouds presents two key challenges: (1) the non-grid structure of point clouds makes conventional image-based decomposition models ineffective, and (2) point-cloud models designed for other tasks do not explicitly consider global-light direction, resulting in inaccurate shade. In this paper, we introduce \textbf{Intrinsic Point-Cloud Decomposition (IPCD)}, which extends image decomposition to the direct decomposition of colored point clouds into albedo and shade. To overcome challenge (1), we propose \textbf{IPCD-Net} that extends image-based model with point-wise feature aggregation for non-grid data processing. For challenge (2), we introduce \textbf{Projection-based Luminance Distribution (PLD)} with a hierarchical feature refinement, capturing global-light ques via multi-view projection. For comprehensive evaluation, we create a synthetic outdoor-scene dataset. Experimental results demonstrate that IPCD-Net reduces cast shadows in albedo and enhances color accuracy in shade. Furthermore, we showcase its applications in texture editing, relighting, and point-cloud registration under varying illumination. Finally, we verify the real-world applicability of IPCD-Net.

</details>


### [62] [Remember Me: Bridging the Long-Range Gap in LVLMs with Three-Step Inference-Only Decay Resilience Strategies](https://arxiv.org/abs/2511.09868)
*Peng Gao,Yujian Lee,Xiaofeng Zhang,Zailong Chen,Hui Zhang*

Main category: cs.CV

> 本文提出了用于推理阶段的长期依赖衰减恢复方法（T-DRS），以解决大型视觉-语言模型在使用旋转位置编码时长期标记对注意力的衰退问题，这三阶段策略通过恢复远程信号有效提升了模型的全局连贯性和性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型视觉-语言模型（LVLMs）在处理长距离依赖时面临挑战，特别是旋转位置编码（ROPE）的使用会导致注意力随着标记距离的增加而逐渐衰减，严重损害模型记住全局上下文的能力。

**Method:** 我们提出了三种推理阶段的衰减恢复策略（T-DRS）：1. 语义驱动的衰减恢复策略（SD-DRS），通过内容感知的残差增强语义上重要但距离较远的信号；2. 距离感知控制衰减恢复策略（DC-DRS），通过基于位置距离的平滑调节权重来净化注意力，抑制噪音同时保留局部性；3. 重增强远距离衰减恢复策略（reRD-DRS），巩固剩下的有意义的远程依赖以保持全局一致性。这些策略在不损害局部归纳偏差的情况下恢复被抑制的长距离标记对。

**Result:** 在视觉问答（VQA）基准测试上的广泛实验表明，T-DRS能够在不进行训练的情况下持续提升模型性能。

**Conclusion:** 这项工作通过提出三种推理阶段的衰减恢复策略（T-DRS）显著提升了大型视觉-语言模型处理长距离依赖的能力，并且这些策略在不需要训练的情况下实现了性能的提升。

**Abstract:** Large Vision-Language Models (LVLMs) have achieved impressive performance across a wide range of multimodal tasks. However, they still face critical challenges in modeling long-range dependencies under the usage of Rotary Positional Encoding (ROPE). Although it can facilitate precise modeling of token positions, it induces progressive attention decay as token distance increases, especially with progressive attention decay over distant token pairs, which severely impairs the model's ability to remember global context. To alleviate this issue, we propose inference-only Three-step Decay Resilience Strategies (T-DRS), comprising (1) Semantic-Driven DRS (SD-DRS), amplifying semantically meaningful but distant signals via content-aware residuals, (2) Distance-aware Control DRS (DC-DRS), which can purify attention by smoothly modulating weights based on positional distances, suppressing noise while preserving locality, and (3) re-Reinforce Distant DRS (reRD-DRS), consolidating the remaining informative remote dependencies to maintain global coherence. Together, the T-DRS recover suppressed long-range token pairs without harming local inductive biases. Extensive experiments on Vision Question Answering (VQA) benchmarks demonstrate that T-DRS can consistently improve performance in a training-free manner. The code can be accessed in https://github.com/labixiaoq-qq/Remember-me

</details>


### [63] [SAM-DAQ: Segment Anything Model with Depth-guided Adaptive Queries for RGB-D Video Salient Object Detection](https://arxiv.org/abs/2511.09870)
*Jia Lin,Xiaofei Zhou,Jiyuan Liu,Runmin Cong,Guodao Zhang,Zhi Liu,Jiyong Zhang*

Main category: cs.CV

> A new method called SAM-DAQ improves the Segment Anything Model for RGB-D video salient object detection by integrating a parallel adapter for depth and temporal cues, and outperforms state-of-the-art techniques.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the limitations of SAM in RGB-D VSOD tasks, such as heavy reliance on manual prompts, high memory consumption of sequential adapters, and the computational burden of memory attention.

**Method:** The paper proposes a novel method called SAM-DAQ, which includes the deployment of a parallel adapter-based multi-modal image encoder (PAMIE) and a query-driven temporal memory (QTM) module to enhance the Segment Anything Model (SAM) for RGB-D video salient object detection (RGB-D VSOD).

**Result:** Experiments on three RGB-D VSOD datasets show that SAM-DAQ outperforms existing methods across all evaluation metrics.

**Conclusion:** SAM-DAQ effectively addresses the challenges faced by the Segment Anything Model in RGB-D VSOD tasks and achieves superior performance compared to other methods.

**Abstract:** Recently segment anything model (SAM) has attracted widespread concerns, and it is often treated as a vision foundation model for universal segmentation. Some researchers have attempted to directly apply the foundation model to the RGB-D video salient object detection (RGB-D VSOD) task, which often encounters three challenges, including the dependence on manual prompts, the high memory consumption of sequential adapters, and the computational burden of memory attention. To address the limitations, we propose a novel method, namely Segment Anything Model with Depth-guided Adaptive Queries (SAM-DAQ), which adapts SAM2 to pop-out salient objects from videos by seamlessly integrating depth and temporal cues within a unified framework. Firstly, we deploy a parallel adapter-based multi-modal image encoder (PAMIE), which incorporates several depth-guided parallel adapters (DPAs) in a skip-connection way. Remarkably, we fine-tune the frozen SAM encoder under prompt-free conditions, where the DPA utilizes depth cues to facilitate the fusion of multi-modal features. Secondly, we deploy a query-driven temporal memory (QTM) module, which unifies the memory bank and prompt embeddings into a learnable pipeline. Concretely, by leveraging both frame-level queries and video-level queries simultaneously, the QTM module can not only selectively extract temporal consistency features but also iteratively update the temporal representations of the queries. Extensive experiments are conducted on three RGB-D VSOD datasets, and the results show that the proposed SAM-DAQ consistently outperforms state-of-the-art methods in terms of all evaluation metrics.

</details>


### [64] [RWKV-PCSSC: Exploring RWKV Model for Point Cloud Semantic Scene Completion](https://arxiv.org/abs/2511.09878)
*Wenzhe He,Xiaojun Chen,Wentang Chen,Hongyu Wang,Ying Liu,Ruihui Li*

Main category: cs.CV

> 本文提出RWKV-PCSSC，通过轻量化点云语义场景补全网络，提高了模型的效率和性能。

<details>
  <summary>Details</summary>

**Motivation:** 针对现有方法使用密集网络架构导致模型复杂度高、资源需求大的问题，提出了一种轻量级的解决方案。

**Method:** RWKV-PCSSC采用轻量化的点云语义场景补全网络，通过RWKV Seed Generator模块从部分点云中聚集特征生成粗略点云，并且通过RWKV Point Deconvolution模块逐步恢复点云的点特征。

**Result:** 实验结果显示，RWKV-PCSSC在参数量上减少了4.18倍，内存效率提高了1.37倍，并且在多个室内和室外场景数据集上达到了最先进的性能。

**Conclusion:** 通过对部分点云的特征进行聚合生成粗略点云，并逐步恢复点特征，RWKV-PCSSC在减少参数量和内存消耗的同时取得了优秀的性能。

**Abstract:** Semantic Scene Completion (SSC) aims to generate a complete semantic scene from an incomplete input. Existing approaches often employ dense network architectures with a high parameter count, leading to increased model complexity and resource demands. To address these limitations, we propose RWKV-PCSSC, a lightweight point cloud semantic scene completion network inspired by the Receptance Weighted Key Value (RWKV) mechanism. Specifically, we introduce a RWKV Seed Generator (RWKV-SG) module that can aggregate features from a partial point cloud to produce a coarse point cloud with coarse features. Subsequently, the point-wise feature of the point cloud is progressively restored through multiple stages of the RWKV Point Deconvolution (RWKV-PD) modules. By leveraging a compact and efficient design, our method achieves a lightweight model representation. Experimental results demonstrate that RWKV-PCSSC reduces the parameter count by 4.18$\times$ and improves memory efficiency by 1.37$\times$ compared to state-of-the-art methods PointSSC. Furthermore, our network achieves state-of-the-art performance on established indoor (SSC-PC, NYUCAD-PC) and outdoor (PointSSC) scene dataset, as well as on our proposed datasets (NYUCAD-PC-V2, 3D-FRONT-PC).

</details>


### [65] [HCC-3D: Hierarchical Compensatory Compression for 98% 3D Token Reduction in Vision-Language Models](https://arxiv.org/abs/2511.09883)
*Liheng Zhang,Jin Wang,Hui Li,Bingfeng Zhang,Weifeng Liu*

Main category: cs.CV

> Introduction of HCC-3D for efficient 3D token compression in Vision-Language Models (VLMs), achieving high compression rates and improved performance in 3D understanding tasks.

<details>
  <summary>Details</summary>

**Motivation:** The need to address the high computational demands of current 3D-VLMs by reducing the overhead associated with 3D tokens while preserving their essential structure, facilitating broader applications of 3D-VLMs.

**Method:** Hierarchical Compensatory Compression (HCC-3D) is used to effectively compress 3D tokens while maintaining key details. It includes global structure compression (GSC) and adaptive detail mining (ADM) to retain essential information while reducing computational effort.

**Result:** Experiments show HCC-3D achieves a compression ratio of about 98% and state-of-the-art performance, proving significant gains in efficiency and performance.

**Conclusion:** The method successfully reduces computational costs in 3D-VLMs while maintaining high performance, opening new avenues in the field of 3D understanding.

**Abstract:** 3D understanding has drawn significant attention recently, leveraging Vision-Language Models (VLMs) to enable multi-modal reasoning between point cloud and text data. Current 3D-VLMs directly embed the 3D point clouds into 3D tokens, following large 2D-VLMs with powerful reasoning capabilities. However, this framework has a great computational cost limiting its application, where we identify that the bottleneck lies in processing all 3D tokens in the Large Language Model (LLM) part. This raises the question: how can we reduce the computational overhead introduced by 3D tokens while preserving the integrity of their essential information? To address this question, we introduce Hierarchical Compensatory Compression (HCC-3D) to efficiently compress 3D tokens while maintaining critical detail retention. Specifically, we first propose a global structure compression (GSC), in which we design global queries to compress all 3D tokens into a few key tokens while keeping overall structural information. Then, to compensate for the information loss in GSC, we further propose an adaptive detail mining (ADM) module that selectively recompresses salient but under-attended features through complementary scoring. Extensive experiments demonstrate that HCC-3D not only achieves extreme compression ratios (approximately 98%) compared to previous 3D-VLMs, but also achieves new state-of-the-art performance, showing the great improvements on both efficiency and performance.

</details>


### [66] [Scale-Aware Relay and Scale-Adaptive Loss for Tiny Object Detection in Aerial Images](https://arxiv.org/abs/2511.09891)
*Jinfu Li,Yuqi Huang,Hong Song,Ting Wang,Jianghan Xia,Yucong Lin,Jingfan Fan,Jian Yang*

Main category: cs.CV

> Paper presents SARL and SAL for better tiny object detection in aerial images, improving accuracy and robustness.

<details>
  <summary>Details</summary>

**Motivation:** Modern object detection models struggle with tiny objects in aerial images due to feature degradation and uneven training penalties.

**Method:** SARL (Scale-Aware Relay Layer) employs cross-scale spatial-channel attention to enrich features, and SAL (Scale-Adaptive Loss) adjusts loss weights for different object sizes.

**Result:** Experiments on AI-TOD, DOTA-v2.0, and VisDrone2019 show improved detection of tiny objects in aerial images.

**Conclusion:** The proposed methods enhance the average precision by 5.5% and the performance on noisy datasets by 29.0% AP, demonstrating robustness and generalization improvements.

**Abstract:** Recently, despite the remarkable advancements in object detection, modern detectors still struggle to detect tiny objects in aerial images. One key reason is that tiny objects carry limited features that are inevitably degraded or lost during long-distance network propagation. Another is that smaller objects receive disproportionately greater regression penalties than larger ones during training. To tackle these issues, we propose a Scale-Aware Relay Layer (SARL) and a Scale-Adaptive Loss (SAL) for tiny object detection, both of which are seamlessly compatible with the top-performing frameworks. Specifically, SARL employs a cross-scale spatial-channel attention to progressively enrich the meaningful features of each layer and strengthen the cross-layer feature sharing. SAL reshapes the vanilla IoU-based losses so as to dynamically assign lower weights to larger objects. This loss is able to focus training on tiny objects while reducing the influence on large objects. Extensive experiments are conducted on three benchmarks (\textit{i.e.,} AI-TOD, DOTA-v2.0 and VisDrone2019), and the results demonstrate that the proposed method boosts the generalization ability by 5.5\% Average Precision (AP) when embedded in YOLOv5 (anchor-based) and YOLOx (anchor-free) baselines. Moreover, it also promotes the robust performance with 29.0\% AP on the real-world noisy dataset (\textit{i.e.,} AI-TOD-v2.0).

</details>


### [67] [Regional Attention-Enhanced Swin Transformer for Clinically Relevant Medical Image Captioning](https://arxiv.org/abs/2511.09893)
*Zubia Naz,Farhan Asghar,Muhammad Ishfaq Hussain,Yahya Hadadi,Muhammad Aasim Rafique,Wookjin Choi,Moongu Jeon*

Main category: cs.CV

> 本研究提出了一种自动化医学图像标注技术，通过引入Swin-BART编码-解码结构与一个轻量级区域注意力模块，实现了在保持紧凑性和可解释性的同时达到语义保真度的最先进水平。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机是实现一种自动化的医学图像标注技术，该技术可以将复杂的医学影像转化为诊断报告中的叙述，支持现有的报告工作流程。

**Method:** 我们提出了一种基于Swin-BART的编码-解码系统，并加入了一个轻量级的区域注意力模块，该模块可以在跨注意力之前放大诊断上重要的区域。方法主要是通过对复杂的放射学图像进行自动标注，生成诊断性的描述。

**Result:** 实验在ROCO数据集上进行，结果显示，与基线模型相比，我们的方法在ROUGE和BERTScore指标上有显著提升，同时在BLEU，CIDEr，METEOR指标上保持竞争力。

**Conclusion:** 该研究的方法可以生成准确的、临床语言的标注，并提供了透明的区域归因信息，支持在人类监督下的安全使用。

**Abstract:** Automated medical image captioning translates complex radiological images into diagnostic narratives that can support reporting workflows. We present a Swin-BART encoder-decoder system with a lightweight regional attention module that amplifies diagnostically salient regions before cross-attention. Trained and evaluated on ROCO, our model achieves state-of-the-art semantic fidelity while remaining compact and interpretable. We report results as mean$\pm$std over three seeds and include $95\%$ confidence intervals. Compared with baselines, our approach improves ROUGE (proposed 0.603, ResNet-CNN 0.356, BLIP2-OPT 0.255) and BERTScore (proposed 0.807, BLIP2-OPT 0.645, ResNet-CNN 0.623), with competitive BLEU, CIDEr, and METEOR. We further provide ablations (regional attention on/off and token-count sweep), per-modality analysis (CT/MRI/X-ray), paired significance tests, and qualitative heatmaps that visualize the regions driving each description. Decoding uses beam search (beam size $=4$), length penalty $=1.1$, $no\_repeat\_ngram\_size$ $=3$, and max length $=128$. The proposed design yields accurate, clinically phrased captions and transparent regional attributions, supporting safe research use with a human in the loop.

</details>


### [68] [Simulating Distribution Dynamics: Liquid Temporal Feature Evolution for Single-Domain Generalized Object Detection](https://arxiv.org/abs/2511.09909)
*Zihao Zhang,Yang Li,Aming Wu,Yahong Han*

Main category: cs.CV

> This paper presents a method for Single-Domain Generalized Object Detection that simulates continuous cross-domain feature evolution through temporal modeling and liquid parameter adjustment, overcoming the limitations of static and discrete feature perturbations.

<details>
  <summary>Details</summary>

**Motivation:** To address the limitations of existing Single-DGOD methods which rely on discrete data augmentation or static perturbation, which fail to capture dynamic variation of feature distributions under continuous and gradual domain shifts.

**Method:** Liquid Temporal Feature Evolution, incorporating temporal modeling and liquid neural network-driven parameter adjustment, with controllable Gaussian noise injection and multi-scale Gaussian blurring for initial feature perturbations.

**Result:** Significant performance improvements were observed on the Diverse Weather dataset and Real-to-Art benchmark, demonstrating the effectiveness of the proposed method.

**Conclusion:** The Liquid Temporal Feature Evolution method enhances the model's ability to perceive fine-grained cross-domain differences and adapts smoothly and continuously across domains, thus bridging the source-unknown domain distribution gap and improving generalization and robustness to unseen shifts.

**Abstract:** In this paper, we focus on Single-Domain Generalized Object Detection (Single-DGOD), aiming to transfer a detector trained on one source domain to multiple unknown domains. Existing methods for Single-DGOD typically rely on discrete data augmentation or static perturbation methods to expand data diversity, thereby mitigating the lack of access to target domain data. However, in real-world scenarios such as changes in weather or lighting conditions, domain shifts often occur continuously and gradually. Discrete augmentations and static perturbations fail to effectively capture the dynamic variation of feature distributions, thereby limiting the model's ability to perceive fine-grained cross-domain differences. To this end, we propose a new method, Liquid Temporal Feature Evolution, which simulates the progressive evolution of features from the source domain to simulated latent distributions by incorporating temporal modeling and liquid neural network-driven parameter adjustment. Specifically, we introduce controllable Gaussian noise injection and multi-scale Gaussian blurring to simulate initial feature perturbations, followed by temporal modeling and a liquid parameter adjustment mechanism to generate adaptive modulation parameters, enabling a smooth and continuous adaptation across domains. By capturing progressive cross-domain feature evolution and dynamically regulating adaptation paths, our method bridges the source-unknown domain distribution gap, significantly boosting generalization and robustness to unseen shifts. Significant performance improvements on the Diverse Weather dataset and Real-to-Art benchmark demonstrate the superiority of our method. Our code is available at https://github.com/2490o/LTFE.

</details>


### [69] [MosaicDoc: A Large-Scale Bilingual Benchmark for Visually Rich Document Understanding](https://arxiv.org/abs/2511.09919)
*Ketong Chen,Yuhao Chen,Yang Xue*

Main category: cs.CV

> 研究团队开发了DocWeaver，用于自动生成评估视觉丰富文档理解能力的新基准MosaicDoc，后者是一个大规模的双语资源，设定了该领域的全新标准。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试主要以英语为中心，布局简单，支持的任务类型有限，无法充分评估视觉语言模型在处理视觉丰富文档理解（VRDU）方面的能力。

**Method:** 本研究通过引入DocWeaver这一新型多代理管道来解决现有评估基准的问题，该管道利用大型语言模型自动生成新的评估基准。

**Result:** MosaicDoc包含72,000张图片和超过600,000个问答对，可以充分测试现有模型处理复杂文档的能力。评估结果揭示了这些模型在处理现实生活中的复杂文档时的局限性。

**Conclusion:** 通过MosaicDoc的引入，为评估视觉语言模型处理视觉丰富文档的能力设定了新标准，并为未来的模型改进研究指明了方向。

**Abstract:** Despite the rapid progress of Vision-Language Models (VLMs), their capabilities are inadequately assessed by existing benchmarks, which are predominantly English-centric, feature simplistic layouts, and support limited tasks. Consequently, they fail to evaluate model performance for Visually Rich Document Understanding (VRDU), a critical challenge involving complex layouts and dense text. To address this, we introduce DocWeaver, a novel multi-agent pipeline that leverages Large Language Models to automatically generate a new benchmark. The result is MosaicDoc, a large-scale, bilingual (Chinese and English) resource designed to push the boundaries of VRDU. Sourced from newspapers and magazines, MosaicDoc features diverse and complex layouts (including multi-column and non-Manhattan), rich stylistic variety from 196 publishers, and comprehensive multi-task annotations (OCR, VQA, reading order, and localization). With 72K images and over 600K QA pairs, MosaicDoc serves as a definitive benchmark for the field. Our extensive evaluation of state-of-the-art models on this benchmark reveals their current limitations in handling real-world document complexity and charts a clear path for future research.

</details>


### [70] [Compensating Distribution Drifts in Class-incremental Learning of Pre-trained Vision Transformers](https://arxiv.org/abs/2511.09926)
*Xuan Rao,Simian Xu,Zheng Li,Bo Zhao,Derong Liu,Mingming Ha,Cesare Alippi*

Main category: cs.CV

> 研究提出了SLDC方法来减轻序列微调Vision Transformers中的分布偏移问题，该方法在标准增量学习基准上显著提高了性能，接近联合训练的效果。

<details>
  <summary>Details</summary>

**Motivation:** 解决预训练的Vision Transformers(维特)进行序列微调后，由于共享骨干参数的逐序列优化引起的分布偏移问题，导致先前学习类别与更新模型之间的特征分布不匹配，从而降低分类器性能的问题。

**Method:** 提出Sequential Learning with Drift Compensation (SLDC)方法，包括线性和弱非线性的变体，通过学习一个线性/弱非线性变换器来映射微调前后的特征，并结合知识蒸馏减少表示偏移。

**Result:** 该研究针对序列微调(ViT)后分类器调整中的分布偏移问题，提出了带有偏移补偿的顺序学习(SLDC)，通过引入潜在空间转换操作符来对齐不同任务的特征分布，缓解偏移影响。研究提出了线性和弱非线性的SLDC变体，并使用知识蒸馏进一步降低表示偏移。实验显示，该方法显著提高了序列微调的性能，与联合训练相当。

**Conclusion:** SLDC显著提高了序列微调Vision Transformers的性能，并通过结合知识蒸馏，该策略能够在多个评估数据集中达到与联合训练相似的性能水平。

**Abstract:** Recent advances have shown that sequential fine-tuning (SeqFT) of pre-trained vision transformers (ViTs), followed by classifier refinement using approximate distributions of class features, can be an effective strategy for class-incremental learning (CIL). However, this approach is susceptible to distribution drift, caused by the sequential optimization of shared backbone parameters. This results in a mismatch between the distributions of the previously learned classes and that of the updater model, ultimately degrading the effectiveness of classifier performance over time. To address this issue, we introduce a latent space transition operator and propose Sequential Learning with Drift Compensation (SLDC). SLDC aims to align feature distributions across tasks to mitigate the impact of drift. First, we present a linear variant of SLDC, which learns a linear operator by solving a regularized least-squares problem that maps features before and after fine-tuning. Next, we extend this with a weakly nonlinear SLDC variant, which assumes that the ideal transition operator lies between purely linear and fully nonlinear transformations. This is implemented using learnable, weakly nonlinear mappings that balance flexibility and generalization. To further reduce representation drift, we apply knowledge distillation (KD) in both algorithmic variants. Extensive experiments on standard CIL benchmarks demonstrate that SLDC significantly improves the performance of SeqFT. Notably, by combining KD to address representation drift with SLDC to compensate distribution drift, SeqFT achieves performance comparable to joint training across all evaluated datasets. Code: https://github.com/raoxuan98-hash/sldc.git.

</details>


### [71] [Debiased Dual-Invariant Defense for Adversarially Robust Person Re-Identification](https://arxiv.org/abs/2511.09933)
*Yuhang Zhou,Yanxiang Zhao,Zhongyun Hua,Zhipu Liu,Zhaoquan Gu,Qing Liao,Leo Yu Zhang*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Person re-identification (ReID) is a fundamental task in many real-world applications such as pedestrian trajectory tracking. However, advanced deep learning-based ReID models are highly susceptible to adversarial attacks, where imperceptible perturbations to pedestrian images can cause entirely incorrect predictions, posing significant security threats. Although numerous adversarial defense strategies have been proposed for classification tasks, their extension to metric learning tasks such as person ReID remains relatively unexplored. Moreover, the several existing defenses for person ReID fail to address the inherent unique challenges of adversarially robust ReID. In this paper, we systematically identify the challenges of adversarial defense in person ReID into two key issues: model bias and composite generalization requirements. To address them, we propose a debiased dual-invariant defense framework composed of two main phases. In the data balancing phase, we mitigate model bias using a diffusion-model-based data resampling strategy that promotes fairness and diversity in training data. In the bi-adversarial self-meta defense phase, we introduce a novel metric adversarial training approach incorporating farthest negative extension softening to overcome the robustness degradation caused by the absence of classifier. Additionally, we introduce an adversarially-enhanced self-meta mechanism to achieve dual-generalization for both unseen identities and unseen attack types. Experiments demonstrate that our method significantly outperforms existing state-of-the-art defenses.

</details>


### [72] [AdaptViG: Adaptive Vision GNN with Exponential Decay Gating](https://arxiv.org/abs/2511.09942)
*Mustafa Munir,Md Mostafijur Rahman,Radu Marculescu*

Main category: cs.CV

> 提出AdaptViG，一种高效的Vision GNN，解决了计算效率问题，达到了新的性能-效率平衡。

<details>
  <summary>Details</summary>

**Motivation:** Vision Graph Neural Networks (ViGs)尽管强大，但构建图的阶段会导致显著的计算挑战，这影响了其效率。本研究是为了提出一个更有效且强大的Vision GNN。

**Method:** AdaptViG采用自适应图卷积机制，包含高效的静态轴向支架和动态的内容感知门控策略（指数衰减门控）。门控机制通过特征相似性选择性地权重远程连接。此外，AdaptViG在早期阶段使用高效的门控机制，在最后阶段使用全局注意力块以最大化特征聚合。

**Result:** AdaptViG实现了一个新的准确性和效率之间的平衡。例如，AdaptViG-M达到82.6%的top-1准确率，比ViG-B高出0.3%，同时减少80%的参数和84%的GMACs。AdaptViG-M在下游任务中获得45.8 mIoU，44.8 APbox，和41.1 APmask，分别超过EfficientFormer-L7 0.7 mIoU，2.2 APbox，和2.1 APmask，参数减少78%。

**Conclusion:** AdaptViG引入的自适应图构造机制解决了计算效率问题，实现了新的高性能-高效能之间的平衡。

**Abstract:** Vision Graph Neural Networks (ViGs) offer a new direction for advancements in vision architectures. While powerful, ViGs often face substantial computational challenges stemming from their graph construction phase, which can hinder their efficiency. To address this issue we propose AdaptViG, an efficient and powerful hybrid Vision GNN that introduces a novel graph construction mechanism called Adaptive Graph Convolution. This mechanism builds upon a highly efficient static axial scaffold and a dynamic, content-aware gating strategy called Exponential Decay Gating. This gating mechanism selectively weighs long-range connections based on feature similarity. Furthermore, AdaptViG employs a hybrid strategy, utilizing our efficient gating mechanism in the early stages and a full Global Attention block in the final stage for maximum feature aggregation. Our method achieves a new state-of-the-art trade-off between accuracy and efficiency among Vision GNNs. For instance, our AdaptViG-M achieves 82.6% top-1 accuracy, outperforming ViG-B by 0.3% while using 80% fewer parameters and 84% fewer GMACs. On downstream tasks, AdaptViG-M obtains 45.8 mIoU, 44.8 APbox, and 41.1 APmask, surpassing the much larger EfficientFormer-L7 by 0.7 mIoU, 2.2 APbox, and 2.1 APmask, respectively, with 78% fewer parameters.

</details>


### [73] [TSPE-GS: Probabilistic Depth Extraction for Semi-Transparent Surface Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.09944)
*Zhiyuan Xu,Nan Min,Yuhang Guo,Tong Wei*

Main category: cs.CV

> TSPE-GS improves semi-transparent surface reconstruction in 3D Gaussian Splatting by addressing depth ambiguity.

<details>
  <summary>Details</summary>

**Motivation:** To address the issue of 3D Gaussian Splatting in reconstructing semi-transparent surfaces where most methods fail due to the assumption of a single depth per pixel.

**Method:** TSPE-GS (Transparent Surface Probabilistic Extraction for Gaussian Splatting) uniformly samples transmittance to model a multi-modal distribution of opacity and depth, resolving ambiguous depths caused by multiple surfaces being visible.

**Result:** Experiments show TSPE-GS improves semi-transparent geometry reconstruction while maintaining performance on opaque scenes.

**Conclusion:** TSPE-GS resolves cross-surface depth ambiguity by progressively fusing truncated signed distance functions and generalizes to other Gaussian-based reconstruction pipelines.

**Abstract:** 3D Gaussian Splatting offers a strong speed-quality trade-off but struggles to reconstruct semi-transparent surfaces because most methods assume a single depth per pixel, which fails when multiple surfaces are visible. We propose TSPE-GS (Transparent Surface Probabilistic Extraction for Gaussian Splatting), which uniformly samples transmittance to model a pixel-wise multi-modal distribution of opacity and depth, replacing the prior single-peak assumption and resolving cross-surface depth ambiguity. By progressively fusing truncated signed distance functions, TSPE-GS reconstructs external and internal surfaces separately within a unified framework. The method generalizes to other Gaussian-based reconstruction pipelines without extra training overhead. Extensive experiments on public and self-collected semi-transparent and opaque datasets show TSPE-GS significantly improves semi-transparent geometry reconstruction while maintaining performance on opaque scenes.

</details>


### [74] [Beyond Cosine Similarity Magnitude-Aware CLIP for No-Reference Image Quality Assessment](https://arxiv.org/abs/2511.09948)
*Zhicheng Liao,Dongxu Wu,Zhenshan Shi,Sijie Mai,Hanwei Zhu,Lingyu Zhu,Yuncheng Jiang,Baoliang Chen*

Main category: cs.CV

> 本文提出了一种新的框架，通过结合CLIP模型中的余弦相似性和改进后的特征幅度信息，提升无参考图像质量评估的表现。

<details>
  <summary>Details</summary>

**Motivation:** 虽然过去的CLIP模型尝试通过测量图像嵌入与文本提示间的余弦相似性来进行无参考图像质量评估，但这种方法忽视了CLIP图像特征幅度这一与感知质量强相关的线索，本文目的即在于解决这个问题。

**Method:** 我们提出了一种新的自适应融合框架，该框架不仅利用了图像嵌入与文本提示（如“一张好的照片”或“一张坏的照片”）之间的余弦相似性，还增加了对CLIP图像特征幅度的感知。首先，我们提取CLIP图像特征的绝对值，并应用Box-Cox变换对特征分布进行统计标准化，以减少语义敏感性。得到的标量概述作为一个语义标准化的辅助线索，补充了基于余弦的提示匹配。为了有成效地整合两个线索，我们设计了一个信心引导的融合方案，根据各自的力量来自适应地加权每个条款。

**Result:** 在多个基准图像质量评估数据集上的广泛实验表明，我们提出的方法在不需要任务特定训练的情况下，能够稳定地超过标准CLIP和最先进的基线方法。

**Conclusion:** 在无需任务特定训练的情况下，我们的方法表现出更好的性能，说明了在图像质量评估中囊括CLIP图像特征幅度信息的有效性。

**Abstract:** Recent efforts have repurposed the Contrastive Language-Image Pre-training (CLIP) model for No-Reference Image Quality Assessment (NR-IQA) by measuring the cosine similarity between the image embedding and textual prompts such as "a good photo" or "a bad photo." However, this semantic similarity overlooks a critical yet underexplored cue: the magnitude of the CLIP image features, which we empirically find to exhibit a strong correlation with perceptual quality. In this work, we introduce a novel adaptive fusion framework that complements cosine similarity with a magnitude-aware quality cue. Specifically, we first extract the absolute CLIP image features and apply a Box-Cox transformation to statistically normalize the feature distribution and mitigate semantic sensitivity. The resulting scalar summary serves as a semantically-normalized auxiliary cue that complements cosine-based prompt matching. To integrate both cues effectively, we further design a confidence-guided fusion scheme that adaptively weighs each term according to its relative strength. Extensive experiments on multiple benchmark IQA datasets demonstrate that our method consistently outperforms standard CLIP-based IQA and state-of-the-art baselines, without any task-specific training.

</details>


### [75] [Robust Object Detection with Pseudo Labels from VLMs using Per-Object Co-teaching](https://arxiv.org/abs/2511.09955)
*Uday Bhaskar,Rishabh Bhattacharya,Avinash Patel,Sarthak Khoche,Praveen Anil Kulkarni,Naresh Manwani*

Main category: cs.CV

> 本文提出一种利用视觉语言模型生成伪标签，通过每个物体的协同教学策略进一步提高物体检测模型性能的方法，特别适用于自动驾驶等需要实时物体检测的场景。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在通过利用视觉语言模型(VLMs)自动生成伪标签，来有效训练高效的实时物体检测器，从而解决零样本对象检测在自动驾驶等领域中的延迟和虚假预测问题，同时显著减少昂贵的人工标注依赖。

**Method:** 本文提出了一种新颖的管道，建议了一个基于每个物体的协同教学的训练策略，该策略通过过滤训练中不准确的边界框，减少了VLM生成标签中的内在噪声。具体而言，两个YOLO模型可以协作学习，过滤出每小批量数据中根据同伴每个对象的损失值判断为不可靠的边界框。

**Result:** 实验结果表明，该方法在KITTI数据集上优于基线YOLOv5m模型，mAP@0.5显著提升（从31.12%提升至46.61%），同时保持实时检测延迟。此外，通过补充少量真实标签（10%）的伪标签数据进一步提高了性能，达到了57.97%的mAP@0.5。对于ACDC和BDD100k数据集也观察到了类似的性能提升。

**Conclusion:** 总的来说，该管道为训练自动驾驶领域中的高性能物体检测器提供了一种高效的、健壮的和可扩展的方法，显著降低了对昂贵的人工标注的依赖。

**Abstract:** Foundation models, especially vision-language models (VLMs), offer compelling zero-shot object detection for applications like autonomous driving, a domain where manual labelling is prohibitively expensive. However, their detection latency and tendency to hallucinate predictions render them unsuitable for direct deployment. This work introduces a novel pipeline that addresses this challenge by leveraging VLMs to automatically generate pseudo-labels for training efficient, real-time object detectors. Our key innovation is a per-object co-teaching-based training strategy that mitigates the inherent noise in VLM-generated labels. The proposed per-object coteaching approach filters noisy bounding boxes from training instead of filtering the entire image. Specifically, two YOLO models learn collaboratively, filtering out unreliable boxes from each mini-batch based on their peers' per-object loss values. Overall, our pipeline provides an efficient, robust, and scalable approach to train high-performance object detectors for autonomous driving, significantly reducing reliance on costly human annotation. Experimental results on the KITTI dataset demonstrate that our method outperforms a baseline YOLOv5m model, achieving a significant mAP@0.5 boost ($31.12\%$ to $46.61\%$) while maintaining real-time detection latency. Furthermore, we show that supplementing our pseudo-labelled data with a small fraction of ground truth labels ($10\%$) leads to further performance gains, reaching $57.97\%$ mAP@0.5 on the KITTI dataset. We observe similar performance improvements for the ACDC and BDD100k datasets.

</details>


### [76] [Equivariant Sampling for Improving Diffusion Model-based Image Restoration](https://arxiv.org/abs/2511.09965)
*Chenxu Wu,Qingpeng Kong,Peiang Zhao,Wendi Yang,Wenxin Ma,Fenghe Tang,Zihang Jiang,S. Kevin Zhou*

Main category: cs.CV

> This paper presents EquS, an advanced diffusion model for image restoration which employs dual sampling trajectories and TAS to improve performance and sampling efficiency without increasing computational costs.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to tackle the limitations of current problem-agnostic diffusion model-based image restoration methods, which struggle to fully utilize diffusion priors and achieve optimal performance.

**Method:** The paper proposes EquS, a new diffusion model-based image restoration method, which imposes equivariant information through dual sampling trajectories. It further introduces TAS (Timestep-Aware Schedule) to prioritize deterministic steps and boost sampling efficiency, leading to the enhanced version EquS$^+$.

**Result:** Experiments show that EquS and its enhanced version EquS$^+$ can significantly improve the performance of previous problem-agnostic diffusion model-based image restoration methods without adding extra computational costs.

**Conclusion:** The introduction of EquS and TAS effectively enhances the performance of diffusion model-based image restoration methods, making them more compatible with existing approaches and efficient in sampling.

**Abstract:** Recent advances in generative models, especially diffusion models, have significantly improved image restoration (IR) performance. However, existing problem-agnostic diffusion model-based image restoration (DMIR) methods face challenges in fully leveraging diffusion priors, resulting in suboptimal performance. In this paper, we address the limitations of current problem-agnostic DMIR methods by analyzing their sampling process and providing effective solutions. We introduce EquS, a DMIR method that imposes equivariant information through dual sampling trajectories. To further boost EquS, we propose the Timestep-Aware Schedule (TAS) and introduce EquS$^+$. TAS prioritizes deterministic steps to enhance certainty and sampling efficiency. Extensive experiments on benchmarks demonstrate that our method is compatible with previous problem-agnostic DMIR methods and significantly boosts their performance without increasing computational costs. Our code is available at https://github.com/FouierL/EquS.

</details>


### [77] [Difference Vector Equalization for Robust Fine-tuning of Vision-Language Models](https://arxiv.org/abs/2511.09973)
*Satoshi Suzuki,Shin'ya Yamaguchi,Shoichiro Takeda,Taiga Yamane,Naoki Makishima,Naotaka Kawata,Mana Ihori,Tomohiro Tanaka,Shota Orihashi,Ryo Masumura*

Main category: cs.CV

> 本文提出了一种名为DiVE的方法，用于在视觉-语言模型微调时保持嵌入的几何结构，从而确保模型在ID，OOD及zero-shot设置下的性能。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在鲁棒地微调视觉-语言模型，使其在无需牺牲模型在分布外（OOD）和零样本（zero-shot）场景下泛化能力的同时，增强模型在常规分布（ID）数据上的表现。现有的微调方法在应用对比学习时，往往会扭曲嵌入的几何结构，从而限制了OOD和zero-shot场景下的性能。

**Method:** 本论文提出了一种名为Difference Vector Equalization (DiVE)的方法，用于保持在微调过程中视觉-语言模型的嵌入几何结构。DiVE通过约束来自预训练模型和微调模型的同一数据样本嵌入差异向量，来实现对几何结构的保持。为此，引入了平均向量损失（AVL）和成对向量损失（PVL）来维持全局和局部的几何结构和多模态对齐。

**Result:** 实验结果表明，DiVE方法有效地保持了嵌入的几何结构，并在ID、OOD以及零样本度量标准上表现出了强劲的结果。

**Conclusion:** 通过引入新方法DiVE，本文展示了在不损害OOD和zero-shot泛化能力的前提下，可以更有效地微调现有视觉-语言模型以提升在ID数据上的性能。

**Abstract:** Contrastive pre-trained vision-language models, such as CLIP, demonstrate strong generalization abilities in zero-shot classification by leveraging embeddings extracted from image and text encoders. This paper aims to robustly fine-tune these vision-language models on in-distribution (ID) data without compromising their generalization abilities in out-of-distribution (OOD) and zero-shot settings. Current robust fine-tuning methods tackle this challenge by reusing contrastive learning, which was used in pre-training, for fine-tuning. However, we found that these methods distort the geometric structure of the embeddings, which plays a crucial role in the generalization of vision-language models, resulting in limited OOD and zero-shot performance. To address this, we propose Difference Vector Equalization (DiVE), which preserves the geometric structure during fine-tuning. The idea behind DiVE is to constrain difference vectors, each of which is obtained by subtracting the embeddings extracted from the pre-trained and fine-tuning models for the same data sample. By constraining the difference vectors to be equal across various data samples, we effectively preserve the geometric structure. Therefore, we introduce two losses: average vector loss (AVL) and pairwise vector loss (PVL). AVL preserves the geometric structure globally by constraining difference vectors to be equal to their weighted average. PVL preserves the geometric structure locally by ensuring a consistent multimodal alignment. Our experiments demonstrate that DiVE effectively preserves the geometric structure, achieving strong results across ID, OOD, and zero-shot metrics.

</details>


### [78] [STELLAR: Scene Text Editor for Low-Resource Languages and Real-World Data](https://arxiv.org/abs/2511.09977)
*Yongdeuk Seo,Hyun-seok Min,Sungchul Choi*

Main category: cs.CV

> STELLAR, a novel scene text editing method, addresses key limitations of previous works by providing multilingual support, a multi-stage training strategy, a new dataset (STIPLAR), and a new evaluation metric (TAS) that assesses text appearance similarity effectively.

<details>
  <summary>Details</summary>

**Motivation:** To improve scene text editing with support for low-resource languages, address the domain gap between synthetic and real data, and develop appropriate metrics for evaluating text style preservation.

**Method:** The method proposed is STELLAR, which utilizes a language-adaptive glyph encoder and a multi-stage training strategy consisting of pre-training on synthetic data and fine-tuning on real-world images.

**Result:** STELLAR outperforms existing models in visual consistency and recognition accuracy, with an average TAS improvement of 2.2% across languages.

**Conclusion:** STELLAR provides a robust solution for scene text editing, effectively handling low-resource languages, synthetic-to-real domain gaps, and offering a new evaluation metric for style preservation.

**Abstract:** Scene Text Editing (STE) is the task of modifying text content in an image while preserving its visual style, such as font, color, and background. While recent diffusion-based approaches have shown improvements in visual quality, key limitations remain: lack of support for low-resource languages, domain gap between synthetic and real data, and the absence of appropriate metrics for evaluating text style preservation. To address these challenges, we propose STELLAR (Scene Text Editor for Low-resource LAnguages and Real-world data). STELLAR enables reliable multilingual editing through a language-adaptive glyph encoder and a multi-stage training strategy that first pre-trains on synthetic data and then fine-tunes on real images. We also construct a new dataset, STIPLAR(Scene Text Image Pairs of Low-resource lAnguages and Real-world data), for training and evaluation. Furthermore, we propose Text Appearance Similarity (TAS), a novel metric that assesses style preservation by independently measuring font, color, and background similarity, enabling robust evaluation even without ground truth. Experimental results demonstrate that STELLAR outperforms state-of-the-art models in visual consistency and recognition accuracy, achieving an average TAS improvement of 2.2% across languages over the baselines.

</details>


### [79] [MOBA: A Material-Oriented Backdoor Attack against LiDAR-based 3D Object Detection Systems](https://arxiv.org/abs/2511.09999)
*Saket S. Chaturvedi,Gaurav Bagwe,Lan Zhang,Pan He,Xiaoyong Yuan*

Main category: cs.CV

> A novel framework MOBA is introduced to perform physically realizable backdoor attacks on LiDAR systems by considering material properties and achieving a success rate of 93.50%, showcasing the need for robust physical defenses.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to address the vulnerability of LiDAR-based safety-critical systems to backdoor attacks and to overcome the limitations of current backdoor attack methods that lack physical realizability due to the digital-to-physical domain gap.

**Method:** The paper introduces a new framework called Material-Oriented Backdoor Attack (MOBA), designed to bridge the digital-physical gap for backdoor attacks on LiDAR-based systems. It specifically selects titanium dioxide (TiO_2) as the trigger material due to its characteristics and develops a simulation pipeline to mimic its physical behavior accurately.

**Result:** The conducted experiments demonstrate that MOBA achieves an attack success rate of 93.50%, significantly outperforming previous methods by over 41%. This indicates that MOBA is highly effective at creating physically realizable backdoor attacks on LiDAR-based object detection systems.

**Conclusion:** The paper concludes that the MOBA framework offers a significant advancement in the creation of physically realizable backdoor attacks on LiDAR-based systems, highlighting the necessity for defenses that account for material-level properties in real-world deployment environments.

**Abstract:** LiDAR-based 3D object detection is widely used in safety-critical systems. However, these systems remain vulnerable to backdoor attacks that embed hidden malicious behaviors during training. A key limitation of existing backdoor attacks is their lack of physical realizability, primarily due to the digital-to-physical domain gap. Digital triggers often fail in real-world settings because they overlook material-dependent LiDAR reflection properties. On the other hand, physically constructed triggers are often unoptimized, leading to low effectiveness or easy detectability.This paper introduces Material-Oriented Backdoor Attack (MOBA), a novel framework that bridges the digital-physical gap by explicitly modeling the material properties of real-world triggers. MOBA tackles two key challenges in physical backdoor design: 1) robustness of the trigger material under diverse environmental conditions, 2) alignment between the physical trigger's behavior and its digital simulation. First, we propose a systematic approach to selecting robust trigger materials, identifying titanium dioxide (TiO_2) for its high diffuse reflectivity and environmental resilience. Second, to ensure the digital trigger accurately mimics the physical behavior of the material-based trigger, we develop a novel simulation pipeline that features: (1) an angle-independent approximation of the Oren-Nayar BRDF model to generate realistic LiDAR intensities, and (2) a distance-aware scaling mechanism to maintain spatial consistency across varying depths. We conduct extensive experiments on state-of-the-art LiDAR-based and Camera-LiDAR fusion models, showing that MOBA achieves a 93.50% attack success rate, outperforming prior methods by over 41%. Our work reveals a new class of physically realizable threats and underscores the urgent need for defenses that account for material-level properties in real-world environments.

</details>
