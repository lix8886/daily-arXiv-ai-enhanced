<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 11]
- [cs.CV](#cs.CV) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Enhancing Urban Visual Place Recognition for Crowdsourced Flood Imagery via LLM-Guided Attention](https://arxiv.org/abs/2512.11811)
*Fengyi Xu,Jun Ma,Waishan Qiu,Cui Guo*

Main category: cs.CL

> VPR-AttLLM利用大型语言模型的语义和地理知识，增强视觉位置识别的性能，在处理众包街道视图图像，尤其是危机事件图像时，它的整合提高了VPR模型的召回率。

<details>
  <summary>Details</summary>

**Motivation:** 目前的VPR模型在应用于来自社交媒体的众包街道视图图像时性能大幅下降，因为这些图像存在视觉失真和领域转移等问题。而这类图像为城市洪水和其他危机事件提供了宝贵的实时视觉证据。本研究旨在通过整合LLMs提高这些场景下的VPR性能。

**Method:** VPR-AttLLM整合大型语言模型（LLMs）的语义推理和地理空间知识，通过注意力引导的描述符增强，将其融入现有的视觉位置识别（VPR）管道。该方法通过LLMs来识别城市背景中的位置相关区域并抑制瞬时视觉噪声，从而提高检索性能，且无需重新训练模型或额外数据。

**Result:** 在多个扩展基准数据集上的综合评估表明，将VPR-AttLLM与三个最先进的VPR模型（CosPlace，EigenPlaces和SALAD）结合使用，能一致提高召回率，相对增益通常在1-3%之间，最高可达8%。

**Conclusion:** 该研究建立的是一种将LLM指导的多模态融合范例应用于视觉检索系统的通用方法，其插件设计、强的跨源鲁棒性和可解释性，为规模化城市监控和快速地理定位众包危机图像提供了潜力。

**Abstract:** Crowdsourced street-view imagery from social media provides valuable real-time visual evidence of urban flooding and other crisis events, yet it often lacks reliable geographic metadata for emergency response. Existing Visual Place Recognition (VPR) models exhibit substantial performance degradation when applied to such imagery due to visual distortions and domain shifts inherent in cross-source scenarios. This paper presents VPR-AttLLM, a model-agnostic framework that integrates the semantic reasoning and geospatial knowledge of Large Language Models (LLMs) into established VPR pipelines through attention-guided descriptor enhancement. By leveraging LLMs to identify location-informative regions within the city context and suppress transient visual noise, VPR-AttLLM improves retrieval performance without requiring model retraining or additional data. Comprehensive evaluations are conducted on extended benchmarks including SF-XL enriched with real social-media flood images, synthetic flooding scenarios over established query sets and Mapillary photos, and a new HK-URBAN dataset capturing morphologically distinct cityscapes. Integrating VPR-AttLLM with three state-of-the-art VPR models-CosPlace, EigenPlaces, and SALAD-consistently improves recall performance, yielding relative gains typically between 1-3% and reaching up to 8% on the most challenging real flood imagery. Beyond measurable gains in retrieval accuracy, this study establishes a generalizable paradigm for LLM-guided multimodal fusion in visual retrieval systems. By embedding principles from urban perception theory into attention mechanisms, VPR-AttLLM bridges human-like spatial reasoning with modern VPR architectures. Its plug-and-play design, strong cross-source robustness, and interpretability highlight its potential for scalable urban monitoring and rapid geo-localization of crowdsourced crisis imagery.

</details>


### [2] [Reinforcement Learning for Latent-Space Thinking in LLMs](https://arxiv.org/abs/2512.11816)
*Enes Özeren,Matthias Aßenmacher*

Main category: cs.CL

> 该研究探索了潜空间思考的强化学习方法，以解决Coconut方法的敏感性和局限性问题，但实验结果表明，这些模型在数学推理领域仍不及传统模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的潜空间思考训练方法在特定领域有改进但无法保持在复杂任务中的性能。特别地，在数学推理时表现不佳。因此，研究动机是解决这些问题。

**Method:** 通过实验展示了Coconut方法在潜空间思考中的敏感性和局限性，并探索了使用强化学习技术进行直接优化潜思考步骤的方法，包括GRPO和一种新型潜强化学习方法。

**Result:** 实验结果显示，这些用RL训练的模型在数学推理领域仍然落后于传统的语言空间CoT模型。

**Conclusion:** 研究结论是虽然提出了新的潜强化学习方法，但在数学推理领域仍旧无法超越传统语言空间CoT模型的性能。

**Abstract:** Chain-of-Thought (CoT) reasoning typically utilizes the discrete language space for thinking, which is inherently inefficient, as many generated tokens only enforce linguistic rules that are not required for reasoning. To bypass this, latent-space thinking allows models to think using the continuous embedding space. While existing methods for training those models show domain-specific gains, they fail to maintain performance in complex tasks, such as mathematical reasoning. We experimentally demonstrate that the Coconut approach, a form of supervised fine-tuning for latent-space thinking, is highly sensitive to design choices and exhibits several inherent limitations. To address these issues, we investigate reinforcement learning (RL) techniques -- an underexplored direction in latent-space thinking -- including GRPO and design a novel Latent RL method for directly optimizing the latent thinking steps. Our experimental results reveal that these RL-trained models still lag behind traditional language-space CoT models in the mathematical reasoning domain. We make our codebase publicly available.

</details>


### [3] [KH-FUNSD: A Hierarchical and Fine-Grained Layout Analysis Dataset for Low-Resource Khmer Business Document](https://arxiv.org/abs/2512.11849)
*Nimol Thuon,Jun Du*

Main category: cs.CL

> 该研究介绍了KH-FUNSD，这是首个针对高棉语商业文档（包括收据、发票和报价单）理解的公开可用和分层注释的数据集，并对其进行了基准测试，提供了第一个针对高棉语商业文档的基准结果。

<details>
  <summary>Details</summary>

**Motivation:** 由于高棉语文档处理工具的发展滞后，特别在商业文档领域，这一研究旨在填补相关数据集的空白，以支持文档AI工具的开发。这些文档对于公共管理和私营企业都非常重要。

**Method:** 该研究介绍了一个名为KH-FUNSD的数据集，这是首个公开的、分层注释的高棉语表单文档理解数据集。该数据集涵盖了收据、发票和报价单等文档，并采用了三级注释框架：（1）区域检测，将每个文档划分为核心区域，如页眉、表单字段和页脚；（2）类似FUNSD的注释，区分问题、答案、标题等关键实体及其关系；（3）细粒度分类，分配特定的语义角色，如字段标签、值、标题、页脚和符号。

**Result:** 已经进行了几个领先模型的基准测试，提供了针对高棉语商业文档的第一个基准结果。

**Conclusion:** KH-FUNSD数据集及其文档将在指定URL上公开提供，这对于分析非拉丁、低资源脚本带来的独特挑战，尤其是在商业文档的自动分析和精准信息提取方面具有重要意义。

**Abstract:** Automated document layout analysis remains a major challenge for low-resource, non-Latin scripts. Khmer is a language spoken daily by over 17 million people in Cambodia, receiving little attention in the development of document AI tools. The lack of dedicated resources is particularly acute for business documents, which are critical for both public administration and private enterprise. To address this gap, we present \textbf{KH-FUNSD}, the first publicly available, hierarchically annotated dataset for Khmer form document understanding, including receipts, invoices, and quotations. Our annotation framework features a three-level design: (1) region detection that divides each document into core zones such as header, form field, and footer; (2) FUNSD-style annotation that distinguishes questions, answers, headers, and other key entities, together with their relationships; and (3) fine-grained classification that assigns specific semantic roles, such as field labels, values, headers, footers, and symbols. This multi-level approach supports both comprehensive layout analysis and precise information extraction. We benchmark several leading models, providing the first set of baseline results for Khmer business documents, and discuss the distinct challenges posed by non-Latin, low-resource scripts. The KH-FUNSD dataset and documentation will be available at URL.

</details>


### [4] [Direct Confidence Alignment: Aligning Verbalized Confidence with Internal Confidence In Large Language Models](https://arxiv.org/abs/2512.11998)
*Glenn Zhang,Treasure Mayowa,Jason Fan,Yicheng Fu,Aaron Sandoval,Sean O'Brien,Kevin Zhu*

Main category: cs.CL

> 本研究提出了直接置信度对齐（DCA）方法，评估了多个开源大语言模型，并引入了三个新的校准误差指标，结果显示DCA在某些模型架构上改善了对齐指标，但在其它架构上效果有限，强调在追求更可解释和更值得信赖的大语言模型时需要更多模型特定的方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是改善大语言模型输出的信任度和可靠性，通过校准方法改进模型的置信度与实际输出正确概率之间的对齐，解决内部置信度与表达置信度不一致的问题。

**Method:** 本研究提出直接置信度对齐(DCA)方法，通过直接偏好优化将大语言模型的表达置信度与其内部置信度对齐，而不是与基本准确率对齐，从而增强了模型的透明度和可靠性。

**Result:** 研究结果表明，DCA在某些模型架构上改善了对齐指标，减少了模型置信度表达的不一致。然而，在其他模型上，DCA的效果并不显著，这强调了在改进模型可解释性和可信度方向上，需要针对不同模型特性的方法。

**Conclusion:** 本研究展示了DCA方法在增强大语言模型透明度和可靠性方面的有效性，但也指出在不同模型架构上，需要采用更加以模型为中心的方法来实现更可信和更可解释的语言模型。

**Abstract:** Producing trustworthy and reliable Large Language Models (LLMs) has become increasingly important as their usage becomes more widespread. Calibration seeks to achieve this by improving the alignment between the model's confidence and the actual likelihood of its responses being correct or desirable. However, it has been observed that the internal confidence of a model, derived from token probabilities, is not well aligned with its verbalized confidence, leading to misleading results with different calibration methods. In this paper, we propose Direct Confidence Alignment (DCA), a method using Direct Preference Optimization to align an LLM's verbalized confidence with its internal confidence rather than ground-truth accuracy, enhancing model transparency and reliability by ensuring closer alignment between the two confidence measures. We evaluate DCA across multiple open-weight LLMs on a wide range of datasets. To further assess this alignment, we also introduce three new calibration error-based metrics. Our results show that DCA improves alignment metrics on certain model architectures, reducing inconsistencies in a model's confidence expression. However, we also show that it can be ineffective on others, highlighting the need for more model-aware approaches in the pursuit of more interpretable and trustworthy LLMs.

</details>


### [5] [Hold Onto That Thought: Assessing KV Cache Compression On Reasoning](https://arxiv.org/abs/2512.12008)
*Minghui Liu,Aadi Palnitkar,Tahseen Rabbani,Hyunwoo Jae,Kyle Rui Sang,Dixi Yao,Shayan Shabihi,Fuheng Zhao,Tian Li,Ce Zhang,Furong Huang,Kunpeng Zhang*

Main category: cs.CL

> 本文测试了几种流行的压缩策略在长推理任务中的表现，发现策略选择需依据数据集类型，并指出在成本效益之间存在权衡。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型（LLMs）表现出在长上下文任务上的优异性能，但往往受内存限制的掣肘。具体的KV缓存随着上下文长度线性增长，尽管一些压缩算法已经引入以减轻缓存增长，但他们的性能很少在需要长期解码的任务上被评估，因此本文旨在探讨不同压缩策略的效果。

**Method:** 本文研究了几种流行的压缩策略在长期推理任务上的性能表现，特别是在处理短但复杂的提示时，如GSM8K和MATH500等基准测试中的问题，这些问题通常需要多步骤推理和自我反思，导致思考序列达到数千个token的长度。

**Result:** 研究发现，对于非推理模型，没有一种压缩策略适用于所有情况，其性能严重依赖于数据集的类型；而对于推理模型，H2O和解码增强版的SnapKV是主要策略，这表明了重击者跟踪对于推理轨迹的有用性。同时，研究还发现了较小预算下的替换策略能产生更长的推理轨迹，这揭示了缓存大小和推理成本之间的权衡关系。

**Conclusion:** 本文揭示了不同压缩策略在处理复杂的推理任务时的表现，并强调了缓存大小与推理成本之间的平衡关系，这些发现有助于未来更有效地应用压缩技术。

**Abstract:** Large language models (LLMs) have demonstrated remarkable performance on long-context tasks, but are often bottlenecked by memory constraints. Namely, the KV cache, which is used to significantly speed up attention computations, grows linearly with context length. A suite of compression algorithms has been introduced to alleviate cache growth by evicting unimportant tokens. However, several popular strategies are targeted towards the prefill phase, i.e., processing long prompt context, and their performance is rarely assessed on reasoning tasks requiring long decoding. In particular, short but complex prompts, such as those in benchmarks like GSM8K and MATH500, often benefit from multi-step reasoning and self-reflection, resulting in thinking sequences thousands of tokens long. In this work, we benchmark the performance of several popular compression strategies on long-reasoning tasks. For the non-reasoning Llama-3.1-8B-Instruct, we determine that no singular strategy fits all, and that performance is heavily influenced by dataset type. However, we discover that H2O and our decoding-enabled variant of SnapKV are dominant strategies for reasoning models, indicating the utility of heavy-hitter tracking for reasoning traces. We also find that eviction strategies at low budgets can produce longer reasoning traces, revealing a tradeoff between cache size and inference costs.

</details>


### [6] [Benchmarking Contextual Understanding for In-Car Conversational Systems](https://arxiv.org/abs/2512.12042)
*Philipp Habicht,Lev Sorokin,Abdullah Saydemir,Ken E. Friedl,Andrea Stocco*

Main category: cs.CL

> 本研究表明，使用大型语言模型结合高级提示技术评估车内对话问答系统的效果良好，尤其在餐厅推荐案例中，DeepSeek-R1模型在评估中表现出色，成本效益高。

<details>
  <summary>Details</summary>

**Motivation:** 车内对话问答系统通过无缝语音交互极大提升了用户体验，但其准确性和可靠性评估仍然是一项挑战，本研究旨在解决这一问题。

**Method:** 本研究采用了大型语言模型(LLMs)结合高级提示技术和基于代理的方法来评估车内对话问答系统(ConvQA)的反应与用户陈述之间的一致性。重点在于上下文理解和在考虑用户限制和情境背景下提供准确地点推荐的能力。研究使用了输入-输出、思考链、自我一致性提示和多代理提示技术，涉及不同规模和不同提供商（包括OpenAI、DeepSeek、Mistral AI、Meta）的13种推理和非推理LLMs模型。

**Result:** 最大改进发生在对小型非推理模型应用高级提示技术时，尤其是多代理提示。推理模型整体上优于非推理模型，其中，在使用单代理提示和自我一致性策略时，DeepSeek-R1的F1得分达到0.99，每次请求成本仅为0.002美元。总体最佳平衡成本-时间效率的模型是DeepSeek-V3。

**Conclusion:** 基于LLM的评估为ConvQA系统中的上下文理解提供了可扩展且准确的标杆替代方法。

**Abstract:** In-Car Conversational Question Answering (ConvQA) systems significantly enhance user experience by enabling seamless voice interactions. However, assessing their accuracy and reliability remains a challenge. This paper explores the use of Large Language Models (LLMs) alongside advanced prompting techniques and agent-based methods to evaluate the extent to which ConvQA system responses adhere to user utterances. The focus lies on contextual understanding and the ability to provide accurate venue recommendations considering user constraints and situational context. To evaluate utterance-response coherence using an LLM, we synthetically generate user utterances accompanied by correct and modified failure-containing system responses. We use input-output, chain-of-thought, self-consistency prompting, and multi-agent prompting techniques with 13 reasoning and non-reasoning LLMs of varying sizes and providers, including OpenAI, DeepSeek, Mistral AI, and Meta. We evaluate our approach on a case study involving restaurant recommendations. The most substantial improvements occur for small non-reasoning models when applying advanced prompting techniques, particularly multi-agent prompting. However, reasoning models consistently outperform non-reasoning models, with the best performance achieved using single-agent prompting with self-consistency. Notably, DeepSeek-R1 reaches an F1-score of 0.99 at a cost of 0.002 USD per request. Overall, the best balance between effectiveness and cost-time efficiency is reached with the non-reasoning model DeepSeek-V3. Our findings show that LLM-based evaluation offers a scalable and accurate alternative to traditional human evaluation for benchmarking contextual understanding in ConvQA systems.

</details>


### [7] [VOYAGER: A Training Free Approach for Generating Diverse Datasets using LLMs](https://arxiv.org/abs/2512.12072)
*Avinash Amballa,Yashas Malur Saidutta,Chi-Heng Lin,Vivek Kulkarni,Srinivas Chappidi*

Main category: cs.CL

> We introduce Voyager, a flexible and scalable approach for enhancing diversity in synthetic datasets, which significantly outperforms existing methods with a 1.5-3x improvement in diversity.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for our work stems from the observation that synthetic datasets generated by large language models lack diversity, which can negatively impact the performance of downstream models.

**Method:** Our approach, named Voyager, is iterative and uses determinantal point processes to optimize a mathematical quantity that directly enhances the diversity of the generated data. This method is training-free, can be applied to closed-source models, and is scalable.

**Result:** Through extensive experiments, we show that Voyager outperforms popular baseline methods by providing a 1.5-3x improvement in diversity of the generated datasets.

**Conclusion:** We propose a novel, principled approach to generate diverse synthetic datasets that not only provides theoretical justification but also demonstrates significant improvements over baseline methods in terms of diversity.

**Abstract:** Large language models (LLMs) are increasingly being used to generate synthetic datasets for the evaluation and training of downstream models. However, prior work has noted that such generated data lacks diversity. In this paper, we propose Voyager, a novel principled approach to generate diverse datasets. Our approach is iterative and directly optimizes a mathematical quantity that optimizes the diversity of the dataset using the machinery of determinantal point processes. Furthermore, our approach is training-free, applicable to closed-source models, and scalable. In addition to providing theoretical justification for the working of our method, we also demonstrate through comprehensive experiments that Voyager significantly outperforms popular baseline approaches by providing a 1.5-3x improvement in diversity.

</details>


### [8] [BLASST: Dynamic BLocked Attention Sparsity via Softmax Thresholding](https://arxiv.org/abs/2512.12087)
*Jiayi Yuan,Cameron Shinn,Kai Xu,Jingze Cui,George Klimiashvili,Guangxuan Xiao,Perkz Zheng,Bo Li,Yuxin Zhou,Zhouhai Ye,Weijie You,Tian Zheng,Dominic Brown,Pengbo Wang,Richard Cai,Julien Demouth,John D. Owens,Xia Hu,Song Han,Timmy Liu,Huizi Mao*

Main category: cs.CL

> BLASST is a method to accelerate long-context inference in LLMs by dynamically pruning the attention matrix, improving both prefill and decode performance with negligible latency overhead.

<details>
  <summary>Details</summary>

**Motivation:** To tackle the computational and memory challenges associated with the standard attention mechanism in LLMs when dealing with long contexts.

**Method:** BLASST uses a fixed threshold and information from the online softmax to identify and ignore negligible attention scores, reducing unnecessary computations.

**Result:** Demonstrates a 1.62x speedup for prefill at 74.7% sparsity and a 1.48x speedup for decode at 73.2% sparsity, with an automated calibration procedure.

**Conclusion:** BLASST offers a unified solution for improving performance across different attention variants and can be extended to sparsity-aware training for even better results.

**Abstract:** The growing demand for long-context inference capabilities in Large Language Models (LLMs) has intensified the computational and memory bottlenecks inherent to the standard attention mechanism. To address this challenge, we introduce BLASST, a drop-in sparse attention method that dynamically prunes the attention matrix without any pre-computation or proxy scores. Our method uses a fixed threshold and existing information from online softmax to identify negligible attention scores, skipping softmax computation, Value block loading, and the subsequent matrix multiplication. This fits seamlessly into existing FlashAttention kernel designs with negligible latency overhead. The approach is applicable to both prefill and decode stages across all attention variants (MHA, GQA, MQA, and MLA), providing a unified solution for accelerating long-context inference. We develop an automated calibration procedure that reveals a simple inverse relationship between optimal threshold and context length, enabling robust deployment across diverse scenarios. Maintaining high accuracy, we demonstrate a 1.62x speedup for prefill at 74.7% sparsity and a 1.48x speedup for decode at 73.2% sparsity on modern GPUs. Furthermore, we explore sparsity-aware training as a natural extension, showing that models can be trained to be inherently more robust to sparse attention patterns, pushing the accuracy-sparsity frontier even further.

</details>


### [9] [Extending the Context of Pretrained LLMs by Dropping Their Positional Embeddings](https://arxiv.org/abs/2512.12167)
*Yoav Gelberg,Koshi Eguchi,Takuya Akiba,Edoardo Cetin*

Main category: cs.CL

> 通过去除语言模型中的位置嵌入，实现无缝的零样本上下文扩展，避免了昂贵的微调过程。

<details>
  <summary>Details</summary>

**Motivation:** 去除位置嵌入是为了克服依赖显式位置信息所带来的测试时间泛化问题，特别是在处理未见过长度的序列时。

**Method:** DroPE方法通过在训练后去除语言模型中的位置嵌入来实现有效的上下文扩展，方法简单且效果显著。

**Result:** DroPE方法在不同的模型和数据集规模中都显著优于之前的专业架构和旋转位置嵌入缩放方法。

**Conclusion:** 去除位置嵌入并在简短的重新校准阶段后，可以有效地扩展语言模型的上下文而无需额外的长上下文微调。

**Abstract:** So far, expensive finetuning beyond the pretraining sequence length has been a requirement for effectively extending the context of language models (LM). In this work, we break this key bottleneck by Dropping the Positional Embeddings of LMs after training (DroPE). Our simple method is motivated by three key theoretical and empirical observations. First, positional embeddings (PEs) serve a crucial role during pretraining, providing an important inductive bias that significantly facilitates convergence. Second, over-reliance on this explicit positional information is also precisely what prevents test-time generalization to sequences of unseen length, even when using popular PE-scaling methods. Third, positional embeddings are not an inherent requirement of effective language modeling and can be safely removed after pretraining, following a short recalibration phase. Empirically, DroPE yields seamless zero-shot context extension without any long-context finetuning, quickly adapting pretrained LMs without compromising their capabilities in the original training context. Our findings hold across different models and dataset sizes, far outperforming previous specialized architectures and established rotary positional embedding scaling methods.

</details>


### [10] [Diffusion Language Model Inference with Monte Carlo Tree Search](https://arxiv.org/abs/2512.12168)
*Zheng Huang,Kiran Ramnath,Yueyan Chen,Aosong Feng,Sangmin Woo,Balasubramaniam Srinivasan,Zhichao Xu,Kang Zhou,Shuai Wang,Haibo Ding,Lin Lee Cheong*

Main category: cs.CL

> 本文提出了MEDAL框架，通过在初始化阶段采用蒙特卡洛树搜索来解决扩散语言模型推理中的挑战，大幅提高了模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 为了在扩散语言模型推理中引入一个原理性的搜索机制。现有的推理方法通过启发式方法近似此搜索，通常会产生次优的解码路径；其他方法依赖于额外的训练来指导令牌的选择。因此，提出了一种新的框架来改善这些不足。

**Method:** MEDAL框架通过在初始化阶段采用蒙特卡洛树搜索来探索有前景的去噪路径，为后续的细化提供一个坚实的基础。同时通过限制搜索空间为高置信度动作，并优先选择能提高剩余遮罩位置模型置信度的令牌来实现这种集成。

**Result:** 在多个基准测试中，MEDAL相比现有推理策略最高提高了22.0%，在扩散语言模型的基于搜索的推理中建立了新的范式。

**Conclusion:** 提出的MEDAL框架通过集成蒙特卡洛树搜索初始化来改进扩散语言模型的推理，显著提高了模型性能，展示了其在扩散语言模型中的潜力。

**Abstract:** Diffusion language models (DLMs) have recently emerged as a compelling alternative to autoregressive generation, offering parallel generation and improved global coherence. During inference, DLMs generate text by iteratively denoising masked sequences in parallel; however, determining which positions to unmask and which tokens to commit forms a large combinatorial search problem. Existing inference methods approximate this search using heuristics, which often yield suboptimal decoding paths; other approaches instead rely on additional training to guide token selection. To introduce a principled search mechanism for DLMs inference, we introduce MEDAL, a framework that integrates Monte Carlo Tree SEarch initialization for Diffusion LAnguage Model inference. We employ Monte Carlo Tree Search at the initialization stage to explore promising unmasking trajectories, providing a robust starting point for subsequent refinement. This integration is enabled by restricting the search space to high-confidence actions and prioritizing token choices that improve model confidence over remaining masked positions. Across multiple benchmarks, MEDAL achieves up to 22.0% improvement over existing inference strategies, establishing a new paradigm for search-based inference in diffusion language models.

</details>


### [11] [Semantic Distance Measurement based on Multi-Kernel Gaussian Processes](https://arxiv.org/abs/2512.12238)
*Yinzhu Cheng,Haihua Xie,Yaqing Wang,Miao He,Mingming Sun*

Main category: cs.CL

> This paper introduces a novel semantic distance measure using multi-kernel Gaussian processes that is more adaptable to different data and tasks than traditional methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the limitations of classical semantic distance methods which are typically fixed and thus not adaptable to specific data distributions or task requirements. The proposed method aims to offer a more flexible and data-driven approach.

**Method:** The paper proposes a semantic distance measure based on multi-kernel Gaussian processes (MK-GP). It models the semantic function associated with texts as a Gaussian process, where the covariance function combines Matérn and polynomial kernels. The kernel parameters are learned automatically from data under supervision.

**Result:** The semantic distance measure was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning setup. The experimental results demonstrated the effectiveness of the proposed measure.

**Conclusion:** The proposed MK-GP based semantic distance measure was found to be effective in the context of fine-grained sentiment classification, indicating its utility and adaptability for tasks requiring semantic text analysis.

**Abstract:** Semantic distance measurement is a fundamental problem in computational linguistics, providing a quantitative characterization of similarity or relatedness between text segments, and underpinning tasks such as text retrieval and text classification. From a mathematical perspective, a semantic distance can be viewed as a metric defined on a space of texts or on a representation space derived from them. However, most classical semantic distance methods are essentially fixed, making them difficult to adapt to specific data distributions and task requirements. In this paper, a semantic distance measure based on multi-kernel Gaussian processes (MK-GP) was proposed. The latent semantic function associated with texts was modeled as a Gaussian process, with its covariance function given by a combined kernel combining Matérn and polynomial components. The kernel parameters were learned automatically from data under supervision, rather than being hand-crafted. This semantic distance was instantiated and evaluated in the context of fine-grained sentiment classification with large language models under an in-context learning (ICL) setup. The experimental results demonstrated the effectiveness of the proposed measure.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2512.11865)
*Ju-Young Kim,Ji-Hong Park,Myeongjun Kim,Gun-Woo Kim*

Main category: cs.CV

> 文章提出一种可解释的对抗鲁棒模型用于智能农业，通过集成证据模块检测和解释光度扰动，对抗干扰下操作预测更准确和可解释。

<details>
  <summary>Details</summary>

**Motivation:** 在智能农业中，依赖RGB相机感知和机器人操纵器控制的系统容易受到光度扰动（如色调、光照和噪声变化）的影响，从而导致在对抗攻击下出现故障。

**Method:** 提出了一种基于OpenVLA-OFT框架的可解释对抗鲁棒视觉-语言-动作模型。该模型集成了一个证据-3模块，用于检测光度扰动，并生成自然语言解释这些扰动的原因和影响。

**Result:** 实验表明，相较于基线模型，所提模型减少了21.7%的当前操作L1损失和18.4%的下一个操作L1损失，表现出在对抗条件下操作预测精度和可解释性的提升。

**Conclusion:** 所提模型在遇到光度扰动时依然保持可靠的性能，并且可以通过自然语言解释来提高模型的可解释性。

**Abstract:** Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.

</details>


### [13] [Temporal-Anchor3DLane: Enhanced 3D Lane Detection with Multi-Task Losses and LSTM Fusion](https://arxiv.org/abs/2512.11869)
*D. Shainu Suhas,G. Rahul,K. Muni*

Main category: cs.CV

> 研究提出了Temporal-Anchor3DLane，改进了3D车道检测的鲁棒性和时间连续性。

<details>
  <summary>Details</summary>

**Motivation:** 解决基本模型在回归异常敏感、全局曲线几何弱监督、多损失项平衡困难以及时间连续性利用不足的问题。

**Method:** Anchor3DLane的基础上提出了Temporal-Anchor3DLane，加入了三个关键贡献：多任务损失改进、轻量级时序LSTM融合模块、ESCOP样式的训练细化，以提高3D车道检测的鲁棒性。

**Result:** 在OpenLane数据集上，F1提升了6.2，并且时间上的轨迹更加平滑。

**Conclusion:** 实验结果表明，Temporal-Anchor3DLane在OpenLane数据集上F1提高了6.2，并生成了更加平稳的时间轨迹，证明了架构和损失调整显著提升了3D车道检测的鲁棒性，而无需增加传感器或扩展模型复杂性。

**Abstract:** Monocular 3D lane detection remains challenging due to depth ambiguity, occlusion, and temporal instability across frames. Anchor-based approaches such as Anchor3DLane have demonstrated strong performance by regressing continuous 3D lane curves from multi-camera surround views. However, the baseline model still exhibits (i) sensitivity to regression outliers, (ii) weak supervision of global curve geometry, (iii) difficulty in balancing multiple loss terms, and (iv) limited exploitation of temporal continuity. We propose Temporal-Anchor3DLane, an enhanced 3D lane detection framework that extends Anchor3DLane with three key contributions: (1) a set of multi-task loss improvements, including Balanced L1 regression, Chamfer point-set distance, and uncertainty-based loss weighting, together with focal and Dice components for classification and visibility; (2) a lightweight Temporal LSTM Fusion module that aggregates per-anchor features across frames, replacing a heavier Transformer-style temporal fusion; and (3) ESCOP-style training refinements that couple curve-level supervision with temporal consistency. On OpenLane, Temporal-Anchor3DLane improves F1 by +6.2 and yields smoother temporal trajectories, showing that small architectural and loss refinements significantly enhance 3D lane robustness without extra sensors or scaling.

</details>


### [14] [Automated Plant Disease and Pest Detection System Using Hybrid Lightweight CNN-MobileViT Models for Diagnosis of Indigenous Crops](https://arxiv.org/abs/2512.11871)
*Tekleab G. Gebremedhin,Hailom S. Asegede,Bruh W. Tesheme,Tadesse B. Gebremichael,Kalayu G. Redae*

Main category: cs.CV

> 该研究开发了一种离线优先的作物疾病检测系统，用于埃塞俄比亚提格雷地区的一种仙人掌果作物。通过测试三种轻量级模型，发现EfficientNet-Lite1和定制的轻量级CNN在准确率和部署条件之间有较好的权衡，而MobileViT-XS则显示出高交叉验证准确率。模型被部署在一个本地化的移动应用程序上，以增强该地区作物病害诊断的可访问性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于提格雷地区的基础设施不完善，影响了作物疾病诊断专家的可获得性，研究旨在通过提供一个离线优先的检测系统来解决这一问题，以支持该地区80%以上的人口所依赖的农业。

**Method:** 研究提出了一个面向离线部署的作物疾病检测系统，专门针对埃塞俄比亚提格雷地区的土著仙人掌果（Opuntia ficus-indica）。该系统基于3587张田野图片，涉及到三个主要的病害症状类别。为了适应冲突后环境中的边缘条件，研究评估了三种轻量级模型架构：定制的轻量级CNN、EfficientNet-Lite1和CNN-Transformer混合架构MobileViT-XS。

**Result:** 实验结果显示EfficientNet-Lite1在测试集上达到了90.7%的准确率；轻量级CNN模型达到了89.5%的准确率，同时具有最低的部署负担（42毫秒推理延迟，4.8 MB模型大小）；MobileViT-XS在交叉验证中平均准确率达到了97.3%，证实了多头自我注意力（MHSA）能够更可靠地区分病虫害群体和二维真菌病斑，相比局部纹理的CNN核来说效果更佳。

**Conclusion:** 该研究通过在ARM兼容的Tigrigna和Amharic本地化Flutter应用程序中部署模型，支持在Cortex-A53类设备上完全离线推理，强化了食品安全检测方面的共包容性。

**Abstract:** Agriculture supports over 80% of the population in the Tigray region of Ethiopia, where infrastructural disruptions limit access to expert crop disease diagnosis. We present an offline-first detection system centered on a newly curated indigenous cactus-fig (Opuntia ficus-indica) dataset consisting of 3,587 field images across three core symptom classes. Given deployment constraints in post-conflict edge environments, we benchmark three mobile-efficient architectures: a custom lightweight CNN, EfficientNet-Lite1, and the CNN-Transformer hybrid MobileViT-XS. While the broader system contains independent modules for potato, apple, and corn, this study isolates cactus-fig model performance to evaluate attention sensitivity and inductive bias transfer on indigenous morphology alone. Results establish a clear Pareto trade-off: EfficientNet-Lite1 achieves 90.7% test accuracy, the lightweight CNN reaches 89.5% with the most favorable deployment profile (42 ms inference latency, 4.8 MB model size), and MobileViT-XS delivers 97.3% mean cross-validation accuracy, demonstrating that MHSA-based global reasoning disambiguates pest clusters from two dimensional fungal lesions more reliably than local texture CNN kernels. The ARM compatible models are deployed in a Tigrigna and Amharic localized Flutter application supporting fully offline inference on Cortex-A53 class devices, strengthening inclusivity for food security critical diagnostics.

</details>


### [15] [Pseudo-Label Refinement for Robust Wheat Head Segmentation via Two-Stage Hybrid Training](https://arxiv.org/abs/2512.11874)
*Jiahao Jiang,Zhangrui Yang,Xuanhan Wang,Jingkuan Song*

Main category: cs.CV

> 本文介绍了一种系统化的自我训练框架，用于全球小麦全语义分割竞赛，通过两阶段混合训练策略与数据增强技术提高模型准确性，实现了具有竞争力的表现。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在解决全球小麦全语义分割竞赛中提出的问题。希望通过开发一种系统化的自我训练框架，结合高效的训练策略和数据增强技术，在该竞赛中取得具有竞争力的表现。

**Method:** 本文提出了一种系统化的自我训练框架，该框架结合了两阶段混合训练策略和大量的数据增强技术。核心模型采用了带有Mix Transformer (MiT-B4) 主干网络的SegFormer。通过迭代的师生循环，逐步提高模型的准确性并最大化数据的利用率。

**Result:** 该方法在竞赛的开发和测试阶段数据上取得了具有竞争力的性能。

**Conclusion:** 通过系统化的自我训练框架，结合有效的训练策略和数据增强技术，实现了在小麦全语义分割任务上的高效准确性提升，表明了方法的潜力和有效性。

**Abstract:** This extended abstract details our solution for the Global Wheat Full Semantic Segmentation Competition. We developed a systematic self-training framework. This framework combines a two-stage hybrid training strategy with extensive data augmentation. Our core model is SegFormer with a Mix Transformer (MiT-B4) backbone. We employ an iterative teacher-student loop. This loop progressively refines model accuracy. It also maximizes data utilization. Our method achieved competitive performance. This was evident on both the Development and Testing Phase datasets.

</details>


### [16] [Generalization vs. Specialization: Evaluating Segment Anything Model (SAM3) Zero-Shot Segmentation Against Fine-Tuned YOLO Detectors](https://arxiv.org/abs/2512.11884)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.CV

> 该论文比较了零样本模式下的SAM3与经过细调的Ultralytics YOLO11模型在实例分割任务上的表现，使用了含有大量高密度和遮挡情况的MinneApple数据集。结果显示在合适的IoU阈值下，YOLO模型的F1得分比SAM3高，但在IoU范围变化时，YOLO模型性能波动更大，表现出SAM3在边界稳定性的优势。

<details>
  <summary>Details</summary>

**Motivation:** 研究目标是综合比较专用的细调模型和基础模型的性能，理解它们在密集实例分割任务中的优劣和适用场景。

**Method:** 通过使用MinneApple数据集进行评估，并分析了不同IoU阈值对模型性能的影响，对比了纯零样本模式下的SAM3与多种类型YOLO模型的检测结果。

**Result:** 在IoU阈值为0.15时，YOLO模型的F1得分为68.9%到72.2%，SAM3为59.8%。但随着IoU变化，YOLO模型的性能下降显著，SAM3则表现出更好的边界稳定性。

**Conclusion:** SAM3在边界稳定性方面表现优于YOLO模型，适合对稳定性要求高的场景，而细调过的YOLO模型则在检测完整度方面更占优势。研究人员提供了开源代码和评估流程，方便进一步研究和应用。

**Abstract:** Deep learning has advanced two fundamentally different paradigms for instance segmentation: specialized models optimized through task-specific fine-tuning and generalist foundation models capable of zero-shot segmentation. This work presents a comprehensive comparison between SAM3 (Segment Anything Model, also called SAMv3) operating in zero-shot mode and three variants of Ultralytics YOLO11 (nano, medium, and large) fine-tuned for instance segmentation. The evaluation is conducted on the MinneApple dataset, a dense benchmark comprising 670 orchard images with 28,179 annotated apple instances, enabling rigorous validation of model behavior under high object density and occlusion. Our analysis shows IoU choices can inflate performance gaps by up to 30%. At the appropriate IoU = 0.15 threshold, YOLO models achieve 68.9%, 72.2%, and 71.9% F1, while SAM3 reaches 59.8% in pure zero-shot mode. However, YOLO exhibits steep degradation 48-50 points across IoU ranges whereas SAM3 drops only 4 points, revealing 12 times superior boundary stability of SAM3. This highlights the strength of SAMv3 in mask precision versus specialization in detection completeness of YOLO11. We provide open-source code, evaluation pipelines, and methodological recommendations, contributing to a deeper understanding of when specialized fine-tuned models or generalist foundation models are preferable for dense instance segmentation tasks. This project repository is available on GitHub as https://github.com/Applied-AI-Research-Lab/Segment-Anything-Model-SAM3-Zero-Shot-Segmentation-Against-Fine-Tuned-YOLO-Detectors

</details>


### [17] [mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description](https://arxiv.org/abs/2512.11894)
*Mahathir Monjur,Shahriar Nirjon*

Main category: cs.CV

> mmWeaver 是一种创新框架，通过使用隐式神经表示（INRs）合成环境特定的复杂毫米波信号，实现高达49倍的压缩率，并在活动识别和姿态估计任务中展示出优于现有方法的表现，同时速度快6-35倍。

<details>
  <summary>Details</summary>

**Motivation:** 由于毫米波信号复杂且稀疏，物理模拟计算成本高，该研究旨在通过更加高效的方法生成实际信号并扩展数据集以提升毫米波雷达在活动识别和姿态估计的应用效果。

**Method:** mmWeaver 采用隐式神经表示方法将毫米波信号建模为连续函数，并使用超网络基于环境上下文（RGB-D图像提取）和人体运动特征（通过MotionGPT从文本生成），动态生成INR参数实现信号合成。

**Result:** 实验表明，与现有方法相比，mmWeaver 在信号真实感方面表现出色，复杂SSIM为0.88，PSNR为35dB，提高了7%的活动识别准确率，降低了15%的人体姿态估计误差。

**Conclusion:** mmWeaver 提供了更快速、更高效的合成实际毫米波信号方法，极大地推动了毫米波雷达技术在活动和姿态相关领域的应用。

**Abstract:** Realistic signal generation and dataset augmentation are essential for advancing mmWave radar applications such as activity recognition and pose estimation, which rely heavily on diverse, and environment-specific signal datasets. However, mmWave signals are inherently complex, sparse, and high-dimensional, making physical simulation computationally expensive. This paper presents mmWeaver, a novel framework that synthesizes realistic, environment-specific complex mmWave signals by modeling them as continuous functions using Implicit Neural Representations (INRs), achieving up to 49-fold compression. mmWeaver incorporates hypernetworks that dynamically generate INR parameters based on environmental context (extracted from RGB-D images) and human motion features (derived from text-to-pose generation via MotionGPT), enabling efficient and adaptive signal synthesis. By conditioning on these semantic and geometric priors, mmWeaver generates diverse I/Q signals at multiple resolutions, preserving phase information critical for downstream tasks such as point cloud estimation and activity classification. Extensive experiments show that mmWeaver achieves a complex SSIM of 0.88 and a PSNR of 35 dB, outperforming existing methods in signal realism while improving activity recognition accuracy by up to 7% and reducing human pose estimation error by up to 15%, all while operating 6-35 times faster than simulation-based approaches.

</details>


### [18] [Hot Hém: Sài Gòn Giũa Cái Nóng Hông Còng Bàng -- Saigon in Unequal Heat](https://arxiv.org/abs/2512.11896)
*Tessa Vu*

Main category: cs.CV

> Hot Hém是一个能估计和操作行人人热暴露的GeoAI工作流，通过结合Google街景图像、语义图像分割和两个XGBoost模型，实现了热感知路由，有助于理解城市走廊中的热分布。

<details>
  <summary>Details</summary>

**Motivation:** 行人人热暴露是热带密集城市的一个重要健康风险，但标准路由算法往往忽略微尺度的热变化。为了应对这一问题，提出了Hot Hém方法。

**Method:** Hot Hém是一个结合了Google街景图像、语义图像分割和遥感的GeoAI工作流，用于估计和操作胡志明市（越南，俗称西贡）的行人人热暴露。该方法使用在选定行政区划（称为坊）训练的两个XGBoost模型来预测地表温度（LST），并通过OSMnx生成的行人网络节点以拼接方式部署这些模型，从而实现热感知路由。

**Result:** 该模型在部署后可以作为基础，用于精确定位城市走廊中为何某些地区可能会经历更高的温度。

**Conclusion:** 此模型和其方法论为理解城市基础设施中热分布的原因和精确指示热点地点提供了一个基础。

**Abstract:** Pedestrian heat exposure is a critical health risk in dense tropical cities, yet standard routing algorithms often ignore micro-scale thermal variation. Hot Hém is a GeoAI workflow that estimates and operationalizes pedestrian heat exposure in Hô Chí Minh City (HCMC), Vi\d{e}t Nam, colloquially known as Sài Gòn. This spatial data science pipeline combines Google Street View (GSV) imagery, semantic image segmentation, and remote sensing. Two XGBoost models are trained to predict land surface temperature (LST) using a GSV training dataset in selected administrative wards, known as phŏng, and are deployed in a patchwork manner across all OSMnx-derived pedestrian network nodes to enable heat-aware routing. This is a model that, when deployed, can provide a foundation for pinpointing where and further understanding why certain city corridors may experience disproportionately higher temperatures at an infrastructural scale.

</details>


### [19] [Microscopic Vehicle Trajectory Datasets from UAV-collected Video for Heterogeneous, Area-Based Urban Traffic](https://arxiv.org/abs/2512.11898)
*Yawar Ali,K. Ramachandra Rao,Ashish Bhaskar,Niladri Chatterjee*

Main category: cs.CV

> 本文通过UAV采集并公开发布了微观车辆轨迹(MVT)数据集，旨在为复杂城市交通环境下的研究提供资源。

<details>
  <summary>Details</summary>

**Motivation:** 传统的路边视频采集在密集的混合交通中经常由于遮挡、视角有限和车辆运动不规则而失败。使用UAV采集提供了一个顶视图，减少了这些问题，并捕捉了丰富的空间和时间动态。这些数据集的目的是为全球研究社区提供一个资源，以支持在基于区域的交通条件下的仿真建模、安全评估和行为研究。

**Method:** 本文使用无人飞行器(UAV)在异质城市交通条件下收集了开放获取的微观车辆轨迹(MVT)数据集。这些数据通过Data from Sky (DFS)平台提取，并且已经通过前期工作中的手动计数、空间平均速度和探针轨迹进行了验证。

**Result:** 每个数据集都包含有关时间戳、车辆位置、速度、纵向和横向加速度以及车辆分类的信息，其分辨率高达每秒30帧。数据在印度国家首都地区的六个中途路段位置收集，涵盖了多样化的交通组合和密度水平。探索性分析突出了许多关键的行为模式，包括车道保持偏好、速度分布和典型的异质交通设置中的横向操作。

**Conclusion:** 通过提供这些实证数据集，这项工作为研究人员提供了一个独特的机会，可以开发、测试和验证更准确地表示复杂城市交通环境的模型。

**Abstract:** This paper offers openly available microscopic vehicle trajectory (MVT) datasets collected using unmanned aerial vehicles (UAVs) in heterogeneous, area-based urban traffic conditions. Traditional roadside video collection often fails in dense mixed traffic due to occlusion, limited viewing angles, and irregular vehicle movements. UAV-based recording provides a top-down perspective that reduces these issues and captures rich spatial and temporal dynamics. The datasets described here were extracted using the Data from Sky (DFS) platform and validated against manual counts, space mean speeds, and probe trajectories in earlier work. Each dataset contains time-stamped vehicle positions, speeds, longitudinal and lateral accelerations, and vehicle classifications at a resolution of 30 frames per second. Data were collected at six mid-block locations in the national capital region of India, covering diverse traffic compositions and density levels. Exploratory analyses highlight key behavioural patterns, including lane-keeping preferences, speed distributions, and lateral manoeuvres typical of heterogeneous and area-based traffic settings. These datasets are intended as a resource for the global research community to support simulation modelling, safety assessment, and behavioural studies under area-based traffic conditions. By making these empirical datasets openly available, this work offers researchers a unique opportunity to develop, test, and validate models that more accurately represent complex urban traffic environments.

</details>
