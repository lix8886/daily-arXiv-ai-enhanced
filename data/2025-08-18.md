<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 17]
- [cs.CV](#cs.CV) [Total: 13]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A2HCoder: An LLM-Driven Coding Agent for Hierarchical Algorithm-to-HDL Translation](https://arxiv.org/abs/2508.10904)
*Jie Lei,Ruofan Jia,J. Andrew Zhang,Hao Zhang*

Main category: cs.CL

> 提出了A2HCoder：一种由大型语言模型驱动的分层算法到硬件描述语言编码代理，用以解决算法设计和硬件实现之间的差距，特别适用于无线通信系统的高效部署。

<details>
  <summary>Details</summary>

**Motivation:** 针对无线通信系统对于低延迟和低功耗等严格要求提出了更大的算法到硬件部署效率需求。然而，由于高层次编程语言和硬件描述语言在内存访问模式、数据处理方式和数据类型表示方面的根本性不匹配，当前算法设计与硬件实现之间依然存在显著差距。

**Method:** 提出了一种名为A2HCoder的分层算法到硬件描述语言（HDL）编码代理，该代理由大型语言模型（LLMs）驱动，旨在实现灵活和可靠的算法到硬件翻译。A2HCoder引入了一个分层框架来提高鲁棒性和可解释性，并解决LLMs生成代码时常见的幻觉问题。该框架水平上将复杂算法分解为模块化功能块，简化代码生成并提高一致性；垂直上采用逐步细化的翻译方式，同时利用MATLAB和Vitis HLS等外部工具链进行调试和电路级综合。

**Result:** 通过5G无线通信领域的一个实际部署案例展示了A2HCoder的实用性和可靠性，验证其部署效率。

**Conclusion:** A2HCoder在5G实际部署案例中的应用证明了其能够提高算法到硬件翻译的效率和可靠性，提供了从算法设计到硬件实现的有效桥梁。

**Abstract:** In wireless communication systems, stringent requirements such as ultra-low
latency and power consumption have significantly increased the demand for
efficient algorithm-to-hardware deployment. However, a persistent and
substantial gap remains between algorithm design and hardware implementation.
Bridging this gap traditionally requires extensive domain expertise and
time-consuming manual development, due to fundamental mismatches between
high-level programming languages like MATLAB and hardware description languages
(HDLs) such as Verilog-in terms of memory access patterns, data processing
manners, and datatype representations. To address this challenge, we propose
A2HCoder: a Hierarchical Algorithm-to-HDL Coding Agent, powered by large
language models (LLMs), designed to enable agile and reliable
algorithm-to-hardware translation. A2HCoder introduces a hierarchical framework
that enhances both robustness and interpretability while suppressing common
hallucination issues in LLM-generated code. In the horizontal dimension,
A2HCoder decomposes complex algorithms into modular functional blocks,
simplifying code generation and improving consistency. In the vertical
dimension, instead of relying on end-to-end generation, A2HCoder performs
step-by-step, fine-grained translation, leveraging external toolchains such as
MATLAB and Vitis HLS for debugging and circuit-level synthesis. This structured
process significantly mitigates hallucinations and ensures hardware-level
correctness. We validate A2HCoder through a real-world deployment case in the
5G wireless communication domain, demonstrating its practicality, reliability,
and deployment efficiency.

</details>


### [2] [PersonaTwin: A Multi-Tier Prompt Conditioning Framework for Generating and Evaluating Personalized Digital Twins](https://arxiv.org/abs/2508.10906)
*Sihan Chen,John P. Lalor,Yi Yang,Ahmed Abbasi*

Main category: cs.CL

> PersonaTwin是一种多层次的提示条件框架，通过整合人口统计、行为和心理测量数据来构建自适应的数字双胞胎。研究显示，该框架在模拟真实用户行为及其情感细节方面表现出色，为个性化数字用户建模提供了强大工具。

<details>
  <summary>Details</summary>

**Motivation:** 现有大型语言模型虽然提供了新的用户建模和模拟人类行为的可能性，但经常无法准确捕捉用户的多维度特征。研究动机在于通过PersonaTwin框架提高用户建模的准确性和情感细节的捕捉。

**Method:** 使用一个包含超过8,500个个体的综合数据集，作者系统地将PersonaTwin与标准语言模型的输出进行基准测试，并采用最先进的文本相似度度量和人口统计相似性评估，确保生成的响应既准确又无偏。

**Result:** 实验结果表明，PersonaTwin框架在模拟保真度上与金标准相当，且在GPT-4o和Llama模型基础上训练的下游模型在预测和公平性指标上也能与个体训练的模型相媲美。

**Conclusion:** 这些研究发现强调了基于大型语言模型数字双胞胎方法在产生真实和情感细腻的用户体验模拟方面的潜力，为个性化数字用户建模和行为分析提供了有力工具。

**Abstract:** While large language models (LLMs) afford new possibilities for user modeling
and approximation of human behaviors, they often fail to capture the
multidimensional nuances of individual users. In this work, we introduce
PersonaTwin, a multi-tier prompt conditioning framework that builds adaptive
digital twins by integrating demographic, behavioral, and psychometric data.
Using a comprehensive data set in the healthcare context of more than 8,500
individuals, we systematically benchmark PersonaTwin against standard LLM
outputs, and our rigorous evaluation unites state-of-the-art text similarity
metrics with dedicated demographic parity assessments, ensuring that generated
responses remain accurate and unbiased. Experimental results show that our
framework produces simulation fidelity on par with oracle settings. Moreover,
downstream models trained on persona-twins approximate models trained on
individuals in terms of prediction and fairness metrics across both
GPT-4o-based and Llama-based models. Together, these findings underscore the
potential for LLM digital twin-based approaches in producing realistic and
emotionally nuanced user simulations, offering a powerful tool for personalized
digital user modeling and behavior analysis.

</details>


### [3] [gpt-oss-120b & gpt-oss-20b Model Card](https://arxiv.org/abs/2508.10925)
*OpenAI,:,Sandhini Agarwal,Lama Ahmad,Jason Ai,Sam Altman,Andy Applebaum,Edwin Arbus,Rahul K. Arora,Yu Bai,Bowen Baker,Haiming Bao,Boaz Barak,Ally Bennett,Tyler Bertao,Nivedita Brett,Eugene Brevdo,Greg Brockman,Sebastien Bubeck,Che Chang,Kai Chen,Mark Chen,Enoch Cheung,Aidan Clark,Dan Cook,Marat Dukhan,Casey Dvorak,Kevin Fives,Vlad Fomenko,Timur Garipov,Kristian Georgiev,Mia Glaese,Tarun Gogineni,Adam Goucher,Lukas Gross,Katia Gil Guzman,John Hallman,Jackie Hehir,Johannes Heidecke,Alec Helyar,Haitang Hu,Romain Huet,Jacob Huh,Saachi Jain,Zach Johnson,Chris Koch,Irina Kofman,Dominik Kundel,Jason Kwon,Volodymyr Kyrylov,Elaine Ya Le,Guillaume Leclerc,James Park Lennon,Scott Lessans,Mario Lezcano-Casado,Yuanzhi Li,Zhuohan Li,Ji Lin,Jordan Liss,Lily,Liu,Jiancheng Liu,Kevin Lu,Chris Lu,Zoran Martinovic,Lindsay McCallum,Josh McGrath,Scott McKinney,Aidan McLaughlin,Song Mei,Steve Mostovoy,Tong Mu,Gideon Myles,Alexander Neitz,Alex Nichol,Jakub Pachocki,Alex Paino,Dana Palmie,Ashley Pantuliano,Giambattista Parascandolo,Jongsoo Park,Leher Pathak,Carolina Paz,Ludovic Peran,Dmitry Pimenov,Michelle Pokrass,Elizabeth Proehl,Huida Qiu,Gaby Raila,Filippo Raso,Hongyu Ren,Kimmy Richardson,David Robinson,Bob Rotsted,Hadi Salman,Suvansh Sanjeev,Max Schwarzer,D. Sculley,Harshit Sikchi,Kendal Simon,Karan Singhal,Yang Song,Dane Stuckey,Zhiqing Sun,Philippe Tillet,Sam Toizer,Foivos Tsimpourlas,Nikhil Vyas,Eric Wallace,Xin Wang,Miles Wang,Olivia Watkins,Kevin Weil,Amy Wendling,Kevin Whinnery,Cedric Whitney,Hannah Wong,Lin Yang,Yu Yang,Michihiro Yasunaga,Kristen Ying,Wojciech Zaremba,Wenting Zhan,Cyril Zhang,Brian Zhang,Eddie Zhang,Shengjia Zhao*

Main category: cs.CL

> 本文介绍了gpt-oss-120b和gpt-oss-20b两个开放权重推理模型，它们通过高效的混合专家Transformer架构进行训练，并优化了代理能力。模型在多个基准测试中表现出色，且作者开源了相关资源以便进一步研究。

<details>
  <summary>Details</summary>

**Motivation:** 推动了准确性和推理成本的前沿，并希望增强模型的代理能力，使模型能够更好地遵循指令和区分角色。另外，作者希望开放模型权重，促进更广泛的应用和进一步的研究。

**Method:** 使用了混合专家Transformer架构，并通过大规模蒸馏和强化学习进行训练。模型优化以拥有强大的代理能力（深入研究浏览、Python工具使用和开发者提供的函数支持），同时采用渲染对话格式，旨在实现清晰的指令遵循和角色区分。

**Result:** 两个模型在数学、编程和安全性等基准测试中均表现出色。

**Conclusion:** 作者希望通过开源释放模型权重、推理实现、工具环境和分词器，促进广泛的应用和进一步的研究。

**Abstract:** We present gpt-oss-120b and gpt-oss-20b, two open-weight reasoning models
that push the frontier of accuracy and inference cost. The models use an
efficient mixture-of-expert transformer architecture and are trained using
large-scale distillation and reinforcement learning. We optimize the models to
have strong agentic capabilities (deep research browsing, python tool use, and
support for developer-provided functions), all while using a rendered chat
format that enables clear instruction following and role delineation. Both
models achieve strong results on benchmarks ranging from mathematics, coding,
and safety. We release the model weights, inference implementations, tool
environments, and tokenizers under an Apache 2.0 license to enable broad use
and further research.

</details>


### [4] [Modeling and Detecting Company Risks from News: A Case Study in Bloomberg News](https://arxiv.org/abs/2508.10927)
*Jiaxin Pei,Soumya Vadlamannati,Liang-Kang Huang,Daniel Preotiuc-Pietro,Xinyu Hua*

Main category: cs.CL

> 研究开发了一个计算框架，用于从新闻文章中自动提取七种不同方面的公司风险因素。实验显示，尽管大语言模型在许多自然语言处理任务中取得了巨大进步，但预训练模型经过微调在识别风险因素上表现更好。

<details>
  <summary>Details</summary>

**Motivation:** 识别与公司相关的风险对于投资者以及整体金融市场状况至关重要。这项研究的目的是自动提取新闻文章中的公司风险因素，提供关于公司和行业的广泛见解。

**Method:** 本研究开发了一个计算框架，用于从新闻文章中自动提取公司风险因素。该框架包括一个新提出的模式，涵盖七个不同的方面，例如供应链、法规和竞争。

**Result:** 实验结果显示，零样本和少量样本提示最先进的大语言模型(LLMs)在识别风险因素方面仅能达到中等到较低的性能，而微调过的预训练语言模型在大多数风险因素上表现更为出色。

**Conclusion:** 使用该模型分析了超过277,000篇Bloomberg新闻文章，表明从新闻中识别风险因素可以提供对公司运营和行业的深入见解。这些发现有助于投资者做出更加明智的决策。

**Abstract:** Identifying risks associated with a company is important to investors and the
well-being of the overall financial market. In this study, we build a
computational framework to automatically extract company risk factors from news
articles. Our newly proposed schema comprises seven distinct aspects, such as
supply chain, regulations, and competitions. We sample and annotate 744 news
articles and benchmark various machine learning models. While large language
models have achieved huge progress in various types of NLP tasks, our
experiment shows that zero-shot and few-shot prompting state-of-the-art LLMs
(e.g. LLaMA-2) can only achieve moderate to low performances in identifying
risk factors. And fine-tuned pre-trained language models are performing better
on most of the risk factors. Using this model, we analyze over 277K Bloomberg
news articles and demonstrate that identifying risk factors from news could
provide extensive insight into the operations of companies and industries.

</details>


### [5] [Rule2Text: A Framework for Generating and Evaluating Natural Language Explanations of Knowledge Graph Rules](https://arxiv.org/abs/2508.10971)
*Nasim Shirvani-Mahdavi,Chengkai Li*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Knowledge graphs (KGs) can be enhanced through rule mining; however, the
resulting logical rules are often difficult for humans to interpret due to
their inherent complexity and the idiosyncratic labeling conventions of
individual KGs. This work presents Rule2Text, a comprehensive framework that
leverages large language models (LLMs) to generate natural language
explanations for mined logical rules, thereby improving KG accessibility and
usability. We conduct extensive experiments using multiple datasets, including
Freebase variants (FB-CVT-REV, FB+CVT-REV, and FB15k-237) as well as the
ogbl-biokg dataset, with rules mined using AMIE 3.5.1. We systematically
evaluate several LLMs across a comprehensive range of prompting strategies,
including zero-shot, few-shot, variable type incorporation, and
Chain-of-Thought reasoning. To systematically assess models' performance, we
conduct a human evaluation of generated explanations on correctness and
clarity. To address evaluation scalability, we develop and validate an
LLM-as-a-judge framework that demonstrates strong agreement with human
evaluators. Leveraging the best-performing model (Gemini 2.0 Flash), LLM judge,
and human-in-the-loop feedback, we construct high-quality ground truth
datasets, which we use to fine-tune the open-source Zephyr model. Our results
demonstrate significant improvements in explanation quality after fine-tuning,
with particularly strong gains in the domain-specific dataset. Additionally, we
integrate a type inference module to support KGs lacking explicit type
information. All code and data are publicly available at
https://github.com/idirlab/KGRule2NL.

</details>


### [6] [Improving Text Style Transfer using Masked Diffusion Language Models with Inference-time Scaling](https://arxiv.org/abs/2508.10995)
*Tejomay Kishor Padole,Suyash P Awate,Pushpak Bhattacharyya*

Main category: cs.CL

> 本研究展示了掩码扩散语言模型（MDM）作为一种计算效率高且易于训练的生成框架，其通过引入基于验证器的推理时扩展方法，在标准文本风格转换任务中表现出优于自回归模型的效果。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型，特别是掩码扩散语言模型（MDM），已经显示出通过在推理阶段调整变量（如增加去噪步骤数量或使用验证器）来改善生成质量的卓越能力。研究动机在于探索一种基于验证器的方法来提高MDM生成离散数据的质量。

**Method:** 本研究提出了一种基于验证器的推理时扩展方法，以帮助在MDM的去噪过程中找到更好的候选生成。这一方法通过使用现成的预训练嵌入模型来构建一个简单的基于软值的验证器设置，从而在现有的无分类器自由引导设置之上显著提高生成质量。

**Result:** 实验结果展示了MDM在标准文本风格转换任务中的应用，并确立了MDM作为比自回归语言模型更好的替代方案的地位。使用提出的验证器设置，即使在现有的无分类器自由引导设置之上也能显著提高生成质量。

**Conclusion:** 研究结果表明，MDM作为一种非自回归生成器在离散数据生成中表现出了强大的能力，并证明了通过简单的基于验证器的方法进行推理时扩展可以显著提高生成质量，从而进一步证明了MDM在文本生成任务中的有效性。

**Abstract:** Masked diffusion language models (MDMs) have recently gained traction as a
viable generative framework for natural language. This can be attributed to its
scalability and ease of training compared to other diffusion model paradigms
for discrete data, establishing itself as the state-of-the-art
non-autoregressive generator for discrete data. Diffusion models, in general,
have shown excellent ability to improve the generation quality by leveraging
inference-time scaling either by increasing the number of denoising steps or by
using external verifiers on top of the outputs of each step to guide the
generation. In this work, we propose a verifier-based inference-time scaling
method that aids in finding a better candidate generation during the denoising
process of the MDM. Our experiments demonstrate the application of MDMs for
standard text-style transfer tasks and establish MDMs as a better alternative
to autoregressive language models. Additionally, we show that a simple
soft-value-based verifier setup for MDMs using off-the-shelf pre-trained
embedding models leads to significant gains in generation quality even when
used on top of typical classifier-free guidance setups in the existing
literature.

</details>


### [7] [SproutBench: A Benchmark for Safe and Ethical Large Language Models for Youth](https://arxiv.org/abs/2508.11009)
*Wenpeng Xing,Lanyi Wei,Haixiao Hu,Rongchang Li,Mohan Li,Changting Lin,Meng Han*

Main category: cs.CL

> 论文指出当前大型语言模型安全基准在处理儿童和青少年用户时存在的不足，并引入SproutBench来评估这些模型对未成年用户的潜在风险，从而促进以儿童为中心的AI设计和部署。

<details>
  <summary>Details</summary>

**Motivation:** 由于针对儿童和青少年的大语言模型应用迅速增加，现有的大多为成人用户设计的AI安全框架需要进行根本性的重新评估。这些框架忽视了未成年人特有的发展脆弱性。

**Method:** 此论文引入了SproutBench，一个包含1,283个开发性对抗提示的评估套件，旨在检查如情感依赖、隐私侵犯和模仿危险行为等风险。通过严格评估47种多样化的大型语言模型，揭示了显著的安全漏洞。

**Result:** 通过评估，论文发现了大型语言模型在面对未成年用户时存在显著的安全漏洞，并揭示了安全与风险预防、互动性和年龄适宜性之间的强有力的相关性。

**Conclusion:** 研究结果为推进儿童中心的AI设计与部署提供了实用指南。

**Abstract:** The rapid proliferation of large language models (LLMs) in applications
targeting children and adolescents necessitates a fundamental reassessment of
prevailing AI safety frameworks, which are largely tailored to adult users and
neglect the distinct developmental vulnerabilities of minors. This paper
highlights key deficiencies in existing LLM safety benchmarks, including their
inadequate coverage of age-specific cognitive, emotional, and social risks
spanning early childhood (ages 0--6), middle childhood (7--12), and adolescence
(13--18). To bridge these gaps, we introduce SproutBench, an innovative
evaluation suite comprising 1,283 developmentally grounded adversarial prompts
designed to probe risks such as emotional dependency, privacy violations, and
imitation of hazardous behaviors. Through rigorous empirical evaluation of 47
diverse LLMs, we uncover substantial safety vulnerabilities, corroborated by
robust inter-dimensional correlations (e.g., between Safety and Risk
Prevention) and a notable inverse relationship between Interactivity and Age
Appropriateness. These insights yield practical guidelines for advancing
child-centric AI design and deployment.

</details>


### [8] [Beyond the Rosetta Stone: Unification Forces in Generalization Dynamics](https://arxiv.org/abs/2508.11017)
*Carter Blum,Katja Filipova,Ann Yuan,Asma Ghandeharioun,Julian Zimmert,Fred Zhang,Jessica Hoffmann,Tal Linzen,Martin Wattenberg,Lucas Dixon,Mor Geva*

Main category: cs.CL

> 研究展示了模型在形成跨语言知识时选择独立还是统一的知识表示形式对跨语言知识迁移的重要性，并提出了通过调整数据分布和分词方式影响跨语言知识迁移度的方法。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在跨语言知识转移时存在困难，研究旨在找出导致这一现象的原因和动态变化，并提出改进方法。

**Method:** 本研究通过在合成的多语言数据集上从零开始训练小型Transformer模型，来创建一个受控环境，用以研究跨语言知识迁移中出现的现象及其机制。

**Result:** 研究表明，跨语言知识的有效迁移依赖于模型能否形成关于同一事实的统一语言表示，这种统一性取决于事实和训练数据语言之间的相互信息，以及语言的可提取性。

**Conclusion:** 研究开发了调节跨语言知识迁移的方法，并提出了量化和可视化这些影响的指标和方法，揭示了受控设置对理解预训练动态和优化跨语言知识迁移的重要性。

**Abstract:** Large language models (LLMs) struggle with cross-lingual knowledge transfer:
they hallucinate when asked in one language about facts expressed in a
different language during training. This work introduces a controlled setting
to study the causes and dynamics of this phenomenon by training small
Transformer models from scratch on synthetic multilingual datasets. We identify
a learning phase wherein a model develops either separate or unified
representations of the same facts across languages, and show that unification
is essential for cross-lingual transfer. We also show that the degree of
unification depends on mutual information between facts and training data
language, and on how easy it is to extract that language. Based on these
insights, we develop methods to modulate the level of cross-lingual transfer by
manipulating data distribution and tokenization, and we introduce metrics and
visualizations to formally characterize their effects on unification. Our work
shows how controlled settings can shed light on pre-training dynamics and
suggests new directions for improving cross-lingual transfer in LLMs.

</details>


### [9] [Hell or High Water: Evaluating Agentic Recovery from External Failures](https://arxiv.org/abs/2508.11027)
*Andrew Wang,Sophia Hager,Adi Asija,Daniel Khashabi,Nicholas Andrews*

Main category: cs.CL

> A specialized agentic planning benchmark tests language models' adaptability in dynamic environments with external failures, revealing difficulties in formulating and executing backup plans.

<details>
  <summary>Details</summary>

**Motivation:** To assess the ability of language model agents to adapt and search for alternative solutions when encountering external failures during task execution.

**Method:** Our benchmark involves solving planning problems via combinations of function calls, where agents search through a large set of functions and adapt to environmental feedback, including function unavailability.

**Result:** State-of-the-art models can identify correct functions but fail to adapt to feedback and find alternate solutions, even when the search space is limited.

**Conclusion:** Current generative models struggle with adapting to environmental feedback and pursuing alternate courses of action, highlighting key challenges for future research.

**Abstract:** As language model agents are applied to real world problems of increasing
complexity, they will be expected to formulate plans across large search
spaces. If those plans fail for reasons beyond their control, how well do
language agents search for alternative ways to achieve their goals? We devise a
specialized agentic planning benchmark to study this question. Each planning
problem is solved via combinations of function calls. The agent searches for
relevant functions from a set of over four thousand possibilities, and observes
environmental feedback in the form of function outputs or error messages. Our
benchmark confronts the agent with external failures in its workflow, such as
functions that suddenly become unavailable. At the same time, even with the
introduction of these failures, we guarantee that the task remains solvable.
Ideally, an agent's performance on the planning task should not be affected by
the presence of external failures. Overall, we find that language agents
struggle to formulate and execute backup plans in response to environment
feedback. While state-of-the-art models are often able to identify the correct
function to use in the right context, they struggle to adapt to feedback from
the environment and often fail to pursue alternate courses of action, even when
the search space is artificially restricted. We provide a systematic analysis
of the failures of both open-source and commercial models, examining the
effects of search space size, as well as the benefits of scaling model size in
our setting. Our analysis identifies key challenges for current generative
models as well as promising directions for future work.

</details>


### [10] [BIPOLAR: Polarization-based granular framework for LLM bias evaluation](https://arxiv.org/abs/2508.11061)
*Martin Pavlíček,Tomáš Filip,Petr Sosík*

Main category: cs.CL

> 本文提出了一种框架，用于评估大型语言模型中的极化相关偏见，通过一个关于俄罗斯-乌克兰战争的案例研究，评估了几个LLMs的偏见，发现它们在语义类别中的情感上存在显著差异。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在偏见检测和缓解技术方面取得了一定进展，某些挑战仍然未被充分探讨。本文针对LLMs在处理政治讨论、性别认同、族裔关系或国家刻板印象等敏感话题时表现出的偏见问题，提出了一个新框架。

**Method:** 本研究提出了一种可重复使用、细致且主题无关的框架，用于评估大型语言模型（LLM）中的极化相关偏见。方法结合了极化敏感情感度量和一个用预定义语义类别生成的、平衡的冲突相关声明的合成数据集。

**Result:** 以俄罗斯-乌克兰战争为案例研究，创建了一个合成数据集，评估了几个LLMs的偏见，包括Llama-3、Mistral、GPT-4、Claude 3.5和Gemini 1.0。发现偏见评分中存在针对乌克兰的总体积极情感趋势，并在语义类别中显示出较大的变化，揭示了模型之间的异质行为模式。

**Conclusion:** 该框架支持自动化数据集生成和细致的偏见评估，适用于各种由极化驱动的情景和话题，并且与其他偏见评估策略互不冲突。

**Abstract:** Large language models (LLMs) are known to exhibit biases in downstream tasks,
especially when dealing with sensitive topics such as political discourse,
gender identity, ethnic relations, or national stereotypes. Although
significant progress has been made in bias detection and mitigation techniques,
certain challenges remain underexplored. This study proposes a reusable,
granular, and topic-agnostic framework to evaluate polarisation-related biases
in LLM (both open-source and closed-source). Our approach combines
polarisation-sensitive sentiment metrics with a synthetically generated
balanced dataset of conflict-related statements, using a predefined set of
semantic categories.
  As a case study, we created a synthetic dataset that focusses on the
Russia-Ukraine war, and we evaluated the bias in several LLMs: Llama-3,
Mistral, GPT-4, Claude 3.5, and Gemini 1.0. Beyond aggregate bias scores, with
a general trend for more positive sentiment toward Ukraine, the framework
allowed fine-grained analysis with considerable variation between semantic
categories, uncovering divergent behavioural patterns among models. Adaptation
to prompt modifications showed further bias towards preconceived language and
citizenship modification.
  Overall, the framework supports automated dataset generation and fine-grained
bias assessment, is applicable to a variety of polarisation-driven scenarios
and topics, and is orthogonal to many other bias-evaluation strategies.

</details>


### [11] [Approaching the Source of Symbol Grounding with Confluent Reductions of Abstract Meaning Representation Directed Graphs](https://arxiv.org/abs/2508.11068)
*Nicolas Goulet,Alexandre Blondin Massé,Moussa Abdendi*

Main category: cs.CL

> 本文探究了在AMR图中嵌入数字词典，并通过保持电路空间的方式削减这些图，分析了削减后的图与符号接地问题的关系。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于探索数字词典嵌入和AMR图的结合，以及通过削减图来分析其与符号接地问题的关系。

**Method:** 本文描述了如何将实际的数字词典嵌入到AMR有向无环图中，使用最先进的预训练大型语言模型。然后，以一致性的方式减少这些图，即进行保持其电路空间的转换。

**Result:** 通过分析削减后的图，进一步讨论了这些图的特性及其与符号接地问题的关系。

**Conclusion:** 本文展示了将数字词典嵌入AMR图，并通过保持电路空间的削减图的方法，为理解符号接地问题及其相关特性提供了新的视角。

**Abstract:** Abstract meaning representation (AMR) is a semantic formalism used to
represent the meaning of sentences as directed acyclic graphs. In this paper,
we describe how real digital dictionaries can be embedded into AMR directed
graphs (digraphs), using state-of-the-art pre-trained large language models.
Then, we reduce those graphs in a confluent manner, i.e. with transformations
that preserve their circuit space. Finally, the properties of these reduces
digraphs are analyzed and discussed in relation to the symbol grounding
problem.

</details>


### [12] [Towards Reliable Multi-Agent Systems for Marketing Applications via Reflection, Memory, and Planning](https://arxiv.org/abs/2508.11120)
*Lorenzo Jaime Yu Flores,Junyi Shen,Xiaoyuan Gu*

Main category: cs.CL

> 本研究介绍了一个名为RAMP的框架，用于营销任务中的受众策划，通过迭代计划、工具调用、输出验证和质量改进，证明了使用LLM规划和记忆可以提高精度，并提高了模糊查询的召回率和用户满意度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）的发展使得AI代理能够规划并使用工具完成复杂任务，但关于它们在实际应用中的可靠性研究仍然有限。因此，本文旨在探索在一个具体的营销任务，即受众策划任务中，如何通过LLMs来实现可靠的任务执行。

**Method:** 本文介绍了一个名为RAMP的框架，该框架可以迭代地规划、调用工具、验证输出并生成建议，以改进生成的受众质量。同时，研究还为模型配备了长期记忆存储，这是一个包含客户特定事实和过去查询的知识库。

**Result:** 研究结果表明，在一个包含88个评价查询的数据集上，模型准确率提高了28个百分比；同时，对10个模糊查询的测试集上，通过增加验证/反思的迭代次数，召回率有了大约20个百分比的提升，用户满意度也有所增加。

**Conclusion:** 研究结果展示了在使用LLMs进行任务规划与记忆功能时，在动态的、面向行业的环境中部署可靠系统的实用价值。

**Abstract:** Recent advances in large language models (LLMs) enabled the development of AI
agents that can plan and interact with tools to complete complex tasks.
However, literature on their reliability in real-world applications remains
limited. In this paper, we introduce a multi-agent framework for a marketing
task: audience curation. To solve this, we introduce a framework called RAMP
that iteratively plans, calls tools, verifies the output, and generates
suggestions to improve the quality of the audience generated. Additionally, we
equip the model with a long-term memory store, which is a knowledge base of
client-specific facts and past queries. Overall, we demonstrate the use of LLM
planning and memory, which increases accuracy by 28 percentage points on a set
of 88 evaluation queries. Moreover, we show the impact of iterative
verification and reflection on more ambiguous queries, showing progressively
better recall (roughly +20 percentage points) with more verify/reflect
iterations on a smaller challenge set, and higher user satisfaction. Our
results provide practical insights for deploying reliable LLM-based systems in
dynamic, industry-facing environments.

</details>


### [13] [MoNaCo: More Natural and Complex Questions for Reasoning Across Dozens of Documents](https://arxiv.org/abs/2508.11133)
*Tomer Wolfson,Harsh Trivedi,Mor Geva,Yoav Goldberg,Dan Roth,Tushar Khot,Ashish Sabharwal,Reut Tsarfaty*

Main category: cs.CL

> 新的基准测验MoNaCo包含1,315个复杂问题，结果表明前沿模型在此上有提升空间，需改进推理模型。

<details>
  <summary>Details</summary>

**Motivation:** 当前大型语言模型的基准测验很少包含既是信息查询又是非常耗时的自然问题。MoNaCo旨在填补这一空白，激励开发能处理复杂信息查询的模型。

**Method:** 本研究开发了一个名为MoNaCo的新基准测试，包含1,315个复杂且自然的问题，这些问题需要数十甚至上百个中间步骤才能解决。研究采用了一种分解式的标注流水线，以大规模收集和手动回答这类问题。

**Result:** 前沿的语言模型在MoNaCo上的表现最高只能达到61.2%的F1分数，主要因为低召回率和幻觉（hallucinations）问题。

**Conclusion:** 实验结果强调了需要更好的推理模型来处理现实世界信息查询的复杂性。MoNaCo提供了一个追踪此类进展的有效资源。

**Abstract:** Large language models (LLMs) are emerging as a go-to tool for querying
information. However, current LLM benchmarks rarely feature natural questions
that are both information-seeking as well as genuinely time-consuming for
humans. To address this gap we introduce MoNaCo, a benchmark of 1,315 natural
and complex questions that require dozens, and at times hundreds, of
intermediate steps to solve -- far more than any existing QA benchmark. To
build MoNaCo, we developed a decomposed annotation pipeline to elicit and
manually answer natural time-consuming questions at scale. Frontier LLMs
evaluated on MoNaCo achieve at most 61.2% F1, hampered by low recall and
hallucinations. Our results underscore the need for reasoning models that
better handle the complexity and sheer breadth of real-world
information-seeking questions -- with MoNaCo providing an effective resource
for tracking such progress. The MONACO benchmark, codebase, prompts and models
predictions are publicly available at: https://tomerwolgithub.github.io/monaco

</details>


### [14] [MobQA: A Benchmark Dataset for Semantic Understanding of Human Mobility Data through Question Answering](https://arxiv.org/abs/2508.11163)
*Hikaru Asano,Hiroki Ouchi,Akira Kasuga,Ryo Yonetani*

Main category: cs.CL

> MobQA数据集用于评估LLMs在人类移动数据语义理解方面的能力，发现这些模型在事实检索方面表现良好，但在语义推理和解释方面存在显著限制。

<details>
  <summary>Details</summary>

**Motivation:** 虽然现有的模型在预测人类行为模式方面表现出色，但它们对这些模式背后的原因或语义的理解程度尚不清楚。MobQA提供了评估LLMs理解能力的框架。

**Method:** MobQA是一个基准数据集，旨在通过自然语言问答来评估大型语言模型（LLMs）对人类移动数据的语义理解能力。它包括5,800对高质量的问答，涵盖三种不同类型的题目：事实检索、多选推理和自由解释。

**Result:** 评估了主要的LLMs后，发现它们在事实检索方面表现出色，但在语义推理和解释方面存在显著限制，移动轨迹长度对模型的有效性有重大影响。

**Conclusion:** 这些发现展示了当前最先进的LLMs在语义移动理解方面的成就和局限性。

**Abstract:** This paper presents MobQA, a benchmark dataset designed to evaluate the
semantic understanding capabilities of large language models (LLMs) for human
mobility data through natural language question answering.
  While existing models excel at predicting human movement patterns, it remains
unobvious how much they can interpret the underlying reasons or semantic
meaning of those patterns. MobQA provides a comprehensive evaluation framework
for LLMs to answer questions about diverse human GPS trajectories spanning
daily to weekly granularities. It comprises 5,800 high-quality question-answer
pairs across three complementary question types: factual retrieval (precise
data extraction), multiple-choice reasoning (semantic inference), and free-form
explanation (interpretive description), which all require spatial, temporal,
and semantic reasoning. Our evaluation of major LLMs reveals strong performance
on factual retrieval but significant limitations in semantic reasoning and
explanation question answering, with trajectory length substantially impacting
model effectiveness. These findings demonstrate the achievements and
limitations of state-of-the-art LLMs for semantic mobility
understanding.\footnote{MobQA dataset is available at
https://github.com/CyberAgentAILab/mobqa.}

</details>


### [15] [Overcoming Low-Resource Barriers in Tulu: Neural Models and Corpus Creation for OffensiveLanguage Identification](https://arxiv.org/abs/2508.11166)
*Anusha M D,Deepthi Vikram,Bharathi Raja Chakravarthi,Parameshwar R Hegde*

Main category: cs.CL

> 本研究构建了首个图卢语混合代码冒犯性语言识别基准数据集，评估了多种深度学习模型，发现BiGRU与自我注意力机制结合效果最佳。

<details>
  <summary>Details</summary>

**Motivation:** 尽管图卢语的数字化程度不断提高，但该语言的计算资源仍然有限。这项工作的目的是填补该语言在冒犯性语言识别方面的研究空白，并为低资源混合语言的NLP研究奠定基础。

**Method:** 本研究构建了首个用于识别图卢语（一种在印度南部使用的德拉威语）混合代码社交媒体中的冒犯性语言的数据集，数据来自YouTube评论。该数据集包含3,845条评论，分为四类：非冒犯性，非图卢语，冒犯性但未针对特定群体和有目标的冒犯性内容。

**Result:** 评估了一系列深度学习模型包括GRU，LSTM，BiGRU，BiLSTM，CNN及其注意力机制版本，以及Transformer架构（mBERT，XLM-RoBERTa）。BiGRU模型结合自我注意力机制表现最佳，达到了82%的准确率和0.81的宏观F1分数。Transformer模型表现不佳，表明在混合语言和资源匮乏环境下多语言预训练的局限性。

**Conclusion:** 本研究为图卢语及类似低资源、混合语言背景下的NLP研究铺平了道路，也表明在资源匮乏的语言环境中，预训练模型可能面临挑战。

**Abstract:** Tulu, a low-resource Dravidian language predominantly spoken in southern
India, has limited computational resources despite its growing digital
presence. This study presents the first benchmark dataset for Offensive
Language Identification (OLI) in code-mixed Tulu social media content,
collected from YouTube comments across various domains. The dataset, annotated
with high inter-annotator agreement (Krippendorff's alpha = 0.984), includes
3,845 comments categorized into four classes: Not Offensive, Not Tulu,
Offensive Untargeted, and Offensive Targeted. We evaluate a suite of deep
learning models, including GRU, LSTM, BiGRU, BiLSTM, CNN, and attention-based
variants, alongside transformer architectures (mBERT, XLM-RoBERTa). The BiGRU
model with self-attention achieves the best performance with 82% accuracy and a
0.81 macro F1-score. Transformer models underperform, highlighting the
limitations of multilingual pretraining in code-mixed, under-resourced
contexts. This work lays the foundation for further NLP research in Tulu and
similar low-resource, code-mixed languages.

</details>


### [16] [Personalized Distractor Generation via MCTS-Guided Reasoning Reconstruction](https://arxiv.org/abs/2508.11184)
*Tao Wu,Jingyuan Chen,Wang Lin,Jian Zhan,Mengze Li,Kun Kuang,Fei Wu*

Main category: cs.CL

> 该论文提出了一种基于学生过去的问答记录生成个性化干扰选项的方法，以更好地诊断个体学生的概念误解。该方法分为两个阶段：第一阶段，使用蒙特卡洛树搜索（MCTS）从学生过去的错误答案中恢复其推理轨迹，构建学生特定的误解原型；第二阶段，利用该原型模拟学生在新问题上的推理，生成符合学生特定概念误解的个性化干扰选项。实验表明，此方法在为140名学生生成合理且个性化的干扰选项方面表现出色，并且能够有效推广到群体设置中。

<details>
  <summary>Details</summary>

**Motivation:** 虽然现有的大规模语言模型（LLMs）可以生成针对群体的干扰选项，但这些选项往往无法捕捉个体学生的多样化推理错误，限制了它们的诊断效用。因此，作者提出了一种新的任务：个性化干扰选项生成。

**Method:** 该方法采用无训练的两阶段框架。第一阶段，使用MCTS从学生过去的错误答案中恢复推理轨迹，构建学生特定的误解原型。第二阶段，利用该原型引导新问题上的推理模拟，生成符合学生特定概念误解的个性化干扰选项。

**Result:** 实验结果显示，该方法在为140名学生生成合理且个性化的干扰选项方面取得了最佳性能，并且能够有效扩展到群体设置中，展现了其鲁棒性和适应性。

**Conclusion:** 该论文的方法通过创建学生特定的误解原型并模拟其在新问题上的推理，成功生成了高质量的个性化干扰选项，这对于提高教育评估的有效性具有重要意义。

**Abstract:** Distractors, incorrect but plausible answer choices in multiple-choice
questions (MCQs), play a critical role in educational assessment by diagnosing
student misconceptions. Recent work has leveraged large language models (LLMs)
to generate shared, group-level distractors by learning common error patterns
across large student populations. However, such distractors often fail to
capture the diverse reasoning errors of individual students, limiting their
diagnostic effectiveness. To address this limitation, we introduce the task of
personalized distractor generation, which aims to generate tailored distractors
based on individual misconceptions inferred from each student's past
question-answering (QA) records, ensuring every student receives options that
effectively exposes their specific reasoning errors. While promising, this task
is challenging because each student typically has only a few QA records, which
often lack the student's underlying reasoning processes, making training-based
group-level approaches infeasible. To overcome this, we propose a training-free
two-stage framework. In the first stage, we construct a student-specific
misconception prototype by applying Monte Carlo Tree Search (MCTS) to recover
the student's reasoning trajectories from past incorrect answers. In the second
stage, this prototype guides the simulation of the student's reasoning on new
questions, enabling the generation of personalized distractors that align with
the student's recurring misconceptions. Experiments show that our approach
achieves the best performance in generating plausible, personalized distractors
for 140 students, and also effectively generalizes to group-level settings,
highlighting its robustness and adaptability.

</details>


### [17] [Novel Parasitic Dual-Scale Modeling for Efficient and Accurate Multilingual Speech Translation](https://arxiv.org/abs/2508.11189)
*Chenyang Le,Yinfeng Xia,Huiyan Li,Manhong Wang,Yutao Sun,Xingyang Ma,Yanmin Qian*

Main category: cs.CL

> We introduce the Parasitic Dual-Scale Approach and KVSPN module, enhancing the Whisper Medium model's performance and inference efficiency for multilingual speech translation, achieving SOTA results with significant speed improvements.

<details>
  <summary>Details</summary>

**Motivation:** The motivation arises from the challenge of balancing inference efficiency and performance in multilingual speech-to-text models, particularly in the context of local deployment. The large parameter sizes of existing models make them difficult to use efficiently in such environments.

**Method:** Our paper introduces a new method named the Parasitic Dual-Scale Approach which integrates an enhanced speculative sampling method with model compression and knowledge distillation techniques. This method is applied to the Whisper Medium model to improve its performance and efficiency for multilingual speech translation.

**Result:** The modified Whisper Medium model, named whisperM2M, together with the KVSPN module, achieves state-of-the-art performance for speech translation across six popular languages. KVSPN alone provides a 40% speedup without any compromise in BLEU scores. In combination with distillation techniques, a 2.6x speedup over the original Whisper Medium is achieved.

**Conclusion:** The proposed approach, including the KVSPN module and distilled Whisper Medium enhancement, not only maintains but also surpasses the original model's performance while significantly improving inference efficiency.

**Abstract:** Recent advancements in speech-to-text translation have led to the development
of multilingual models capable of handling multiple language pairs
simultaneously. However, these unified models often suffer from large parameter
sizes, making it challenging to balance inference efficiency and performance,
particularly in local deployment scenarios. We propose an innovative Parasitic
Dual-Scale Approach, which combines an enhanced speculative sampling method
with model compression and knowledge distillation techniques. Building on the
Whisper Medium model, we enhance it for multilingual speech translation into
whisperM2M, and integrate our novel KVSPN module, achieving state-of-the-art
(SOTA) performance across six popular languages with improved inference
efficiency. KVSPN enables a 40\% speedup with no BLEU score degradation.
Combined with distillation methods, it represents a 2.6$\times$ speedup over
the original Whisper Medium with superior performance.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [18] [Privacy Enhancement for Gaze Data Using a Noise-Infused Autoencoder](https://arxiv.org/abs/2508.10918)
*Samantha Aziz,Oleg Komogortsev*

Main category: cs.CV

> 提出了一种用于保护凝视信号隐私的机制，利用潜在噪声自编码器防止用户未经同意在不同游戏会话中被重新识别，同时保持数据的可用性。

<details>
  <summary>Details</summary>

**Motivation:** 目的是在保留数据可用性的同时，保护用户的隐私不被侵犯。

**Method:** Structure

**Result:** 研究表明，这种方法能显著减少生物识别身份的可能性，同时数据的实用性仅轻微下降。

**Conclusion:** 该研究成功为基于凝视的系统提供了一种可用且有效的机制，用于保护敏感的凝视数据。

**Abstract:** We present a privacy-enhancing mechanism for gaze signals using a
latent-noise autoencoder that prevents users from being re-identified across
play sessions without their consent, while retaining the usability of the data
for benign tasks. We evaluate privacy-utility trade-offs across biometric
identification and gaze prediction tasks, showing that our approach
significantly reduces biometric identifiability with minimal utility
degradation. Unlike prior methods in this direction, our framework retains
physiologically plausible gaze patterns suitable for downstream use, which
produces favorable privacy-utility trade-off. This work advances privacy in
gaze-based systems by providing a usable and effective mechanism for protecting
sensitive gaze data.

</details>


### [19] [A Survey on Video Temporal Grounding with Multimodal Large Language Model](https://arxiv.org/abs/2508.10922)
*Jianlong Wu,Wei Liu,Ye Liu,Meng Liu,Liqiang Nie,Zhouchen Lin,Chang Wen Chen*

Main category: cs.CV

> 本文系统综述了基于多模态语言模型的视频时序定位(VTG-MLLMs)的现有研究，通过三维分类法分析，并提出未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 由于针对VTG-MLLMs的全面综述较少，该研究旨在填补这一空白，综述该领域的最新进展，提供系统化的分析。

**Method:** 该研究通过一个三维分类法系统性地考察当前基于多模态语言模型的视频时序定位(VTG-MLLMs)研究，包括多模态语言模型的功能角色、训练范式以及视频特征处理技术。

**Result:** 研究系统地探讨了VTG-MLLMs的功能角色、训练范式、视频特征处理技术，并讨论了基准数据集、评估协议和经验发现。还会识别现有局限并提出未来研究方向。

**Conclusion:** 本文旨在系统性地概括VTG-MLLMs的研究现状，同时提出未来研究的潜在方向，并欢迎读者在提供的GitHub存储库中寻找更多资源和细节。

**Abstract:** The recent advancement in video temporal grounding (VTG) has significantly
enhanced fine-grained video understanding, primarily driven by multimodal large
language models (MLLMs). With superior multimodal comprehension and reasoning
abilities, VTG approaches based on MLLMs (VTG-MLLMs) are gradually surpassing
traditional fine-tuned methods. They not only achieve competitive performance
but also excel in generalization across zero-shot, multi-task, and multi-domain
settings. Despite extensive surveys on general video-language understanding,
comprehensive reviews specifically addressing VTG-MLLMs remain scarce. To fill
this gap, this survey systematically examines current research on VTG-MLLMs
through a three-dimensional taxonomy: 1) the functional roles of MLLMs,
highlighting their architectural significance; 2) training paradigms, analyzing
strategies for temporal reasoning and task adaptation; and 3) video feature
processing techniques, which determine spatiotemporal representation
effectiveness. We further discuss benchmark datasets, evaluation protocols, and
summarize empirical findings. Finally, we identify existing limitations and
propose promising research directions. For additional resources and details,
readers are encouraged to visit our repository at
https://github.com/ki-lw/Awesome-MLLMs-for-Video-Temporal-Grounding.

</details>


### [20] [VSF: Simple, Efficient, and Effective Negative Guidance in Few-Step Image Generation Models By \underline{V}alue \underline{S}ign \underline{F}lip](https://arxiv.org/abs/2508.10931)
*Wenqi Guo,Shan Du*

Main category: cs.CV

> VSF, a novel method for enhancing negative prompt guidance in image generation models, demonstrates superior performance with minimal computational overhead and effectiveness across varied architectures.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the negative prompt guidance in few-step image generation models, providing a simpler and more effective method compared to existing techniques like classifier-free guidance (CFG), NASA, and NAG.

**Method:** We introduce Value Sign Flip (VSF), a method that dynamically suppresses undesired content by flipping the sign of attention values from negative prompts. It is efficient and integrates well with MMDiT-style architectures and cross-attention-based models.

**Result:** The experimental results indicate that VSF significantly enhances the adherence to negative prompts, surpassing previous methods in few-step models and even CFG in non-few-step models, with competitive image quality.

**Conclusion:** VSF is concluded as an effective and efficient approach to improving negative prompt adherence in fewer-step image and video generation tasks.

**Abstract:** We introduce Value Sign Flip (VSF), a simple and efficient method for
incorporating negative prompt guidance in few-step diffusion and flow-matching
image generation models. Unlike existing approaches such as classifier-free
guidance (CFG), NASA, and NAG, VSF dynamically suppresses undesired content by
flipping the sign of attention values from negative prompts. Our method
requires only small computational overhead and integrates effectively with
MMDiT-style architectures such as Stable Diffusion 3.5 Turbo, as well as
cross-attention-based models like Wan. We validate VSF on challenging datasets
with complex prompt pairs and demonstrate superior performance in both static
image and video generation tasks. Experimental results show that VSF
significantly improves negative prompt adherence compared to prior methods in
few-step models, and even CFG in non-few-step models, while maintaining
competitive image quality. Code and ComfyUI node are available in
https://github.com/weathon/VSF/tree/main.

</details>


### [21] [Relative Pose Regression with Pose Auto-Encoders: Enhancing Accuracy and Data Efficiency for Retail Applications](https://arxiv.org/abs/2508.10933)
*Yoli Shavit,Yosi Keller*

Main category: cs.CV

> 本研究提出了一种使用Camera Pose Auto-Encoders (PAEs) 进行相对位姿回归的新方法，该方法能提高绝对位姿回归的精度，并减少数据存储负担。

<details>
  <summary>Details</summary>

**Motivation:** 由于通过单张图像实现精确相机定位对于现代零售环境至关重要，但现有方法通常依赖大量数据存储。该工作的动机是提出一种利用PAE的方法，提高绝对位姿回归的准确性，并减少数据存储和采集的需求。

**Method:** 本研究扩展了Camera Pose Auto-Encoders (PAEs) 在相对位姿回归(RPR)的任务中的应用，并提出了一种利用PAE进行相对位姿回归来优化绝对位姿回归（APR）预测的新重定位方案。该方法无需额外存储图像或位姿数据。

**Result:** 实验结果表明，提出的用PAE指导的相对位姿回归方法可以有效改进绝对位姿回归预测，甚至在训练数据只有30%的情况下，也有很好的表现。

**Conclusion:** 本研究展示了PAE在相对位姿回归中的有效性，并证明了该方法在减少数据收集负担的同时，能够提高相机定位精度。代码和预训练模型可在指定链接下载。

**Abstract:** Accurate camera localization is crucial for modern retail environments,
enabling enhanced customer experiences, streamlined inventory management, and
autonomous operations. While Absolute Pose Regression (APR) from a single image
offers a promising solution, approaches that incorporate visual and spatial
scene priors tend to achieve higher accuracy. Camera Pose Auto-Encoders (PAEs)
have recently been introduced to embed such priors into APR. In this work, we
extend PAEs to the task of Relative Pose Regression (RPR) and propose a novel
re-localization scheme that refines APR predictions using PAE-based RPR,
without requiring additional storage of images or pose data. We first introduce
PAE-based RPR and establish its effectiveness by comparing it with image-based
RPR models of equivalent architectures. We then demonstrate that our refinement
strategy, driven by a PAE-based RPR, enhances APR localization accuracy on
indoor benchmarks. Notably, our method is shown to achieve competitive
performance even when trained with only 30% of the data, substantially reducing
the data collection burden for retail deployment. Our code and pre-trained
models are available at: https://github.com/yolish/camera-pose-auto-encoders

</details>


### [22] [ViPE: Video Pose Engine for 3D Geometric Perception](https://arxiv.org/abs/2508.10934)
*Jiahui Huang,Qunjie Zhou,Hesam Rabeti,Aleksandr Korovko,Huan Ling,Xuanchi Ren,Tianchang Shen,Jun Gao,Dmitry Slepichev,Chen-Hsuan Lin,Jiawei Ren,Kevin Xie,Joydeep Biswas,Laura Leal-Taixe,Sanja Fidler*

Main category: cs.CV

> ViPE 提出了一种处理视频的引擎，能从未校准视频中估计相机的内在参数、相机运动和稠密的深度图，适用于多种场景和相机模型，并在多个基准测试中表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 准确的3D几何感知是许多空间AI系统的基础，但获得从真实世界视频中获得一致和精确的3D标注仍然是一个挑战。ViPE旨在解决这个难题。

**Method:** ViPE从无约束的原始视频中有效地估计相机内参、运动和稠密的深度图，适用于多种相机模型，包括针孔、广角和全景相机。

**Result:** ViPE在TUM和KITTI序列上的未校准姿态估计基线中表现突出，性能提升了18%至50%，在单个GPU上运行速度为3-5FPS。

**Conclusion:** ViPE的开源以及大规模视频数据集的标注希望加速空间AI系统的发展。

**Abstract:** Accurate 3D geometric perception is an important prerequisite for a wide
range of spatial AI systems. While state-of-the-art methods depend on
large-scale training data, acquiring consistent and precise 3D annotations from
in-the-wild videos remains a key challenge. In this work, we introduce ViPE, a
handy and versatile video processing engine designed to bridge this gap. ViPE
efficiently estimates camera intrinsics, camera motion, and dense, near-metric
depth maps from unconstrained raw videos. It is robust to diverse scenarios,
including dynamic selfie videos, cinematic shots, or dashcams, and supports
various camera models such as pinhole, wide-angle, and 360{\deg} panoramas. We
have benchmarked ViPE on multiple benchmarks. Notably, it outperforms existing
uncalibrated pose estimation baselines by 18%/50% on TUM/KITTI sequences, and
runs at 3-5FPS on a single GPU for standard input resolutions. We use ViPE to
annotate a large-scale collection of videos. This collection includes around
100K real-world internet videos, 1M high-quality AI-generated videos, and 2K
panoramic videos, totaling approximately 96M frames -- all annotated with
accurate camera poses and dense depth maps. We open-source ViPE and the
annotated dataset with the hope of accelerating the development of spatial AI
systems.

</details>


### [23] [HQ-OV3D: A High Box Quality Open-World 3D Detection Framework based on Diffision Model](https://arxiv.org/abs/2508.10935)
*Qi Liu,Yabei Li,Hongsong Wang,Lei He*

Main category: cs.CV

> HQ-OV3D is introduced to enhance the geometric precision of pseudo-labels in 3D object detection, showing significant improvement over existing methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the issues of traditional 3D detection methods in open-world applications, specifically focusing on improving the geometric quality of pseudo-label bounding boxes.

**Method:** The paper proposes HQ-OV3D framework that includes an Intra-Modality Cross-Validated (IMCV) Proposal Generator for generating high-quality 3D proposals and an Annotated-Class Assisted (ACA) Denoiser for refining these proposals.

**Result:** Training with pseudo-labels generated by the HQ-OV3D approach achieves a 7.37% improvement in mAP on novel classes, compared to the state-of-the-art method.

**Conclusion:** The HQ-OV3D framework serves as a high-quality pseudo-label generator and can be used as a standalone open-vocabulary 3D detector or integrated into existing detection/annotation pipelines.

**Abstract:** Traditional closed-set 3D detection frameworks fail to meet the demands of
open-world applications like autonomous driving. Existing open-vocabulary 3D
detection methods typically adopt a two-stage pipeline consisting of
pseudo-label generation followed by semantic alignment. While vision-language
models (VLMs) recently have dramatically improved the semantic accuracy of
pseudo-labels, their geometric quality, particularly bounding box precision,
remains commonly neglected.To address this issue, we propose a High Box Quality
Open-Vocabulary 3D Detection (HQ-OV3D) framework, dedicated to generate and
refine high-quality pseudo-labels for open-vocabulary classes. The framework
comprises two key components: an Intra-Modality Cross-Validated (IMCV) Proposal
Generator that utilizes cross-modality geometric consistency to generate
high-quality initial 3D proposals, and an Annotated-Class Assisted (ACA)
Denoiser that progressively refines 3D proposals by leveraging geometric priors
from annotated categories through a DDIM-based denoising mechanism.Compared to
the state-of-the-art method, training with pseudo-labels generated by our
approach achieves a 7.37% improvement in mAP on novel classes, demonstrating
the superior quality of the pseudo-labels produced by our framework. HQ-OV3D
can serve not only as a strong standalone open-vocabulary 3D detector but also
as a plug-in high-quality pseudo-label generator for existing open-vocabulary
detection or annotation pipelines.

</details>


### [24] [Vision-Only Gaussian Splatting for Collaborative Semantic Occupancy Prediction](https://arxiv.org/abs/2508.10936)
*Cheng Chen,Hao Huang,Saurabh Bagchi*

Main category: cs.CV

> The paper introduces a new method using sparse 3D semantic Gaussian splatting for collaborative 3D semantic occupancy prediction in connected vehicles, providing better performance and reduced communication costs compared to existing methods.

<details>
  <summary>Details</summary>

**Motivation:** To surmount the challenges of high communication costs and limitations of dense 3D voxels or 2D planar features, and to better support collaborative perception among connected vehicles.

**Method:** Sparse 3D semantic Gaussian splatting is used for collaborative 3D semantic occupancy prediction, enabling neighborhood-based cross-agent fusion which removes duplicates and suppresses noisy Gaussians, joint encoding of geometry and semantics in each primitive, and sparse, object-centric messages that preserve structure while reducing communication volume.

**Result:** The method outperforms single-agent perception and baseline collaborative methods by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU, respectively. Even when reducing the number of transmitted Gaussians, it still achieves a +1.9 improvement in mIoU with only 34.6% communication volume.

**Conclusion:** Sparse 3D semantic Gaussian splatting improves collaborative 3D semantic occupancy prediction for connected vehicles by reducing communication costs while maintaining or enhancing performance.

**Abstract:** Collaborative perception enables connected vehicles to share information,
overcoming occlusions and extending the limited sensing range inherent in
single-agent (non-collaborative) systems. Existing vision-only methods for 3D
semantic occupancy prediction commonly rely on dense 3D voxels, which incur
high communication costs, or 2D planar features, which require accurate depth
estimation or additional supervision, limiting their applicability to
collaborative scenarios. To address these challenges, we propose the first
approach leveraging sparse 3D semantic Gaussian splatting for collaborative 3D
semantic occupancy prediction. By sharing and fusing intermediate Gaussian
primitives, our method provides three benefits: a neighborhood-based
cross-agent fusion that removes duplicates and suppresses noisy or inconsistent
Gaussians; a joint encoding of geometry and semantics in each primitive, which
reduces reliance on depth supervision and allows simple rigid alignment; and
sparse, object-centric messages that preserve structural information while
reducing communication volume. Extensive experiments demonstrate that our
approach outperforms single-agent perception and baseline collaborative methods
by +8.42 and +3.28 points in mIoU, and +5.11 and +22.41 points in IoU,
respectively. When further reducing the number of transmitted Gaussians, our
method still achieves a +1.9 improvement in mIoU, using only 34.6%
communication volume, highlighting robust performance under limited
communication budgets.

</details>


### [25] [Personalized Face Super-Resolution with Identity Decoupling and Fitting](https://arxiv.org/abs/2508.10937)
*Jiarui Yang,Hang Guo,Wen Huang,Tao Dai,Shutao Xia*

Main category: cs.CV

> 本研究提出了一种新的面部超级分辨率方法（IDFSR），通过解耦和拟合身份信息，旨在改善在极端退化情况下面部身份的一致性和恢复效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在极端退化情况下（如缩放比例大于8倍）难以恢复真实的面部身份信息，容易产生幻觉效果，导致重建的面部图像缺乏真实的面部身份特征。

**Method:** IDFSR方法包括三个关键设计：1) 对低分辨率图像中的面部区域进行遮罩处理以消除不可靠的身份线索；2) 调整参考图像以与低分辨率输入对齐，提供风格指导；3) 使用从地面实况图像中提取的身份嵌入进行精细的身份建模和个人化适应。首先预训练一个基于扩散的模型，以明确解耦风格和身份信息，再进行轻量化的身份嵌入微调。

**Result:** 实验表明，相较于现有方法，IDFSR在极端退化情况下显著提高了身份一致性和感知质量，特别是在高缩放比例时表现更为优越。

**Conclusion:** 通过解耦身份信息并利用微调后的身份嵌入，IDFSR方法能够在极端退化情况下成功增强身份信息的恢复，减少幻觉效果，提供更真实且一致的面部重建结果。

**Abstract:** In recent years, face super-resolution (FSR) methods have achieved remarkable
progress, generally maintaining high image fidelity and identity (ID)
consistency under standard settings. However, in extreme degradation scenarios
(e.g., scale $> 8\times$), critical attributes and ID information are often
severely lost in the input image, making it difficult for conventional models
to reconstruct realistic and ID-consistent faces. Existing methods tend to
generate hallucinated faces under such conditions, producing restored images
lacking authentic ID constraints. To address this challenge, we propose a novel
FSR method with Identity Decoupling and Fitting (IDFSR), designed to enhance ID
restoration under large scaling factors while mitigating hallucination effects.
Our approach involves three key designs: 1) \textbf{Masking} the facial region
in the low-resolution (LR) image to eliminate unreliable ID cues; 2)
\textbf{Warping} a reference image to align with the LR input, providing style
guidance; 3) Leveraging \textbf{ID embeddings} extracted from ground truth (GT)
images for fine-grained ID modeling and personalized adaptation. We first
pretrain a diffusion-based model to explicitly decouple style and ID by forcing
it to reconstruct masked LR face regions using both style and identity
embeddings. Subsequently, we freeze most network parameters and perform
lightweight fine-tuning of the ID embedding using a small set of target ID
images. This embedding encodes fine-grained facial attributes and precise ID
information, significantly improving both ID consistency and perceptual
quality. Extensive quantitative evaluations and visual comparisons demonstrate
that the proposed IDFSR substantially outperforms existing approaches under
extreme degradation, particularly achieving superior performance on ID
consistency.

</details>


### [26] [Deep Learning for Automated Identification of Vietnamese Timber Species: A Tool for Ecological Monitoring and Conservation](https://arxiv.org/abs/2508.10938)
*Tianyu Song,Van-Doan Duong,Thi-Phuong Le,Ton Viet Ta*

Main category: cs.CV

> 本研究利用深度学习技术实现了十种木材种类的高精度分类，ShuffleNetV2模型表现最优，在资源受限环境中具有应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的分类方法依赖于宏观和微观的检查，费时费力，并且需要专业知识。本研究旨在通过自动化方法提高生态监测、生物多样性保护和可持续森林管理的效率。

**Method:** 本研究探索了深度学习在自动化分类越南常见的十种木材种类中的应用。构建了一个源自现场采集木材样本的自定义图像数据集，并评估了五个最先进的卷积神经网络架构——ResNet50、EfficientNet、MobileViT、MobileNetV3和ShuffleNetV2。

**Result:** 在20次独立运行中，ShuffleNetV2表现最佳，实现了99.29%的平均准确率和99.35%的F1得分，显示了其在分类性能和计算效率之间的良好平衡。

**Conclusion:** 研究结果证明了轻量化深度学习模型在资源受限环境中进行实时、高精度物种识别的潜力。这项工作通过提供可扩展的图像解决方案，为自动化木材分类和森林生物多样性评估做出了贡献。

**Abstract:** Accurate identification of wood species plays a critical role in ecological
monitoring, biodiversity conservation, and sustainable forest management.
Traditional classification approaches relying on macroscopic and microscopic
inspection are labor-intensive and require expert knowledge. In this study, we
explore the application of deep learning to automate the classification of ten
wood species commonly found in Vietnam. A custom image dataset was constructed
from field-collected wood samples, and five state-of-the-art convolutional
neural network architectures--ResNet50, EfficientNet, MobileViT, MobileNetV3,
and ShuffleNetV2--were evaluated. Among these, ShuffleNetV2 achieved the best
balance between classification performance and computational efficiency, with
an average accuracy of 99.29\% and F1-score of 99.35\% over 20 independent
runs. These results demonstrate the potential of lightweight deep learning
models for real-time, high-accuracy species identification in
resource-constrained environments. Our work contributes to the growing field of
ecological informatics by providing scalable, image-based solutions for
automated wood classification and forest biodiversity assessment.

</details>


### [27] [NIRMAL Pooling: An Adaptive Max Pooling Approach with Non-linear Activation for Enhanced Image Classification](https://arxiv.org/abs/2508.10940)
*Nirmal Gaud,Krishna Kumar Jha,Jhimli Adhikari,Adhini Nasarin P S,Joydeep Das,Samarth S Deshpande,Nitasha Barara,Vaduguru Venkata Ramya,Santu Saha,Mehmet Tarik Baran,Sarangi Venkateshwarlu,Anusha M D,Surej Mouli,Preeti Katiyar,Vipin Kumar Chaudhary*

Main category: cs.CV

> NIRMAL Pooling outperforms Max Pooling in image classification, delivering better results on three benchmark datasets.

<details>
  <summary>Details</summary>

**Motivation:** To improve robustness and feature expressiveness in image classification tasks by dynamically adjusting pooling parameters.

**Method:** NIRMAL Pooling, a novel pooling layer for CNNs that integrates adaptive max pooling with ReLU activation function.

**Result:** NIRMAL Pooling shows improved test accuracies over standard Max Pooling on MNIST Digits, MNIST Fashion, and CIFAR-10 datasets.

**Conclusion:** NIRMAL Pooling enhances CNN performance across diverse image recognition tasks, providing a flexible and reliable pooling method.

**Abstract:** This paper presents NIRMAL Pooling, a novel pooling layer for Convolutional
Neural Networks (CNNs) that integrates adaptive max pooling with non-linear
activation function for image classification tasks. The acronym NIRMAL stands
for Non-linear Activation, Intermediate Aggregation, Reduction, Maximum,
Adaptive, and Localized. By dynamically adjusting pooling parameters based on
desired output dimensions and applying a Rectified Linear Unit (ReLU)
activation post-pooling, NIRMAL Pooling improves robustness and feature
expressiveness. We evaluated its performance against standard Max Pooling on
three benchmark datasets: MNIST Digits, MNIST Fashion, and CIFAR-10. NIRMAL
Pooling achieves test accuracies of 99.25% (vs. 99.12% for Max Pooling) on
MNIST Digits, 91.59% (vs. 91.44%) on MNIST Fashion, and 70.49% (vs. 68.87%) on
CIFAR-10, demonstrating consistent improvements, particularly on complex
datasets. This work highlights the potential of NIRMAL Pooling to enhance CNN
performance in diverse image recognition tasks, offering a flexible and
reliable alternative to traditional pooling methods.

</details>


### [28] [Topological Structure Description for Artcode Detection Using the Shape of Orientation Histogram](https://arxiv.org/abs/2508.10942)
*Liming Xu,Dave Towey,Andrew P. French,Steve Benford*

Main category: cs.CV

> 本文研究了识别Artcodes存在的一种新计算机视觉任务，提出了一种新的特征描述符，并通过实验验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 研究一种特殊类型的连接虚拟元素的对象——Artcodes，这是一种具有自由形式外观的、对人类有意义且可由机器读取的装饰标记。

**Method:** 本文提出了一种新的特征描述符，称为方向直方图形状，用于描述Artcode的通用拓扑结构。

**Result:** 所构建的基于新特征向量的Artcode检测提案系统的性能通过收集的数据集和综合实验得到了评估。

**Conclusion:** 实验结果表明，所提出的特征向量用于表示拓扑结构的可行性以及用于检测Artcode提案的有效性。这项工作为进一步开发基于特征的拓扑对象检测系统奠定了基础。

**Abstract:** The increasing ubiquity of smartphones and resurgence of VR/AR techniques, it
is expected that our everyday environment may soon be decorating with objects
connecting with virtual elements. Alerting to the presence of these objects is
therefore the first step for motivating follow-up further inspection and
triggering digital material attached to the objects. This work studies a
special kind of these objects -- Artcodes -- a human-meaningful and
machine-readable decorative markers that camouflage themselves with freeform
appearance by encoding information into their topology. We formulate this
problem of recongising the presence of Artcodes as Artcode proposal detection,
a distinct computer vision task that classifies topologically similar but
geometrically and semantically different objects as a same class. To deal with
this problem, we propose a new feature descriptor, called the shape of
orientation histogram, to describe the generic topological structure of an
Artcode. We collect datasets and conduct comprehensive experiments to evaluate
the performance of the Artcode detection proposer built upon this new feature
vector. Our experimental results show the feasibility of the proposed feature
vector for representing topological structures and the effectiveness of the
system for detecting Artcode proposals. Although this work is an initial
attempt to develop a feature-based system for detecting topological objects
like Artcodes, it would open up new interaction opportunities and spark
potential applications of topological object detection.

</details>


### [29] [Analysis of the Compaction Behavior of Textile Reinforcements in Low-Resolution In-Situ CT Scans via Machine-Learning and Descriptor-Based Methods](https://arxiv.org/abs/2508.10943)
*Christian Düreth,Jan Condé-Wolter,Marek Danczak,Karsten Tittmann,Jörn Jaschinski,Andreas Hornig,Maik Gude*

Main category: cs.CV

> 通过低分辨率CT扫描和定制的3D-UNet模型，本研究提出了一个量化纺织增强复合材料嵌套行为的方法，并证明了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 深入理解跨多尺度的材料结构对于预测纺织增强复合材料的性能至关重要，而相邻织物层之间的嵌套行为在定义其机械性能方面扮演着关键角色。

**Method:** 本研究通过低分辨率CT扫描，在不同堆叠配置下的干纺织增强材料的原位压实实验中量化了材料的嵌套行为。利用定制的3D-UNet实现了压实过程中纤维体积含量为50-60%的基质、纬纱及经纱相的语义分割。

**Result:** 该模型达到了最小平均交并比（Intersection-over-Union）为0.822和F1评分为0.902的性能。通过二维相关函数S2，建立了一个概率提取平均层厚度和嵌套程度的空间结构分析方法。结果与基于显微照片的验证结果高度一致。

**Conclusion:** 这种方法提供了一种从工业相关的CT数据中提取关键几何特性的稳健方法，也为复合预成型件的反向建模和描述符为基础的结构分析奠定了基础。

**Abstract:** A detailed understanding of material structure across multiple scales is
essential for predictive modeling of textile-reinforced composites. Nesting --
characterized by the interlocking of adjacent fabric layers through local
interpenetration and misalignment of yarns -- plays a critical role in defining
mechanical properties such as stiffness, permeability, and damage tolerance.
This study presents a framework to quantify nesting behavior in dry textile
reinforcements under compaction using low-resolution computed tomography (CT).
In-situ compaction experiments were conducted on various stacking
configurations, with CT scans acquired at 20.22 $\mu$m per voxel resolution. A
tailored 3D{-}UNet enabled semantic segmentation of matrix, weft, and fill
phases across compaction stages corresponding to fiber volume contents of
50--60 %. The model achieved a minimum mean Intersection-over-Union of 0.822
and an $F1$ score of 0.902. Spatial structure was subsequently analyzed using
the two-point correlation function $S_2$, allowing for probabilistic extraction
of average layer thickness and nesting degree. The results show strong
agreement with micrograph-based validation. This methodology provides a robust
approach for extracting key geometrical features from industrially relevant CT
data and establishes a foundation for reverse modeling and descriptor-based
structural analysis of composite preforms.

</details>


### [30] [iWatchRoad: Scalable Detection and Geospatial Visualization of Potholes for Smart Cities](https://arxiv.org/abs/2508.10945)
*Rishi Raj Sahoo,Surbhi Saswati Mohanty,Subhankar Mishra*

Main category: cs.CV

> 本文提出了一个名为iWatchRoad的端到端系统，用于路坑的自动检测、地理标注和实时绘制，使用了YOLO模型进行实时检测并使用OCR提取时间戳，显著提升了检测精度，并为道路管理提供了实用工具。

<details>
  <summary>Details</summary>

**Motivation:** 路坑对道路安全和车辆寿命构成严重威胁，特别是在维护不足的复杂道路上，例如印度的环境。因此，本文旨在提出一种成本低廉、硬件高效并且可扩展的系统，用于路坑检测和维护规划，从而改善道路条件并促进城市和农村的道路管理。

**Method:** 本文提出了一种名为iWatchRoad的从数据采集到处理再到可视化的全自动路坑检测系统。该系统利用YOLO模型实现实时路坑检测，并使用自定义的OCR模块从视频帧中提取时间戳。时间戳与GPS日志同步以准确地地理标记每个检测到的路坑。

**Result:** 开发了一个独特的、具有7000多个帧的自我标注数据集，用于训练YOLO模型进行路坑检测。系统不仅能够在具有挑战性的条件下提高检测精度，还能够生成政府兼容的用于道路评估和维护计划的输出。

**Conclusion:** iWatchRoad系统展现出高精度和实用性，特别是在变化多端的印度道路情况下。它不仅带来更高效的检测流程，还提供易于政府使用的成本效益和硬件高效的解决方案，适用于城市和农村道路管理。

**Abstract:** Potholes on the roads are a serious hazard and maintenance burden. This poses
a significant threat to road safety and vehicle longevity, especially on the
diverse and under-maintained roads of India. In this paper, we present a
complete end-to-end system called iWatchRoad for automated pothole detection,
Global Positioning System (GPS) tagging, and real time mapping using
OpenStreetMap (OSM). We curated a large, self-annotated dataset of over 7,000
frames captured across various road types, lighting conditions, and weather
scenarios unique to Indian environments, leveraging dashcam footage. This
dataset is used to fine-tune, Ultralytics You Only Look Once (YOLO) model to
perform real time pothole detection, while a custom Optical Character
Recognition (OCR) module was employed to extract timestamps directly from video
frames. The timestamps are synchronized with GPS logs to geotag each detected
potholes accurately. The processed data includes the potholes' details and
frames as metadata is stored in a database and visualized via a user friendly
web interface using OSM. iWatchRoad not only improves detection accuracy under
challenging conditions but also provides government compatible outputs for road
assessment and maintenance planning through the metadata visible on the
website. Our solution is cost effective, hardware efficient, and scalable,
offering a practical tool for urban and rural road management in developing
regions, making the system automated. iWatchRoad is available at
https://smlab.niser.ac.in/project/iwatchroad

</details>
