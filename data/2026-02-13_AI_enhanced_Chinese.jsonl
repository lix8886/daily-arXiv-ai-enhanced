{"id": "2602.11214", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.11214", "abs": "https://arxiv.org/abs/2602.11214", "authors": ["Manuel Hetzel", "Kerim Turacan", "Hannes Reichert", "Konrad Doll", "Bernhard Sick"], "title": "DD-MDN: Human Trajectory Forecasting with Diffusion-Based Dual Mixture Density Networks and Uncertainty Self-Calibration", "comment": null, "summary": "Human Trajectory Forecasting (HTF) predicts future human movements from past trajectories and environmental context, with applications in Autonomous Driving, Smart Surveillance, and Human-Robot Interaction. While prior work has focused on accuracy, social interaction modeling, and diversity, little attention has been paid to uncertainty modeling, calibration, and forecasts from short observation periods, which are crucial for downstream tasks such as path planning and collision avoidance. We propose DD-MDN, an end-to-end probabilistic HTF model that combines high positional accuracy, calibrated uncertainty, and robustness to short observations. Using a few-shot denoising diffusion backbone and a dual mixture density network, our method learns self-calibrated residence areas and probability-ranked anchor paths, from which diverse trajectory hypotheses are derived, without predefined anchors or endpoints. Experiments on the ETH/UCY, SDD, inD, and IMPTC datasets demonstrate state-of-the-art accuracy, robustness at short observation intervals, and reliable uncertainty modeling. The code is available at: https://github.com/kav-institute/ddmdn.", "AI": {"tldr": "本文研究了人体轨迹预测问题，提出了一种新的端到端概率模型DD-MDN，具备高精度、校准的不确定性建模以及处理短观察期的能力。", "motivation": "尽管先前的研究集中于精度、社会互动建模及多样性，但很少有人关注不确定性建模、校准以及基于短观察期的预测，这些对于下游任务如路径规划和避撞至关重要。本研究旨在填补这个空白。", "method": "我们提出了DD-MDN模型，这是一个端到端的概率人体轨迹预测模型，结合了高位置精度、校准的不确定性以及对短观察期的鲁棒性。使用少量样本的去噪扩散主干网络和双重混合密度网络，我们的方法学习自校准的居住区域和概率排名锚点路径，从中推导出多样化的轨迹假设，无需预定义的锚点或终点。", "result": "在ETH/UCY、SDD、inD和IMPTC数据集上的实验表明，我们的方法达到了最先进的准确性、在短观察间隔下的鲁棒性以及可靠的不确定性建模。", "conclusion": "提出的DD-MDN模型在实验中展现出优越的性能，具有高精度、鲁棒性及可靠的不确定性建模能力。"}}
{"id": "2602.11236", "categories": ["cs.CV", "cs.CL", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.11236", "abs": "https://arxiv.org/abs/2602.11236", "authors": ["Yandan Yang", "Shuang Zeng", "Tong Lin", "Xinyuan Chang", "Dekang Qi", "Junjin Xiao", "Haoyun Liu", "Ronghan Chen", "Yuzhi Chen", "Dongjie Huo", "Feng Xiong", "Xing Wei", "Zhiheng Ma", "Mu Xu"], "title": "ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning", "comment": "Project website: https://amap-cvlab.github.io/ABot-Manipulation/ . Code: https://github.com/amap-cvlab/ABot-Manipulation . 22 pages, 10 figures, 10 tables", "summary": "Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.", "AI": {"tldr": "ABot-M0 是一个框架，它构建了一个系统的数据整理管道，同时优化模型架构和训练策略，将异构的原始数据转换为统一、有效的表示，支持跨平台和任务的知识转移和泛化，提高行动预测的效率和稳定性，并且增强了三维空间理解能力。", "motivation": "解决机器人领域跨多样硬件构建通用嵌入代理的挑战，克服数据分散、表示不一致和训练目标不一致的问题，支持跨平台和任务的通用嵌入智能。", "method": "通过系统的数据清理，标准化与平衡构建UniACT数据集；提出行动流形假设并引入行动流形学习（AML），使用DiT骨干预测干净、连续的动作序列；提出模块化感知的双流机制，将视觉语言模型的语义与几何先验以及多个视角的信息融合，提升空间理解能力。", "result": "实验表明ABot-M0的各个组件可以独立工作，有累积的好处。将会发布所有的代码和流程以促进可重复性和未来研究。", "conclusion": "ABot-M0框架通过高效的数据转换和统一的预训练支持了跨多样化机器形态和任务场景的机器人智能，提出了新的行动预测策略和模块化感知机制以提高性能。"}}
{"id": "2602.11239", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11239", "abs": "https://arxiv.org/abs/2602.11239", "authors": ["Samanta Ghosh", "Jannatul Adan Mahi", "Shayan Abrar", "Md Parvez Mia", "Asaduzzaman Rayhan", "Abdul Awal Yasir", "Asaduzzaman Hridoy"], "title": "Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training", "comment": "6 pages,9 figures, 2025 IEEE International Women in Engineering (WIE) Conference on Electrical and Computer Engineering (WIECON-ECE)", "summary": "Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.", "AI": {"tldr": "本研究提出了一种使用深度学习模型自动识别茶树叶片疾病的方案，通过对teaLeafBD数据集的训练，成功实现了高精度的疾病分类，为农业管理提供了新技术手段。", "motivation": "由于手动检测茶树叶片疾病存在困难且容易出错，因此本研究的目的是开发一种自动化和高效的疾病分类方法，以促进高效农业管理。", "method": "研究旨在开发一个基于深度学习的自动化的自动分类模型，用于分类茶树叶片疾病。该模型利用了名为teaLeafBD的数据集，该数据集包含5,278张高分辨率图像，这些图像被分类为七个类别，其中六个代表不同的疾病，一个代表健康的叶片。该研究使用了DenseNet201和EfficientNetB3模型，并采用了对抗性训练和数据增强等技术，以提高模型的鲁棒性和准确性。", "result": "实验结果表明，EfficientNetB3达到了93%的最高分类准确率，而DenseNet201则达到了91%。", "conclusion": "研究证明了所提方法能够准确检测茶树叶片疾病，并提供了先进农业管理的一个实用解决方案。"}}
{"id": "2602.11241", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.11241", "abs": "https://arxiv.org/abs/2602.11241", "authors": ["Jinghan He", "Junfeng Fang", "Feng Xiong", "Zijun Yao", "Fei Shen", "Haiyun Guo", "Jinqiao Wang", "Tat-Seng Chua"], "title": "Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration", "comment": null, "summary": "Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2602.11156", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.11156", "abs": "https://arxiv.org/abs/2602.11156", "authors": ["Sungmoon Kim", "Hyuna Jeon", "Dahye Kim", "Mingyu Kim", "Dong-Kyu Chae", "Jiwoong Kim"], "title": "HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents", "comment": null, "summary": "Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.", "AI": {"tldr": "HybridRAG是一种新型的RAG框架，它能够处理复杂的无结构文档并预先生成问答知识库，从而提供更快更准确的聊天机器人响应。", "motivation": "传统的检索增强生成(RAG)方法假设了结构良好的文本源，并在查询时执行检索和生成，这限制了它们在实际聊天机器人场景中的应用。HybridRAG旨在解决处理大量无结构文档并提供更准确和更快速的聊天机器人响应的问题。", "method": "首先，HybridRAG通过光学字符识别(OCR)和布局分析摄入包含复杂布局（文本、表格、图表）的原始无结构PDF文档，并将它们转换为分层文本块。然后，使用大语言模型(LLM)从组织好的文本块中预先生成一个合理的问答知识库。在查询时，用户的问题会与这个问答库进行匹配以检索即时答案。只有当没有合适的问答匹配时，框架才会退回至即时响应生成。", "result": "实验表明，与标准RAG基线相比，HybridRAG提供了更高的答案质量和更低的延迟。", "conclusion": "HybridRAG可以作为一个能够处理大量无结构文档和大量用户的实际聊天机器人应用的解决方案，尤其是在有限的计算资源情况下。"}}
{"id": "2602.11242", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11242", "abs": "https://arxiv.org/abs/2602.11242", "authors": ["Yitong Wang", "Yue Yao"], "title": "ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems", "comment": null, "summary": "We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts \"what to do\" and \"what not to do\" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?", "AI": {"tldr": "ReTracing 是一个以考古学方法探讨人工智能对人类身体动作影响的多智能体具身表演艺术，揭示了社会文化偏见如何通过生成系统编码在动作中，并提出了关于人工智能时代的“人类性”的问题。", "motivation": "研究人工智能如何影响和重塑人类身体动作，并通过艺术形式来审视人工智能的社会文化影响。", "method": "从科幻小说中提取描述人机交互的句子，使用大型语言模型生成动作指令提示，通过文本到视频的扩散模型将这些指令转换为人类表演者和四足机器人执行的动作指南。", "result": "通过多镜头动作捕捉和重建为3D点云和动作轨迹，形成了动作轨迹的数字档案。过程中揭示了生成系统如何通过编排的动作编码社会文化偏见。通过AI、人类和机器人之间的沉浸式互动，ReTracing提出了一个关键问题：在也会移动、思考并留下痕迹的人工智能中，作为人类意味着什么？", "conclusion": "ReTracing 作为一个多智能体具身表演艺术，采用考古学方法探讨人工智能如何塑造、限制和生成身体动作。通过生成系统编码的社会文化偏见的揭示，ReTracing 对人工智能时代中的“人类性”提出了疑问。"}}
{"id": "2602.11157", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.11157", "abs": "https://arxiv.org/abs/2602.11157", "authors": ["Max Zhang", "Derek Liu", "Kai Zhang", "Joshua Franco", "Haihao Liu"], "title": "Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety", "comment": "9 pages, Poster presented at Socially Responsible and Trustworthy Foundation Models at NeurIPS 2025 Workshop", "summary": "Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.", "AI": {"tldr": "研究通过知识蒸馏方法将模型的安全拒绝行为转化为多语言环境中的其他模型，发现标准微调会意外增加越狱成功率，但改良可以使安全性有所恢复。", "motivation": "大语言模型的安全对齐主要集中在英语中，因此，在非英语上下文中存在漏洞，尤其是在低资源语言中。此研究旨在通过知识蒸馏探索多语言越狱预防的安全对齐。", "method": "通过知识蒸馏(KD)方法，使用大约28000个多语言越狱提示，将特制教师模型（OpenAI o1-mini）的拒绝行为通过低秩适应（LoRA）技术，转移到三个开源学生模型中：Meta-Llama-3-8B-Instruct、Gemma-2-2B-IT和Qwen3-8B。", "result": "标准微调对教师模型的“安全”拒绝数据导致所有学生模型的越狱成功率（JSR）意外增加，最高达16.6个百分点。通过对“边界”拒绝的改良，研究减轻或甚至逆转了学生模型的安全性下降。", "conclusion": "本研究展示了知识蒸馏作为一种技术在多语言安全性对齐中的挑战和潜力，并为未来的研究提供了基础。"}}
{"id": "2602.11244", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11244", "abs": "https://arxiv.org/abs/2602.11244", "authors": ["Sethuraman T", "Savya Khosla", "Aditi Tiwari", "Vidya Ganesh", "Rakshana Jayaprakash", "Aditya Jain", "Vignesh Srinivasakumar", "Onkar Kishor Susladkar", "Srinidhi Sunkara", "Aditya Shanmugham", "Rakesh Vaideeswaran", "Abbaas Alif Mohamed Nishar", "Simon Jenni", "Derek Hoiem"], "title": "Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models", "comment": null, "summary": "This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.", "AI": {"tldr": "本文研究了视频语言模型（VidLMs）是否能稳健地处理视频内容、时间序列和运动。作者通过一个名为REVEAL的诊断基准测试发现，现有的VidLMs在处理时间预期偏差、依赖语言捷径、视频一致性、摄像机运动和时空遮挡时表现出明显的不足。同时，提出了自动生成诊断示例的数据管道，并计划发布基准测试和代码供未来研究使用。", "motivation": "研究视频语言模型（VidLMs）是否能够稳健地处理视频内容中的时间序列和运动，而这一点在现有模型中尚未得到很好的解决。通过深入探究几个关键问题，包括时间预期偏差、依赖语言捷径、视频一致性、摄像机运动敏感度及对时空遮挡的抗性，期望揭示和改进这些模型中的根本弱点。", "method": "引入REVEAL诊断基准测试，包含五个控制性压力测试以探查现代VidLMs的根本弱点。测试涵盖时间预期偏差、依赖语言捷径、视频一致性、摄像机运动敏感度及对时空遮挡的抗性。", "result": "测试结果显示领先的开放式和封闭式源码VidLMs在逆向场景描述、忽视视频内容作答、回应错误声明、处理基础摄像机动作及合并受到简单时空遮挡的临时信息时存在显著问题。相比之下，人类在这些任务上表现良好。", "conclusion": "现有的视频语言模型在处理一连串关键任务上表现出显著弱点，这表明了未来改进和研究的需要。同时提供一个自动生成诊断示例的数据管道，并通过公开基准测试和代码支持未来的相关研究。"}}
{"id": "2602.11162", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.11162", "abs": "https://arxiv.org/abs/2602.11162", "authors": ["Yuping Lin", "Zitao Li", "Yue Xing", "Pengfei He", "Yingqian Cui", "Yaliang Li", "Bolin Ding", "Jingren Zhou", "Jiliang Tang"], "title": "Retrieval Heads are Dynamic", "comment": null, "summary": "Recent studies have identified \"retrieval heads\" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.", "AI": {"tldr": "本研究从动态角度分析大语言模型中的检索头，揭示了其在时间步上的变化，提出了三个核心观点，并在特定任务上进行了验证，提供了大语言模型内部机制的新见解。", "motivation": "之前的大部分研究依赖于跨数据集的静态统计数据，忽略了自回归生成中时间动态的细微差别。本研究从动态角度考察检索头。", "method": "通过广泛的分析，研究了检索头在时间步上的动态变化，并在针在稻草堆中的任务和多跳问答任务上验证了这些发现。", "result": "研究建立了三个核心观点：（1）动态性：检索头在时间步上动态变化；（2）不可替代性：特定时间步的动态检索头无法被静态检索头有效替代；（3）相关性：模型的隐藏状态包含了对未来检索头模式的预测信号，表明存在内部规划机制。", "conclusion": "该研究为理解大语言模型内部机制提供了新见解。"}}
{"id": "2602.11314", "categories": ["cs.CV", "cs.GR"], "pdf": "https://arxiv.org/pdf/2602.11314", "abs": "https://arxiv.org/abs/2602.11314", "authors": ["Jacob Rubinstein", "Avi Donaty", "Don Engel"], "title": "Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking", "comment": "9 pages, 10 figures. Preprint", "summary": "The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.", "AI": {"tldr": "提出一种利用高质量3D模型和程序生成的相机姿态来生成合成图像的新型流水线，用以进行可重复和可量化的实验，提高对3D模型生成技术的评估和理解。", "motivation": "目前，通过摄影测量生成3D模型的方法在设计选择上存在多样性，但这些方法之间的差异主要基于定性判断。希望通过更系统的方法来比较和量化这些差异。", "method": "采用从高质量3D模型生成合成图像的新型流水线，并结合程序生成的相机姿态，进行可重复和可量化的实验。", "result": "此方法能够比较虚拟相机参数和虚拟对象的实际值与重建估计值之间的差异，从而提供可重复和可量化的实验。", "conclusion": "这种新型流水线提供了一种新的方法来生成3D模型的合成图像，这种方法便于进行定量实验，促进对3D模型生成技术的理解和发展。"}}
{"id": "2602.11163", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11163", "abs": "https://arxiv.org/abs/2602.11163", "authors": ["Muhammad Haris", "Hans Höft", "Markus M. Becker", "Markus Stocker"], "title": "Nested Named Entity Recognition in Plasma Physics Research Articles", "comment": null, "summary": "Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.", "AI": {"tldr": "本文提出了一种基于BERT-CRF模型的轻量级方法，用于从等离子物理学研究文章中提取嵌套的命名实体，并提出了一个优化过程以提升模型性能，从而帮助科研人员提取关键信息以便高级搜索。", "motivation": "等离子物理学研究文章常常包含高度复杂且富含上下文的内容，必须从这些内容中提取关键实体以便支持高级搜索等功能。现有的实体识别方法在处理此类科学文本时具有挑战性，因此需要一种更有效的解决方案。", "method": "我们提出了一种基于编码器-变压器和条件随机场的轻量级方法，用于从等离子物理学研究文章中提取嵌套命名实体。第一步，我们使用16个专门设计用于嵌套NER任务的类别对等离子物理学语料库进行了标注。第二步，我们评估了实体特定模型专业化的方法，其中独立的BERT-CRF模型被训练以识别等离子物理学文本中的个体实体类型。第三步，我们集成了一个优化过程，系统地微调超参数并提升模型性能。", "result": "我们提出的方法提高了在等离子物理学领域中实体识别的准确性，并系统化地提升了模型性能，这为科研人员提供了一种有效的工具，帮助他们在科学研究文献中进行导航和分析。", "conclusion": "这项工作对等离子物理学领域的实体识别研究做出了重要贡献，也为科研人员提供了一个强大的工具，以支持他们在科学研究文献中进行导航和分析。"}}
{"id": "2602.11316", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11316", "abs": "https://arxiv.org/abs/2602.11316", "authors": ["Ishan Mishra", "Jiajie Li", "Deepak Mishra", "Jinjun Xiong"], "title": "Selective Prior Synchronization via SYNC Loss", "comment": null, "summary": "Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.", "AI": {"tldr": "This paper proposes an innovative method called SYNC loss that combines ad-hoc and post-hoc selective prediction techniques, leading to improved model generalization and performance on benchmarks.", "motivation": "To improve the selective prediction abilities of deep neural networks by leveraging uncertainty information, specifically the selective prior generated by post-hoc methods, not just during inference but also during training.", "method": "We propose the SYNC loss which integrates ad-hoc (SelectiveNet) and post-hoc (softmax response) method by incorporating the softmax response into the training process to enhance selective prediction capabilities.", "result": "Evaluated on CIFAR-100, ImageNet-100, and Stanford Cars datasets, our method enhances model generalization and surpasses previous works in selective prediction performance.", "conclusion": "The integration of the selective prior into the training stage through the SYNC loss improves deep neural networks' selective prediction performance and sets new benchmarks."}}
{"id": "2602.11165", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11165", "abs": "https://arxiv.org/abs/2602.11165", "authors": ["Pushwitha Krishnappa", "Amit Das", "Vinija Jain", "Tathagata Mukherjee", "Aman Chadha"], "title": "Assessing LLM Reliability on Temporally Recent Open-Domain Questions", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0", "AI": {"tldr": "通过RECOM基准数据集评估了四个开源LLM在处理近期Reddit问题上的效能。得出模型通过大量改写而非核心词的重用来维持语义；模型规模与性能表现无直接关系；提出多维度框架来评估语义保真度，而不仅仅是词法匹配。", "motivation": "探讨大语言模型对人类近期信息的理解对齐问题，尤其是在未能充分研究的开放领域问题上。", "method": "使用了RECOM数据集，在四个开源LLM（Llama3.1-8B, Mistral-7B, Gemma-2-9B, 和 GPT-OSS-20B）上评估了它们对近期信息的表现。使用了词法衡量指标（如BLEU，ROUGE），语义相似度衡量（如BERTScore，MoverScore，余弦相似度），以及逻辑推理（NLI）来评估对齐情况。", "result": "发现所有模型在对参考答案的余弦相似度上超过99%，但在BLEU-1重叠度上少于8%，表明模型通过大量改写保留了意义而不是文字上的重复。此外，模型规模并不一定影响性能，7B参数的Mistral-7B在所有指标上都优于20B参数的GPT-OSS-20B。NLI分析揭示，模型生成内容与人类共识相矛盾的情况不到7%。", "conclusion": "挑战仅依赖词法衡量指标来评估抽象生成的可靠性，提出应使用多维框架来捕捉超出表面层次文本匹配的语义保真度。"}}
{"id": "2602.11323", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11323", "abs": "https://arxiv.org/abs/2602.11323", "authors": ["Arda Alniak", "Sinan Kalkan", "Mustafa Mert Ankarali", "Afsar Saranli", "Abdullah Aydin Alatan"], "title": "MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors", "comment": "6 pages, 2 figures, 3 tables. Submitted to ICIP 2026", "summary": "Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.", "AI": {"tldr": "本文提出了一种新的框架，将学习到的深度先验集成到单目视觉惯性里程计系统中，通过严格遵守边缘设备的计算限制，该框架在低纹理环境下显著提高了系统的鲁棒性和准确性。", "motivation": "传统的单目视觉惯性里程计（VIO）系统在低纹理环境中因稀疏视觉特征不足而难以获得准确的姿态估计。近期基于Vision Transformer（ViT）的复杂基础模型虽能提供密集且几何结构一致的深度信息，但其计算需求往往阻碍了它们在边缘设备上的实时部署。本文旨在填补这一空白。", "method": "本文提出了一种新的框架，该框架将学习到的深度先验直接集成到VINS-Mono优化后端中，并强制执行仿射不变的深度一致性以及成对的序关系约束。通过基于方差的门控机制明确过滤不稳定的伪影，该方法严格遵守边缘设备的计算限制，同时稳健地恢复度量尺度。", "result": "在TartanGround和M3ED数据集上的广泛实验表明，本文提出的方法在具有挑战性的场景中防止了发散，并显著提高了准确度，将绝对轨迹误差（ATE）减少了多达28.3%。", "conclusion": "本文通过将深度先验集成到VINS-Mono优化后端并引入一种新的约束框架，实现了在低纹理环境下增强单目视觉惯性里程计系统的性能，提高了系统的鲁棒性和准确性。"}}
{"id": "2602.11166", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11166", "abs": "https://arxiv.org/abs/2602.11166", "authors": ["Xu Hu", "Yifan Zhang", "Songtao Wei", "Chen Zhao", "Qiannan Li", "Bingzhe Li", "Feng Chen"], "title": "Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?", "comment": "18 pages, 13 figures, 8 tables", "summary": "Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.", "AI": {"tldr": "研究人员发现，参数高效微调方法能显著提升大语言模型在幻觉检测任务中的表现，主要通过改变不确定性编码和呈现方式，而非单纯的注入新的知识点。", "motivation": "尽管参数高效微调方法广泛用于适应下游任务，并被认为可以提高事实正确性，但对于这些方法如何影响幻觉行为，尤其是在问答数据集上，了解还不够。因此，研究旨在解决这一不足。", "method": "本研究通过综合实证研究系统地调查了参数高效微调方法对幻觉检测的影响，研究涵盖了三个开源权重的语言模型骨架和三个事实寻求问答基准。对于每个模型，使用七种无监督幻觉检测方法进行性能评估，这些方法涵盖了三种互补的方法：基于语义一致性、基于置信度和基于熵的检测器。", "result": "研究结果表明，通过参数高效微调方法，幻觉检测能力得到显著提升，尤其是在不确定性编码方面的效果。", "conclusion": "实验结果表明，参数高效微调方法一致增强了幻觉检测能力，大幅提高了各种幻觉检测器的AUROC。进一步分析表明，这些方法主要影响了不确定性编码和呈现方式，而不仅仅是向模型中注入新的事实知识。"}}
{"id": "2602.11339", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.11339", "abs": "https://arxiv.org/abs/2602.11339", "authors": ["Evgeney Bogatyrev", "Khaled Abud", "Ivan Molodetskikh", "Nikita Alutis", "Dmitry Vatolin"], "title": "Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content", "comment": null, "summary": "Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.\n  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.\n  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.", "AI": {"tldr": "本文引入了适用于视频流场景的数据集StreamSR，并提出了一种名为EfRLFN的有效实时超分辨率模型，该模型显著提高了视觉质量和运行效率。研究还展示了通过微调模型可以在多个标准基准上获得性能提升。", "motivation": "尽管实时超分辨率技术为高清视频流媒体提供了更高的质量，但现有的方法难以处理压缩视频内容的独特挑战。现有数据集不能准确反映流媒体内容的特征，从而限制了相关基准的实用性。为此，本研究意在填补这个空缺。", "method": "本研究提出了一种名为EfRLFN的有效实时模型，该模型在实时超分辨率领域引入了高效通道注意力机制和双曲正切激活函数。同时，研究团队还对架构进行了深度优化以提高效率，并设计了一个复合损失函数来改善训练的收敛性。此外，他们还提出了一种专门用于视频流场景的数据集StreamSR，涵盖了各种视频类型和分辨率。", "result": "实验表明，EfRLFN结合了现有架构的优点，进一步提升了视觉质量和运行效率。同时，通过使用新的数据集对其他模型进行微调，这些模型在各种标准测试基准上的性能也得到了显著提高。", "conclusion": "研究展示了通过在新的数据集上对其他模型进行微调，可以获得在各类标准基准上通用的显著性能提升。本文提供的数据集、代码和基准评定工具已经在GitHub上开源并供他人使用。"}}
{"id": "2602.11167", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.11167", "abs": "https://arxiv.org/abs/2602.11167", "authors": ["Nathan Mao", "Varun Kaushik", "Shreya Shivkumar", "Parham Sharafoleslami", "Kevin Zhu", "Sunishchal Dev"], "title": "Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering", "comment": null, "summary": "Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.", "AI": {"tldr": "本研究介绍了一个用来捕捉和标准化由误导性引用导致的大型语言模型幻觉的FalseCite数据集，并提及GPT-4o-mini在这种误导性引用下产生了显著更多的幻觉。", "motivation": "大语言模型在生成信息时经常产生幻觉，即生成无意义或错误的信息，尤其是在医学或法律等敏感领域中非常有害。为了系统地研究这一现象，提出了FalseCite数据集。", "method": "研究者引入了一个名为FalseCite的数据集，用于捕捉和基准测试由误导性或伪造引用引发的幻觉响应。他们使用GPT-4o-mini，Falcon-7B，和Mistral 7-B这些大语言模型在FalseCite数据集上运行，并通过分析模型的内部状态，可视化和聚类隐藏状态矢量来研究这个问题。", "result": "研究发现，对于带有误导性引用的虚假信息，GPT-4o-mini模型的幻觉活动显著增加。无论是否存在幻觉，隐藏状态矢量倾向于展现出独特的角状图案。研究强调了FalseCite数据集在评价和缓解未来LLM研究中幻觉问题方面的潜力。", "conclusion": "FalseCite数据集为评估和减少未来大语言模型中的幻觉提供了一个基础。"}}
