{"id": "2509.03609", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.03609", "abs": "https://arxiv.org/abs/2509.03609", "authors": ["Shengkai Sun", "Zefan Zhang", "Jianfeng Dong", "Zhiyong Cheng", "Xiaojun Chang", "Meng Wang"], "title": "Towards Efficient General Feature Prediction in Masked Skeleton Modeling", "comment": "Accepted by ICCV 2025", "summary": "Recent advances in the masked autoencoder (MAE) paradigm have significantly\npropelled self-supervised skeleton-based action recognition. However, most\nexisting approaches limit reconstruction targets to raw joint coordinates or\ntheir simple variants, resulting in computational redundancy and limited\nsemantic representation. To address this, we propose a novel General Feature\nPrediction framework (GFP) for efficient mask skeleton modeling. Our key\ninnovation is replacing conventional low-level reconstruction with high-level\nfeature prediction that spans from local motion patterns to global semantic\nrepresentations. Specifically, we introduce a collaborative learning framework\nwhere a lightweight target generation network dynamically produces diversified\nsupervision signals across spatial-temporal hierarchies, avoiding reliance on\npre-computed offline features. The framework incorporates constrained\noptimization to ensure feature diversity while preventing model collapse.\nExperiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits\nof our approach: Computational efficiency (with 6.2$\\times$ faster training\nthan standard masked skeleton modeling methods) and superior representation\nquality, achieving state-of-the-art performance in various downstream tasks.", "AI": {"tldr": "提出了一种新的自监督骨架动作识别方法GFP，提高了计算效率和语义表示能力，实验结果优于现有方法。", "motivation": "目的是解决现有方法中存在的计算冗余和语义表示有限的问题，通过改进的特征预测方法，提升动作识别性能。", "method": "我们提出了一种名为GFP（General Feature Prediction）的新框架，用高阶特征预测替代了传统的低层次重建，以提高计算效率和语义表示能力。该框架通过一个轻量级目标生成网络动态生成时空层次上的多样化监督信号，并采用约束优化确保特征多样性。", "result": "实验结果表明，我们的方法在计算效率方面提高了6.2倍，并且在NTU RGB+D 60, NTU RGB+D 120 和 PKU-MMD数据集上表现出了优越的表示质量和最先进的性能。", "conclusion": "GFP框架展示了卓越的计算效率和表示质量，在多种下游任务中达到了最先进的性能。"}}
{"id": "2509.03614", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.03614", "abs": "https://arxiv.org/abs/2509.03614", "authors": ["Seungho Choe", "Xiaoli Qin", "Abubakr Shafique", "Amanda Dy", "Susan Done", "Dimitrios Androutsos", "April Khademi"], "title": "Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge", "comment": "4 pages, 1 figures, final submission for MIDOG 2025 challenge", "summary": "Counting mitotic figures is time-intensive for pathologists and leads to\ninter-observer variability. Artificial intelligence (AI) promises a solution by\nautomatically detecting mitotic figures while maintaining decision consistency.\nHowever, AI tools are susceptible to domain shift, where a significant drop in\nperformance can occur due to differences in the training and testing sets,\nincluding morphological diversity between organs, species, and variations in\nstaining protocols. Furthermore, the number of mitoses is much less than the\ncount of normal nuclei, which introduces severely imbalanced data for the\ndetection task. In this work, we formulate mitosis detection as a pixel-level\nsegmentation and propose a teacher-student model that simultaneously addresses\nmitosis detection (Track 1) and atypical mitosis classification (Track 2). Our\nmethod is based on a UNet segmentation backbone that integrates domain\ngeneralization modules, namely contrastive representation learning and\ndomain-adversarial training. A teacher-student strategy is employed to generate\npixel-level pseudo-masks not only for annotated mitoses and hard negatives but\nalso for normal nuclei, thereby enhancing feature discrimination and improving\nrobustness against domain shift. For the classification task, we introduce a\nmulti-scale CNN classifier that leverages feature maps from the segmentation\nmodel within a multi-task learning paradigm. On the preliminary test set, the\nalgorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of\n0.8414 in Track 2, demonstrating the effectiveness of integrating\nsegmentation-based detection and classification into a unified framework for\nrobust mitosis analysis.", "AI": {"tldr": "提出一种新的教师-学生模型解决领域泛化问题，同时实现丝状分裂检测和分类，实现了性能上的显著提升。", "motivation": "希望通过AI提高丝状分裂计数的一致性和效率，同时解决领域泛化的问题。", "method": "采用UNet分割模型结合领域对抗训练和对比表示学习模块，利用教师-学生策略生成伪掩模，另外提出了一种多尺度CNN分类器用于非典型丝状分裂分类。", "result": "{\"tldr\": \"本文提出了一个基于UNet分割骨干网络的教师-学生模型，该模型通过对比表示学习和领域对抗训练模块解决领域泛化问题，同时实现了丝状分裂检测和非典型丝状分裂分类任务，并在初步测试集中取得了F1得分为0.7660和平衡准确率为0.8414的不错效果。\", \"motivation\": \"由于人工计数丝状分裂图像是耗时的，并且会导致观察者间的变异，而AI工具有能力自动检测丝状分裂，但这些工具对领域泛化问题敏感，导致训练集和测试集上性能变化。本文旨在解决上述问题并提高检测的一致性。\", \"method\": \"主要采用UNet作为分割骨干网络，并结合对比表示学习和领域对抗训练的领域泛化模块以及教师-学生策略来生成像素级伪掩膜增强特征分辨能力。另一方面，对于分类任务提出了一种融合特征图的多尺度CNN分类器，在多任务学习框架中使用以挖掘丝状分裂信息。\", \"result\": \"在初步测试集合上，本文方法在检测任务上取得了F1得分0.7660，在分类任务上取得了平衡准确率0.8414。\", \"conclusion\": \"本文成功展示了通过结合基于分割的检测和分类任务在统一框架中进行丝状分裂分析的有效性，能够提高系统在面临领域偏移时的鲁棒性。\"}", "conclusion": "本文提出了一个基于分割的丝状分裂检测和分类统一框架，有效解决了领域泛化问题并展示了良好性能。"}}
{"id": "2509.03616", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.03616", "abs": "https://arxiv.org/abs/2509.03616", "authors": ["Rajeev Ranjan Dwivedi", "Ankur Kumar", "Vinod K Kurmi"], "title": "Multi Attribute Bias Mitigation via Representation Learning", "comment": "ECAI 2025 (28th European Conference on Artificial Intelligence)", "summary": "Real world images frequently exhibit multiple overlapping biases, including\ntextures, watermarks, gendered makeup, scene object pairings, etc. These biases\ncollectively impair the performance of modern vision models, undermining both\ntheir robustness and fairness. Addressing these biases individually proves\ninadequate, as mitigating one bias often permits or intensifies others. We\ntackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a\nlean two stage framework that needs group labels only while training and\nminimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)\ndeliberately identifies the influence of known shortcuts by training encoders\nfor each attribute and integrating them with the main backbone, compelling the\nclassifier to explicitly recognize these biases. Then Gradient Suppression Fine\nTuning prunes those very bias directions from the backbone's gradients, leaving\na single compact network that ignores all the shortcuts it just learned to\nrecognize. Moreover we find that existing bias metrics break under subgroup\nimbalance and train test distribution shifts, so we introduce Scaled Bias\nAmplification (SBA): a test time measure that disentangles model induced bias\namplification from distributional differences. We validate GMBM on FB CMNIST,\nCelebA, and COCO, where we boost worst group accuracy, halve multi attribute\nbias amplification, and set a new low in SBA even as bias complexity and\ndistribution shifts intensify, making GMBM the first practical, end to end\nmultibias solution for visual recognition. Project page:\nhttp://visdomlab.github.io/GMBM/", "AI": {"tldr": "本研究提出了一种名为GMBM的方法，该方法通过一个两阶段框架来解决图像处理中的多偏见问题，并且通过实验数据证明了GMBM的有效性。", "motivation": "由于现实世界图像中经常存在多种重叠偏见，单独解决这些偏见是不够的，因为缓解一个偏见可能会使其他偏见变得更加严重，因此需要一个综合方法来一次性解决多个偏见。", "method": "GMBM 方法通过一个两阶段框架来解决多偏见问题，首先通过ABIL（自适应偏见综合学习）阶段识别已知的偏见来源，然后通过梯度抑制微调阶段消除这些偏见。", "result": "在FB CMNIST、CelebA和COCO数据集上的实验表明，GMBM方法提高了最差群体的准确率，减少了多属性偏见的放大，并且在偏见复杂度和分布变化增强的情况下，SBA评分降低到了新的低点。", "conclusion": "研究人员认为GMBM是第一个实用的、端到端的多偏见解决方案，适用于视觉识别领域，其有效性已在多个基准测试数据集上得到验证。"}}
