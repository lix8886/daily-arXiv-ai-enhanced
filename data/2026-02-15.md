<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [HybridRAG: A Practical LLM-based ChatBot Framework based on Pre-Generated Q&A over Raw Unstructured Documents](https://arxiv.org/abs/2602.11156)
*Sungmoon Kim,Hyuna Jeon,Dahye Kim,Mingyu Kim,Dong-Kyu Chae,Jiwoong Kim*

Main category: cs.CL

> 本文提出了HybridRAG框架，该框架能处理非结构化PDF文档，并预生成问答知识库以缩减查询时间，适用于资源受限条件下的大量用户和文档处理。

<details>
  <summary>Details</summary>

**Motivation:** 现有的检索增强生成方法主要针对结构化文本数据进行查询时的检索与生成，这限制了其在现实聊天机器人中的应用。HybridRAG旨在通过处理非结构化数据和生成预设问答库，实现更准确、快速的回答。

**Method:** HybridRAG采用OCR和布局分析技术识别并转换包含复杂布局的原始、非结构化PDF文档，并将其转换为分层文本块。随后，利用大型语言模型预生成组织文本块的问答知识库。查询时，首先尝试从问答库中直接匹配用户问题的答案，仅在找不到合适匹配时才转为即时生成回复。

**Result:** 实验结果表明，HybridRAG相比标准RAG基线，能够提供更高质量的答案和更低的延迟。

**Conclusion:** HybridRAG为处理大量非结构化文档和在计算资源有限的情况下响应大量用户提供了一种实用的解决方案。

**Abstract:** Retrieval-Augmented Generation (RAG) has emerged as a powerful approach for grounding Large Language Model (LLM)-based chatbot responses on external knowledge. However, existing RAG studies typically assume well-structured textual sources (e.g. Wikipedia or curated datasets) and perform retrieval and generation at query time, which can limit their applicability in real-world chatbot scenarios. In this paper, we present HybridRAG, a novel and practical RAG framework towards more accurate and faster chatbot responses. First, HybridRAG ingests raw, unstructured PDF documents containing complex layouts (text, tables, figures) via Optical Character Recognition (OCR) and layout analysis, and convert them into hierarchical text chunks. Then, it pre-generates a plausible question-answer (QA) knowledge base from the organized chunks using an LLM. At query time, user questions are matched against this QA bank to retrieve immediate answers when possible, and only if no suitable QA match is found does our framework fall back to an on-the-fly response generation. Experiments on OHRBench demonstrate that our HybridRAG provides higher answer quality and lower latency compared to a standard RAG baseline. We believe that HybridRAG could be a practical solution for real-world chatbot applications that must handle large volumes of unstructured documents and lots of users under limited computational resources.

</details>


### [2] [Response-Based Knowledge Distillation for Multilingual Jailbreak Prevention Unwittingly Compromises Safety](https://arxiv.org/abs/2602.11157)
*Max Zhang,Derek Liu,Kai Zhang,Joshua Franco,Haihao Liu*

Main category: cs.CL

> 本文介绍了一种在多语言防范越狱行为中应用知识蒸馏技术的新方法。但是标准微调意外地增加了越狱成功率。通过去除安全减弱的主要来源——复杂的`边界'拒绝行为，可以减轻或逆转学生的模型的安全恶化，尽管在某些推理性能上仍然有所下降。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型（LLMs）在全世界越来越广泛应用，但其安全性对齐主要集中在英语情境下，导致非英语环境中存在漏洞，特别是低资源语言。因此，本文提出在多语言防范越狱行为的背景下应用知识蒸馏技术，并研究其有效性。

**Method:** 本研究采用知识蒸馏(KD)技术在多语言防范越狱行为中进行应用。将一个专有教师模型（OpenAI o1-mini）的拒绝行为通过低秩适应（LoRA）蒸馏到三个开源学生模型中：Meta-Llama-3-8B-Instruct、Gemma-2-2B-IT和Qwen3-8B，使用了XSafety提供的约28,000个多语言越狱提示，通过黑盒响应基、参数高效微调(PEFT)进行。

**Result:** 评估显示，标准微调意外地增加了所有学生模型的越狱成功率，最高达16.6个百分点。通过去除主要的安全降级来源，即复杂的`边界'拒绝行为，可以减轻或逆转学生的模型的安全恶化，但推理性能有所下降。

**Conclusion:** 这项探索性研究突出了使用KD技术在多语言安全对齐中的挑战和潜在价值，为未来研究奠定了基础。

**Abstract:** Large language models (LLMs) are increasingly deployed worldwide, yet their safety alignment remains predominantly English-centric. This allows for vulnerabilities in non-English contexts, especially with low-resource languages. We introduce a novel application of knowledge distillation (KD) in the context of multilingual jailbreak prevention, examining its efficacy. We distill the refusal behaviors of a proprietary teacher model (OpenAI o1-mini) with Low-Rank Adaptation (LoRA) into three open-source student models: Meta-Llama-3-8B-Instruct, Gemma-2-2B-IT, and Qwen3-8B, using ~28,000 multilingual jailbreak prompts from XSafety via black-box response-based, parameter-efficient fine-tuning (PEFT). Evaluation on the MultiJail benchmark reveals a counterintuitive behavior: standard fine-tuning on the teacher's ``safe'' refusal data inadvertently increases Jailbreak Success Rate (JSR) for all student models, up to 16.6 percentage points. Our experiments reveal a divergent generalization to unseen languages during distillation, with varying outcomes depending on the base model. By removing a primary source of safety degradation, nuanced `boundary' refusals, we mitigate or even reverse safety declines in student models, although reductions in reasoning performance (GSM8K) persist. Overall, our exploratory study highlights the challenges and potential of KD as a technique for multilingual safety alignment, offering a foundation for future research in this direction.

</details>


### [3] [Retrieval Heads are Dynamic](https://arxiv.org/abs/2602.11162)
*Yuping Lin,Zitao Li,Yue Xing,Pengfei He,Yingqian Cui,Yaliang Li,Bolin Ding,Jingren Zhou,Jiliang Tang*

Main category: cs.CL

> 本文从动态视角研究大语言模型中的检索头，揭示了检索头在时步上的动态变化及其不可替代性，并表明模型内部存在一种规划机制。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究依赖于跨数据集聚合的静态统计数据，这忽略了自回归生成中的精细时间动态特性。

**Method:** 通过广泛分析，本文提出了三个核心主张：(1) 动态性：检索头在时步上动态变化；(2) 不可替代性：每个时步上的动态检索头是特定的，不能被静态检索头有效替代；(3) 相关性：模型的隐藏状态编码了对未来检索头模式的预测信号，表明内部规划机制。

**Result:** 研究结果是在Needle-in-a-Haystack任务和多跳QA任务上验证这些发现，并在一个动态检索增强生成框架中量化动态和静态检索头的效用差异。

**Conclusion:** 这项研究为大语言模型的内部工作机制提供了新的见解。

**Abstract:** Recent studies have identified "retrieval heads" in Large Language Models (LLMs) responsible for extracting information from input contexts. However, prior works largely rely on static statistics aggregated across datasets, identifying heads that perform retrieval on average. This perspective overlooks the fine-grained temporal dynamics of autoregressive generation. In this paper, we investigate retrieval heads from a dynamic perspective. Through extensive analysis, we establish three core claims: (1) Dynamism: Retrieval heads vary dynamically across timesteps; (2) Irreplaceability: Dynamic retrieval heads are specific at each timestep and cannot be effectively replaced by static retrieval heads; and (3) Correlation: The model's hidden state encodes a predictive signal for future retrieval head patterns, indicating an internal planning mechanism. We validate these findings on the Needle-in-a-Haystack task and a multi-hop QA task, and quantify the differences on the utility of dynamic and static retrieval heads in a Dynamic Retrieval-Augmented Generation framework. Our study provides new insights into the internal mechanisms of LLMs.

</details>


### [4] [Nested Named Entity Recognition in Plasma Physics Research Articles](https://arxiv.org/abs/2602.11163)
*Muhammad Haris,Hans Höft,Markus M. Becker,Markus Stocker*

Main category: cs.CL

> 本文提出了一种针对等离子体物理学研究文章的命名实体识别方法，并通过一系列优化手段提高了模型性能，为后续研究提供了一个有力的基础。

<details>
  <summary>Details</summary>

**Motivation:** 等离子体物理学的研究文章往往包含高度复杂且具有丰富上下文的内容，必须从中提取关键实体以支持例如高级搜索等功能。

**Method:** 我们提出了一种基于编码器-变压器和条件随机场的轻量级方法，来从等离子体物理学研究文章中提取（嵌套的）命名实体。首先，我们用16个专门为嵌套实体识别任务设计的类别对等离子体物理学语料库进行了注释。其次，我们评估了实体特定模型专业化方法，这种方法训练独立的BERT-CRF模型来识别等离子体物理学文本中的个别实体类型。第三，我们整合了一个优化过程，系统地微调超参数以提高模型表现。

**Result:** 我们的工作对等离子体物理学中的实体识别做出了贡献，同时也为研究人员导航和分析科学文献提供了坚实的基础。

**Conclusion:** 本文提出的方案和方法为未来的实体识别研究尤其是在科学文献处理方面开辟了道路。

**Abstract:** Named Entity Recognition (NER) is an important task in natural language processing that aims to identify and extract key entities from unstructured text. We present a novel application of NER in plasma physics research articles and address the challenges of extracting specialized entities from scientific text in this domain. Research articles in plasma physics often contain highly complex and context-rich content that must be extracted to enable, e.g., advanced search. We propose a lightweight approach based on encoder-transformers and conditional random fields to extract (nested) named entities from plasma physics research articles. First, we annotate a plasma physics corpus with 16 classes specifically designed for the nested NER task. Second, we evaluate an entity-specific model specialization approach, where independent BERT-CRF models are trained to recognize individual entity types in plasma physics text. Third, we integrate an optimization process to systematically fine-tune hyperparameters and enhance model performance. Our work contributes to the advancement of entity recognition in plasma physics and also provides a foundation to support researchers in navigating and analyzing scientific literature.

</details>


### [5] [Assessing LLM Reliability on Temporally Recent Open-Domain Questions](https://arxiv.org/abs/2602.11165)
*Pushwitha Krishnappa,Amit Das,Vinija Jain,Tathagata Mukherjee,Aman Chadha*

Main category: cs.CL

> RECOM数据集和多维衡量方法揭示了语言模型虽能保持语义一致性但往往不是通过词汇相同的方式。小型模型Mistral-7B表现优于大型模型GPT-OSS-20B。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于当前大型语言模型（LLMs）在处理即时信息时与人类视角的一致性缺乏探索。

**Method:** 本研究引入了RECOM数据集，一个包含15,000个近期Reddit问题及社区提供的参考答案的数据集。通过对四个开源语言模型（Llama3.1-8B, Mistral-7B, Gemma-2-9B, GPT-OSS-20B）的回答进行评估，使用了包括词汇衡量（BLEU, ROUGE）、语义相似度（BERTScore, MoverScore, 余弦相似度）以及逻辑推理（NLI）等多种评估方法。

**Result:** 模型们在余弦相似性上达到99%，但在BLEU-1数值上低于8%的重叠，这表明模型通过大量的词法改写来保持意义而非直接复制词汇。MoverScore在51-53%支持这一发现。NLI分析显示矛盾率低于7%，表明模型生成的内容很少直接与人类共识产生冲突。

**Conclusion:** 本研究中的发现挑战了使用词汇度量来评估抽象生成的可靠性，提倡使用多维度评估框架来确保语义层面的准确性。

**Abstract:** Large Language Models (LLMs) are increasingly deployed for open-domain question answering, yet their alignment with human perspectives on temporally recent information remains underexplored. We introduce RECOM (Reddit Evaluation for Correspondence of Models), a benchmark dataset of 15,000 recent Reddit questions from September 2025 paired with community-derived reference answers. We investigate how four open-source LLMs (Llama3.1-8B, Mistral-7B, Gemma-2-9B, and GPT-OSS-20B) respond to these questions, evaluating alignment using lexical metrics (BLEU, ROUGE), semantic similarity (BERTScore, MoverScore, cosine similarity), and logical inference (NLI). Our central finding is a striking semantic-lexical paradox: all models achieve over 99% cosine similarity with references despite less than 8% BLEU-1 overlap, a 90+ percentage point gap indicating that models preserve meaning through extensive paraphrasing rather than lexical reproduction. MoverScore (51-53%) confirms this pattern, occupying an intermediate position that reflects the optimal transport cost of semantic alignment. Furthermore, model scale does not predict performance: Mistral-7B (7B parameters) outperforms GPT-OSS-20B (20B parameters) across all metrics. NLI analysis reveals that contradiction rates remain below 7%, suggesting models rarely generate content that directly conflicts with human consensus. These findings challenge the reliability of lexical metrics for evaluating abstractive generation and argue for multi-dimensional evaluation frameworks that capture semantic fidelity beyond surface-level text matching. The RECOM dataset is publicly available at https://anonymous.4open.science/r/recom-D4B0

</details>


### [6] [Small Updates, Big Doubts: Does Parameter-Efficient Fine-tuning Enhance Hallucination Detection ?](https://arxiv.org/abs/2602.11166)
*Xu Hu,Yifan Zhang,Songtao Wei,Chen Zhao,Qiannan Li,Bingzhe Li,Feng Chen*

Main category: cs.CL

> 该研究指出，通过对三种大型语言模型和三种问答基准数据集的系统性研究，发现参数高效微调能显著提高幻觉检测能力，主要通过重新塑造不确定性编码方式实现。

<details>
  <summary>Details</summary>

**Motivation:** 尽管参数高效微调方法被广泛用于适应语言模型以执行下游任务，并且通常被认为是提高事实正确性的方法，但这些方法如何影响幻觉检测行为还不足为外人道，尤其是在问答数据集上。

**Method:** 通过全面的实证研究，作者探讨了参数高效微调方法对来自三种开放权重大型语言模型骨干及三种事实查询问答基准数据集上的幻觉检测的影响。对于每个模型，作者使用了七种无监督幻觉检测方法进行评估，这些方法涵盖了语义一致性、置信度和熵三种互补的方法。

**Result:** 实验证明，参数高效微调方法能显著提升幻觉检测能力，大幅提高多组幻觉检测器的AUROC评分。进一步使用线性探测和表示诊断分析发现，微调方法主要重塑了不确定性编码和呈现方式，而非注入新的事实知识。

**Conclusion:** 该研究发现参数高效微调方法能显著提升幻觉检测能力，而不仅仅是注入新的事实知识，而是改变了不确定性编码方式。

**Abstract:** Parameter-efficient fine-tuning (PEFT) methods are widely used to adapt large language models (LLMs) to downstream tasks and are often assumed to improve factual correctness. However, how the parameter-efficient fine-tuning methods affect hallucination behavior remains insufficiently understood, especially on QA datasets. In this work, we systematically investigate the impact of PEFT on hallucination detection through a comprehensive empirical study across three open-weight LLM backbones and three fact-seeking QA benchmarks. For each model, we evaluate performance using seven unsupervised hallucination detection methods spanning three complementary approaches: semantic consistency based detectors, confidence based detectors, and entropy based detectors. This multifaceted evaluation enables us to characterize how PEFT reshapes uncertainty across different detection paradigms. In conclusion, our experimental results show that PEFT consistently strengthens hallucination detection ability, substantially improving AUROC across a wide range of hallucination detectors. Besides, further analyses using linear probes and representation diagnostics indicate that PEFT methods primarily reshapes how uncertainty is encoded and surfaced, comparing with injecting new factual knowledge into the models.

</details>


### [7] [Visualizing and Benchmarking LLM Factual Hallucination Tendencies via Internal State Analysis and Clustering](https://arxiv.org/abs/2602.11167)
*Nathan Mao,Varun Kaushik,Shreya Shivkumar,Parham Sharafoleslami,Kevin Zhu,Sunishchal Dev*

Main category: cs.CL

> 该研究介绍了FalseCite数据集，用于系统研究误导性或伪造引用引起的大型语言模型（如GPT-4o-mini、Falcon-7B和Mistral 7-B）的幻觉现象，并提出了使用该数据集分析幻觉模型的内部状态的方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是探索大型语言模型在误导性或虚假引用下的幻觉产生，尤其是在医疗或法律等敏感领域中幻觉可能带来的负面影响。

**Method:** 使用FalseCite数据集评估了几个大型语言模型在幻觉生成中的表现，同时分析和可视化这些模型在生成幻觉响应时的隐藏状态向量。

**Result:** 结果发现误导性引用会导致幻觉行为的显著增加，特别是在GPT-4o-mini模型中。另外，分析还显示无论是否产生幻觉，隐藏状态向量会呈现出一条类似角状的路径。

**Conclusion:** 这项工作展示了FalseCite数据集作为评估和减轻未来研究中大型语言模型幻觉现象潜在基础的重要意义。

**Abstract:** Large Language Models (LLMs) often hallucinate, generating nonsensical or false information that can be especially harmful in sensitive fields such as medicine or law. To study this phenomenon systematically, we introduce FalseCite, a curated dataset designed to capture and benchmark hallucinated responses induced by misleading or fabricated citations. Running GPT-4o-mini, Falcon-7B, and Mistral 7-B through FalseCite, we observed a noticeable increase in hallucination activity for false claims with deceptive citations, especially in GPT-4o-mini. Using the responses from FalseCite, we can also analyze the internal states of hallucinating models, visualizing and clustering the hidden state vectors. From this analysis, we noticed that the hidden state vectors, regardless of hallucination or non-hallucination, tend to trace out a distinct horn-like shape. Our work underscores FalseCite's potential as a foundation for evaluating and mitigating hallucinations in future LLM research.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [DD-MDN: Human Trajectory Forecasting with Diffusion-Based Dual Mixture Density Networks and Uncertainty Self-Calibration](https://arxiv.org/abs/2602.11214)
*Manuel Hetzel,Kerim Turacan,Hannes Reichert,Konrad Doll,Bernhard Sick*

Main category: cs.CV

> 本文提出DD-MDN模型，它是一个端到端的概率性人类轨迹预测模型，能够保证高位置准确性、校准过的不确定性以及对短时间观测的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管先前的工作集中在准确性、社交互动建模和多样性上，但对不确定性建模、校准以及基于短时间观测的预测关注度较低，而这些对于下游任务如路径规划和碰撞避免至关重要。

**Method:** DD-MDN结合了去噪扩散模型和双混合密度网络，通过学习自我校准的居住区域和概率排序的基准路径，实现了对多样化轨迹假设的衍生，不需要预定义的基准点或终点。

**Result:** 在ETH/UCY、SDD、inD和IMPTC数据集上的实验展示出最先进的准确性、对短时间观测的鲁棒性以及可靠的不确定性建模。

**Conclusion:** DD-MDN模型在解决不确定性建模和短时间观测预测问题上取得了显著的进步，为路径规划和碰撞避免等应用提供了可靠支持。

**Abstract:** Human Trajectory Forecasting (HTF) predicts future human movements from past trajectories and environmental context, with applications in Autonomous Driving, Smart Surveillance, and Human-Robot Interaction. While prior work has focused on accuracy, social interaction modeling, and diversity, little attention has been paid to uncertainty modeling, calibration, and forecasts from short observation periods, which are crucial for downstream tasks such as path planning and collision avoidance. We propose DD-MDN, an end-to-end probabilistic HTF model that combines high positional accuracy, calibrated uncertainty, and robustness to short observations. Using a few-shot denoising diffusion backbone and a dual mixture density network, our method learns self-calibrated residence areas and probability-ranked anchor paths, from which diverse trajectory hypotheses are derived, without predefined anchors or endpoints. Experiments on the ETH/UCY, SDD, inD, and IMPTC datasets demonstrate state-of-the-art accuracy, robustness at short observation intervals, and reliable uncertainty modeling. The code is available at: https://github.com/kav-institute/ddmdn.

</details>


### [9] [ABot-M0: VLA Foundation Model for Robotic Manipulation with Action Manifold Learning](https://arxiv.org/abs/2602.11236)
*Yandan Yang,Shuang Zeng,Tong Lin,Xinyuan Chang,Dekang Qi,Junjin Xiao,Haoyun Liu,Ronghan Chen,Yuzhi Chen,Dongjie Huo,Feng Xiong,Xing Wei,Zhiheng Ma,Mu Xu*

Main category: cs.CV

> 提出ABot-M0框架，通过构建数据整理管道和优化模型架构与训练策略，将异质数据转化为统一高效表示，支持具身智能的通用化。引入动作流形学习，直接预测连续动作序列，提升效率和稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 当前机器人领域面临的一个主要挑战是如何构建适用于多种硬件的通用化具身智能体。这一挑战源于数据碎片化、表示不一致以及训练目标不同步等问题。该论文旨在提升不同平台和任务间的知识迁移和泛化能力，即支持通用化具身智能。

**Method:** 通过构建系统的数据整理管道，同时优化模型架构和训练策略，ABot-M0框架能够将异质原始数据转化为统一高效的表示形式。为了提高动作预测的效率和稳定性，提出动作流形假设：有效的机器人动作存在于低维平稳流形上，而不是全面的高维空间。基于此，引入动作流形学习(AML)，该方法使用DiT骨干网络直接预测干净的连续动作序列。

**Result:** 通过统一预训练，跨平台和任务的知识迁移和泛化能力得到提升，支持了通用化具身智能。实验展示了各个组件能独立运行并具有叠加效果。

**Conclusion:** ABot-M0框架在机器人领域中的应用展示了其在学习和操作优化方面的有效性。该研究为未来的研究和重现提供了所有代码和管道。

**Abstract:** Building general-purpose embodied agents across diverse hardware remains a central challenge in robotics, often framed as the ''one-brain, many-forms'' paradigm. Progress is hindered by fragmented data, inconsistent representations, and misaligned training objectives. We present ABot-M0, a framework that builds a systematic data curation pipeline while jointly optimizing model architecture and training strategies, enabling end-to-end transformation of heterogeneous raw data into unified, efficient representations. From six public datasets, we clean, standardize, and balance samples to construct UniACT-dataset, a large-scale dataset with over 6 million trajectories and 9,500 hours of data, covering diverse robot morphologies and task scenarios. Unified pre-training improves knowledge transfer and generalization across platforms and tasks, supporting general-purpose embodied intelligence. To improve action prediction efficiency and stability, we propose the Action Manifold Hypothesis: effective robot actions lie not in the full high-dimensional space but on a low-dimensional, smooth manifold governed by physical laws and task constraints. Based on this, we introduce Action Manifold Learning (AML), which uses a DiT backbone to predict clean, continuous action sequences directly. This shifts learning from denoising to projection onto feasible manifolds, improving decoding speed and policy stability. ABot-M0 supports modular perception via a dual-stream mechanism that integrates VLM semantics with geometric priors and multi-view inputs from plug-and-play 3D modules such as VGGT and Qwen-Image-Edit, enhancing spatial understanding without modifying the backbone and mitigating standard VLM limitations in 3D reasoning. Experiments show components operate independently with additive benefits. We will release all code and pipelines for reproducibility and future research.

</details>


### [10] [Toward Reliable Tea Leaf Disease Diagnosis Using Deep Learning Model: Enhancing Robustness With Explainable AI and Adversarial Training](https://arxiv.org/abs/2602.11239)
*Samanta Ghosh,Jannatul Adan Mahi,Shayan Abrar,Md Parvez Mia,Asaduzzaman Rayhan,Abdul Awal Yasir,Asaduzzaman Hridoy*

Main category: cs.CV

> 研究开发了一个深学习模型，用于自动识别孟加拉茶叶叶片疾病，并且EfficientNetB3模型在分类准确率上取得了优于DenseNet201的结果。

<details>
  <summary>Details</summary>

**Motivation:** 由于手动检测茶叶病害耗时且易出错，因此研究旨在开发一种自动化深度学习模型，使得病害检测更准确和高效，从而为茶叶生产和经济提供帮助。

**Method:** 研究采用了基于深度学习的自动化模型来分类孟加拉茶叶叶片疾病。该模型基于teaLeafBD数据集，此数据集包含5,278张高质量图片，被分类为七类，其中六类代表不同的疾病，一类代表健康叶片。研究中使用了数据预处理、数据分割、对抗训练、数据增强、模型训练、评估和解释性的AI策略，其中采用了DenseNet201和EfficientNetB3进行分类任务。

**Result:** 实验结果表明，EfficientNetB3达到了93%的最高分类准确率，而DenseNet201达到91%。通过使用对抗训练和Grad-CAM可视化技术，这些模型不仅分类准确，而且对噪声或干扰输入仍有很好的辨识能力。

**Conclusion:** 研究证明，所提出的方法可以准确检测茶叶病害，并为先进的农业管理提供实用解决方案。

**Abstract:** Tea is a valuable asset for the economy of Bangladesh. So, tea cultivation plays an important role to boost the economy. These valuable plants are vulnerable to various kinds of leaf infections which may cause less production and low quality. It is not so easy to detect these diseases manually. It may take time and there could be some errors in the detection.Therefore, the purpose of the study is to develop an automated deep learning model for tea leaf disease classification based on the teaLeafBD dataset so that anyone can detect the diseases more easily and efficiently. There are 5,278 high-resolution images in this dataset. The images are classified into seven categories. Six of them represents various diseases and the rest one represents healthy leaves. The proposed pipeline contains data preprocessing, data splitting, adversarial training, augmentation, model training, evaluation, and comprehension made possible with Explainable AI strategies. DenseNet201 and EfficientNetB3 were employed to perform the classification task. To prepare the model more robustly, we applied adversarial training so it can operate effectively even with noisy or disturbed inputs. In addition, Grad-CAM visualization was executed to analyze the model's predictions by identifying the most influential regions of each image. Our experimental outcomes revealed that EfficientNetB3 achieved the highest classification accuracy of 93%, while DenseNet201 reached 91%. The outcomes prove that the effectiveness of the proposed approach can accurately detect tea leaf diseases and provide a practical solution for advanced agricultural management.

</details>


### [11] [Active Zero: Self-Evolving Vision-Language Models through Active Environment Exploration](https://arxiv.org/abs/2602.11241)
*Jinghan He,Junfeng Fang,Feng Xiong,Zijun Yao,Fei Shen,Haiyun Guo,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

> 提出了Active-Zero框架来改进现有视觉语言模型中的自我博弈问题，通过主动探索而非被动交互来优化模型的学习效率和效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有的自我博弈方法依赖于与静态图像集合的被动交互，这使得模型过分依赖初始数据集并且学习效率低下。缺少主动寻求与其能力相匹配的视觉数据的能力导致了大量的计算资源浪费。

**Method:** Active-Zero框架，通过三个协同演化的代理来实现从被动交互到积极环境探索的转变：一个检索者根据模型的能力边界从开放世界仓库中获取图像，一个提问者合成校准的推理任务，以及一个解题者通过准确性的奖励进行优化。

**Result:** Active-Zero在Qwen2.5-VL-7B-Instruct上的12个基准测试中实现了推理任务53.97的平均准确率（提高5.7%）以及一般理解59.77的准确率（提高3.9%），持续超越现有的自我博弈基线。

**Conclusion:** 结果表明，主动探索是可扩展和适应性强的自我演化的视觉语言系统的关键成分。

**Abstract:** Self-play has enabled large language models to autonomously improve through self-generated challenges. However, existing self-play methods for vision-language models rely on passive interaction with static image collections, resulting in strong dependence on initial datasets and inefficient learning. Without the ability to actively seek visual data tailored to their evolving capabilities, agents waste computational effort on samples that are either trivial or beyond their current skill level. To address these limitations, we propose Active-Zero, a framework that shifts from passive interaction to active exploration of visual environments. Active-Zero employs three co-evolving agents: a Searcher that retrieves images from open-world repositories based on the model's capability frontier, a Questioner that synthesizes calibrated reasoning tasks, and a Solver refined through accuracy rewards. This closed loop enables self-scaffolding auto-curricula where the model autonomously constructs its learning trajectory. On Qwen2.5-VL-7B-Instruct across 12 benchmarks, Active-Zero achieves 53.97 average accuracy on reasoning tasks (5.7% improvement) and 59.77 on general understanding (3.9% improvement), consistently outperforming existing self-play baselines. These results highlight active exploration as a key ingredient for scalable and adaptive self-evolving vision-language systems.

</details>


### [12] [ReTracing: An Archaeological Approach Through Body, Machine, and Generative Systems](https://arxiv.org/abs/2602.11242)
*Yitong Wang,Yue Yao*

Main category: cs.CV

> ReTracing是一个多代理具身表演艺术，通过考古学方法分析AI对人类行为的影响，并提出新的如何理解人类身份的研究角度。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过艺术实践探讨AI对人类行为的社会文化影响，提出对于AI时代人类身份与存在方式的新思考

**Method:** 采用了大规模语言模型技术及文本至视频转化技术，创作了ReTracing表演项目，以此展现人工智能对身体运动的影响方式

**Result:** <tool_call>
data: {{"name": "Structure", "arguments": {"tldr": "ReTracing 是一个多代理具身表演艺术项目，采用了考古学方法来考察人工智能如何塑造、限制和生产身体运动。该项目从科幻小说中提取有关人机交互的句子，通过大型语言模型生成提示，由文本到视频模型转化为人和四足机器人执行的指导，通过多摄像头动作捕捉技术记录它们的动作，从而揭示生成系统如何通过设定的舞蹈运动编码社会文化偏见。", "motivation": "探讨人工智能如何影响人类行为和思考方式。", "method": "利用大型语言模型生成提示，以及将文本转化成多镜头视频捕捉记录的行为指导。", "result": "形成了一种新的方法，揭示了生成系统如何通过设计的行为编码社会文化偏见。", "conclusion": "通过AI、人类和机器人之间的互动揭示了在AI也拥有行动、思考和留下痕迹的时代，对于“何为人”这一核心问题的新的理解。"}}}
</tool_call>

**Conclusion:** 本论文通过结合人工智能与人类/机器人执行的动作分析，探索了AI对人类行为与存在的影响，提出了一种新的审视人类身份的方式。

**Abstract:** We present ReTracing, a multi-agent embodied performance art that adopts an archaeological approach to examine how artificial intelligence shapes, constrains, and produces bodily movement. Drawing from science-fiction novels, the project extracts sentences that describe human-machine interaction. We use large language models (LLMs) to generate paired prompts "what to do" and "what not to do" for each excerpt. A diffusion-based text-to-video model transforms these prompts into choreographic guides for a human performer and motor commands for a quadruped robot. Both agents enact the actions on a mirrored floor, captured by multi-camera motion tracking and reconstructed into 3D point clouds and motion trails, forming a digital archive of motion traces. Through this process, ReTracing serves as a novel approach to reveal how generative systems encode socio-cultural biases through choreographed movements. Through an immersive interplay of AI, human, and robot, ReTracing confronts a critical question of our time: What does it mean to be human among AIs that also move, think, and leave traces behind?

</details>


### [13] [Stress Tests REVEAL Fragile Temporal and Visual Grounding in Video-Language Models](https://arxiv.org/abs/2602.11244)
*Sethuraman T,Savya Khosla,Aditi Tiwari,Vidya Ganesh,Rakshana Jayaprakash,Aditya Jain,Vignesh Srinivasakumar,Onkar Kishor Susladkar,Srinidhi Sunkara,Aditya Shanmugham,Rakesh Vaideeswaran,Abbaas Alif Mohamed Nishar,Simon Jenni,Derek Hoiem*

Main category: cs.CV

> 本研究发现当代视频-语言模型在处理视频内容、时间序列和运动时表现出显著弱点，并引入了REVEAL{}诊断基准测试来进一步检测这些弱点。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于调查视频-语言模型是否能够稳健地处理视频内容、时间序列和运动。

**Method:** 本研究采用了一个名为REVEAL{}的诊断基准测试，通过五个受控的压力测试来检测当代视频-语言模型（VidLMs）的基本弱点，包括对时间预期偏见、仅依赖语言捷径、视频阿谀、摄像机运动敏感性以及对抗空间-时间遮挡的鲁棒性。

**Result:** 研究发现，这些视频-语言模型在描述反向场景时会自信地将其描述为正向，回答问题时会忽略视频内容，同意错误的主张，在基本的摄像机运动方面存在问题，并且在简单的空间-时间遮挡时无法聚合时间信息。

**Conclusion:** 人类在这些任务中轻松地完成了，而当前的视频-语言模型表现出显著的弱点。本研究通过发布基准和代码来支持未来的研究。

**Abstract:** This work investigates a fundamental question: Do Video-Language Models (VidLMs) robustly account for video content, temporal sequence, and motion? Our investigation shows that, surprisingly, they often do not. We introduce REVEAL{}, a diagnostic benchmark that probes fundamental weaknesses of contemporary VidLMs through five controlled stress tests; assessing temporal expectation bias, reliance on language-only shortcuts, video sycophancy, camera motion sensitivity, and robustness to spatiotemporal occlusion. We test leading open- and closed-source VidLMs and find that these models confidently describe reversed scenes as forward, answer questions while neglecting video content, agree with false claims, struggle with basic camera motion, and fail to aggregate temporal information amidst simple spatiotemporal masking. Humans, on the other hand, succeed at these tasks with ease. Alongside our benchmark, we provide a data pipeline that automatically generates diagnostic examples for our stress tests, enabling broader and more scalable evaluation. We will release our benchmark and code to support future research.

</details>


### [14] [Advancing Digital Twin Generation Through a Novel Simulation Framework and Quantitative Benchmarking](https://arxiv.org/abs/2602.11314)
*Jacob Rubinstein,Avi Donaty,Don Engel*

Main category: cs.CV

> 本文介绍了一种新的流程，用于从高质量的3D模型生成合成图像，并利用程序化生成的相机位置进行实验，以实现可重复和量化的比较。

<details>
  <summary>Details</summary>

**Motivation:** 通过创造一种新的方法来生成和实验，可以更精确地评估不同3D模型生成技术的性能。

**Method:** 该研究提出了用高质量3D模型创建合成图像的流程，并使用程序化相机位置进行实验，以此来比较虚拟物体和摄像参数的估计值与真实值。

**Result:** 该研究成功设计了一种可量化比较方法，用来衡量3D模型重建的效果。

**Conclusion:** 新提出的合成图像生成流程和实验方法为3D重建领域提供了一种新的、可重复的量化评估方式。

**Abstract:** The generation of 3D models from real-world objects has often been accomplished through photogrammetry, i.e., by taking 2D photos from a variety of perspectives and then triangulating matched point-based features to create a textured mesh. Many design choices exist within this framework for the generation of digital twins, and differences between such approaches are largely judged qualitatively. Here, we present and test a novel pipeline for generating synthetic images from high-quality 3D models and programmatically generated camera poses. This enables a wide variety of repeatable, quantifiable experiments which can compare ground-truth knowledge of virtual camera parameters and of virtual objects against the reconstructed estimations of those perspectives and subjects.

</details>


### [15] [Selective Prior Synchronization via SYNC Loss](https://arxiv.org/abs/2602.11316)
*Ishan Mishra,Jiajie Li,Deepak Mishra,Jinjun Xiong*

Main category: cs.CV

> The paper introduces a new method that combines ad-hoc and post-hoc approaches for selective prediction in DNNs, named SYNC loss, achieving state-of-the-art performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the integration of post-hoc selective prior into the training process of DNNs for better selective prediction when facing uncertainties.

**Method:** The paper proposes a new loss function called SYNC loss, which integrates the softmax response into the training process of SelectiveNet to enhance its selective prediction capabilities.

**Result:** The proposed method enhances model generalization and improves selective prediction performance over existing methods on datasets such as CIFAR-100, ImageNet-100, and Stanford Cars.

**Conclusion:** The proposed approach demonstrates superior performance in selective prediction and sets a new benchmark, showing the importance of integrating selective prior into the training process for responsible deep learning models.

**Abstract:** Prediction under uncertainty is a critical requirement for the deep neural network to succeed responsibly. This paper focuses on selective prediction, which allows DNNs to make informed decisions about when to predict or abstain based on the uncertainty level of their predictions. Current methods are either ad-hoc such as SelectiveNet, focusing on how to modify the network architecture or objective function, or post-hoc such as softmax response, achieving selective prediction through analyzing the model's probabilistic outputs. We observe that post-hoc methods implicitly generate uncertainty information, termed the selective prior, which has traditionally been used only during inference. We argue that the selective prior provided by the selection mechanism is equally vital during the training stage. Therefore, we propose the SYNC loss which introduces a novel integration of ad-hoc and post-hoc method. Specifically, our approach incorporates the softmax response into the training process of SelectiveNet, enhancing its selective prediction capabilities by examining the selective prior. Evaluated across various datasets, including CIFAR-100, ImageNet-100, and Stanford Cars, our method not only enhances the model's generalization capabilities but also surpasses previous works in selective prediction performance, and sets new benchmarks for state-of-the-art performance.

</details>


### [16] [MDE-VIO: Enhancing Visual-Inertial Odometry Using Learned Depth Priors](https://arxiv.org/abs/2602.11323)
*Arda Alniak,Sinan Kalkan,Mustafa Mert Ankarali,Afsar Saranli,Abdullah Aydin Alatan*

Main category: cs.CV

> 通过将学习到的深度先验直接整合到VINS-Mono的优化后端，并提出一个确保仿射不变深度一致性和成对顺序约束的新框架，使得在资源受限的边缘设备上也能实现准确的视觉惯性里程计，从而在低纹理环境中提高跟踪稳定性与准确性，实验表明该方法最多可降低28.3%的绝对轨迹误差。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统单目视觉惯性里程计在低纹理环境下性能不佳的问题，这些环境通常会使稀疏视觉特征不足以进行精确的姿态估计。通过结合密集的单目深度估计作为补充信息来改善这一状况。

**Method:** 将ViT基础模型提供的密集且几何一致的深度先验整合到VINS-Mono中，提出一个确保仿射不变性深度一致性并使用基于方差的门控过滤不稳定噪点的新框架。

**Result:** 实验在TartanGround和M3ED数据集上展示了该方法在面临挑战性场景时的有效性，能有效防止系统发散并显著提高精度，最多降低28.3%的绝对轨迹误差。

**Conclusion:** 提出的方案成功地在保持边缘设备计算限制的同时，通过深度的合理整合使视觉惯性里程计在低纹理环境下能保持稳定性能。

**Abstract:** Traditional monocular Visual-Inertial Odometry (VIO) systems struggle in low-texture environments where sparse visual features are insufficient for accurate pose estimation. To address this, dense Monocular Depth Estimation (MDE) has been widely explored as a complementary information source. While recent Vision Transformer (ViT) based complex foundational models offer dense, geometrically consistent depth, their computational demands typically preclude them from real-time edge deployment. Our work bridges this gap by integrating learned depth priors directly into the VINS-Mono optimization backend. We propose a novel framework that enforces affine-invariant depth consistency and pairwise ordinal constraints, explicitly filtering unstable artifacts via variance-based gating. This approach strictly adheres to the computational limits of edge devices while robustly recovering metric scale. Extensive experiments on the TartanGround and M3ED datasets demonstrate that our method prevents divergence in challenging scenarios and delivers significant accuracy gains, reducing Absolute Trajectory Error (ATE) by up to 28.3%. Code will be made available.

</details>


### [17] [Exploring Real-Time Super-Resolution: Benchmarking and Fine-Tuning for Streaming Content](https://arxiv.org/abs/2602.11339)
*Evgeney Bogatyrev,Khaled Abud,Ivan Molodetskikh,Nikita Alutis,Dmitry Vatolin*

Main category: cs.CV

> 本文介绍了一个名为StreamSR的数据集以及EfRLFN模型，以解决现有实时超级分辨率技术在处理流媒体内容方面的局限性。研究成果表明在新数据集上微调其他模型可以显著提升性能，并泛化到多种标准基准中。

<details>
  <summary>Details</summary>

**Motivation:** 随着实时超级分辨率技术的进步，当前方法在处理压缩视频内容方面仍面临挑战。现有数据集无法准确反映流媒体的特点，限制了当前基准测试的相关性。

**Method:** 本文提出了EfRLFN模型，该模型整合了高效的通道注意力机制和双曲正切激活函数，并通过架构优化和复合损失函数设计来提高训练收敛性，以实现更高的视觉质量和运行性能。此外，本文还介绍了一个名为StreamSR的数据集，用于更适合流媒体场景的实时超级分辨率模型的基准测试。

**Result:** 研究结果显示，基于该数据集对其他模型进行微调能显著提升性能，并且在各种标准基准测试中表现出良好的泛化性。

**Conclusion:** 本文通过提出新的数据集和高效实时模型，改善了当前实时超级分辨率技术在流媒体内容处理上的局限性，进而提升了视频流媒体的质量。

**Abstract:** Recent advancements in real-time super-resolution have enabled higher-quality video streaming, yet existing methods struggle with the unique challenges of compressed video content. Commonly used datasets do not accurately reflect the characteristics of streaming media, limiting the relevance of current benchmarks. To address this gap, we introduce a comprehensive dataset - StreamSR - sourced from YouTube, covering a wide range of video genres and resolutions representative of real-world streaming scenarios. We benchmark 11 state-of-the-art real-time super-resolution models to evaluate their performance for the streaming use-case.
  Furthermore, we propose EfRLFN, an efficient real-time model that integrates Efficient Channel Attention and a hyperbolic tangent activation function - a novel design choice in the context of real-time super-resolution. We extensively optimized the architecture to maximize efficiency and designed a composite loss function that improves training convergence. EfRLFN combines the strengths of existing architectures while improving both visual quality and runtime performance.
  Finally, we show that fine-tuning other models on our dataset results in significant performance gains that generalize well across various standard benchmarks. We made the dataset, the code, and the benchmark available at https://github.com/EvgeneyBogatyrev/EfRLFN.

</details>
