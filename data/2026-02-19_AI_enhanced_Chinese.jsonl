{"id": "2602.15843", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15843", "abs": "https://arxiv.org/abs/2602.15843", "authors": ["Warren Johnson"], "title": "The Perplexity Paradox: Why Code Compresses Better Than Math in LLM Prompts", "comment": "19 pages, 5 figures, 4 tables. Second paper in TAAC research series. Code and data at https://github.com/micoverde/taac-llm-compression", "summary": "In \"Compress or Route?\" (Johnson, 2026), we found that code generation tolerates aggressive prompt compression (r >= 0.6) while chain-of-thought reasoning degrades gradually. That study was limited to HumanEval (164 problems), left the \"perplexity paradox\" mechanism unvalidated, and provided no adaptive algorithm. This paper addresses all three gaps. First, we validate across six code benchmarks (HumanEval, MBPP, HumanEval+, MultiPL-E) and four reasoning benchmarks (GSM8K, MATH, ARC-Challenge, MMLU-STEM), confirming the compression threshold generalizes across languages and difficulties. Second, we conduct the first per-token perplexity analysis (n=723 tokens), revealing a \"perplexity paradox\": code syntax tokens are preserved (high perplexity) while numerical values in math problems are pruned despite being task-critical (low perplexity). Signature injection recovers +34 percentage points in pass rate (5.3% to 39.3%; Cohen's h=0.890). Third, we propose TAAC (Task-Aware Adaptive Compression), achieving 22% cost reduction with 96% quality preservation, outperforming fixed-ratio compression by 7%. MBPP validation (n=1,800 trials) confirms systematic variation: 3.6% at r=0.3 to 54.6% at r=1.0.", "AI": {"tldr": "本文验证了先前关于代码生成和推理理解的压缩效果，发现新的算法签名注入可以提高任务通过率，提出了任务感知自适应压缩TAAC方法，证明了其有效性和优越性。", "motivation": "为了填补之前的研究空白，进一步验证了前文发现的“困惑度悖论”机制，补充了自适应压缩算法，并通过分析推广之前发现的压缩阈值。", "method": "本研究通过跨六个代码基准（HumanEval、MBPP、HumanEval+、MultiPL-E）和四个推理基准（GSM8K、MATH、ARC-Challenge、MMLU-STEM）验证了前文发现的问题，并首次进行了逐个标记的困惑度分析（n=723个标记）。此外，提出了TAAC（任务感知自适应压缩算法）。", "result": "研究证明了代码语法标记与数学问题中的数值在压缩过程中有不同的保留情况，并提出了签名注入方法以提高通过率。TAAC算法实现了成本减少22%且质量保持96%，超越了固定比率压缩方法7%。", "conclusion": "研究验证了代码压缩与语言无关的压缩阈值，揭示了困惑度悖论现象，提出了提高任务通过率的新方法，并证明了自适应压缩算法的有效性。"}}
{"id": "2602.15844", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15844", "abs": "https://arxiv.org/abs/2602.15844", "authors": ["Inwon Kang", "Parikshit Ram", "Yi Zhou", "Horst Samulowitz", "Oshani Seneviratne"], "title": "Language Model Representations for Efficient Few-Shot Tabular Classification", "comment": "Accepted to WWW'26", "summary": "The Web is a rich source of structured data in the form of tables, from product catalogs and knowledge bases to scientific datasets. However, the heterogeneity of the structure and semantics of these tables makes it challenging to build a unified method that can effectively leverage the information they contain. Meanwhile, Large language models (LLMs) are becoming an increasingly integral component of web infrastructure for tasks like semantic search. This raises a crucial question: can we leverage these already-deployed LLMs to classify structured data in web-native tables (e.g., product catalogs, knowledge base exports, scientific data portals), avoiding the need for specialized models or extensive retraining? This work investigates a lightweight paradigm, $\\textbf{Ta}$ble $\\textbf{R}$epresentation with $\\textbf{L}$anguage Model~($\\textbf{TaRL}$), for few-shot tabular classification that directly utilizes semantic embeddings of individual table rows. We first show that naive application of these embeddings underperforms compared to specialized tabular models. We then demonstrate that their potentials can be unlocked with two key techniques: removing the common component from all embeddings and calibrating the softmax temperature. We show that a simple meta-learner, trained on handcrafted features, can learn to predict an appropriate temperature. This approach achieves performance comparable to state-of-the-art models in low-data regimes ($k \\leq 32$) of semantically-rich tables. Our findings demonstrate the viability of reusing existing LLM infrastructure for efficient semantics-driven pathway to reuse existing LLM infrastructure for Web table understanding.", "AI": {"tldr": "研究了一种轻量级方法TaRL，利用语言模型进行少量样本的表格分类，展示了在低数据量下良好的性能。", "motivation": "由于网络中表格结构和语义的异构性，统一利用表格信息的方法具有挑战性。同时，大型语言模型（LLMs）正在成为网络基础设施的一个重要组成部分。本文探讨了是否可以利用这些已经部署的LLMs对网络表格进行分类，从而避免需要专门的模型或大量重新训练。", "method": "本文提出了一种轻量级的方法TaRL，通过利用语言模型为表格中的每一行生成语义嵌入来进行少量样本的表格分类。为了解决简单应用这些嵌入表现不佳的问题，文中提出了两种关键技术：从所有嵌入中去除公共成分和校准softmax温度。此外，文章还展示了一种简单的元学习器可以学习预测适当的温度。", "result": "实验结果表明，在少量数据的情况下（k≤32），该方法在语义丰富的表格分类中可以达到与最先进的模型相当的性能。", "conclusion": "研究发现，通过复用现有的LLMs基础设施，可以达到有效的网络表格理解，从而提供了一种效率高的语义驱动方法。"}}
{"id": "2602.15845", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15845", "abs": "https://arxiv.org/abs/2602.15845", "authors": ["Ona de Gibert", "Joseph Attieh", "Timothee Mickus", "Yves Scherrer", "Jörg Tiedemann"], "title": "KD4MT: A Survey of Knowledge Distillation for Machine Translation", "comment": "Pre-print under Review submitted to Computational Linguistics Journal", "summary": "Knowledge Distillation (KD) as a research area has gained a lot of traction in recent years as a compression tool to address challenges related to ever-larger models in NLP. Remarkably, Machine Translation (MT) offers a much more nuanced take on this narrative: in MT, KD also functions as a general-purpose knowledge transfer mechanism that shapes supervision and translation quality as well as efficiency.\n  This survey synthesizes KD for MT (KD4MT) across 105 papers (through October 1, 2025). We begin by introducing both MT and KD for non-experts, followed by an overview of the standard KD approaches relevant to MT applications. Subsequently, we categorize advances in the KD4MT literature based on (i) their methodological contributions and (ii) their practical applications. Our qualitative and quantitative analyses identify common trends in the field and highlight key research gaps as well as the absence of unified evaluation practice for KD methods in MT. We further provide practical guidelines for selecting a KD method in concrete settings and highlight potential risks associated with the application of KD to MT such as increased hallucination and bias amplification. Finally, we discuss the role of LLMs in re-shaping the KD4MT field. To support further research, we complement our survey with a publicly available database summarizing the main characteristics of the surveyed KD methods and a glossary of key terms.", "AI": {"tldr": "这篇论文综述了知识蒸馏（KD）在机器翻译（MT）领域的应用（KD4MT），基于105篇论文进行了综合分析。论文对MT和KD进行了介绍，并按方法论贡献和实际应用两个维度对相关文献进行分类。此外，还提出了选择KD方法的实践指南，并讨论了大型语言模型（LLMs）对KD4MT领域的影响。附带提供了一个公开数据库和术语表来支持进一步研究。", "motivation": "由于NLP领域的模型越来越大，知识蒸馏作为一种压缩工具变得越来越重要。而在机器翻译领域，知识蒸馏还扮演了一个知识转移机制的角色，可以影响翻译质量、监督方式及效率。因此，有必要对这一领域的研究进行全面的综述，以便更好地理解和利用知识蒸馏在机器翻译中的作用。", "method": "论文通过概述传统知识蒸馏方法、文献分类（基于方法论贡献和实际应用）以及综合分析（定性和定量）来综述知识蒸馏在机器翻译中的应用。此外，还提供了选择KD方法的具体指导和潜在风险的讨论。", "result": "该综述识别出领域中的常见趋势，并指出一些关键的研究空白以及统一的KD方法评估实践的缺失。它还提供了一个公开的数据库来总结已调查的KD方法的主要特征，以及一个包含关键术语的术语表。", "conclusion": "此综述揭示了知识蒸馏在机器翻译领域的应用现状，并提出未来研究的方向，特别是大型语言模型对这一点的影响。此外，它还提供了有助于选择和应用适当KD方法的实用指导。"}}
{"id": "2602.15846", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.15846", "abs": "https://arxiv.org/abs/2602.15846", "authors": ["Xinyu Gao", "Shaonan Wang", "Nai Ding"], "title": "Gated Tree Cross-attention for Checkpoint-Compatible Syntax Injection in Decoder-Only LLMs", "comment": null, "summary": "Decoder-only large language models achieve strong broad performance but are brittle to minor grammatical perturbations, undermining reliability for downstream reasoning. However, directly injecting explicit syntactic structure into an existing checkpoint can interfere with its pretrained competence. We introduce a checkpoint-compatible gated tree cross-attention (GTCA) branch that reads precomputed constituency chunk memory while leaving backbone architecture unchanged. Our design uses a token update mask and staged training to control the scope and timing of structural updates. Across benchmarks and Transformer backbones, GTCA strengthens syntactic robustness beyond continued-training baselines without compromising Multiple-Choice QA performance or commonsense reasoning, providing a practical checkpoint-compatible route to more syntax-robust decoder-only LLMs.", "AI": {"tldr": "提出了一种新的方法GTCA，增强了解码器仅模型的语法鲁棒性，同时保持了多选题问答性能和常识推理能力，提供了一条实用且与检查点兼容的途径来增强解码器仅语言模型的语法鲁棒性。", "motivation": "解码器仅用的大语言模型虽然实现了强广性能，但对轻微的语法扰动非常脆弱，这影响了它们在下游推理中的可靠性。然而，直接将显式的句法结构注入现有的检查点可能会干扰其预训练的能力。", "method": "引入了与检查点兼容的门控树交叉注意力（GTCA）分支，该分支在不改变主干架构的情况下读取预计算的构成成分记忆。设计中使用了令牌更新掩码和分阶段训练来控制结构更新的范围和时间。", "result": "GTCA增强的语法鲁棒性超越了持续训练的基线，同时没有损害多选题问答性能或常识推理能力。", "conclusion": "GTCA是实现更健壮语法的解码器仅语言模型的一种有效的，与检查点兼容的方法。"}}
{"id": "2602.15892", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15892", "abs": "https://arxiv.org/abs/2602.15892", "authors": ["Maijunxian Wang", "Yijiang Li", "Bingyang Wang", "Tianwei Zhao", "Ran Ji", "Qingying Gao", "Emmy Liu", "Hokin Deng", "Dezhi Luo"], "title": "Egocentric Bias in Vision-Language Models", "comment": null, "summary": "Visual perspective taking--inferring how the world appears from another's viewpoint--is foundational to social cognition. We introduce FlipSet, a diagnostic benchmark for Level-2 visual perspective taking (L2 VPT) in vision-language models. The task requires simulating 180-degree rotations of 2D character strings from another agent's perspective, isolating spatial transformation from 3D scene complexity. Evaluating 103 VLMs reveals systematic egocentric bias: the vast majority perform below chance, with roughly three-quarters of errors reproducing the camera viewpoint. Control experiments expose a compositional deficit--models achieve high theory-of-mind accuracy and above-chance mental rotation in isolation, yet fail catastrophically when integration is required. This dissociation indicates that current VLMs lack the mechanisms needed to bind social awareness to spatial operations, suggesting fundamental limitations in model-based spatial reasoning. FlipSet provides a cognitively grounded testbed for diagnosing perspective-taking capabilities in multimodal systems.", "AI": {"tldr": "该论文介绍了一个基准测试FlipSet，用于评估视觉语言模型进行二级视觉视角转换的能力，发现这些模型存在自我中心偏误，并且在需要将社会认知与空间操作结合的任务上表现不佳。", "motivation": "该研究旨在评估视觉语言模型的空间变换能力和其是否能够执行视觉视角转换，这是社会认知的重要组成部分。", "method": "引入了FlipSet，这是一个用于评估视觉语言模型二级视觉视角转换（L2 VPT）能力的基准测试，任务要求从另一个代理的视角模拟2D字符字符串的180度旋转，从而将空间转换与3D场景复杂性分离。", "result": "评估了103个视觉语言模型，结果显示系统自我中心偏误：大多数模型的表现低于随机水平，大约四分之三的错误再现了摄像机视角。", "conclusion": "该研究揭示了当前视觉语言模型在将社会认知与空间操作结合的能力上存在基本限制，提出了FlipSet作为评估多模态系统视角转换能力的认知基准测试。"}}
{"id": "2602.15847", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.15847", "abs": "https://arxiv.org/abs/2602.15847", "authors": ["Pranav Bhandari", "Usman Naseem", "Mehwish Nasim"], "title": "Do Personality Traits Interfere? Geometric Limitations of Steering in Large Language Models", "comment": null, "summary": "Personality steering in large language models (LLMs) commonly relies on injecting trait-specific steering vectors, implicitly assuming that personality traits can be controlled independently. In this work, we examine whether this assumption holds by analysing the geometric relationships between Big Five personality steering directions. We study steering vectors extracted from two model families (LLaMA-3-8B and Mistral-8B) and apply a range of geometric conditioning schemes, from unconstrained directions to soft and hard orthonormalisation. Our results show that personality steering directions exhibit substantial geometric dependence: steering one trait consistently induces changes in others, even when linear overlap is explicitly removed. While hard orthonormalisation enforces geometric independence, it does not eliminate cross-trait behavioural effects and can reduce steering strength. These findings suggest that personality traits in LLMs occupy a slightly coupled subspace, limiting fully independent trait control.", "AI": {"tldr": "研究发现，大型语言模型中的个性特质并非完全独立控制，而是存在一定程度的耦合，影响了独立控制个性的能力。", "motivation": "研究动机在于调查在大型语言模型（LLMs）中通过注入特定个性特质的转向向量来引导个性是否有效，尤其是在个性特质是否能够被独立控制这一假设的基础上。", "method": "通过分析两个模型系列（LLaMA-3-8B和Mistral-8B）中提取的转向向量的几何关系来研究个性特质的独立控制假设。使用了一系列的几何条件方案，从无约束方向到软正交化和硬正交化。", "result": "研究结果显示个性转向方向具有显著的几何依赖性：不仅一个特质的转向会一致地引起其他特质的变化，即使在消除了线性重叠的情况下也是如此。尽管硬正交化强制了几何上的独立性，但这并不会消除跨特质的行为效应，同时可能会降低转向强度。", "conclusion": "这些发现表明，大型语言模型中的个性特质占据一个略微耦合的子空间，限制了完全独立控制特质的能力。"}}
{"id": "2602.15903", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.15903", "abs": "https://arxiv.org/abs/2602.15903", "authors": ["Jingwei Li", "Jiaxin Tong", "Pengfei Wu"], "title": "Detecting Deepfakes with Multivariate Soft Blending and CLIP-based Image-Text Alignment", "comment": null, "summary": "The proliferation of highly realistic facial forgeries necessitates robust detection methods. However, existing approaches often suffer from limited accuracy and poor generalization due to significant distribution shifts among samples generated by diverse forgery techniques. To address these challenges, we propose a novel Multivariate and Soft Blending Augmentation with CLIP-guided Forgery Intensity Estimation (MSBA-CLIP) framework. Our method leverages the multimodal alignment capabilities of CLIP to capture subtle forgery traces. We introduce a Multivariate and Soft Blending Augmentation (MSBA) strategy that synthesizes images by blending forgeries from multiple methods with random weights, forcing the model to learn generalizable patterns. Furthermore, a dedicated Multivariate Forgery Intensity Estimation (MFIE) module is designed to explicitly guide the model in learning features related to varied forgery modes and intensities. Extensive experiments demonstrate state-of-the-art performance. On in-domain tests, our method improves Accuracy and AUC by 3.32\\% and 4.02\\%, respectively, over the best baseline. In cross-domain evaluations across five datasets, it achieves an average AUC gain of 3.27\\%. Ablation studies confirm the efficacy of both proposed components. While the reliance on a large vision-language model entails higher computational cost, our work presents a significant step towards more generalizable and robust deepfake detection.", "AI": {"tldr": "本文提出了一种基于多变量软融合增强策略和CLIP引导伪造强度估计的面部伪造图像检测方法，显著改善了检测的准确率和泛化能力。", "motivation": "当前面部伪造检测方法受限于样本分布偏差，准确性和泛化能力不足，因此提出一种多变量软融合增强策略结合CLIP引导强度估计的方法以提升伪造检测效果。", "method": "我们的方法提出了MSBA-CLIP框架，该框架结合了多变量软融合增强策略和CLIP引导的伪造强度估计模块，以提高伪造检测的准确性和泛化能力。", "result": "实验表明，该方法在内部验证中将准确率和AUC分别提高了3.32%和4.02%，在跨域验证中实现了平均AUC增益为3.27%。消融研究证实了所提组件的有效性。", "conclusion": "尽管使用大规模视觉语言模型带来了更高的计算成本，我们提出的方法在面部伪造图像的检测领域提供了一个更有通用性和鲁棒性的解决方案。"}}
{"id": "2602.15848", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.15848", "abs": "https://arxiv.org/abs/2602.15848", "authors": ["Andrius Matšenas", "Anet Lello", "Tõnis Lees", "Hans Peep", "Kim Lilii Tamm"], "title": "Can LLMs Assess Personality? Validating Conversational AI for Trait Profiling", "comment": "13 pages, 7 figures, 4 tables, 2 appendices", "summary": "This study validates Large Language Models (LLMs) as a dynamic alternative to questionnaire-based personality assessment. Using a within-subjects experiment (N=33), we compared Big Five personality scores derived from guided LLM conversations against the gold-standard IPIP-50 questionnaire, while also measuring user-perceived accuracy. Results indicate moderate convergent validity (r=0.38-0.58), with Conscientiousness, Openness, and Neuroticism scores statistically equivalent between methods. Agreeableness and Extraversion showed significant differences, suggesting trait-specific calibration is needed. Notably, participants rated LLM-generated profiles as equally accurate as traditional questionnaire results. These findings suggest conversational AI offers a promising new approach to traditional psychometrics.", "AI": {"tldr": "研究验证了大型语言模型（LLMs）作为一种动态的个性评估问卷方法的替代方案。实验结果表明，LLMs与黄金标准IPIP-50问卷之间有适度的相关性，并且用户对LLMs生成的个性档案评价较高。", "motivation": "验证大型语言模型（LLMs）是否可以作为一种替代问卷进行个性评估的有效手段。", "method": "采用了一项涉及33名参与者的被试内实验，将个性特征得分与黄金标准IPIP-50问卷得分进行比较，同时测量用户对个性特征测量准确性的感知。", "result": "结果显示中等的收敛有效性，表明某些性格特征在LLM评估和标准问卷评估之间具有统计学上相同的得分，而对于另两种特质则显示出显著差异，这表明需要特定的特性校准。用户觉得LLM生成的个性特征与传统的问卷结果具有相同的准确性。", "conclusion": "总体来说，大型语言模型（LLMs）作为一种个性评估手段，提供了传统心理测量学上的一个有前景的新方法。"}}
