<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 6]
- [cs.CV](#cs.CV) [Total: 10]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi,Jessica Morley,Claudio Novelli,David Watson*

Main category: cs.CL

> 文章分析了大型语言模型（LLMs）的随机性及它们与人类归纳推理的相似之处，指出LLMs生成的文本似乎具有归纳性，但实际上并没有进行实际的归纳推理。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于揭示当前LLMs的随机性和它们与人类归纳推理之间的相似性。通过讨论五点反对意见，文章试图提供一个全面的评估。

**Method:** 该文章通过分析大型语言模型（LLMs）的令牌完成机制，探讨了它们在推理机制方面的表现。文章通过提供示例，展示了这些模型能够生成看似合理的设想、模拟常识推理，以及提供解释性答案。

**Result:** 研究表明，尽管LLMs的输出可能看起来像是进行了归纳推理，但实际上它们仅仅是基于学习的模式生成文本，而不是真正进行了归纳推理。

**Conclusion:** 文章的结论是，LLMs对于生成创意和支持人类思考具有辅助作用，但它们的输出必须经过严格评估，因为它们无法确定真相或验证它们的解释。

**Abstract:** This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [2] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei,John Stamper,Paulo F. Carvalho*

Main category: cs.CL

> 研究展示了小规模语言模型（SLM）在自动生成问题中的应用潜力，通过生成-验证策略，SLM能够生成高质量问题，且经专家和大规模语言模型评估证明效果良好。

<details>
  <summary>Details</summary>

**Motivation:** 探索小规模语言模型（SLM）在学习分析研究中自动问题生成的应用，作为大规模模型的补充。

**Method:** 提出了一种新的问题生成管道，采用“先生成，后验证”的策略，利用SLM的文本生成和概率推理能力生成并精炼问题。

**Result:** 通过两项评估研究（含人类专家和大规模语言模型反馈），证明生成的问题大多数具备清晰答案且通常符合学习目标。

**Conclusion:** SLM在指导机制良好设计的管道下能有效生成高质量问题。

**Abstract:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [3] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

Main category: cs.CL

> 本文提出了DeepNews框架，通过模仿经验丰富的金融记者的隐性认知过程，以解决现有大语言模型在低幻想率、深度逻辑一致性和个性化表达方面难以兼顾的问题。框架包括三部分：双粒度检索机制、模式指导策略规划、对抗约束提示技术，实验表明该框架在深度财经报道中的表现优于最先进的零样本生成模型。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有语言模型在生成长文本时无法同时实现低幻想率、深度逻辑一致性和个性化表达的问题。

**Method:** 提出DeepNews框架，包括：1）基于信息搜寻理论的双粒度检索机制；2）利用领域专家知识库的模式指导策略规划；3）采用包括节奏中断和技术迷惑的对抗约束提示技术。

**Result:** 实验发现知识悬崖现象：报道内容的真实性在检索上下文少于15,000字符时急剧下降，而超过30,000字符的高冗余输入可以稳定幻觉自由率在85%以上。在顶级中国科技媒体盲测试中，DeepNews系统实现了25%的提交接受率，远超零样本生成模型的0%。

**Conclusion:** 结果表明，DeepNews框架在深度财经报道中展现出了出色的性能，并有效提升了文本的真实性与接受度。

**Abstract:** Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [4] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park,Jeongseok Yun,Bohyung Kim*

Main category: cs.CL

> 本文提出了一种从简短评论文本中推断用户人格特征的方法，并通过调整解码温度，生成了多样化且忠实的回复。此方法在提升回复个性化和相关性方面效果显著。

<details>
  <summary>Details</summary>

**Motivation:** 针对在线食品配送平台中存在的用户信息有限问题，该文旨在解决现有大型语言模型在缺乏上下文用户数据的情况下产生通用回复的问题，这种通用回复减少了用户参与度和有效性。通过增强回复的个性化，提高其与用户的贴合度。

**Method:** 提出了一种两阶段的提示框架，该框架可以从简短的评论文本中推断出用户显性和隐性的人格特征。这些推断出的人格属性随后被整合到回复生成的提示中，以产生用户定制化的回复。为了鼓励多样化但忠实的生成，我们在推理过程中调整解码温度。

**Result:** 使用从韩国食品配送应用中收集的真实世界数据集进行评估，评估了方法对精度、多样性和语义一致性的影响。结果显示，人格增强提示在不需要模型微调的情况下，显著提高了自动回复的相关性和个性化水平。

**Conclusion:** 研究展示了人格增强提示在提升自动回复的相关性和个性化方面的有效性，并且无需进行模型微调。这种方法克服了在用户信息有限的场景下，大型语言模型产生通用化回复的问题。

**Abstract:** Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [5] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum,Hani Itani,Hasan Abed Al Kader Hammoud,Philip Torr,Adel Bibi,Bernard Ghanem*

Main category: cs.CL

> 本文探讨了大规模语言模型（LLMs）在适应新任务时的安全退化问题，并提出采用持续学习（CL）方法，尤其是DER方法，能有效减轻安全退化，保持任务效用。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模语言模型（LLMs）的普及，它们的安全性对齐变得越来越重要。本文研究了在适应新任务时，LLMs的安全性退化。我们认为，这种安全妥协与灾难性遗忘有关，并将保持安全性的微调问题定为持续学习（CL）问题。

**Method:** 我们考虑了将微调作为服务的设置，用户将他们的数据上传到服务提供商处，以获得一个在其选定任务上表现出色的定制模型。我们从文献中适应了几种持续学习（CL）方法，并系统地评估了它们减轻安全退化的能力。这些方法包括基于正则化的、基于记忆的和模型融合的方法。

**Result:** 我们的结果显示，CL方法比标准微调方法在降低攻击成功率方面更一致。在这些方法中，DER表现优于其他CL方法和现有的保持安全性的基线，同时保持任务效用。这些发现在三个下游任务（GSM8K、SST2、Code）和三种模型家族（LLaMA2-7B、Mistral-7B、Gemma-2B）之间具有一致性，确立了CL作为保持安全性的实用解决方案。

**Conclusion:** CL方法特别是基于正则化的模型DER，不仅能够有效降低攻击成功率，还能在不同的模型族和任务之间保持一致的性能，成为保持安全性的实用解决方案。

**Abstract:** The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [6] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim*

Main category: cs.CL

> 本文提出了AutoMedic框架来评估LLM在临床对话中的表现，此框架可以生成虚拟患者档案以进行多回合临床对话，并使用CARE指标评估代理的临床对话准确性、效率/策略、同理心和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管已经提出了各种医学问答的静态基准测试，但在生成互动多回合临床对话响应的效果以及在评估策略方面的多方面评估方面仍有许多尚未探索的内容。本文旨在解决这些难题，以便安全和可信地应用LLM于医疗领域。

**Method:** 本文提出了AutoMedic，这是一个多代理模拟框架，用于自动评估LLM作为临床对话代理的能力。AutoMedic可以将现成的静态QA数据集转化为虚拟患者档案，从而实现真实且基于临床的多回合临床对话之间的交流。

**Result:** 研究表明，经过人类专家验证，AutoMedic作为一个自动化评估框架，可用于评估临床对话代理，为在对话医疗应用中有效开发LLM提供了可行指南。

**Conclusion:** AutoMedic框架被证明是一个有效的自动化评估工具，用于评估LLM在医疗对话中的表现，为开发更符合临床需求的LLM提供了实际指导。

**Abstract:** Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [7] [Neuromorphic Eye Tracking for Low-Latency Pupil Detection](https://arxiv.org/abs/2512.09969)
*Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes*

Main category: cs.CV

> The paper proposes a neuromorphic event-based eye-tracking model using LIF layers and depth-wise separable convolutions, achieving high accuracy at lower power and latency compared to conventional frame-based methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the efficiency and reduce the latency of eye-tracking systems for wearable devices like AR and VR, which conventional frame-based pipelines cannot achieve due to their high computational cost and limited temporal resolution.

**Method:** The method is to develop a neuromorphic version of top-performing event-based eye-tracking models by using lightweight LIF layers and reducing model complexity with depth-wise separable convolutions.

**Result:** The results are a 3.7-4.1px mean error and a significant reduction in model size and compute compared to ANN methods, projecting an operation at 3.9-4.9mW with 3ms latency at 1kHz.

**Conclusion:** The conclusion is that event-based eye-tracking can be efficiently achieved with SNNs, making it suitable for real-time wearable systems.

**Abstract:** Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.

</details>


### [8] [ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects](https://arxiv.org/abs/2512.10031)
*Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim*

Main category: cs.CV

> ABBSPO框架改进了弱监督环境下的边界框尺度预测和对称先验角预测，提高了精度和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 提出ABBSPO框架，以克服现有弱监督下水平边界框监督法在尺度估计和自监督学习方面的不足。

**Method:** ABBSPO框架包括自适应边界框缩放(ABBS)和基于对称先验的角度预测(SPA)，解决了以往方法中边界框尺度估计不准确和学习过程易坍塌的问题。

**Result:** 实验显示ABBSPO成功地提升了尺度预测的准确性，并解决了学习过程中的坍塌问题，取得了最佳性能。

**Conclusion:** 实验结果表明，ABBSPO达到了最先进的性能，优于现有的方法。

**Abstract:** Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.

</details>


### [9] [Diffusion Is Your Friend in Show, Suggest and Tell](https://arxiv.org/abs/2512.10038)
*Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi*

Main category: cs.CV

> 作者结合扩散模型和自回归模型的优势，提出了Show, Suggest and Tell方法，并在COCO数据集上获得了最佳结果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散降噪模型在生成计算机视觉任务中表现出色，但在离散领域仍无法超越标准自回归解决方案，这促使作者提出了一种新范式。

**Method:** 采用扩散模型为自回归生成提供建议而非直接替代，以此结合扩散模型的双向及改进能力与自回归模型的强语言结构能力。

**Result:** 提出的Show, Suggest and Tell (SST)方法在COCO数据集上实现了125.1的CIDEr-D评分，相比同类方法，在不使用强化学习的情况下，分别超出自回归和扩散模型的最新技术水平1.5和2.5分。

**Conclusion:** 实验验证表明，建议模块的质量与生成的描述的质量正相关，显示出该方法是目前尚未充分探索但很有前景的研究方向。

**Abstract:** Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: https://github.com/jchenghu/show\_suggest\_tell.

</details>


### [10] [MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata](https://arxiv.org/abs/2512.10041)
*Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman*

Main category: cs.CV

> MetaVoxel introduces a single diffusion process to model joint distributions of medical imaging and metadata, achieving comparable performance across multiple tasks without retraining.

<details>
  <summary>Details</summary>

**Motivation:** Traditional deep learning methods are limited to specific predictive directions and input variables, and require separate models for different tasks. This paper aims to unify these tasks using one model.

**Method:** MetaVoxel, a generative joint diffusion modeling framework, is introduced to model the joint distribution over imaging data and clinical metadata by learning a single diffusion process.

**Result:** The model can perform tasks like image generation, age estimation, and sex prediction with performance comparable to established task-specific baselines.

**Conclusion:** The findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enhancing clinical applicability.

**Abstract:** Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible inference.Together, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

</details>


### [11] [Independent Density Estimation](https://arxiv.org/abs/2512.10067)
*Jiahao Liu*

Main category: cs.CV

> 本文提出了一种名为独立密度估计（IDE）的新方法，旨在解决大规模视觉语言模型在组合泛化方面的难题，并构建了两个基于IDE理念的模型，展现了在未见组合上的优越泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 大规模视觉语言模型虽然在图像描述生成等领域取得了显著成果，但在实现像人一样的组合泛化方面仍然存在困难，因此提出该研究。

**Method:** 本文提出了独立密度估计（IDE）方法，用于学习句子中各个词语与图像中相应特征之间的联系，以实现组合泛化。构建了两个基于IDE的模型，第一个利用完全解耦的视觉表示作为输入，第二个使用变分自编码器从原始图像中提取部分解耦特征。此外还提出了一种基于熵的组合推理方法来组合句子中每个词的预测。

**Result:** 当在各种数据集上进行评估时，我们的模型展现出了优越的泛化能力到未见过的组合。

**Conclusion:** 与当前模型相比，本文提出的模型在处理未见组合方面表现出更好的泛化性能。

**Abstract:** Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Nevertheless, these models still encounter difficulties in achieving human-like compositional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connection between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy-based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.

</details>


### [12] [TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing](https://arxiv.org/abs/2512.10095)
*Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan*

Main category: cs.CV

> TraceFlow 框架利用 Residual Material-Augmented 2D Gaussian Splatting 和 Dynamic Environment Gaussian 解决动态场景下的镜面反射问题，优于现有技术，提供了更真实、更尖锐的渲染结果。

<details>
  <summary>Details</summary>

**Motivation:** 解决动态镜面场景的高保真渲染中精确反射方向估计和物理准确反射建模这两个关键挑战。

**Method:** Residual Material-Augmented 2D Gaussian Splatting representation 和 Dynamic Environment Gaussian 结合 hybrid rendering pipeline

**Result:** 在动态场景基准测试中，TraceFlow 在量化和质化上都优于之前的方法，产生了更尖锐和更真实的动态环境中的镜面反射。

**Conclusion:** TraceFlow 通过创新的渲染框架提供了先进的动态镜面反射渲染能力。

**Abstract:** We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.

</details>


### [13] [Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information](https://arxiv.org/abs/2512.10102)
*Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari*

Main category: cs.CV

> 提出了一个新任务：层次实例跟踪，创建了相应基准数据集并进行了初步模型评估。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于现有的跟踪任务未能涵盖对象和部件同时追踪并维持其层级关系的需求。

**Method:** 我们提出了一个名为“层次实例跟踪”的新任务，该任务旨在追踪预定义类别的所有对象及其部件实例，并保持它们之间的层级关系。

**Result:** 引入了首个支持该任务的基准数据集，包含2,765个独特的实体，分布在552个视频中，且这些实体属于40个不同的类别。对四种模型的七种变体进行评估，结果显示该数据集具有挑战性。

**Conclusion:** 该研究展示了层次实例跟踪的挑战，并提供了一个新数据集，这将促进未来研究的发展。

**Abstract:** We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/

</details>


### [14] [Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization](https://arxiv.org/abs/2512.10151)
*Charles Fanning,Mehmet Emin Aktas*

Main category: cs.CV

> 研究提出了一种方法，基于小波基和持续同源性来提升乳腺癌图像分析的准确性，通过这种方法，研究在跨不同成像设备和患者群体时，特别是葡萄牙和中国的数据实验中，证明了其能够有效地提高检测准确性。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺癌是女性中最常见的癌症，是全球癌症死亡的主要原因之一。目前的筛查乳房X线照相术虽然减少了死亡率，但解释结果时仍存在大量误诊（假阴性和假阳性），并且模型的准确性在跨不同扫描仪、成像模式和患者群体部署时会有所下降。

**Method:** 使用拓扑数据分析，我们通过对强度阈值的持续性同源性进行小波基向量化，来总结图像结构，并将这些信息转化为空间、多尺度地图，这些地图可以证明对强度的小扰动具有稳定性。这些地图被整合到一个两阶段检测管道中，通过输入级别的通道拼接。

**Result:** 该模型在美国CBIS DDSM数字化乳房X线项目组上接受训练和验证，并在葡萄牙(INbreast)和中国(CMMD)的两个独立全数字乳房X线照相项目组上进行了评估。在INbreast项目组中，在有限的训练预算下，使用波浪持久性通道增强的ConvNeXt Tiny模型将患者级别的AUC从0.55提高到了0.75。

**Conclusion:** 该研究提出了一种通过小波基及其持续性同源性的信号方式，来提升模型的外部性能，特别是在跨不同成像设备和患者群体时的模型性能表现，进一步改善了乳腺癌检测的准确性。

**Abstract:** Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.

</details>


### [15] [Feature Coding for Scalable Machine Vision](https://arxiv.org/abs/2512.10209)
*Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

> 本文介绍了一个用于压缩中间特征的编码模型（FCTM），该模型在多个视觉任务中实现了显著的比特率减少。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络（DNN）推动了现代机器视觉的发展，但其高计算需求使其难以在边缘设备上部署。传统的在设备上运行完整模型或卸载到云端的方法在延迟、带宽和隐私方面存在权衡。因此，本研究旨在通过压缩中间特征解决带宽问题。

**Method:** 本研究提出了一种名为特征编码测试模型（FCTM）的设计，该设计是为了解决在边缘设备和云端之间分配深度神经网络（DNN）推理工作负载时，传输中间特征面临的带宽挑战。通过Moving Picture Experts Group（MPEG）发起的Feature Coding for Machines（FCM）标准，建立了专用于压缩中间特征的位流语法和编码管道。

**Result:** 实验结果显示，FCM在多个视觉任务中平均实现了85.14%的比特率减少，同时保持了精度。

**Conclusion:** FCM为在带宽有限和隐私敏感的消费者应用中高效且互操作地部署智能特征提供了可扩展的途径。

**Abstract:** Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.

</details>


### [16] [Latent Chain-of-Thought World Modeling for End-to-End Driving](https://arxiv.org/abs/2512.10226)
*Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

</details>
