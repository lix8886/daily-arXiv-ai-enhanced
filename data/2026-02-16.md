<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Lightweight LLM Framework for Disaster Humanitarian Information Classification](https://arxiv.org/abs/2602.12284)
*Han Jinzhen,Kim Jisung,Yang Jong Soo,Yun Hong Sik*

Main category: cs.CL

> 论文提出了一个轻量级、成本效益高的框架，用于灾难推特分类，在参数高效微调下取得了显著的分类准确率，证明了在资源受限的紧急情况下进行有效灾难响应的能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了在紧急情况下有效应对灾难响应，及时分类来自社交媒体的人道主义信息至关重要，但大规模语言模型的部署面临着资源受限的挑战。

**Method:** 本论文介绍了一种轻量级、成本效益高的灾难推特分类框架，通过参数高效微调来应对资源受限的紧急情况。研究使用了HumAID数据集（包括跨越19个灾难事件的76,484条推特）构建了一个双任务基准：人道主义信息分类和事件类型识别。

**Result:** 研究系统性评估了提示策略、LoRA微调和检索增强生成（RAG）在Llama 3.1 8B上的应用，结果显示LoRA达到了79.62%的人道主义分类准确率（比零样本提高了37.79%），只需训练约2%的参数；QLoRA在50%内存成本下提供了99.4%的LoRA性能；RAG策略由于标签噪声问题降低了微调模型的性能。

**Conclusion:** 研究确立了一个实用且可重复的管道，用于在计算资源有限的情况下构建可靠的情报系统。这些结果为开发应用于紧急情况的最佳实践提供了重要参考。

**Abstract:** Timely classification of humanitarian information from social media is critical for effective disaster response. However, deploying large language models (LLMs) for this task faces challenges in resource-constrained emergency settings. This paper develops a lightweight, cost-effective framework for disaster tweet classification using parameter-efficient fine-tuning. We construct a unified experimental corpus by integrating and normalizing the HumAID dataset (76,484 tweets across 19 disaster events) into a dual-task benchmark: humanitarian information categorization and event type identification. Through systematic evaluation of prompting strategies, LoRA fine-tuning, and retrieval-augmented generation (RAG) on Llama 3.1 8B, we demonstrate that: (1) LoRA achieves 79.62% humanitarian classification accuracy (+37.79% over zero-shot) while training only ~2% of parameters; (2) QLoRA enables efficient deployment with 99.4% of LoRA performance at 50% memory cost; (3) contrary to common assumptions, RAG strategies degrade fine-tuned model performance due to label noise from retrieved examples. These findings establish a practical, reproducible pipeline for building reliable crisis intelligence systems with limited computational resources.

</details>


### [2] [From Biased Chatbots to Biased Agents: Examining Role Assignment Effects on LLM Agent Robustness](https://arxiv.org/abs/2602.12285)
*Linbo Cao,Lihao Sun,Yang Yue*

Main category: cs.CL

> 本研究首次系统地研究了基于人口统计学的人设分配如何影响大语言模型（LLMs）作为自主代理的行为及性能。实验显示，这种影响可能导致性能下降高达26.2%，从而揭示了LLMs代理系统中被忽视的一个漏洞。

<details>
  <summary>Details</summary>

**Motivation:** 虽然人们已经认识到语言模型中存在的人设引起的偏见，但这种偏见对代理任务表现的影响却很少被探索。鉴于这种影响可能带来的直接操作风险，作者决定对此进行研究。

**Method:** 在涉及战略推理、规划和技术操作的代理基准上，评估广泛部署的模型，探究任务无关的人设线索对代理决策可靠性的潜在扭曲效应。

**Result:** 研究表明，任务无关的人设线索会导致性能大幅波动，性能下降最高可达26.2%，这种现象在不同的任务类型和模型架构中都存在。

**Conclusion:** 人设分配可以引入隐性偏见，增加行为的不稳定性，这对LLMs代理系统安全和鲁棒性的部署提出了担忧。

**Abstract:** Large Language Models (LLMs) are increasingly deployed as autonomous agents capable of actions with real-world impacts beyond text generation. While persona-induced biases in text generation are well documented, their effects on agent task performance remain largely unexplored, even though such effects pose more direct operational risks. In this work, we present the first systematic case study showing that demographic-based persona assignments can alter LLM agents' behavior and degrade performance across diverse domains. Evaluating widely deployed models on agentic benchmarks spanning strategic reasoning, planning, and technical operations, we uncover substantial performance variations - up to 26.2% degradation, driven by task-irrelevant persona cues. These shifts appear across task types and model architectures, indicating that persona conditioning and simple prompt injections can distort an agent's decision-making reliability. Our findings reveal an overlooked vulnerability in current LLM agentic systems: persona assignments can introduce implicit biases and increase behavioral volatility, raising concerns for the safe and robust deployment of LLM agents.

</details>


### [3] [Retrieval-Augmented Self-Taught Reasoning Model with Adaptive Chain-of-Thought for ASR Named Entity Correction](https://arxiv.org/abs/2602.12287)
*Junjie An,Jingguang Tian,Tianyi Wang,Yu Gao,Xiaofeng Mou,Yi Xu*

Main category: cs.CL

> This paper proposes a method for named entity error correction in ASR using a novel retrieval-augmented generation framework which uses a rephrasing language model and a self-taught reasoning model with adaptive chain-of-thought to achieve better performance compared to strong baselines.

<details>
  <summary>Details</summary>

**Motivation:** End-to-end ASR systems often misrecognize domain-specific phrases like named entities, which can lead to failures in downstream tasks. Recent correction methods based on large language models have not fully utilized these models' reasoning capabilities.

**Method:** Our approach is a retrieval-augmented generation framework consisting of a rephrasing language model for named entity recognition and candidate retrieval using a phonetic-level edit distance, along with a self-taught reasoning model with adaptive chain-of-thought that adjusts reasoning depth based on task difficulty.

**Result:** Our method achieves relative reductions in named entity character error rate of 17.96% on the AISHELL-1 dataset and 34.42% on the Homophone dataset compared to a strong baseline.

**Conclusion:** The proposed method effectively reduces named entity errors in ASR by leveraging the sophisticated reasoning capabilities of language models, demonstrating its potential for enhancing the reliability of ASR systems in real-world applications.

**Abstract:** End-to-end automatic speech recognition (ASR) systems frequently misrecognize domain-specific phrases like named entities, which can cause catastrophic failures in downstream tasks. A new family of named entity correction methods based on large language models (LLMs) has recently emerged. However, these approaches have yet to fully exploit the sophisticated reasoning capabilities inherent to LLMs. To bridge this gap, we propose a novel retrieval-augmented generation framework for correcting named entity errors in ASR. Our approach consists of two key components: (1) a rephrasing language model (RLM) for named entity recognition, followed by candidate retrieval using a phonetic-level edit distance; and (2) a novel self-taught reasoning model with adaptive chain-of-thought (A-STAR) that dynamically adjusts the depth of its reasoning based on task difficulty. Experiments on the AISHELL-1 and Homophone datasets demonstrate the effectiveness of our method, which achieves relative reductions in the named entity character error rate of 17.96\% and 34.42\%, respectively, compared to a strong baseline.

</details>


### [4] [Grandes Modelos de Linguagem Multimodais (MLLMs): Da Teoria à Prática](https://arxiv.org/abs/2602.12302)
*Neemias da Silva,Júlio C. W. Scholz,John Harrison,Marina Borges,Paulo Ávila,Frances A Santos,Myriam Delgado,Rodrigo Minetto,Thiago H Silva*

Main category: cs.CL

> 本文综述了多模态大语言模型（MLLMs）的基本原理、标志性模型以及如何使用LangChain和LangGraph构建多模态管道的技术。同时讨论了挑战和趋势。更多实践内容可以在提供的GitHub仓库中找到。

<details>
  <summary>Details</summary>

**Motivation:** 多模态大语言模型结合了LLMs在自然语言处理方面的理解和生成能力，以及在图像和音频等多模态感知技能方面的关键进展，代表了当代AI的重要进步。因此有必要对这一研究领域进行综述和展望。

**Method:** 本文通过介绍多模态大语言模型（MLLMs）的基本原理和标志性模型来探讨这一主题。文章还探索了预处理、指令工程以及使用LangChain和LangGraph构建多模态管道的实际技术。

**Result:** 读者可以通过研究补充材料进一步了解实践操作，这些材料可以在以下网址获取：https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica。

**Conclusion:** 文章最后讨论了多模态模型面临的挑战，并指出了有前景的趋势。

**Abstract:** Multimodal Large Language Models (MLLMs) combine the natural language understanding and generation capabilities of LLMs with perception skills in modalities such as image and audio, representing a key advancement in contemporary AI. This chapter presents the main fundamentals of MLLMs and emblematic models. Practical techniques for preprocessing, prompt engineering, and building multimodal pipelines with LangChain and LangGraph are also explored. For further practical study, supplementary material is publicly available online: https://github.com/neemiasbsilva/MLLMs-Teoria-e-Pratica. Finally, the chapter discusses the challenges and highlights promising trends.

</details>


### [5] [propella-1: Multi-Property Document Annotation for LLM Data Curation at Scale](https://arxiv.org/abs/2602.12414)
*Maximilian Idahl,Benedikt Droste,Björn Plüster,Jan Philipp Harries*

Main category: cs.CL

> 文章介绍了propella-1系列LLM，它们能够在多维属性上标注文本，生成结构化注释，并公开了超过三十亿文档注释的数据集。

<details>
  <summary>Details</summary>

**Motivation:** 现有的数据整理方法主要依赖单一的标量质量分数，这种方法混淆了多个质量维度，限制了灵活的过滤，并且缺乏解释性。

**Method:** 我们提出了propella-1，这是一系列小型多语言LLM，能够根据预定义的模式在18个属性上标注文本，这些属性分为六个类别。模型支持57种语言，能够生成结构化的JSON注释。

**Result:** 4B参数的模型在与前沿商用LLM的对比评估中，表现出了比更大规模的通用模型更高的一致性。

**Conclusion:** 通过propella-注释数据集，我们进行了广泛的预训练数据集的多维度组合分析，揭示了不同文本之间的显著差异。这些模型和注释数据集都已公开发布。

**Abstract:** Since FineWeb-Edu, data curation for LLM pretraining has predominantly relied on single scalar quality scores produced by small classifiers. A single score conflates multiple quality dimensions, prevents flexible filtering, and offers no interpretability. We introduce propella-1, a family of small multilingual LLMs (0.6B, 1.7B, 4B parameters) that annotate text documents across 18 properties organized into six categories: core content, classification, quality and value, audience and purpose, safety and compliance, and geographic relevance. The models support 57 languages and produce structured JSON annotations conforming to a predefined schema. Evaluated against a frontier commercial LLM as a reference annotator, the 4B model achieves higher agreement than much larger general-purpose models. We release propella-annotations, a dataset of over three billion document annotations covering major pretraining corpora including data from FineWeb-2, FinePDFs, HPLT 3.0, and Nemotron-CC. Using these annotations, we present a multi-dimensional compositional analysis of widely used pretraining datasets, revealing substantial differences in quality, reasoning depth, and content composition that single-score approaches cannot capture. All model weights and annotations are released under permissive, commercial-use licenses.

</details>


### [6] [RankLLM: Weighted Ranking of LLMs by Quantifying Question Difficulty](https://arxiv.org/abs/2602.12424)
*Ziqian Zhang,Xingjian Hu,Yue Huang,Kai Zhang,Ruoxi Chen,Yixin Liu,Qingsong Wen,Kaidi Xu,Xiangliang Zhang,Neil Zhenqiang Gong,Lichao Sun*

Main category: cs.CL

> RankLLM 框架解决了现有基准测试中无法区分问题难度的问题，从而提供更细致的 LLM 能力评估，显示出高准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试无法区分问题难度，导致无法有效区分模型的能力。RankLLM 旨在解决这一问题，提供更细致的 LLM 能力评估。

**Method:** RankLLM 提出了一种量化问题难度和模型能力的方法，通过双向分数传播机制，在模型正确回答问题时为其能力打分，并在问题挑战模型时提高问题的难度评分。

**Result:** 使用 RankLLM 在 35,550 个问题上评估了 30 个模型，结果与人类判断的共识率达到 90%，并在各种指标上超越了强基线 IRT。

**Conclusion:** RankLLM 显示出高稳定性、快速收敛和高计算效率，成为大规模难度感知 LLM 评估的实际解决方案。

**Abstract:** Benchmarks establish a standardized evaluation framework to systematically assess the performance of large language models (LLMs), facilitating objective comparisons and driving advancements in the field. However, existing benchmarks fail to differentiate question difficulty, limiting their ability to effectively distinguish models' capabilities. To address this limitation, we propose RankLLM, a novel framework designed to quantify both question difficulty and model competency. RankLLM introduces difficulty as the primary criterion for differentiation, enabling a more fine-grained evaluation of LLM capabilities. RankLLM's core mechanism facilitates bidirectional score propagation between models and questions. The core intuition of RankLLM is that a model earns a competency score when it correctly answers a question, while a question's difficulty score increases when it challenges a model. Using this framework, we evaluate 30 models on 35,550 questions across multiple domains. RankLLM achieves 90% agreement with human judgments and consistently outperforms strong baselines such as IRT. It also exhibits strong stability, fast convergence, and high computational efficiency, making it a practical solution for large-scale, difficulty-aware LLM evaluation.

</details>


### [7] [RBCorr: Response Bias Correction in Language Models](https://arxiv.org/abs/2602.12445)
*Om Bhatt,Anna A. Ivanova*

Main category: cs.CL

> 本文提出了一个名为RBCorr的简单反应偏差纠正方法，验证后证明它可以有效消除语言模型的反应偏差，提高其性能，并确保其在封闭型回答任务上的表现与其真实能力更加匹配。

<details>
  <summary>Details</summary>

**Motivation:** 针对语言模型（LMs）在固定回答问题中表现出的反应偏差，特别是选项偏好偏差，开发低成本且有效的方法来纠正这些偏差，从而改善LMs的表现并更准确地评估其能力。

**Method:** 提出一种简单的反应偏差纠正策略（RBCorr），并在12个公开权重的语言模型上使用是/否、蕴含和多项选择问题进行测试。该策略基于LogProbs进行偏差纠正。

**Result:** 结果显示在纠正前LMs普遍存在反应偏差，并且RBCorr策略能够有效地消除偏差并提升模型性能。研究表明偏差行为在模型、数据集和提示格式之间具有泛化性。

**Conclusion:** RBCorr是一种易于使用的方法，可以提升小型LMs的表现，并确保LMs在封闭型回答基准测试中的表现更能反映其真实能力。

**Abstract:** Language models (LMs) are known to be prone to response biases, which present as option preference biases in fixed-response questions. It is therefore imperative to develop low-cost and effective response bias correction methods to improve LM performance and enable more accurate evaluations of model abilities. Here, we propose a simple response bias correction strategy ($\texttt{RBCorr}$) and test it on 12 open-weight language models using yes-no, entailment, and multiple choice questions. We show that response bias is prevalent in LMs pre-correction and that $\texttt{RBCorr}$ effectively eliminates bias and boosts model performance. We also explore the generalizability of bias behavior across models, datasets, and prompt formats, showing that LogProbs-based correction is highly dependent on all three of these aspects. Overall, $\texttt{RBCorr}$ is an easy-to-use method that can boost the performance of smaller LMs and ensure that LM performance on closed-response benchmarks aligns more closely with their true capabilities.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Thermal Imaging for Contactless Cardiorespiratory and Sudomotor Response Monitoring](https://arxiv.org/abs/2602.12361)
*Constantino Álvarez Casado,Mohammad Rahman,Sasan Sharifipour,Nhi Nguyen,Manuel Lage Cañellas,Xiaoting Wu,Miguel Bordallo López*

Main category: cs.CV

> 本文通过面部热成像视频提取心率、呼吸频率和电皮活动三种生物信号，并将电皮活动的配置进行了优化。最佳电皮活动配置的平均绝对相关性为0.40，呼吸频率估计的平均绝对误差为3.1bpm，心率估计的平均绝对误差为13.8bpm，结果受到相机帧率限制。

<details>
  <summary>Details</summary>

**Motivation:** 接触式皮肤电活动测量存在不便，本研究旨在探索使用面部热成像作为非接触式测量皮肤电活动（EDA）、心率（HR）和呼吸频率（BR）的新方法。

**Method:** 通过信号处理流程，跟踪面部的解剖区域，执行空间聚合，并从较快的心肺成分中分离缓慢的汗腺趋势。心率的测量使用各个面部感兴趣区域的正交矩阵图像转换，呼吸频率的测量使用鼻部和脸颊信号的平均值进行频谱峰检测。

**Result:** 对31个会话进行了测试，最佳固定电皮活动配置（鼻部区域，指数移动平均）达到的平均绝对相关性为0.40，呼吸频率估计的平均绝对误差为3.1bpm，心率估计的平均绝对误差为13.8bpm，但结果受到相机帧率的影响。

**Conclusion:** 研究结果为热成像非接触式生物信号估计提供了性能基准和设计指南，同时指出信号极性的变化、短暂的热动力学延迟以及提取质量随条件和人口统计学特征的变化。

**Abstract:** Thermal infrared imaging captures skin temperature changes driven by autonomic regulation and can potentially provide contactless estimation of electrodermal activity (EDA), heart rate (HR), and breathing rate (BR). While visible-light methods address HR and BR, they cannot access EDA, a standard marker of sympathetic activation. This paper characterizes the extraction of these three biosignals from facial thermal video using a signal-processing pipeline that tracks anatomical regions, applies spatial aggregation, and separates slow sudomotor trends from faster cardiorespiratory components. For HR, we apply an orthogonal matrix image transformation (OMIT) decomposition across multiple facial regions of interest (ROIs), and for BR we average nasal and cheek signals before spectral peak detection. We evaluate 288 EDA configurations and the HR/BR pipeline on 31 sessions from the public SIMULATOR STUDY 1 (SIM1) driver monitoring dataset. The best fixed EDA configuration (nose region, exponential moving average) reaches a mean absolute correlation of $0.40 \pm 0.23$ against palm EDA, with individual sessions reaching 0.89. BR estimation achieves a mean absolute error of $3.1 \pm 1.1$ bpm, while HR estimation yields $13.8 \pm 7.5$ bpm MAE, limited by the low camera frame rate (7.5 Hz). We report signal polarity alternation across sessions, short thermodynamic latency for well-tracked signals, and condition-dependent and demographic effects on extraction quality. These results provide baseline performance bounds and design guidance for thermal contactless biosignal estimation.

</details>


### [9] [LLaMo: Scaling Pretrained Language Models for Unified Motion Understanding and Generation with Continuous Autoregressive Tokens](https://arxiv.org/abs/2602.12370)
*Zekun Li,Sizhe An,Chengcheng Tang,Chuan Guo,Ivan Shugurov,Linguang Zhang,Amy Zhao,Srinath Sridhar,Lingling Tao,Abhay Mittal*

Main category: cs.CV

> LLaMo作为一个统一框架，通过对预训练语言模型的扩展，解决了动作-语言生成和理解中的灾难性遗忘和离散化抖动伪影问题，实现了高保真文本到动作生成和动作到文本描述，并达到了实时流式动作生成能力。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法通常通过在配对的动作-文本数据上微调大型语言模型（LLMs）来实现动作-语言的生成和理解，但这种方法可能导致语言能力的灾难性遗忘，由于可用动作-文本对的数量有限。此外，先前的方法通常通过量化将动作转换为离散表达，从而引入了显著的抖动伪影。为了应对这些挑战，提出了LLaMo框架。

**Method:** LLaMo采用了一种特定模态的变换器混合架构（MoT），旨在通过扩展预训练的语言模型来实现统一的多模态适应。同时，它将人类动作编码到因果连续潜在空间，并通过一个轻量级的流匹配头部保持解码器中的下一个标记预测范式，从而实现每秒超过30帧的实时动作生成。

**Result:** 实验结果表明，LLaMo在通用设置下实现了高质量的文本到动作生成和动作到文本描述，尤其是在零样本动作生成方面，这标志着向着通用的统一运动-语言大型模型迈出了重要一步。

**Conclusion:** LLaMo通过创新架构解决了动作-语言任务中的难题，实现了高质量的多模态生成和理解，特别是零样本动作生成，展现出了在通用化多模态模型方面的潜力。

**Abstract:** Recent progress in large models has led to significant advances in unified multimodal generation and understanding. However, the development of models that unify motion-language generation and understanding remains largely underexplored. Existing approaches often fine-tune large language models (LLMs) on paired motion-text data, which can result in catastrophic forgetting of linguistic capabilities due to the limited scale of available text-motion pairs. Furthermore, prior methods typically convert motion into discrete representations via quantization to integrate with language models, introducing substantial jitter artifacts from discrete tokenization. To address these challenges, we propose LLaMo, a unified framework that extends pretrained LLMs through a modality-specific Mixture-of-Transformers (MoT) architecture. This design inherently preserves the language understanding of the base model while enabling scalable multimodal adaptation. We encode human motion into a causal continuous latent space and maintain the next-token prediction paradigm in the decoder-only backbone through a lightweight flow-matching head, allowing for streaming motion generation in real-time (>30 FPS). Leveraging the comprehensive language understanding of pretrained LLMs and large-scale motion-text pretraining, our experiments demonstrate that LLaMo achieves high-fidelity text-to-motion generation and motion-to-text captioning in general settings, especially zero-shot motion generation, marking a significant step towards a general unified motion-language large model.

</details>


### [10] [Synthetic Image Detection with CLIP: Understanding and Assessing Predictive Cues](https://arxiv.org/abs/2602.12381)
*Marco Willi,Melanie Mathys,Michael Graber*

Main category: cs.CV

> 研究通过SynthCLIC数据集分析CLIP基础检测器，发现它们主要依赖高级摄影属性而非生成器特异性瑕疵，虽然准确率高但泛化性能受限，提示模型需要持续更新和更广泛的训练。

<details>
  <summary>Details</summary>

**Motivation:** 现有的合成图像检测方法在面对新型生成模型时泛化性能差，且在实际场景中表现不佳。研究旨在探索CLIP基础检测技术的准确性和泛化能力，以及识别CLIP特征中相关线索的性质。

**Method:** 通过引入SynthCLIC数据集，分析CLIP基础检测器学习的内容。该数据集由真实照片和最近扩散模型生成的高质量合成图像配对构成，旨在减少SID中的语义偏差。研究使用可解释的线性头部和文本关联概念模型，分析CLIP特征中的相关线索。

**Result:** 研究发现，CLIP基础线性检测器在GAN基准上达到0.96 mAP，但在高质量的SynthCLIC数据集上只有0.92 mAP，且在不同生成器之间的泛化性能下降到0.37 mAP。检测器主要依赖高级摄影属性，而不是明显的生成器特异性瑕疵。

**Conclusion:** CLIP基础检测器总体上表现出色，但对不同生成架构的泛化不均衡。这表明需要持续更新模型和更广泛的训练，同时也强化了CLIP基础方法作为强大、通用的SID基础的价值。

**Abstract:** Recent generative models produce near-photorealistic images, challenging the trustworthiness of photographs. Synthetic image detection (SID) has thus become an important area of research. Prior work has highlighted how synthetic images differ from real photographs--unfortunately, SID methods often struggle to generalize to novel generative models and often perform poorly in practical settings. CLIP, a foundational vision-language model which yields semantically rich image-text embeddings, shows strong accuracy and generalization for SID. Yet, the underlying relevant cues embedded in CLIP-features remain unknown. It is unclear, whether CLIP-based detectors simply detect strong visual artifacts or exploit subtle semantic biases, both of which would render them useless in practical settings or on generative models of high quality. We introduce SynthCLIC, a paired dataset of real photographs and high-quality synthetic counterparts from recent diffusion models, designed to reduce semantic bias in SID. Using an interpretable linear head with de-correlated activations and a text-grounded concept-model, we analyze what CLIP-based detectors learn. CLIP-based linear detectors reach 0.96 mAP on a GAN-based benchmark but only 0.92 on our high-quality diffusion dataset SynthCLIC, and generalization across generator families drops to as low as 0.37 mAP. We find that the detectors primarily rely on high-level photographic attributes (e.g., minimalist style, lens flare, or depth layering), rather than overt generator-specific artifacts. CLIP-based detectors perform well overall but generalize unevenly across diverse generative architectures. This highlights the need for continual model updates and broader training exposure, while reinforcing CLIP-based approaches as a strong foundation for more universal, robust SID.

</details>
