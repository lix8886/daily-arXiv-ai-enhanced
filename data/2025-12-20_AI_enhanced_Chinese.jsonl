{"id": "2512.15907", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15907", "abs": "https://arxiv.org/abs/2512.15907", "authors": ["Tejas Anvekar", "Juhna Park", "Aparna Garimella", "Vivek Gupta"], "title": "TabReX : Tabular Referenceless eXplainable Evaluation", "comment": null, "summary": "Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. TabReX converts both source text and generated tables into canonical knowledge graphs, aligns them through an LLM-guided matching process, and computes interpretable, rubric-aware scores that quantify structural and factual fidelity. The resulting metric provides controllable trade-offs between sensitivity and specificity, yielding human-aligned judgments and cell-level error traces. To systematically asses metric robustness, we introduce TabReX-Bench, a large-scale benchmark spanning six domains and twelve planner-driven perturbation types across three difficulty tiers. Empirical results show that TabReX achieves the highest correlation with expert rankings, remains stable under harder perturbations, and enables fine-grained model-vs-prompt analysis establishing a new paradigm for trustworthy, explainable evaluation of structured generation systems.", "AI": {"tldr": "TabReX 是一个无参考的、属性驱动的框架，用于通过图基准推理来评估表格生成的质量。它能提供控制敏感性和具体性之间平衡的能力，还能生成人机对齐的判断和单元级错误轨迹，并通过TabReX-Bench基准测试显示了其在专家排名中的高相关性以及在更复杂扰动下的稳定性。", "motivation": "当前评估大型语言模型生成表格质量的度量方法往往无法兼顾结构信息或者依赖固定参考，这限制了它们的广泛适用性。TabReX旨在解决这一问题，提供一个更加全面和动态的评估方法。", "method": "TabReX将源文本和生成的表格转换为规范的知识图，通过大型语言模型引导的匹配过程进行对齐，并计算可解释的分数量化结构和事实的保真度。", "result": "实验结果显示，TabReX在专家排名中的关联性最高，并且在面对更复杂的扰动时展现出稳定性，还能实现模型与提示的精细分析。", "conclusion": "TabReX为结构生成系统提供了可信、可解释的评价新范式，扩大了评估框架的适用范围并增强了其稳定性。"}}
{"id": "2512.15925", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.15925", "abs": "https://arxiv.org/abs/2512.15925", "authors": ["Joel Mire", "Maria Antoniak", "Steven R. Wilson", "Zexin Ma", "Achyutarama R. Ganti", "Andrew Piper", "Maarten Sap"], "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception", "comment": "Presented at IC2S2 2025; Under Review (ARR Oct 2025)", "summary": "Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader response, such as perceived author intent, explanatory and predictive reasoning, affective responses, and value judgments, using conversational context and a taxonomy grounded in narrative theory, linguistic pragmatics, and psychology. We develop two models, SSF-Generator and SSF-Classifier, validated through human surveys (N=382 participants) and expert annotations, respectively. We conduct pilot analyses to showcase the utility of the formalism for studying storytelling at scale. Specifically, applying our models to SSF-Corpus, a curated dataset of 6,140 social media stories from diverse contexts, we characterize the frequency and interdependence of storytelling intents, and we compare and contrast narrative practices (and their diversity) across communities. By linking fine-grained, context-sensitive modeling with a generic taxonomy of reader responses, SocialStoryFrames enable new research into storytelling in online communities.", "AI": {"tldr": "介绍了一种用于提炼读者对故事的多种反应的框架（SocialStoryFrames），并开发了两个模型SSF-Generator和SSF-Classifier，展示了该框架在大规模研究叙事方面的应用。", "motivation": "叙事阅读引发丰富的解释性、情感性和价值性反应，比如对叙述意图的推断或对人物的评价。然而，计算读者反应的模型较为有限，阻碍了精细化分析，因此需要填补这一空白。", "method": "提出SocialStoryFrames框架，使用对话上下文和基于叙事理论、语言学语用学和心理学的分类法，来提炼读者反应的合理推断，如感知的作者意图、解释性和预测性推理、情感反应和价值判断。开发了两个模型SSF-Generator和SSF-Classifier，分别通过人类调查（N=382参与者）和专家注释进行验证。", "result": "通过将模型应用于包含6,140个来自不同背景的社交媒体故事的SSF-Corpus语料库，对叙事意图的频率和相互依赖性进行了描述，并对比了跨越社区的叙述实践（及其多样性）。", "conclusion": "通过结合细粒度、上下文敏感的建模与读者反应的通用分类法，SocialStoryFrames可以在在线社区中进行新的叙事研究。"}}
{"id": "2512.15959", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15959", "abs": "https://arxiv.org/abs/2512.15959", "authors": ["Armağan Amcalar", "Eyup Cinar"], "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions", "comment": null, "summary": "Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.", "AI": {"tldr": "论文通过BRAID在GPT模型上进行结构化提示研究，证明了其在提高推理准确性和成本效益方面的有效性。", "motivation": "大型语言模型（LLMs）展示出性能、成本和令牌使用之间呈非线性关系。本文旨在通过定量研究展示结构化提示在提高推理准确性及成本效益方面的有效性。", "method": "本文研究了结构化提示在多个GPT模型级别上的效果，使用了BRAID框架，该框架通过Mermaid基础指令图进行有界推理，允许模型以结构化的方式进行推理，而不是通过无界自然语言令牌扩展。", "result": "研究结果表明，结构化的、机器可读的提示显著提高了生产系统中代理的推理准确性和成本效益。", "conclusion": "本文确立了BRAID作为优化自主智能体系统中推理效率的有效且可扩展技术。"}}
{"id": "2512.16034", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16034", "abs": "https://arxiv.org/abs/2512.16034", "authors": ["Kieran Henderson", "Kian Omoomi", "Vasudha Varadarajan", "Allison Lahnala", "Charles Welch"], "title": "Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms", "comment": null, "summary": "Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind of information is most informative for predicting annotator labels. In this work, we categorize self-disclosure sentences and use them to build annotator models for predicting judgments of social norms. We perform several ablations and analyses to examine the impact of the type of information on our ability to predict annotation patterns. We find that demographics are more impactful than attitudes, relationships, and experiences. Generally, theory-based approaches worked better than automatic clusters. Contrary to previous work, only a small number of related comments are needed. Lastly, having a more diverse sample of annotator self-disclosures leads to the best performance.", "AI": {"tldr": "研究发现，在预测标注者标签的过程中，人口统计信息比其他信息类型更重要。基于理论的方法在预测性能上优于自动聚类方法，并且少量的相关评论就足以改善预测结果，多样化的自我披露样本能进一步提高性能。", "motivation": "由于个人信息的数量一直受限，因此对哪些信息最有助于预测注释者的标签知之甚少。我们希望探索自我披露的不同类别对预测标注者标签的影响。", "method": "我们将自我披露的句子进行分类，并使用它们来构建注释者模型，以预测社会规范的判断。我们进行了多种消融分析来探讨不同类型的信息对预测注释模式的影响。", "result": "我们发现人口统计学信息比态度、关系和经历更为重要。总体而言，基于理论的方法比自动聚类表现得更好。与之前的研究相反，只需要少量相关评论。最后，拥有更多样化的注释者自我披露样本会带来更好的性能。", "conclusion": "人口统计信息在预测注释者的标签中起着最为重要的作用。基于理论的方法优于自动聚类方法。并且，少量的自我披露信息就足以改善模型性能，而多样化的自我披露样本更有利于提升模型的预测能力。"}}
{"id": "2512.15774", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15774", "abs": "https://arxiv.org/abs/2512.15774", "authors": ["Yan Yang", "George Bebis", "Mircea Nicolescu"], "title": "Two-Step Data Augmentation for Masked Face Detection and Recognition: Turning Fake Masks to Real", "comment": "9 pages, 9 figures. Conference version", "summary": "Data scarcity and distribution shift pose major challenges for masked face detection and recognition. We propose a two-step generative data augmentation framework that combines rule-based mask warping with unpaired image-to-image translation using GANs, enabling the generation of realistic masked-face samples beyond purely synthetic transformations. Compared to rule-based warping alone, the proposed approach yields consistent qualitative improvements and complements existing GAN-based masked face generation methods such as IAMGAN. We introduce a non-mask preservation loss and stochastic noise injection to stabilize training and enhance sample diversity. Experimental observations highlight the effectiveness of the proposed components and suggest directions for future improvements in data-centric augmentation for face recognition tasks.", "AI": {"tldr": "研究提出了一种新颖的数据增强方法来改进戴口罩人脸检测和识别的性能，该方法结合了基于规则的口罩变形和GAN技术，并引入了训练稳定的保障措施。", "motivation": "动机在于解决数据稀缺性和分布变化对被遮挡面部检测和识别的挑战。", "method": "分析论文中的方法，该方法是一个两步的生成数据增强框架，结合了基于规则的口罩变形和不配对的图像到图像的GAN翻译，以生成比纯粹的合成变换更现实的戴口罩人脸样本。引入了一个非掩模保持损失和随机噪声注入来稳定训练并增强样本多样性。", "result": "与仅基于规则的变形方法相比，所提出的方法在定性上表现出一致的改进，并且补充了现有的基于GAN的戴口罩人脸生成方法，如IAMGAN。", "conclusion": "实验观察表明提出的组件的有效性，并为未来在基于数据的增强方法中提高面部识别任务提供方向。"}}
{"id": "2512.16041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16041", "abs": "https://arxiv.org/abs/2512.16041", "authors": ["Yuanning Feng", "Sinan Wang", "Zhengxiang Cheng", "Yao Wan", "Dongping Chen"], "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?", "comment": null, "summary": "LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.", "AI": {"tldr": "提出Sage评估套件，以解决当前LLM评估依赖人类标注的问题，通过新的评估方法揭示了LLM在担任裁判时的可靠性和一致性问题。", "motivation": "现有的LLM-as-a-Judge基准主要依赖于人类标注的地面真实值，这引入了人类偏见并限制了评估的可靠性和可扩展性。因此，研究的动机在于提出一种无需人类标注的评估方法来克服这些限制。", "method": "Sage评估套件引入了两种新的衡量LLM-as-a-Judge的方法：局部自一致性（成对偏好稳定性）和全局逻辑一致性（整个偏好集的传递性），并通过结合结构化基准问题和真实世界用户查询，创建了包含650个问题的数据集进行评估。此外，研究还包括微调LLM-as-a-Judge和使用基于小组的裁判及深层推理来提升判断一致性。", "result": "实验表明了Sage评估套件的稳定性和与监督基准的高相关性，确认了Sage作为评估LLM-as-a-Judge可靠性的实用价值。同时也揭示了当前最先进模型在担任裁判角色时的可靠性问题。", "conclusion": "Sage作为一种评估工具是可靠的，它揭示了当前最先进的LLM在充当裁判角色时存在显著的可靠性和一致性问题。研究还指出，显式的评分准则可以帮助模型在答案对的判断中更加一致。"}}
{"id": "2512.15885", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15885", "abs": "https://arxiv.org/abs/2512.15885", "authors": ["Davide Caffagni", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Pier Luigi Dovesi", "Shaghayegh Roohi", "Mark Granroth-Wilding", "Rita Cucchiara"], "title": "Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have recently demonstrated impressive capabilities in connecting vision and language, yet their proficiency in fundamental visual reasoning tasks remains limited. This limitation can be attributed to the fact that MLLMs learn visual understanding primarily from textual descriptions, which constitute a subjective and inherently incomplete supervisory signal. Furthermore, the modest scale of multimodal instruction tuning compared to massive text-only pre-training leads MLLMs to overfit language priors while overlooking visual details. To address these issues, we introduce JARVIS, a JEPA-inspired framework for self-supervised visual enhancement in MLLMs. Specifically, we integrate the I-JEPA learning paradigm into the standard vision-language alignment pipeline of MLLMs training. Our approach leverages frozen vision foundation models as context and target encoders, while training the predictor, implemented as the early layers of an LLM, to learn structural and semantic regularities from images without relying exclusively on language supervision. Extensive experiments on standard MLLM benchmarks show that JARVIS consistently improves performance on vision-centric benchmarks across different LLM families, without degrading multimodal reasoning abilities. Our source code is publicly available at: https://github.com/aimagelab/JARVIS.", "AI": {"tldr": "针对多模态大型语言模型在视觉任务上的不足，研究人员提出JARVIS框架，利用自我监督学习增强视觉理解，并在标准基准上提高了视觉任务的表现，同时保持多模态推理能力。", "motivation": "多模态大型语言模型在连接视觉和语言方面展示了令人印象深刻的能力，但在基本视觉推理任务上的表现仍有限。这是因为这些模型主要通过文本描述来学习视觉理解，而这种信号主观且不完备。此外，模态指令调优的规模较小，导致模型过度依赖语言先验知识而忽略了视觉细节。", "method": "我们介绍了JARVIS，一个基于JEPA的自我监督视觉增强框架，用于解决多模态大型语言模型在视觉任务中的不足。具体来说，我们在标准的视觉-语言对齐流水线中整合了I-JEPA学习范式，并使用冻结的视觉基础模型作为上下文和目标编码器，训练作为LLM早期层实现的预测器，以从图像中学习结构和语义规律，而不完全依赖于语言监督。", "result": "大量实验表明，JARVIS在不同语言模型家族上提高了视觉为中心的基准任务的表现，且不会降低多模态推理能力。", "conclusion": "JARVIS通过利用冻结的视觉基础模型作为上下文和目标编码器，并训练预测器来学习图像中的结构和语义规律，有效增强了多模态语言模型在视觉推理任务上的能力，且对多模态推理能力没有负面影响。"}}
{"id": "2512.16125", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16125", "abs": "https://arxiv.org/abs/2512.16125", "authors": ["Daniela N. Rim", "Heeyoul Choi"], "title": "Convolutional Lie Operator for Sentence Classification", "comment": "Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval", "summary": "Traditional Convolutional Neural Networks have been successful in capturing local, position-invariant features in text, but their capacity to model complex transformation within language can be further explored. In this work, we explore a novel approach by integrating Lie Convolutions into Convolutional-based sentence classifiers, inspired by the ability of Lie group operations to capture complex, non-Euclidean symmetries. Our proposed models SCLie and DPCLie empirically outperform traditional Convolutional-based sentence classifiers, suggesting that Lie-based models relatively improve the accuracy by capturing transformations not commonly associated with language. Our findings motivate more exploration of new paradigms in language modeling.", "AI": {"tldr": "本文介绍了在卷积神经网络中引入Lie卷积以改善对复杂语言转换的捕捉能力，并通过实验表明这种方法优于传统方法，提高了精度。", "motivation": "传统卷积神经网络成功于捕捉文本中的局部特征，但在捕捉语言中的复杂转换方面仍有提升空间。", "method": "通过引入Lie群操作的复杂、非欧几里得对称性，提出了SCLie和DPCLie模型，以此来提高传统的卷积基于句子分类器的性能。", "result": "实验显示提出的SCLie和DPCLie模型超过了传统卷积句子分类器，表明Lie卷积模型在捕捉语言转换方面有所改善。", "conclusion": "发现推动了在语言建模中对新范式的更深层次的探索。"}}
{"id": "2512.15933", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15933", "abs": "https://arxiv.org/abs/2512.15933", "authors": ["Dwip Dalal", "Utkarsh Mishra", "Narendra Ahuja", "Nebojsa Jojic"], "title": "City Navigation in the Wild: Exploring Emergent Navigation from Web-Scale Knowledge in MLLMs", "comment": null, "summary": "Leveraging multimodal large language models (MLLMs) to develop embodied agents offers significant promise for addressing complex real-world tasks. However, current evaluation benchmarks remain predominantly language-centric or heavily reliant on simulated environments, rarely probing the nuanced, knowledge-intensive reasoning essential for practical, real-world scenarios. To bridge this critical gap, we introduce the task of Sparsely Grounded Visual Navigation, explicitly designed to evaluate the sequential decision-making abilities of MLLMs in challenging, knowledge-intensive real-world environments. We operationalize this task with CityNav, a comprehensive benchmark encompassing four diverse global cities, specifically constructed to assess raw MLLM-driven agents in city navigation. Agents are required to rely solely on visual inputs and internal multimodal reasoning to sequentially navigate 50+ decision points without additional environmental annotations or specialized architectural modifications. Crucially, agents must autonomously achieve localization through interpreting city-specific cues and recognizing landmarks, perform spatial reasoning, and strategically plan and execute routes to their destinations. Through extensive evaluations, we demonstrate that current state-of-the-art MLLMs and standard reasoning techniques (e.g., Chain-of-Thought, Reflection) significantly underperform in this challenging setting. To address this, we propose Verbalization of Path (VoP), which explicitly grounds the agent's internal reasoning by probing an explicit cognitive map (key landmarks and directions toward the destination) from the MLLMs, substantially enhancing navigation success. Project Webpage: https://dwipddalal.github.io/AgentNav/", "AI": {"tldr": "本文提出了一个名为CityNav的新基准，用于评估MLLM在现实世界的导航能力，并提出VoP方法以提高成功率。实验结果表明现有模型在复杂环境下表现不佳，而VoP方法提高了导航成功率。", "motivation": "当前，评估基准主要集中在语言能力上，或过度依赖模拟环境，很少考察在知识密集型现实世界场景中的推理能力。为了填补这一关键缺口，作者引入了Sparsely Grounded Visual Navigation任务，旨在评估MLLM在知识密集型现实世界环境中的序列决策能力。", "method": "本文提出了一个名为CityNav的新基准，用于评估MLLM（多模态大型语言模型）在现实世界环境中进行视觉导航的能力。在这个任务中，代理需要仅依靠视觉输入和内部的多模态推理来完成导航任务，而不依靠额外的环境注释或特定的架构修改。此外，本文还提出了一种名为VoP（路径的语言化）的方法，该方法通过明确地构建代理内部的认知地图来提高导航成功率，即通过探查关键地标和目标方向，这显著增强了导航性能。", "result": "通过广泛的评估，作者证明了现有的最先进的MLLM和标准推理技术（例如链式思维、反思）在具有挑战性的环境中显著表现不佳。提出的方法VoP显著提高了导航任务的成功率。", "conclusion": "本研究表明，要实现有效的实际场景导航，需要改进现有的MLLM和推理技术。提出的方法VoP通过显式地将代理的内部推理与认知地图相连接，达到了显著提升导航成功率的效果。"}}
{"id": "2512.16145", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16145", "abs": "https://arxiv.org/abs/2512.16145", "authors": ["Pengyu Wang", "Shuchang Ye", "Usman Naseem", "Jinman Kim"], "title": "MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation", "comment": "12 pages", "summary": "Medical report generation (MRG) aims to automatically derive radiology-style reports from medical images to aid in clinical decision-making. However, existing methods often generate text that mimics the linguistic style of radiologists but fails to guarantee clinical correctness, because they are trained on token-level objectives which focus on word-choice and sentence structure rather than actual medical accuracy. We propose a semantic-driven reinforcement learning (SRL) method for medical report generation, adopted on a large vision-language model (LVLM). SRL adopts Group Relative Policy Optimization (GRPO) to encourage clinical-correctness-guided learning beyond imitation of language style. Specifically, we optimise a report-level reward: a margin-based cosine similarity (MCCS) computed between key radiological findings extracted from generated and reference reports, thereby directly aligning clinical-label agreement and improving semantic correctness. A lightweight reasoning format constraint further guides the model to generate structured \"thinking report\" outputs. We evaluate Medical Report Generation with Sematic-driven Reinforment Learning (MRG-R1), on two datasets: IU X-Ray and MIMIC-CXR using clinical efficacy (CE) metrics. MRG-R1 achieves state-of-the-art performance with CE-F1 51.88 on IU X-Ray and 40.39 on MIMIC-CXR. We found that the label-semantic reinforcement is better than conventional token-level supervision. These results indicate that optimizing a clinically grounded, report-level reward rather than token overlap,meaningfully improves clinical correctness. This work is a prior to explore semantic-reinforcement in supervising medical correctness in medical Large vision-language model(Med-LVLM) training.", "AI": {"tldr": "该研究提出了一种基于语义驱动的强化学习方法(SRL)，用于在大型视觉语言模型上生成临床准确的医学报告，显著提高了报告的临床有效性。", "motivation": "尽管现有的方法模仿了放射科医生的语言风格，但它们无法保证临床准确性，因为训练的重点在于单词选择和句子结构。因此，需要一种能够保证医学准确性的方法。", "method": "研究团队提出了一种基于语义驱动的强化学习(SRL)方法，利用集团相对策略优化(GRPO)鼓励学习临床正确的语言，同时采用了轻量级的推理格式约束以生成结构化的“思考报告”。", "result": "在IU X-Ray和MIMIC-CXR两个数据集上，MRG-R1使用临床疗效(CE)指标进行评估，分别取得了51.88和40.39的CE-F1分数，达到了最先进的性能。", "conclusion": "研究结论表明，相较于传统的基于单词级别的监督，基于标签-语义强化的监督显著提高了临床正确性，这为在Med-LVLM训练中监督医学正确性的语义强化提供了前期探索。"}}
{"id": "2512.15940", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.15940", "abs": "https://arxiv.org/abs/2512.15940", "authors": ["Tin Stribor Sohn", "Maximilian Dillitzer", "Jason J. Corso", "Eric Sax"], "title": "R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space", "comment": null, "summary": "Humans perceive and reason about their surroundings in four dimensions by building persistent, structured internal representations that encode semantic meaning, spatial layout, and temporal dynamics. These multimodal memories enable them to recall past events, infer unobserved states, and integrate new information into context-dependent reasoning. Inspired by this capability, we introduce R4, a training-free framework for retrieval-augmented reasoning in 4D spatio-temporal space that equips vision-language models (VLMs) with structured, lifelong memory. R4 continuously constructs a 4D knowledge database by anchoring object-level semantic descriptions in metric space and time, yielding a persistent world model that can be shared across agents. At inference, natural language queries are decomposed into semantic, spatial, and temporal keys to retrieve relevant observations, which are integrated into the VLM's reasoning. Unlike classical retrieval-augmented generation methods, retrieval in R4 operates directly in 4D space, enabling episodic and collaborative reasoning without training. Experiments on embodied question answering and navigation benchmarks demonstrate that R4 substantially improves retrieval and reasoning over spatio-temporal information compared to baselines, advancing a new paradigm for embodied 4D reasoning in dynamic environments.", "AI": {"tldr": "本文介绍了一个无训练框架R4，它提高了基于视觉-语言模型在4D时空中的检索和推理能力，无需训练即可进行情景和协作推理。", "motivation": "受人类感知和推理周围环境的启发，特别是通过构建持久的结构化内部表示来感知环境的语义意义、空间布局和时间动态的能力，该研究引入了R4框架，以赋予VLMs结构化、终生记忆的能力。", "method": "R4框架通过在4D时空空间中构建结构化的持久世界模型，该模型能够在度量空间和时间中锚定对象级的语义描述，从而在推理时通过自然语言查询分解成语义、空间和时间键来检索相关信息，并将其整合到视觉-语言模型(VLM)的推理中。", "result": "实验表明，在基于身体的问题回答和导航基准测试中，与基线相比，R4显著提升了对时空信息的检索和推理能力。", "conclusion": "R4框架的研究成果展示了在动态环境中进行4D推理的新范式，增强了对时空信息的处理能力。"}}
{"id": "2512.16147", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16147", "abs": "https://arxiv.org/abs/2512.16147", "authors": ["Yash Bhaskar", "Sankalp Bahad", "Parameswari Krishnamurthy"], "title": "Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning", "comment": "Accepted Paper, Anthology ID: 2024.icon-fauxhate.3, 4 pages, 1 figure, 1 table", "summary": "Social media platforms, while enabling global connectivity, have become hubs for the rapid spread of harmful content, including hate speech and fake narratives \\cite{davidson2017automated, shu2017fake}. The Faux-Hate shared task focuses on detecting a specific phenomenon: the generation of hate speech driven by fake narratives, termed Faux-Hate. Participants are challenged to identify such instances in code-mixed Hindi-English social media text. This paper describes our system developed for the shared task, addressing two primary sub-tasks: (a) Binary Faux-Hate detection, involving fake and hate speech classification, and (b) Target and Severity prediction, categorizing the intended target and severity of hateful content. Our approach combines advanced natural language processing techniques with domain-specific pretraining to enhance performance across both tasks. The system achieved competitive results, demonstrating the efficacy of leveraging multi-task learning for this complex problem.", "AI": {"tldr": "本文描述了一个系统，用于检测社交媒体上印地语-英语混合文本中的虚假仇恨言论，通过多任务学习实现有效分类和预测。", "motivation": "社交媒体平台虽然促进了全球连接，但已成为迅速传播有害内容的中心，如仇恨言论和虚假叙事。本文旨在应对社交媒体上混合使用印地语和英语的有害内容检测问题。", "method": "本文描述了一个系统，该系统结合了先进自然语言处理技术与领域特定的预训练技术，来提升在两种子任务上的表现：(a) 二元Faux-Hate检测，包括虚假信息和仇恨言论分类；(b) 目标和严重性预测，分类仇恨内容的目标及其严重程度。", "result": "该系统实现了具有竞争力的结果，展示了利用多任务学习解决这一复杂问题的有效性。", "conclusion": "该研究证明了结合自然语言处理技术与特定领域预训练技术在检测混合语言文本中的虚假仇恨言论方面的有效性。"}}
{"id": "2512.15949", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15949", "abs": "https://arxiv.org/abs/2512.15949", "authors": ["Tejas Anvekar", "Fenil Bardoliya", "Pavan K. Turaga", "Chitta Baral", "Vivek Gupta"], "title": "The Perceptual Observatory Characterizing Robustness and Grounding in MLLMs", "comment": "Accepted at WACV 2026", "summary": "Recent advances in multimodal large language models (MLLMs) have yielded increasingly powerful models, yet their perceptual capacities remain poorly characterized. In practice, most model families scale language component while reusing nearly identical vision encoders (e.g., Qwen2.5-VL 3B/7B/72B), which raises pivotal concerns about whether progress reflects genuine visual grounding or reliance on internet-scale textual world knowledge. Existing evaluation methods emphasize end-task accuracy, overlooking robustness, attribution fidelity, and reasoning under controlled perturbations. We present The Perceptual Observatory, a framework that characterizes MLLMs across verticals like: (i) simple vision tasks, such as face matching and text-in-vision comprehension capabilities; (ii) local-to-global understanding, encompassing image matching, grid pointing game, and attribute localization, which tests general visual grounding. Each vertical is instantiated with ground-truth datasets of faces and words, systematically perturbed through pixel-based augmentations and diffusion-based stylized illusions. The Perceptual Observatory moves beyond leaderboard accuracy to yield insights into how MLLMs preserve perceptual grounding and relational structure under perturbations, providing a principled foundation for analyzing strengths and weaknesses of current and future models.", "AI": {"tldr": "A new framework called The Perceptual Observatory evaluates the visual grounding capabilities of multimodal large language models using perturbed datasets, aiming to understand perceptual grounding rather than just measuring end-task accuracy.", "motivation": "To address the undercharacterized perceptual capacities of MLLMs, particularly in relation to visual grounding versus textual world knowledge, and to move beyond just end-task accuracy to understand robustness and reasoning under controlled conditions.", "method": "The Perceptual Observatory, a framework designed to assess MLLMs across various visual tasks, including simple vision tasks and local-to-global understanding. This framework uses datasets of faces and words with systematic perturbations through pixel and diffusion-based augmentations.", "result": "None provided in the abstract, but the aim is to provide insights into the perceptual grounding and relational structure preservation of MLLMs under controlled perturbations.", "conclusion": "This framework serves as a principled foundation for analyzing the strengths and weaknesses of present and future MLLMs, providing a deeper understanding beyond mere task performance."}}
{"id": "2512.16183", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.16183", "abs": "https://arxiv.org/abs/2512.16183", "authors": ["Mengfan Shen", "Kangqi Song", "Xindi Wang", "Wei Jia", "Tao Wang", "Ziqiang Han"], "title": "A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media", "comment": "41 pages,3figures and 9 tables", "summary": "Structured information extraction from police incident announcements is crucial for timely and accurate data processing, yet presents considerable challenges due to the variability and informal nature of textual sources such as social media posts. To address these challenges, we developed a domain-adapted extraction pipeline that leverages targeted prompt engineering with parameter-efficient fine-tuning of the Qwen2.5-7B model using Low-Rank Adaptation (LoRA). This approach enables the model to handle noisy, heterogeneous text while reliably extracting 15 key fields, including location, event characteristics, and impact assessment, from a high-quality, manually annotated dataset of 4,933 instances derived from 27,822 police briefing posts on Chinese Weibo (2019-2020). Experimental results demonstrated that LoRA-based fine-tuning significantly improved performance over both the base and instruction-tuned models, achieving an accuracy exceeding 98.36% for mortality detection and Exact Match Rates of 95.31% for fatality counts and 95.54% for province-level location extraction. The proposed pipeline thus provides a validated and efficient solution for multi-task structured information extraction in specialized domains, offering a practical framework for transforming unstructured text into reliable structured data in social science research.", "AI": {"tldr": "本文提出了一种利用Qwen2.5-7B模型结合LoRA技术的领域适应性信息抽取管道，能够高效、准确地从中国微博的警务公告中提取关键信息。", "motivation": "警务公告中的结构化信息提取对于及时、准确的数据处理至关重要，但由于来源的文本（如社交媒体帖子）的多样性和非正式性，这一直具有挑战性。", "method": "研究团队开发了一种采用目标化提示工程与基于LoRA参数高效微调的领域适应性信息抽取管道，用于处理噪声的、异构的文本，并可靠地提取出15个关键字段。", "result": "实验结果显示，基于LoRA微调的方法比基础模型和指令调整后的模型表现更好，准确率超过98.36%，精确匹配率分别为95.31%和95.54%。", "conclusion": "所提出的管道为特定领域的多任务结构化信息提取提供了有效和验证的解决方案，为将非结构化的文本转换为社会科学研究中的可靠结构化数据提供了一个实用的框架。"}}
{"id": "2512.15957", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15957", "abs": "https://arxiv.org/abs/2512.15957", "authors": ["Utsav Panchal", "Yuchen Liu", "Luigi Palmieri", "Ilche Georgievski", "Marco Aiello"], "title": "Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models", "comment": "Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026", "summary": "Accurately predicting human behaviors is crucial for mobile robots operating in human-populated environments. While prior research primarily focuses on predicting actions in single-human scenarios from an egocentric view, several robotic applications require understanding multiple human behaviors from a third-person perspective. To this end, we present CAMP-VLM (Context-Aware Multi-human behavior Prediction): a Vision Language Model (VLM)-based framework that incorporates contextual features from visual input and spatial awareness from scene graphs to enhance prediction of humans-scene interactions. Due to the lack of suitable datasets for multi-human behavior prediction from an observer view, we perform fine-tuning of CAMP-VLM with synthetic human behavior data generated by a photorealistic simulator, and evaluate the resulting models on both synthetic and real-world sequences to assess their generalization capabilities. Leveraging Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), CAMP-VLM outperforms the best-performing baseline by up to 66.9% in prediction accuracy.", "AI": {"tldr": "提出了CAMP-VLM框架，通过大量的合成人类行为数据进行微调，显著提高了多视角人类行为预测的准确性。", "motivation": "现有的研究主要集中在从个人视角预测单一人类行为，但是对于需要理解多个个体行为的应用而言，需要从第三者的视角进行预测。", "method": "我们提出了CAMP-VLM：一个基于视觉语言模型的框架，它融合了视觉输入中的背景特征和场景图中的空间感知能力，以提升预测人与场景互动的能力。", "result": "通过使用监督微调和直接偏好优化，CAMP-VLM在预测精度上比最优基线高出66.9%。", "conclusion": "CAMP-VLM框架能够有效地预测多个个体行为，提高了在人群环境中的预测准确性。"}}
{"id": "2512.16189", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16189", "abs": "https://arxiv.org/abs/2512.16189", "authors": ["Musarrat Zeba", "Abdullah Al Mamun", "Kishoar Jahan Tithee", "Debopom Sutradhar", "Mohaimenul Azam Khan Raiaan", "Saddam Mukta", "Reem E. Mohamed", "Md Rafiqul Islam", "Yakub Sebastian", "Mukhtar Hussain", "Sami Azam"], "title": "Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation", "comment": null, "summary": "In healthcare, it is essential for any LLM-generated output to be reliable and accurate, particularly in cases involving decision-making and patient safety. However, the outputs are often unreliable in such critical areas due to the risk of hallucinated outputs from the LLMs. To address this issue, we propose a fact-checking module that operates independently of any LLM, along with a domain-specific summarization model designed to minimize hallucination rates. Our model is fine-tuned using Low-Rank Adaptation (LoRa) on the MIMIC III dataset and is paired with the fact-checking module, which uses numerical tests for correctness and logical checks at a granular level through discrete logic in natural language processing (NLP) to validate facts against electronic health records (EHRs). We trained the LLM model on the full MIMIC-III dataset. For evaluation of the fact-checking module, we sampled 104 summaries, extracted them into 3,786 propositions, and used these as facts. The fact-checking module achieves a precision of 0.8904, a recall of 0.8234, and an F1-score of 0.8556. Additionally, the LLM summary model achieves a ROUGE-1 score of 0.5797 and a BERTScore of 0.9120 for summary quality.", "AI": {"tldr": "针对LLM在医疗健康领域输出不可靠的问题，本研究提出了一种独立工作的事实核查模块及领域特定的摘要模型，以降低幻觉输出。", "motivation": "由于LLM生成的输出在医疗保健这个关键领域里往往不可靠，存在幻觉输出的风险，而该领域的决策制定和患者安全需要高度可靠的输出。因此，提出了这项研究。", "method": "我们提出了一种独立于LLM工作的事实核查模块以及一个旨在降低幻觉率的领域特定摘要模型。该模型使用Low-Rank Adaptation (LoRa)在MIMIC III数据集上微调，并与事实核查模块配对，该模块通过NLP中的离散逻辑进行细致的正确性数值测试和逻辑检查，以验证事实是否符合电子健康记录(EHR)的内容。", "result": "事实核查模块在采样的104个摘要中，分割成3,786个命题的事实检查中，达到了0.8904的精度，0.8234的召回率和0.8556的F1值。LLM摘要模型在摘要质量方面获得了0.5797的ROUGE-1分数和0.9120的BERTScore。", "conclusion": "本研究表明，通过结合事实核查模块，LLM可以为医疗保健领域提供更加可靠和精确的输出，同时提高了在关键领域的决策制定和患者安全方面的质量。"}}
{"id": "2512.15971", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15971", "abs": "https://arxiv.org/abs/2512.15971", "authors": ["Manuel Nkegoum", "Minh-Tan Pham", "Élisa Fromont", "Bruno Avignon", "Sébastien Lefèvre"], "title": "From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection", "comment": null, "summary": "Multispectral object detection is critical for safety-sensitive applications such as autonomous driving and surveillance, where robust perception under diverse illumination conditions is essential. However, the limited availability of annotated multispectral data severely restricts the training of deep detectors. In such data-scarce scenarios, textual class information can serve as a valuable source of semantic supervision. Motivated by the recent success of Vision-Language Models (VLMs) in computer vision, we explore their potential for few-shot multispectral object detection. Specifically, we adapt two representative VLM-based detectors, Grounding DINO and YOLO-World, to handle multispectral inputs and propose an effective mechanism to integrate text, visual and thermal modalities. Through extensive experiments on two popular multispectral image benchmarks, FLIR and M3FD, we demonstrate that VLM-based detectors not only excel in few-shot regimes, significantly outperforming specialized multispectral models trained with comparable data, but also achieve competitive or superior results under fully supervised settings. Our findings reveal that the semantic priors learned by large-scale VLMs effectively transfer to unseen spectral modalities, ofFering a powerful pathway toward data-efficient multispectral perception.", "AI": {"tldr": "研究探索了视觉语言模型在多光谱物体检测中的应用，实验证明其在少量样本和完全监督设置下均具有良好性能。", "motivation": "鉴于标注的多光谱数据有限，限制了深度检测器的训练。因此，试图利用文本类信息作为语义监督的重要来源，探索视觉语言模型在多光谱物体检测中的潜力。", "method": "通过改编Grounding DINO和YOLO-World以处理多光谱输入，并提出一种有效的文本、视觉和热成像模态整合机制，探索视觉语言模型在少量样本多光谱物体检测中的潜力。", "result": "在FLIR和M3FD两个流行的多光谱图像基准上进行广泛实验，证明基于视觉语言模型的检测器在少量样本制度中表现出色，显著优于使用类似数据训练的专用多光谱模型，并且在全监督设置下实现具有竞争力或更优的结果。", "conclusion": "发现大规模视觉语言模型所学习到的语义先验有效地转移到了未见过的光谱模态，为实现数据高效的多光谱感知提供了强大的路径。"}}
