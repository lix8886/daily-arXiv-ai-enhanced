<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 3]
- [cs.CV](#cs.CV) [Total: 7]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ReportLogic: Evaluating Logical Quality in Deep Research Reports](https://arxiv.org/abs/2602.18446)
*Jujia Zhao,Zhaoxin Huan,Zihan Wang,Xiaolu Zhang,Jun Zhou,Suzan Verberne,Zhaochun Ren*

Main category: cs.CL

> Introduces ReportLogic, a benchmark assessing the logical quality of large language model (LLM) generated reports for deep research from a reader’s perspective, focusing on traceability, context understanding, and claim verification.

<details>
  <summary>Details</summary>

**Motivation:** Current evaluation frameworks overlook the logical quality of reports, which is crucial for their practical reliability. ReportLogic aims to address this gap by focusing on logical quality from a reader-centric view.

**Method:** ReportLogic evaluates reports based on a hierarchical taxonomy focusing on Macro-Logic, Expositional-Logic, and Structural-Logic. A human-annotated dataset and LogicJudge are developed for scalable evaluation.

**Result:** Evaluation shows that off-the-shelf LLMs are often influenced by superficial cues, and adversarial attacks reveal issues with support relations in LLM-generated reports.

**Conclusion:** ReportLogic provides a structured way to assess the logical reliability of LLM-generated reports, offering insights for improving their robustness and logical integrity.

**Abstract:** Users increasingly rely on Large Language Models (LLMs) for Deep Research, using them to synthesize diverse sources into structured reports that support understanding and action. In this context, the practical reliability of such reports hinges on logical quality: whether the report's claims and arguments are explicitly supported and can be trusted as a basis for downstream use, rather than merely appearing fluent or informative. However, current evaluation frameworks largely overlook this requirement. To bridge this gap, we introduce ReportLogic, a benchmark that quantifies report-level logical quality through a reader-centric lens of auditability. Specifically, ReportLogic adopts a hierarchical taxonomy that evaluates whether readers can (1) trace an on-topic report structure with a unified analytical arc (Macro-Logic), (2) understand the progression with necessary context (Expositional-Logic), and (3) verify conclusions via explicit claim--support (Structural-Logic). Based on this taxonomy, we construct a human-annotated rubric-guided dataset and train an open-source LogicJudge for scalable evaluation. We further evaluate judge robustness via adversarial attacks, showing that off-the-shelf LLM judges are frequently influenced by superficial cues (e.g., verbosity), and reasoning modes can mask broken support relations. Overall, our results provide actionable guidance for building more robust logic evaluators and improving the logical reliability of LLM-generated reports.

</details>


### [2] [ConfSpec: Efficient Step-Level Speculative Reasoning via Confidence-Gated Verification](https://arxiv.org/abs/2602.18447)
*Siran Liu,Cyril Y. He*

Main category: cs.CL

> ConfSpec improves the speed and resource usage of chain-of-thought reasoning in large language models by using smaller models for decision verification, offering significant inference speedups without sacrificing accuracy.

<details>
  <summary>Details</summary>

**Motivation:** To improve inference speed and resource efficiency of chain-of-thought reasoning in large language models without compromising accuracy.

**Method:** ConfSpec, a confidence-gated cascaded verification framework, uses small draft models for step-level verification, which allows high-confidence decisions to be accepted directly, reducing the need for large model inference.

**Result:** Achieved up to 2.24 times end-to-end speedup while matching the accuracy of the target model across various workloads.

**Conclusion:** ConfSpec effectively resolves the trade-off between accuracy, inference speed, and resource efficiency in chain-of-thought reasoning tasks without requiring external judge models.

**Abstract:** Chain-of-Thought reasoning significantly improves the performance of large language models on complex tasks, but incurs high inference latency due to long generation traces. Step-level speculative reasoning aims to mitigate this cost, yet existing approaches face a long-standing trade-off among accuracy, inference speed, and resource efficiency. We propose ConfSpec, a confidence-gated cascaded verification framework that resolves this trade-off. Our key insight is an asymmetry between generation and verification: while generating a correct reasoning step requires substantial model capacity, step-level verification is a constrained discriminative task for which small draft models are well-calibrated within their competence range, enabling high-confidence draft decisions to be accepted directly while selectively escalating uncertain cases to the large target model. Evaluation across diverse workloads shows that ConfSpec achieves up to 2.24$\times$ end-to-end speedups while matching target-model accuracy. Our method requires no external judge models and is orthogonal to token-level speculative decoding, enabling further multiplicative acceleration.

</details>


### [3] [INSURE-Dial: A Phase-Aware Conversational Dataset \& Benchmark for Compliance Verification and Phase Detection](https://arxiv.org/abs/2602.18448)
*Shubham Kulkarni,Alexander Lyzhov,Preetam Joshi,Shiva Chaitanya*

Main category: cs.CL

> 研究介绍了INSURE-Dial，用于评估保险福利验证的合规性语音代理，揭示了自动化电话处理的现实挑战。

<details>
  <summary>Details</summary>

**Motivation:** 目的是减少美国医疗保健中大约每年1万亿美元的行政电话任务成本，特别是在保险福利验证上超过5亿次的手动处理电话。

**Method:** 介绍了一种名为INSURE-Dial的基准测试，用于开发和评估具有合规性的语音代理，特别是在基于跨度的合规性验证下的多阶段呼叫审计。该基准测试包括50次去标识化的、AI发起的通话（平均每个通话71轮）和1000次模仿相同工作流程的合成生成的通话，并对所有通话进行了标注。

**Result:** 该研究定义了两个新的评估任务：阶段边界检测和合规性验证。各阶段分数在小的、低延迟的基线模型上表现良好，但端到端的可靠性受到跨度边界错误的限制。真实通话的完整呼叫精确分段率低，显示了对话流畅度和审计级证据之间的差距。

**Conclusion:** 研究结果强调了在自动化保险福利验证电话处理中的挑战，尽管有良好的阶段性结果，但在保持端到端的可靠性和精确度方面仍有改进空间。

**Abstract:** Administrative phone tasks drain roughly 1 trillion USD annually from U.S. healthcare, with over 500 million insurance-benefit verification calls manually handled in 2024. We introduce INSURE-Dial, to our knowledge the first public benchmark for developing and assessing compliance-aware voice agents for phase-aware call auditing with span-based compliance verification. The corpus includes 50 de-identified, AI-initiated calls with live insurance representatives (mean 71 turns/call) and 1,000 synthetically generated calls that mirror the same workflow. All calls are annotated with a phase-structured JSON schema covering IVR navigation, patient identification, coverage status, medication checks (up to two drugs), and agent identification (CRN), and each phase is labeled for Information and Procedural compliance under explicit ask/answer logic. We define two novel evaluation tasks: (1) Phase Boundary Detection (span segmentation under phase-specific acceptance rules) and (2) Compliance Verification (IC/PC decisions given fixed spans). Per-phase scores are strong across small, low-latency baselines, but end-to-end reliability is constrained by span-boundary errors. On real calls, full-call exact segmentation is low, showing a gap between conversational fluency and audit-grade evidence.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [4] [Replication Study: Federated Text-Driven Prompt Generation for Vision-Language Models](https://arxiv.org/abs/2602.18439)
*Suraj Prasad,Anubha Pant*

Main category: cs.CV

> 本文复现了FedTPG方法，在多个数据集上验证了其在未见类别上的优越泛化能力以及联合训练提示生成器在不分享私有数据的情况下在不同视觉领域内的高性能。

<details>
  <summary>Details</summary>

**Motivation:** 适应联合学习场景中的视觉语言模型，特别是在泛化到未见类别时存在挑战的情况下。

**Method:** 文本驱动的提示生成网络在联合学习场景中动态创建基于类名的提示，以实现更好的跨类泛化。

**Result:** 复现研究在六个不同的视觉数据集上评估了预训练模型，结果显示与原论文报告的准确率的差异在0.2%以内，且对未见类别的泛化能力提高了1.43个百分点。

**Conclusion:** 复现研究确认了原论文的核心主张：文本驱动的提示生成相比静态提示学习方法可以更好地泛化到未见类别，以及联合训练提示生成器能够在不同的视觉领域内保持高性能而不分享私有数据。

**Abstract:** Vision-language models like CLIP have demonstrated remarkable zero-shot capabilities, yet their adaptation to federated learning scenarios presents significant challenges, particularly regarding generalization to unseen classes. The original FedTPG paper \cite{Qiu2024} addresses this limitation by introducing a text driven prompt generation network that dynamically creates prompts conditioned on class names, enabling better cross-class generalization in federated settings. In this work, we present a faithful replication study of FedTPG, evaluating the pre-trained model on six diverse vision datasets: Caltech101, Oxford Flowers, FGVC Aircraft, Oxford Pets, Food-101, and DTD. Our evaluation achieves results within 0.2\% of the original paper's reported accuracies, with an average accuracy of 74.58\% on seen (base) classes and 76.00\% on unseen (new) classes, demonstrating a +1.43 percentage point improvement in generalization. These results validate the original paper's core claims: (1) text-driven prompt generation enables superior generalization to unseen classes compared to static prompt learning methods, and (2) federated training of prompt generators maintains high performance across diverse visual domains without sharing private data. Our successful replication confirms the robustness and reproducibility of the FedTPG approach.

</details>


### [5] [A Patient-Specific Digital Twin for Adaptive Radiotherapy of Non-Small Cell Lung Cancer](https://arxiv.org/abs/2602.18496)
*Anvi Sud,Jialu Huang,Gregory R. Hart,Keshav Saxena,John Kim,Lauren Tressel,Jun Deng*

Main category: cs.CV

> 研究人员开发了名为COMPASS的系统，利用AI技术对非小细胞肺癌患者进行个性化的放射治疗监控，通过分析治疗过程中生成的高频率图像和剂量数据，预测毒性等级和个体剂量反应动力学。

<details>
  <summary>Details</summary>

**Motivation:** 当前的NTCP模型主要基于静态和群体数据，忽视了病程中独一无二的生物学变化。研究动机在于开发一种能捕捉这些动态变化，以提供更安全、适应性的放射治疗的新系统。

**Method:** COMPASS系统使用时间数字仿生架构结合GRU自动编码器和逻辑回归，处理PET、CT、剂量学和放射组学数据以预测毒性。

**Result:** 研究结果显示，在一个小队列的NSCLC患者中，利用密集的BED驱动表达，可以提前识别毒性发生的生物相关空间剂量纹理特征，并提供早期预警。

**Conclusion:** COMPASS验证了AI辅助的适应性放射治疗的概念，提供了一种连续更新、跟踪患者生物学反应的数字双胞胎模型。

**Abstract:** Radiotherapy continues to become more precise and data dense, with current treatment regimens generating high frequency imaging and dosimetry streams ideally suited for AI driven temporal modeling to characterize how normal tissues evolve with time. Each fraction in biologically guided radiotherapy(BGRT) treated non small cell lung cancer (NSCLC) patients records new metabolic, anatomical, and dose information. However, clinical decision making is largely informed by static, population based NTCP models which overlook the dynamic, unique biological trajectories encoded in sequential data. We developed COMPASS (Comprehensive Personalized Assessment System) for safe radiotherapy, functioning as a temporal digital twin architecture utilizing per fraction PET, CT, dosiomics, radiomics, and cumulative biologically equivalent dose (BED) kinetics to model normal tissue biology as a dynamic time series process. A GRU autoencoder was employed to learn organ specific latent trajectories, which were classified via logistic regression to predict eventual CTCAE grade 1 or higher toxicity. Eight NSCLC patients undergoing BGRT contributed to the 99 organ fraction observations covering 24 organ trajectories (spinal cord, heart, and esophagus). Despite the small cohort, intensive temporal phenotyping allowed for comprehensive analysis of individual dose response dynamics. Our findings revealed a viable AI driven early warning window, as increasing risk ratings occurred from several fractions before clinical toxicity. The dense BED driven representation revealed biologically relevant spatial dose texture characteristics that occur before toxicity and are averaged out with traditional volume based dosimetry. COMPASS establishes a proof of concept for AI enabled adaptive radiotherapy, where treatment is guided by a continually updated digital twin that tracks each patients evolving biological response.

</details>


### [6] [Scaling Ultrasound Volumetric Reconstruction via Mobile Augmented Reality](https://arxiv.org/abs/2602.18500)
*Kian Wei Ng,Yujia Gao,Deborah Khoo,Ying Zhen Tan,Chengzheng Mao,Haojie Cheng,Andrew Makmur,Kee Yuan Ngiam,Serene Goh,Eng Tat Khoo*

Main category: cs.CV

> MARVUS系统显著提升了2D-US在体积评估准确性与再现性方面的表现，通过提供增强现实可视化工具给临床医生使用。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服传统2D-US存在的体积评估高度不一致的缺点以及现有3D-US解决方案高昂的成本及欠佳的便携性。

**Method:** Structure

**Result:** {"tldr": "MARVUS, a resource-efficient system, significantly improves volumetric assessment accuracy and reproducibility of lesions in 2D-US by providing augmented reality visualizations to clinicians.", "motivation": "To address the limitations of conventional 2D-US, which exhibits high inter-user variability in volume estimation, and existing 3D-US solutions, which are expensive and lack portability.", "method": "Developed MARVUS, a system that works with conventional US systems and uses a foundation model to enhance cross-specialty generalization, while AR visualizations are provided to improve performance and usability.", "result": "In a user study, MARVUS demonstrated a substantial improvement in volume estimation accuracy (mean difference: 0.469 cm3) and reduced inter-user variability (mean difference: 0.417 cm3) among experienced clinicians.", "conclusion": "MARVUS has the potential to improve 2D-US volumetric assessment, enabling more accurate and reproducible cancer screening, diagnostics, and treatment planning, in a cost-effective manner.", "abstract": "Accurate volumetric characterization of lesions is essential for oncologic diagnosis, risk stratification, and treatment planning..."}

**Conclusion:** MARVUS可以提高2D-US体积评估的准确性，有利于癌症筛查、诊断和治疗规划，并以成本有效的方式进行。

**Abstract:** Accurate volumetric characterization of lesions is essential for oncologic diagnosis, risk stratification, and treatment planning. While imaging modalities such as Computed Tomography provide high-quality 3D data, 2D ultrasound (2D-US) remains the preferred first-line modality for breast and thyroid imaging due to cost, portability, and safety factors. However, volume estimates derived from 2D-US suffer from high inter-user variability even among experienced clinicians. Existing 3D ultrasound (3D-US) solutions use specialized probes or external tracking hardware, but such configurations increase costs and diminish portability, constraining widespread clinical use. To address these limitations, we present Mobile Augmented Reality Volumetric Ultrasound (MARVUS), a resource-efficient system designed to increase accessibility to accurate and reproducible volumetric assessment. MARVUS is interoperable with conventional ultrasound (US) systems, using a foundation model to enhance cross-specialty generalization while minimizing hardware requirements relative to current 3D-US solutions. In a user study involving experienced clinicians performing measurements on breast phantoms, MARVUS yielded a substantial improvement in volume estimation accuracy (mean difference: 0.469 cm3) with reduced inter-user variability (mean difference: 0.417 cm3). Additionally, we prove that augmented reality (AR) visualizations enhance objective performance metrics and clinician-reported usability. Collectively, our findings suggests that MARVUS can enhance US-based cancer screening, diagnostic workflows, and treatment planning in a scalable, cost-conscious, and resource-efficient manner. Usage video demonstration available (https://youtu.be/m4llYcZpqmM).

</details>


### [7] [Mitigating Shortcut Learning via Feature Disentanglement in Medical Imaging: A Benchmark Study](https://arxiv.org/abs/2602.18502)
*Sarah Müller,Philipp Berens*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Although deep learning models in medical imaging often achieve excellent classification performance, they can rely on shortcut learning, exploiting spurious correlations or confounding factors that are not causally related to the target task. This poses risks in clinical settings, where models must generalize across institutions, populations, and acquisition conditions. Feature disentanglement is a promising approach to mitigate shortcut learning by separating task-relevant information from confounder-related features in latent representations. In this study, we systematically evaluated feature disentanglement methods for mitigating shortcuts in medical imaging, including adversarial learning and latent space splitting based on dependence minimization. We assessed classification performance and disentanglement quality using latent space analyses across one artificial and two medical datasets with natural and synthetic confounders. We also examined robustness under varying levels of confounding and compared computational efficiency across methods. We found that shortcut mitigation methods improved classification performance under strong spurious correlations during training. Latent space analyses revealed differences in representation quality not captured by classification metrics, highlighting the strengths and limitations of each method. Model reliance on shortcuts depended on the degree of confounding in the training data. The best-performing models combine data-centric rebalancing with model-centric disentanglement, achieving stronger and more robust shortcut mitigation than rebalancing alone while maintaining similar computational efficiency.

</details>


### [8] [A Computer Vision Framework for Multi-Class Detection and Tracking in Soccer Broadcast Footage](https://arxiv.org/abs/2602.18504)
*Daniel Tshiani*

Main category: cs.CV

> A cost-effective computer vision pipeline is developed to track players and officials from broadcast footage, democratizing data access for smaller soccer teams.

<details>
  <summary>Details</summary>

**Motivation:** To reduce the competitive data advantage held by well-funded clubs with access to expensive multi-camera setups or GPS tracking systems by creating a cost-effective single-camera computer vision system.

**Method:** This paper develops an end-to-end system using a YOLO object detector combined with the ByteTrack tracking algorithm to extract detailed data from standard broadcast footage, specifically focusing on player, referee, goalkeeper, and ball tracking throughout a soccer match.

**Result:** The system shows high performance with strong precision, recall, and mAP50 scores for detecting and tracking players and officials, although ball detection remains challenging.

**Conclusion:** The system demonstrates that AI can extract meaningful player-level spatial information from a single broadcast camera, enabling lower-budget teams access to data-driven analysis methods previously only available to professional teams.

**Abstract:** Clubs with access to expensive multi-camera setups or GPS tracking systems gain a competitive advantage through detailed data, whereas lower-budget teams are often unable to collect similar information. This paper examines whether such data can instead be extracted directly from standard broadcast footage using a single-camera computer vision pipeline. This project develops an end-to-end system that combines a YOLO object detector with the ByteTrack tracking algorithm to identify and track players, referees, goalkeepers, and the ball throughout a match. Experimental results show that the pipeline achieves high performance in detecting and tracking players and officials, with strong precision, recall, and mAP50 scores, while ball detection remains the primary challenge. Despite this limitation, our findings demonstrate that AI can extract meaningful player-level spatial information from a single broadcast camera. By reducing reliance on specialized hardware, the proposed approach enables colleges, academies, and amateur clubs to adopt scalable, data-driven analysis methods previously accessible only to professional teams, highlighting the potential for affordable computer vision-based soccer analytics.

</details>


### [9] [Suppression or Deletion: A Restoration-Based Representation-Level Analysis of Machine Unlearning](https://arxiv.org/abs/2602.18505)
*Yurim Jang,Jaeung Lee,Dohyun Kim,Jaemin Jo,Simon S. Woo*

Main category: cs.CV

> 针对当前遗忘方法评估的局限，我们提出了一种新的基于恢复分析的框架，对遗忘方法进行了评估，发现许多方法只在决策边界层抑制信息，而非真正的删除，并提出了新的评估指导方针。

<details>
  <summary>Details</summary>

**Motivation:** 当前的遗忘方法评估依赖于输出基线度量，这些度量无法验证信息是否已完全删除，还是仅仅在表示层进行了抑制。由于抑制不能满足真正的遗忘要求，我们提出了新的评估标准。

**Method:** 我们提出了一种基于恢复分析的框架，使用稀疏自编码器识别中间层中的特定类专家特征，并通过推理时的引导定量区分抑制和删除。

**Result:** 我们可以发现，大多数方法对于遗忘信息的恢复率较高，表明它们只在决策边界层抑制信息，而保留了中间表示中的语义特征。甚至从预训练检查点重新训练也没有移除继承的稳健语义特征。

**Conclusion:** 这些发现表明，在输出基线度量中被忽视的表示层保留提出了显著的风险，强调了需要新的遗忘评估标准。我们建议在预训练模型隐私关键应用中优先验证表示层。

**Abstract:** As pretrained models are increasingly shared on the web, ensuring that models can forget or delete sensitive, copyrighted, or private information upon request has become crucial. Machine unlearning has been proposed to address this challenge. However, current evaluations for unlearning methods rely on output-based metrics, which cannot verify whether information is completely deleted or merely suppressed at the representation level, where suppression is insufficient for true unlearning. To address this gap, we propose a novel restoration-based analysis framework that uses Sparse Autoencoders to identify class-specific expert features in intermediate layers and applies inference-time steering to quantitatively distinguish between suppression and deletion. Applying our framework to 12 major unlearning methods in image classification tasks, we find that most methods achieve high restoration rates of unlearned information, indicating that they only suppress information at the decision-boundary level, while preserving semantic features in intermediate representations. Notably, even retraining from pretrained checkpoints shows high restoration, revealing that robust semantic features inherited from pretraining are not removed by retraining. These results demonstrate that representation-level retention poses significant risks overlooked by output-based metrics, highlighting the need for new unlearning evaluation criteria. We propose new evaluation guidelines that prioritize representation-level verification, especially for privacy-critical applications in the era of pre-trained models.

</details>


### [10] [Depth from Defocus via Direct Optimization](https://arxiv.org/abs/2602.18509)
*Holly Jackson,Caleb Adams,Ignacio Lopez-Francos,Benjamin Recht*

Main category: cs.CV

> 本文提出了一种基于当代优化方法的全局优化方法来解决从前聚焦图像恢复深度的问题，并在基准数据集上获得了良好的效果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于光学物理的模糊前向模型是合理的，但从前聚焦图像集合恢复深度仍然是一个具有计算挑战性的优化问题。本文旨在证明通过当代优化方法和合理的计算资源，全局优化方法是可行的。

**Method:** 本文提出的方法是基于交替最小化的全局优化方法来解决从散焦图恢复深度的问题。方法主要包括：当深度图固定时，前向模型对于全聚焦图像来说是线性的；当全聚焦图像固定时，可以通过并行网格搜索独立地计算每个像素的深度。

**Result:** 实验结果表明，与当前的深度学习方法相比，该方法可以有效地在更高的分辨率下解决从散焦恢复深度的问题。

**Conclusion:** 最终得出结论，通过交替使用的凸优化和平行网格搜索能有效地解决高分辨率的从散焦恢复深度问题，并且在合成和真实的散焦模糊数据集上展示了良好的结果。

**Abstract:** Though there exists a reasonable forward model for blur based on optical physics, recovering depth from a collection of defocused images remains a computationally challenging optimization problem. In this paper, we show that with contemporary optimization methods and reasonable computing resources, a global optimization approach to depth from defocus is feasible. Our approach rests on alternating minimization. When holding the depth map fixed, the forward model is linear with respect to the all-in-focus image. When holding the all-in-focus image fixed, the depth at each pixel can be computed independently, enabling embarrassingly parallel computation. We show that alternating between convex optimization and parallel grid search can effectively solve the depth-from-defocus problem at higher resolutions than current deep learning methods. We demonstrate our approach on benchmark datasets with synthetic and real defocus blur and show promising results compared to prior approaches. Our code is available at github.com/hollyjackson/dfd.

</details>
