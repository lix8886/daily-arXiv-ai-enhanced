{"id": "2602.16802", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16802", "abs": "https://arxiv.org/abs/2602.16802", "authors": ["Kejian Shi", "Yixin Liu", "Peifeng Wang", "Alexander R. Fabbri", "Shafiq Joty", "Arman Cohan"], "title": "References Improve LLM Alignment in Non-Verifiable Domains", "comment": "ICLR 2026 Camera Ready", "summary": "While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft \"verifiers\". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show that a reference-guided approach substantially improves the accuracy of less capable LLM-judges using references from frontier models; stronger LLM-judges can also be enhanced by high-quality (i.e., human-written) references. Building on these improved judges, we demonstrate the utility of high-quality references in alignment tuning, where LLMs guided with references are used as judges to self-improve. We show that reference-guided self-improvement yields clear gains over both direct SFT on reference outputs and self-improvement with reference-free judges, achieving performance comparable to training with ArmoRM, a strong finetuned reward model. Specifically, our method achieves 73.1% and 58.7% on AlpacaEval and Arena-Hard with Llama-3-8B-Instruct, and 70.0% and 74.1% with Qwen2.5-7B, corresponding to average absolute gains of +20.2 / +17.1 points over SFT distillation and +5.3 / +3.6 points over reference-free self-improvement on AlpacaEval / Arena-Hard. These results highlight the potential of using reference-guided LLM-evaluators to enable effective LLM post-training in non-verifiable domains.", "AI": {"tldr": "研究通过使用参考指导的LLM评估器来弥补RLVR在非可验证领域（如LLM对齐）中的应用空白，实验表明这种方法可以显著提升评估器的准确性，并且在LLM自改进中也能取得优于直接SFT和无参照自改进的效果。", "motivation": "RLVR虽在可验证任务中表现出色，但无法直接应用于像LLM对齐这样的非可验证领域，因为这类领域没有明确的验证器。本文旨在探索使用参考指导的LLM评估器能否充当软验证器，弥补这一不足。", "method": "设计了使用参考输出增强LLM评估器的评估协议。通过使用前沿模型的参考输出显著提高较弱模型评估器的准确性；同时，高质量参考（如人工编写的）也能改善强模型评估器的性能。利用这些改进后的评估器，展示了高质量参考在对齐调优中的优势，即使用带有参考的LLM评估器进行自改进。", "result": "含有参考信息的自改进方法在使用Llama-3-8B-Instruct和Qwen2.5-7B模型时，分别在AlpacaEval和Arena-Hard上显著优于直接SFT与无参照自改进，达到了与经过强微调奖励模型ArmoRM训练接近的性能。具体而言，改进方法在AlpacaEval和Arena-Hard上的得分分别为73.1%/58.7%和70.0%/74.1%，对比SFT蒸馏分别提高了+20.2/+17.1个百分点，对比无参照自改进分别提高了+5.3/+3.6个百分点。", "conclusion": "实验证明，使用参考指导的LLM评估器能够在非可验证领域中实现有前景的LLM后训练，特别是在LLM对齐任务中，这种技术显著增强了模型的性能。"}}
{"id": "2602.16811", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16811", "abs": "https://arxiv.org/abs/2602.16811", "authors": ["Charalampos Mastrokostas", "Nikolaos Giarelis", "Nikos Karacapilidis"], "title": "Evaluating Monolingual and Multilingual Large Language Models for Greek Question Answering: The DemosQA Benchmark", "comment": null, "summary": "Recent advancements in Natural Language Processing and Deep Learning have enabled the development of Large Language Models (LLMs), which have significantly advanced the state-of-the-art across a wide range of tasks, including Question Answering (QA). Despite these advancements, research on LLMs has primarily targeted high-resourced languages (e.g., English), and only recently has attention shifted toward multilingual models. However, these models demonstrate a training data bias towards a small number of popular languages or rely on transfer learning from high- to under-resourced languages; this may lead to a misrepresentation of social, cultural, and historical aspects. To address this challenge, monolingual LLMs have been developed for under-resourced languages; however, their effectiveness remains less studied when compared to multilingual counterparts on language-specific tasks. In this study, we address this research gap in Greek QA by contributing: (i) DemosQA, a novel dataset, which is constructed using social media user questions and community-reviewed answers to better capture the Greek social and cultural zeitgeist; (ii) a memory-efficient LLM evaluation framework adaptable to diverse QA datasets and languages; and (iii) an extensive evaluation of 11 monolingual and multilingual LLMs on 6 human-curated Greek QA datasets using 3 different prompting strategies. We release our code and data to facilitate reproducibility.", "AI": {"tldr": "研究针对希腊语问答问题，创建了新的数据集DemosQA，并提出了高效评估框架，评估了11个单语和多语言模型，填补了该领域的空白。", "motivation": "尽管大语言模型在多种任务上取得了显著的进步，但它们的研究主要集中在资源丰富的语言上，而忽视了资源贫乏的语言，并且现有的多语言模型存在训练数据偏差或依赖于从资源丰富语言到资源匮乏语言的迁移学习问题。因此，研究关注单语大语言模型在资源匮乏语言上特定语言任务的有效性，并专注于希腊语的问答研究。", "method": "研究通过创建DemosQA数据集来解决针对希腊语的问答问题，该数据集利用社交媒体上的用户问题和社区审核的回答，旨在更好地捕捉希腊的社会和文化特征。此外，研究还提出了一种适用于多种问答数据集和语言的记忆高效的大语言模型评估框架，并且对11个单语和多语言大语言模型在6个人工策划的希腊语问答数据集上使用了3种不同的提示策略进行了广泛的评估。", "result": "研究贡献了针对希腊语问答的新数据集DemosQA，提出了适应多种问答数据集和语言的记忆高效评估框架，并对11个单语和多语言大语言模型进行了广泛的评估。", "conclusion": "通过此次研究，填补了在希腊语问答上的研究空白，并为未来单语大语言模型在资源匮乏语言上的有效性研究提供了新的方向和数据支持。"}}
{"id": "2602.16813", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16813", "abs": "https://arxiv.org/abs/2602.16813", "authors": ["Chanhyuk Lee", "Jaehoon Yoo", "Manan Agarwal", "Sheel Shah", "Jerry Huang", "Aditi Raghunathan", "Seunghoon Hong", "Nicholas M. Boffi", "Jinwoo Kim"], "title": "One-step Language Modeling via Continuous Denoising", "comment": "39 pages, 17 figures", "summary": "Language models based on discrete diffusion have attracted widespread interest for their potential to provide faster generation than autoregressive models. In practice, however, they exhibit a sharp degradation of sample quality in the few-step regime, failing to realize this promise. Here we show that language models leveraging flow-based continuous denoising can outperform discrete diffusion in both quality and speed. By revisiting the fundamentals of flows over discrete modalities, we build a flow-based language model (FLM) that performs Euclidean denoising over one-hot token encodings. We show that the model can be trained by predicting the clean data via a cross entropy objective, where we introduce a simple time reparameterization that greatly improves training stability and generation quality. By distilling FLM into its associated flow map, we obtain a distilled flow map language model (FMLM) capable of few-step generation. On the LM1B and OWT language datasets, FLM attains generation quality matching state-of-the-art discrete diffusion models. With FMLM, our approach outperforms recent few-step language models across the board, with one-step generation exceeding their 8-step quality. Our work calls into question the widely held hypothesis that discrete diffusion processes are necessary for generative modeling over discrete modalities, and paves the way toward accelerated flow-based language modeling at scale. Code is available at https://github.com/david3684/flm.", "AI": {"tldr": "基于流的连续去噪模型FLM在生成质量和速度上超越了离散扩散模型，在一步生成中取得了超过8步模型的质量。", "motivation": "解决基于离散扩散的语言模型在低步数生成时质量下降的问题，探索一种能同时提高生成质量和速度的方法。", "method": "通过构建基于流的语言模型 (FLM)，该模型在one-hot Token编码上进行欧几里得去噪。模型通过交叉熵目标训练来预测干净数据，并引入简单的时间重参数化来改进训练稳定性和生成质量。进一步，通过将其蒸馏为对应的流映射模型（FMLM）以实现快速生成。", "result": "本文提出了基于流的连续去噪语言模型（FLM），该模型通过在one-hot编码的令牌上进行欧几里得去噪，能够在质量和速度上超过离散扩散模型。通过简单的时间重参数化，改进了训练稳定性和生成质量，并通过蒸馏得到的流映射语言模型（FMLM）实现了快速生成。实验结果显示，FLM在LM1B和OWT数据集上的生成质量可与最先进的离散扩散模型匹敌。FMLM在一步生成中超过了其他多步模型的质量。这一工作质疑了离散扩散过程在离散模态生成建模中必要性的假设，并为大规模加速的流式语言模型奠定了基础。", "conclusion": "基于流的连续去噪语言模型（FLM）不仅在生成质量上可与最先进的离散扩散模型相媲美，而且通过蒸馏的流映射模型（FMLM）在一步生成中能够超过其他多步模型的质量。这表明，离散扩散过程中存在的一些假设可以通过基于流的方法来进行优化或替换。"}}
{"id": "2602.16836", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16836", "abs": "https://arxiv.org/abs/2602.16836", "authors": ["Zhengda Mo", "Zhiyu Quan", "Eli O'Donohue", "Kaiwen Zhong"], "title": "Claim Automation using Large Language Model", "comment": "46 pages, 12 figures. Code and data processing pipeline described", "summary": "While Large Language Models (LLMs) have achieved strong performance on general-purpose language tasks, their deployment in regulated and data-sensitive domains, including insurance, remains limited. Leveraging millions of historical warranty claims, we propose a locally deployed governance-aware language modeling component that generates structured corrective-action recommendations from unstructured claim narratives. We fine-tune pretrained LLMs using Low-Rank Adaptation (LoRA), scoping the model to an initial decision module within the claim processing pipeline to speed up claim adjusters' decisions. We assess this module using a multi-dimensional evaluation framework that combines automated semantic similarity metrics with human evaluation, enabling a rigorous examination of both practical utility and predictive accuracy. Our results show that domain-specific fine-tuning substantially outperforms commercial general-purpose and prompt-based LLMs, with approximately 80% of the evaluated cases achieving near-identical matches to ground-truth corrective actions. Overall, this study provides both theoretical and empirical evidence to prove that domain-adaptive fine-tuning can align model output distributions more closely with real-world operational data, demonstrating its promise as a reliable and governable building block for insurance applications.", "AI": {"tldr": "本研究通过低秩适配技术对大型语言模型进行特定领域的微调，实现了从非结构化保险索赔叙述中快速生成结构化补救措施推荐的目标。这种方法显示出了在受监管领域的巨大潜力。", "motivation": "尽管大型语言模型在通用语言任务上表现良好，但它们在受监管和数据敏感领域的部署仍然有限。本研究旨在解决保险领域的问题，特别是在处理索赔上，通过提出一个更具针对性和更快速决策的模型来提升效率和合规性。", "method": "通过使用数百万的历史保修索赔数据，我们提出了一种本地部署的合规性语言模型组件，该组件能够从非结构化的索赔叙述中生成结构化的补救措施推荐。我们使用低秩适配（LoRA）技术对预先训练好的大型语言模型进行微调，将其应用于索赔处理管道中的初始决策模块，以加快索赔调整人员的决策过程。", "result": "实验评估中，我们的模型在80%的案例中实现了与实际补救措施的高度匹配，并且在实用性和预测准确性方面都优于商业上使用的通用和基于提示的大型语言模型。", "conclusion": "该研究表明，通过针对特定领域的微调，可以显著改善模型输出与实际运营数据的对齐，从而在保险应用程序中实现可靠的、可治理的模块构建。"}}
{"id": "2602.16713", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16713", "abs": "https://arxiv.org/abs/2602.16713", "authors": ["Shuo Wang", "Shuo Wang", "Xin Nie", "Yasutaka Narazaki", "Thomas Matiki", "Billie F. Spencer"], "title": "Three-dimensional Damage Visualization of Civil Structures via Gaussian Splatting-enabled Digital Twins", "comment": null, "summary": "Recent advancements in civil infrastructure inspections underscore the need for precise three-dimensional (3D) damage visualization on digital twins, transcending traditional 2D image-based damage identifications. Compared to conventional photogrammetric 3D reconstruction techniques, modern approaches such as Neural Radiance Field (NeRF) and Gaussian Splatting (GS) excel in scene representation, rendering quality, and handling featureless regions. Among them, GS stands out for its efficiency, leveraging discrete anisotropic 3D Gaussians to represent radiance fields, unlike NeRF's continuous implicit model. This study introduces a GS-enabled digital twin method tailored for effective 3D damage visualization. The method's key contributions include: 1) utilizing GS-based 3D reconstruction to visualize 2D damage segmentation results while reducing segmentation errors; 2) developing a multi-scale reconstruction strategy to balance efficiency and damage detail; 3) enabling digital twin updates as damage evolves over time. Demonstrated on an open-source synthetic dataset for post-earthquake inspections, the proposed approach offers a promising solution for comprehensive 3D damage visualization in civil infrastructure digital twins.", "AI": {"tldr": "This paper presents a GS-based method for 3D damage visualization on digital twins, which improves upon current 2D and 3D visualization techniques by offering precision, efficiency in reconstruction, and the ability to continually update the digital twin model as damage evolves.", "motivation": "The need for precise 3D damage visualization on digital twins for civil infrastructure inspections has increased, moving beyond traditional 2D damage identification methods. This paper aims to address the limitations of conventional techniques like photo-grammetric methods and improve upon modern techniques such as NeRF and GS.", "method": "The study introduces a Gaussian Splatting (GS) method for 3D damage visualization on digital twins of civil infrastructure. It uses GS for 3D reconstruction to represent 2D damage segmentation results more accurately, adopting a multi-scale strategy for balancing efficiency and damage detail, and allows for updating the digital twins as damage progresses.", "result": "The proposed method demonstrated effectiveness in 3D damage visualization using an open-source synthetic dataset for post-earthquake inspections, suggesting a promising approach for 3D damage visualization in civil infrastructure digital twins.", "conclusion": "The study concludes that using GS for 3D reconstruction in digital twins of civil infrastructure provides a more efficient and accurate method for 3D damage visualization compared to existing methods, with potential for real-world applications in infrastructure inspection."}}
{"id": "2602.16843", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16843", "abs": "https://arxiv.org/abs/2602.16843", "authors": ["Ahmed Rafid", "Rumman Adib", "Fariya Ahmed", "Ajwad Abrar", "Mohammed Saidul Islam"], "title": "BanglaSummEval: Reference-Free Factual Consistency Evaluation for Bangla Summarization", "comment": "Accepted in 2nd LoResLM at EACL 2026", "summary": "Evaluating factual consistency is essential for reliable text summarization, particularly in high-stakes domains such as healthcare and news. However, most existing evaluation metrics overlook Bangla, a widely spoken yet under-resourced language, and often depend on reference summaries. We introduce BanglaSummEval, a reference-free, question-answering-based framework for evaluating factual consistency in Bangla summarization. The proposed method assesses both factual accuracy and content coverage through automatically generated questions and answers derived from the source document and the summary. A single multilingual instruction-tuned language model handles question generation, question answering, candidate answer extraction, and question importance weighting. This unified design reduces system complexity and computational cost. To capture semantic consistency beyond surface-level overlap, we use BERTScore-Recall for answer comparison. We validate BanglaSummEval on 300 human-written summaries from educational and medical domains, demonstrating strong correlation with expert human judgments (Pearson's $r = 0.694$, Spearman's $ρ= 0.763$). By providing interpretable, step-wise diagnostics alongside reliable evaluation scores, BanglaSummEval offers a practical and transparent solution for factual consistency evaluation in low-resource language settings.", "AI": {"tldr": "BanglaSummEval是一种无参考、基于问答的框架，用于评估孟加拉语总结中的事实一致性，它使用模型自动生成问题和答案，并通过BERTScore-Recall进行语义一致性评估，验证结果与专家判断高度相关。", "motivation": "评价事实一致性对于可靠的文本摘要至关重要，尤其是在医疗保健和新闻等高风险领域。然而，大多数现有的评估指标忽略了孟加拉语这种使用广泛但资源有限的语言，并且经常依赖参考摘要。", "method": "我们引入了BanglaSummEval，这是一种无参考的、基于问答的框架，用于评估孟加拉语摘要中的事实一致性。该方法通过源文档和摘要自动生成的问题和答案来评估事实准确性和内容覆盖。单一的多语言指令调整的语言模型负责问题生成、问题回答、候选答案提取以及问题重要性加权。为了捕捉语义一致性，使用BERTScore-Recall进行答案比较。", "result": "我们在教育和医疗领域的300个人写的摘要上验证了BanglaSummEval，展示出与专家人类判断的高度相关性（皮尔逊r=0.694，斯皮尔曼ρ=0.763）。", "conclusion": "BanglaSummEval提供了一个实用和透明的解决方案，可以在资源有限的语言设置中评估事实一致性。"}}
{"id": "2602.16856", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16856", "abs": "https://arxiv.org/abs/2602.16856", "authors": ["Boda Lin", "Yongjie Zhu", "Wenyu Qin", "Meng Wang", "Pengfei Wan"], "title": "Analytic Score Optimization for Multi Dimension Video Quality Assessment", "comment": "18 pages", "summary": "Video Quality Assessment (VQA) is evolving beyond single-number mean opinion score toward richer, multi-faceted evaluations of video content. In this paper, we present a large-scale multi-dimensional VQA dataset UltraVQA that encompasses diverse User-Generated Content~(UGC) annotated across five key quality dimensions: Motion Quality, Motion Amplitude, Aesthetic Quality, Content Quality, and Clarity Quality. Each video in our dataset is scored by over 3 human raters on these dimensions, with fine-grained sub-attribute labels, and accompanied by an explanatory rationale generated by GPT based on the collective human judgments. To better leverage these rich annotations and improve discrete quality score assessment, we introduce Analytic Score Optimization (ASO), a theoretically grounded post-training objective derived for multi-dimensional VQA. By reframing quality assessment as a regularized decision-making process, we obtain a closed-form solution that naturally captures the ordinal nature of human ratings, ensuring alignment with human ranking preferences. In experiments, our method outperforms most baselines including closed-source APIs and open-source models, while also reducing mean absolute error (MAE) in quality prediction. Our work highlights the importance of multi-dimensional, interpretable annotations and reinforcement-based alignment in advancing video quality assessment.", "AI": {"tldr": "本文提出UltraVQA数据集和ASO方法，推动视频质量评估的多维度发展，并展示了其在质量预测中的优越性。", "motivation": "推动视频质量评估从单一的平均意见分数向更丰富、多方面的视频内容评估发展，突出多维度、可解释注释以及基于强化的排列对视频质量评估的推动作用。", "method": "我们提出了一个大规模多维度的视频质量评估数据集UltraVQA，该数据集涵盖了五种关键质量维度：运动质量、运动幅度、审美质量、内容质量和清晰度质量，并在此基础上引入了分析评分优化（ASO）方法，以更好地利用这些丰富的注释并改进离散质量评分评估。", "result": "实验结果表明，我们的方法在质量预测中减少了平均绝对误差（MAE），并且在大多数基线方法中表现更好，包括闭源API和开源模型。", "conclusion": "本研究展示了多维度、可解释注释和基于强化的排列对推进视频质量评估的重要性。"}}
{"id": "2602.16852", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16852", "abs": "https://arxiv.org/abs/2602.16852", "authors": ["Minh Duc Bui", "Manuel Mager", "Peter Herbert Kann", "Katharina von der Wense"], "title": "Meenz bleibt Meenz, but Large Language Models Do Not Speak Its Dialect", "comment": "Accepted at LREC 2026", "summary": "Meenzerisch, the dialect spoken in the German city of Mainz, is also the traditional language of the Mainz carnival, a yearly celebration well known throughout Germany. However, Meenzerisch is on the verge of dying out-a fate it shares with many other German dialects. Natural language processing (NLP) has the potential to help with the preservation and revival efforts of languages and dialects. However, so far no NLP research has looked at Meenzerisch. This work presents the first research in the field of NLP that is explicitly focused on the dialect of Mainz. We introduce a digital dictionary-an NLP-ready dataset derived from an existing resource (Schramm, 1966)-to support researchers in modeling and benchmarking the language. It contains 2,351 words in the dialect paired with their meanings described in Standard German. We then use this dataset to answer the following research questions: (1) Can state-of-the-art large language models (LLMs) generate definitions for dialect words? (2) Can LLMs generate words in Meenzerisch, given their definitions? Our experiments show that LLMs can do neither: the best model for definitions reaches only 6.27% accuracy and the best word generation model's accuracy is 1.51%. We then conduct two additional experiments in order to see if accuracy is improved by few-shot learning and by extracting rules from the training set, which are then passed to the LLM. While those approaches are able to improve the results, accuracy remains below 10%. This highlights that additional resources and an intensification of research efforts focused on German dialects are desperately needed.", "AI": {"tldr": "本研究建立了针对美因茨方言梅恩左里许的数字词典，并探讨了大型语言模型在生成该方言词汇定义及根据定义生成词汇的能力方面表现不佳的问题。实验结果显示，即使应用了少量样本学习和规则提取方法，准确性仍低于10%。强调需要更多的资源和支持来加强针对德国方言的研究工作。", "motivation": "梅恩左里许是德国美因茨市的一种地方方言，也是美因茨狂欢节的传统语言，而梅恩左里许正面临消失的风险，与其他许多德国方言类似。研究的动机在于利用NLP技术来帮助语言和方言的保存与复兴，此前尚无NLP研究关注梅恩左里许。", "method": "本研究首次将自然语言处理（NLP）应用于美因茨方言梅恩左里许的研究。建立了基于现有资源的数字词典（Schramm, 1966），包含2351个方言词汇及其标准德语解释，用以支持语言建模和基准测试。研究使用该数据集探讨了两个问题：大型语言模型（LLMs）能否生成方言词汇的定义？LLMs能否根据其定义生成梅恩左里许词汇？", "result": "实验结果显示，大型语言模型在生成美因茨方言定义任务上最佳准确率为6.27%，在生成词汇任务上为1.51%。即使应用少量样本学习及规则提取法，准确率仍低于10%。", "conclusion": "研究实验表明，尽管少量样本学习和规则提取方法能一定程度提升准确率，但大型语言模型在生成梅恩左里许词汇定义和根据定义生成词汇上的表现不佳，准确率均低于10%。这突显了需要更多资源和聚焦于德国方言的研究投入的迫切性。"}}
{"id": "2602.16872", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16872", "abs": "https://arxiv.org/abs/2602.16872", "authors": ["Sean Man", "Roy Ganz", "Roi Ronen", "Shahar Tsiper", "Shai Mazor", "Niv Nayman"], "title": "DODO: Discrete OCR Diffusion Models", "comment": null, "summary": "Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual understanding. While modern Vision-Language Models (VLM) have achieved high accuracy in this domain, they predominantly rely on autoregressive decoding, which becomes computationally expensive and slow for long documents as it requires a sequential forward pass for every generated token. We identify a key opportunity to overcome this bottleneck: unlike open-ended generation, OCR is a highly deterministic task where the visual input strictly dictates a unique output sequence, theoretically enabling efficient, parallel decoding via diffusion models. However, we show that existing masked diffusion models fail to harness this potential; those introduce structural instabilities that are benign in flexible tasks, like captioning, but catastrophic for the rigid, exact-match requirements of OCR. To bridge this gap, we introduce DODO, the first VLM to utilize block discrete diffusion and unlock its speedup potential for OCR. By decomposing generation into blocks, DODO mitigates the synchronization errors of global diffusion. Empirically, our method achieves near state-of-the-art accuracy while enabling up to 3x faster inference compared to autoregressive baselines.", "AI": {"tldr": "本文提出了DODO模型，该模型使用块离散扩散来提高OCR任务的解码速度，同时保持近似最先进水平的准确性。实验表明，DODO相比自回归基准模型提高了大约3倍的推理速度。", "motivation": "尽管现代视觉语言模型在OCR任务中取得了高精度，但它们主要依赖于计算密集型的自回归解码，这在处理长文档时效率低下。本文旨在通过利用OCR任务的确定性来提高解码效率。", "method": "介绍了一种名为DODO的新视觉语言模型，该模型利用了块离散扩散方法来克服现有遮罩扩散模型在光学字符识别（OCR）任务中结构不稳定的问题。通过将生成分解为区块，DODO可以减少全局扩散中的同步错误。", "result": "实验结果表明，DODO在实现几乎最先进的精度的同时，能够将推理时间加速到自回归基线模型的3倍。", "conclusion": "研究展示了DODO模型在光学字符识别任务中的潜力，实现了高效准确的文本生成，为解决自回归方法的计算瓶颈提供了一种新的解决方案。"}}
{"id": "2602.16922", "categories": ["cs.OH"], "pdf": "https://arxiv.org/pdf/2602.16922", "abs": "https://arxiv.org/abs/2602.16922", "authors": ["Md. Ismiel Hossen Abir"], "title": "A Conceptual Hybrid Framework for Post-Quantum Security: Integrating BB84 QKD, AES, and Bio-inspired Mechanisms", "comment": null, "summary": "Quantum computing is a significant risk to classical cryptographic, especially RSA, which depends on the difficulty of factoring large numbers. Classical factorization methods, such as Trial Division and Pollard's Rho, are inefficient for large keys, while Shor's quantum algorithm can break RSA efficiently in polynomial time. This research studies RSA's vulnerabilities under both classical and quantum attacks and designs a hybrid security framework to ensure data protection in the post-quantum era. The conceptual framework combines AES encryption for classical security, BB84 Quantum Key Distribution (QKD) for secure key exchange with eavesdropping detection, quantum state comparison for lightweight authentication, and a bio-inspired immune system for adaptive threat detection. RSA is vulnerable to Shor's algorithm, BB84 achieves full key agreement in ideal conditions, and it detects eavesdropping with high accuracy. The conceptual model includes both classical and quantum security methods, providing a scalable and adaptive solution for Post-Quantum encryption data protection. This work primarily proposes a conceptual framework. Detailed implementation, security proofs, and extensive experimental validation are considered future work.", "AI": {"tldr": "本研究探讨了RSA在古典和量子攻击下的脆弱性，并提出了一种结合AES、BB84量子密钥分发、量子态对比以及生物启发的免疫系统的混合安全框架，以应对未来的后量子安全挑战。", "motivation": "量子计算，特别是Shor的量子算法，对基于大数分解困难的RSA加密构成了重大风险，因此需要设计新的安全框架以增强数据保护。", "method": "研究分析了RSA在古典和量子攻击下的脆弱性，并设计了一个混合安全框架以确保后量子时代的数据保护。该框架结合了AES加密、BB84量子密钥分发（QKD）、量子态对比和生物启发的免疫系统。", "result": "研究成果为后量子时代的加密数据保护提供了一个结合了古典和量子安全方法的概念模型。", "conclusion": "该论文提出的安全框架能够提供可扩展和自适应的解决方案，但详细实施、安全性证明和广泛的验证实验仍需未来继续研究。"}}
{"id": "2602.16915", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16915", "abs": "https://arxiv.org/abs/2602.16915", "authors": ["Zeyu Ren", "Xiang Li", "Yiran Wang", "Zeyu Zhang", "Hao Tang"], "title": "StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation", "comment": null, "summary": "Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2.", "AI": {"tldr": "StereoAdapter-2通过使用新型ConvSS2D操作符，解决了在水下三维感知中的长视差和无纹理区域问题，实现了在无样本情况下的最佳性能。", "motivation": "论文旨在解决水下立体深度估计中存在的由于波长相关光衰减、散射和折射导致的严重领域迁移问题，特别是在大视差和无纹理区域表现不佳的问题。", "method": "该论文提出了StereoAdapter-2，将传统的ConvGRU更新器替换为基于选择性状态空间模型的新型ConvSS2D操作符，采用四方向扫描策略，该策略与视差几何自然对齐，能够在单次更新步骤中高效传播长范围空间，同时保持线性计算复杂度。", "result": "结合动态的LoRA调整，该框架在水下基准上取得了显著进步，如在TartanAir-UW上提高了17%的性能，在SQUID上提高了7.2%的性能。", "conclusion": "StereoAdapter-2在大规模合成水下立体数据集UW-StereoDepth-80K上取得了突破性的无样本表现，并通过在BlueROV2平台上的真实世界验证了其方法的鲁棒性。"}}
{"id": "2602.16938", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16938", "abs": "https://arxiv.org/abs/2602.16938", "authors": ["Ofer Meshi", "Krisztian Balog", "Sally Goldman", "Avi Caciularu", "Guy Tennenholtz", "Jihwan Jeong", "Amir Globerson", "Craig Boutilier"], "title": "ConvApparel: A Benchmark Dataset and Validation Framework for User Simulators in Conversational Recommenders", "comment": "EACL 2026", "summary": "The promise of LLM-based user simulators to improve conversational AI is hindered by a critical \"realism gap,\" leading to systems that are optimized for simulated interactions, but may fail to perform well in the real world. We introduce ConvApparel, a new dataset of human-AI conversations designed to address this gap. Its unique dual-agent data collection protocol -- using both \"good\" and \"bad\" recommenders -- enables counterfactual validation by capturing a wide spectrum of user experiences, enriched with first-person annotations of user satisfaction. We propose a comprehensive validation framework that combines statistical alignment, a human-likeness score, and counterfactual validation to test for generalization. Our experiments reveal a significant realism gap across all simulators. However, the framework also shows that data-driven simulators outperform a prompted baseline, particularly in counterfactual validation where they adapt more realistically to unseen behaviors, suggesting they embody more robust, if imperfect, user models.", "AI": {"tldr": "论文介绍了ConvApparel数据集和验证框架，旨在解决基于LLM的用户模拟器在真实世界表现不佳的问题。", "motivation": "动机在于解决LLM模拟器和现实用户交互之间的'现实差距'问题。", "method": "提出一个包括统计一致性、人性化评分和反事实验证的综合验证框架。", "result": "研究发现所有的模拟器都存在现实差距，但数据驱动的模拟器在反事实验证中表现出更真实的适应性。", "conclusion": "即使存在缺陷，数据驱动的模拟器仍能提供更强大、更真实的用户模型。"}}
{"id": "2602.16917", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16917", "abs": "https://arxiv.org/abs/2602.16917", "authors": ["Sakib Ahammed", "Xia Cui", "Xinqi Fan", "Wenqi Lu", "Moi Hoon Yap"], "title": "SemCovNet: Towards Fair and Semantic Coverage-Aware Learning for Underrepresented Visual Concepts", "comment": null, "summary": "Modern vision models increasingly rely on rich semantic representations that extend beyond class labels to include descriptive concepts and contextual attributes. However, existing datasets exhibit Semantic Coverage Imbalance (SCI), a previously overlooked bias arising from the long-tailed semantic representations. Unlike class imbalance, SCI occurs at the semantic level, affecting how models learn and reason about rare yet meaningful semantics. To mitigate SCI, we propose Semantic Coverage-Aware Network (SemCovNet), a novel model that explicitly learns to correct semantic coverage disparities. SemCovNet integrates a Semantic Descriptor Map (SDM) for learning semantic representations, a Descriptor Attention Modulation (DAM) module that dynamically weights visual and concept features, and a Descriptor-Visual Alignment (DVA) loss that aligns visual features with descriptor semantics. We quantify semantic fairness using a Coverage Disparity Index (CDI), which measures the alignment between coverage and error. Extensive experiments across multiple datasets demonstrate that SemCovNet enhances model reliability and substantially reduces CDI, achieving fairer and more equitable performance. This work establishes SCI as a measurable and correctable bias, providing a foundation for advancing semantic fairness and interpretable vision learning.", "AI": {"tldr": "本文提出了SemCovNet模型，旨在通过纠正语义覆盖差异来解决语义覆盖不平衡(SCI)问题。", "motivation": "现有的数据集存在语义覆盖不平衡问题(SCI)，这影响了模型学习和推理稀有但有意义的语义的能力。", "method": "SemCovNet模型通过集成语义描述图(SDM)，描述注意力调制(DAM)模块以及描述-视觉对齐(DVA)损失来纠正语义覆盖差异。", "result": "实验结果表明，SemCovNet提高了模型的可靠性，显著减少了Coverage Disparity Index (CDI)，从而实现了更公平、更均衡的性能。", "conclusion": "这项工作将SCI确立为可测量和可纠正的偏差，为推进语义公平性和可解释的视觉学习打下了基础。"}}
{"id": "2602.16957", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16957", "abs": "https://arxiv.org/abs/2602.16957", "authors": ["Hasan Can Biyik", "Libby Barak", "Jing Peng", "Anna Feldman"], "title": "When Semantic Overlap Is Not Enough: Cross-Lingual Euphemism Transfer Between Turkish and English", "comment": null, "summary": "Euphemisms substitute socially sensitive expressions, often softening or reframing meaning, and their reliance on cultural and pragmatic context complicates modeling across languages. In this study, we investigate how cross-lingual equivalence influences transfer in multilingual euphemism detection. We categorize Potentially Euphemistic Terms (PETs) in Turkish and English into Overlapping (OPETs) and Non-Overlapping (NOPETs) subsets based on their functional, pragmatic, and semantic alignment. Our findings reveal a transfer asymmetry: semantic overlap is insufficient to guarantee positive transfer, particularly in low-resource Turkish-to-English direction, where performance can degrade even for overlapping euphemisms, and in some cases, improve under NOPET-based training. Differences in label distribution help explain these counterintuitive results. Category-level analysis suggests that transfer may be influenced by domain-specific alignment, though evidence is limited by sparsity.", "AI": {"tldr": "本研究探讨了跨语言等价性如何影响多种语言中的委婉语检测，发现语义重叠不足以保证积极转移，特别是在资源较少的情况下。", "motivation": "由于委婉语在很大程度上依赖于文化和语用学背景，这使得跨语言建模复杂化。本研究旨在探讨跨语言等价性如何影响多种语言中的委婉语检测。", "method": "本研究将土耳其语和英语中的潜在委婉语(PETs)分为重叠的(OPETs)和非重叠的(NOPETs)两类，基于它们的功能、实用性和语义对齐。", "result": "研究结果显示跨语言转移存在不对称性：语义重叠不足以保证积极转移，特别是在资源较少的土耳其语到英语方向上，性能甚至可能下降，而在某些情况下NOPET训练下的性能反而有所提高。", "conclusion": "跨语言转移的影响可能受领域特定对齐的影响，但由于稀疏性，此类证据有限。"}}
{"id": "2602.16918", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16918", "abs": "https://arxiv.org/abs/2602.16918", "authors": ["Shlok Mishra", "Tsung-Yu Lin", "Linda Wang", "Hongli Xu", "Yimin Liu", "Michael Hsu", "Chaitanya Ahuja", "Hao Yuan", "Jianpeng Cheng", "Hong-You Chen", "Haoyuan Xu", "Chao Li", "Abhijeet Awasthi", "Jihye Moon", "Don Husa", "Michael Ge", "Sumedha Singla", "Arkabandhu Chowdhury", "Phong Dingh", "Satya Narayan Shukla", "Yonghuan Yang", "David Jacobs", "Qi Guo", "Jun Xiao", "Xiangjun Fan", "Aashu Singh"], "title": "Xray-Visual Models: Scaling Vision models on Industry Scale Data", "comment": null, "summary": "We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines self-supervised MAE, semi-supervised hashtag classification, and CLIP-style contrastive learning to jointly optimize image and video modalities. Our architecture builds on a Vision Transformer backbone enhanced with efficient token reorganization (EViT) for improved computational efficiency. Extensive experiments demonstrate that Xray-Visual achieves state-of-the-art performance across diverse benchmarks, including ImageNet for image classification, Kinetics and HMDB51 for video understanding, and MSCOCO for cross-modal retrieval. The model exhibits strong robustness to domain shift and adversarial perturbations. We further demonstrate that integrating large language models as text encoders (LLM2CLIP) significantly enhances retrieval performance and generalization capabilities, particularly in real-world environments. Xray-Visual establishes new benchmarks for scalable, multimodal vision models, while maintaining superior accuracy and computational efficiency.", "AI": {"tldr": "本文介绍了一种名为Xray-Visual的统一视觉模型架构，该模型基于Facebook和Instagram上的大规模图像和视频数据训练而成，采用了多阶段的训练方法和高效的计算技术，实现了跨多种基准测试的最先进性能，同时表现出强大的鲁棒性和泛化能力。", "motivation": "当前大规模图像和视频理解模型需要处理巨大的数据量和复杂的数据结构。为此，作者提出Xray-Visual模型，旨在通过训练和架构优化，提供一种高效的解决方案，以适应现实世界中的各种环境，提升模型的鲁棒性和泛化能力。", "method": "模型采用三阶段训练流程，结合自监督的MAE、半监督的标签分类和CLIP风格的对比学习，来共同优化图像和视频模态。其架构基于Vision Transformer，通过高效的token重组技术（EViT）提高了计算效率。同时，也探索了将大型语言模型作为文本编码器的方法，进一步增强模型性能。", "result": "该模型在ImageNet图像分类、Kinetics和HMDB51视频理解以及MSCOCO跨模态检索等多个基准测试中均达到了最先进的性能。此外，该模型还表现出对领域迁移和对抗性扰动的强大鲁棒性。研究表明，将大型语言模型作为文本编码器集成到模型中进一步提高了检索性能和在现实世界环境中的泛化能力。Xray-Visual在保持优越准确性和计算效率的同时，为可扩展的多模态视觉模型设立了一个新的标准。", "conclusion": "Xray-Visual利用大规模和高质量的数据训练，并通过创新的训练和技术优化，实现了在多个视觉任务上的顶尖性能。此外，利用集成大型语言模型的方法，模型在真实环境中的泛化能力和检索性能得到大幅度提升。这表明Xray-Visual架构适应未来复杂应用的潜力。"}}
{"id": "2602.16959", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16959", "abs": "https://arxiv.org/abs/2602.16959", "authors": ["Kourosh Shahnazari", "Seyed Moein Ayyoubzadeh", "Mohammadali Keshtparvar"], "title": "Eigenmood Space: Uncertainty-Aware Spectral Graph Analysis of Psychological Patterns in Classical Persian Poetry", "comment": null, "summary": "Classical Persian poetry is a historically sustained archive in which affective life is expressed through metaphor, intertextual convention, and rhetorical indirection. These properties make close reading indispensable while limiting reproducible comparison at scale. We present an uncertainty-aware computational framework for poet-level psychological analysis based on large-scale automatic multi-label annotation. Each verse is associated with a set of psychological concepts, per-label confidence scores, and an abstention flag that signals insufficient evidence. We aggregate confidence-weighted evidence into a Poet $\\times$ Concept matrix, interpret each poet as a probability distribution over concepts, and quantify poetic individuality as divergence from a corpus baseline using Jensen--Shannon divergence and Kullback--Leibler divergence. To capture relational structure beyond marginals, we build a confidence-weighted co-occurrence graph over concepts and define an Eigenmood embedding through Laplacian spectral decomposition. On a corpus of 61{,}573 verses across 10 poets, 22.2\\% of verses are abstained, underscoring the analytical importance of uncertainty. We further report sensitivity analysis under confidence thresholding, selection-bias diagnostics that treat abstention as a category, and a distant-to-close workflow that retrieves verse-level exemplars along Eigenmood axes. The resulting framework supports scalable, auditable digital-humanities analysis while preserving interpretive caution by propagating uncertainty from verse-level evidence to poet-level inference.", "AI": {"tldr": "研究创建了一个不确定性感知的计算框架，用于自动标注并分析波斯诗歌中的心理概念，通过引入置信度分数和序列嵌入来支持大规模的可扩展和可审计的人文分析，同时保留了对不确定性的处理。", "motivation": "由于传统波斯诗歌通过隐喻、互文性惯例和修辞技巧来表达情感生活，这使得文本密集型的阅读变得至关重要，同时也限制了大规模可重复的比较分析。", "method": "本研究提出了一个以不确定性为意识的计算框架，用于基于大规模自动多标签注释的诗人心理分析。每个诗句会关联到一组心理概念，每个标签会有相应的置信度分数，并且有一个弃权标志来表示证据不足。", "result": "该框架通过诗行加权置信度证据聚集成一个诗人×概念的矩阵，并将每位诗人解释为一个概念上的概率分布。此外，通过使用Jensen-Shannon和Kullback-Leibler发散度量化诗人的独特性。使用概念上的置信度加权共现图构建了Eigenmood嵌入，并通过Laplacian谱分解定义。研究在包含10位诗人共61,573首诗的语料库上进行了实验。", "conclusion": "所设计的框架支持可以进行可扩展、可审计的数字人文分析，并通过将不确定性从诗行级证据传播到诗人级推断来保持解释上的谨慎。通过敏感度分析、选择偏差诊断和远离到逼近的工作流程支持分析。"}}
{"id": "2602.16950", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16950", "abs": "https://arxiv.org/abs/2602.16950", "authors": ["Kibon Ku", "Talukder Z. Jubery", "Adarsh Krishnamurthy", "Baskar Ganapathysubramanian"], "title": "HS-3D-NeRF: 3D Surface and Hyperspectral Reconstruction From Stationary Hyperspectral Images Using Multi-Channel NeRFs", "comment": "16 pages, 14 figures, 3 tables", "summary": "Advances in hyperspectral imaging (HSI) and 3D reconstruction have enabled accurate, high-throughput characterization of agricultural produce quality and plant phenotypes, both essential for advancing agricultural sustainability and breeding programs. HSI captures detailed biochemical features of produce, while 3D geometric data substantially improves morphological analysis. However, integrating these two modalities at scale remains challenging, as conventional approaches involve complex hardware setups incompatible with automated phenotyping systems. Recent advances in neural radiance fields (NeRF) offer computationally efficient 3D reconstruction but typically require moving-camera setups, limiting throughput and reproducibility in standard indoor agricultural environments. To address these challenges, we introduce HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for high-throughput hyperspectral 3D reconstruction targeting postharvest inspection of agricultural produce. Multi-view hyperspectral data is captured using a stationary camera while the object rotates within a custom-built Teflon imaging chamber providing diffuse, uniform illumination. Object poses are estimated via ArUco calibration markers and transformed to the camera frame of reference through simulated pose transformations, enabling standard NeRF training on stationary-camera data. A multi-channel NeRF formulation optimizes reconstruction across all hyperspectral bands jointly using a composite spectral loss, supported by a two-stage training protocol that decouples geometric initialization from radiometric refinement. Experiments on three agricultural produce samples demonstrate high spatial reconstruction accuracy and strong spectral fidelity across the visible and near-infrared spectrum, confirming the suitability of HSI-SC-NeRF for integration into automated agricultural workflows.", "AI": {"tldr": "本文提出了一种新的方法HSI-SC-NeRF，该方法可以对农作物进行高效的高光谱三维重建，适用于自动化的农业工作流。", "motivation": "随着高光谱成像和3D重建技术的发展，准确高效的农产品质量和植物表型特征的获取变得可能。然而，将这两种技术大规模地整合在一起仍然是一个挑战。本文旨在解决这一问题。", "method": "本文提出了HSI-SC-NeRF方法，该方法是一种基于固定摄像头的多通道神经辐射场框架，用于实现高通量的高光谱三维重建。这种方法可以在固定摄像头下通过物体旋转和阿鲁科校准标记来捕获多视角高光谱数据，并通过模拟姿态转换以适应标准的NeRF训练。", "result": "实验结果表明，该方法在农产品样本的三维重建中实现了高度的空间准确性，并且在可见光和近红外光谱上表现出了良好的光谱保真度。", "conclusion": "实验结果证明了HSI-SC-NeRF方法在农业工作流自动化中的适用性。这种新方法为将来农业可持续性和育种计划的发展做出了贡献。"}}
{"id": "2602.17003", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17003", "abs": "https://arxiv.org/abs/2602.17003", "authors": ["Serin Kim", "Sangam Lee", "Dongha Lee"], "title": "Persona2Web: Benchmarking Personalized Web Agents for Contextual Reasoning with User History", "comment": null, "summary": "Large language models have advanced web agents, yet current agents lack personalization capabilities. Since users rarely specify every detail of their intent, practical web agents must be able to interpret ambiguous queries by inferring user preferences and contexts. To address this challenge, we present Persona2Web, the first benchmark for evaluating personalized web agents on the real open web, built upon the clarify-to-personalize principle, which requires agents to resolve ambiguity based on user history rather than relying on explicit instructions. Persona2Web consists of: (1) user histories that reveal preferences implicitly over long time spans, (2) ambiguous queries that require agents to infer implicit user preferences, and (3) a reasoning-aware evaluation framework that enables fine-grained assessment of personalization. We conduct extensive experiments across various agent architectures, backbone models, history access schemes, and queries with varying ambiguity levels, revealing key challenges in personalized web agent behavior. For reproducibility, our codes and datasets are publicly available at https://anonymous.4open.science/r/Persona2Web-73E8.", "AI": {"tldr": "文章介绍了Persona2Web，用于评估能在真实开放网络上工作的个性化网络代理，强调了解决模糊查询中用户偏好不确定性的重要性和挑战。", "motivation": "大规模语言模型已经促进了网络代理的发展，然而当前的网络代理缺乏个性化能力。由于用户很少会精确描述自己的意图，实用的网络代理必须能够通过推断用户的偏好和背景来解释模糊的查询。", "method": "提出了Persona2Web基准测试，它基于'澄清以个性化'的原则，要求网络代理能够利用用户历史记录解决不确定性，而不是依赖明确的指示。Persona2Web 包含用户历史记录、需要推理隐性用户偏好的模糊查询以及能够细粒度评估个性化的推理感知评估框架。", "result": "在多种代理架构、基础模型、用户历史访问方案和不同模糊程度查询上进行了广泛实验，揭示了个性化网络代理行为中的关键挑战。", "conclusion": "Persona2Web 是首个在真正的开放网络上评估个性化网络代理的基准测试，揭示了个性化代理在实际环境中的挑战，为将来研究奠定了基础。"}}
{"id": "2602.16968", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16968", "abs": "https://arxiv.org/abs/2602.16968", "authors": ["Dahye Kim", "Deepti Ghadiyaram", "Raghudeep Gadde"], "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers", "comment": null, "summary": "Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\\times$ and $3.2\\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.", "AI": {"tldr": "提出了一种在内容生成中的动态分块方法，根据内容复杂度和去噪步骤动态调整分块大小，实现计算成本显著减少且保持生成质量。", "motivation": "扩散变压器（DiTs）在图像和视频生成方面表现出色，但是由于固定的分块过程，其计算效率低。这种固定分块使用的常规模块在整个去噪过程中不变，忽略了内容复杂度的不同。我们希望通过改变分块策略，提高计算效率。", "method": "我们提出了一种叫做动态分块的方法，该方法根据内容复杂性和去噪时间步来调整分块大小。早期时间步只需要更大的分块来建模全局结构，而后期的时间步则需要更小的分块来细化局部细节。这种动态分配分块大小的方法在不影响生成质量的情况下减少了计算成本。", "result": "我们的方法实现了显著的计算成本减少，在不影响生成质量和指令遵循性的前提下，分别在FLUX-1.Dev和Wan$2.1$上实现了最高$3.52\times$和$3.2\times$的加速。", "conclusion": "实验结果表明，动态分块方法在图像和视频生成中的有效性和高效性，显著加速了生成过程而不牺牲生成质量和指令遵循性。"}}
{"id": "2602.17022", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.17022", "abs": "https://arxiv.org/abs/2602.17022", "authors": ["Takyoung Kim", "Jinseok Nam", "Chandrayee Basu", "Xing Fan", "Chengyuan Ma", "Heng Ji", "Gokhan Tur", "Dilek Hakkani-Tür"], "title": "ReIn: Conversational Error Recovery with Reasoning Inception", "comment": "ICLR 2026", "summary": "Conversational agents powered by large language models (LLMs) with tool integration achieve strong performance on fixed task-oriented dialogue datasets but remain vulnerable to unanticipated, user-induced errors. Rather than focusing on error prevention, this work focuses on error recovery, which necessitates the accurate diagnosis of erroneous dialogue contexts and execution of proper recovery plans. Under realistic constraints precluding model fine-tuning or prompt modification due to significant cost and time requirements, we explore whether agents can recover from contextually flawed interactions and how their behavior can be adapted without altering model parameters and prompts. To this end, we propose Reasoning Inception (ReIn), a test-time intervention method that plants an initial reasoning into the agent's decision-making process. Specifically, an external inception module identifies predefined errors within the dialogue context and generates recovery plans, which are subsequently integrated into the agent's internal reasoning process to guide corrective actions, without modifying its parameters or system prompts. We evaluate ReIn by systematically simulating conversational failure scenarios that directly hinder successful completion of user goals: user's ambiguous and unsupported requests. Across diverse combinations of agent models and inception modules, ReIn substantially improves task success and generalizes to unseen error types. Moreover, it consistently outperforms explicit prompt-modification approaches, underscoring its utility as an efficient, on-the-fly method. In-depth analysis of its operational mechanism, particularly in relation to instruction hierarchy, indicates that jointly defining recovery tools with ReIn can serve as a safe and effective strategy for improving the resilience of conversational agents without modifying the backbone models or system prompts.", "AI": {"tldr": "研究了在不修改模型参数和系统提示的情况下，对话代理如何从错误的对话上下文中恢复。通过提出Reasoning Inception (ReIn) 方法，系统性地提高了任务成功率，并表明其比明确的提示修改方法更有效。", "motivation": "尽管对话代理在固定任务导向对话数据集上表现出色，但仍对未预见的、由用户引起的错误敏感。研究着重于错误恢复，而不是预防，这需要准确诊断错误的对话上下文并执行适当的恢复计划。我们的工作探讨了在不修改模型参数和提示的前提下，代理能否从情境错误交互中恢复。", "method": "我们提出了Reasoning Inception (ReIn) ，这是一种测试时间干预方法，它将初始推理植入代理的决策过程。具体来说，一个外部起始模块在对话上下文中识别预定义的错误，并生成补救计划，然后将其整合到代理的内部推理过程，指导更正行为。", "result": "通过系统性地模拟对话失败的场景来评估ReIn，例如用户的模糊和不被支持的请求。实验结果显示，ReIn大大提高了任务的成功率，并且能够泛化到没有见过的错误类型。", "conclusion": "实验表明，ReIn显著提高了任务成功率，对未见过的错误类型具有良好的泛化能力。此外，它在各种代理模型和起始模块的组合中，始终比明确的提示修改方法表现更好，这表明ReIn是一个有效的即时方法，可以在不修改基础模型或系统提示的情况下提升对话代理的稳定性。"}}
