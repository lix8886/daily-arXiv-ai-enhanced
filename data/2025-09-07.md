<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Towards Efficient General Feature Prediction in Masked Skeleton Modeling](https://arxiv.org/abs/2509.03609)
*Shengkai Sun,Zefan Zhang,Jianfeng Dong,Zhiyong Cheng,Xiaojun Chang,Meng Wang*

Main category: cs.CV

> 提出了一种新的自监督骨架动作识别方法GFP，提高了计算效率和语义表示能力，实验结果优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 目的是解决现有方法中存在的计算冗余和语义表示有限的问题，通过改进的特征预测方法，提升动作识别性能。

**Method:** 我们提出了一种名为GFP（General Feature Prediction）的新框架，用高阶特征预测替代了传统的低层次重建，以提高计算效率和语义表示能力。该框架通过一个轻量级目标生成网络动态生成时空层次上的多样化监督信号，并采用约束优化确保特征多样性。

**Result:** 实验结果表明，我们的方法在计算效率方面提高了6.2倍，并且在NTU RGB+D 60, NTU RGB+D 120 和 PKU-MMD数据集上表现出了优越的表示质量和最先进的性能。

**Conclusion:** GFP框架展示了卓越的计算效率和表示质量，在多种下游任务中达到了最先进的性能。

**Abstract:** Recent advances in the masked autoencoder (MAE) paradigm have significantly
propelled self-supervised skeleton-based action recognition. However, most
existing approaches limit reconstruction targets to raw joint coordinates or
their simple variants, resulting in computational redundancy and limited
semantic representation. To address this, we propose a novel General Feature
Prediction framework (GFP) for efficient mask skeleton modeling. Our key
innovation is replacing conventional low-level reconstruction with high-level
feature prediction that spans from local motion patterns to global semantic
representations. Specifically, we introduce a collaborative learning framework
where a lightweight target generation network dynamically produces diversified
supervision signals across spatial-temporal hierarchies, avoiding reliance on
pre-computed offline features. The framework incorporates constrained
optimization to ensure feature diversity while preventing model collapse.
Experiments on NTU RGB+D 60, NTU RGB+D 120 and PKU-MMD demonstrate the benefits
of our approach: Computational efficiency (with 6.2$\times$ faster training
than standard masked skeleton modeling methods) and superior representation
quality, achieving state-of-the-art performance in various downstream tasks.

</details>


### [2] [Teacher-Student Model for Detecting and Classifying Mitosis in the MIDOG 2025 Challenge](https://arxiv.org/abs/2509.03614)
*Seungho Choe,Xiaoli Qin,Abubakr Shafique,Amanda Dy,Susan Done,Dimitrios Androutsos,April Khademi*

Main category: cs.CV

> 提出一种新的教师-学生模型解决领域泛化问题，同时实现丝状分裂检测和分类，实现了性能上的显著提升。

<details>
  <summary>Details</summary>

**Motivation:** 希望通过AI提高丝状分裂计数的一致性和效率，同时解决领域泛化的问题。

**Method:** 采用UNet分割模型结合领域对抗训练和对比表示学习模块，利用教师-学生策略生成伪掩模，另外提出了一种多尺度CNN分类器用于非典型丝状分裂分类。

**Result:** {"tldr": "本文提出了一个基于UNet分割骨干网络的教师-学生模型，该模型通过对比表示学习和领域对抗训练模块解决领域泛化问题，同时实现了丝状分裂检测和非典型丝状分裂分类任务，并在初步测试集中取得了F1得分为0.7660和平衡准确率为0.8414的不错效果。", "motivation": "由于人工计数丝状分裂图像是耗时的，并且会导致观察者间的变异，而AI工具有能力自动检测丝状分裂，但这些工具对领域泛化问题敏感，导致训练集和测试集上性能变化。本文旨在解决上述问题并提高检测的一致性。", "method": "主要采用UNet作为分割骨干网络，并结合对比表示学习和领域对抗训练的领域泛化模块以及教师-学生策略来生成像素级伪掩膜增强特征分辨能力。另一方面，对于分类任务提出了一种融合特征图的多尺度CNN分类器，在多任务学习框架中使用以挖掘丝状分裂信息。", "result": "在初步测试集合上，本文方法在检测任务上取得了F1得分0.7660，在分类任务上取得了平衡准确率0.8414。", "conclusion": "本文成功展示了通过结合基于分割的检测和分类任务在统一框架中进行丝状分裂分析的有效性，能够提高系统在面临领域偏移时的鲁棒性。"}

**Conclusion:** 本文提出了一个基于分割的丝状分裂检测和分类统一框架，有效解决了领域泛化问题并展示了良好性能。

**Abstract:** Counting mitotic figures is time-intensive for pathologists and leads to
inter-observer variability. Artificial intelligence (AI) promises a solution by
automatically detecting mitotic figures while maintaining decision consistency.
However, AI tools are susceptible to domain shift, where a significant drop in
performance can occur due to differences in the training and testing sets,
including morphological diversity between organs, species, and variations in
staining protocols. Furthermore, the number of mitoses is much less than the
count of normal nuclei, which introduces severely imbalanced data for the
detection task. In this work, we formulate mitosis detection as a pixel-level
segmentation and propose a teacher-student model that simultaneously addresses
mitosis detection (Track 1) and atypical mitosis classification (Track 2). Our
method is based on a UNet segmentation backbone that integrates domain
generalization modules, namely contrastive representation learning and
domain-adversarial training. A teacher-student strategy is employed to generate
pixel-level pseudo-masks not only for annotated mitoses and hard negatives but
also for normal nuclei, thereby enhancing feature discrimination and improving
robustness against domain shift. For the classification task, we introduce a
multi-scale CNN classifier that leverages feature maps from the segmentation
model within a multi-task learning paradigm. On the preliminary test set, the
algorithm achieved an F1 score of 0.7660 in Track 1 and balanced accuracy of
0.8414 in Track 2, demonstrating the effectiveness of integrating
segmentation-based detection and classification into a unified framework for
robust mitosis analysis.

</details>


### [3] [Multi Attribute Bias Mitigation via Representation Learning](https://arxiv.org/abs/2509.03616)
*Rajeev Ranjan Dwivedi,Ankur Kumar,Vinod K Kurmi*

Main category: cs.CV

> 本研究提出了一种名为GMBM的方法，该方法通过一个两阶段框架来解决图像处理中的多偏见问题，并且通过实验数据证明了GMBM的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 由于现实世界图像中经常存在多种重叠偏见，单独解决这些偏见是不够的，因为缓解一个偏见可能会使其他偏见变得更加严重，因此需要一个综合方法来一次性解决多个偏见。

**Method:** GMBM 方法通过一个两阶段框架来解决多偏见问题，首先通过ABIL（自适应偏见综合学习）阶段识别已知的偏见来源，然后通过梯度抑制微调阶段消除这些偏见。

**Result:** 在FB CMNIST、CelebA和COCO数据集上的实验表明，GMBM方法提高了最差群体的准确率，减少了多属性偏见的放大，并且在偏见复杂度和分布变化增强的情况下，SBA评分降低到了新的低点。

**Conclusion:** 研究人员认为GMBM是第一个实用的、端到端的多偏见解决方案，适用于视觉识别领域，其有效性已在多个基准测试数据集上得到验证。

**Abstract:** Real world images frequently exhibit multiple overlapping biases, including
textures, watermarks, gendered makeup, scene object pairings, etc. These biases
collectively impair the performance of modern vision models, undermining both
their robustness and fairness. Addressing these biases individually proves
inadequate, as mitigating one bias often permits or intensifies others. We
tackle this multi bias problem with Generalized Multi Bias Mitigation (GMBM), a
lean two stage framework that needs group labels only while training and
minimizes bias at test time. First, Adaptive Bias Integrated Learning (ABIL)
deliberately identifies the influence of known shortcuts by training encoders
for each attribute and integrating them with the main backbone, compelling the
classifier to explicitly recognize these biases. Then Gradient Suppression Fine
Tuning prunes those very bias directions from the backbone's gradients, leaving
a single compact network that ignores all the shortcuts it just learned to
recognize. Moreover we find that existing bias metrics break under subgroup
imbalance and train test distribution shifts, so we introduce Scaled Bias
Amplification (SBA): a test time measure that disentangles model induced bias
amplification from distributional differences. We validate GMBM on FB CMNIST,
CelebA, and COCO, where we boost worst group accuracy, halve multi attribute
bias amplification, and set a new low in SBA even as bias complexity and
distribution shifts intensify, making GMBM the first practical, end to end
multibias solution for visual recognition. Project page:
http://visdomlab.github.io/GMBM/

</details>
