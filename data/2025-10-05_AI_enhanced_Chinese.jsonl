{"id": "2510.01219", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01219", "abs": "https://arxiv.org/abs/2510.01219", "authors": ["Leroy Z. Wang"], "title": "Uncovering Implicit Bias in Large Language Models with Concept Learning Dataset", "comment": null, "summary": "We introduce a dataset of concept learning tasks that helps uncover implicit\nbiases in large language models. Using in-context concept learning experiments,\nwe found that language models may have a bias toward upward monotonicity in\nquantifiers; such bias is less apparent when the model is tested by direct\nprompting without concept learning components. This demonstrates that\nin-context concept learning can be an effective way to discover hidden biases\nin language models.", "AI": {"tldr": "研究通过概念学习实验发现，大型语言模型可能具有向上单调性的量词偏见，这种偏见在直接提示测试中不明显。", "motivation": "引入一个概念学习任务的数据集，目的是揭示大型语言模型中隐含的偏见。", "method": "通过在上下文中的概念学习实验，作者研究了大型语言模型中的潜在偏见问题。具体的实验方法是利用概念学习任务对语言模型进行测试，以揭露在直接提示测试中不太明显的偏见现象。", "result": "研究发现，语言模型可能在量词方面存在向上单调性的偏见。这种偏见在没有概念学习组件的情况下通过直接提示测试时并不明显。", "conclusion": "这表明，在上下文中的概念学习可以成为发现语言模型潜在偏见的有效方法。"}}
{"id": "2510.01220", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01220", "abs": "https://arxiv.org/abs/2510.01220", "authors": ["Bonaventure F. P. Dossou", "Henri Aïdasso"], "title": "Towards Open-Ended Discovery for Low-Resource NLP", "comment": "Proceedings of the 2nd Workshop on Uncertainty-Aware NLP\n  (UncertaiNLP) at EMNLP 2025", "summary": "Natural Language Processing (NLP) for low-resource languages remains\nfundamentally constrained by the lack of textual corpora, standardized\northographies, and scalable annotation pipelines. While recent advances in\nlarge language models have improved cross-lingual transfer, they remain\ninaccessible to underrepresented communities due to their reliance on massive,\npre-collected data and centralized infrastructure. In this position paper, we\nargue for a paradigm shift toward open-ended, interactive language discovery,\nwhere AI systems learn new languages dynamically through dialogue rather than\nstatic datasets. We contend that the future of language technology,\nparticularly for low-resource and under-documented languages, must move beyond\nstatic data collection pipelines toward interactive, uncertainty-driven\ndiscovery, where learning emerges dynamically from human-machine collaboration\ninstead of being limited to pre-existing datasets. We propose a framework\ngrounded in joint human-machine uncertainty, combining epistemic uncertainty\nfrom the model with hesitation cues and confidence signals from human speakers\nto guide interaction, query selection, and memory retention. This paper is a\ncall to action: we advocate a rethinking of how AI engages with human knowledge\nin under-documented languages, moving from extractive data collection toward\nparticipatory, co-adaptive learning processes that respect and empower\ncommunities while discovering and preserving the world's linguistic diversity.\nThis vision aligns with principles of human-centered AI, emphasizing\ninteractive, cooperative model building between AI systems and speakers.", "AI": {"tldr": "本文主张从静态数据收集转向通过对话进行动态、不确定性驱动的语言发现，以更好地服务于资源匮乏和少有记录的语言。", "motivation": "当前的自然语言处理技术受限于数据、标准书写系统和注释管道的缺乏，尤其是对于资源匮乏的语言，大型语言模型依赖大量的预收集数据和集中式基础设施，对这些语言社区来说并不实用。", "method": "提出一个基于共同的人机不确定性的框架，结合模型的认知不确定性与人类说话者的犹豫线索和信心信号来引导交互、查询选择和记忆保留。", "result": "该框架强调通过人类中心的AI理念，利用互动、协同建模的过程来发现和保护世界语言多样性。", "conclusion": "本文呼吁重新考虑AI如何与少有记录的语言的人类知识互动，从抽取式数据收集转向参与式、共同适应的学习过程，尊重和赋能社区。"}}
{"id": "2510.01222", "categories": ["cs.CL", "cs.AI", "cs.CY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01222", "abs": "https://arxiv.org/abs/2510.01222", "authors": ["Bertrand Kian Hassani", "Yacoub Bahini", "Rizwan Mushtaq"], "title": "Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs", "comment": null, "summary": "Climate change has increased demands for transparent and comparable corporate\nclimate disclosures, yet imitation and symbolic reporting often undermine their\nvalue. This paper develops a multidimensional framework to assess disclosure\nmaturity among 828 U.S.listed firms using large language models (LLMs)\nfine-tuned for climate communication. Four classifiers-sentiment, commitment,\nspecificity, and target ambition-extract narrative indicators from\nsustainability and annual reports, which are linked to firm attributes such as\nemissions, market capitalization, and sector. Analyses reveal three insights:\n(1) risk-focused narratives often align with explicit commitments, but\nquantitative targets (e.g., net-zero pledges) remain decoupled from tone; (2)\nlarger and higher-emitting firms disclose more commitments and actions than\npeers, though inconsistently with quantitative targets; and (3) widespread\nsimilarity in disclosure styles suggests mimetic behavior, reducing\ndifferentiation and decision usefulness. These results highlight the value of\nLLMs for ESG narrative analysis and the need for stronger regulation to connect\ncommitments with verifiable transition strategies.", "AI": {"tldr": "该研究通过使用大语言模型评估公司的气候披露成熟度，揭示了披露风格的广泛相似性，并强调了将承诺与转型策略连接起来的更强监管的重要性。", "motivation": "研究的动机在于解决气候变化增加对企业透明和可比较的气候披露需求的问题，同时应对模仿和象征性报告经常削弱其价值的挑战。", "method": "该论文的方法是使用针对气候沟通进行微调的大语言模型(LLMs)，通过四个分类器—情感、承诺、具体性和目标雄心—从可持续性和年度报告中提取叙述指标，并将这些指标与公司特征如排放量、市值和行业相关联。", "result": "该研究通过使用针对气候沟通进行微调的大语言模型（LLMs），开发了一个多维度框架来评估828家美国上市公司的披露成熟度。通过情感、承诺、具体性和目标雄心这四个分类器，从可持续性和年度报告中提取叙述指标，并将其与公司特征（如排放量、市值和行业）相关联。研究揭示了三个洞见：(1) 以风险为导向的叙述通常与明确的承诺相吻合，但定量目标（例如净零承诺）与语气脱钩；(2) 较大和排放量较高的公司比同行披露更多的承诺和行动，尽管这些与定量目标不一致；(3) 披露风格的广泛相似性表明了拟仿行为，降低了差异化和决策的有用性。这些结果强调了LLMs在ESG叙述分析中的价值，以及将承诺与可验证的转型策略联系起来的更强监管需求。", "conclusion": "该研究得出的结论是，需要更强有力的监管来连接承诺和可验证的转型策略，并表明LLMs在ESG叙述分析中的价值。"}}
{"id": "2510.01339", "categories": ["cs.CV", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.01339", "abs": "https://arxiv.org/abs/2510.01339", "authors": ["Alessio Spagnoletti", "Andrés Almansa", "Marcelo Pereyra"], "title": "LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration", "comment": "23 pages, 12 figures", "summary": "Computational imaging methods increasingly rely on powerful generative\ndiffusion models to tackle challenging image restoration tasks. In particular,\nstate-of-the-art zero-shot image inverse solvers leverage distilled\ntext-to-image latent diffusion models (LDMs) to achieve unprecedented accuracy\nand perceptual quality with high computational efficiency. However, extending\nthese advances to high-definition video restoration remains a significant\nchallenge, due to the need to recover fine spatial detail while capturing\nsubtle temporal dependencies. Consequently, methods that naively apply\nimage-based LDM priors on a frame-by-frame basis often result in temporally\ninconsistent reconstructions. We address this challenge by leveraging recent\nadvances in Video Consistency Models (VCMs), which distill video latent\ndiffusion models into fast generators that explicitly capture temporal\ncausality. Building on this foundation, we propose LVTINO, the first zero-shot\nor plug-and-play inverse solver for high definition video restoration with\npriors encoded by VCMs. Our conditioning mechanism bypasses the need for\nautomatic differentiation and achieves state-of-the-art video reconstruction\nquality with only a few neural function evaluations, while ensuring strong\nmeasurement consistency and smooth temporal transitions across frames.\nExtensive experiments on a diverse set of video inverse problems show\nsignificant perceptual improvements over current state-of-the-art methods that\napply image LDMs frame by frame, establishing a new benchmark in both\nreconstruction fidelity and computational efficiency.", "AI": {"tldr": "LVTINO 方法以视频一致性模型为基础，解决了高分辨率视频恢复中的时间和空间一致问题，超越了现有的顶级方法。", "motivation": "当前基于图像的扩散模型在处理视频时容易产生时间上的不一致性，LVTINO 旨在解决这一问题，通过引入视频一致性模型来保持时间因果关系。", "method": "研究提出 LVTINO 方法，利用视频一致性模型（VCM）的视频潜扩散模型，实现了零样本或即插即用逆向求解，改进了视频与图像间的处理差异。", "result": "该研究解决了高清晰度视频恢复中的时间不一致性问题。通过采用视频一致性模型（VCM），LVTINO 方法实现了零样本和插件式逆向求解，无需自动微分即可达到顶级的视频重建质量和计算效率。实验结果表明，该方法在感知质量和计算效率方面均超越了当前的顶级方法。", "conclusion": "实验证明，LVTINO 方法在各种视频逆问题上实现了显著的感知质量提升，确立了新基准，实现了高重建保真度和计算效率。"}}
{"id": "2510.01224", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01224", "abs": "https://arxiv.org/abs/2510.01224", "authors": ["Tyler J Poore", "Christopher J Pinard", "Aleena Shabbir", "Andrew Lagree", "Andre Telfer", "Kuan-Chuen Wu"], "title": "Context Matters: Comparison of commercial large language tools in veterinary medicine", "comment": "4 Figures, 10 pages", "summary": "Large language models (LLMs) are increasingly used in clinical settings, yet\ntheir performance in veterinary medicine remains underexplored. We evaluated\nthree commercially available veterinary-focused LLM summarization tools\n(Product 1 [Hachiko] and Products 2 and 3) on a standardized dataset of\nveterinary oncology records. Using a rubric-guided LLM-as-a-judge framework,\nsummaries were scored across five domains: Factual Accuracy, Completeness,\nChronological Order, Clinical Relevance, and Organization. Product 1 achieved\nthe highest overall performance, with a median average score of 4.61 (IQR:\n0.73), compared to 2.55 (IQR: 0.78) for Product 2 and 2.45 (IQR: 0.92) for\nProduct 3. It also received perfect median scores in Factual Accuracy and\nChronological Order. To assess the internal consistency of the grading\nframework itself, we repeated the evaluation across three independent runs. The\nLLM grader demonstrated high reproducibility, with Average Score standard\ndeviations of 0.015 (Product 1), 0.088 (Product 2), and 0.034 (Product 3).\nThese findings highlight the importance of veterinary-specific commercial LLM\ntools and demonstrate that LLM-as-a-judge evaluation is a scalable and\nreproducible method for assessing clinical NLP summarization in veterinary\nmedicine.", "AI": {"tldr": "研究评估了三种商用兽医专用LLM摘要工具，发现工具1表现最好，并证实了基于LLM的评估方法在兽医临床NLP摘要中的有效性和重复性。", "motivation": "尽管大型语言模型在临床环境中的应用越来越多，但在兽医医学中的性能关注较少。因此，作者旨在评估商用的兽医专用LLM摘要工具的性能，并验证基于LLM评判框架的可扩展性和可重复性。", "method": "使用了一个基于LLM评分的框架，对三种商用的专注于兽医领域的语言模型摘要工具在兽医肿瘤学记录上的表现进行了评估。评估体系包括五个领域：事实准确性、完整性、时间顺序、临床相关性和组织结构。为了验证评估框架的内部一致性，进行了三次独立的测试。", "result": "工具1（哈奇基）在整体评估中表现最好，平均得分为4.61（IQR：0.73），而工具2为2.55（IQR：0.78），工具3为2.45（IQR：0.92）。工具1在事实准确性和时间顺序上获得了满分。LLM评分者的标准偏差分别为工具1 0.015，工具2 0.088，工具3 0.034，表明评估框架具有高重复性。", "conclusion": "这项研究强调了兽医专用的商用LLM工具的重要性，并表明基于LLM评判的评估方法是评估兽医医学临床NLP摘要有效性的可扩展和可重复的方法。"}}
{"id": "2510.01347", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.01347", "abs": "https://arxiv.org/abs/2510.01347", "authors": ["Shuochen Chang"], "title": "Image Generation Based on Image Style Extraction", "comment": null, "summary": "Image generation based on text-to-image generation models is a task with\npractical application scenarios that fine-grained styles cannot be precisely\ndescribed and controlled in natural language, while the guidance information of\nstylized reference images is difficult to be directly aligned with the textual\nconditions of traditional textual guidance generation. This study focuses on\nhow to maximize the generative capability of the pretrained generative model,\nby obtaining fine-grained stylistic representations from a single given\nstylistic reference image, and injecting the stylistic representations into the\ngenerative body without changing the structural framework of the downstream\ngenerative model, so as to achieve fine-grained controlled stylized image\ngeneration. In this study, we propose a three-stage training style\nextraction-based image generation method, which uses a style encoder and a\nstyle projection layer to align the style representations with the textual\nrepresentations to realize fine-grained textual cue-based style guide\ngeneration. In addition, this study constructs the Style30k-captions dataset,\nwhose samples contain a triad of images, style labels, and text descriptions,\nto train the style encoder and style projection layer in this experiment.", "AI": {"tldr": "The paper introduces a method for fine-grained style control in text-to-image generation, using a style encoder and projection layer to integrate stylized reference images into the generation process, without changing the generative model's structure. The Style30k-captions dataset is used for training.", "motivation": "The motivation is to overcome the limitations of existing text-to-image generation models that cannot precisely control fine-grained styles and to integrate stylized reference images with textual conditions more effectively.", "method": "This study proposes a three-stage training method for style extraction and fine-grained style control in image generation. It utilizes a style encoder and a style projection layer to align style representations with textual cues. The method does not alter the structural framework of the pretrained generative model.", "result": "The study constructs the Style30k-captions dataset for experimental training, which contains triads of images, style labels, and text descriptions. This enables the training of the style encoder and style projection layer to achieve fine-grained style control.", "conclusion": "This innovative method maximizes the generative capabilities of pretrained models by integrating fine-grained stylistic representations from reference images into the generative process, thus achieving more controlled and precise stylized image generation."}}
{"id": "2510.01226", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01226", "abs": "https://arxiv.org/abs/2510.01226", "authors": ["Akshith Reddy Putta", "Jacob Devasier", "Chengkai Li"], "title": "ClaimCheck: Real-Time Fact-Checking with Small Language Models", "comment": null, "summary": "We introduce ClaimCheck, an LLM-guided automatic fact-checking system\ndesigned to verify real-world claims using live Web evidence and small language\nmodels. Unlike prior systems that rely on large, closed-source models and\nstatic knowledge stores, ClaimCheck employs a transparent, stepwise\nverification pipeline that mirrors human fact-checking workflows consisting of\nWeb search query planning, Web-based evidence retrieval and summarization,\nevidence synthesis and re-retrieval, and claim verdict evaluation. Each module\nis optimized for small LLMs, allowing the system to deliver accurate and\ninterpretable fact-checking with significantly lower computational\nrequirements. Despite using a much smaller Qwen3-4B model, ClaimCheck achieves\nstate-of-the-art accuracy of 76.4% on the AVeriTeC dataset, outperforming\nprevious approaches using LLaMA3.1 70B and GPT-4o. Extensive ablations\ndemonstrate that careful modular design and prompting strategies can overcome\nthe limitations of smaller LLMs. To promote accessibility and transparency, we\nprovide a public demo at https://idir.uta.edu/claimcheck.", "AI": {"tldr": "ClaimCheck是一种基于小型语言模型的自动事实核查系统，采用透明的步骤化验证流程，实现实时网络证据的事实核查，同时保持高准确率和低计算成本。", "motivation": "动机在于开发一种使用小型语言模型和实时网络证据进行自动事实核查的系统，从而提高系统的透明度和可解释性，并降低计算成本。", "method": "ClaimCheck采用了一种透明的、分步验证的流水线，包括网络搜索查询规划、基于Web的证据检索和摘要生成、证据综合与再检索以及声明判决评估。每个模块都针对小型语言模型进行了优化，从而降低了计算需求。", "result": "尽管使用了更小的Qwen3-4B模型，ClaimCheck在AVeriTeC数据集上仍达到了76.4%的准确率，超越了使用LLaMA3.1 70B和GPT-4o的先前方法。", "conclusion": "研究表明，通过精心的模块化设计和提示策略，可以克服小语言模型的局限性，实现高效的事实核查，并提供了公开演示以促进透明度和可访问性。"}}
{"id": "2510.01362", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.01362", "abs": "https://arxiv.org/abs/2510.01362", "authors": ["Shijia Feng", "Michael Wray", "Walterio Mayol-Cuevas"], "title": "EvoStruggle: A Dataset Capturing the Evolution of Struggle across Activities and Skill Levels", "comment": "10 pages", "summary": "The ability to determine when a person struggles during skill acquisition is\ncrucial for both optimizing human learning and enabling the development of\neffective assistive systems. As skills develop, the type and frequency of\nstruggles tend to change, and understanding this evolution is key to\ndetermining the user's current stage of learning. However, existing\nmanipulation datasets have not focused on how struggle evolves over time. In\nthis work, we collect a dataset for struggle determination, featuring 61.68\nhours of video recordings, 2,793 videos, and 5,385 annotated temporal struggle\nsegments collected from 76 participants. The dataset includes 18 tasks grouped\ninto four diverse activities -- tying knots, origami, tangram puzzles, and\nshuffling cards, representing different task variations. In addition,\nparticipants repeated the same task five times to capture their evolution of\nskill. We define the struggle determination problem as a temporal action\nlocalization task, focusing on identifying and precisely localizing struggle\nsegments with start and end times. Experimental results show that Temporal\nAction Localization models can successfully learn to detect struggle cues, even\nwhen evaluated on unseen tasks or activities. The models attain an overall\naverage mAP of 34.56% when generalizing across tasks and 19.24% across\nactivities, indicating that struggle is a transferable concept across various\nskill-based tasks while still posing challenges for further improvement in\nstruggle detection. Our dataset is available at\nhttps://github.com/FELIXFENG2019/EvoStruggle.", "AI": {"tldr": "研究收集了一个用于挣扎识别的数据集，并使用时间动作定位模型进行挣扎检测，取得了较好的效果，展示了挣扎识别在不同任务间的可迁移性。数据集已公开。", "motivation": "现有操作数据集未关注挣扎随时间的演变，本研究旨在通过理解挣扎的演变优化人类学习并开发有效的辅助系统。", "method": "收集了一个包含61.68小时视频，2793个视频片段，5385个标注时间挣扎段的数据集。定义挣扎识别为时间动作定位任务，用于定位挣扎段的起止时间。", "result": "实验结果表明时间动作定位模型能够成功检测挣扎线索，即使是在未知任务或活动上。模型泛化至任务和活动的mAP分别为34.56%和19.24%。", "conclusion": "研究表明挣扎是一个在各种基于技能的任务间可迁移的概念，但仍需进一步提高挣扎检测的准确性。"}}
{"id": "2510.01227", "categories": ["cs.CL", "math.HO"], "pdf": "https://arxiv.org/pdf/2510.01227", "abs": "https://arxiv.org/abs/2510.01227", "authors": ["Nicole N Khatibi", "Daniil A. Radamovich", "Michael P. Brenner"], "title": "EEFSUVA: A New Mathematical Olympiad Benchmark", "comment": "16 Pages, 5 figures", "summary": "Recent breakthroughs have spurred claims that large language models (LLMs)\nmatch gold medal Olympiad to graduate level proficiency on mathematics\nbenchmarks. In this work, we examine these claims in detail and assess the\nextent to which current benchmarks capture genuine LLM mathematical reasoning.\nThe composition of these benchmarks, primarily drawing from the International\nMathematics Olympiad (IMO) and related competitions, may overstate models\nreasoning ability due to potential data contamination and a narrow focus on\nfamiliar problem types. To enable a more holistic assessment of mathematical\nunderstanding, we introduce EEFSUVA, a novel benchmark curated from under\ncirculated regional and national Olympiads of Eastern Europe and the countries\nfrom the former Soviet Union. These contests feature problems of comparable\ndifficulty to the IMO and are renowned for demanding nonstandard\nproblem-solving techniques, yet their problems are far less prevalent in online\ncorpora. Preliminary results suggest that even state-of-the-art LLMs exhibit a\nnotable performance decline on EEFSUVA relative to other Olympiad-style\nbenchmarks. These findings also suggest the potential importance of broader\nevaluation datasets for a fuller assessment of mathematical reasoning and for\nguiding future model development.", "AI": {"tldr": "引入EEFSUVA评估LLMs数学推理，发现现有模型性能下降，提示需更多样化评估数据。", "motivation": "探讨大型语言模型（LLMs）在数学能力评估方面的表现，特别是针对现有基准测试可能存在的数据污染和问题类型单一化的局限性。", "method": "引入一个新的基准测试EEFSUVA，该测试基于东欧和前苏联国家较少公开的国际数学奥林匹克竞赛，这些竞赛中的问题难度与国际数学奥林匹克竞赛相当，但更加注重非标准的问题解决技巧。", "result": "初步结果显示，即使是最先进的LLMs在EEFSUVA上的表现相较于其他奥林匹克风格的基准测试有所下降。", "conclusion": "这些发现表明，需要更广泛的评估数据集来更全面地评估数学推理能力，并为未来的模型开发提供指导。"}}
{"id": "2510.01370", "categories": ["cs.CV", "cs.AI", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.01370", "abs": "https://arxiv.org/abs/2510.01370", "authors": ["Abu Bucker Siddik", "Diane Oyen", "Alexander Most", "Michal Kucer", "Ayan Biswas"], "title": "SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs", "comment": null, "summary": "We introduce Small PDE U-Net Solver (SPUS), a compact and efficient\nfoundation model (FM) designed as a unified neural operator for solving a wide\nrange of partial differential equations (PDEs). Unlike existing\nstate-of-the-art PDE FMs-primarily based on large complex transformer\narchitectures with high computational and parameter overhead-SPUS leverages a\nlightweight residual U-Net-based architecture that has been largely\nunderexplored as a foundation model architecture in this domain. To enable\neffective learning in this minimalist framework, we utilize a simple yet\npowerful auto-regressive pretraining strategy which closely replicates the\nbehavior of numerical solvers to learn the underlying physics. SPUS is\npretrained on a diverse set of fluid dynamics PDEs and evaluated across 6\nchallenging unseen downstream PDEs spanning various physical systems.\nExperimental results demonstrate that SPUS using residual U-Net based\narchitecture achieves state-of-the-art generalization on these downstream tasks\nwhile requiring significantly fewer parameters and minimal fine-tuning data,\nhighlighting its potential as a highly parameter-efficient FM for solving\ndiverse PDE systems.", "AI": {"tldr": "本文提出了SPUS模型，采用轻量级的U-Net架构，结合自回归预训练策略，取得了在求解多种PDE系统中的高水平表现，并拥有更高的参数效率和更低的微调要求。", "motivation": "相较于基于复杂大模型结构的基础模型，SPUS通过采用轻量级的U-Net架构，旨在在保持高性能的同时减少计算和参数复杂度。", "method": "本文提出了一种名为Small PDE U-Net Solver (SPUS) 的紧凑高效的模型，用于求解广泛的偏微分方程(PDEs)。与现有的基于复杂大模型架构的最优PDE基础模型不同，SPUS采用了一种轻量级的残差U-Net架构，这种架构在基础模型领域尚未得到充分利用。为了使这种简约框架的学习更加有效，本文采用了一种简单的自回归预训练策略，它模仿数值求解器的行为来学习底层物理。", "result": "实验结果显示，SPUS利用基于残差U-Net的架构在这些任务上实现了最先进的泛化性能，同时需要的参数量显著减少，并且需要的微调数据非常少，这突显了其作为高度参数高效的PDE求解基础模型的潜力。", "conclusion": "SPUS模型具有较高的参数效率，并能在多个不同的PDE系统中展现出强大的求解能力。"}}
{"id": "2510.01228", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.01228", "abs": "https://arxiv.org/abs/2510.01228", "authors": ["Siqi Zeng"], "title": "Who is In Charge? Dissecting Role Conflicts in Instruction Following", "comment": null, "summary": "Large language models should follow hierarchical instructions where system\nprompts override user inputs, yet recent work shows they often ignore this rule\nwhile strongly obeying social cues such as authority or consensus. We extend\nthese behavioral findings with mechanistic interpretations on a large-scale\ndataset. Linear probing shows conflict-decision signals are encoded early, with\nsystem-user and social conflicts forming distinct subspaces. Direct Logit\nAttribution reveals stronger internal conflict detection in system-user cases\nbut consistent resolution only for social cues. Steering experiments show that,\ndespite using social cues, the vectors surprisingly amplify instruction\nfollowing in a role-agnostic way. Together, these results explain fragile\nsystem obedience and underscore the need for lightweight hierarchy-sensitive\nalignment methods.", "AI": {"tldr": "大语言模型通过社会线索放大角色无关的指令遵循程度，即便面对系统-用户冲突也能检测内部冲突，但解决冲突的能力有限。这揭示了系统顺从性的脆弱性，突出需要更细腻的等级结构敏感对齐方法的重要性。", "motivation": "大语言模型应遵循分层指令，即系统提示覆盖用户输入，但近期研究表明它们经常忽视此规则，强烈遵守权威或共识等社会线索。", "method": "通过大规模数据集的机制解释扩展了这些行为发现。线性探测显示冲突决策信号编码较早，系统-用户和社会冲突形成不同的子空间。直接Logit归因揭示了在系统-用户情况下更强的内部冲突检测，但仅对社会线索有一致的解决结果。转向实验显示，尽管使用了社会线索，角色无关的方式意外地放大了指令遵循程度。", "result": "这些结果解释了系统顺从性的脆弱性，并强调了需要采用轻量级等级敏感的对齐方法。", "conclusion": "研究表明，尽管大语言模型在面对社会和系统指示之间的冲突时，能够检测到冲突的存在，但其解决冲突的方式主要依赖于社会线索，而不是系统指示。这表明系统对指示的遵守性较为脆弱，并提出需要轻量级的等级敏感对齐方法来提高模型的行为一致性。"}}
{"id": "2510.01399", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.01399", "abs": "https://arxiv.org/abs/2510.01399", "authors": ["Shubhankar Borse", "Farzad Farhadzadeh", "Munawar Hayat", "Fatih Porikli"], "title": "DisCo: Reinforcement with Diversity Constraints for Multi-Human Generation", "comment": null, "summary": "State-of-the-art text-to-image models excel at realism but collapse on\nmulti-human prompts - duplicating faces, merging identities, and miscounting\nindividuals. We introduce DisCo (Reinforcement with Diversity Constraints), the\nfirst RL-based framework to directly optimize identity diversity in multi-human\ngeneration. DisCo fine-tunes flow-matching models via Group-Relative Policy\nOptimization (GRPO) with a compositional reward that (i) penalizes intra-image\nfacial similarity, (ii) discourages cross-sample identity repetition, (iii)\nenforces accurate person counts, and (iv) preserves visual fidelity through\nhuman preference scores. A single-stage curriculum stabilizes training as\ncomplexity scales, requiring no extra annotations. On the DiverseHumans\nTestset, DisCo achieves 98.6 Unique Face Accuracy and near-perfect Global\nIdentity Spread - surpassing both open-source and proprietary methods (e.g.,\nGemini, GPT-Image) while maintaining competitive perceptual quality. Our\nresults establish DisCo as a scalable, annotation-free solution that resolves\nthe long-standing identity crisis in generative models and sets a new benchmark\nfor compositional multi-human generation.", "AI": {"tldr": "DisCo是首个用于优化多个人物生成中身份多样性的RL框架。它通过组相对策略优化（GRPO）和组合奖励方法来改善多个人物的生成质量，并在DiverseHumans测试集上取得了卓越的成绩。", "motivation": "最先进的文本到图像模型在现实主义方面表现出色，但在处理多人提示时会遇到问题，如面部复制、身份合并和个体计数错误。", "method": "引入DisCo（利用多样性约束的强化学习），这是首个用于直接优化多个人物生成中身份多样性的RL框架。DisCo通过组相对策略优化（GRPO）微调流匹配模型，使用组合奖励进行优化，该奖励（i）惩罚图像内的面部相似度，（ii）阻止跨样例身份重复，（iii）强制准确的人数统计，并（iv）通过人类偏好分数保持视觉保真度。", "result": "在DiverseHumans测试集上，DisCo达到了98.6%的独特面部准确性，并接近完美的全局身份分散，优于开源和专用方法（例如Gemini，GPT-Image），同时保持了竞争性的感知质量。", "conclusion": "DisCo作为一个可扩展、无需附加注释的解决方案解决了生成模型中的身份危机问题，并为多个人物的生成树立了新的基准。"}}
{"id": "2510.01229", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01229", "abs": "https://arxiv.org/abs/2510.01229", "authors": ["Dimitar Peshevski", "Kiril Blazhevski", "Martin Popovski", "Gjorgji Madjarov"], "title": "Enhancing Transformer-Based Rerankers with Synthetic Data and LLM-Based Supervision", "comment": "Accepted by RANLP 2025", "summary": "Effective document reranking is essential for improving search relevance\nacross diverse applications. While Large Language Models (LLMs) excel at\nreranking due to their deep semantic understanding and reasoning, their high\ncomputational cost makes them impractical for many real-world deployments.\nFine-tuning smaller, task-specific models is a more efficient alternative but\ntypically depends on scarce, manually labeled data. To overcome this, we\npropose a novel pipeline that eliminates the need for human-labeled\nquery-document pairs. Our method uses LLMs to generate synthetic queries from\ndomain-specific corpora and employs an LLM-based classifier to label positive\nand hard-negative pairs. This synthetic dataset is then used to fine-tune a\nsmaller transformer model with contrastive learning using Localized Contrastive\nEstimation (LCE) loss. Experiments on the MedQuAD dataset show that our\napproach significantly boosts in-domain performance and generalizes well to\nout-of-domain tasks. By using LLMs for data generation and supervision rather\nthan inference, we reduce computational costs while maintaining strong\nreranking capabilities.", "AI": {"tldr": "The paper proposes a method to generate and label synthetic query-document pairs using LLMs, which are then used to fine-tune a smaller transformer model with contrastive learning. This method reduces the need for manually labeled data and lowers computational cost for effective document reranking.", "motivation": "The motivation is to reduce the computational cost of using Large Language Models (LLMs) for reranking while still improving search relevance. The reliance on manually labeled data for training smaller, task-specific models is also a challenge they aim to overcome.", "method": "Our method uses LLMs to generate synthetic queries from domain-specific corpora and employs an LLM-based classifier to label positive and hard-negative pairs. This synthetic dataset is then used to fine-tune a smaller transformer model with contrastive learning using Localized Contrastive Estimation (LCE) loss.", "result": "Experiments on the MedQuAD dataset show that their approach significantly boosts in-domain performance and generalizes well to out-of-domain tasks.", "conclusion": "By using LLMs for data generation and supervision rather than inference, the approach reduces computational costs while maintaining strong reranking capabilities."}}
{"id": "2510.01448", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.01448", "abs": "https://arxiv.org/abs/2510.01448", "authors": ["Angel Daruna", "Nicholas Meegan", "Han-Pang Chiu", "Supun Samarasekera", "Rakesh Kumar"], "title": "GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings", "comment": "preprint under review", "summary": "Worldwide visual geo-localization seeks to determine the geographic location\nof an image anywhere on Earth using only its visual content. Learned\nrepresentations of geography for visual geo-localization remain an active\nresearch topic despite much progress. We formulate geo-localization as aligning\nthe visual representation of the query image with a learned geographic\nrepresentation. Our novel geographic representation explicitly models the world\nas a hierarchy of geographic embeddings. Additionally, we introduce an approach\nto efficiently fuse the appearance features of the query image with its\nsemantic segmentation map, forming a robust visual representation. Our main\nexperiments demonstrate improved all-time bests in 22 out of 25 metrics\nmeasured across five benchmark datasets compared to prior state-of-the-art\n(SOTA) methods and recent Large Vision-Language Models (LVLMs). Additional\nablation studies support the claim that these gains are primarily driven by the\ncombination of geographic and visual representations.", "AI": {"tldr": "The paper proposes a novel method for visual geo-localization that uses a hierarchical geographic embedding and a combination of appearance and semantic segmentation features to improve localization accuracy over existing methods.", "motivation": "There is a strong push in research to develop more accurate learned representations of geography for visual geo-localization on a global scale.", "method": "Our paper introduces a novel approach to visual geo-localization by aligning the visual content of an image with a hierarchical geographic embedding model. We also present a method to combine appearance and semantic segmentation features to create a robust visual representation.", "result": "Our experiments show significant improvements over previous state-of-the-art methods and LVLMs, achieving new bests in 22 out of 25 metrics across five benchmark datasets. Ablation studies highlight the effectiveness of our geographic and visual representation fusion.", "conclusion": "The combination of our geographic and visual representations leads to significant performance improvements in visual geo-localization. This suggests that geographic hierarchies and feature fusion can be powerful tools for improving location determination precision."}}
{"id": "2510.01230", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.01230", "abs": "https://arxiv.org/abs/2510.01230", "authors": ["Wen G. Gong"], "title": "Geometric Structures and Patterns of Meaning: A PHATE Manifold Analysis of Chinese Character Embeddings", "comment": "33 pages, 17 figures", "summary": "We systematically investigate geometric patterns in Chinese character\nembeddings using PHATE manifold analysis. Through cross-validation across seven\nembedding models and eight dimensionality reduction methods, we observe\nclustering patterns for content words and branching patterns for function\nwords. Analysis of over 1000 Chinese characters across 12 semantic domains\nreveals that geometric complexity correlates with semantic content: meaningful\ncharacters exhibit rich geometric diversity while structural radicals collapse\ninto tight clusters. The comprehensive child-network analysis (123 phrases)\ndemonstrates systematic semantic expansion from elemental character. These\nfindings provide computational evidence supporting traditional linguistic\ntheory and establish a novel framework for geometric analysis of semantic\norganization.", "AI": {"tldr": "通过几何分析揭示了中文字符的语义组织结构，发现有意义的汉字在几何上表现出多样性和复杂性，支持了传统语言学理论，并建立了新的几何分析框架。", "motivation": "研究的动机在于系统地探究中文字符嵌入中的几何模式，并通过降维分析跨语义领域的字符。通过几何复杂性来探究语义内容的本质，为理解和分析字符的结构和功能提供了新的视角。", "method": "利用PHATE流形分析方法，系统调查了中文字符嵌入中的几何模式。通过在七种嵌入模型和八种降维方法之间进行交叉验证，观察到实词的聚类模式和虚词的分支模式。", "result": "分析了跨越12个语义领域的1000多个汉字，发现几何复杂性与语义内容相关：有意义的汉字表现出丰富的几何多样性，而结构部首则聚集在紧密的簇中。对123个短语的全面子网分析展示了从基本字符开始的系统性语义扩展。", "conclusion": "这些发现提供了支持传统语言理论的计算证据，并为语义组织的几何分析建立了一个新的框架。"}}
