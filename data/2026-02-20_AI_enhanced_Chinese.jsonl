{"id": "2602.16713", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16713", "abs": "https://arxiv.org/abs/2602.16713", "authors": ["Shuo Wang", "Shuo Wang", "Xin Nie", "Yasutaka Narazaki", "Thomas Matiki", "Billie F. Spencer"], "title": "Three-dimensional Damage Visualization of Civil Structures via Gaussian Splatting-enabled Digital Twins", "comment": null, "summary": "Recent advancements in civil infrastructure inspections underscore the need for precise three-dimensional (3D) damage visualization on digital twins, transcending traditional 2D image-based damage identifications. Compared to conventional photogrammetric 3D reconstruction techniques, modern approaches such as Neural Radiance Field (NeRF) and Gaussian Splatting (GS) excel in scene representation, rendering quality, and handling featureless regions. Among them, GS stands out for its efficiency, leveraging discrete anisotropic 3D Gaussians to represent radiance fields, unlike NeRF's continuous implicit model. This study introduces a GS-enabled digital twin method tailored for effective 3D damage visualization. The method's key contributions include: 1) utilizing GS-based 3D reconstruction to visualize 2D damage segmentation results while reducing segmentation errors; 2) developing a multi-scale reconstruction strategy to balance efficiency and damage detail; 3) enabling digital twin updates as damage evolves over time. Demonstrated on an open-source synthetic dataset for post-earthquake inspections, the proposed approach offers a promising solution for comprehensive 3D damage visualization in civil infrastructure digital twins.", "AI": {"tldr": "The paper introduces a Gaussian Splatting (GS)-enabled digital twin method for 3D damage visualization in civil infrastructure, which improves on damage identification and segmentation by offering efficient 3D reconstruction capabilities.", "motivation": "To enhance the precision of damage identification in civil infrastructure, moving beyond 2D to 3D through leveraging advanced 3D reconstruction technologies such as Gaussian Splatting to address limitations in handling featureless regions and achieving high-quality scene representation.", "method": "The paper utilizes Gaussian Splatting for 3D reconstruction, integrating GS-based methods with digital twin models to visualize damage, reduce segmentation errors, and apply a multi-scale reconstruction strategy for efficiency and detailed damage depiction.", "result": "The proposed GS-enabled method is demonstrated to efficiently support 3D damage visualization, validated on a synthetic dataset for post-earthquake inspection scenarios.", "conclusion": "Gaussian Splatting offers a viable and efficient approach for 3D damage visualization in digital twins of civil infrastructure, providing a promising solution for comprehensive damage identification and assessment in complex settings."}}
{"id": "2602.16856", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16856", "abs": "https://arxiv.org/abs/2602.16856", "authors": ["Boda Lin", "Yongjie Zhu", "Wenyu Qin", "Meng Wang", "Pengfei Wan"], "title": "Analytic Score Optimization for Multi Dimension Video Quality Assessment", "comment": "18 pages", "summary": "Video Quality Assessment (VQA) is evolving beyond single-number mean opinion score toward richer, multi-faceted evaluations of video content. In this paper, we present a large-scale multi-dimensional VQA dataset UltraVQA that encompasses diverse User-Generated Content~(UGC) annotated across five key quality dimensions: Motion Quality, Motion Amplitude, Aesthetic Quality, Content Quality, and Clarity Quality. Each video in our dataset is scored by over 3 human raters on these dimensions, with fine-grained sub-attribute labels, and accompanied by an explanatory rationale generated by GPT based on the collective human judgments. To better leverage these rich annotations and improve discrete quality score assessment, we introduce Analytic Score Optimization (ASO), a theoretically grounded post-training objective derived for multi-dimensional VQA. By reframing quality assessment as a regularized decision-making process, we obtain a closed-form solution that naturally captures the ordinal nature of human ratings, ensuring alignment with human ranking preferences. In experiments, our method outperforms most baselines including closed-source APIs and open-source models, while also reducing mean absolute error (MAE) in quality prediction. Our work highlights the importance of multi-dimensional, interpretable annotations and reinforcement-based alignment in advancing video quality assessment.", "AI": {"tldr": "本文介绍了UltraVQA数据集和ASO方法，强调了多维度注释的价值，结果显示方法的有效性。", "motivation": "视频质量评估正从单一的平均意见评分向更丰富、多方面的视频内容评估发展。当前的VQA领域缺乏这样的大规模数据集和相应的评估方法。", "method": "我们提出了一个大规模的多维度VQA数据集UltraVQA，该数据集涵盖了丰富的用户生成内容，并通过五个关键质量维度进行标注。此外，我们引入了分析评分优化(ASO)，这是一种理论上基于多维度VQA的后训练目标，可以更好地利用这些丰富的注释并改进离散质量评分评估。", "result": "实验结果表明，我们的方法在大多数基线，包括闭源API和开源模型中表现出色，同时也减少了质量预测的平均绝对误差(MAE)。", "conclusion": "这项研究强调了多维度、可解释的标注和基于强化的对齐在推进视频质量评估中的重要性。"}}
{"id": "2602.16872", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16872", "abs": "https://arxiv.org/abs/2602.16872", "authors": ["Sean Man", "Roy Ganz", "Roi Ronen", "Shahar Tsiper", "Shai Mazor", "Niv Nayman"], "title": "DODO: Discrete OCR Diffusion Models", "comment": null, "summary": "Optical Character Recognition (OCR) is a fundamental task for digitizing information, serving as a critical bridge between visual data and textual understanding. While modern Vision-Language Models (VLM) have achieved high accuracy in this domain, they predominantly rely on autoregressive decoding, which becomes computationally expensive and slow for long documents as it requires a sequential forward pass for every generated token. We identify a key opportunity to overcome this bottleneck: unlike open-ended generation, OCR is a highly deterministic task where the visual input strictly dictates a unique output sequence, theoretically enabling efficient, parallel decoding via diffusion models. However, we show that existing masked diffusion models fail to harness this potential; those introduce structural instabilities that are benign in flexible tasks, like captioning, but catastrophic for the rigid, exact-match requirements of OCR. To bridge this gap, we introduce DODO, the first VLM to utilize block discrete diffusion and unlock its speedup potential for OCR. By decomposing generation into blocks, DODO mitigates the synchronization errors of global diffusion. Empirically, our method achieves near state-of-the-art accuracy while enabling up to 3x faster inference compared to autoregressive baselines.", "AI": {"tldr": "本研究解决了OCR中的计算成本高和推理慢的问题，提出了一种新的视觉语言模型DODO，利用块离散扩散技术实现了更快的推理速度。", "motivation": "当前的视觉语言模型在处理光学字符识别(OCR)任务时，虽然准确率高，但由于依赖自回归解码，对于长文档仍然存在计算昂贵且推理速度慢的问题。研究旨在通过新方法解决这一瓶颈。", "method": "研究提出了DODO模型，这是首次应用于OCR任务的视觉语言模型(VLM)，利用块离散扩散来生成文本，通过将生成过程分解为块，减少了全局扩散中出现的同步错误。", "result": "该研究通过引入DODO模型，利用块离散扩散的方法，解决了现有方法在OCR任务中的计算复杂度高和速度慢的问题，实现在保持接近最先进精度的同时，推理速度提高到基线方法的3倍。", "conclusion": "研究结论表明，通过应用DODO模型，光学字符识别任务的效率得到了提升，同时保持了接近最先进模型的准确性，实现了高质量与高效率的结合。"}}
{"id": "2602.16915", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16915", "abs": "https://arxiv.org/abs/2602.16915", "authors": ["Zeyu Ren", "Xiang Li", "Yiran Wang", "Zeyu Zhang", "Hao Tang"], "title": "StereoAdapter-2: Globally Structure-Consistent Underwater Stereo Depth Estimation", "comment": null, "summary": "Stereo depth estimation is fundamental to underwater robotic perception, yet suffers from severe domain shifts caused by wavelength-dependent light attenuation, scattering, and refraction. Recent approaches leverage monocular foundation models with GRU-based iterative refinement for underwater adaptation; however, the sequential gating and local convolutional kernels in GRUs necessitate multiple iterations for long-range disparity propagation, limiting performance in large-disparity and textureless underwater regions. In this paper, we propose StereoAdapter-2, which replaces the conventional ConvGRU updater with a novel ConvSS2D operator based on selective state space models. The proposed operator employs a four-directional scanning strategy that naturally aligns with epipolar geometry while capturing vertical structural consistency, enabling efficient long-range spatial propagation within a single update step at linear computational complexity. Furthermore, we construct UW-StereoDepth-80K, a large-scale synthetic underwater stereo dataset featuring diverse baselines, attenuation coefficients, and scattering parameters through a two-stage generative pipeline combining semantic-aware style transfer and geometry-consistent novel view synthesis. Combined with dynamic LoRA adaptation inherited from StereoAdapter, our framework achieves state-of-the-art zero-shot performance on underwater benchmarks with 17% improvement on TartanAir-UW and 7.2% improvment on SQUID, with real-world validation on the BlueROV2 platform demonstrates the robustness of our approach. Code: https://github.com/AIGeeksGroup/StereoAdapter-2. Website: https://aigeeksgroup.github.io/StereoAdapter-2.", "AI": {"tldr": "本文提出了StereoAdapter-2，使用基于选择性状态空间模型的ConvSS2D操作符来改进立体深度估计。通过一个四方向扫描策略实现了有效的大范围空间传播。同时，构建了一个大规模合成水下立体数据集UW-StereoDepth-80K，推动了无监督水下深度估计技术的发展和取得了超过现有主流方案的表现，分别在TartanAir-UW和SQUID数据集上提升了17%和7.2%。", "motivation": "本文旨在解决现有的立体深度估计方法在适应水下环境时所遇到的严重领域转移问题，特别是长距离不匹配和无纹理区域的局限性。", "method": "引入了ConvSS2D操作符，使用选择性状态空间模型，替代了传统的ConvGRU，同时提出了一种能够捕捉垂直结构一致性的四方向扫描策略，能在单次更新步骤中实现线性复杂度下的效率空间传播。", "result": "基于UW-StereoDepth-80K数据集，该框架在无监督水下深度估计中实现了先进的零样本性能。实验证明在TartanAir-UW和SQUID数据集上提升了17%和7.2%，并在真实世界BlueROV2平台上证明了方法的鲁棒性。", "conclusion": "StereoAdapter-2通过引入ConvSS2D操作符和新的四方向扫描策略，解决了传统长距离传播的局限性，显著提升了水下立体深度估计的效果，具有重要的实际意义。"}}
{"id": "2602.16802", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16802", "abs": "https://arxiv.org/abs/2602.16802", "authors": ["Kejian Shi", "Yixin Liu", "Peifeng Wang", "Alexander R. Fabbri", "Shafiq Joty", "Arman Cohan"], "title": "References Improve LLM Alignment in Non-Verifiable Domains", "comment": "ICLR 2026 Camera Ready", "summary": "While Reinforcement Learning with Verifiable Rewards (RLVR) has shown strong effectiveness in reasoning tasks, it cannot be directly applied to non-verifiable domains lacking ground-truth verifiers, such as LLM alignment. In this work, we investigate whether reference-guided LLM-evaluators can bridge this gap by serving as soft \"verifiers\". First, we design evaluation protocols that enhance LLM-based evaluators for LLM alignment using reference outputs. Through comprehensive experiments, we show that a reference-guided approach substantially improves the accuracy of less capable LLM-judges using references from frontier models; stronger LLM-judges can also be enhanced by high-quality (i.e., human-written) references. Building on these improved judges, we demonstrate the utility of high-quality references in alignment tuning, where LLMs guided with references are used as judges to self-improve. We show that reference-guided self-improvement yields clear gains over both direct SFT on reference outputs and self-improvement with reference-free judges, achieving performance comparable to training with ArmoRM, a strong finetuned reward model. Specifically, our method achieves 73.1% and 58.7% on AlpacaEval and Arena-Hard with Llama-3-8B-Instruct, and 70.0% and 74.1% with Qwen2.5-7B, corresponding to average absolute gains of +20.2 / +17.1 points over SFT distillation and +5.3 / +3.6 points over reference-free self-improvement on AlpacaEval / Arena-Hard. These results highlight the potential of using reference-guided LLM-evaluators to enable effective LLM post-training in non-verifiable domains.", "AI": {"tldr": "本文调查了在LLM对齐中，基于参考的LLM评估器能否作为软“验证器”以提高准确性。实验结果证明了这种方法的有效性，显著提高了LLM的性能。", "motivation": "RLVR在推理任务中表现出色，但无法直接应用于没有地面事实验证器的不可验证领域（如LLM对齐）。本文研究了基于参考的LLM评估器能否通过作为软“验证器”来弥补这一差距。", "method": "我们设计了评估协议，利用参考输出增强了LLM对齐中的LLM评估器。通过全面的实验，我们展示了基于参考的方法显著提高了较不成熟的LLM裁判的准确性。此外，更强的LLM裁判也可以通过高质量的（即人工编写的）参考进行改进。", "result": "实验结果显示，基于参考的自我改进在AlpacaEval和Arena-Hard上使用Llama-3-8B-Instruct获得了73.1%和58.7%，使用Qwen2.5-7B获得了70.0%和74.1%，分别对应于SFT蒸馏和无参考自我改进的绝对增益。", "conclusion": "这些结果表明，在不可验证的领域，使用基于参考的LLM评估器来实现有效的LLM后期训练具有巨大的潜力。"}}
{"id": "2602.16917", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16917", "abs": "https://arxiv.org/abs/2602.16917", "authors": ["Sakib Ahammed", "Xia Cui", "Xinqi Fan", "Wenqi Lu", "Moi Hoon Yap"], "title": "SemCovNet: Towards Fair and Semantic Coverage-Aware Learning for Underrepresented Visual Concepts", "comment": null, "summary": "Modern vision models increasingly rely on rich semantic representations that extend beyond class labels to include descriptive concepts and contextual attributes. However, existing datasets exhibit Semantic Coverage Imbalance (SCI), a previously overlooked bias arising from the long-tailed semantic representations. Unlike class imbalance, SCI occurs at the semantic level, affecting how models learn and reason about rare yet meaningful semantics. To mitigate SCI, we propose Semantic Coverage-Aware Network (SemCovNet), a novel model that explicitly learns to correct semantic coverage disparities. SemCovNet integrates a Semantic Descriptor Map (SDM) for learning semantic representations, a Descriptor Attention Modulation (DAM) module that dynamically weights visual and concept features, and a Descriptor-Visual Alignment (DVA) loss that aligns visual features with descriptor semantics. We quantify semantic fairness using a Coverage Disparity Index (CDI), which measures the alignment between coverage and error. Extensive experiments across multiple datasets demonstrate that SemCovNet enhances model reliability and substantially reduces CDI, achieving fairer and more equitable performance. This work establishes SCI as a measurable and correctable bias, providing a foundation for advancing semantic fairness and interpretable vision learning.", "AI": {"tldr": "作者表示语义覆盖率失衡（SCI）是现有数据集中的一个以前被忽视的偏差，提出SemCovNet纠正这一偏差，从而实现更公平的模型学习。", "motivation": "作者意识到现有数据集中的语义覆盖率失衡（SCI）问题，这可能导致模型对罕见但有意义的语义学习和推理存在问题。", "method": "本文提出了语义覆盖率感知网络（SemCovNet），该网络旨在纠正语义覆盖率差异。它包含语义描述图层（SDM）、描述注意力调制模块（DAM）和描述-视觉对齐损失（DVA）。", "result": "实验结果表明SemCovNet能够提高模型性能的公平性和均衡性。", "conclusion": "研究表明，通过SemCovNet能够提高模型的可靠性，并且显著降低覆盖率差异指数（CDI），从而实现更为公平和均衡的模型性能。"}}
{"id": "2602.16811", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16811", "abs": "https://arxiv.org/abs/2602.16811", "authors": ["Charalampos Mastrokostas", "Nikolaos Giarelis", "Nikos Karacapilidis"], "title": "Evaluating Monolingual and Multilingual Large Language Models for Greek Question Answering: The DemosQA Benchmark", "comment": null, "summary": "Recent advancements in Natural Language Processing and Deep Learning have enabled the development of Large Language Models (LLMs), which have significantly advanced the state-of-the-art across a wide range of tasks, including Question Answering (QA). Despite these advancements, research on LLMs has primarily targeted high-resourced languages (e.g., English), and only recently has attention shifted toward multilingual models. However, these models demonstrate a training data bias towards a small number of popular languages or rely on transfer learning from high- to under-resourced languages; this may lead to a misrepresentation of social, cultural, and historical aspects. To address this challenge, monolingual LLMs have been developed for under-resourced languages; however, their effectiveness remains less studied when compared to multilingual counterparts on language-specific tasks. In this study, we address this research gap in Greek QA by contributing: (i) DemosQA, a novel dataset, which is constructed using social media user questions and community-reviewed answers to better capture the Greek social and cultural zeitgeist; (ii) a memory-efficient LLM evaluation framework adaptable to diverse QA datasets and languages; and (iii) an extensive evaluation of 11 monolingual and multilingual LLMs on 6 human-curated Greek QA datasets using 3 different prompting strategies. We release our code and data to facilitate reproducibility.", "AI": {"tldr": "本研究创建了DemosQA数据集，提出了一种适应多种QA数据集和语言的低内存消耗的LLM评估框架，并对多个单语和多语LLM在希腊语QA任务上进行了详尽评估。", "motivation": "现有LLM研究主要集中在高资源语言上，对于多语言模型的关注较少，并且这些模型存在训练数据偏向于几种流行语言或依赖于从高资源语言向低资源语言的迁移学习，这可能导致社会、文化和历史方面的表述不准确。因此，本研究关注单语LLM在低资源语言问题上的表现，特别是希腊语的问答任务。", "method": "研究通过创建DemosQA数据集来解决希腊语问题解答任务中的资源匮乏问题，该数据集由社交媒体中的用户提问和社区审查的答案组成。此外，研究还提出了一种适应多种QA数据集和语言的低内存消耗的LLM评估框架，并对11个单语和多语LLM在6个人类编译的希腊语QA数据集上使用了3种不同的提示策略进行详尽评估。", "result": "通过对11个单语和多语大型语言模型使用三种不同的提示策略进行评估，研究发现单语模型在某些情况下表现优于多语模型，特别是在DemosQA数据集上，这表明特定语言的单语模型可能更适合该语言的特定任务。", "conclusion": "本研究深入探讨了单语LLM在低资源语言如希腊语的QA任务中的表现，通过DemosQA数据集和定制的评估框架，为后续研究提供了重要的参考和基础。"}}
{"id": "2602.16918", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16918", "abs": "https://arxiv.org/abs/2602.16918", "authors": ["Shlok Mishra", "Tsung-Yu Lin", "Linda Wang", "Hongli Xu", "Yimin Liu", "Michael Hsu", "Chaitanya Ahuja", "Hao Yuan", "Jianpeng Cheng", "Hong-You Chen", "Haoyuan Xu", "Chao Li", "Abhijeet Awasthi", "Jihye Moon", "Don Husa", "Michael Ge", "Sumedha Singla", "Arkabandhu Chowdhury", "Phong Dingh", "Satya Narayan Shukla", "Yonghuan Yang", "David Jacobs", "Qi Guo", "Jun Xiao", "Xiangjun Fan", "Aashu Singh"], "title": "Xray-Visual Models: Scaling Vision models on Industry Scale Data", "comment": null, "summary": "We present Xray-Visual, a unified vision model architecture for large-scale image and video understanding trained on industry-scale social media data. Our model leverages over 15 billion curated image-text pairs and 10 billion video-hashtag pairs from Facebook and Instagram, employing robust data curation pipelines that incorporate balancing and noise suppression strategies to maximize semantic diversity while minimizing label noise. We introduce a three-stage training pipeline that combines self-supervised MAE, semi-supervised hashtag classification, and CLIP-style contrastive learning to jointly optimize image and video modalities. Our architecture builds on a Vision Transformer backbone enhanced with efficient token reorganization (EViT) for improved computational efficiency. Extensive experiments demonstrate that Xray-Visual achieves state-of-the-art performance across diverse benchmarks, including ImageNet for image classification, Kinetics and HMDB51 for video understanding, and MSCOCO for cross-modal retrieval. The model exhibits strong robustness to domain shift and adversarial perturbations. We further demonstrate that integrating large language models as text encoders (LLM2CLIP) significantly enhances retrieval performance and generalization capabilities, particularly in real-world environments. Xray-Visual establishes new benchmarks for scalable, multimodal vision models, while maintaining superior accuracy and computational efficiency.", "AI": {"tldr": "提出Xray-Visual模型，通过大规模社交媒体数据和先进的训练技术，实现了图像和视频理解的最新性能，并提高了泛化能力。", "motivation": "推动多模态视觉模型的发展，通过利用大规模的图像和视频数据来提高模型的性能，同时保持高精度和计算效率。", "method": "提出了一种名为Xray-Visual的统一视觉模型架构，用于大规模图像和视频理解。模型基于超过150亿个精心挑选的图像-文本配对和100亿个视频-标签配对的工业规模社交媒体数据进行训练。采用三阶段训练管线，包括自我监督的掩码自动编码器（MAE）、半监督的标签分类以及基于CLIP的对比学习，以同时优化图像和视频模态。该架构基于视觉变换器（Vision Transformer）骨干网，优化了计算效率。此外，集成大型语言模型（LLM2CLIP）作为文本编码器，进一步增强了检索性能和泛化能力。", "result": "实验表明，Xray-Visual在ImageNet、Kinetics、HMDB51等基准测试中取得了最先进的性能，并在真实世界环境中展现出强大的稳健性和泛化能力。", "conclusion": "Xray-Visual设立多模态视觉模型的新基准，提高了准确性和计算效率。通过引入大型语言模型，进一步加强了其在跨模态检索和泛化领域的性能。"}}
{"id": "2602.16813", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16813", "abs": "https://arxiv.org/abs/2602.16813", "authors": ["Chanhyuk Lee", "Jaehoon Yoo", "Manan Agarwal", "Sheel Shah", "Jerry Huang", "Aditi Raghunathan", "Seunghoon Hong", "Nicholas M. Boffi", "Jinwoo Kim"], "title": "One-step Language Modeling via Continuous Denoising", "comment": "39 pages, 17 figures", "summary": "Language models based on discrete diffusion have attracted widespread interest for their potential to provide faster generation than autoregressive models. In practice, however, they exhibit a sharp degradation of sample quality in the few-step regime, failing to realize this promise. Here we show that language models leveraging flow-based continuous denoising can outperform discrete diffusion in both quality and speed. By revisiting the fundamentals of flows over discrete modalities, we build a flow-based language model (FLM) that performs Euclidean denoising over one-hot token encodings. We show that the model can be trained by predicting the clean data via a cross entropy objective, where we introduce a simple time reparameterization that greatly improves training stability and generation quality. By distilling FLM into its associated flow map, we obtain a distilled flow map language model (FMLM) capable of few-step generation. On the LM1B and OWT language datasets, FLM attains generation quality matching state-of-the-art discrete diffusion models. With FMLM, our approach outperforms recent few-step language models across the board, with one-step generation exceeding their 8-step quality. Our work calls into question the widely held hypothesis that discrete diffusion processes are necessary for generative modeling over discrete modalities, and paves the way toward accelerated flow-based language modeling at scale. Code is available at https://github.com/david3684/flm.", "AI": {"tldr": "研究展示了一种基于流的语言模型（FLM）和精炼流图语言模型（FMLM），在生成质量和速度上均优于离散扩散模型，挑战了离散扩散过程在离散模态生成建模中必要性的假设。", "motivation": "尽管基于离散扩散的语言模型吸引了广泛关注，但它们在少量步骤生成时的质量会急剧下降。因此，研究提出了一种基于流的连续去噪方法来改善语言生成的质量和速度。", "method": "通过重新审视离散模态上的流的基本原理，构建了一种基于流的语言模型（FLM），该模型对one-hot令牌编码执行欧式去噪。模型可以通过预测干净数据的交叉熵目标进行训练，在此过程中引入了一种简单的时间重新参数化技术，显著提高了训练稳定性和生成质量。通过将FLM知识蒸馏到其相关流图中，获得了能够进行少量步骤生成的精炼流图语言模型（FMLM）.", "result": "在LM1B和OWT语言数据集上，FLM的生成质量达到了离散扩散模型的顶级水平；使用FMLM，研究方法在各个不同步骤的生成上表现均优于近期的少量步骤语言模型，实现了一步生成超过其八步的质量水平。", "conclusion": "该研究提出了能够在少量步骤生成高质量文本的加速基于流的语言模型，挑战了离散扩散过程在离散模态生成建模中必要性的传统观点，为大规模加速流式语言建模铺平了道路。"}}
{"id": "2602.16950", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2602.16950", "abs": "https://arxiv.org/abs/2602.16950", "authors": ["Kibon Ku", "Talukder Z. Jubery", "Adarsh Krishnamurthy", "Baskar Ganapathysubramanian"], "title": "HS-3D-NeRF: 3D Surface and Hyperspectral Reconstruction From Stationary Hyperspectral Images Using Multi-Channel NeRFs", "comment": "16 pages, 14 figures, 3 tables", "summary": "Advances in hyperspectral imaging (HSI) and 3D reconstruction have enabled accurate, high-throughput characterization of agricultural produce quality and plant phenotypes, both essential for advancing agricultural sustainability and breeding programs. HSI captures detailed biochemical features of produce, while 3D geometric data substantially improves morphological analysis. However, integrating these two modalities at scale remains challenging, as conventional approaches involve complex hardware setups incompatible with automated phenotyping systems. Recent advances in neural radiance fields (NeRF) offer computationally efficient 3D reconstruction but typically require moving-camera setups, limiting throughput and reproducibility in standard indoor agricultural environments. To address these challenges, we introduce HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for high-throughput hyperspectral 3D reconstruction targeting postharvest inspection of agricultural produce. Multi-view hyperspectral data is captured using a stationary camera while the object rotates within a custom-built Teflon imaging chamber providing diffuse, uniform illumination. Object poses are estimated via ArUco calibration markers and transformed to the camera frame of reference through simulated pose transformations, enabling standard NeRF training on stationary-camera data. A multi-channel NeRF formulation optimizes reconstruction across all hyperspectral bands jointly using a composite spectral loss, supported by a two-stage training protocol that decouples geometric initialization from radiometric refinement. Experiments on three agricultural produce samples demonstrate high spatial reconstruction accuracy and strong spectral fidelity across the visible and near-infrared spectrum, confirming the suitability of HSI-SC-NeRF for integration into automated agricultural workflows.", "AI": {"tldr": "The paper introduces HSI-SC-NeRF, a stationary-camera multi-channel NeRF framework for efficient, high-throughput hyperspectral 3D reconstruction of agricultural produce, enhancing postharvest inspection.", "motivation": "The motivation behind the paper is to integrate hyperspectral imaging (HSI) and 3D reconstruction techniques for the accurate and high-throughput characterization of agricultural produce and plant phenotypes, while addressing the challenges associated with current complex hardware setups and moving-camera requirements of traditional NeRF techniques that limit their feasibility in routine agricultural environments.", "method": "HSI-SC-NeRF framework uses a stationary camera to capture multi-view hyperspectral data of rotating agricultural produce within an imaging chamber. It employs simulated pose transformations of calibration markers and a composite spectral loss in a multi-channel NeRF formulation to achieve high spatial and spectral fidelity. The training consists of a two-stage protocol that first initializes the geometry and then refines the radiometric details.", "result": "Experiments on three agricultural produce samples show high spatial reconstruction accuracy and spectral fidelity throughout the visible and near-infrared spectrum, confirming the viability of the HSI-SC-NeRF approach for automated agricultural inspection systems.", "conclusion": "The HSI-SC-NeRF framework represents a promising solution for high-throughput hyperspectral 3D reconstruction suitable for postharvest inspection of agricultural produce, offering an efficient alternative to existing methods with complex setup and operational constraints."}}
{"id": "2602.16836", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16836", "abs": "https://arxiv.org/abs/2602.16836", "authors": ["Zhengda Mo", "Zhiyu Quan", "Eli O'Donohue", "Kaiwen Zhong"], "title": "Claim Automation using Large Language Model", "comment": "46 pages, 12 figures. Code and data processing pipeline described", "summary": "While Large Language Models (LLMs) have achieved strong performance on general-purpose language tasks, their deployment in regulated and data-sensitive domains, including insurance, remains limited. Leveraging millions of historical warranty claims, we propose a locally deployed governance-aware language modeling component that generates structured corrective-action recommendations from unstructured claim narratives. We fine-tune pretrained LLMs using Low-Rank Adaptation (LoRA), scoping the model to an initial decision module within the claim processing pipeline to speed up claim adjusters' decisions. We assess this module using a multi-dimensional evaluation framework that combines automated semantic similarity metrics with human evaluation, enabling a rigorous examination of both practical utility and predictive accuracy. Our results show that domain-specific fine-tuning substantially outperforms commercial general-purpose and prompt-based LLMs, with approximately 80% of the evaluated cases achieving near-identical matches to ground-truth corrective actions. Overall, this study provides both theoretical and empirical evidence to prove that domain-adaptive fine-tuning can align model output distributions more closely with real-world operational data, demonstrating its promise as a reliable and governable building block for insurance applications.", "AI": {"tldr": "本文研究了一个从保修索赔中的非结构化叙述生成结构化纠正行动建议的本地化治理意识型语言模型部件，结果表明，领域适应性微调大大提升了性能，接近实际运营数据，具有作为保险应用可靠且可控构件的潜力。", "motivation": "尽管大型语言模型（LLMs）在通用语言任务上表现出色，但在保险等监管和数据敏感领域中的部署仍然受限。为此，我们研究了将LLMs本地化部署，生成结构化纠正行动建议的可行性。", "method": "通过使用数百万份历史保修索赔记录，我们提出了一个本地部署的、考虑治理的语言模型部件，该部件可以从非结构化的索赔叙述中生成结构化的纠正行动建议。通过使用Low-Rank Adaptation（LoRA）对预训练的语言模型进行领域适应性微调，将模型范围限制在索赔处理管道中的初始决策模块，以加快索赔调整者的决策过程。", "result": "评估结果表明，领域特定的微调显著优于商业通用和提示驱动的语言模型，在评估案例中约有80%的案例可以实现与地面实况纠正行动几乎一致的匹配结果。", "conclusion": "本研究提供了理论和实证证据，证明领域适应性微调可以使模型输出分布更加接近现实世界的运营数据，使其作为保险应用的可靠和可控组件具有很大潜力。"}}
{"id": "2602.16968", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.16968", "abs": "https://arxiv.org/abs/2602.16968", "authors": ["Dahye Kim", "Deepti Ghadiyaram", "Raghudeep Gadde"], "title": "DDiT: Dynamic Patch Scheduling for Efficient Diffusion Transformers", "comment": null, "summary": "Diffusion Transformers (DiTs) have achieved state-of-the-art performance in image and video generation, but their success comes at the cost of heavy computation. This inefficiency is largely due to the fixed tokenization process, which uses constant-sized patches throughout the entire denoising phase, regardless of the content's complexity. We propose dynamic tokenization, an efficient test-time strategy that varies patch sizes based on content complexity and the denoising timestep. Our key insight is that early timesteps only require coarser patches to model global structure, while later iterations demand finer (smaller-sized) patches to refine local details. During inference, our method dynamically reallocates patch sizes across denoising steps for image and video generation and substantially reduces cost while preserving perceptual generation quality. Extensive experiments demonstrate the effectiveness of our approach: it achieves up to $3.52\\times$ and $3.2\\times$ speedup on FLUX-1.Dev and Wan $2.1$, respectively, without compromising the generation quality and prompt adherence.", "AI": {"tldr": "研究提出动态分块策略以优化扩散变压器的计算效率，实现了显著的速度提升，同时保持图像和视频生成的质量。", "motivation": "尽管扩散变压器（DiTs）在图像和视频生成中表现出色，但其计算成本较高。这项研究旨在通过改进的分块策略来解决这一问题，提高生成效率而不牺牲质量。", "method": "本研究提出了动态分块技术，它是一种高效的测试阶段策略，可以根据内容的复杂性和去噪时间步长来改变块的大小。该方法的关键见解是在早期时间步段只需要较大的块来建模全局结构，而在后续的迭代中需要更细的块来细化局部细节。", "result": "实验表明，该方法在FLUX-1.Dev和Wan $2.1$数据集上分别能够实现最高$3.52\times$和$3.2\times$的速度提升，同时保持生成的质量和遵循提示的准确性。", "conclusion": "通过动态调整块的大小，该研究提出了一种能显著减少计算成本并维持感知生成质量的新方法。"}}
{"id": "2602.16843", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2602.16843", "abs": "https://arxiv.org/abs/2602.16843", "authors": ["Ahmed Rafid", "Rumman Adib", "Fariya Ahmed", "Ajwad Abrar", "Mohammed Saidul Islam"], "title": "BanglaSummEval: Reference-Free Factual Consistency Evaluation for Bangla Summarization", "comment": "Accepted in 2nd LoResLM at EACL 2026", "summary": "Evaluating factual consistency is essential for reliable text summarization, particularly in high-stakes domains such as healthcare and news. However, most existing evaluation metrics overlook Bangla, a widely spoken yet under-resourced language, and often depend on reference summaries. We introduce BanglaSummEval, a reference-free, question-answering-based framework for evaluating factual consistency in Bangla summarization. The proposed method assesses both factual accuracy and content coverage through automatically generated questions and answers derived from the source document and the summary. A single multilingual instruction-tuned language model handles question generation, question answering, candidate answer extraction, and question importance weighting. This unified design reduces system complexity and computational cost. To capture semantic consistency beyond surface-level overlap, we use BERTScore-Recall for answer comparison. We validate BanglaSummEval on 300 human-written summaries from educational and medical domains, demonstrating strong correlation with expert human judgments (Pearson's $r = 0.694$, Spearman's $ρ= 0.763$). By providing interpretable, step-wise diagnostics alongside reliable evaluation scores, BanglaSummEval offers a practical and transparent solution for factual consistency evaluation in low-resource language settings.", "AI": {"tldr": "引入BanglaSummEval框架，用于孟加拉语事实一致性的评估，证明了它与人类评判的一致性，并为低资源语言的事实一致性评估提供了实用和透明的解决方案。", "motivation": "评估文本摘要的事实一致性在如医疗和新闻等高风险领域尤为重要，但大多数现有评估指标忽视了孟加拉语这种广泛使用的资源较少的语言，并且通常依赖参考摘要。", "method": "介绍了一种无参考、基于问题回答的框架BanglaSummEval，用于评估孟加拉语摘要中的事实一致性。该方法通过从源文档和摘要中自动生成问题和答案来评估事实准确性和内容覆盖率。单一的多语言指令调整语言模型负责问题生成、问题回答、候选答案提取和问题重要性加权。使用BERTScore-Recall进行超越表面重叠的语义一致性捕捉。", "result": "在来自教育和医疗领域的300个人类编写的摘要上验证BanglaSummEval，显示与专家人类判断有很强的相关性(Pearson's $r = 0.694$, Spearman's $ρ= 0.763$)。", "conclusion": "BanglaSummEval为低资源语言环境下的事实一致性评估提供了实用且透明的解决方案。它可以进行可解释的逐步诊断，并提供可靠的评估分数。"}}
{"id": "2602.16979", "categories": ["cs.CV", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.16979", "abs": "https://arxiv.org/abs/2602.16979", "authors": ["Divyam Madaan", "Sumit Chopra", "Kyunghyun Cho"], "title": "Characterizing the Predictive Impact of Modalities with Supervised Latent-Variable Modeling", "comment": null, "summary": "Despite the recent success of Multimodal Large Language Models (MLLMs), existing approaches predominantly assume the availability of multiple modalities during training and inference. In practice, multimodal data is often incomplete because modalities may be missing, collected asynchronously, or available only for a subset of examples. In this work, we propose PRIMO, a supervised latent-variable imputation model that quantifies the predictive impact of any missing modality within the multimodal learning setting. PRIMO enables the use of all available training examples, whether modalities are complete or partial. Specifically, it models the missing modality through a latent variable that captures its relationship with the observed modality in the context of prediction. During inference, we draw many samples from the learned distribution over the missing modality to both obtain the marginal predictive distribution (for the purpose of prediction) and analyze the impact of the missing modalities on the prediction for each instance. We evaluate PRIMO on a synthetic XOR dataset, Audio-Vision MNIST, and MIMIC-III for mortality and ICD-9 prediction. Across all datasets, PRIMO obtains performance comparable to unimodal baselines when a modality is fully missing and to multimodal baselines when all modalities are available. PRIMO quantifies the predictive impact of a modality at the instance level using a variance-based metric computed from predictions across latent completions. We visually demonstrate how varying completions of the missing modality result in a set of plausible labels.", "AI": {"tldr": "PRIMO is a model that handles missing modalities in multimodal data by using latent-variable imputation to quantify the impact of these missing modalities on predictions.", "motivation": "The current approaches for MLLMs presuppose complete multimodal data, but in real-world scenarios, data can be incomplete. PRIMO addresses this issue by allowing for the use of partial multimodal examples.", "method": "Structure", "result": "{ \"tldr\": \"PRIMO is a model that handles missing modalities in multimodal data by using latent-variable imputation to quantify the impact of these missing modalities on predictions.\", \"motivation\": \"The current approaches for MLLMs presuppose complete multimodal data, but in real-world scenarios, data can be incomplete. PRIMO addresses this issue by allowing for the use of partial multimodal examples.\", \"method\": \"PRIMO uses a latent variable to model the missing modality, considering its relationship with the observed modality. During inference, multiple samples are drawn from the learned distribution of the missing modality to evaluate the marginal predictive distribution.\", \"result\": \"PRIMO displays comparable performance to unimodal baselines when a modality is missing and to multimodal baselines when all modalities are present. It quantifies the predictive impact of a missing modality using a variance-based metric.\", \"conclusion\": \"PRIMO demonstrates the potential of handling incomplete multimodal data effectively, potentially broadening the applicability of multimodal models.\"]}", "conclusion": "PRIMO demonstrates the potential of handling incomplete multimodal data effectively, potentially broadening the applicability of multimodal models."}}
