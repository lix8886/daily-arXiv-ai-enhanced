{"id": "2508.08317", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2508.08317", "abs": "https://arxiv.org/abs/2508.08317", "authors": ["Saptarshi Banerjee", "Tausif Mallick", "Amlan Chakroborty", "Himadri Nath Saha", "Nityananda T. Takur"], "title": "Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection", "comment": "AI/ML, Computer Vision", "summary": "Addressing plant diseases and pests is critical for enhancing crop production\nand preventing economic losses. Recent advances in artificial intelligence\n(AI), machine learning (ML), and deep learning (DL) have significantly improved\nthe precision and efficiency of detection methods, surpassing the limitations\nof manual identification. This study reviews modern computer-based techniques\nfor detecting plant diseases and pests from images, including recent AI\ndevelopments. The methodologies are organized into five categories:\nhyperspectral imaging, non-visualization techniques, visualization approaches,\nmodified deep learning architectures, and transformer models. This structured\ntaxonomy provides researchers with detailed, actionable insights for selecting\nadvanced state-of-the-art detection methods. A comprehensive survey of recent\nwork and comparative studies demonstrates the consistent superiority of modern\nAI-based approaches, which often outperform older image analysis methods in\nspeed and accuracy. In particular, vision transformers such as the Hierarchical\nVision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease\ndetection, outperforming architectures like MobileNetV3. The study concludes by\ndiscussing system design challenges, proposing solutions, and outlining\npromising directions for future research.", "AI": {"tldr": "研究了基于计算机的植物病害和害虫图像检测技术，现代AI方法如视觉变压器（HvT）在准确性和速度上优于传统方法。", "motivation": "提高作物产量并防止经济损失，通过人工识别的限制优化植物病害和害虫识别方法。", "method": "结构化分析方法，包括五大类：高光谱成像、非可视化技术、可视化方法、修改后的深度学习架构和变压器模型。", "result": "现代AI技术如视觉变压器（HvT）的准确率超过99.3%，展示出了超高的检测精度。", "conclusion": "讨论了系统设计挑战，并提出了解决方案和未来研究方向。"}}
{"id": "2508.08338", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2508.08338", "abs": "https://arxiv.org/abs/2508.08338", "authors": ["Yuqin He", "Tengfei Ma", "Chaoyi Li", "Pengsen Ma", "Hongxin Xiang", "Jianmin Wang", "Yiping Liu", "Bosheng Song", "Xiangxiang Zeng"], "title": "ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction", "comment": "Accepted By Information Fusion", "summary": "To mitigate the potential adverse health effects of simultaneous multi-drug\nuse, including unexpected side effects and interactions, accurately identifying\nand predicting drug-drug interactions (DDIs) is considered a crucial task in\nthe field of deep learning. Although existing methods have demonstrated\npromising performance, they suffer from the bottleneck of limited functional\nmotif-based representation learning, as DDIs are fundamentally caused by motif\ninteractions rather than the overall drug structures. In this paper, we propose\nan Image-enhanced molecular motif sequence representation framework for\n\\textbf{DDI} prediction, called ImageDDI, which represents a pair of drugs from\nboth global and local structures. Specifically, ImageDDI tokenizes molecules\ninto functional motifs. To effectively represent a drug pair, their motifs are\ncombined into a single sequence and embedded using a transformer-based encoder,\nstarting from the local structure representation. By leveraging the\nassociations between drug pairs, ImageDDI further enhances the spatial\nrepresentation of molecules using global molecular image information (e.g.\ntexture, shadow, color, and planar spatial relationships). To integrate\nmolecular visual information into functional motif sequence, ImageDDI employs\nAdaptive Feature Fusion, enhancing the generalization of ImageDDI by\ndynamically adapting the fusion process of feature representations.\nExperimental results on widely used datasets demonstrate that ImageDDI\noutperforms state-of-the-art methods. Moreover, extensive experiments show that\nImageDDI achieved competitive performance in both 2D and 3D image-enhanced\nscenarios compared to other models.", "AI": {"tldr": "本文提出了一个增强型分子基序序列表示框架ImageDDI，用于准确预测药物-药物相互作用，通过结合局部结构和全局分子图像信息来增强模型性能，实验结果表明，ImageDDI优于当前最先进的方法。", "motivation": "现有的药物相互作用预测方法受限于基于功能基序的表征学习，本文希望通过整合局部和全局图象信息来增强模型的表征能力，以提高预测准确性。", "method": "本文提出的方法ImageDDI通过药物分子的功能基序进行标记，结合局部与全局的分子图象信息，采用基于Transformer的编码器进行嵌入，并利用自适应特征融合方法将分子视觉信息与功能基序序列整合。", "result": "实验结果表明，ImageDDI在广泛接受的数据集上超越了现有的先进方法，在2D和3D图像增强场景中均表现出较强的竞争性能。", "conclusion": "ImageDDI通过结合功能基序与分子的图象信息，提出了一个有效的药物药物相互作用预测框架，并展示了其在性能上的优势。"}}
{"id": "2508.08352", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2508.08352", "abs": "https://arxiv.org/abs/2508.08352", "authors": ["Christophe EL Zeinaty", "Wassim Hamidouche", "Glenn Herrou", "Daniel Menard"], "title": "Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions", "comment": null, "summary": "Object detection (OD) has become vital for numerous computer vision\napplications, but deploying it on resource-constrained IoT devices presents a\nsignificant challenge. These devices, often powered by energy-efficient\nmicrocontrollers, struggle to handle the computational load of deep\nlearning-based OD models. This issue is compounded by the rapid proliferation\nof IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a\ncompelling solution by enabling OD on ultra-low-power devices, paving the way\nfor efficient and real-time processing at the edge. Although numerous survey\npapers have been published on this topic, they often overlook the optimization\nchallenges associated with deploying OD models in TinyML environments. To\naddress this gap, this survey paper provides a detailed analysis of key\noptimization techniques for deploying OD models on resource-constrained\ndevices. These techniques include quantization, pruning, knowledge\ndistillation, and neural architecture search. Furthermore, we explore both\ntheoretical approaches and practical implementations, bridging the gap between\nacademic research and real-world edge artificial intelligence deployment.\nFinally, we compare the key performance indicators (KPIs) of existing OD\nimplementations on microcontroller devices, highlighting the achieved maturity\nlevel of these solutions in terms of both prediction accuracy and efficiency.\nWe also provide a public repository to continually track developments in this\nfast-evolving field:\nhttps://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.", "AI": {"tldr": "本文着眼于优化TinyML环境下资源受限设备上目标检测模型的技术，比较了各方法的性能，并提供了公共库以追踪此领域的持续发展。", "motivation": "鉴于部署深度学习目标检测模型到资源受限的IoT设备上的重大挑战，以及此类设备数量的快速增长，研究优化技术变得尤为重要。", "method": "分析物联网设备在运行基于深度学习的目标检测模型时面临的计算负载挑战，探讨通过量化、剪枝、知识蒸馏和神经架构搜索等关键技术优化目标检测模型的方法。", "result": "该调查论文详细分析了在资源受限的设备上部署目标检测模型的关键优化技术，并通过性能指标（KPIs）比较现有的目标检测实现方法。", "conclusion": "论文填补了TinyML环境下目标检测模型部署优化挑战的分析空白，为学术研究与实际边缘人工智能部署架起了桥梁。"}}
