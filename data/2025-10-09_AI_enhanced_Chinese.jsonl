{"id": "2510.06239", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.06239", "abs": "https://arxiv.org/abs/2510.06239", "authors": ["Pranav Gupta"], "title": "OpenStaxQA: A multilingual dataset based on open-source college textbooks", "comment": null, "summary": "We present OpenStaxQA, an evaluation benchmark specific to college-level\neducational applications based on 43 open-source college textbooks in English,\nSpanish, and Polish, available under a permissive Creative Commons license. We\nfinetune and evaluate large language models (LLMs) with approximately 7 billion\nparameters on this dataset using quantized low rank adapters (QLoRa).\nAdditionally we also perform a zero-shot evaluation on the AI2 reasoning\nchallenge dev dataset in order to check if OpenStaxQA can lead to an improved\nperformance on other tasks. We also discuss broader impacts relevant to\ndatasets such as OpenStaxQA.", "AI": {"tldr": "研究介绍了OpenStaxQA基准测试，通过在该数据集上微调和评估语言模型，并进行零样本任务评估，来改进和评估大学水平教育应用的性能。", "motivation": "我们的动机是创建一个专门针对大学水平教育应用的评估基准OpenStaxQA，基于43本开放源代码的大学教科书，这些教科书用英语、西班牙语和波兰语撰写，并在许可的Creative Commons许可下提供。", "method": "我们通过在OpenStaxQA数据集上使用量化低秩适配器(QLoRa)微调和评估具有大约70亿参数的大型语言模型(LLMs)，来展示OpenStaxQA基准测试。此外，我们还对AI2推理挑战开发数据集进行了零样本评估，以检验OpenStaxQA是否能够提高其他任务的性能。", "result": "结果表明，通过OpenStaxQA基准测试，我们可以评估和改进大型语言模型在教育应用中的性能，并检查其在其他任务上的潜在零样本学习能力。", "conclusion": "结论是，OpenStaxQA不仅为评估和改进大型语言模型提供了基准，而且还讨论了与OpenStaxQA相关的更广泛的影响，从而有助于理解和改善教育领域的人工智能应用。"}}
