<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 17]
- [cs.CV](#cs.CV) [Total: 13]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [How Deep Is Representational Bias in LLMs? The Cases of Caste and Religion](https://arxiv.org/abs/2508.03712)
*Agrima Seth,Monojit Choudhary,Sunayana Sitaram,Kentaro Toyama,Aditya Vashistha,Kalika Bali*

Main category: cs.CL

> 作者通过生成故事审计GPT-4 Turbo，发现其对文化主导群体存在过度代表的偏见，这表明仅依赖训练数据多样化的解决方案可能不足以纠正偏见，需进行更根本的模型开发变化。

<details>
  <summary>Details</summary>

**Motivation:** 扩展当前关于语言模型代表性偏见的研究，该研究主要集中在单一响应交互和针对全球北部中心身份的研究上，作者希望通过拓宽维度来探索身份偏见。

**Method:** 通过系统审计GPT-4 Turbo，生成超过7,200个关于印度重大生活事件（如婚礼）的故事，用不同程度鼓励多样性的提示来评估语言模型中的代表性偏见。

**Result:** 研究发现GPT-4的响应会过度代表文化主导群体，尽管提示设计旨在鼓励代表性多样性，这一发现表明语言模型中的代表性偏见具有赢家通吃的特性，并且提示调整偏见的效果有限且不一致。

**Conclusion:** 研究结果表明，仅依赖训练数据多样化可能不足以纠正语言模型的偏见，需要在模型开发上进行更根本的改变。

**Abstract:** Representational bias in large language models (LLMs) has predominantly been
measured through single-response interactions and has focused on Global
North-centric identities like race and gender. We expand on that research by
conducting a systematic audit of GPT-4 Turbo to reveal how deeply encoded
representational biases are and how they extend to less-explored dimensions of
identity. We prompt GPT-4 Turbo to generate over 7,200 stories about
significant life events (such as weddings) in India, using prompts designed to
encourage diversity to varying extents. Comparing the diversity of religious
and caste representation in the outputs against the actual population
distribution in India as recorded in census data, we quantify the presence and
"stickiness" of representational bias in the LLM for religion and caste. We
find that GPT-4 responses consistently overrepresent culturally dominant groups
far beyond their statistical representation, despite prompts intended to
encourage representational diversity. Our findings also suggest that
representational bias in LLMs has a winner-take-all quality that is more biased
than the likely distribution bias in their training data, and repeated
prompt-based nudges have limited and inconsistent efficacy in dislodging these
biases. These results suggest that diversifying training data alone may not be
sufficient to correct LLM bias, highlighting the need for more fundamental
changes in model development. Dataset and Codebook:
https://github.com/agrimaseth/How-Deep-Is-Representational-Bias-in-LLMs

</details>


### [2] [FeynTune: Large Language Models for High-Energy Theory](https://arxiv.org/abs/2508.03716)
*Paul Richmond,Prarit Agarwal,Borun Chowdhury,Vasilis Niarchos,Constantinos Papageorgakis*

Main category: cs.CL

> 本文介绍了基于Llama-3.1模型微调的20种专门针对高能理论物理学的大型语言模型，并进行了性能评估和对比研究。

<details>
  <summary>Details</summary>

**Motivation:** 旨在开发针对高能理论物理学的专门大规模语言模型，以提高在特定领域的表现。

**Method:** 使用了两种不同的低秩适应微调方法，并基于不同大小的数据集对80亿参数的Llama-3.1模型进行了20种变体的微调，这些数据集包括hep-th, hep-ph, gr-qc以及q-bio, cs领域的arXiv摘要。

**Result:** 微调后的模型在hep-th摘要完成任务上优于基础模型，并且与领先的商用LLMs（ChatGPT, Claude, Gemini, DeepSeek）进行了性能比较。

**Conclusion:** 研究为开发针对高能理论物理学的专门语言模型提供了见解。

**Abstract:** We present specialized Large Language Models for theoretical High-Energy
Physics, obtained as 20 fine-tuned variants of the 8-billion parameter
Llama-3.1 model. Each variant was trained on arXiv abstracts (through August
2024) from different combinations of hep-th, hep-ph and gr-qc. For a
comparative study, we also trained models on datasets that contained abstracts
from disparate fields such as the q-bio and cs categories. All models were
fine-tuned using two distinct Low-Rank Adaptation fine-tuning approaches and
varying dataset sizes, and outperformed the base model on hep-th abstract
completion tasks. We compare performance against leading commercial LLMs
(ChatGPT, Claude, Gemini, DeepSeek) and derive insights for further developing
specialized language models for High-Energy Theoretical Physics.

</details>


### [3] [Intent Aware Context Retrieval for Multi-Turn Agricultural Question Answering](https://arxiv.org/abs/2508.03719)
*Abhay Vijayvargia,Ajay Nagpal,Kundeshwar Pundalik,Atharva Savarkar,Smita Gautam,Pankaj Singh,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

> 本文介绍了一种名为Krishi Sathi的AI驱动的农业聊天机器人，旨在通过文本和语音提供个性化和易于理解的回答，以解决印度农民获取及时、易于理解和语言友好的农业建议的问题。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决印度农民获取农业建议时所面临的及时性、可获取性和语言友好性不足的问题，尤其是低识字率的农村地区。

**Method:** 采用了一种基于IFT模型的AI驱动聊天机器人，该模型经过印度农业领域数据的微调优化。聊天机器人采用多轮对话流程，通过意图驱动对话流、指令微调模型和检索增强生成（RAG）方法提供个性化、易于理解的回答。

**Result:** 该系统在英语和印地语互动中均实现了97.53%的查询响应准确率，91.35%的语境相关性和个性化，以及97.53%的查询完成率。平均响应时间保持在6秒以下，确保了用户的及时支持。

**Conclusion:** 展示了如何通过结合意图驱动对话流、指令调优模型和检索增强生成（RAG）来提高印度农业数字支持的质量和可访问性。

**Abstract:** Indian farmers often lack timely, accessible, and language-friendly
agricultural advice, especially in rural areas with low literacy. To address
this gap in accessibility, this paper presents a novel AI-powered agricultural
chatbot, Krishi Sathi, designed to support Indian farmers by providing
personalized, easy-to-understand answers to their queries through both text and
speech. The system's intelligence stems from an IFT model, subsequently refined
through fine-tuning on Indian agricultural knowledge across three curated
datasets. Unlike traditional chatbots that respond to one-off questions, Krishi
Sathi follows a structured, multi-turn conversation flow to gradually collect
the necessary details from the farmer, ensuring the query is fully understood
before generating a response. Once the intent and context are extracted, the
system performs Retrieval-Augmented Generation (RAG) by first fetching
information from a curated agricultural database and then generating a tailored
response using the IFT model. The chatbot supports both English and Hindi
languages, with speech input and output features (via ASR and TTS) to make it
accessible for users with low literacy or limited digital skills. This work
demonstrates how combining intent-driven dialogue flows, instruction-tuned
models, and retrieval-based generation can improve the quality and
accessibility of digital agricultural support in India.
  This approach yielded strong results, with the system achieving a query
response accuracy of 97.53%, 91.35% contextual relevance and personalization,
and a query completion rate of 97.53%. The average response time remained under
6 seconds, ensuring timely support for users across both English and Hindi
interactions.

</details>


### [4] [Hierarchical Verification of Speculative Beams for Accelerating LLM Inference](https://arxiv.org/abs/2508.03726)
*Jaydip Sen,Harshitha Puvvala,Subhasis Dasgupta*

Main category: cs.CL

> 本文为处理大型语言模型在推理效率上遇到的瓶颈问题，提出了一种名为层次验证树（HVT）的新框架，通过优化推测性解码过程，成功减少了推理时间与能源消耗，并证明了这种方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）在自然语言处理任务上取得了显著成功，但它们由于自回归特性而在推理效率方面面临持续挑战。作者认为虽然推测性解码和束采样提供了显著改进，但传统方法没有优先级地顺序验证草案会导致不必要的计算开销。

**Method:** 本文提出了一种名为层次验证树（HVT）的新框架，该框架通过优先处理高似然草案并允许过早修剪次优候选来重新构建推测性束解码。

**Result:** 实验评估证明，HVT 在多个数据集和模型上始终超出现有推测性解码方案的表现，实现了显著的推理时间和能源消耗减少，同时保持或提高输出质量。

**Conclusion:** 研究凸显了层级验证策略作为一种加速大型语言模型推理的新策略的潜力。

**Abstract:** Large language models (LLMs) have achieved remarkable success across diverse
natural language processing tasks but face persistent challenges in inference
efficiency due to their autoregressive nature. While speculative decoding and
beam sampling offer notable improvements, traditional methods verify draft
sequences sequentially without prioritization, leading to unnecessary
computational overhead. This work proposes the Hierarchical Verification Tree
(HVT), a novel framework that restructures speculative beam decoding by
prioritizing high-likelihood drafts and enabling early pruning of suboptimal
candidates. Theoretical foundations and a formal verification-pruning algorithm
are developed to ensure correctness and efficiency. Integration with standard
LLM inference pipelines is achieved without requiring retraining or
architecture modification. Experimental evaluations across multiple datasets
and models demonstrate that HVT consistently outperforms existing speculative
decoding schemes, achieving substantial reductions in inference time and energy
consumption while maintaining or enhancing output quality. The findings
highlight the potential of hierarchical verification strategies as a new
direction for accelerating large language model inference.

</details>


### [5] [WINELL: Wikipedia Never-Ending Updating with LLM Agents](https://arxiv.org/abs/2508.03728)
*Revanth Gangi Reddy,Tanay Dixit,Jiaxin Qin,Cheng Qian,Daniel Lee,Jiawei Han,Kevin Small,Xing Fan,Ruhi Sarikaya,Heng Ji*

Main category: cs.CL

> 本文介绍了WiNELL，一个用于持续更新维基百科文章的代理框架，通过多代理框架收集信息并生成编辑建议，最终通过人工审核。

<details>
  <summary>Details</summary>

**Motivation:** 维基百科面临维持内容更新的问题，因为它依赖于手动编辑。受到NELL持续知识获取的启发，并利用基于语言模型的代理的进展，本文提出WiNELL框架。

**Method:** 采用多智能体框架，收集在线信息，选择目标实体的新颖和重要知识，并生成精确的编辑建议以供人工审核。编辑模型基于维基百科的人类编辑历史进行训练，以保持一致性。

**Result:** 编辑模型在关键信息覆盖和编辑效率方面优于开源指令跟随基线和闭源语言模型（如GPT-4o）。整体评估表明WiNELL框架有能力识别和建议及时事实更新。

**Conclusion:** WiNELL有助于自动更新知识库的研究方向，能够在不断进行的方式下保持知识基的更新。

**Abstract:** Wikipedia, a vast and continuously consulted knowledge base, faces
significant challenges in maintaining up-to-date content due to its reliance on
manual human editors. Inspired by the vision of continuous knowledge
acquisition in NELL and fueled by advances in LLM-based agents, this paper
introduces WiNELL, an agentic framework for continuously updating Wikipedia
articles. Our approach employs a multi-agent framework to aggregate online
information, select new and important knowledge for a target entity in
Wikipedia, and then generate precise edit suggestions for human review. Our
fine-grained editing models, trained on Wikipedia's extensive history of human
edits, enable incorporating updates in a manner consistent with human editing
behavior. Our editor models outperform both open-source instruction-following
baselines and closed-source LLMs (e.g., GPT-4o) in key information coverage and
editing efficiency. End-to-end evaluation on high-activity Wikipedia pages
demonstrates WiNELL's ability to identify and suggest timely factual updates.
This opens up a promising research direction in LLM agents for automatically
updating knowledge bases in a never-ending fashion.

</details>


### [6] [GanitBench: A bi-lingual benchmark for evaluating mathematical reasoning in Vision Language Models](https://arxiv.org/abs/2508.03737)
*Ashutosh Bandooni,Brindha Subburaj*

Main category: cs.CL

> 研究引入GanitBench，涵盖数学领域多个主题的视觉问题，并提供英语和印地语版本，以评估视觉语言模型（VLM）在非英语任务上的性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于现有的视觉语言模型（VLM）的基准测试往往是单语言的，大部分是英语，而且针对印地语的语料库缺乏，尤其是在非理解及翻译任务中。本研究旨在促进像印地语这样的语言在研究中的应用。

**Method:** 引入GanitBench，一个由1527个仅视觉问题构成的基准测试，涵盖数学领域的多个主题，并提供英语和印地语版本。这些问题来自JEE Advanced和CBSE Boards两项主要印度考试。评估了两个闭源模型在同一基准下的零样本链式思考（CoT）和两样本CoT设置中的表现。

**Result:** 在零样本CoT和两样本CoT设置中，GPT-4o mini在基准中的表现更佳，最高的平均准确率为38.15%。通过“双重锁定”限制，模型性能显著下降，观察到两样本CoT在此环境下表现更优。在用印地语回答相同问题时，两个VLMs的表现也有所下降。

**Conclusion:** 本研究希望自己的工作能够为进一步纳入像印地语这样的语言研究提供便利。

**Abstract:** Benchmarks for evaluating reasoning among Vision Language Models (VLMs) on
several fields and domains are being curated more frequently over the last few
years. However these are often monolingual, mostly available in English.
Additionally there also is a lack of datasets available in Hindi on tasks apart
from comprehension and translation. We introduce GanitBench, a tough benchmark
consisting of 1527 vision-only questions covering several topics in Mathematics
- available in languages English and Hindi. Collected from two major
examinations from India, the JEE Advanced and the CBSE Boards examinations,
this benchmark includes questions in the form of images comprising of figures
essential to a question as well as text. We evaluate two closed source models
for the same, in zero-shot Chain-of-Thought (CoT) and two-shot CoT settings.
GPT-4o mini is found to be the more dominant model on the benchmark, with it's
highest average accuracy being 38.15%. We also evaluate models through a
"Double Lock" constraint, which brings down the performance of the models by
considerable margins. We observe that two-shot CoT appears to be a more
effective setting under this environment. Performance of the two VLMs also
decreases when answering the same questions in the Hindi language. We hope to
facilitate the inclusion of languages like Hindi in research through our work.

</details>


### [7] [AttnTrace: Attention-based Context Traceback for Long-Context LLMs](https://arxiv.org/abs/2508.03793)
*Yanting Wang,Runpeng Geng,Ying Chen,Jinyuan Jia*

Main category: cs.CL

> 研究提出了一种名为AttnTrace的新方法，该方法基于LLM关注权重进行背景追踪，可以更准确且更有效地进行追踪，同时引入了两种设计技术，增强了其效果和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 当前最先进的背景追踪解决方案如TracLLM常常导致高昂的计算成本，本文旨在通过提出AttnTrace来提高背景追踪的准确性和效率，同时也促进了LLM输出的解释性和可信度。

**Method:** 本文提出了AttnTrace，这是一种基于大型语言模型（LLM）对提示词生成的关注权重来进行背景追踪的新方法。为了有效地利用注意力权重，作者引入了两种设计技术，并提供了理论见解支持这些设计选择。

**Result:** 实验结果表明，AttnTrace比现有的最先进的背景追踪方法更准确、更高效，并且还能提高在长上下文中检测提示注入的性能。通过归因于检测范式下，它能有效地识别操控LLM产生评论的插入指令。

**Conclusion:** AttnTrace在提升背景追踪效率与准确性上取得了显著效果，同时也加强了在一定程度上检测和防止提示注入的能力，实验证明其在真实应用场景中的有效性。

**Abstract:** Long-context large language models (LLMs), such as Gemini-2.5-Pro and
Claude-Sonnet-4, are increasingly used to empower advanced AI systems,
including retrieval-augmented generation (RAG) pipelines and autonomous agents.
In these systems, an LLM receives an instruction along with a context--often
consisting of texts retrieved from a knowledge database or memory--and
generates a response that is contextually grounded by following the
instruction. Recent studies have designed solutions to trace back to a subset
of texts in the context that contributes most to the response generated by the
LLM. These solutions have numerous real-world applications, including
performing post-attack forensic analysis and improving the interpretability and
trustworthiness of LLM outputs. While significant efforts have been made,
state-of-the-art solutions such as TracLLM often lead to a high computation
cost, e.g., it takes TracLLM hundreds of seconds to perform traceback for a
single response-context pair. In this work, we propose AttnTrace, a new context
traceback method based on the attention weights produced by an LLM for a
prompt. To effectively utilize attention weights, we introduce two techniques
designed to enhance the effectiveness of AttnTrace, and we provide theoretical
insights for our design choice. We also perform a systematic evaluation for
AttnTrace. The results demonstrate that AttnTrace is more accurate and
efficient than existing state-of-the-art context traceback methods. We also
show that AttnTrace can improve state-of-the-art methods in detecting prompt
injection under long contexts through the attribution-before-detection
paradigm. As a real-world application, we demonstrate that AttnTrace can
effectively pinpoint injected instructions in a paper designed to manipulate
LLM-generated reviews. The code is at
https://github.com/Wang-Yanting/AttnTrace.

</details>


### [8] [Majority Bit-Aware Watermarking For Large Language Models](https://arxiv.org/abs/2508.03829)
*Jiahao Xu,Rui Hu,Zikai Zhang*

Main category: cs.CL

> 本文提出了一种新颖的水印方法 MajorMark 及其扩展 MajorMark$^+$，在保持高质量文本生成的同时提高了解码准确性，解决了传统水印技术中生成质量和解码准确性之间的权衡问题。

<details>
  <summary>Details</summary>

**Motivation:** 水印技术能通过在生成的文本中嵌入可识别的二进制消息来验证来源和追踪误用行为，但对于多比特水印技术，存在着文本质量和解码准确性之间的权衡问题。本文旨在解决这一问题。

**Method:** MajorMark 是一种新颖的水印技术，通过基于位大多数编码策略，在不牺牲解码准确性和内容质量的情况下，使首选令牌集合更大且更灵活。此外，MajorMark$^+$通过将消息划分为多个块，独立编码和解码每个块，进一步提升水印文本的质量和解码准确性。

**Result:** 大规模语言模型上的广泛实验表明，与现有的多比特水印技术相比，本文的方法在提升解码准确性和文本质量方面表现出色。

**Conclusion:** MajorMark 和 MajorMark$^+$方法显著提升了多比特水印技术的解码准确性和文本生成质量，适用于复杂水印信息的嵌入和识别。

**Abstract:** The growing deployment of Large Language Models (LLMs) in real-world
applications has raised concerns about their potential misuse in generating
harmful or deceptive content. To address this issue, watermarking techniques
have emerged as a promising solution by embedding identifiable binary messages
into generated text for origin verification and misuse tracing. While recent
efforts have explored multi-bit watermarking schemes capable of embedding rich
information such as user identifiers, they typically suffer from the
fundamental trade-off between text quality and decoding accuracy: to ensure
reliable message decoding, they have to restrict the size of preferred token
sets during encoding, yet such restrictions reduce the quality of the generated
content. In this work, we propose MajorMark, a novel watermarking method that
improves this trade-off through majority bit-aware encoding. MajorMark selects
preferred token sets based on the majority bit of the message, enabling a
larger and more flexible sampling of tokens. In contrast to prior methods that
rely on token frequency analysis for decoding, MajorMark employs a
clustering-based decoding strategy, which maintains high decoding accuracy even
when the preferred token set is large, thus preserving both content quality and
decoding accuracy. We further introduce MajorMark$^+$, which partitions the
message into multiple blocks to independently encode and deterministically
decode each block, thereby further enhancing the quality of watermarked text
and improving decoding accuracy. Extensive experiments on state-of-the-art LLMs
demonstrate that our methods significantly enhance both decoding accuracy and
text generation quality, outperforming prior multi-bit watermarking baselines.

</details>


### [9] [Hallucination to Truth: A Review of Fact-Checking and Factuality Evaluation in Large Language Models](https://arxiv.org/abs/2508.03860)
*Subhey Sadi Rahman,Md. Adnanul Islam,Md. Mahbub Alam,Musarrat Zeba,Md. Abdur Rahman,Sadia Sultana Chowa,Mohaimenul Azam Khan Raiaan,Sami Azam*

Main category: cs.CL

> 论文综述了大型语言模型(LLMs)生成内容的事实准确性评估，指出需要更强大的事实核查框架，并提出了五个研究问题来指导这一领域的文献分析。文章还强调了当前评估指标的局限性和领域特定定制的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 由于大型语言模型可能会生成不准确的信息，因此需要一个系统的框架来评估并纠正这些模型生成内容的事实准确性。

**Method:** 系统分析了从2020年至2025年的文献，重点关注评估方法和缓解技术。文章提出了五个研究问题来指导分析，并讨论了指令调整、多代理推理和通过检索增强生成(RAG)框架获取外部知识的作用。

**Result:** 发现了当前评估指标的限制，并强调了使用可验证的外部证据来增强模型输出的重要性。此外，强调了领域特定制订以改善事实一致性的价值。

**Conclusion:** 论文强调了构建准确、可解释且适用于特定领域的事实核查的大型语言模型的重要性，并对朝着更值得信赖和语境感知的语言模型的研究提供了见解。

**Abstract:** Large Language Models (LLMs) are trained on vast and diverse internet corpora
that often include inaccurate or misleading content. Consequently, LLMs can
generate misinformation, making robust fact-checking essential. This review
systematically analyzes how LLM-generated content is evaluated for factual
accuracy by exploring key challenges such as hallucinations, dataset
limitations, and the reliability of evaluation metrics. The review emphasizes
the need for strong fact-checking frameworks that integrate advanced prompting
strategies, domain-specific fine-tuning, and retrieval-augmented generation
(RAG) methods. It proposes five research questions that guide the analysis of
the recent literature from 2020 to 2025, focusing on evaluation methods and
mitigation techniques. The review also discusses the role of instruction
tuning, multi-agent reasoning, and external knowledge access via RAG
frameworks. Key findings highlight the limitations of current metrics, the
value of grounding outputs with validated external evidence, and the importance
of domain-specific customization to improve factual consistency. Overall, the
review underlines the importance of building LLMs that are not only accurate
and explainable but also tailored for domain-specific fact-checking. These
insights contribute to the advancement of research toward more trustworthy and
context-aware language models.

</details>


### [10] [An Entity Linking Agent for Question Answering](https://arxiv.org/abs/2508.03865)
*Yajie Luo,Yihong Wu,Muzhi Li,Fengran Mo,Jia Ao Sun,Xinyu Wang,Liheng Ma,Yingxue Zhang,Jian-Yun Nie*

Main category: cs.CL

> 本文针对现有实体链接方法在处理问答任务中的短文本时存在的问题，提出了一种基于大型语言模型的实体链接代理，并通过实验验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于改进现有实体链接方法在问答任务中处理短且模糊用户提问时的性能。传统的实体链接方法主要针对长上下文设计，在短文本处理方面存在不足。

**Method:** 提出了一种基于大型语言模型的实体链接代理，模拟人类认知流程，主动识别实体提及，检索候选实体并做出决策。

**Result:** 该论文通过设计一个基于大型语言模型的实体链接代理，解决了现有实体链接方法在处理问答任务中的短且模糊用户提问时效果不佳的问题。实验验证了该代理的有效性和鲁棒性。

**Conclusion:** 实验结果表明，所提出的实体链接代理在工具辅助的实体链接和问答任务评估中表现出了强大的鲁棒性和有效性，验证了方法的有效性。

**Abstract:** Some Question Answering (QA) systems rely on knowledge bases (KBs) to provide
accurate answers. Entity Linking (EL) plays a critical role in linking natural
language mentions to KB entries. However, most existing EL methods are designed
for long contexts and do not perform well on short, ambiguous user questions in
QA tasks. We propose an entity linking agent for QA, based on a Large Language
Model that simulates human cognitive workflows. The agent actively identifies
entity mentions, retrieves candidate entities, and makes decision. To verify
the effectiveness of our agent, we conduct two experiments: tool-based entity
linking and QA task evaluation. The results confirm the robustness and
effectiveness of our agent.

</details>


### [11] [Sotopia-RL: Reward Design for Social Intelligence](https://arxiv.org/abs/2508.03905)
*Haofei Yu,Zhengyang Qi,Yining Zhao,Kolby Nottingham,Keyang Xuan,Bodhisattwa Prasad Majumder,Hao Zhu,Paul Pu Liang,Jiaxuan You*

Main category: cs.CL

> 论文提出了一种名为Sotopia-RL的新框架，通过将粗粒度的回合级反馈转变为细粒度的多维奖励，解决了基于Markov决策过程的强化学习在处理社交互动问题时遇到的不完全可观测性和多维行为特性问题，取得了优于现有方法的社交目标完成率分数。相关的实现已开源。

<details>
  <summary>Details</summary>

**Motivation:** 现有的MDP基础的单维回合级奖励强化学习框架在训练社交智能体时，由于社交互动的不完全可观测性和多维特性，无法有效且稳定地进行。

**Method:** 论文提出了Sotopia-RL框架，该框架通过细化回合级反馈为细粒度的多维奖励，将信用分配细化到各个话语级，同时通过多维奖励来捕捉社交互动的丰富性。

**Result:** 在Sotopia环境中，实验显示Sotopia-RL超过了现有方法，实现了高水平的社交目标完成率。次级研究表明话语级信用分配和多维奖励方案对强化学习训练是必需的。

**Conclusion:** Sotopia-RL框架能够有效处理不完全可观测性和多维特性问题，提供一种新方法解决强化学习训练社交智能体的效果和稳定性问题。该框架的相关代码已经公开。

**Abstract:** Social intelligence has become a critical capability for large language
models (LLMs), enabling them to engage effectively in real-world social tasks
such as accommodation, persuasion, collaboration, and negotiation.
Reinforcement learning (RL) is a natural fit for training socially intelligent
agents because it allows models to learn sophisticated strategies directly
through social interactions. However, social interactions have two key
characteristics that set barriers for RL training: (1) partial observability,
where utterances have indirect and delayed effects that complicate credit
assignment, and (2) multi-dimensionality, where behaviors such as
rapport-building or knowledge-seeking contribute indirectly to goal
achievement. These characteristics make Markov decision process (MDP)-based RL
with single-dimensional episode-level rewards inefficient and unstable. To
address these challenges, we propose Sotopia-RL, a novel framework that refines
coarse episode-level feedback into utterance-level, multi-dimensional rewards.
Utterance-level credit assignment mitigates partial observability by
attributing outcomes to individual utterances, while multi-dimensional rewards
capture the full richness of social interactions and reduce reward hacking.
Experiments in Sotopia, an open-ended social learning environment, demonstrate
that Sotopia-RL achieves state-of-the-art social goal completion scores (7.17
on Sotopia-hard and 8.31 on Sotopia-full), significantly outperforming existing
approaches. Ablation studies confirm the necessity of both utterance-level
credit assignment and multi-dimensional reward design for RL training. Our
implementation is publicly available at:
https://github.com/sotopia-lab/sotopia-rl.

</details>


### [12] [CoAct-1: Computer-using Agents with Coding as Actions](https://arxiv.org/abs/2508.03923)
*Linxin Song,Yutong Dai,Viraj Prabhu,Jieyu Zhang,Taiwei Shi,Li Li,Junnan Li,Silvio Savarese,Zeyuan Chen,Jieyu Zhao,Ran Xu,Caiming Xiong*

Main category: cs.CL

> 本文介绍了CoAct-1，一个结合GUI控制和直接编程执行的新多智能体系统。通过使用编程增强操作，CoAct-1在OSWorld基准测试中表现出色，效率与成功率均优于现有技术。

<details>
  <summary>Details</summary>

**Motivation:** 现有自主智能体通过GUI操作计算机在处理复杂、长时任务时效率低下且不可靠。尽管可以通过添加规划器来改善任务分解，但它们仍然受制于GUI交互的内在局限性。该研究旨在通过允许智能体使用编程作为增强操作来提高效率和健壮性。

**Method:** 本文提出了CoAct-1，这是一种新型多智能体系统，它将GUI操作与直接编程执行相结合。该系统包括一个编排者，它会根据任务需求动态地将子任务分配给GUI操作员或程序员智能体，后者能够编写和执行Python或Bash脚本，以克服传统GUI操作中的效率低下和易脆性问题。

**Result:** CoAct-1在OSWorld基准测试中达到了60.76%的成功率，为新的最先进水平，并显著提高了任务完成的效率，将完成任务所需的平均步骤减少到10.15步，相比之下，现有顶级GUI智能体需要15步。

**Conclusion:** 将编程整合为一个核心操作，提供了一条更为强大、高效和可扩展的一般计算机自动化路径。

**Abstract:** Autonomous agents that operate computers via Graphical User Interfaces (GUIs)
often struggle with efficiency and reliability on complex, long-horizon tasks.
While augmenting these agents with planners can improve task decomposition,
they remain constrained by the inherent limitations of performing all actions
through GUI manipulation, leading to brittleness and inefficiency. In this
work, we introduce a more robust and flexible paradigm: enabling agents to use
coding as a enhanced action. We present CoAct-1, a novel multi-agent system
that synergistically combines GUI-based control with direct programmatic
execution. CoAct-1 features an Orchestrator that dynamically delegates subtasks
to either a conventional GUI Operator or a specialized Programmer agent, which
can write and execute Python or Bash scripts. This hybrid approach allows the
agent to bypass inefficient GUI action sequences for tasks like file management
and data processing, while still leveraging visual interaction when necessary.
We evaluate our system on the challenging OSWorld benchmark, where CoAct-1
achieves a new state-of-the-art success rate of 60.76%, significantly
outperforming prior methods. Furthermore, our approach dramatically improves
efficiency, reducing the average number of steps required to complete a task to
just 10.15, compared to 15 for leading GUI agents. Our results demonstrate that
integrating coding as a core action provides a more powerful, efficient, and
scalable path toward generalized computer automation.

</details>


### [13] [CAP-LLM: Context-Augmented Personalized Large Language Models for News Headline Generation](https://arxiv.org/abs/2508.03935)
*Raymond Wilson,Cole Graham,Chase Carter,Zefeng Yang,Ruiqi Gu*

Main category: cs.CL

> CAP-LLM, a personalized news headline generation framework, integrates user preferences and ensures factual consistency using a large language model.

<details>
  <summary>Details</summary>

**Motivation:** To address the challenges of existing methods in capturing complex user interests and maintaining factual consistency in personalized news headlines.

**Method:** CAP-LLM includes a User Preference Encoder, a Context Injection Adapter, and a Fact-Consistency Reinforcement Module with a contrastive loss to prevent hallucination.

**Result:** On the PENS dataset, CAP-LLM significantly outperforms baselines like BART with better factual consistency and personalization scores.

**Conclusion:** CAP-LLM effectively achieves a balance between personalization and fact accuracy, making it a robust solution for news headline generation.

**Abstract:** In the era of information overload, personalized news headline generation is
crucial for engaging users by tailoring content to their preferences while
accurately conveying news facts. Existing methods struggle with effectively
capturing complex user interests and ensuring factual consistency, often
leading to generic or misleading headlines. Leveraging the unprecedented
capabilities of Large Language Models (LLMs) in text generation, we propose
Context-Augmented Personalized LLM (CAP-LLM), a novel framework that integrates
user preferences and factual consistency constraints into a powerful
pre-trained LLM backbone. CAP-LLM features a User Preference Encoder to capture
long-term user interests, a Context Injection Adapter to seamlessly integrate
these preferences and current article context into the LLM's generation
process, and a Fact-Consistency Reinforcement Module employing a novel
contrastive loss to mitigate hallucination. Evaluated on the real-world PENS
dataset, CAP-LLM achieves state-of-the-art performance across all metrics.
Notably, it significantly improves factual consistency (FactCC of 87.50) over
strong baselines like BART (86.67), while simultaneously enhancing
personalization (Pc(avg) 2.73, Pc(max) 17.25) and content coverage (ROUGE-1
26.55, ROUGE-2 9.95, ROUGE-L 23.01). Our ablation studies, human evaluations,
and sensitivity analyses further validate the effectiveness of each component
and the robustness of our approach, demonstrating CAP-LLM's ability to achieve
a superior balance between personalization and factual accuracy in news
headline generation.

</details>


### [14] [Data and AI governance: Promoting equity, ethics, and fairness in large language models](https://arxiv.org/abs/2508.03970)
*Alok Abhishek,Lisa Erickson,Tushar Bandopadhyay*

Main category: cs.CL

> 该研究介绍了用于管理大型语言模型偏差、道德公平性的数据和AI治理方法，助力创建负责任、伦理导向的生成式AI应用。

<details>
  <summary>Details</summary>

**Motivation:** 文章旨在系统化治理、评估和量化机器学习模型（特别是LLMs）在完整生命周期中的偏差问题，从最初的开发和验证到生产过程中的持续监控。

**Method:** 本研究基于先前对大型语言模型（LLMs）的偏差评估与测试套件（BEATS）的工作，讨论了数据和人工智能治理框架如何用于解决LLMs中的偏差、道德、公平性和事实性问题。

**Result:** 提出的数据和AI治理方法适合实际应用，能够提供严格的基准测试、持续的实时评估以及主动治理LLM生成的响应，从而增强系统的安全性和可靠性。

**Conclusion:** 通过在整个AI开发周期中实施数据和AI治理方法，组织可以显著提高其生成式AI系统的责任感和道德一致性，减少歧视风险，预防潜在的品牌或声誉损害。

**Abstract:** In this paper, we cover approaches to systematically govern, assess and
quantify bias across the complete life cycle of machine learning models, from
initial development and validation to ongoing production monitoring and
guardrail implementation. Building upon our foundational work on the Bias
Evaluation and Assessment Test Suite (BEATS) for Large Language Models, the
authors share prevalent bias and fairness related gaps in Large Language Models
(LLMs) and discuss data and AI governance framework to address Bias, Ethics,
Fairness, and Factuality within LLMs. The data and AI governance approach
discussed in this paper is suitable for practical, real-world applications,
enabling rigorous benchmarking of LLMs prior to production deployment,
facilitating continuous real-time evaluation, and proactively governing LLM
generated responses. By implementing the data and AI governance across the life
cycle of AI development, organizations can significantly enhance the safety and
responsibility of their GenAI systems, effectively mitigating risks of
discrimination and protecting against potential reputational or brand-related
harm. Ultimately, through this article, we aim to contribute to advancement of
the creation and deployment of socially responsible and ethically aligned
generative artificial intelligence powered applications.

</details>


### [15] [Confidence-Weighted Token Set Cover for Early Hypothesis Pruning in Self-Consistency](https://arxiv.org/abs/2508.03979)
*Md Arafat Sultan,Ramón Fernandez Astudillo*

Main category: cs.CL

> 本文研究了通过假设剪枝提高自洽性在长链推理任务中的令牌效率，同时保持其并行性。评估显示在某些情况下可提升效率10-35%。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自洽性简单且有效，但在长链推理任务中由于高令牌消耗限制了其实用性。这项研究的动机在于解决这一问题。

**Method:** 通过早期假设剪枝来提高长链推理任务中的自洽性，同时保持其并行性。具体来说，我们并行生成所有解决方案，但根据模型对个别假设的置信度和所有当前假设的词汇覆盖率这两个轻量级指标，定期剪枝被认为是不必要的中间假设。我们设计了一个快速的加权集合覆盖算法，该算法利用这两个指标。

**Result:** 在五个大语言模型上的三个数学基准测试评估表明，该方法可以提高所有模型的令牌效率，许多情况下提高了10-35%。

**Conclusion:** 研究表明，通过使用早期假设剪枝的方法，可以显著提高长链推理任务中自洽性的令牌效率，从而提高了其实用性。

**Abstract:** Despite its simplicity and efficacy, the high token expenditure of
self-consistency can limit its practical utility. Here we investigate if
self-consistency can be made more token-efficient for long chain-of-thought
reasoning tasks, while preserving its parallelism, through early hypothesis
pruning. Concretely, we generate all solutions in parallel, but periodically
prune intermediate hypotheses that are deemed unnecessary based on two
lightweight indicators: (a) the model's own confidence in individual
hypotheses, and (b) lexical coverage of all current hypotheses by candidate
subsets that are under consideration for continued retention. We design a fast
weighted set cover algorithm that utilizes the two indicators; our evaluation
of five LLMs on three math benchmarks shows that this method can improve token
efficiency for all models, by 10-35% in many cases.

</details>


### [16] [Are Today's LLMs Ready to Explain Well-Being Concepts?](https://arxiv.org/abs/2508.03990)
*Bohan Jiang,Dawei Li,Zhen Tan,Chengshuai Zhao,Huan Liu*

Main category: cs.CL

> 本研究通过构建大规模解释数据集并采用LLM作为评判者评估解释质量，展示出经SFT和DPO微调的开源LLM在生成高质量福祉概念解释方面有显著改善。

<details>
  <summary>Details</summary>

**Motivation:** 随着个人越来越多地咨询大型语言模型（LLM）以理解福祉，一个关键的挑战随之而来：LLM能否生成不仅是准确的解释，而且还能满足不同受众群体的期望。高质量的解释不仅需要事实上的正确性，还需要能够满足具有不同专业知识的用户的期望。

**Method:** 构建了一个大规模的数据集，包含2,194个福祉概念的43,880个解释，并由十种不同的LLM生成。同时引入了一个由原则指导的LLM作为评判者的评估框架，采用双重评判者来评估解释的质量。此外，还展示了使用监督微调（SFT）和直接偏好优化（DPO）对开源LLM进行微调可以显著提高生成解释的质量。

**Result:** 研究结果表明：（1）建议的LLM评判者与人类评估高度一致；（2）解释的质量在不同模型、受众和类别之间存在显著差异；（3）经过DPO和SFT微调的模型超越了其较大的同类模型，展示了偏好学习对于专门解释任务的有效性。

**Conclusion:** 研究提出的方法能够提升LLM生成福祉概念解释的质量，并表明特定领域的微调方法（SFT和DPO）对于提高解释质量尤为有效。

**Abstract:** Well-being encompasses mental, physical, and social dimensions essential to
personal growth and informed life decisions. As individuals increasingly
consult Large Language Models (LLMs) to understand well-being, a key challenge
emerges: Can LLMs generate explanations that are not only accurate but also
tailored to diverse audiences? High-quality explanations require both factual
correctness and the ability to meet the expectations of users with varying
expertise. In this work, we construct a large-scale dataset comprising 43,880
explanations of 2,194 well-being concepts, generated by ten diverse LLMs. We
introduce a principle-guided LLM-as-a-judge evaluation framework, employing
dual judges to assess explanation quality. Furthermore, we show that
fine-tuning an open-source LLM using Supervised Fine-Tuning (SFT) and Direct
Preference Optimization (DPO) can significantly enhance the quality of
generated explanations. Our results reveal: (1) The proposed LLM judges align
well with human evaluations; (2) explanation quality varies significantly
across models, audiences, and categories; and (3) DPO- and SFT-finetuned models
outperform their larger counterparts, demonstrating the effectiveness of
preference-based learning for specialized explanation tasks.

</details>


### [17] [Transferring Expert Cognitive Models to Social Robots via Agentic Concept Bottleneck Models](https://arxiv.org/abs/2508.03998)
*Xinyu Zhao,Zhen Tan,Maya Enisman,Minjae Seo,Marta R. Durantini,Dolores Albarracin,Tianlong Chen*

Main category: cs.CL

> 本研究开发了一种社交机器人辅助会议协调，通过一个基于人类可理解概念进行决策的模型，辅助提高会议效率和促进群体社交关系。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于填补一个关键空白：开发一种能够阐释社交互动，并能感知群体中个体需求以提供建议的具身技术。这种技术超越了仅能识别社交线索的强大但黑箱模型。

**Method:** 本研究开发了一种社交机器人辅助协调员，该机器人能够分析多模态会议数据并提供对协调员的微妙提示。其决策基于代理概念瓶颈模型（CBM），基于参与者参与度和情感等人类可理解的概念进行决策，保证了透明度和可信度。同时，研究还提出了一种迁移学习框架，可将基础模型的广泛社交理解提炼到透明的CBM中。

**Result:** 研究结果显示，这种概念驱动的系统在预测干预需求时显著优于基础模型的直接零射击预测，并允许实现实时的对机器逻辑的人类纠正。该模型在不同群体间表现出良好的知识转移能力，并能够将资深协调员的专长转移给新手。

**Conclusion:** 本研究为复杂社交领域的增强人类功能提供了强有力的设计方案。通过转移专家的认知模型到一个可解释的机器人伙伴，这一解决方案不仅提高了会议效率，还增强了群体间的社交网络。

**Abstract:** Successful group meetings, such as those implemented in group
behavioral-change programs, work meetings, and other social contexts, must
promote individual goal setting and execution while strengthening the social
relationships within the group. Consequently, an ideal facilitator must be
sensitive to the subtle dynamics of disengagement, difficulties with individual
goal setting and execution, and interpersonal difficulties that signal a need
for intervention. The challenges and cognitive load experienced by facilitators
create a critical gap for an embodied technology that can interpret social
exchanges while remaining aware of the needs of the individuals in the group
and providing transparent recommendations that go beyond powerful but "black
box" foundation models (FMs) that identify social cues. We address this
important demand with a social robot co-facilitator that analyzes multimodal
meeting data and provides discreet cues to the facilitator. The robot's
reasoning is powered by an agentic concept bottleneck model (CBM), which makes
decisions based on human-interpretable concepts like participant engagement and
sentiments, ensuring transparency and trustworthiness. Our core contribution is
a transfer learning framework that distills the broad social understanding of
an FM into our specialized and transparent CBM. This concept-driven system
significantly outperforms direct zero-shot FMs in predicting the need for
intervention and enables real-time human correction of its reasoning.
Critically, we demonstrate robust knowledge transfer: the model generalizes
across different groups and successfully transfers the expertise of senior
human facilitators to improve the performance of novices. By transferring an
expert's cognitive model into an interpretable robotic partner, our work
provides a powerful blueprint for augmenting human capabilities in complex
social domains.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [18] [Text2VR: Automated instruction Generation in Virtual Reality using Large language Models for Assembly Task](https://arxiv.org/abs/2508.03699)
*Subin Raj Peter*

Main category: cs.CV

> 论文提出了一种基于大型语言模型自动生成VR培训内容的新方法，通过智能模块将文本信息转化为VR环境中的动画和视觉提示，实现更有效的培训并降低开发成本。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决因时间、专业知识和资源需求而带来的VR应用程序开发困难的问题，进而提高培训效果并降低开发成本。

**Method:** 该研究提出了一个利用大型语言模型（LLMs）自动生成VR环境中虚拟指令的新方法。系统由两部分组成：1）LLM模块从文本中提取任务相关信息；2）智能模块将这些信息转化为VR环境中的动画演示和视觉提示。

**Result:** 通过改变虚拟物体的颜色和创建动画来解释任务，提高了VR培训内容的生成效率。

**Conclusion:** 这种方法提高了培训效果，减少了开发工作量，使VR培训更具可扩展性和适应工业需求的能力。

**Abstract:** Virtual Reality (VR) has emerged as a powerful tool for workforce training,
offering immersive, interactive, and risk-free environments that enhance skill
acquisition, decision-making, and confidence. Despite its advantages,
developing VR applications for training remains a significant challenge due to
the time, expertise, and resources required to create accurate and engaging
instructional content. To address these limitations, this paper proposes a
novel approach that leverages Large Language Models (LLMs) to automate the
generation of virtual instructions from textual input. The system comprises two
core components: an LLM module that extracts task-relevant information from the
text, and an intelligent module that transforms this information into animated
demonstrations and visual cues within a VR environment. The intelligent module
receives input from the LLM module and interprets the extracted information.
Based on this, an instruction generator creates training content using relevant
data from a database. The instruction generator generates the instruction by
changing the color of virtual objects and creating animations to illustrate
tasks. This approach enhances training effectiveness and reduces development
overhead, making VR-based training more scalable and adaptable to evolving
industrial needs.

</details>


### [19] [Outlier Detection Algorithm for Circle Fitting](https://arxiv.org/abs/2508.03720)
*Ahmet Gökhan Poyraz*

Main category: cs.CV

> The paper presents a new method for outlier detection in circle fitting applications, demonstrating its effectiveness through a case study on high-precision diameter measurement of industrial washers using machine vision technology.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to address the issue of noisy point sets that can degrade the performance of circle fitting algorithms. By effectively detecting and removing outliers, the accuracy of circle fitting can be significantly improved.

**Method:** The study introduces the Polar Coordinate-Based Outlier Detection (PCOD) algorithm for improving circle fitting accuracy. The process involves transforming point sets into polar coordinates and calculating local and global standard deviations to detect and remove outliers.

**Result:** Experimental results show that the proposed PCOD algorithm outperforms other circle fitting algorithms and outlier detection methods in terms of accuracy for high-precision measurements.

**Conclusion:** The proposed Polar Coordinate-Based Outlier Detection (PCOD) algorithm demonstrates superior performance in circle fitting accuracy, especially in industrial environments with noisy point sets, thus promising enhanced applications in quality control and design.

**Abstract:** Circle fitting methods are extensively utilized in various industries,
particularly in quality control processes and design applications. The
effectiveness of these algorithms can be significantly compromised when the
point sets to be predicted are noisy. To mitigate this issue, outlier detection
and removal algorithms are often applied before the circle fitting procedure.
This study introduces the Polar Coordinate-Based Outlier Detection (PCOD)
algorithm, which can be effectively employed in circle fitting applications. In
the proposed approach, the point set is first transformed into polar
coordinates, followed by the calculation of both local and global standard
deviations. Outliers are then identified by comparing local mean values with
the global standard deviation. The practicality and efficiency of the proposed
method are demonstrated by focusing on the high-precision diameter measurement
of industrial washer parts. Images from a machine vision system are processed
through preprocessing steps, including sub-pixel edge detection. The resulting
sub-pixel edge points are then cleaned using the proposed outlier detection and
removal algorithm, after which circle fitting is performed. A comparison is
made using ten different circle fitting algorithms and five distinct outlier
detection methods. The results indicate that the proposed method outperforms
the other approaches, delivering the best performance in terms of accuracy
within the dataset, thereby demonstrating its potential for enhancing circle
fitting applications in industrial environments.

</details>


### [20] [Enhancing Diameter Measurement Accuracy in Machine Vision Applications](https://arxiv.org/abs/2508.03721)
*Ahmet Gokhan Poyraz,Ahmet Emir Dirik,Hakan Gurkan,Mehmet Kacmaz*

Main category: cs.CV

> This paper addresses measurement errors in camera systems by proposing a conversion factor-based method and a pixel-based method, reducing errors from 13-114 micrometers to 1-2 micrometers.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this study is to address the issue of measurement errors in camera measurement systems, which are particularly evident when measuring parts of different diameters using the same setup.

**Method:** The paper proposes two methods to enhance the accuracy of measurements in camera measurement systems: a conversion factor-based method and a pixel-based method. These methods utilize several known reference parts to improve accuracy.

**Result:** Experiments conducted on glass and metal samples showed that measurement errors were significantly reduced to 1-2 micrometers from an original range of 13-114 micrometers using the proposed methods.

**Conclusion:** The proposed methods enable high-accuracy measurements using only a few known reference parts and significantly enhance measurement reliability and reduce error rates in the literature of diameter measurements.

**Abstract:** In camera measurement systems, specialized equipment such as telecentric
lenses is often employed to measure parts with narrow tolerances. However,
despite the use of such equipment, measurement errors can occur due to
mechanical and software-related factors within the system. These errors are
particularly evident in applications where parts of different diameters are
measured using the same setup. This study proposes two innovative approaches to
enhance measurement accuracy using multiple known reference parts: a conversion
factor-based method and a pixel-based method. In the first approach, the
conversion factor is estimated from known references to calculate the diameter
(mm) of the unknown part. In the second approach, the diameter (mm) is directly
estimated using pixel-based diameter information from the references. The
experimental setup includes an industrial-grade camera and telecentric lenses.
Tests conducted on glass samples (1-12 mm) and metal workpieces (3-24 mm) show
that measurement errors, which originally ranged from 13-114 micrometers, were
reduced to 1-2 micrometers using the proposed methods. By utilizing only a few
known reference parts, the proposed approach enables high-accuracy measurement
of all parts within the camera's field of view. Additionally, this method
enhances the existing diameter measurement literature by significantly reducing
error rates and improving measurement reliability.

</details>


### [21] [Multimodal Video Emotion Recognition with Reliable Reasoning Priors](https://arxiv.org/abs/2508.03722)
*Zhepeng Wang,Yingjian Zhu,Guanghao Dong,Hongzhu Yi,Feng Chen,Xinming Wang,Jun Xie*

Main category: cs.CV

> 本研究探讨了将可信先验推理知识整合进多模态情感识别的方法，通过引入平衡双对比学习（Balanced Dual-Contrastive Learning）来缓解类别不平衡问题，性能显著提升。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在将多语言大模型（MLLM）中的可信先验推理知识整合进多模态情感识别中。

**Method:** 本研究使用Gemini生成细粒度的、可分离模态的推理轨迹作为先验知识，在融合阶段被注入以丰富跨模态交互。为了缓解模态情感识别中显著的类别不平衡问题，引入了平衡双对比学习（Balanced Dual-Contrastive Learning），这是一种联合平衡类间和类内分布的损失函数。

**Result:** 本框架应用于MER2024基准测试中，性能显著提升。

**Conclusion:** 研究表明，MLLM生成的推理可靠性可以与轻量级融合网络的领域自适应性相结合，实现稳健、可扩展的情感识别。

**Abstract:** This study investigates the integration of trustworthy prior reasoning
knowledge from MLLMs into multimodal emotion recognition. We employ Gemini to
generate fine-grained, modality-separable reasoning traces, which are injected
as priors during the fusion stage to enrich cross-modal interactions. To
mitigate the pronounced class-imbalance in multimodal emotion recognition, we
introduce Balanced Dual-Contrastive Learning, a loss formulation that jointly
balances inter-class and intra-class distributions. Applied to the MER2024
benchmark, our prior-enhanced framework yields substantial performance gains,
demonstrating that the reliability of MLLM-derived reasoning can be
synergistically combined with the domain adaptability of lightweight fusion
networks for robust, scalable emotion recognition.

</details>


### [22] [From Waveforms to Pixels: A Survey on Audio-Visual Segmentation](https://arxiv.org/abs/2508.03724)
*Jia Li,Yapeng Tian*

Main category: cs.CV

> 本文对音频-视觉分割（AVS）领域的现有研究进行了全面综述，分析了其方法进展、训练范式，并指出了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** AVS旨在通过结合视觉和音频模式来识别和分割视频中的发声物体。这已成为多模式感知领域的重要研究方向，能够实现细致的物体级理解。

**Method:** 本文综述了音频-视觉分割（AVS）领域的进展，包括问题定义、基准数据集、评估指标以及各类方法的发展历程。涵盖了单模态和多模态编码架构、音频-视觉融合策略以及不同的解码设计。研究了完全监督学习、弱监督学习及无训练方法的不同训练范式。

**Result:** 本文提供了对AVS方法在标准基准上的广泛比较，显示了不同架构选择、融合策略和训练范式对性能的影响。

**Conclusion:** 文章概述了当前的挑战，如有限的时间建模能力、视觉模式偏见、复杂环境中鲁棒性不足及高计算需求，提出了通过改进时间推理、多模态融合和利用基础模型来提高泛化能力及降低对标记数据的依赖等未来研究方向。

**Abstract:** Audio-Visual Segmentation (AVS) aims to identify and segment sound-producing
objects in videos by leveraging both visual and audio modalities. It has
emerged as a significant research area in multimodal perception, enabling
fine-grained object-level understanding. In this survey, we present a
comprehensive overview of the AVS field, covering its problem formulation,
benchmark datasets, evaluation metrics, and the progression of methodologies.
We analyze a wide range of approaches, including architectures for unimodal and
multimodal encoding, key strategies for audio-visual fusion, and various
decoder designs. Furthermore, we examine major training paradigms, from fully
supervised learning to weakly supervised and training-free methods. Notably, we
provide an extensive comparison of AVS methods across standard benchmarks,
highlighting the impact of different architectural choices, fusion strategies,
and training paradigms on performance. Finally, we outline the current
challenges, such as limited temporal modeling, modality bias toward vision,
lack of robustness in complex environments, and high computational demands, and
propose promising future directions, including improving temporal reasoning and
multimodal fusion, leveraging foundation models for better generalization and
few-shot learning, reducing reliance on labeled data through selfand weakly
supervised learning, and incorporating higher-level reasoning for more
intelligent AVS systems.

</details>


### [23] [A Large Language Model Powered Integrated Circuit Footprint Geometry Understanding](https://arxiv.org/abs/2508.03725)
*Yida Wang,Taiting Lu,Runze Liu,Lanqing Yang,Yifan Yang,Zhe Chen,Yuehai Wang,Yixin Liu,Kaiyuan Lin,Xiaomeng Chen,Dian Ding,Yijie Li,Yi-Chao Chen,Yincheng Jin,Mahanth Gowda*

Main category: cs.CV

> 本文探讨了大型多模态模型（LMMs）在理解集成电路（IC）封装几何结构方面的视觉感知表现，并提出了LLM4-IC8K框架，该框架使用LMMs对IC机械图纸进行结构化几何解释。通过两阶段训练，首先在合成的IC封装图纸上学习基本几何推理，然后在实际的数据表绘图上进行微调以提高鲁棒性和准确性。实验表明，该模型在提出的基准上优于当前先进的LMMs模型。

<details>
  <summary>Details</summary>

**Motivation:** 由于IC封装几何学的标注工作需要高度的视觉感知能力，而现有的方法在处理非结构化的封装图纸和抽象的图注方面还存在很大的困难，本文旨在克服这些困难，提出了一种新的方法，以改善IC封装几何结构的自动化解释和标注。

**Method:** 提出了LLM4-IC8K框架，使用LMMs对IC机械图纸进行结构化几何解读，并设计了一个两阶段的框架，首先在合成的IC封装图样上训练基础几何推理，然后在真实世界的数据表图纸上进行微调。

**Result:** 进行了大量的实验，结果表明，所提出的模型在所提出的基准上比现有的先进的LMMs模型表现更好。

**Conclusion:** LLM4-IC8K框架通过针对具体子任务的两阶段训练策略改进IC封装几何理解的性能，证明了其在准确性和鲁棒性方面的优越性。

**Abstract:** Printed-Circuit-board (PCB) footprint geometry labeling of integrated
circuits (IC) is essential in defining the physical interface between
components and the PCB layout, requiring exceptional visual perception
proficiency. However, due to the unstructured footprint drawing and abstract
diagram annotations, automated parsing and accurate footprint geometry modeling
remain highly challenging. Despite its importance, no methods currently exist
for automated package geometry labeling directly from IC mechanical drawings.
In this paper, we first investigate the visual perception performance of Large
Multimodal Models (LMMs) when solving IC footprint geometry understanding. Our
findings reveal that current LMMs severely suffer from inaccurate geometric
perception, which hinders their performance in solving the footprint geometry
labeling problem. To address these limitations, we propose LLM4-IC8K, a novel
framework that treats IC mechanical drawings as images and leverages LLMs for
structured geometric interpretation. To mimic the step-by-step reasoning
approach used by human engineers, LLM4-IC8K addresses three sub-tasks:
perceiving the number of pins, computing the center coordinates of each pin,
and estimating the dimensions of individual pins. We present a two-stage
framework that first trains LMMs on synthetically generated IC footprint
diagrams to learn fundamental geometric reasoning and then fine-tunes them on
real-world datasheet drawings to enhance robustness and accuracy in practical
scenarios. To support this, we introduce ICGeo8K, a multi-modal dataset with
8,608 labeled samples, including 4138 hand-crafted IC footprint samples and
4470 synthetically generated samples. Extensive experiments demonstrate that
our model outperforms state-of-the-art LMMs on the proposed benchmark.

</details>


### [24] [TIR-Diffusion: Diffusion-based Thermal Infrared Image Denoising via Latent and Wavelet Domain Optimization](https://arxiv.org/abs/2508.03727)
*Tai Hyoung Rhee,Dong-guw Lee,Ayoung Kim*

Main category: cs.CV

> 提出了一种新的基于扩散模型的热红外图像去噪方法，实现了高保真度的去噪效果，并在现实世界数据集上表现出了优越的性能和良好的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 热红外成像在机器人感知任务中展现出巨大的潜力，尤其是在可见度差或照明条件复杂的环境下。然而，热红外图像通常受到严重的非均匀固定模式噪声的影响，这使得目标检测、定位和映射等任务变得复杂。为了应对这些问题，提出了上述方法。

**Method:** 提出了一种基于扩散模型的热红外图像去噪框架，该框架利用了潜空间表征和小波域优化。通过一个预训练的稳定扩散模型，并通过结合潜空间和离散小波变换（DWT）/双重树复小波变换（DTCWT）损失的新型损失函数对其进行微调。此外，还实现了一个级联精细处理阶段，以增强细节，确保高质量的去噪结果。

**Result:** 基准数据集上的实验结果表明，该方法相较于现有的去噪方法具有优越的性能。此外，该方法还实现了对各种具有挑战性的现实世界热红外数据集的鲁棒零样本泛化，凸显了其在实际机器人部署中的有效性。

**Conclusion:** 研究展示了所提出方法在现实世界热红外图像去噪中的优越性能和泛化能力，对于实际机器人应用具有重要意义。

**Abstract:** Thermal infrared imaging exhibits considerable potentials for robotic
perception tasks, especially in environments with poor visibility or
challenging lighting conditions. However, TIR images typically suffer from
heavy non-uniform fixed-pattern noise, complicating tasks such as object
detection, localization, and mapping. To address this, we propose a
diffusion-based TIR image denoising framework leveraging latent-space
representations and wavelet-domain optimization. Utilizing a pretrained stable
diffusion model, our method fine-tunes the model via a novel loss function
combining latent-space and discrete wavelet transform (DWT) / dual-tree complex
wavelet transform (DTCWT) losses. Additionally, we implement a cascaded
refinement stage to enhance fine details, ensuring high-fidelity denoising
results. Experiments on benchmark datasets demonstrate superior performance of
our approach compared to state-of-the-art denoising methods. Furthermore, our
method exhibits robust zero-shot generalization to diverse and challenging
real-world TIR datasets, underscoring its effectiveness for practical robotic
deployment.

</details>


### [25] [What is Beneath Misogyny: Misogynous Memes Classification and Explanation](https://arxiv.org/abs/2508.03732)
*Kushal Kanwar,Dushyant Singh Chauhan,Gopendra Vikram Singh,Asif Ekbal*

Main category: cs.CV

> 本文提出了一种名为	extit{	extbf{MM-Misogyny}}的方法，用于检测和分类网络梗中的厌女内容，并通过跨注意力机制处理模态数据，使其与其他现有方法相比具有优势。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于网络梗在现代社会的流行及其中可能潜藏的有害意识形态（例如，厌女）问题，本文旨在通过一种多模态的方法来识别和理解这些隐秘的厌女内容。这项工作旨在应对多种模态（图像和文本）以及在不同社会背景下厌女内容复杂表现所带来的研究挑战。

**Method:** 本研究提出了一种名为	extit{	extbf{MM-Misogyny}}的新型多模态方法，用于检测、分类和解释网络流行梗（memes）中的厌女内容。该方法通过跨注意力机制分别处理文本和图像模态，并将它们统一为多模态上下文。此多模态上下文随后通过分类器和大型语言模型(Large Language Model, LLM)进行标签化、分类和解释。

**Result:** 评估展示了	extit{	extbf{MM-Misogyny}}方法能够有效检测和分类厌女梗，并且该方法在对厌女内容的多模态理解和解释上优于现有方法。

**Conclusion:** 本文介绍的多模态方法（	extit{	extbf{MM-Misogyny}}）不仅能够检测和分类厌女梗，还能对这些厌女内容在生活各领域的运作提供深入理解。模型在新构的数据集上的评估显示了其相对于现有方法的优越性。

**Abstract:** Memes are popular in the modern world and are distributed primarily for
entertainment. However, harmful ideologies such as misogyny can be propagated
through innocent-looking memes. The detection and understanding of why a meme
is misogynous is a research challenge due to its multimodal nature (image and
text) and its nuanced manifestations across different societal contexts. We
introduce a novel multimodal approach, \textit{namely},
\textit{\textbf{MM-Misogyny}} to detect, categorize, and explain misogynistic
content in memes. \textit{\textbf{MM-Misogyny}} processes text and image
modalities separately and unifies them into a multimodal context through a
cross-attention mechanism. The resulting multimodal context is then easily
processed for labeling, categorization, and explanation via a classifier and
Large Language Model (LLM). The evaluation of the proposed model is performed
on a newly curated dataset (\textit{\textbf{W}hat's \textbf{B}eneath
\textbf{M}isogynous \textbf{S}tereotyping (WBMS)}) created by collecting
misogynous memes from cyberspace and categorizing them into four categories,
\textit{namely}, Kitchen, Leadership, Working, and Shopping. The model not only
detects and classifies misogyny, but also provides a granular understanding of
how misogyny operates in domains of life. The results demonstrate the
superiority of our approach compared to existing methods. The code and dataset
are available at
\href{https://github.com/kushalkanwarNS/WhatisBeneathMisogyny/tree/main}{https://github.com/Misogyny}.

</details>


### [26] [StorySync: Training-Free Subject Consistency in Text-to-Image Generation via Region Harmonization](https://arxiv.org/abs/2508.03735)
*Gopalji Gaur,Mohammadreza Zolfaghari,Thomas Brox*

Main category: cs.CV

> 为了克服使用文本到图像扩散模型生成连贯图像序列时的主体一致性难题，本文提出了一种无需训练的方法，通过掩码跨图像注意力共享和区域性特征和谐来改进主体一致性。实验结果表明该方法可在不同场景中成功生成视觉上一致的主体。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法需要微调或重新训练模型，这需要大量的计算资源和时间，并且可能会影响模型的预存能力。为了解决这些问题并降低计算成本，同时保持模型的创造力，提出了这种方法。

**Method:** 通过引入掩码跨图像注意力共享来动态对齐一批图像中的主题特征，并使用区域性特征和谐来改进视觉上相似细节，从而实现主题一致性。这种方法不需要额外训练，可以无缝地与预训练的扩散模型结合使用。

**Result:** 实验结果表明，提出的方法在各种场景中成功生成了视觉上一致的主体，并且保持了扩散模型的创造性。

**Conclusion:** 所提出的方法在没有额外训练的情况下，有效地提高了图像生成中主题的一致性，并且与预训练的扩散模型无缝工作。

**Abstract:** Generating a coherent sequence of images that tells a visual story, using
text-to-image diffusion models, often faces the critical challenge of
maintaining subject consistency across all story scenes. Existing approaches,
which typically rely on fine-tuning or retraining models, are computationally
expensive, time-consuming, and often interfere with the model's pre-existing
capabilities. In this paper, we follow a training-free approach and propose an
efficient consistent-subject-generation method. This approach works seamlessly
with pre-trained diffusion models by introducing masked cross-image attention
sharing to dynamically align subject features across a batch of images, and
Regional Feature Harmonization to refine visually similar details for improved
subject consistency. Experimental results demonstrate that our approach
successfully generates visually consistent subjects across a variety of
scenarios while maintaining the creative abilities of the diffusion model.

</details>


### [27] [Fusion of Pervasive RF Data with Spatial Images via Vision Transformers for Enhanced Mapping in Smart Cities](https://arxiv.org/abs/2508.03736)
*Rafayel Mkrtchyan,Armen Manukyan,Hrant Khachatrian,Theofanis P. Raptis*

Main category: cs.CV

> 本文提出了一种新型的制图方法，改进了现有技术，提高了准确性，并通过合成数据集验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的智慧城市制图技术（如卫星图像、LiDAR扫描和手动注释）存在成本、可访问性和准确性方面的局限性。尽管开源制图平台在人工智能应用中被广泛用于环境制图，并作为地面真实数据源，但人与人之间的错误和现实世界的演变引入了偏差，可能会影响基于此类数据训练的神经网络的性能。

**Method:** 提出了一种基于深度学习的方法，该方法整合了DINOv2架构，结合了开源平台的地图和来自多个无线用户设备和基站的无线电频率（RF）数据，以改进建筑制图。该方法利用了基于视觉变压器的架构，在统一框架中联合处理RF和地图模态，有效捕捉空间依赖性和结构先验，从而提高制图准确性。

**Result:** 研究采用华为联合制作的合成数据集进行评估。模型仅利用聚合路径损耗信息来解决制图问题。根据Jaccard指数、Hausdorff距离和Chamfer距离三个性能指标来衡量结果。设计方案实现了65.3%的宏观IoU性能，显著优于误图基准、RF数据的现有方法和非人工智能融合基准。

**Conclusion:** 研究的结果表明，结合RF数据和地图信息的深度学习方法可以显著提升环境地图的准确性，显示出在智慧城市应用中的潜力。

**Abstract:** Environment mapping is an important computing task for a wide range of smart
city applications, including autonomous navigation, wireless network operations
and extended reality environments. Conventional smart city mapping techniques,
such as satellite imagery, LiDAR scans, and manual annotations, often suffer
from limitations related to cost, accessibility and accuracy. Open-source
mapping platforms have been widely utilized in artificial intelligence
applications for environment mapping, serving as a source of ground truth.
However, human errors and the evolving nature of real-world environments
introduce biases that can negatively impact the performance of neural networks
trained on such data. In this paper, we present a deep learning-based approach
that integrates the DINOv2 architecture to improve building mapping by
combining maps from open-source platforms with radio frequency (RF) data
collected from multiple wireless user equipments and base stations. Our
approach leverages a vision transformer-based architecture to jointly process
both RF and map modalities within a unified framework, effectively capturing
spatial dependencies and structural priors for enhanced mapping accuracy. For
the evaluation purposes, we employ a synthetic dataset co-produced by Huawei.
We develop and train a model that leverages only aggregated path loss
information to tackle the mapping problem. We measure the results according to
three performance metrics which capture different qualities: (i) The Jaccard
index, also known as intersection over union (IoU), (ii) the Hausdorff
distance, and (iii) the Chamfer distance. Our design achieves a macro IoU of
65.3%, significantly surpassing (i) the erroneous maps baseline, which yields
40.1%, (ii) an RF-only method from the literature, which yields 37.3%, and
(iii) a non-AI fusion baseline that we designed which yields 42.2%.

</details>


### [28] [VQ-DeepISC: Vector Quantized-Enabled Digital Semantic Communication with Channel Adaptive Image Transmission](https://arxiv.org/abs/2508.03740)
*Jianqiao Chen,Tingting Zhu,Huishi Song,Nan Ma,Xiaodong Xu*

Main category: cs.CV

> 提出了一种新的通信系统VQ-DeepISC，用于语义特征的数字化传输，实现了高效且健壮的图像传输，实验结果表明，其在重建保真度上优于基准方法。

<details>
  <summary>Details</summary>

**Motivation:** 语义特征的离散化可以实现语义和数字通信系统间的互操作性，这在实际情况中具显著的应用潜力。然而，将语义特征数字化的根本难点在于在压缩成离散符号的过程中需要保持其连续性与上下文的一致性，同时确保在信道损伤下仍保持强健性。

**Method:** 我们提出了一种名为VQ-DeepISC的基于矢量量化（VQ）的数字语义通信系统，该系统具备信道自适应的图像传输能力。系统首先采用Swin Transformer骨干网络进行分层语义特征提取，然后通过VQ模块将特征投影到离散的潜在空间。我们开发了一种基于注意力机制的信道自适应模块，用于动态优化索引传输。为了防止训练过程中发生码本崩溃，我们通过最小化码字使用频率与均匀先验之间的Kullback-Leibler散度来施加分布正则化。同时，采用指数移动平均（EMA）来稳定训练并确保码本更新期间的特征平衡覆盖。最后，按照IEEE 802.11a标准，利用四相相移键控（QPSK）调制以及正交频分复用（OFDM）实现数字通信。

**Result:** 实验结果表明，所提出的系统相较于基准方法具有更优的重建保真度。

**Conclusion:** 所提出的基于矢量量化的数字语义通信系统在信道自适应的图像传输方面取得了出色的效果，相较现有方法，系统在重建保真度上表现出显著优势。

**Abstract:** Discretization of semantic features enables interoperability between semantic
and digital communication systems, showing significant potential for practical
applications. The fundamental difficulty in digitizing semantic features stems
from the need to preserve continuity and context in inherently analog
representations during their compression into discrete symbols while ensuring
robustness to channel degradation. In this paper, we propose a vector quantized
(VQ)-enabled digital semantic communication system with channel adaptive image
transmission, named VQ-DeepISC. Guided by deep joint source-channel coding
(DJSCC), we first design a Swin Transformer backbone for hierarchical semantic
feature extraction, followed by VQ modules projecting features into discrete
latent spaces. Consequently, it enables efficient index-based transmission
instead of raw feature transmission. To further optimize this process, we
develop an attention mechanism-driven channel adaptation module to dynamically
optimize index transmission. Secondly, to counteract codebook collapse during
training process, we impose a distributional regularization by minimizing the
Kullback-Leibler divergence (KLD) between codeword usage frequencies and a
uniform prior. Meanwhile, exponential moving average (EMA) is employed to
stabilize training and ensure balanced feature coverage during codebook
updates. Finally, digital communication is implemented using quadrature phase
shift keying (QPSK) modulation alongside orthogonal frequency division
multiplexing (OFDM), adhering to the IEEE 802.11a standard. Experimental
results demonstrate superior reconstruction fidelity of the proposed system
over benchmark methods.

</details>


### [29] [Tobler's First Law in GeoAI: A Spatially Explicit Deep Learning Model for Terrain Feature Detection Under Weak Supervision](https://arxiv.org/abs/2508.03745)
*Wenwen Li,Chia-Yu Hsu,Maosheng Hu*

Main category: cs.CV

> 本文提出了一种新的弱监督下的目标检测方法，解决了AI在地理研究中的应用挑战，并成功应用在火星陨石坑检测上。

<details>
  <summary>Details</summary>

**Motivation:** 由于缺乏训练数据和忽视空间原理，AI与地理研究的深度整合遇到了挑战。本文旨在通过开发新的检测模型解决这些问题。

**Method:** 开发了一个基于弱标签的目标检测方法，该方法基于地理学的第一定律。同时，引入注意力图和多阶段训练策略来优化模型性能。

**Result:** 该模型能够准确检测火星上的陨石坑，并能推广应用于地球和其他行星的自然和人造特征检测。

**Conclusion:** 本研究为地理人工智能的理论和方法基础做出了贡献，证明了在弱监督情况下进行目标检测的潜力。

**Abstract:** Recent interest in geospatial artificial intelligence (GeoAI) has fostered a
wide range of applications using artificial intelligence (AI), especially deep
learning, for geospatial problem solving. However, major challenges such as a
lack of training data and the neglect of spatial principles and spatial effects
in AI model design remain, significantly hindering the in-depth integration of
AI with geospatial research. This paper reports our work in developing a deep
learning model that enables object detection, particularly of natural features,
in a weakly supervised manner. Our work makes three contributions: First, we
present a method of object detection using only weak labels. This is achieved
by developing a spatially explicit model based on Tobler's first law of
geography. Second, we incorporate attention maps into the object detection
pipeline and develop a multistage training strategy to improve performance.
Third, we apply this model to detect impact craters on Mars, a task that
previously required extensive manual effort. The model generalizes to both
natural and human-made features on the surfaces of Earth and other planets.
This research advances the theoretical and methodological foundations of GeoAI.

</details>


### [30] [Closed-Circuit Television Data as an Emergent Data Source for Urban Rail Platform Crowding Estimation](https://arxiv.org/abs/2508.03749)
*Riccardo Fiorista,Awad Abdelhalim,Anson F. Stewart,Gabriel L. Pincus,Ian Thistle,Jinhua Zhao*

Main category: cs.CV

> 研究通过三种先进的计算机视觉方法从平台CCTV图像中提取与人群相关的特征来评估CCTV影像对估算人群数量的潜力，并验证了计算机视觉方法可以为人群估算提供实质性价值。

<details>
  <summary>Details</summary>

**Motivation:** 准确估算城市铁路站台人数可以提高交通机构的运营决策能力，从而提高安全性、运营效率和客户体验，特别是在拥挤的情况下。但实时感应拥挤仍具有挑战性，计算机视觉方法被用以进行改进。

**Method:** 研究比较了三种先进的计算机视觉方法：使用YOLOv11、RT-DETRv2和APGCC进行目标检测和计数，通过定制训练的Vision Transformer（Crowd-ViT）进行人群级别分类，以及使用DeepLabV3进行语义分割。并且提出了一种新的高效的线性优化方法，以从生成的分割图中提取计数。

**Result:** 测试显示，基于计算机视觉的方法可以在没有其它数据的情况下为交通机构提供精确的实时拥挤估算。

**Conclusion:** 这项工作证明了CCTV影像数据能够独立于其他交通机构可用的数据源提供更精确的实时拥挤估算，并且最终支持及时的操作反应以减轻平台拥堵。

**Abstract:** Accurately estimating urban rail platform occupancy can enhance transit
agencies' ability to make informed operational decisions, thereby improving
safety, operational efficiency, and customer experience, particularly in the
context of crowding. However, sensing real-time crowding remains challenging
and often depends on indirect proxies such as automatic fare collection data or
staff observations. Recently, Closed-Circuit Television (CCTV) footage has
emerged as a promising data source with the potential to yield accurate,
real-time occupancy estimates. The presented study investigates this potential
by comparing three state-of-the-art computer vision approaches for extracting
crowd-related features from platform CCTV imagery: (a) object detection and
counting using YOLOv11, RT-DETRv2, and APGCC; (b) crowd-level classification
via a custom-trained Vision Transformer, Crowd-ViT; and (c) semantic
segmentation using DeepLabV3. Additionally, we present a novel, highly
efficient linear-optimization-based approach to extract counts from the
generated segmentation maps while accounting for image object depth and, thus,
for passenger dispersion along a platform. Tested on a privacy-preserving
dataset created in collaboration with the Washington Metropolitan Area Transit
Authority (WMATA) that encompasses more than 600 hours of video material, our
results demonstrate that computer vision approaches can provide substantive
value for crowd estimation. This work demonstrates that CCTV image data,
independent of other data sources available to a transit agency, can enable
more precise real-time crowding estimation and, eventually, timely operational
responses for platform crowding mitigation.

</details>
