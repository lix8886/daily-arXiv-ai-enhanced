<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 16]
- [cs.CV](#cs.CV) [Total: 19]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [What Kind of Reasoning (if any) is an LLM actually doing? On the Stochastic Nature and Abductive Appearance of Large Language Models](https://arxiv.org/abs/2512.10080)
*Luciano Floridi,Jessica Morley,Claudio Novelli,David Watson*

Main category: cs.CL

> 本文探讨了基于token-completion的大型语言模型工作的随机性质，并指出这些模型在看似具备人类溯因推理能力的情况下，实际上是基于训练数据中的推理结构生成文本。模型输出虽然看似有道理，但实际上缺乏真实性和验证能力。

<details>
  <summary>Details</summary>

**Motivation:** 文章动机在于揭示当前基于token-completion方法的大型语言模型的随机性质及其与人类溯因推理（abductive reasoning）的相似性。

**Method:** 本文通过探讨大型语言模型（LLMs）的工作原理，着重分析了这些模型如何通过学习人类生成文本中的推理结构，来表现出类似人类的溯因推理能力。

**Result:** 结果表明，尽管LLMs能够生成看似具有溯因推理能力的文本，但这并不意味着模型自身具备这种能力。这种表象主要来源于训练数据中的人类推理结构。

**Conclusion:** 文章结论强调了理解LLMs输出的随机性和表象的重要意义，认为尽管LLMs可以辅助生成想法并支持人类思维，但结果必须进行批判性评估。

**Abstract:** This article looks at how reasoning works in current Large Language Models (LLMs) that function using the token-completion method. It examines their stochastic nature and their similarity to human abductive reasoning. The argument is that these LLMs create text based on learned patterns rather than performing actual abductive reasoning. When their output seems abductive, this is largely because they are trained on human-generated texts that include reasoning structures. Examples are used to show how LLMs can produce plausible ideas, mimic commonsense reasoning, and give explanatory answers without being grounded in truth, semantics, verification, or understanding, and without performing any real abductive reasoning. This dual nature, where the models have a stochastic base but appear abductive in use, has important consequences for how LLMs are evaluated and applied. They can assist with generating ideas and supporting human thinking, but their outputs must be critically assessed because they cannot identify truth or verify their explanations. The article concludes by addressing five objections to these points, noting some limitations in the analysis, and offering an overall evaluation.

</details>


### [2] [Generate-Then-Validate: A Novel Question Generation Approach Using Small Language Models](https://arxiv.org/abs/2512.10110)
*Yumou Wei,John Stamper,Paulo F. Carvalho*

Main category: cs.CL

> 研究探索了小型语言模型(SLMs)在自动问题生成中的应用，提出了一种新型问题生成管道，该管道利用了SLMs的文本生成和概率推理能力。通过“先生成后验证”的策略，该管道初步生成大量候选问题并利用概率推理进行精心筛选。实验结果显示，生成的问题质量良好，得到了人类专家和大型语言模型的一致认可，表明在合理设计的管道辅助下，SLMs可以有效生成高质量问题。

<details>
  <summary>Details</summary>

**Motivation:** 自动问题生成在学习分析领域通常依赖大型语言模型，然而，小型语言模型是否也能胜任此任务尚未得到充分探索。本文旨在探索小型语言模型在自动问题生成中的应用潜力。

**Method:** 研究提出了一种创新的问题生成管道，利用了小型语言模型的文本生成能力和概率推理能力。首先采用“生成-验证”策略，生成大量候选问题，然后通过概率推理法进行错误选择和优化。

**Result:** 通过两种评估研究—一种由七位人类专家进行，另一种由大型语言模型执行—验证了生成问题的质量。大多数评判者认为生成的问题清晰且大多符合预设学习目标。

**Conclusion:** 本研究发现，有适当设计的管道指导，小型语言模型能够生成高质量问题，证实了小型语言模型在问题生成任务中的潜力。

**Abstract:** We explore the use of small language models (SLMs) for automatic question generation as a complement to the prevalent use of their large counterparts in learning analytics research. We present a novel question generation pipeline that leverages both the text generation and the probabilistic reasoning abilities of SLMs to generate high-quality questions. Adopting a "generate-then-validate" strategy, our pipeline first performs expansive generation to create an abundance of candidate questions and refine them through selective validation based on novel probabilistic reasoning. We conducted two evaluation studies, one with seven human experts and the other with a large language model (LLM), to assess the quality of the generated questions. Most judges (humans or LLMs) agreed that the generated questions had clear answers and generally aligned well with the intended learning objectives. Our findings suggest that an SLM can effectively generate high-quality questions when guided by a well-designed pipeline that leverages its strengths.

</details>


### [3] [Workflow is All You Need: Escaping the "Statistical Smoothing Trap" via High-Entropy Information Foraging and Adversarial Pacing](https://arxiv.org/abs/2512.10121)
*Zhongjie Jiang*

Main category: cs.CL

> The paper addresses the generation of high-quality long-form texts by proposing the DeepNews Framework, which combats the Statistical Smoothing Trap through integrated retrieval, planning, and adversarial prompting methods, showing improved performance in a financial journalism context over existing models.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the limitations of current large language models that struggle with the 'impossible trinity' of low hallucination, deep logical coherence, and personalized expression in long-form text generation, especially in vertical domains like financial journalism.

**Method:** The method involves the DeepNews Framework with three core modules: (1) a dual-granularity retrieval mechanism enforcing a 10:1 saturated information input ratio, (2) schema-guided strategic planning using narrative schemas and Atomic Blocks, and (3) adversarial constraint prompting with tactics such as Rhythm Break and Logic Fog to reduce the Statistical Smoothing Trap.

**Result:** Experiments show a Knowledge Cliff in deep financial reporting, suggesting that retrieved context above 15,000 characters is necessary for content truthfulness and a high-redundancy input over 30,000 characters keeps the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test, DeepNews achieved a 25% submission acceptance rate, better than SOTA models with 0% acceptance.

**Conclusion:** The conclusion is that the DeepNews Framework can effectively mitigate hallucinations and improve logical coherence and personalization in long-form text generation, particularly for financial domain texts.

**Abstract:** Central to long-form text generation in vertical domains is the "impossible trinity" confronting current large language models (LLMs): the simultaneous achievement of low hallucination, deep logical coherence, and personalized expression. This study establishes that this bottleneck arises from existing generative paradigms succumbing to the Statistical Smoothing Trap, a phenomenon that overlooks the high-entropy information acquisition and structured cognitive processes integral to expert-level writing. To address this limitation, we propose the DeepNews Framework, an agentic workflow that explicitly models the implicit cognitive processes of seasoned financial journalists. The framework integrates three core modules: first, a dual-granularity retrieval mechanism grounded in information foraging theory, which enforces a 10:1 saturated information input ratio to mitigate hallucinatory outputs; second, schema-guided strategic planning, a process leveraging domain expert knowledge bases (narrative schemas) and Atomic Blocks to forge a robust logical skeleton; third, adversarial constraint prompting, a technique deploying tactics including Rhythm Break and Logic Fog to disrupt the probabilistic smoothness inherent in model-generated text. Experiments delineate a salient Knowledge Cliff in deep financial reporting: content truthfulness collapses when retrieved context falls below 15,000 characters, while a high-redundancy input exceeding 30,000 characters stabilizes the Hallucination-Free Rate (HFR) above 85%. In an ecological validity blind test conducted with a top-tier Chinese technology media outlet, the DeepNews system--built on a previous-generation model (DeepSeek-V3-0324)-achieved a 25% submission acceptance rate, significantly outperforming the 0% acceptance rate of zero-shot generation by a state-of-the-art (SOTA) model (GPT-5).

</details>


### [4] [PARAN: Persona-Augmented Review ANswering system on Food Delivery Review Dataset](https://arxiv.org/abs/2512.10148)
*Moonsoo Park,Jeongseok Yun,Bohyung Kim*

Main category: cs.CL

> 本文提出一种两阶段提示框架，旨在通过分析用户简短评论来推断用户的人格特征（显性和隐性），并将这些特征融入到回复生成中，以生成个性化回复，提高自动回复的相关性和个性化水平，而不需要对模型进行微调。

<details>
  <summary>Details</summary>

**Motivation:** 在用户信息有限的领域，如外卖平台，语言模型生成的回复往往缺乏针对性，为此提出了这种方法以提高回复的相关性和用户参与度。

**Method:** 使用两阶段的提示框架，从用户简短评论中推断显性和隐性的人格特征，并调整解码温度以生成多样但保持语义一致的回复。

**Result:** 通过使用从韩国外卖应用程序收集的真实数据集进行评估，结果表明所提出的方法在精度、多样性和语义一致性方面均表现出色。

**Conclusion:** 实验证明，基于人格特征增强的提示框架可以有效提高自动化回复的相关性和个性化。

**Abstract:** Personalized review response generation presents a significant challenge in domains where user information is limited, such as food delivery platforms. While large language models (LLMs) offer powerful text generation capabilities, they often produce generic responses when lacking contextual user data, reducing engagement and effectiveness. In this work, we propose a two-stage prompting framework that infers both explicit (e.g., user-stated preferences) and implicit (e.g., demographic or stylistic cues) personas directly from short review texts. These inferred persona attributes are then incorporated into the response generation prompt to produce user-tailored replies. To encourage diverse yet faithful generations, we adjust decoding temperature during inference. We evaluate our method using a real-world dataset collected from a Korean food delivery app, and assess its impact on precision, diversity, and semantic consistency. Our findings highlight the effectiveness of persona-augmented prompting in enhancing the relevance and personalization of automated responses without requiring model fine-tuning.

</details>


### [5] [Unforgotten Safety: Preserving Safety Alignment of Large Language Models with Continual Learning](https://arxiv.org/abs/2512.10150)
*Lama Alssum,Hani Itani,Hasan Abed Al Kader Hammoud,Philip Torr,Adel Bibi,Bernard Ghanem*

Main category: cs.CL

> 本研究探讨了大规模语言模型在适应新任务时的安全性退化问题，并通过实验验证了连续学习方法在维持模型安全性方面的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 由于大规模语言模型的普及，其安全性对齐变得越来越重要。本研究旨在解决这些模型在适应新任务时安全性降低的问题。

**Method:** 我们研究了LLMs在适应新任务时的安全性退化问题，将其归因于灾难性遗忘，并将保持安全性的任务视作连续学习问题。我们在“基于服务的微调”设置中测试了几种文献中的连续学习方法，包括基于正则化的、基于记忆的和模型合并的方法。

**Result:** 研究结果表明，连续学习方法比标准微调方法降低了攻击成功率。在几种方法中，DER方法在保持任务效率的同时，表现优于其他连续学习方法和现有的安全保护基线。

**Conclusion:** 通过对三种下游任务和三种模型家族的评估，建立连续学习作为一种保留安全性的实用解决方案。

**Abstract:** The safety alignment of large language models (LLMs) is becoming increasingly important with their democratization. In this paper, we study the safety degradation that comes with adapting LLMs to new tasks. We attribute this safety compromise to catastrophic forgetting and frame the problem of preserving safety when fine-tuning as a continual learning (CL) problem. We consider the fine-tuning-as-a-service setup where the user uploads their data to a service provider to get a customized model that excels on the user's selected task. We adapt several CL approaches from the literature and systematically evaluate their ability to mitigate safety degradation. These include regularization-based, memory-based, and model merging approaches. We consider two scenarios, (1) benign user data and (2) poisoned user data. Our results demonstrate that CL approaches consistently achieve lower attack success rates than standard fine-tuning. Among these, DER outperforms both other CL methods and existing safety-preserving baselines while maintaining task utility. These findings generalize across three downstream tasks (GSM8K, SST2, Code) and three model families (LLaMA2-7B, Mistral-7B, Gemma-2B), establishing CL as a practical solution to preserve safety.

</details>


### [6] [AutoMedic: An Automated Evaluation Framework for Clinical Conversational Agents with Medical Dataset Grounding](https://arxiv.org/abs/2512.10195)
*Gyutaek Oh,Sangjoon Park,Byung-Hoon Kim*

Main category: cs.CL

> 研究提出了一种多智能体模拟框架AutoMedic，用于评估LLM在动态互动临床对话代理中的表现，评估基于多面性标准，实验结果得到专家验证，表明AutoMedic作为临床对话代理自动化评估框架的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 虽然静态医疗问答基准已被提出，但在生成动态、互动的临床多轮对话响应及多方面评估策略方面仍存在大量未探索的领域。动态、互动临床情景的正式评估受限于大量可能的患者状态和交互轨迹的组合空间，难以标准化和定量测量。

**Method:** 提出了AutoMedic，一个多智能体模拟框架，该框架通过转化现成的静态QA数据集为虚拟患者档案，实现LLM作为临床对话代理的自动化评估。性能评估基于CARE指标，该指标涵盖临床对话准确性、效率/策略、共情与稳健性的多维度评价标准。

**Result:** 研究发现，经人类专家验证，AutoMedic作为自动化评估框架在评估临床对话代理的有效性和实用性上是有效的，为LLM在对话式医疗应用领域的有效开发提供实用指南。

**Conclusion:** 研究显示，AutoMedic框架提供了一种新颖的方法，用于自动化评估LLM在临床对话代理中的表现，并强调其在指导LLM在对话式医疗应用中得到有效开发中的作用。

**Abstract:** Evaluating large language models (LLMs) has recently emerged as a critical issue for safe and trustworthy application of LLMs in the medical domain. Although a variety of static medical question-answering (QA) benchmarks have been proposed, many aspects remain underexplored, such as the effectiveness of LLMs in generating responses in dynamic, interactive clinical multi-turn conversation situations and the identification of multi-faceted evaluation strategies beyond simple accuracy. However, formally evaluating a dynamic, interactive clinical situation is hindered by its vast combinatorial space of possible patient states and interaction trajectories, making it difficult to standardize and quantitatively measure such scenarios. Here, we introduce AutoMedic, a multi-agent simulation framework that enables automated evaluation of LLMs as clinical conversational agents. AutoMedic transforms off-the-shelf static QA datasets into virtual patient profiles, enabling realistic and clinically grounded multi-turn clinical dialogues between LLM agents. The performance of various clinical conversational agents is then assessed based on our CARE metric, which provides a multi-faceted evaluation standard of clinical conversational accuracy, efficiency/strategy, empathy, and robustness. Our findings, validated by human experts, demonstrate the validity of AutoMedic as an automated evaluation framework for clinical conversational agents, offering practical guidelines for the effective development of LLMs in conversational medical applications.

</details>


### [7] [Multilingual VLM Training: Adapting an English-Trained VLM to French](https://arxiv.org/abs/2512.10336)
*Jules Lahmi,Alexis Roger*

Main category: cs.CL

> 本论文探讨了将英语训练的视觉-语言模型（VLMs）适应不同语言的挑战，并比较了不同方法的性能和计算成本。研究发现，数据集翻译是多语言VLM性能的主要瓶颈，数据质量限制了训练和评估的效果。未来应关注原生语言数据集的收集和改进翻译策略。

<details>
  <summary>Details</summary>

**Motivation:** 虽然人工智能在理解和处理视觉和文本数据方面取得了显著进步，但这些进展主要局限于英语。为了提高非英语使用者的可访问性，有必要扩展这些技术到更广泛的语言中。

**Method:** 研究采用了翻译管道、LoRA微调和两阶段微调策略（分别适应视觉和语言）三种方法进行比较。

**Result:** 结果显示，数据集翻译是多语言VLM性能的重要限制因素，且数据质量直接影响训练和评估的效果。

**Conclusion:** 研究结论表明，为了提高多语言VLM的性能，未来工作的重点应是原生语言数据集的收集和改进翻译方法。

**Abstract:** Artificial intelligence has made great progress in recent years, particularly in the development of Vision--Language Models (VLMs) that understand both visual and textual data. However, these advancements remain largely limited to English, reducing their accessibility for non--English speakers. It is essential to extend these capabilities to a broader range of languages. This paper explores the challenges of adapting an English-trained VLM to different languages. To this end, we will explore and compare different methods for their performance and computational cost. We consider a translation-based pipeline, LoRA finetuning, and a two-stage finetuning strategy that separates vision adaptation from language adaptation. To evaluate these methods, we use a combination of standard multimodal benchmarks translated into the target language and manual assessments by native experts. The results reveal that dataset translation remains a major bottleneck in multilingual VLM performance, with data quality limiting the effectiveness of training and evaluation. These findings suggest that future efforts should focus on native-language dataset collection and improved translation strategies.

</details>


### [8] [Confucius Code Agent: An Open-sourced AI Software Engineer at Industrial Scale](https://arxiv.org/abs/2512.10398)
*Zhaodong Wang,Zhenting Qi,Sherman Wong,Nathan Hu,Samuel Lin,Jun Ge,Erwin Gao,Yining Yang,Ben Maurer,Wenlin Chen,David Recordon,Yilun Du,Minlan Yu,Ying Zhang*

Main category: cs.CL

> 介绍了Confucius Code Agent (CCA)，一个开源的、工业级的AI软件工程师，基于Confucius SDK开发平台，通过统一编排器、持久笔记系统和模块扩展功能等机制，在SWE-Bench-Pro基准测试中取得了54.3%的Resolve@1先进性能，填补了研究原型和生产系统之间的空白。

<details>
  <summary>Details</summary>

**Motivation:** 满足现实世界AI软件工程的需求，解决现有开源编码代理和专有编码代理在工业规模工作负载下的不足。

**Method:** 开发了Confucius SDK，包括统一编排器和持久笔记系统等功能，支持长上下文推理、跨会话持续学习和强大的工具使用。

**Result:** CCA在SWE-Bench-Pro基准测试中实现了54.3%的Resolve@1性能，超越了之前同类产品的表现。

**Conclusion:** Confucius SDK和CCA提供了一个透明、可扩展和支持工业规模代理开发和部署的可靠基础。

**Abstract:** Real-world AI software engineering demands coding agents that can reason over massive repositories, maintain durable memory across and within long sessions, and robustly coordinate complex toolchains at test time. Existing open-source coding agents provide transparency but frequently fall short when pushed to these industrial-scale workloads, while proprietary coding agents offer strong practical performance but limited extensibility, interpretability, and controllability. We present the Confucius Code Agent (CCA), an open-sourced AI software engineer that can operate at an industrial scale. CCA is built atop the Confucius SDK, an open-sourced agent development platform designed around three complementary perspectives: Agent Experience (AX), User Experience (UX), and Developer Experience (DX). The SDK introduces a unified orchestrator with hierarchical working memory for long-context reasoning, a persistent note-taking system for cross-session continual learning, and a modular extension module for robust tool use. Moreover, a meta-agent automates the synthesis, evaluation, and refinement of agent configurations through a build-test-improve loop, enabling rapid agent development on new tasks, environments, and tool stacks. Instantiated on Confucius SDK with these mechanisms, CCA delivers strong performance on real-world software engineering tasks. On SWE-Bench-Pro, CCA achieves a state-of-the-art Resolve@1 performance of 54.3%, substantially improving over prior coding agents. Together, the Confucius SDK and CCA provide a transparent, extensible, and reproducible foundation for AI agents, bridge gaps between research prototypes and production-grade systems, and support agent development and deployment at industrial scale.

</details>


### [9] [Sliding Window Attention Adaptation](https://arxiv.org/abs/2512.10411)
*Yijiong Yu,Jiale Liu,Qingyun Wu,Huazheng Wang,Ji Pei*

Main category: cs.CL

> This paper explores adapting full attention-pretrained LLMs to sliding window attention without retraining through SWAA, showing that by combining specific methods, original long-context performance can be effectively recovered.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to reduce the computational cost of self-attention in Transformer-based LLMs from quadratic to linear complexity while maintaining performance, addressing the issue that naive application of SWA after FA pretraining leads to performance degradation.

**Method:** The paper proposes Sliding Window Attention Adaptation (SWAA), which combines five methods for better adaptation to sliding window attention (SWA) without retraining the model: applying SWA only during prefilling, preserving 'sink' tokens, interleaving full attention (FA)/SWA layers, using chain-of-thought (CoT), and fine-tuning.

**Result:** The experiments demonstrate that adaptation to SWA is possible, but not straightforward; no single method can recover the performance alone, and synergistic combinations of methods are necessary.

**Conclusion:** The study concludes that while adapting full attention-pretrained models to sliding window attention is feasible, it requires careful selection and combination of methods to maintain performance. Recommended configurations are provided for different use cases.

**Abstract:** The self-attention mechanism in Transformer-based Large Language Models (LLMs) scales quadratically with input length, making long-context inference expensive. Sliding window attention (SWA) reduces this cost to linear complexity, but naively enabling complete SWA at inference-time for models pretrained with full attention (FA) causes severe long-context performance degradation due to training-inference mismatch. This makes us wonder: Can FA-pretrained LLMs be well adapted to SWA without pretraining? We investigate this by proposing Sliding Window Attention Adaptation (SWAA), a set of practical recipes that combine five methods for better adaptation: (1) applying SWA only during prefilling; (2) preserving "sink" tokens; (3) interleaving FA/SWA layers; (4) chain-of-thought (CoT); and (5) fine-tuning. Our experiments show that SWA adaptation is feasible while non-trivial: no single method suffices, yet specific synergistic combinations effectively recover the original long-context performance. We further analyze the performance-efficiency trade-offs of different SWAA configurations and provide recommended recipes for diverse scenarios. Our code is available at https://github.com/yuyijiong/sliding-window-attention-adaptation

</details>


### [10] [Cooperative Retrieval-Augmented Generation for Question Answering: Mutual Information Exchange and Ranking by Contrasting Layers](https://arxiv.org/abs/2512.10422)
*Youmin Ko,Sungjong Seo,Hyunjoon Kim*

Main category: cs.CL

> 提出了一种名为CoopRAG的新框架，用于问题回答任务，通过检索器和大型语言模型之间的合作，以及检索器模型各层之间的合作，来准确评估检索文档的相关性，从而在多跳问答和简单问答任务中提高了表现。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有基于检索增强生成（RAG）方法容易发生错误检索和幻觉的问题，特别是在多跳问答（QA）问题中。

**Method:** CoopRAG框架通过将问题分解为子问题和推理链、检索相关文档、对比检索器各层级来重新评估文档相关性，以及利用LLM填充推理链中的不确定位置，以确保准确性和可靠性。

**Result:** 实验结果证明，CoopRAG在多跳问答和简单问答数据集上都优于现有的问答方法，不论是检索性能还是问答性能方面。

**Conclusion:** CoopRAG框架通过优化检索器与大型语言模型之间的合作，有效改善了问答系统的性能，减少了错误和幻觉，并提供了超出原有方法的表现。

**Abstract:** Since large language models (LLMs) have a tendency to generate factually inaccurate output, retrieval-augmented generation (RAG) has gained significant attention as a key means to mitigate this downside of harnessing only LLMs. However, existing RAG methods for simple and multi-hop question answering (QA) are still prone to incorrect retrievals and hallucinations. To address these limitations, we propose CoopRAG, a novel RAG framework for the question answering task in which a retriever and an LLM work cooperatively with each other by exchanging informative knowledge, and the earlier and later layers of the retriever model work cooperatively with each other to accurately rank the retrieved documents relevant to a given query. In this framework, we (i) unroll a question into sub-questions and a reasoning chain in which uncertain positions are masked, (ii) retrieve the documents relevant to the question augmented with the sub-questions and the reasoning chain, (iii) rerank the documents by contrasting layers of the retriever, and (iv) reconstruct the reasoning chain by filling the masked positions via the LLM. Our experiments demonstrate that CoopRAG consistently outperforms state-of-the-art QA methods on three multi-hop QA datasets as well as a simple QA dataset in terms of both the retrieval and QA performances. Our code is available.\footnote{https://github.com/meaningful96/CoopRAG}

</details>


### [11] [T-pro 2.0: An Efficient Russian Hybrid-Reasoning Model and Playground](https://arxiv.org/abs/2512.10430)
*Dmitrii Stoianov,Danil Taranets,Olga Tsymboi,Ramil Latypov,Almaz Dautov,Vladislav Kruglikov,Nikita Surkov,German Abramov,Pavel Gein,Dmitry Abulkhanov,Mikhail Gashkov,Viktor Zelenkovskiy,Artem Batalov,Aleksandr Medvedev,Anatolii Potapov*

Main category: cs.CL

> T-pro 2.0是一款支持俄语混合推理和高效推理的开源语言模型，通过改进的解码流程减少延迟，同时公开了模型权重和其他研究资源，便于研究者进行二次开发和应用评估。

<details>
  <summary>Details</summary>

**Motivation:** 推动俄语语言模型的研究和应用，提供可复现、可扩展的研究资源。

**Method:** 使用包含大量西里尔字母的分词器和优化过的EAGLE猜测性解码流程构建模型。

**Result:** 发布了T-pro 2.0模型权重，T-Wix 500k指令语料库，T-Math推理基准，EAGLE权重。公共web演示界面展示了推理和非推理模式，并呈现出跨领域的推理速度提升。

**Conclusion:** T-pro 2.0作为一套开源系统，可用来构建和评估高效率、实用的俄语语言模型应用。

**Abstract:** We introduce T-pro 2.0, an open-weight Russian LLM for hybrid reasoning and efficient inference. The model supports direct answering and reasoning-trace generation, using a Cyrillic-dense tokenizer and an adapted EAGLE speculative-decoding pipeline to reduce latency. To enable reproducible and extensible research, we release the model weights, the T-Wix 500k instruction corpus, the T-Math reasoning benchmark, and the EAGLE weights on Hugging Face. These resources allow users to study Russian-language reasoning and to extend or adapt both the model and the inference pipeline. A public web demo exposes reasoning and non-reasoning modes and illustrates the speedups achieved by our inference stack across domains. T-pro 2.0 thus serves as an accessible open system for building and evaluating efficient, practical Russian LLM applications.

</details>


### [12] [Semantic Reconstruction of Adversarial Plagiarism: A Context-Aware Framework for Detecting and Restoring "Tortured Phrases" in Scientific Literature](https://arxiv.org/abs/2512.10435)
*Agniva Maiti,Prajwal Panth,Suresh Chandra Satapathy*

Main category: cs.CL

> 本论文提出了一种名为SRAP的框架，旨在检测和恢复科学文献中由自动化改述工具生成的"扭曲短语"，并在实验中显示了显著优于基线方法的效果。

<details>
  <summary>Details</summary>

**Motivation:** 由于自动化改述工具生成的"扭曲短语"问题，科学文献的完整性和可靠性面临严重威胁。现有的检测方法依赖于静态黑名单或通用语言模型，对于新的伪装方式存在较高误漏率且无法确定剽窃源。

**Method:** 本论文提出了一种名为语义重建对抗性剽窃(SRAP)的框架，该框架采用两阶段架构：首先，利用领域特定的掩码语言模型（例如SciBERT）进行统计异常检测；其次，利用密集向量检索（FAISS）和句子级别对齐（SBERT）技术进行基于源的语义重建。

**Result:** 实验结果表明，相对于零样本基线（0%恢复准确率），我们的检索增强方法在对抗性科学文本上的恢复准确率为23.67%。

**Conclusion:** SRAP可以在高专业术语密集的文本中进行有效的检测，并且将混淆表达链接回最可能的来源文档，从而实现取证分析功能。

**Abstract:** The integrity and reliability of scientific literature is facing a serious threat by adversarial text generation techniques, specifically from the use of automated paraphrasing tools to mask plagiarism. These tools generate "tortured phrases", statistically improbable synonyms (e.g. "counterfeit consciousness" for "artificial intelligence"), that preserve the local grammar while obscuring the original source. Most existing detection methods depend heavily on static blocklists or general-domain language models, which suffer from high false-negative rates for novel obfuscations and cannot determine the source of the plagiarized content. In this paper, we propose Semantic Reconstruction of Adversarial Plagiarism (SRAP), a framework designed not only to detect these anomalies but to mathematically recover the original terminology. We use a two-stage architecture: (1) statistical anomaly detection with a domain-specific masked language model (SciBERT) using token-level pseudo-perplexity, and (2) source-based semantic reconstruction using dense vector retrieval (FAISS) and sentence-level alignment (SBERT). Experiments on a parallel corpus of adversarial scientific text show that while zero-shot baselines fail completely (0.00 percent restoration accuracy), our retrieval-augmented approach achieves 23.67 percent restoration accuracy, significantly outperforming baseline methods. We also show that static decision boundaries are necessary for robust detection in jargon-heavy scientific text, since dynamic thresholding fails under high variance. SRAP enables forensic analysis by linking obfuscated expressions back to their most probable source documents.

</details>


### [13] [Enhancing Next-Generation Language Models with Knowledge Graphs: Extending Claude, Mistral IA, and GPT-4 via KG-BERT](https://arxiv.org/abs/2512.10440)
*Nour El Houda Ben Chaabene,Hamza Hammami*

Main category: cs.CL

> 将知识图谱通过KG-BERT与大型语言模型结合，提升了事实一致性和上下文感知能力，特别是在问答和实体链接等需要大量知识的任务上表现优异。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型如Claude、Mistral IA和GPT-4在自然语言处理领域表现出色，但缺乏结构化的知识，导致事实上的不一致性。

**Method:** 通过将知识图谱(KGs)融入到KG-BERT中，以增强大语言模型的知识基础以及推理能力。

**Result:** 实验结果显示，在需要大量知识的任务如问题回答和实体链接方面，该方法显著提升了性能。

**Conclusion:** 这种整合方法提高了大型语言模型的事实可靠性，促进了更具上下文感知能力的下一代模型的发展。

**Abstract:** Large language models (LLMs) like Claude, Mistral IA, and GPT-4 excel in NLP but lack structured knowledge, leading to factual inconsistencies. We address this by integrating Knowledge Graphs (KGs) via KG-BERT to enhance grounding and reasoning. Experiments show significant gains in knowledge-intensive tasks such as question answering and entity linking. This approach improves factual reliability and enables more context-aware next-generation LLMs.

</details>


### [14] [Decoding Student Minds: Leveraging Conversational Agents for Psychological and Learning Analysis](https://arxiv.org/abs/2512.10441)
*Nour El Houda Ben Chaabene,Hamza Hammami,Laid Kahloul*

Main category: cs.CL

> 本文提出了一种心理适应的对话系统，旨在提高学习表现和情感福祉。系统结合了大型语言模型、知识图谱增强的BERT（KG-BERT）和带注意力机制的双向长短期记忆网络（LSTM）来实时识别学生的情感和认知状态。相比之前的聊天机器人，该系统利用多模态数据，包括文本语义、语音特征和时间行为趋势来推断学生的参与度、压力和概念理解程度。在大学学生中的初步研究表明，相较于基线方法，学生动机提高，压力减少，且有中等的学业进步。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在开发一种能够同时提供辅导和支持学生情感的对话系统，以提升教育效果。它关注多模态数据分析和情感认知状态的实时监控，借此辅助个性化、以学生为中心的教育干预。

**Method:** 系统采用了大型语言模型、基于知识图谱的BERT（KG-BERT），以及一个带有注意力机制的双向长短期记忆（LSTM），用于处理多模态数据，以实时识别学生的情感和认知状态。

**Result:** 初步研究显示，该系统相比基线方法能提高学生动机，减少压力，同时还能实现中等程度的学业进步。

**Conclusion:** 这些研究结果表明，融合语义推理、多模态融合和时间建模技术，是支持适应性、以学生为中心的教育干预的一个有前景的方向。

**Abstract:** This paper presents a psychologically-aware conversational agent designed to enhance both learning performance and emotional well-being in educational settings. The system combines Large Language Models (LLMs), a knowledge graph-enhanced BERT (KG-BERT), and a bidirectional Long Short-Term Memory (LSTM) with attention to classify students' cognitive and affective states in real time. Unlike prior chatbots limited to either tutoring or affective support, our approach leverages multimodal data-including textual semantics, prosodic speech features, and temporal behavioral trends-to infer engagement, stress, and conceptual understanding. A pilot study with university students demonstrated improved motivation, reduced stress, and moderate academic gains compared to baseline methods. These results underline the promise of integrating semantic reasoning, multimodal fusion, and temporal modeling to support adaptive, student-centered educational interventions.

</details>


### [15] [Grammaticality Judgments in Humans and Language Models: Revisiting Generative Grammar with LLMs](https://arxiv.org/abs/2512.10453)
*Lars G. B. Johnsen*

Main category: cs.CL

> 大型语言模型在没有明确设计句法结构的情况下，通过预测训练也能展现出对结构化的敏感度，从而在主谓倒装和寄生间隙的许可上表现出语法区分能力。

<details>
  <summary>Details</summary>

**Motivation:** 传统的生成语法认为系统性语法规则的差异是内在层次化语法存在的证据，如主谓倒装和寄生间隙的许可。本文旨在检验仅基于表面形式训练的大语言模型是否也能够重现这些差异。

**Method:** 本文通过测试大型语言模型（LLMs）是否能重现系统性的语法差异，比如主谓倒装和寄生间隙的许可，以此来判断它们是否具有潜在的结构表示能力。研究选择GPT-4和LLaMA-3作为测试模型，并采用了引发可接受性评分的提示语进行评估。

**Result:** 实验结果表明，LLMs 对两种构造中的语法和非语法变化模式能够可靠地区分，这支持了它们对结构的敏感度而不仅仅是线性顺序。

**Conclusion:** 结构泛化从表面形式的预测训练中自然生成，这表明了LLMs 在没有明确编码的情况下对于句法结构的功能敏感性。

**Abstract:** What counts as evidence for syntactic structure? In traditional generative grammar, systematic contrasts in grammaticality such as subject-auxiliary inversion and the licensing of parasitic gaps are taken as evidence for an internal, hierarchical grammar. In this paper, we test whether large language models (LLMs), trained only on surface forms, reproduce these contrasts in ways that imply an underlying structural representation.
  We focus on two classic constructions: subject-auxiliary inversion (testing recognition of the subject boundary) and parasitic gap licensing (testing abstract dependency structure). We evaluate models including GPT-4 and LLaMA-3 using prompts eliciting acceptability ratings. Results show that LLMs reliably distinguish between grammatical and ungrammatical variants in both constructions, and as such support that they are sensitive to structure and not just linear order. Structural generalizations, distinct from cognitive knowledge, emerge from predictive training on surface forms, suggesting functional sensitivity to syntax without explicit encoding.

</details>


### [16] [XDoGE: Multilingual Data Reweighting to Enhance Language Inclusivity in LLMs](https://arxiv.org/abs/2512.10545)
*Iñaki Lacunza,José Javier Saiz,Alexander Shvets,Aitor Gonzalez-Agirre,Marta Villegas*

Main category: cs.CL

> 本研究提出使用扩展的XDoGE算法和数据调整方法来优化多语言大模型的训练过程，以改善其在不同资源级别的语言中的表现。实验涉及六种伊比利亚语言，并公开了一个优化的IberianLLM-7B-Instruct模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型主要依赖于少数几种高资源语言的大量文本数据进行训练，这会影响它们在中低资源语言中的表现。因此，本研究旨在通过上述方法来优化语言分布和训练过程，以改善模型在不同资源级别的语言上的表现。

**Method:** 优化语言分布的方法是通过在域重加权的DoGE算法基础上进行扩展，形成适用于多语言环境的XDoGE算法，以训练一个小的代理模型。此外，我们通过调整数据量，并使用确定的语言权重，训练一个全尺寸模型，这可以通过从头开始预训练或者在持续预训练（CPT）阶段完成。

**Result:** 使用的模型是Salamandra-2b，并针对六种具有不同地理分布和语言家族关系的语言进行了实验，其中包括高资源语言（英语和西班牙语）、中等资源语言（葡萄牙语和加泰罗尼亚语）以及低资源语言（加利西亚语和巴斯克语）。我们通过IberoBench框架来定量评估小语言数据的大量重复以及主要语言的不足抽样对模型性能的影响。

**Conclusion:** 最终，我们公开了一个专注于伊比利亚语言及英语的新模型IberianLLM-7B-Instruct，该模型最初是从零开始预训练的，并进一步通过带有XDoGE权重的持续预训练来改进。

**Abstract:** Current large language models (LLMs) are trained on massive amounts of text data, primarily from a few dominant languages. Studies suggest that this over-reliance on high-resource languages, such as English, hampers LLM performance in mid- and low-resource languages. To mitigate this problem, we propose to (i) optimize the language distribution by training a small proxy model within a domain-reweighing DoGE algorithm that we extend to XDoGE for a multilingual setup, and (ii) rescale the data and train a full-size model with the established language weights either from scratch or within a continual pre-training phase (CPT). We target six languages possessing a variety of geographic and intra- and inter-language-family relations, namely, English and Spanish (high-resource), Portuguese and Catalan (mid-resource), Galician and Basque (low-resource). We experiment with Salamandra-2b, which is a promising model for these languages. We investigate the effects of substantial data repetition on minor languages and under-sampling on dominant languages using the IberoBench framework for quantitative evaluation. Finally, we release a new promising IberianLLM-7B-Instruct model centering on Iberian languages and English that we pretrained from scratch and further improved using CPT with the XDoGE weights.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [17] [Neuromorphic Eye Tracking for Low-Latency Pupil Detection](https://arxiv.org/abs/2512.09969)
*Paul Hueber,Luca Peres,Florian Pitters,Alejandro Gloriani,Oliver Rhodes*

Main category: cs.CV

> 文章提出了一种高效的基于事件的神经形态眼动追踪模型，相比最新的人工神经网络模型，模型大小减少了20倍，理论计算量减少了850倍，同时保持了准确性的适宜实时部署。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在提升可穿戴设备中的眼动追踪能力，解决传统帧基方法中存在的运动模糊、计算成本高和时间分辨率低的问题。

**Method:** 本文提出了一种基于事件的神经形态眼动追踪模型的轻量化设计，用LIF层替换了传统的循环和注意力模块，并利用深度可分离卷积减少模型复杂度。

**Result:** 所提模型获得了3.7-4.1像素的均值误差，接近于特定应用的神经形态系统Retina（3.24像素），并且能以3.9-4.9毫瓦的功耗和3毫秒的延迟在1KHz运行。

**Conclusion:** 研究表明，基于事件的眼动追踪架构可以被设计为高效的SNN，同时保持适用于实时穿戴部署的准确性。

**Abstract:** Eye tracking for wearable systems demands low latency and milliwatt-level power, but conventional frame-based pipelines struggle with motion blur, high compute cost, and limited temporal resolution. Such capabilities are vital for enabling seamless and responsive interaction in emerging technologies like augmented reality (AR) and virtual reality (VR), where understanding user gaze is key to immersion and interface design. Neuromorphic sensors and spiking neural networks (SNNs) offer a promising alternative, yet existing SNN approaches are either too specialized or fall short of the performance of modern ANN architectures. This paper presents a neuromorphic version of top-performing event-based eye-tracking models, replacing their recurrent and attention modules with lightweight LIF layers and exploiting depth-wise separable convolutions to reduce model complexity. Our models obtain 3.7-4.1px mean error, approaching the accuracy of the application-specific neuromorphic system, Retina (3.24px), while reducing model size by 20x and theoretical compute by 850x, compared to the closest ANN variant of the proposed model. These efficient variants are projected to operate at an estimated 3.9-4.9 mW with 3 ms latency at 1 kHz. The present results indicate that high-performing event-based eye-tracking architectures can be redesigned as SNNs with substantial efficiency gains, while retaining accuracy suitable for real-time wearable deployment.

</details>


### [18] [ABBSPO: Adaptive Bounding Box Scaling and Symmetric Prior based Orientation Prediction for Detecting Aerial Image Objects](https://arxiv.org/abs/2512.10031)
*Woojin Lee,Hyugjae Chang,Jaeho Moon,Jaehyup Lee,Munchurl Kim*

Main category: cs.CV

> 本文提出了ABBSPO框架，用于弱监督环境下的倾斜物体检测，该方法在尺度估计和自监督学习方面进行了改进，实验结果显示了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于改进弱监督环境下的倾斜物体检测方法，以达到更高的精确度和效率。

**Method:** ABBSPO框架采用自适应边界框缩放(ABBS)和基于对称先验的角度预测(SPA)，解决了之前方法在尺度估计和自监督学习时遇到的问题。

**Result:** ABBSPO相较于其他方法有更好的性能，特别是在尺度估计和利用对象对称性进行自监督学习方面。

**Conclusion:** 实验结果表明，提出的ABBSPO方法实现了最先进的性能，并超越了现有方法。

**Abstract:** Weakly supervised oriented object detection (WS-OOD) has gained attention as a cost-effective alternative to fully supervised methods, providing both efficiency and high accuracy. Among weakly supervised approaches, horizontal bounding box (HBox)-supervised OOD stands out for its ability to directly leverage existing HBox annotations while achieving the highest accuracy under weak supervision settings. This paper introduces adaptive bounding box scaling and symmetry-prior-based orientation prediction, called ABBSPO, a framework for WS-OOD. Our ABBSPO addresses limitations of previous HBox-supervised OOD methods, which compare ground truth (GT) HBoxes directly with the minimum circumscribed rectangles of predicted RBoxes, often leading to inaccurate scale estimation. To overcome this, we propose: (i) Adaptive Bounding Box Scaling (ABBS), which appropriately scales GT HBoxes to optimize for the size of each predicted RBox, ensuring more accurate scale prediction; and (ii) a Symmetric Prior Angle (SPA) loss that exploits inherent symmetry of aerial objects for self-supervised learning, resolving issues in previous methods where learning collapses when predictions for all three augmented views (original, rotated, and flipped) are consistently incorrect. Extensive experimental results demonstrate that ABBSPO achieves state-of-the-art performance, outperforming existing methods.

</details>


### [19] [Diffusion Is Your Friend in Show, Suggest and Tell](https://arxiv.org/abs/2512.10038)
*Jia Cheng Hu,Roberto Cavicchioli,Alessandro Capotondi*

Main category: cs.CV

> 本文提出了一个新的结合扩散模型与自回归生成的范式，展示了其在图像描述任务的优越性能，特别是在SST上的结果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散降噪模型在生成计算机视觉任务中展示了令人印象深刻的结果，但在离散领域仍未能超越标准自回归解决方案。为了改善这一点，提出了将扩散模型与自回归生成结合的新范式。

**Method:** 通过将扩散模型应用于为自回归生成提供建议而非完全替代的方法，结合了前者双向和细化能力以及后者强大的语言结构能力。

**Result:** 提出的Show, Suggest and Tell (SST) 在COCO数据集上达到了125.1 CIDEr-D分数，超越了同类模型的最先进结果，同时实验显示了建议模块与描述质量之间的积极相关性。

**Conclusion:** 研究结果表明，建议模块与描述质量之间存在积极的相关性，这是一个尚未充分探索但有前景的研究方向。

**Abstract:** Diffusion Denoising models demonstrated impressive results across generative Computer Vision tasks, but they still fail to outperform standard autoregressive solutions in the discrete domain, and only match them at best. In this work, we propose a different paradigm by adopting diffusion models to provide suggestions to the autoregressive generation rather than replacing them. By doing so, we combine the bidirectional and refining capabilities of the former with the strong linguistic structure provided by the latter. To showcase its effectiveness, we present Show, Suggest and Tell (SST), which achieves State-of-the-Art results on COCO, among models in a similar setting. In particular, SST achieves 125.1 CIDEr-D on the COCO dataset without Reinforcement Learning, outperforming both autoregressive and diffusion model State-of-the-Art results by 1.5 and 2.5 points. On top of the strong results, we performed extensive experiments to validate the proposal and analyze the impact of the suggestion module. Results demonstrate a positive correlation between suggestion and caption quality, overall indicating a currently underexplored but promising research direction. Code will be available at: https://github.com/jchenghu/show\_suggest\_tell.

</details>


### [20] [MetaVoxel: Joint Diffusion Modeling of Imaging and Clinical Metadata](https://arxiv.org/abs/2512.10041)
*Yihao Liu,Chenyu Gao,Lianrui Zuo,Michael E. Kim,Brian D. Boyd,Lisa L. Barnes,Walter A. Kukull,Lori L. Beason-Held,Susan M. Resnick,Timothy J. Hohman,Warren D. Taylor,Bennett A. Landman*

Main category: cs.CV

> MetaVoxel, a joint diffusion model, is introduced to unify various medical tasks using imaging and clinical data, showing it can perform multiple tasks effectively without retraining for each task.

<details>
  <summary>Details</summary>

**Motivation:** To unify tasks that traditionally require separate conditional models and support flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining.

**Method:** MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata.

**Result:** A single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines.

**Conclusion:** Joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

**Abstract:** Modern deep learning methods have achieved impressive results across tasks from disease classification, estimating continuous biomarkers, to generating realistic medical images. Most of these approaches are trained to model conditional distributions defined by a specific predictive direction with a specific set of input variables. We introduce MetaVoxel, a generative joint diffusion modeling framework that models the joint distribution over imaging data and clinical metadata by learning a single diffusion process spanning all variables. By capturing the joint distribution, MetaVoxel unifies tasks that traditionally require separate conditional models and supports flexible zero-shot inference using arbitrary subsets of inputs without task-specific retraining. Using more than 10,000 T1-weighted MRI scans paired with clinical metadata from nine datasets, we show that a single MetaVoxel model can perform image generation, age estimation, and sex prediction, achieving performance comparable to established task-specific baselines. Additional experiments highlight its capabilities for flexible inference.Together, these findings demonstrate that joint multimodal diffusion offers a promising direction for unifying medical AI models and enabling broader clinical applicability.

</details>


### [21] [Independent Density Estimation](https://arxiv.org/abs/2512.10067)
*Jiahao Liu*

Main category: cs.CV

> The paper discusses a new method (IDE) for improving compositional generalization in Vision-Language models, where two models are developed and show enhanced generalization on unseen data.

<details>
  <summary>Details</summary>

**Motivation:** The authors observe that while large-scale Vision-Language models perform well in specific tasks, they struggle with compositional generalization, i.e., understanding and generating novel image-word combinations not seen during training.

**Method:** The paper introduces a method called Independent Density Estimation (IDE) to enhance compositional generalization in Vision-Language models. The method aims to connect individual words in a sentence with corresponding features in images. Two models are constructed: one using fully disentangled visual representations as input and the other using a Variational Auto-Encoder for partially disentangled features.

**Result:** The models based on IDE demonstrate a better ability to generalize to unseen compositional instances compared to current models, as evaluated on various datasets.

**Conclusion:** The proposed Independent Density Estimation method, along with the two developed models, successfully enhances compositional generalization in Vision-Language tasks, outperforming existing models.

**Abstract:** Large-scale Vision-Language models have achieved remarkable results in various domains, such as image captioning and conditioned image generation. Neverthe- less, these models still encounter difficulties in achieving human-like composi- tional generalization. In this study, we propose a new method called Independent Density Estimation (IDE) to tackle this challenge. IDE aims to learn the connec- tion between individual words in a sentence and the corresponding features in an image, enabling compositional generalization. We build two models based on the philosophy of IDE. The first one utilizes fully disentangled visual representations as input, and the second leverages a Variational Auto-Encoder to obtain partially disentangled features from raw images. Additionally, we propose an entropy- based compositional inference method to combine predictions of each word in the sentence. Our models exhibit superior generalization to unseen compositions compared to current models when evaluated on various datasets.

</details>


### [22] [TraceFlow: Dynamic 3D Reconstruction of Specular Scenes Driven by Ray Tracing](https://arxiv.org/abs/2512.10095)
*Jiachen Tao,Junyi Wu,Haoxuan Wang,Zongxin Yang,Dawen Cai,Yan Yan*

Main category: cs.CV

> TraceFlow框架，能提升在动态场景中高保真渲染的性能，特别是在镜面反射的计算准确性与合成质量方面。

<details>
  <summary>Details</summary>

**Motivation:** 为了改善动态场景高保真度渲染的过程，特别是镜面反射的精确度以及物理上的准确性。

**Method:** 通过使用Residual Material-Augmented 2D Gaussian Splatting表示法，引入动态环境高斯和混合渲染流水线，以及使用粗到精的训练策略来实现目标。

**Result:** TraceFlow 是一个用于动态镜面场景高保真渲染的新型框架。通过提出Residual Material-Augmented 2D Gaussian Splatting表示法来解决精确反射方向估计和物理精确反射建模两个关键挑战，允许准确的反射光线计算。此外，引入动态环境高斯和混合渲染流水线来分解渲染为散射和镜面反射两个组分，通过光栅化和光线追踪实现实体化的镜面反射合成。最后，通过粗到精的训练策略提高优化的稳定性并促进物理意义明了的分解。在动态场景基准测试中的广泛实验表明，TraceFlow 在准确性和质量上均优于前人的方法，能够在复杂的动态环境中产生更锐利且逼真的镜面反射。

**Conclusion:** TraceFlow能够通过提高反射光线计算准确性以及引入混合渲染管道，实现在复杂动态环境中的更逼真和尖锐的镜面反射效果。粗到精的训练策略有助于优化并改善渲染质量。

**Abstract:** We present TraceFlow, a novel framework for high-fidelity rendering of dynamic specular scenes by addressing two key challenges: precise reflection direction estimation and physically accurate reflection modeling. To achieve this, we propose a Residual Material-Augmented 2D Gaussian Splatting representation that models dynamic geometry and material properties, allowing accurate reflection ray computation. Furthermore, we introduce a Dynamic Environment Gaussian and a hybrid rendering pipeline that decomposes rendering into diffuse and specular components, enabling physically grounded specular synthesis via rasterization and ray tracing. Finally, we devise a coarse-to-fine training strategy to improve optimization stability and promote physically meaningful decomposition. Extensive experiments on dynamic scene benchmarks demonstrate that TraceFlow outperforms prior methods both quantitatively and qualitatively, producing sharper and more realistic specular reflections in complex dynamic environments.

</details>


### [23] [Hierarchical Instance Tracking to Balance Privacy Preservation with Accessible Information](https://arxiv.org/abs/2512.10102)
*Neelima Prasad,Jarek Reynolds,Neel Karsanbhai,Tanusree Sharma,Lotus Zhang,Abigale Stangl,Yang Wang,Leah Findlater,Danna Gurari*

Main category: cs.CV

> 本文提出了一种新的层级实例追踪任务及首个支持该任务的数据集，评估多个模型后发现数据集具有挑战性。

<details>
  <summary>Details</summary>

**Motivation:** 为了推动更复杂场景下的实例追踪研究，提出了一种新的任务和数据集。

**Method:** 提出了一种新的任务，即层级实例追踪，该任务涉及追踪预定义类别的所有对象和部件实例，并维护它们的层级关系。同时引入了首个支持该任务的基准数据集，包含2,765个独特的实体，分布在552个视频中，属于40个类别（包括对象和部件）。

**Result:** 评估了四种模型的七种变体，发现该新数据集具有挑战性。

**Conclusion:** 展示了层级实例追踪任务和相关数据集的必要性及挑战性。

**Abstract:** We propose a novel task, hierarchical instance tracking, which entails tracking all instances of predefined categories of objects and parts, while maintaining their hierarchical relationships. We introduce the first benchmark dataset supporting this task, consisting of 2,765 unique entities that are tracked in 552 videos and belong to 40 categories (across objects and parts). Evaluation of seven variants of four models tailored to our novel task reveals the new dataset is challenging. Our dataset is available at https://vizwiz.org/tasks-and-datasets/hierarchical-instance-tracking/

</details>


### [24] [Topological Conditioning for Mammography Models via a Stable Wavelet-Persistence Vectorization](https://arxiv.org/abs/2512.10151)
*Charles Fanning,Mehmet Emin Aktas*

Main category: cs.CV

> 一篇针对乳腺癌筛查中乳腺X线摄影解释准确性问题的论文，通过引入一种基于拓扑数据和波浪持续同调的方法，实现了在不同乳腺X线摄影队列中的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 乳腺癌是世界上女性诊断最多的癌症，也是癌症死亡的主要原因之一。虽然筛查乳腺X线摄影可以降低死亡率，但其解读仍存在大量的假阴性和假阳性。模型准确性在不同扫描仪、方式和患者群体中部署时会下降。为了改进这些外部表现，研究提出了一种基于持续同调的向量化元素产生的简单条件信号。

**Method:** 使用拓扑数据分析，将图像结构在强度阈值之间保持不变的特征进行总结，并将其转化为在空间上多尺度且对小强度扰动稳定的地图。这些地图通过输入级通道串联被整合到一个两阶段的检测管道中。

**Result:** 该模型在美国的CBIS DDSM数字化乳腺X线摄影队列中进行训练和验证，并在来自葡萄牙（INbreast）和中国的（CMMD）两个独立的全视野数字乳腺X线摄影队列上进行评估。在INbreast上，通过增加波浪持续通道，ConvNeXt Tiny在有限的训练预算下的患者水平AUC从0.55提升到0.75。

**Conclusion:** 研究成功展示了通过集成拓扑数据分析和持续同调波浪向量化的信号来提升乳腺癌X线摄影检测准确性的方法。

**Abstract:** Breast cancer is the most commonly diagnosed cancer in women and a leading cause of cancer death worldwide. Screening mammography reduces mortality, yet interpretation still suffers from substantial false negatives and false positives, and model accuracy often degrades when deployed across scanners, modalities, and patient populations. We propose a simple conditioning signal aimed at improving external performance based on a wavelet based vectorization of persistent homology. Using topological data analysis, we summarize image structure that persists across intensity thresholds and convert this information into spatial, multi scale maps that are provably stable to small intensity perturbations. These maps are integrated into a two stage detection pipeline through input level channel concatenation. The model is trained and validated on the CBIS DDSM digitized film mammography cohort from the United States and evaluated on two independent full field digital mammography cohorts from Portugal (INbreast) and China (CMMD), with performance reported at the patient level. On INbreast, augmenting ConvNeXt Tiny with wavelet persistence channels increases patient level AUC from 0.55 to 0.75 under a limited training budget.

</details>


### [25] [Feature Coding for Scalable Machine Vision](https://arxiv.org/abs/2512.10209)
*Md Eimran Hossain Eimon,Juan Merlos,Ashan Perera,Hari Kalva,Velibor Adzic,Borko Furht*

Main category: cs.CV

> 本文提出了特征编码测试模型（FCTM），作为一种有效的解决方案，能在不牺牲准确性的情况下，减少深度神经网络中间特征的比特率。

<details>
  <summary>Details</summary>

**Motivation:** 为了解决在边缘设备上部署深度神经网络（DNN）时面临的数据传输带宽挑战和隐私问题，提出了该方法。

**Method:** 本文介绍了为机器设计的特征编码（FCM）标准，该标准专为压缩中间特征而设计，提出了一种名为特征编码测试模型（FCTM）的设计方案。

**Result:** 该方案在多个视觉任务中平均实现了85.14%的比特率减少，同时保持了准确性。

**Conclusion:** FCM为在带宽受限和隐私敏感的消费者应用中智能功能的高效和互操作性部署提供了可扩展的途径。

**Abstract:** Deep neural networks (DNNs) drive modern machine vision but are challenging to deploy on edge devices due to high compute demands. Traditional approaches-running the full model on-device or offloading to the cloud face trade-offs in latency, bandwidth, and privacy. Splitting the inference workload between the edge and the cloud offers a balanced solution, but transmitting intermediate features to enable such splitting introduces new bandwidth challenges. To address this, the Moving Picture Experts Group (MPEG) initiated the Feature Coding for Machines (FCM) standard, establishing a bitstream syntax and codec pipeline tailored for compressing intermediate features. This paper presents the design and performance of the Feature Coding Test Model (FCTM), showing significant bitrate reductions-averaging 85.14%-across multiple vision tasks while preserving accuracy. FCM offers a scalable path for efficient and interoperable deployment of intelligent features in bandwidth-limited and privacy-sensitive consumer applications.

</details>


### [26] [Latent Chain-of-Thought World Modeling for End-to-End Driving](https://arxiv.org/abs/2512.10226)
*Shuhan Tan,Kashyap Chitta,Yuxiao Chen,Ran Tian,Yurong You,Yan Wang,Wenjie Luo,Yulong Cao,Philipp Krahenbuhl,Marco Pavone,Boris Ivanovic*

Main category: cs.CV

> Introduces Latent-CoT-Drive (LCDrive) for autonomous driving, which utilizes latent language for CoT reasoning, leading to faster inference, better trajectory quality, and enhanced reinforcement learning outcomes.

<details>
  <summary>Details</summary>

**Motivation:** To improve driving performance and safety in challenging scenarios by moving away from natural language to a possibly more efficient latent language for chain-of-thought (CoT) reasoning.

**Method:** Unified CoT reasoning and decision making by using action-aligned latent space rather than natural language for reasoning, incorporating action-proposal tokens and world model tokens.

**Result:** LCDrive resulted in faster inference, better trajectory quality, and significant improvements from interactive reinforcement learning compared to other baselines.

**Conclusion:** Using a latent language for chain-of-thought reasoning in autonomous driving improves inference speed, trajectory quality, and enhances performance with reinforcement learning.

**Abstract:** Recent Vision-Language-Action (VLA) models for autonomous driving explore inference-time reasoning as a way to improve driving performance and safety in challenging scenarios. Most prior work uses natural language to express chain-of-thought (CoT) reasoning before producing driving actions. However, text may not be the most efficient representation for reasoning. In this work, we present Latent-CoT-Drive (LCDrive): a model that expresses CoT in a latent language that captures possible outcomes of the driving actions being considered. Our approach unifies CoT reasoning and decision making by representing both in an action-aligned latent space. Instead of natural language, the model reasons by interleaving (1) action-proposal tokens, which use the same vocabulary as the model's output actions; and (2) world model tokens, which are grounded in a learned latent world model and express future outcomes of these actions. We cold start latent CoT by supervising the model's action proposals and world model tokens based on ground-truth future rollouts of the scene. We then post-train with closed-loop reinforcement learning to strengthen reasoning capabilities. On a large-scale end-to-end driving benchmark, LCDrive achieves faster inference, better trajectory quality, and larger improvements from interactive reinforcement learning compared to both non-reasoning and text-reasoning baselines.

</details>


### [27] [Emerging Standards for Machine-to-Machine Video Coding](https://arxiv.org/abs/2512.10230)
*Md Eimran Hossain Eimon,Velibor Adzic,Hari Kalva,Borko Furht*

Main category: cs.CV

> 介绍了面向机器的视频编码(VCM)和特征编码(FCM)，研究显示FCM能减少比特率并保持高准确性，分析表明HEVC和VVC对于大多数机器任务的性能相似，而对于跟踪任务HEVC略优于VVC，已部署的HEVC硬件也足以支持机器间通信并保持性能。

<details>
  <summary>Details</summary>

**Motivation:** 解决传统的远程推理中视频流占用带宽高、扩展性差以及隐私问题。

**Method:** 提出了VCM和FCM为机器之间的数据传输设计了更优化的编码方式，尤其是FCM对中间的神经特征进行压缩，减少比特率，同时保护隐私并支持计算卸载。

**Result:** 实验显示FCM能维持接近设备推理的准确性同时大幅度减少比特率，HEVC和VVC在大多数机器任务上的性能近似，在导航任务中HEVC略胜VVC。

**Conclusion:** VCM和FCM的提出为机器间视觉数据传输显着改善了性能和效率，现有HEVC硬件能够支持当前的机器任务而不降低性能。

**Abstract:** Machines are increasingly becoming the primary consumers of visual data, yet most deployments of machine-to-machine systems still rely on remote inference where pixel-based video is streamed using codecs optimized for human perception. Consequently, this paradigm is bandwidth intensive, scales poorly, and exposes raw images to third parties. Recent efforts in the Moving Picture Experts Group (MPEG) redesigned the pipeline for machine-to-machine communication: Video Coding for Machines (VCM) is designed to apply task-aware coding tools in the pixel domain, and Feature Coding for Machines (FCM) is designed to compress intermediate neural features to reduce bitrate, preserve privacy, and support compute offload. Experiments show that FCM is capable of maintaining accuracy close to edge inference while significantly reducing bitrate. Additional analysis of H.26X codecs used as inner codecs in FCM reveals that H.265/High Efficiency Video Coding (HEVC) and H.266/Versatile Video Coding (VVC) achieve almost identical machine task performance, with an average BD-Rate increase of 1.39% when VVC is replaced with HEVC. In contrast, H.264/Advanced Video Coding (AVC) yields an average BD-Rate increase of 32.28% compared to VVC. However, for the tracking task, the impact of codec choice is minimal, with HEVC outperforming VVC and achieving BD Rate of -1.81% and 8.79% for AVC, indicating that existing hardware for already deployed codecs can support machine-to-machine communication without degrading performance.

</details>


### [28] [Multi-dimensional Preference Alignment by Conditioning Reward Itself](https://arxiv.org/abs/2512.10237)
*Jiho Jang,Jinyoung Kim,Kyungjune Baek,Nojun Kwak*

Main category: cs.CV

> 本文提出了一种新的方法MCDPO，它通过引入解耦的Bradley-Terry目标并使用条件偏好向量，解决了当前标准DPO方法中奖励冲突问题，并在Stable Diffusion模型上展示了优越性能。同时，该方法还支持推理时的动态多维度控制。

<details>
  <summary>Details</summary>

**Motivation:** 标准DPO公式依赖于Bradley-Terry模型来将多样化的评价维度（如美学质量和语义一致性）聚集为单一标量奖励，这会导致模型在遇到全局不受欢迎的样本时，被迫重新学习特定维度的可取特征，因而存在根本限制。

**Method:** 我们提出了一种名为多奖励条件DPO（MCDPO）的方法，通过引入解耦的Bradley-Terry目标来解决奖励冲突问题。MCDPO通过在训练中显式地注入偏好结果向量的方式，允许模型为每个奖励轴独立学习正确的优化方向。我们还引入了维度奖励丢弃来确保各维度之间的优化平衡。

**Result:** 在Stable Diffusion 1.5和SDXL上的实验表明，MCDPO在基准测试中实现了更优的表现，并且其条件框架可以通过Classifier Free Guidance在推理时动态放大特定奖励维度，而无需额外训练或外部奖励模型。

**Conclusion:** MCDPO解决了多轴评价系统中的奖励冲突问题，并且在无需额外训练资源的情况下实现了多维度控制，具有较好的性能和灵活性。

**Abstract:** Reinforcement Learning from Human Feedback has emerged as a standard for aligning diffusion models. However, we identify a fundamental limitation in the standard DPO formulation because it relies on the Bradley-Terry model to aggregate diverse evaluation axes like aesthetic quality and semantic alignment into a single scalar reward. This aggregation creates a reward conflict where the model is forced to unlearn desirable features of a specific dimension if they appear in a globally non-preferred sample. To address this issue, we propose Multi Reward Conditional DPO (MCDPO). This method resolves reward conflicts by introducing a disentangled Bradley-Terry objective. MCDPO explicitly injects a preference outcome vector as a condition during training, which allows the model to learn the correct optimization direction for each reward axis independently within a single network. We further introduce dimensional reward dropout to ensure balanced optimization across dimensions. Extensive experiments on Stable Diffusion 1.5 and SDXL demonstrate that MCDPO achieves superior performance on benchmarks. Notably, our conditional framework enables dynamic and multiple-axis control at inference time using Classifier Free Guidance to amplify specific reward dimensions without additional training or external reward models.

</details>


### [29] [Solving Semi-Supervised Few-Shot Learning from an Auto-Annotation Perspective](https://arxiv.org/abs/2512.10244)
*Tian Liu,Anwesha Basu,James Caverlee,Shu Kong*

Main category: cs.CV

> 研究提出SWIFT方法，解决了SSFSL使用开源VLM资源下的性能问题，通过简单的分类器初始化和温度调整，显著提升了在多个基准上的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Vision-Language Models (VLM)及其预训练数据的开源资源强大，但SSFSL研究较少利用这些资源，而FSL领域已经利用这些资源提高了性能。为了实现自动注释等真实世界应用，SSFSL应借鉴这些资源。

**Method:** Semi-supervised few-shot learning (SSFSL)利用现有SSL方法微调Vision-Language Models (VLM)，通过分类器初始化和温度调整提高伪标签的置信度，从而优化未标记数据的使用和增强监督信号。该方法命名为Stage-Wise Finetuning with Temperature Tuning (SWIFT).

**Result:** 在五个SSFSL基准数据集上的广泛实验证明了SWIFT方法比近期FSL和SSL方法提高了约5个准确率点。它甚至可以与监督学习相媲美，后者通过使用真实标签对未标记数据进行微调。

**Conclusion:** 通过SWIFT，现有SSL方法可以在有限的标记数据、大量的未标记数据和从VLM的预训练集中检索的任务相关但嘈杂的数据上有效微调VLM。这显著提高了SSFSL的性能，接近监督学习。

**Abstract:** Semi-supervised few-shot learning (SSFSL) formulates real-world applications like ''auto-annotation'', as it aims to learn a model over a few labeled and abundant unlabeled examples to annotate the unlabeled ones. Despite the availability of powerful open-source Vision-Language Models (VLMs) and their pretraining data, the SSFSL literature largely neglects these open-source resources. In contrast, the related area few-shot learning (FSL) has already exploited them to boost performance. Arguably, to achieve auto-annotation in the real world, SSFSL should leverage such open-source resources. To this end, we start by applying established SSL methods to finetune a VLM. Counterintuitively, they significantly underperform FSL baselines. Our in-depth analysis reveals the root cause: VLMs produce rather ''flat'' distributions of softmax probabilities. This results in zero utilization of unlabeled data and weak supervision signals. We address this issue with embarrassingly simple techniques: classifier initialization and temperature tuning. They jointly increase the confidence scores of pseudo-labels, improving the utilization rate of unlabeled data, and strengthening supervision signals. Building on this, we propose: Stage-Wise Finetuning with Temperature Tuning (SWIFT), which enables existing SSL methods to effectively finetune a VLM on limited labeled data, abundant unlabeled data, and task-relevant but noisy data retrieved from the VLM's pretraining set. Extensive experiments on five SSFSL benchmarks show that SWIFT outperforms recent FSL and SSL methods by $\sim$5 accuracy points. SWIFT even rivals supervised learning, which finetunes VLMs with the unlabeled data being labeled with ground truth!

</details>


### [30] [RobustSora: De-Watermarked Benchmark for Robust AI-Generated Video Detection](https://arxiv.org/abs/2512.10248)
*Zhuo Wang,Xiliang Liu,Ligang Sun*

Main category: cs.CV

> 我们提出RobustSora，一个新的基准测试，以评估AI生成视频水印对检测的影响，并展示了依赖性的现实结果，强调了训练适应性的需求。

<details>
  <summary>Details</summary>

**Motivation:** 现有的AIGC视频检测基准测试没有考虑到水印的影响，而许多先进的生成模型会将数字水印嵌入到输出中。为了评估这一点，我们推出了这个新的基准测试。

**Method:** 我们提出了RobustSora基准测试，用以评估水印对AI生成视频检测的影响。我们构建了一个包含6,500个视频的数据集，分为四种类型：Authentic-Clean (A-C), Authentic-Spoofed (A-S), Generated-Watermarked (G-W), 和 Generated-DeWatermarked (G-DeW)。设计了两个评估任务：Task-I 测试在去除了水印的AI生成视频上的性能，Task-II 评估在嵌入了伪造水印的真实视频上的误报率。

**Result:** 实验结果显示，使用了10种不同的模型，包括专门的AIGC检测器、变压器架构和MLLM方法，这些模型的性能在水印操作下表现出了2-8pp的差异。例如，变压器模型显示出中等程度的依赖性（6-8pp），而MLLM则表现出不同的模式（2-8pp）。

**Conclusion:** 这些发现表明了模型部分依赖于水印进行检测，并强调了开发考虑到水印的训练策略的重要性。RobustSora基准测试为推进稳健的AIGC检测研究提供了必要的工具。

**Abstract:** The proliferation of AI-generated video technologies poses challenges to information integrity. While recent benchmarks advance AIGC video detection, they overlook a critical factor: many state-of-the-art generative models embed digital watermarks in outputs, and detectors may partially rely on these patterns. To evaluate this influence, we present RobustSora, the benchmark designed to assess watermark robustness in AIGC video detection. We systematically construct a dataset of 6,500 videos comprising four types: Authentic-Clean (A-C), Authentic-Spoofed with fake watermarks (A-S), Generated-Watermarked (G-W), and Generated-DeWatermarked (G-DeW). Our benchmark introduces two evaluation tasks: Task-I tests performance on watermark-removed AI videos, while Task-II assesses false alarm rates on authentic videos with fake watermarks. Experiments with ten models spanning specialized AIGC detectors, transformer architectures, and MLLM approaches reveal performance variations of 2-8pp under watermark manipulation. Transformer-based models show consistent moderate dependency (6-8pp), while MLLMs exhibit diverse patterns (2-8pp). These findings indicate partial watermark dependency and highlight the need for watermark-aware training strategies. RobustSora provides essential tools to advance robust AIGC detection research.

</details>


### [31] [THE-Pose: Topological Prior with Hybrid Graph Fusion for Estimating Category-Level 6D Object Pose](https://arxiv.org/abs/2512.10251)
*Eunho Lee,Chaehyeon Song,Seunghoon Jeong,Ayoung Kim*

Main category: cs.CV

> THE-Pose 是一种新型的类别级六自由度姿态估计框架，通过拓扑先验和混合图融合技术，克服了现有3D-GC方法在复杂对象和视觉混淆上的局限性，显著提高了姿态估计的稳定性。

<details>
  <summary>Details</summary>

**Motivation:** 现有3D-GC方法仅关注局部几何和深度信息，但在复杂对象和视觉混淆上表现脆弱。THE-Pose 提出了新的解决方案，旨在提升类别级物体姿态估计的鲁棒性。

**Method:** THE-Pose 提取图像域中的拓扑特征，并通过混合图融合模块自适应地整合这些特征与点云特征，从而实现2D图像上下文与3D几何结构的无缝结合。

**Result:** 在REAL275数据集上的实验表明，THE-Pose 比3D-GC基线（HS-Pose）提高了35.8%，超过了之前的最佳结果7.2%。

**Conclusion:** THE-Pose 通过使用拓扑特征和混合图融合的方法，增强了面对复杂及可视受阻情况下物体识别的稳健性，展示出优异的性能增益。

**Abstract:** Category-level object pose estimation requires both global context and local structure to ensure robustness against intra-class variations. However, 3D graph convolution (3D-GC) methods only focus on local geometry and depth information, making them vulnerable to complex objects and visual ambiguities. To address this, we present THE-Pose, a novel category-level 6D pose estimation framework that leverages a topological prior via surface embedding and hybrid graph fusion. Specifically, we extract consistent and invariant topological features from the image domain, effectively overcoming the limitations inherent in existing 3D-GC based methods. Our Hybrid Graph Fusion (HGF) module adaptively integrates the topological features with point-cloud features, seamlessly bridging 2D image context and 3D geometric structure. These fused features ensure stability for unseen or complicated objects, even under significant occlusions. Extensive experiments on the REAL275 dataset show that THE-Pose achieves a 35.8% improvement over the 3D-GC baseline (HS-Pose) and surpasses the previous state-of-the-art by 7.2% across all key metrics. The code is avaialbe on https://github.com/EHxxx/THE-Pose

</details>


### [32] [GDKVM: Echocardiography Video Segmentation via Spatiotemporal Key-Value Memory with Gated Delta Rule](https://arxiv.org/abs/2512.10252)
*Rui Wang,Yimu Sun,Jingxing Guo,Huisi Wu,Jing Qin*

Main category: cs.CV

> A new echocardiography video segmentation model, GDKVM, improves segmentation accuracy and robustness while maintaining real-time performance, showing superior results compared to current methods on two datasets.

<details>
  <summary>Details</summary>

**Motivation:** The paper aims to address the challenge of accurately segmenting cardiac chambers in echocardiography sequences by improving the trade-off between capturing long-range spatiotemporal dependencies and maintaining computational efficiency.

**Method:** GDKVM architecture is introduced, which includes Linear Key-Value Association (LKVA), Gated Delta Rule (GDR), and Key-Pixel Feature Fusion (KPFF) module to model inter-frame correlations and store memory states efficiently.

**Result:** The GDKVM model outperforms existing state-of-the-art methods on two echocardiography video datasets, CAMUS and EchoNet-Dynamic, in terms of segmentation accuracy and robustness, while also ensuring real-time performance.

**Conclusion:** GDKVM provides a more accurate and efficient segmentation method for echocardiography sequences, which can aid in the clinical diagnosis and treatment of cardiac diseases.

**Abstract:** Accurate segmentation of cardiac chambers in echocardiography sequences is crucial for the quantitative analysis of cardiac function, aiding in clinical diagnosis and treatment. The imaging noise, artifacts, and the deformation and motion of the heart pose challenges to segmentation algorithms. While existing methods based on convolutional neural networks, Transformers, and space-time memory networks have improved segmentation accuracy, they often struggle with the trade-off between capturing long-range spatiotemporal dependencies and maintaining computational efficiency with fine-grained feature representation. In this paper, we introduce GDKVM, a novel architecture for echocardiography video segmentation. The model employs Linear Key-Value Association (LKVA) to effectively model inter-frame correlations, and introduces Gated Delta Rule (GDR) to efficiently store intermediate memory states. Key-Pixel Feature Fusion (KPFF) module is designed to integrate local and global features at multiple scales, enhancing robustness against boundary blurring and noise interference. We validated GDKVM on two mainstream echocardiography video datasets (CAMUS and EchoNet-Dynamic) and compared it with various state-of-the-art methods. Experimental results show that GDKVM outperforms existing approaches in terms of segmentation accuracy and robustness, while ensuring real-time performance. Code is available at https://github.com/wangrui2025/GDKVM.

</details>


### [33] [VLM-NCD:Novel Class Discovery with Vision-Based Large Language Models](https://arxiv.org/abs/2512.10262)
*Yuetong Su,Baoguo Wei,Xinyu Wang,Xu Li,Lixin Li*

Main category: cs.CV

> LLM-NCD is a new multimodal method for discovering novel classes from unlabelled data, outperforming existing methods by up to 25.3% on the CIFAR-100 dataset.

<details>
  <summary>Details</summary>

**Motivation:** To address limitations in existing novel class discovery (NCD) methods such as insufficient feature discriminability and handling long-tail data distributions.

**Method:** A multimodal framework, LLM-NCD, which models cluster centres and semantic prototypes of known classes by integrating visual and textual features, coupled with a dual-phase discovery mechanism.

**Result:** Achieves up to a 25.3% improvement in accuracy for unknown classes on the CIFAR-100 dataset and demonstrates resilience to long-tail data distributions.

**Conclusion:** LLM-NCD presents an effective approach to novel class discovery, significantly outperforming existing methods and setting a new standard in the field, especially in dealing with long-tail distribution data issues.

**Abstract:** Novel Class Discovery aims to utilise prior knowledge of known classes to classify and discover unknown classes from unlabelled data. Existing NCD methods for images primarily rely on visual features, which suffer from limitations such as insufficient feature discriminability and the long-tail distribution of data. We propose LLM-NCD, a multimodal framework that breaks this bottleneck by fusing visual-textual semantics and prototype guided clustering. Our key innovation lies in modelling cluster centres and semantic prototypes of known classes by jointly optimising known class image and text features, and a dualphase discovery mechanism that dynamically separates known or novel samples via semantic affinity thresholds and adaptive clustering. Experiments on the CIFAR-100 dataset show that compared to the current methods, this method achieves up to 25.3% improvement in accuracy for unknown classes. Notably, our method shows unique resilience to long tail distributions, a first in NCD literature.

</details>


### [34] [Long-LRM++: Preserving Fine Details in Feed-Forward Wide-Coverage Reconstruction](https://arxiv.org/abs/2512.10267)
*Chen Ziwen,Hao Tan,Peng Wang,Zexiang Xu,Li Fuxin*

Main category: cs.CV

> Long-LRM++ 使用半显式场景表示和轻量级解码器，在保留隐式表示的优点的同时实现实时渲染，匹配 LaCT 的渲染质量并在 DL3DV 和 ScanNetv2 数据集上表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 克服先前隐式方法的实时渲染障碍，同时保留高质量渲染效果。

**Method:** Long-LRM++ 采用半显式场景表示结合轻量级解码器结构，通过单次前向传递实现360°场景重建，支持64个输入视图。

**Result:** Long-LRM++ 达到与 LaCT 相当的渲染质量，实现每秒14帧的实时渲染速度，并且在深度预测上优于直接使用高斯量的渲染方法。

**Conclusion:** 研究展示了一种既能保持高质量渲染效果又能实现实时渲染的3D场景表示方法。

**Abstract:** Recent advances in generalizable Gaussian splatting (GS) have enabled feed-forward reconstruction of scenes from tens of input views. Long-LRM notably scales this paradigm to 32 input images at $950\times540$ resolution, achieving 360° scene-level reconstruction in a single forward pass. However, directly predicting millions of Gaussian parameters at once remains highly error-sensitive: small inaccuracies in positions or other attributes lead to noticeable blurring, particularly in fine structures such as text. In parallel, implicit representation methods such as LVSM and LaCT have demonstrated significantly higher rendering fidelity by compressing scene information into model weights rather than explicit Gaussians, and decoding RGB frames using the full transformer or TTT backbone. However, this computationally intensive decompression process for every rendered frame makes real-time rendering infeasible. These observations raise key questions: Is the deep, sequential "decompression" process necessary? Can we retain the benefits of implicit representations while enabling real-time performance? We address these questions with Long-LRM++, a model that adopts a semi-explicit scene representation combined with a lightweight decoder. Long-LRM++ matches the rendering quality of LaCT on DL3DV while achieving real-time 14 FPS rendering on an A100 GPU, overcoming the speed limitations of prior implicit methods. Our design also scales to 64 input views at the $950\times540$ resolution, demonstrating strong generalization to increased input lengths. Additionally, Long-LRM++ delivers superior novel-view depth prediction on ScanNetv2 compared to direct depth rendering from Gaussians. Extensive ablation studies validate the effectiveness of each component in the proposed framework.

</details>


### [35] [Sample-wise Adaptive Weighting for Transfer Consistency in Adversarial Distillation](https://arxiv.org/abs/2512.10275)
*Hongsin Lee,Hye Won Chung*

Main category: cs.CV

> 研究人员通过分析揭示了更强教师网络不一定能提高学生网络对抗性鲁棒性的现象，并提出了一种新的方法，即样本自适应对抗性蒸馏（SAAD），通过在训练中根据对抗性迁移能力对样本进行加权，能够提高学生的对抗性鲁棒性，且不需要额外的计算成本。实验表明，SAAD在多个数据集上均优于之前的方法。

<details>
  <summary>Details</summary>

**Motivation:** 在标准的最小-最大对抗训练框架中，对抗性蒸馏旨在将大而健壮的教师网络的对抗鲁棒性转移到紧凑的学生网络上。然而，现有的工作往往忽视了结合最先进的健壮教师模型。作者旨在解决这个问题，提高学生的对抗性鲁棒性。

**Method:** 通过广泛的分析，作者指出更强的教师模型并不一定产生更健壮的学生模型，这种现象被称作健壮性饱和。作者认为这种现象不能单纯用模型容量差异来解释，而是识别出对抗性迁移能力（指学生生成的对抗样本对教师模型的有效程度）是成功转移健壮性的关键因素。基于这一见解，作者提出了样本自适应对抗性蒸馏（SAAD）方法，该方法根据检测到的对抗性迁移能力对训练样本进行重新加权，并且不会增加额外的计算成本。

**Result:** 实验结果表明，SAAD在CIFAR-10、CIFAR-100和Tiny-ImageNet数据集上，相对于先前方法在AutoAttack稳健性方面始终有所改进。

**Conclusion:** 研究结论指出，针对对抗性蒸馏中更强教师模型带来的鲁棒性转移问题，可以通过引入样本自适应对抗性蒸馏（SAAD）来有效提高学生模型的对抗性鲁棒性，而不引入额外计算成本。

**Abstract:** Adversarial distillation in the standard min-max adversarial training framework aims to transfer adversarial robustness from a large, robust teacher network to a compact student. However, existing work often neglects to incorporate state-of-the-art robust teachers. Through extensive analysis, we find that stronger teachers do not necessarily yield more robust students-a phenomenon known as robust saturation. While typically attributed to capacity gaps, we show that such explanations are incomplete. Instead, we identify adversarial transferability-the fraction of student-crafted adversarial examples that remain effective against the teacher-as a key factor in successful robustness transfer. Based on this insight, we propose Sample-wise Adaptive Adversarial Distillation (SAAD), which reweights training examples by their measured transferability without incurring additional computational cost. Experiments on CIFAR-10, CIFAR-100, and Tiny-ImageNet show that SAAD consistently improves AutoAttack robustness over prior methods. Our code is available at https://github.com/HongsinLee/saad.

</details>
