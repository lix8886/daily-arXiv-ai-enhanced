{"id": "2601.00086", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00086", "abs": "https://arxiv.org/abs/2601.00086", "authors": ["Xiang Gao", "Yuguang Yao", "Qi Zhang", "Kaiwen Dong", "Avinash Baidya", "Ruocheng Guo", "Hilaf Hasson", "Kamalika Das"], "title": "RIMRULE: Improving Tool-Using Language Agents via MDL-Guided Rule Learning", "comment": null, "summary": "Large language models (LLMs) often struggle to use tools reliably in domain-specific settings, where APIs may be idiosyncratic, under-documented, or tailored to private workflows. This highlights the need for effective adaptation to task-specific tools. We propose RIMRULE, a neuro-symbolic approach for LLM adaptation based on dynamic rule injection. Compact, interpretable rules are distilled from failure traces and injected into the prompt during inference to improve task performance. These rules are proposed by the LLM itself and consolidated using a Minimum Description Length (MDL) objective that favors generality and conciseness. Each rule is stored in both natural language and a structured symbolic form, supporting efficient retrieval at inference time. Experiments on tool-use benchmarks show that this approach improves accuracy on both seen and unseen tools without modifying LLM weights. It outperforms prompting-based adaptation methods and complements finetuning. Moreover, rules learned from one LLM can be reused to improve others, including long reasoning LLMs, highlighting the portability of symbolic knowledge across architectures.", "AI": {"tldr": "RIMRULE方法通过动态向LLM注入自然语言和符号规则，提高了模型在适应特定任务工具时的表现，且规则可以在不同的LLM间复用。", "motivation": "大语言模型在特定领域的环境下经常无法可靠地使用工具，这表明需要进行有效的任务特定工具适应。", "method": "提出了一种基于动态规则注入的神经符号方法RIMRULE，用于LLM（大语言模型）的适应。从失败追踪中提炼出紧凑、可解释的规则，并在推理过程中注入到提示中以提高任务表现。这些规则由LLM自己提出，并使用最小描述长度（MDL）目标进行整合，该目标偏好泛化性和简洁性。每个规则以自然语言和结构化的符号形式存储，以支持高效检索。", "result": "在工具使用基准实验中，该方法在既见过的工具又没见过的工具上都提高了准确性，而且无需修改LLM权重。这种方法超过了基于提示的适应方法，并且补充了微调方法。此外，一个LLM学习到的规则可以改善其他LLM，包括长推理大语言模型，这表明符号知识在架构间的可移植性。", "conclusion": "提出基于动态规则注入的神经符号方法RIMRULE来提高大语言模型在使用特定任务工具时的表现，这种方法不仅展示了其在基准测试中的优越性，还证明了跨架构知识的复用能力。"}}
{"id": "2601.00095", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00095", "abs": "https://arxiv.org/abs/2601.00095", "authors": ["Ibne Farabi Shihab", "Sanjeda Akter", "Anuj Sharma"], "title": "Universal Adaptive Constraint Propagation: Scaling Structured Inference for Large Language Models via Meta-Reinforcement Learning", "comment": null, "summary": "Large language models increasingly require structured inference, from JSON schema enforcement to multi-lingual parsing, where outputs must satisfy complex constraints. We introduce MetaJuLS, a meta-reinforcement learning approach that learns universal constraint propagation policies applicable across languages and tasks without task-specific retraining. By formulating structured inference as adaptive constraint propagation and training a Graph Attention Network with meta-learning, MetaJuLS achieves 1.5--2.0$\\times$ speedups over GPU-optimized baselines while maintaining within 0.2\\% accuracy of state-of-the-art parsers. On Universal Dependencies across 10 languages and LLM-constrained generation (LogicBench, GSM8K-Constrained), MetaJuLS demonstrates rapid cross-domain adaptation: a policy trained on English parsing adapts to new languages and tasks with 5--10 gradient steps (5--15 seconds) rather than requiring hours of task-specific training. Mechanistic analysis reveals the policy discovers human-like parsing strategies (easy-first) and novel non-intuitive heuristics. By reducing propagation steps in LLM deployments, MetaJuLS contributes to Green AI by directly reducing inference carbon footprint.", "AI": {"tldr": "MetaJuLS 是一种元强化学习方法，它学习可以在不同语言和任务之间普遍应用的约束传播策略，无需针对特定任务重新训练。MetaJuLS 在加速推理和减少碳足迹方面作出了贡献。", "motivation": "大型语言模型日益需要结构化推理，例如 JSON 模式强制执行和多语言解析，这些输出必须满足复杂的约束。这项研究旨在开发一种适用于多种语言和任务的通用策略。", "method": "通过将结构化推理形式化为自适应约束传播，并使用元学习训练图注意力网络，MetaJuLS 实现了相对于 GPU 优化基线 1.5-2.0 倍的加速，同时保持了与最先进的解析器接近的精度（0.2% 以内）。", "result": "MetaJuLS 在 10 种语言的通用依存关系和 LLM 约束生成任务上表现出快速的跨域适应能力：在英语解析上训练的策略，对新的语言和任务只需进行 5-10 次梯度更新（5-15 秒）便能进行适配，无需花费数小时进行特定任务训练。", "conclusion": "机制分析显示，这个策略能够发现类似人类的解析策略（类似于简单优先策略）和新颖的非直观启发式方法。MetaJuLS 通过减少大型语言模型部署中的传播步骤，为绿色 AI 的实现做出了贡献。"}}
{"id": "2601.00166", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00166", "abs": "https://arxiv.org/abs/2601.00166", "authors": ["Yongmin Yoo", "Kris W Pan"], "title": "Pat-DEVAL: Chain-of-Legal-Thought Evaluation for Patent Description", "comment": null, "summary": "Patent descriptions must deliver comprehensive technical disclosure while meeting strict legal standards such as enablement and written description requirements. Although large language models have enabled end-to-end automated patent drafting, existing evaluation approaches fail to assess long-form structural coherence and statutory compliance specific to descriptions. We propose Pat-DEVAL, the first multi-dimensional evaluation framework dedicated to patent description bodies. Leveraging the LLM-as-a-judge paradigm, Pat-DEVAL introduces Chain-of-Legal-Thought (CoLT), a legally-constrained reasoning mechanism that enforces sequential patent-law-specific analysis. Experiments validated by patent expert on our Pap2Pat-EvalGold dataset demonstrate that Pat-DEVAL achieves a Pearson correlation of 0.69, significantly outperforming baseline metrics and existing LLM evaluators. Notably, the framework exhibits a superior correlation of 0.73 in Legal-Professional Compliance, proving that the explicit injection of statutory constraints is essential for capturing nuanced legal validity. By establishing a new standard for ensuring both technical soundness and legal compliance, Pat-DEVAL provides a robust methodological foundation for the practical deployment of automated patent drafting systems.", "AI": {"tldr": "提出了Pat-DEVAL这个专用于专利描述评估的新框架，实现了法律特定推理机制，实验数据表明它在法律合规性方面显著优于现有方法，为自动化专利撰写提供了可靠基础。", "motivation": "虽然大型语言模型已经实现了端到端的自动化专利撰写，现有的评估方法无法评估专利描述中严格的法律标准和长格式结构连贯性。因此，我们提出了Pat-DEVAL框架来解决这一问题。", "method": "我们提出了Pat-DEVAL，这是一个专门用于专利描述评估的多维度框架。该框架通过LLM-as-a-judge范式引入了法律约束推理机制——Chain-of-Legal-Thought (CoLT)，以确保专利法律特定的顺序分析。", "result": "在由专利专家验证的Pap2Pat-EvalGold数据集上的实验表明，Pat-DEVAL在合法专业合规性方面的皮尔逊相关性达到了0.73，显著优于基线度量和现有的LLM评估器，整体相关性达到0.69。", "conclusion": "Pat-DEVAL框架通过注入明确的法定约束来捕捉细微的法律有效性，建立了确保技术可靠性和法律合规性的新标准，为自动化专利撰写系统的实际部署提供了强大的方法论基础。"}}
{"id": "2601.00181", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00181", "abs": "https://arxiv.org/abs/2601.00181", "authors": ["Cheonkam Jeong", "Adeline Nyamathi"], "title": "Understanding Emotion in Discourse: Recognition Insights and Linguistic Patterns for Generation", "comment": null, "summary": "While Emotion Recognition in Conversation (ERC) has achieved high accuracy, two critical gaps remain: a limited understanding of \\textit{which} architectural choices actually matter, and a lack of linguistic analysis connecting recognition to generation. We address both gaps through a systematic analysis of the IEMOCAP dataset.\n  For recognition, we conduct a rigorous ablation study with 10-seed evaluation and report three key findings. First, conversational context is paramount, with performance saturating rapidly -- 90\\% of the total gain achieved within just the most recent 10--30 preceding turns (depending on the label set). Second, hierarchical sentence representations help at utterance-level, but this benefit disappears once conversational context is provided, suggesting that context subsumes intra-utterance structure. Third, external affective lexicons (SenticNet) provide no gain, indicating that pre-trained encoders already capture necessary emotional semantics. With simple architectures using strictly causal context, we achieve 82.69\\% (4-way) and 67.07\\% (6-way) weighted F1, outperforming prior text-only methods including those using bidirectional context.\n  For linguistic analysis, we analyze 5,286 discourse marker occurrences and find a significant association between emotion and marker positioning ($p < .0001$). Notably, \"sad\" utterances exhibit reduced left-periphery marker usage (21.9\\%) compared to other emotions (28--32\\%), consistent with theories linking left-periphery markers to active discourse management. This connects to our recognition finding that sadness benefits most from context (+22\\%p): lacking explicit pragmatic signals, sad utterances require conversational history for disambiguation.", "AI": {"tldr": "在对话中的情感识别研究中，对话背景对识别准确度至关重要，特别指出在识别“悲伤”情感时，对话背景对于辨别角色起着关键作用，同时指出，简单的严格因果背景架构在情感分类上优于前人的方法。", "motivation": "这项研究旨在填补情感识别领域关于架构选择重要性和缺乏识别与生成之间的语言学分析的空白，通过系统性地探索IEMOCAP数据集。", "method": "本研究采用严格的消融分析方法，基于IEMOCAP数据集，使用10次种子（seed）评估，涵盖从对话背景到情感词典对情感识别的影响等多方面。", "result": "通过对IEMOCAP数据集的系统分析，研究解决了情感识别在对话中的两个关键差距：对哪些架构选择真正重要的理解不足，以及识别与生成之间的语言学分析缺失。研究表明，对话背景对性能至关重要，在仅使用最近10-30个轮次的背景时，性能已达到饱和状态。层级句子表达有助于单个话语层面的情感识别，但提供了对话背景后，这一好处消失，表明背景吞没了话语内部的结构。我们还发现，外部情感词典并未提供任何好处。简单地使用严格的因果背景架构，我们在4种和6种情感分类上分别实现了82.69%和67.07%的加权F1值，超过仅用文本的先前方法。此外，通过分析5286个话语标记，我们发现了将情感和标记定位联系起来的重要关联。“悲伤”话语的左侧标记使用较少（21.9%），表明悲伤在缺乏明确的语用信号情况下更加依赖对话背景进行区分。", "conclusion": "总体而言，研究通过严格的消融研究揭示了对话中情感识别的关键因素，指出对话背景在识别“悲伤”情感方面的重要作用，并指出情感识别与语言学分析之间的关系。"}}
{"id": "2601.00051", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00051", "abs": "https://arxiv.org/abs/2601.00051", "authors": ["Yabo Chen", "Yuanzhi Liang", "Jiepeng Wang", "Tingxi Chen", "Junfei Cheng", "Zixiao Gu", "Yuyang Huang", "Zicheng Jiang", "Wei Li", "Tian Li", "Weichen Li", "Zuoxin Li", "Guangce Liu", "Jialun Liu", "Junqi Liu", "Haoyuan Wang", "Qizhen Weng", "Xuan'er Wu", "Xunzhi Xiang", "Xiaoyan Yang", "Xin Zhang", "Shiwen Zhang", "Junyu Zhou", "Chengcheng Zhou", "Haibin Huang", "Chi Zhang", "Xuelong Li"], "title": "TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model", "comment": null, "summary": "World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.", "AI": {"tldr": "TeleWorld是一个实时多模态4D世界建模框架，它通过生成-重建-引导范式，结合自回归扩散模型和规划方法，实现了视频生成、动态场景重建和长期世界记忆，提高了实时生成效率和长期一致性。", "motivation": "当前的视频生成模型存在实时交互、长期一致性和持久场景记忆方面的限制，这阻碍了它们演变为实用的世界模型。TeleWorld旨在解决这些问题，提供一个能够实时、一致地生成和交互的4D世界模型框架。", "method": "TeleWorld采用生成-重建-引导范式，将生成的视频流持续重建为动态的4D时空表示，该表示反过来指导后续生成，以保持空间、时间和物理一致性。它使用增强的自回归扩散视频模型，并结合Macro-from-Micro Planning (MMPL)方法和Distribution Matching Distillation (DMD)，以实现低延迟的长时间生成。", "result": "实验表明，TeleWorld在静态和动态世界理解、长期一致性和实时生成效率方面表现优异，证明了其在多模态生成和具身智能中的应用潜力。", "conclusion": "TeleWorld提出了一个新颖的生成-重建-引导范式，实现了动态物体建模和静态场景表征的无缝集成，向实用、交互式和计算可接入的世界模型迈出了一步。"}}
{"id": "2601.00202", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00202", "abs": "https://arxiv.org/abs/2601.00202", "authors": ["Wang Xing", "Wei Song", "Siyu Lin", "Chen Wu", "Zhesi Li", "Man Wang"], "title": "Knowledge Distillation for Temporal Knowledge Graph Reasoning with Large Language Models", "comment": null, "summary": "Reasoning over temporal knowledge graphs (TKGs) is fundamental to improving the efficiency and reliability of intelligent decision-making systems and has become a key technological foundation for future artificial intelligence applications. Despite recent progress, existing TKG reasoning models typically rely on large parameter sizes and intensive computation, leading to high hardware costs and energy consumption. These constraints hinder their deployment on resource-constrained, low-power, and distributed platforms that require real-time inference. Moreover, most existing model compression and distillation techniques are designed for static knowledge graphs and fail to adequately capture the temporal dependencies inherent in TKGs, often resulting in degraded reasoning performance. To address these challenges, we propose a distillation framework specifically tailored for temporal knowledge graph reasoning. Our approach leverages large language models as teacher models to guide the distillation process, enabling effective transfer of both structural and temporal reasoning capabilities to lightweight student models. By integrating large-scale public knowledge with task-specific temporal information, the proposed framework enhances the student model's ability to model temporal dynamics while maintaining a compact and efficient architecture. Extensive experiments on multiple publicly available benchmark datasets demonstrate that our method consistently outperforms strong baselines, achieving a favorable trade-off between reasoning accuracy, computational efficiency, and practical deployability.", "AI": {"tldr": "A novel distillation approach for TKG reasoning is introduced, transferring reasoning capabilities to lightweight models for efficient real-time inference on constrained platforms.", "motivation": "The motivation is to address the high hardware costs, energy consumption, and the limitations of existing model compression techniques when applied to TKGs, aiming to enable the deployment of TKG reasoning on resource-constrained platforms.", "method": "The paper proposes a distillation framework for temporal knowledge graph reasoning that uses large language models as teacher models to guide the distillation process, transferring both structural and temporal reasoning capabilities to lightweight student models.", "result": "The method outperforms strong baselines in multiple public datasets, demonstrating a favorable balance between reasoning accuracy and computational efficiency.", "conclusion": "The proposed framework effectively enhances the ability of lightweight models to reason over TKGs, offering a practical solution for real-time inference and resource-constrained environments."}}
{"id": "2601.00090", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00090", "abs": "https://arxiv.org/abs/2601.00090", "authors": ["Anne Harrington", "A. Sophia Koepke", "Shyamgopal Karthik", "Trevor Darrell", "Alexei A. Efros"], "title": "It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models", "comment": null, "summary": "Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.", "AI": {"tldr": "通过对噪声优化，该研究提高了文本到图像模型的多样性和生成质量，减少了模式坍塌现象。", "motivation": "解决文本到图像模型中的模式坍塌问题，提高生成图像的多样性和质量。", "method": "提出一种简单的噪声优化目标，通过优化噪声，改变其频率特性以提高模型生成图像的多样性和优化效果。", "result": "实验结果显示，噪声优化方法提高了生成图像的质量和多样性。", "conclusion": "噪声优化作为解决模式坍塌的方法是有效的，并且相比之前的方法，具有更好的生成质量和多样化结果。"}}
{"id": "2601.00216", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00216", "abs": "https://arxiv.org/abs/2601.00216", "authors": ["Jinning Zhang", "Jie Song", "Wenhui Tu", "Zecheng Li", "Jingxuan Li", "Jin Li", "Xuan Liu", "Taole Sha", "Zichen Wei", "Yan Li"], "title": "From Evidence-Based Medicine to Knowledge Graph: Retrieval-Augmented Generation for Sports Rehabilitation and a Domain Benchmark", "comment": "35 pages, 5 figures", "summary": "In medicine, large language models (LLMs) increasingly rely on retrieval-augmented generation (RAG) to ground outputs in up-to-date external evidence. However, current RAG approaches focus primarily on performance improvements while overlooking evidence-based medicine (EBM) principles. This study addresses two key gaps: (1) the lack of PICO alignment between queries and retrieved evidence, and (2) the absence of evidence hierarchy considerations during reranking. We present a generalizable strategy for adapting EBM to graph-based RAG, integrating the PICO framework into knowledge graph construction and retrieval, and proposing a Bayesian-inspired reranking algorithm to calibrate ranking scores by evidence grade without introducing predefined weights. We validated this framework in sports rehabilitation, a literature-rich domain currently lacking RAG systems and benchmarks. We released a knowledge graph (357,844 nodes and 371,226 edges) and a reusable benchmark of 1,637 QA pairs. The system achieved 0.830 nugget coverage, 0.819 answer faithfulness, 0.882 semantic similarity, and 0.788 PICOT match accuracy. In a 5-point Likert evaluation, five expert clinicians rated the system 4.66-4.84 across factual accuracy, faithfulness, relevance, safety, and PICO alignment. These findings demonstrate that the proposed EBM adaptation strategy improves retrieval and answer quality and is transferable to other clinical domains. The released resources also help address the scarcity of RAG datasets in sports rehabilitation.", "AI": {"tldr": "本研究将循证医学（EBM）的原则整合到基于图的检索增强生成（RAG）系统中，采用了PICO框架进行知识图构建和检索，并提出了一种贝叶斯启发的重新排序算法来校准证据等级的排序分数，提升了检索质量和答案质量，并在运动康复领域验证了该系统的有效性。", "motivation": "现有的RAG方法主要关注性能提升，忽视了EBM的原则，导致查询与检索到的证据之间缺乏PICO一致性，且没有考虑证据等级。", "method": "本研究将PICO框架整合进知识图谱构建及检索，并提出了一种贝叶斯启发的重新排序算法。", "result": "在运动康复领域，系统实现了0.830的nugget覆盖度，0.819的答案忠实度，0.882的语义相似度，0.788的PICOT匹配精度，并获得了专家5分量表评分中的高分。", "conclusion": "提出的EBM适应策略改善了检索质量和答案质量，并表明该策略可转移到其他临床领域。同时，发布了知识图谱和问题-答案对数据库，有助于解决运动康复领域的RAG数据集短缺问题。"}}
{"id": "2601.00092", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00092", "abs": "https://arxiv.org/abs/2601.00092", "authors": ["Pan Wang", "Yang Liu", "Guile Wu", "Eduardo R. Corral-Soto", "Chengjie Huang", "Binbin Xu", "Dongfeng Bai", "Xu Yan", "Yuan Ren", "Xingxin Chen", "Yizhe Wu", "Tao Huang", "Wenjun Wan", "Xin Wu", "Pei Zhou", "Xuyang Dai", "Kangbo Lv", "Hongbo Zhang", "Yosef Fried", "Aixue Ye", "Bailan Feng", "Zhenyu Chen", "Zhen Li", "Yingcong Chen", "Yiyi Liao", "Bingbing Liu"], "title": "Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark", "comment": "Technical Report", "summary": "4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.", "AI": {"tldr": "本文介绍了Spatial4D-Bench，这是一个用于全面评估多模态大型语言模型在4D空间智能方面能力的基准，包含近40,000个问题答案对，覆盖18个定义明确的任务。评估结果显示这些模型在多种4D空间推理方面存在显著局限。", "motivation": "旨在探索多模态大型语言模型达到人类4D空间智能的程度，并通过设计更全面、多样性的基准来评估模型能力。", "method": "开发了一个包含大约40,000个问题答案对的多任务评估基准，分为六个认知类别，广泛覆盖了4D空间智能任务。", "result": "评估了多种先进的开源和专有大型语言模型，发现它们在多种4D空间推理任务中都有所欠缺，如路线规划、动作识别和物理合理性推理。", "conclusion": "研究提供的发现为社区带来了有价值的见解，期望Spatial4D-Bench能推动多模态大型语言模型向人类水平4D空间智能发展。"}}
{"id": "2601.00223", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00223", "abs": "https://arxiv.org/abs/2601.00223", "authors": ["Leonard Lin", "Adam Lensenmayer"], "title": "JP-TL-Bench: Anchored Pairwise LLM Evaluation for Bidirectional Japanese-English Translation", "comment": "24 pages, 5 figures, 8 tables", "summary": "We introduce JP-TL-Bench, a lightweight, open benchmark designed to guide the iterative development of Japanese-English translation systems. In this context, the challenge is often \"which of these two good translations is better?\" rather than \"is this translation acceptable?\" This distinction matters for Japanese-English, where subtle choices in politeness, implicature, ellipsis, and register strongly affect perceived naturalness. JP-TL-Bench uses a protocol built to make LLM judging both reliable and affordable: it evaluates a candidate model via reference-free, pairwise LLM comparisons against a fixed, versioned anchor set. Pairwise results are aggregated with a Bradley-Terry model and reported as win rates plus a normalized 0-10 \"LT\" score derived from a logistic transform of fitted log-strengths. Because each candidate is scored against the same frozen anchor set, scores are structurally stable given the same base set, judge, and aggregation code.", "AI": {"tldr": "JP-TL-Bench是一个基准测试，用于指导日语-英语翻译系统的开发，通过无参考的成对比较来评估模型，报告胜率和\"LT\"评分。", "motivation": "由于在日语-英语翻译中，细微的礼貌、含义、省略和语体选择显著影响感知的自然度，因此该研究旨在解决\"这两个好的翻译哪个更好？\"的问题，而不是\"这个翻译是否可以接受？\"", "method": "JP-TL-Bench是一种轻量级、开源的基准测试，旨在指导日语-英语翻译系统的迭代开发。该基准使用一个协议，通过无参考的LLM成对比较固定版本的基准集来评估候选模型。成对结果通过Bradley-Terry模型聚合，并报告成胜率加上0-10的\"LT\"分数。", "result": "每个候选模型都能在相同的基线集、判断者和聚合代码条件下，产生结构稳定的分数评价。", "conclusion": "JP-TL-Bench提供了一个可靠且经济的方法来评价和迭代开发日语-英语翻译系统。"}}
{"id": "2601.00123", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00123", "abs": "https://arxiv.org/abs/2601.00123", "authors": ["Hyunho Lee", "Wenwen Li"], "title": "A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data", "comment": "50 pages, 12 figures, 6 tables", "summary": "Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.", "AI": {"tldr": "本研究提出了一种名为SMAGNet的多模态深度学习模型，用于增强洪水后水体范围制图的准确性，尤其在MSI数据部分或完全缺失的情况下表现优异。", "motivation": "当前研究中，自适应地将部分可用的MSI数据整合到基于SAR的洪水后水体范围制图过程中仍然是个未充分利用的领域。为了填补这一研究空白，本研究提出了新的方法。", "method": "提出了一种名为SMAGNet的多模态深度学习模型，该模型将SAR数据作为洪水后水体范围制图的主要输入，并通过特征融合集成补充的MSI数据。", "result": "在C2S-MS Floods数据集上的实验表明，SMAGNet在具有不同MSI数据可用性水平的预测性能方面始终优于其他多模态深度学习模型。即使在完全没有MSI数据的情况下，SMAGNet的表现也与仅使用SAR数据训练的U-Net模型统计上相当。", "conclusion": "这些发现表明SMAGNet提高了模型对缺失数据的鲁棒性，同时也增强了多模态深度学习在现实世界洪水管理中的适用性。"}}
{"id": "2601.00224", "categories": ["cs.CL", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.00224", "abs": "https://arxiv.org/abs/2601.00224", "authors": ["Yan Sun", "Ming Cai", "Stanley Kok"], "title": "Talk Less, Verify More: Improving LLM Assistants with Semantic Checks and Execution Feedback", "comment": null, "summary": "As large language model (LLM) assistants become increasingly integrated into enterprise workflows, their ability to generate accurate, semantically aligned, and executable outputs is critical. However, current conversational business analytics (CBA) systems often lack built-in verification mechanisms, leaving users to manually validate potentially flawed results. This paper introduces two complementary verification techniques: Q*, which performs reverse translation and semantic matching between code and user intent, and Feedback+, which incorporates execution feedback to guide code refinement. Embedded within a generator-discriminator framework, these mechanisms shift validation responsibilities from users to the system. Evaluations on three benchmark datasets, Spider, Bird, and GSM8K, demonstrate that both Q* and Feedback+ reduce error rates and task completion time. The study also identifies reverse translation as a key bottleneck, highlighting opportunities for future improvement. Overall, this work contributes a design-oriented framework for building more reliable, enterprise-grade GenAI systems capable of trustworthy decision support.", "AI": {"tldr": "论文介绍了Q*和Feedback+技术，这两种技术用于改善大语言模型的商业应用准确性，评估结果显示其可以提升效率并减少错误。", "motivation": "当前对话式商务分析系统缺乏内置的验证机制，用户需要手动验证可能有误的结果。此项研究旨在提高大语言模型助手生成准确、语义一致和可执行输出的能力。", "method": "此论文介绍了两种互补的验证技术：Q*，它执行代码和用户意图之间的反向翻译和语义匹配；Feedback+，它通过执行反馈来指导代码优化。这些机制嵌入生成器-鉴别器框架中，将验证责任从用户转移到系统。", "result": "评估结果表明，Q*和Feedback+技术能降低错误率并减少任务完成时间。", "conclusion": "该研究提出了一种设计导向框架，用于构建更为可靠、适合企业级别的生成式AI系统，以提供值得信赖的决策支持。"}}
{"id": "2601.00139", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00139", "abs": "https://arxiv.org/abs/2601.00139", "authors": ["Brady Zhou", "Philipp Krähenbühl"], "title": "Compressed Map Priors for 3D Perception", "comment": "Tech report; code https://github.com/bradyz/compressed_map_priors", "summary": "Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\\text{KB}/\\text{km}^2$, a $20\\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.", "AI": {"tldr": "本文介绍了压缩地图先验(CMP)，这是一套利用历史行驶记录学习空间先验的方法，能够以极小的计算开销改进3D物体检测性能。", "motivation": "大多数自动驾驶车辆的视觉系统在遇到新地点时都将其视为首次访问，而忽视了之前的访问历史。这种处理方式可能影响系统的效率和准确性。为了改善这一情况，本文研究了如何利用历史行驶数据提高自动驾驶视觉系统的性能。", "method": "本文提出了压缩地图先验（Compressed Map Priors, CMP）框架，该框架能够从历史行驶记录中学习空间先验。压缩地图先验使用二值哈希表，每平方公里只需32KB，相比密集存储减少了20倍的存储需求。", "result": "实验表明，将CMP集成到领先3D感知系统中，在nuScenes数据集上能够显著地、一致地提高3D物体检测性能，适用于多种架构。", "conclusion": "通过引入压缩地图先验，避免了重复处理相同的行驶数据，这不仅减少了存储空间的消耗，还提高了系统的执行效率和物体检测的准确性。"}}
{"id": "2601.00263", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00263", "abs": "https://arxiv.org/abs/2601.00263", "authors": ["Qianli Wang", "Van Bach Nguyen", "Yihong Liu", "Fedor Splitt", "Nils Feldhus", "Christin Seifert", "Hinrich Schütze", "Sebastian Möller", "Vera Schmitt"], "title": "Parallel Universes, Parallel Languages: A Comprehensive Study on LLM-based Multilingual Counterfactual Example Generation", "comment": "In submission", "summary": "Counterfactuals refer to minimally edited inputs that cause a model's prediction to change, serving as a promising approach to explaining the model's behavior. Large language models (LLMs) excel at generating English counterfactuals and demonstrate multilingual proficiency. However, their effectiveness in generating multilingual counterfactuals remains unclear. To this end, we conduct a comprehensive study on multilingual counterfactuals. We first conduct automatic evaluations on both directly generated counterfactuals in the target languages and those derived via English translation across six languages. Although translation-based counterfactuals offer higher validity than their directly generated counterparts, they demand substantially more modifications and still fall short of matching the quality of the original English counterfactuals. Second, we find the patterns of edits applied to high-resource European-language counterfactuals to be remarkably similar, suggesting that cross-lingual perturbations follow common strategic principles. Third, we identify and categorize four main types of errors that consistently appear in the generated counterfactuals across languages. Finally, we reveal that multilingual counterfactual data augmentation (CDA) yields larger model performance improvements than cross-lingual CDA, especially for lower-resource languages. Yet, the imperfections of the generated counterfactuals limit gains in model performance and robustness.", "AI": {"tldr": "本文通过对六种语言的直接生成和翻译生成的反事实示例的评估，探讨大型语言模型在多语言反事实生成的有效性，表明直接生成的反事实质量较低，多语言反事实数据增强比跨语言增强更有效，但仍存在提升空间。", "motivation": "由于大型语言模型在生成英语反事实示例和多语言能力上表现优异，但其在生成多语言反事实示例方面的有效性尚不明确，因此本文旨在进行深入的研究。", "method": "研究同时进行了直接生成目标语言的反事实示例与通过英语翻译生成的反事实示例的自动评估，涵盖六种语言。", "result": "发现通过翻译生成的反事实示例的质量比直接生成的高，但修改量更大，尚不及英语原创反事实示例的质量。发现高资源欧洲语言的反驳文本编辑模式相似，意味着跨语言扰动遵循共同的战略原则。此外，识别并分类了四类生成反事实示例中各语言普遍出现的错误。", "conclusion": "多语言反事实数据增强所产生的模型性能提升大于跨语言反事实数据增强，特别是对于低资源语言，不过生成的反事实示例中的缺陷限制了模型在性能和鲁棒性上的改善。"}}
{"id": "2601.00141", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00141", "abs": "https://arxiv.org/abs/2601.00141", "authors": ["Lawrence Han"], "title": "Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection", "comment": null, "summary": "The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.", "AI": {"tldr": "GLASS 架构结合了全局缩放视角与多个随机采样的局部区域，有效解决了缩放带来的细节丢失问题，并在实验中展示了卓越的预测性能。", "motivation": "目前大多数 AI 生成的图像检测架构在输入模型之前通常会缩小图像，这可能导致细微细节的丢失。本论文提出了 GLASS 架构，旨在解决这一问题。", "method": "GLASS (Global-Local Attention with Stratified Sampling) 结合了全局缩放视角与多个随机采样的局部区域。这些区域通过空间分层采样高效选择，并使用基于注意力的评分聚合。", "result": "实验显示，GLASS 在合理计算限制下的预测性能优于标准迁移学习。", "conclusion": "本文提出的 GLASS 架构可以在不影响计算资源的情况下提高视觉模型的预测性能。"}}
