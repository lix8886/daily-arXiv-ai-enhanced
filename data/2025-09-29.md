<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 2]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [A Novel Differential Feature Learning for Effective Hallucination Detection and Classification](https://arxiv.org/abs/2509.21357)
*Wenkai Wang,Vincent Lee,Yizhen Zheng*

Main category: cs.CL

> 文章提出了一种新架构，通过差异特征学习和特征的稀疏性来检测语言模型的幻觉，并取得了显著的结果，表明幻觉信号集中且易于检测。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型幻觉表示了一个关键挑战，即输出由于训练数据中的分布偏差而偏离了事实准确性。尽管最近的研究表明，特定的隐藏层在幻觉和事实内容之间存在差异，但具体定位层内的幻觉信号尚不清楚，这限制了有效检测方法的发展。

**Method:** 我们提出了一种双模型架构，该架构结合了投影融合（PF）块进行自适应层间特征加权，以及差异特征学习（DFL）机制，通过计算平行编码器从相同输入中学习到的互补表示之间的差异来识别判别特征。

**Result:** 通过在HaluEval的问题回答、对话和总结数据集上的系统实验，我们证明了幻觉信号集中在高度稀疏的特征子集，显著提高了问题回答和对话任务的准确性。

**Conclusion:** 这些发现表明，幻觉信号比先前假定的更加集中，提供了向计算效率高的检测系统发展的途径，这可以降低推理成本同时保持准确性。

**Abstract:** Large language model hallucination represents a critical challenge where
outputs deviate from factual accuracy due to distributional biases in training
data. While recent investigations establish that specific hidden layers exhibit
differences between hallucinatory and factual content, the precise localization
of hallucination signals within layers remains unclear, limiting the
development of efficient detection methods. We propose a dual-model
architecture integrating a Projected Fusion (PF) block for adaptive inter-layer
feature weighting and a Differential Feature Learning (DFL) mechanism that
identifies discriminative features by computing differences between parallel
encoders learning complementary representations from identical inputs. Through
systematic experiments across HaluEval's question answering, dialogue, and
summarization datasets, we demonstrate that hallucination signals concentrate
in highly sparse feature subsets, achieving significant accuracy improvements
on question answering and dialogue tasks. Notably, our analysis reveals a
hierarchical "funnel pattern" where shallow layers exhibit high feature
diversity while deep layers demonstrate concentrated usage, enabling detection
performance to be maintained with minimal degradation using only 1\% of feature
dimensions. These findings suggest that hallucination signals are more
concentrated than previously assumed, offering a pathway toward computationally
efficient detection systems that could reduce inference costs while maintaining
accuracy.

</details>


### [2] [Influence Guided Context Selection for Effective Retrieval-Augmented Generation](https://arxiv.org/abs/2509.21359)
*Jiale Deng,Yanyan Shen,Ziyuan Pei,Youmin Chen,Linpeng Huang*

Main category: cs.CL

> 论文提出了一种新方法，通过引入上下文影响值（CI值）来改进检索增强生成(RAG)中上下文的选择，显著优于现有的基线方法，能够有效过滤掉质量差的上下文并保留关键信息。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法在通过基于预定的上下文质量评估指标选择上下文来提高性能方面的效果有限。我们将其归因于未能全面利用可用信息（查询、上下文列表和生成器）进行综合质量评估。

**Method:** 引入了上下文影响值（CI值）作为衡量上下文质量的新指标。CI值通过测量从上下文列表中移除每个上下文时的性能下降来量化其质量，从而整合了查询感知的相关性、列表感知的独特性和生成器感知的对齐。此外，CI值通过仅保留CI值为正的上下文，消除了复杂的筛选超参数调整。为了应对标签依赖和计算开销的实际挑战，开发了一个参数化的代理模型进行预测。该模型通过分层架构来捕捉局部的查询-上下文相关性以及全局的跨上下文交互，通过CI值的监督以及端到端生成器反馈进行训练。

**Result:** 实验结果展示了本方法如何在多个自然语言处理任务中以多种大型语言模型为基准的数据集上实现卓越的表现。

**Conclusion:** 实验表明，论文提出的方法在8个NLP任务和多个大型语言模型中显著优于现有基线方法，有效地过滤掉了质量差的上下文，同时保留了关键信息。

**Abstract:** Retrieval-Augmented Generation (RAG) addresses large language model (LLM)
hallucinations by grounding responses in external knowledge, but its
effectiveness is compromised by poor-quality retrieved contexts containing
irrelevant or noisy information. While existing approaches attempt to improve
performance through context selection based on predefined context quality
assessment metrics, they show limited gains over standard RAG. We attribute
this limitation to their failure in holistically utilizing available
information (query, context list, and generator) for comprehensive quality
assessment. Inspired by recent advances in data selection, we reconceptualize
context quality assessment as an inference-time data valuation problem and
introduce the Contextual Influence Value (CI value). This novel metric
quantifies context quality by measuring the performance degradation when
removing each context from the list, effectively integrating query-aware
relevance, list-aware uniqueness, and generator-aware alignment. Moreover, CI
value eliminates complex selection hyperparameter tuning by simply retaining
contexts with positive CI values. To address practical challenges of label
dependency and computational overhead, we develop a parameterized surrogate
model for CI value prediction during inference. The model employs a
hierarchical architecture that captures both local query-context relevance and
global inter-context interactions, trained through oracle CI value supervision
and end-to-end generator feedback. Extensive experiments across 8 NLP tasks and
multiple LLMs demonstrate that our context selection method significantly
outperforms state-of-the-art baselines, effectively filtering poor-quality
contexts while preserving critical information. Code is available at
https://github.com/SJTU-DMTai/RAG-CSM.

</details>


### [3] [Context Is What You Need: The Maximum Effective Context Window for Real World Limits of LLMs](https://arxiv.org/abs/2509.21361)
*Norman Paulsen*

Main category: cs.CL

> 研究展示了报告的最大上下文窗口和实际有效上下文窗口之间存在巨大差异，并提出了一些改进模型性能和减少幻觉的见解。

<details>
  <summary>Details</summary>

**Motivation:** 测试上下文窗口在现实世界中的实际应用，特别是在大型语言模型(LLM)中的应用。

**Method:** 通过定义最大有效上下文窗口的概念，制定上下文窗口有效性测试方法，以及创建标准化的比较方法，来测试不同大小和问题类型的上下文窗口的效果，并发现在报告的最大上下文窗口（MCW）和最大有效上下文窗口（MECW）之间存在显著差异。

**Result:** 实验结果表明，一些顶级模型在测试组中，即使只有100个上下文标记也会出现严重问题；大多数模型在1000个上下文标记范围内，其准确性会显著下降。所有测试模型的MECW比其报告的最大上下文窗口小至99%。

**Conclusion:** 研究发现，不仅最大有效上下文窗口（MECW）与最大上下文窗口（MCW）存在巨大差异，并且MECW会根据问题类型变化。这项数据揭示了基于问题类型的最大有效上下文窗口转移现象，提供了提高模型准确性和降低模型幻觉率的明确且可操作的意见。

**Abstract:** Large language model (LLM) providers boast big numbers for maximum context
window sizes. To test the real world use of context windows, we 1) define a
concept of maximum effective context window, 2) formulate a testing method of a
context window's effectiveness over various sizes and problem types, and 3)
create a standardized way to compare model efficacy for increasingly larger
context window sizes to find the point of failure. We collected hundreds of
thousands of data points across several models and found significant
differences between reported Maximum Context Window (MCW) size and Maximum
Effective Context Window (MECW) size. Our findings show that the MECW is, not
only, drastically different from the MCW but also shifts based on the problem
type. A few top of the line models in our test group failed with as little as
100 tokens in context; most had severe degradation in accuracy by 1000 tokens
in context. All models fell far short of their Maximum Context Window by as
much as 99 percent. Our data reveals the Maximum Effective Context Window
shifts based on the type of problem provided, offering clear and actionable
insights into how to improve model accuracy and decrease model hallucination
rates.

</details>


### [4] [How Large Language Models Need Symbolism](https://arxiv.org/abs/2509.21404)
*Xiaotie Deng,Hanyu Li*

Main category: cs.CL

> 论文主张AI的发展不能仅依赖规模扩大，大型语言模型需借助人类设计的符号来引导创意发现。

<details>
  <summary>Details</summary>

**Motivation:** 强调AI未来需要超越单纯扩大规模，提出大型语言模型需要人类设计的符号来引导其强大的但盲目的直觉。

**Method:** N/A

**Result:** N/A

**Conclusion:** N/A

**Abstract:** We argue that AI's future requires more than scaling. To unlock genuine
discovery, large language models need a compass: human-crafted symbols to guide
their powerful but blind intuition.

</details>


### [5] [One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning](https://arxiv.org/abs/2509.21443)
*Sualeha Farid,Jayden Lin,Zean Chen,Shivani Kumar,David Jurgens*

Main category: cs.CL

> 研究探讨了语言如何影响大型语言模型的道德决策，揭示了预训练数据对LLMs道德判断的影响，提示需要开发更加文化适应性的AI。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）越来越多地部署在多语言和多文化环境中，其中道德推理对于生成合乎伦理的响应至关重要。然而，LLMs的主导预训练主要基于英语数据，这一现状对它们在各种语言和文化背景下推广判断的能力提出了严峻挑战。

**Method:** 通过将两个已建立的道德推理基准翻译成五种文化上和类型上多样化的语言来进行多语言零样本评估，系统地研究了语言在LLMs道德决策中的中介作用。

**Result:** 分析显示了LLMs在不同语言中的道德判断存在显著不一致性，经常反映出文化上的不同。通过仔细构建的研究问题，揭示了这些差异的潜在驱动因素，包括LLMs使用的推理策略等。

**Conclusion:** 通过这项工作，将见解提炼为一种道德推理错误的结构化分类，呼吁更加注重文化的AI。

**Abstract:** Large Language Models (LLMs) are increasingly deployed in multilingual and
multicultural environments where moral reasoning is essential for generating
ethically appropriate responses. Yet, the dominant pretraining of LLMs on
English-language data raises critical concerns about their ability to
generalize judgments across diverse linguistic and cultural contexts. In this
work, we systematically investigate how language mediates moral decision-making
in LLMs. We translate two established moral reasoning benchmarks into five
culturally and typologically diverse languages, enabling multilingual zero-shot
evaluation. Our analysis reveals significant inconsistencies in LLMs' moral
judgments across languages, often reflecting cultural misalignment. Through a
combination of carefully constructed research questions, we uncover the
underlying drivers of these disparities, ranging from disagreements to
reasoning strategies employed by LLMs. Finally, through a case study, we link
the role of pretraining data in shaping an LLM's moral compass. Through this
work, we distill our insights into a structured typology of moral reasoning
errors that calls for more culturally-aware AI.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Random Direct Preference Optimization for Radiography Report Generation](https://arxiv.org/abs/2509.21351)
*Valentin Samokhin,Boris Shirokikh,Mikhail Goncharov,Dmitriy Umerenkov,Maksim Bobrin,Ivan Oseledets,Dmitry Dylov,Mikhail Belyaev*

Main category: cs.CV

> 我们提出了一种无模型框架，利用Direct Preference Optimization (DPO)提升放射学报告生成( RRG) 的质量，无需额外训练数据或人工偏好标注，改进了临床性能指标。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于现有的放射学报告生成方法尚未达到在真实临床环境中部署所需的质量水平，我们提出了这种方法以改善这一状况。大型视觉语言模型（VLM）在采用大型语言模型（LLM）的训练策略方面取得了显著进展，我们的方法借鉴了这些进展。

**Method:** 我们的方法采用了一种无模型框架，利用Direct Preference Optimization (DPO)来提高放射学报告生成（RRG）的准确性。通过随机对比采样构建训练对，这种方法不需要奖励模型或人类偏好注释。

**Result:** 实验结果显示，在现有的三种先进模型中加入我们的Random DPO技术，临床性能指标提高了最多5%。

**Conclusion:** 通过我们的模型无关框架，可以有效地提高放射学报告生成的准确性，显著改善了性能而无需额外的数据或手工注释。

**Abstract:** Radiography Report Generation (RRG) has gained significant attention in
medical image analysis as a promising tool for alleviating the growing workload
of radiologists. However, despite numerous advancements, existing methods have
yet to achieve the quality required for deployment in real-world clinical
settings. Meanwhile, large Visual Language Models (VLMs) have demonstrated
remarkable progress in the general domain by adopting training strategies
originally designed for Large Language Models (LLMs), such as alignment
techniques. In this paper, we introduce a model-agnostic framework to enhance
RRG accuracy using Direct Preference Optimization (DPO). Our approach leverages
random contrastive sampling to construct training pairs, eliminating the need
for reward models or human preference annotations. Experiments on supplementing
three state-of-the-art models with our Random DPO show that our method improves
clinical performance metrics by up to 5%, without requiring any additional
training data.

</details>


### [7] [Improving Autism Detection with Multimodal Behavioral Analysis](https://arxiv.org/abs/2509.21352)
*William Saakyan,Matthias Norden,Lola Eversmann,Simon Kirsch,Muyu Lin,Simon Guendelman,Isabel Dziobek,Hanna Drimalla*

Main category: cs.CV

> This study enhances ASC detection by developing improved statistical gaze descriptors and conducting a multimodal behavioral analysis on a large, balanced dataset, achieving a 74% classification accuracy via late fusion.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this research stems from the difficulties in diagnosing ASC, particularly with the existing gaze feature performance and the need for models with better real-world generalizability. The researchers aimed to improve diagnostic support by enhancing the accuracy of gaze-based classifications and integrating multiple behavioral markers.

**Method:** To address the limitations in prior gaze models when diagnosing ASC using computer-aided methods, the researchers developed novel statistical descriptors to quantify variability in eye gaze angles. They conducted a multimodal analysis of facial expressions, voice prosody, head motion, heart rate variability, and gaze behavior using a large, balanced dataset.

**Result:** The research led to a significant increase in the gaze-based classification accuracy from 64% to 69%, while the multimodal late fusion analysis reached an overall classification accuracy of 74%. These improvements align with clinical findings on gaze aversion in ASC.

**Conclusion:** The study emphasizes the potential for scalable, video-based screening tools to improve ASC assessment by offering more accurate and generalized diagnostic support through the integration of multimodal behavioral markers.

**Abstract:** Due to the complex and resource-intensive nature of diagnosing Autism
Spectrum Condition (ASC), several computer-aided diagnostic support methods
have been proposed to detect autism by analyzing behavioral cues in patient
video data. While these models show promising results on some datasets, they
struggle with poor gaze feature performance and lack of real-world
generalizability. To tackle these challenges, we analyze a standardized video
dataset comprising 168 participants with ASC (46% female) and 157 non-autistic
participants (46% female), making it, to our knowledge, the largest and most
balanced dataset available. We conduct a multimodal analysis of facial
expressions, voice prosody, head motion, heart rate variability (HRV), and gaze
behavior. To address the limitations of prior gaze models, we introduce novel
statistical descriptors that quantify variability in eye gaze angles, improving
gaze-based classification accuracy from 64% to 69% and aligning computational
findings with clinical research on gaze aversion in ASC. Using late fusion, we
achieve a classification accuracy of 74%, demonstrating the effectiveness of
integrating behavioral markers across multiple modalities. Our findings
highlight the potential for scalable, video-based screening tools to support
autism assessment.

</details>
