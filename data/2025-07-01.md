<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 13]
- [cs.CV](#cs.CV) [Total: 16]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Psycholinguistic Word Features: a New Approach for the Evaluation of LLMs Alignment with Humans](https://arxiv.org/abs/2506.22439)
*Javier Conde,Miguel González,María Grandury,Gonzalo Martínez,Pedro Reviriego,Mar Brysbaert*

Main category: cs.CL

> 研究通过对比LLMs与人类在心理语言学数据集中的评分一致性，探讨了LLMs在非量化语言特征上的表现。结果表明，LLMs在某些感知特征上与人类认知差异较大，显示了其在模拟人类感官体验上的限制。

<details>
  <summary>Details</summary>

**Motivation:** 本文旨在探索除了常规任务（如推理、问答等）之外，LLMs在语言特征上的表现，尤其是那些不易量化的特征，如唤醒度、具体性或与某个词相关的性别。通过与人类评分的比较，以期揭示LLMs在这些方面与人类认知的差距。

**Method:** 本文通过将LLMs与人类对两个心理语言学数据集（Glasgow 和 Lancaster 规范）中词特征的评分进行比较，来评估LLMs与人类评分的一致性。这些数据集包含了数千个单词的十三个特征。

**Result:** 结果表明，在Glasgow范式评估的特征（如唤醒度、效价、支配性、具体性、形象性、熟悉度和性别）上，一致性较好；而在Lancaster范式评估的感官特征（如内省、味觉、嗅觉、触觉、听觉和视觉）上，一致性较差。这可能表明当前LLMs在与人类感官关联方面存在局限性。

**Conclusion:** 研究结论表明，利用心理语言学数据集评估LLMs是有益的，显示出当前LLMs在模拟人类感官体验方面的能力有限。

**Abstract:** The evaluation of LLMs has so far focused primarily on how well they can
perform different tasks such as reasoning, question-answering, paraphrasing, or
translating. For most of these tasks, performance can be measured with
objective metrics, such as the number of correct answers. However, other
language features are not easily quantified. For example, arousal,
concreteness, or gender associated with a given word, as well as the extent to
which we experience words with senses and relate them to a specific sense.
Those features have been studied for many years by psycholinguistics,
conducting large-scale experiments with humans to produce ratings for thousands
of words. This opens an opportunity to evaluate how well LLMs align with human
ratings on these word features, taking advantage of existing studies that cover
many different language features in a large number of words. In this paper, we
evaluate the alignment of a representative group of LLMs with human ratings on
two psycholinguistic datasets: the Glasgow and Lancaster norms. These datasets
cover thirteen features over thousands of words. The results show that
alignment is \textcolor{black}{generally} better in the Glasgow norms evaluated
(arousal, valence, dominance, concreteness, imageability, familiarity, and
gender) than on the Lancaster norms evaluated (introceptive, gustatory,
olfactory, haptic, auditory, and visual). This suggests a potential limitation
of current LLMs in aligning with human sensory associations for words, which
may be due to their lack of embodied cognition present in humans and
illustrates the usefulness of evaluating LLMs with psycholinguistic datasets.

</details>


### [2] [AI Agents-as-Judge: Automated Assessment of Accuracy, Consistency, Completeness and Clarity for Enterprise Documents](https://arxiv.org/abs/2506.22485)
*Sudip Dasgupta,Himanshu Shankar*

Main category: cs.CL

> A modular, multi-agent AI system for automated enterprise document review is presented, achieving high accuracy and consistency with substantial time savings compared to human review.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this study is to improve upon existing limited AI solutions by offering a more comprehensive and automated system for document review, capable of handling multiple criteria and ensuring high-quality, consistent enterprise documents.

**Method:** This paper introduces a multi-agent AI system for reviewing highly structured enterprise documents. The system uses modern orchestration tools and specialized AI agents to evaluate documents for various criteria such as accuracy and consistency.

**Result:** The system shows promising results, demonstrating performance that either meets or exceeds human capabilities in terms of information consistency, error and bias reduction, and time efficiency.

**Conclusion:** The paper concludes that the proposed system can serve as a scalable, auditable, and flexible solution for AI-driven quality assurance in enterprise document reviews, although it acknowledges the necessity of human oversight in specialized areas.

**Abstract:** This study presents a modular, multi-agent system for the automated review of
highly structured enterprise business documents using AI agents. Unlike prior
solutions focused on unstructured texts or limited compliance checks, this
framework leverages modern orchestration tools such as LangChain, CrewAI,
TruLens, and Guidance to enable section-by-section evaluation of documents for
accuracy, consistency, completeness, and clarity. Specialized agents, each
responsible for discrete review criteria such as template compliance or factual
correctness, operate in parallel or sequence as required. Evaluation outputs
are enforced to a standardized, machine-readable schema, supporting downstream
analytics and auditability. Continuous monitoring and a feedback loop with
human reviewers allow for iterative system improvement and bias mitigation.
  Quantitative evaluation demonstrates that the AI Agent-as-Judge system
approaches or exceeds human performance in key areas: achieving 99% information
consistency (vs. 92% for humans), halving error and bias rates, and reducing
average review time from 30 to 2.5 minutes per document, with a 95% agreement
rate between AI and expert human judgment. While promising for a wide range of
industries, the study also discusses current limitations, including the need
for human oversight in highly specialized domains and the operational cost of
large-scale LLM usage. The proposed system serves as a flexible, auditable, and
scalable foundation for AI-driven document quality assurance in the enterprise
context.

</details>


### [3] [Hallucination Detection with Small Language Models](https://arxiv.org/abs/2506.22486)
*Ming Cheung*

Main category: cs.CL

> 本文提出了一种利用多个小型语言模型验证大型语言模型答案正确性的框架。通过实验验证，该框架能够有效提升F1分数10%，证明这一方法在检测幻觉和提升LLMs可靠性方面有显著效果。

<details>
  <summary>Details</summary>

**Motivation:** 随着像ChatGPT这样的大型语言模型在多种任务中的应用越来越广泛，其生成的回答中的幻觉成为实际应用中的一个可靠性问题。特别是在问答场景下，这些幻觉很难检测，特别是在没有真实依据的情况下。因此，该论文旨在开发一种框架来检测这些幻觉，提高LLMs的可靠性。

**Method:** 该论文提出了一种结合多个小型语言模型的框架，用于验证由大型语言模型（LLMs）生成的基于向量化数据库检索到的上下文的答案。通过将答案分解为单个句子，并利用多个模型针对一组问题、答案和相关上下文生成“是”令牌的概率，来检测幻觉（即不准确的回答）。

**Result:** 实验结果显示，在检测正确答案的F1分数上，相比幻觉，该框架有10%的提升，这表明使用多个小型语言模型可以有效验证答案。

**Conclusion:** 综上所述，该框架提供了一个可扩展且高效的解决方案，适用于学术和实际应用中的答案验证。

**Abstract:** Since the introduction of ChatGPT, large language models (LLMs) have
demonstrated significant utility in various tasks, such as answering questions
through retrieval-augmented generation. Context can be retrieved using a
vectorized database, serving as a foundation for LLMs to generate responses.
However, hallucinations in responses can undermine the reliability of LLMs in
practical applications, and they are not easily detectable in the absence of
ground truth, particularly in question-and-answer scenarios. This paper
proposes a framework that integrates multiple small language models to verify
responses generated by LLMs using the retrieved context from a vectorized
database. By breaking down the responses into individual sentences and
utilizing the probability of generating "Yes" tokens from the outputs of
multiple models for a given set of questions, responses, and relevant context,
hallucinations can be detected. The proposed framework is validated through
experiments with real datasets comprising over 100 sets of questions, answers,
and contexts, including responses with fully and partially correct sentences.
The results demonstrate a 10\% improvement in F1 scores for detecting correct
responses compared to hallucinations, indicating that multiple small language
models can be effectively employed for answer verification, providing a
scalable and efficient solution for both academic and practical applications.

</details>


### [4] [PromptAug: Fine-grained Conflict Classification Using Data Augmentation](https://arxiv.org/abs/2506.22491)
*Oliver Warke,Joemon M. Jose,Faegheh Hasibi,Jan Breitsohl*

Main category: cs.CL

> 本文介绍并评估了PromptAug，这是一种旨在在冲突检测等敏感任务中生成增强数据的新方法。实验显示，该方法在准确性、F1分数上均有显著提升，并提出了一些在增强文本中的问题模式。

<details>
  <summary>Details</summary>

**Motivation:** 由于高质量标注数据的稀缺性、成本高以及获取难度大，尤其是在识别细微任务如冲突行为方面，本文提出PromptAug方法。此外，随着社交媒体平台对研究数据访问的限制增加，文本数据增强作为替代方案引起了更多关注。

**Method:** PromptAug是一种创新的基于大型语言模型（LLM）的数据增强方法，旨在解决敏感任务如冲突检测中的数据增强问题。

**Result:** 通过使用极端数据稀缺场景、定量多样性分析和定性主题分析，实验表明PromptAug在冲突和情感数据集上相比其他数据增强方法，准确性和F1分数上均有2%的统计显著性提高。主题分析识别了增强文本中的四个问题模式：语言流动性、幽默模糊性、增强内容模糊性和增强内容误读。

**Conclusion:** 整体而言，PromptAug被证明是用于如冲突检测这种敏感任务中增强数据的有效方法，为自然语言处理和社科方法之间的跨学科评估提供了独特的案例。

**Abstract:** Given the rise of conflicts on social media, effective classification models
to detect harmful behaviours are essential. Following the
garbage-in-garbage-out maxim, machine learning performance depends heavily on
training data quality. However, high-quality labelled data, especially for
nuanced tasks like identifying conflict behaviours, is limited, expensive, and
difficult to obtain. Additionally, as social media platforms increasingly
restrict access to research data, text data augmentation is gaining attention
as an alternative to generate training data. Augmenting conflict-related data
poses unique challenges due to Large Language Model (LLM) guardrails that
prevent generation of offensive content. This paper introduces PromptAug, an
innovative LLM-based data augmentation method. PromptAug achieves statistically
significant improvements of 2% in both accuracy and F1-score on conflict and
emotion datasets. To thoroughly evaluate PromptAug against other data
augmentation methods we conduct a robust evaluation using extreme data scarcity
scenarios, quantitative diversity analysis and a qualitative thematic analysis.
The thematic analysis identifies four problematic patterns in augmented text:
Linguistic Fluidity, Humour Ambiguity, Augmented Content Ambiguity, and
Augmented Content Misinterpretation.
  Overall, this work presents PromptAug as an effective method for augmenting
data in sensitive tasks like conflict detection, offering a unique,
interdisciplinary evaluation grounded in both natural language processing and
social science methodology.

</details>


### [5] [AgentStealth: Reinforcing Large Language Model for Anonymizing User-generated Text](https://arxiv.org/abs/2506.22508)
*Chenyang Shao,Tianxing Li,Chenhao Pu,Fengli Xu,Yong Li*

Main category: cs.CL

> The paper presents AgentStealth, a framework for text anonymization using locally deployed smaller-scale language models, which enhances privacy without compromising text utility. It uses self-reinforcing techniques and adversarial training, showing significant improvements over baseline methods in both anonymization effectiveness and text utility, while also avoiding cloud reliance and communication-based privacy risks. The framework's code is open-source and designed for edge devices deployment.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this paper is to protect individual privacy by effectively anonymizing text data while maintaining its utility. Existing methods either degrade utility or come with privacy concerns, leading the authors to propose a method that uses locally deployed smaller-scale language models to protect privacy and ensure data utility without cloud dependence.

**Method:** The method involves an adversarial workflow enhanced with in-context contrastive learning and adaptive utility-aware control. Supervised adaptation of smaller-scale language models (SLMs) is performed using a dataset collected from this workflow. Online reinforcement learning is applied to iteratively improve the anonymization performance based on the model's internal adversarial feedback.

**Result:** Experiments on two datasets demonstrated that the proposed method outperformed baseline methods in both anonymization effectiveness (+12.3%) and utility (+6.8%).

**Conclusion:** The conclusion is that AgentStealth provides an effective solution for text anonymization that preserves utility, operates locally on edge devices, and minimizes privacy risks associated with cloud-based anonymization methods. This makes it a promising approach for safeguarding privacy in user-generated content in the digital age.

**Abstract:** In today's digital world, casual user-generated content often contains subtle
cues that may inadvertently expose sensitive personal attributes. Such risks
underscore the growing importance of effective text anonymization to safeguard
individual privacy. However, existing methods either rely on rigid replacements
that damage utility or cloud-based LLMs that are costly and pose privacy risks.
To address these issues, we explore the use of locally deployed smaller-scale
language models (SLMs) for anonymization. Yet training effective SLMs remains
challenging due to limited high-quality supervision. To address the challenge,
we propose AgentStealth, a self-reinforcing LLM anonymization framework.First,
we introduce an adversarial anonymization workflow enhanced by In-context
Contrastive Learning and Adaptive Utility-Aware Control. Second, we perform
supervised adaptation of SLMs using high-quality data collected from the
workflow, which includes both anonymization and attack signals. Finally, we
apply online reinforcement learning where the model leverages its internal
adversarial feedback to iteratively improve anonymization performance.
Experiments on two datasets show that our method outperforms baselines in both
anonymization effectiveness (+12.3%) and utility (+6.8%). Our lightweight
design supports direct deployment on edge devices, avoiding cloud reliance and
communication-based privacy risks. Our code is open-source at
https://github.com/tsinghua-fib-lab/AgentStealth.

</details>


### [6] [Towards Text-free Graph Foundation Models: Rethinking Multi-Domain Graph Contrastive Learning](https://arxiv.org/abs/2506.22510)
*Zihao Zhao,Xinlong Zhai,Jinyu Yang,Chuan Shi*

Main category: cs.CL

> 本文提出了一种名为MDGCL的新框架，用于多域预训练和跨域知识转移，专门针对图数据，特别是没有文本特征的图数据，实验表明该方法在多个基准数据集上显著优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 针对图数据领域，特别是在不同域间语义和属性的巨大差距上，现有的单域对比预训练策略难以有效吸收知识并生成有信息量的表示，因此本文旨在改进这一策略。

**Method:** 提出了一个名为MDGCL的新框架，包含预训练阶段的对比学习策略和引入域标记编码域级全局信息，下游阶段引入域注意力机制实现细粒度的知识转移。

**Result:** 在五个基准数据集上的实验表明，该方法显著优于现有方法，准确率最高提升了19.33%，Macro-F1得分最高提升了19.13%。

**Conclusion:** 该研究提供了一种有效的策略，在多域图数据中引领了更好的预训练和跨域知识转移，展示了显著的性能提升。

**Abstract:** Foundation models have achieved great success in natural language processing
(NLP) and computer vision (CV). Their success largely stems from the ability to
integrate multi-domain knowledge in pre-training and transfer it to target
domains. Considering graph data, especially graphs without textual features, is
ubiquitous in real-world applications such as social networks and
recommendation systems, some researchers have attempted to extend this paradigm
to the graph field, aiming to construct graph foundation models. However,
unlike CV and NLP, there are huge gaps among the semantics and properties of
graphs in different domains, while current works still adopt traditional
contrastive pre-training strategies designed in the single-domain scenario,
which regard contrastive samples from different domains as equivalent. From
experimental investigations, we discovered that inherent domain-specific
differences prevent these strategies from effectively absorbing knowledge from
different domains to generate informative representations. In this paper, we
propose a novel multi-domain pre-training and cross-domain transfer framework,
namely MDGCL.In the pre-training stage, we design a contrastive learning
strategy to substantially recognize and capture domain differences, and
introduce domain tokens to encode domain-level global information. In the
downstream stage, we introduce a domain attention mechanism to enable
fine-grained domain knowledge transfer. Extensive experiments on five benchmark
datasets have demonstrated that our method outperforms state-of-the-art
significantly, with the maximum improvement of 19.33\% on accuracy and 19.13\%
on Macro-F1 score.

</details>


### [7] [Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis](https://arxiv.org/abs/2506.22516)
*Jingkai Li*

Main category: cs.CL

> 通过IIT3.0和4.0评估LLM的表现，以探讨LLM是否能展示意识的特性，虽然结果未能显著表明存在意识现象，但在特定条件下显示出有趣的模式。

<details>
  <summary>Details</summary>

**Motivation:** 研究目的在于探究大型语言模型在处理心智理论测试时是否能够表现出类似于意识的信息整合现象，并尝试通过具体分析方法辨别LLM表示空间中可能存在的意识相关特征。

**Method:** 采用整合信息理论(IIT)的3.0和4.0版本，分析了大型语言模型(LLM)表示的序列，依据现有的心智理论(ToM)测试结果来研究ToM测试表现差异在LLM表示中是否可以通过IIT估计（包括IIT 3.0的$\Phi^{\max}$、概念信息，以及IIT 4.0的$\Phi$、$\Phi$-结构）揭示出来。还比较了这些指标与独立于任何意识估计的跨度表示，以区分潜在的“意识”现象和LLM表示空间内的固有分离。

**Result:** 研究确定，当前的Transformer模型在代表意识的现象上并无统计意义上显著的结果，但是通过空间-排列分析展示了有趣的趋势。

**Conclusion:** 实验结果显示现代变压器基础的LLM表示缺乏统计学上显著的意识现象指标，但在空间-排列分析下显示了有趣的模式。

**Abstract:** Integrated Information Theory (IIT) provides a quantitative framework for
explaining consciousness phenomenon, positing that conscious systems comprise
elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the
latest iterations of this framework -- to sequences of Large Language Model
(LLM) representations, analyzing data derived from existing Theory of Mind
(ToM) test results. Our study systematically investigates whether the
differences of ToM test performances, when presented in the LLM
representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT
3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure
(IIT 4.0). Furthermore, we compare these metrics with the Span Representations
independent of any estimate for consciousness. This additional effort aims to
differentiate between potential "consciousness" phenomena and inherent
separations within LLM representational space. We conduct comprehensive
experiments examining variations across LLM transformer layers and linguistic
spans from stimuli. Our results suggest that sequences of contemporary
Transformer-based LLM representations lack statistically significant indicators
of observed "consciousness" phenomena but exhibit intriguing patterns under
$\textit{spatio}$-permutational analyses. The Appendix and code are available
as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.

</details>


### [8] [Weak-to-Strong GraphRAG: Aligning Weak Retrievers with Large Language Models for Graph-based Retrieval Augmented Generation](https://arxiv.org/abs/2506.22518)
*Deyu Zou,Yongqiang Chen,Mufei Li,Siqi Miao,Chenxi Liu,Bo Han,James Cheng,Pan Li*

Main category: cs.CL

> Paper presents Refined Graph-based RAG (ReG), an approach for improving large language models by better aligning weak retrievers with LLMs in graph-based retrieval-augmented generation systems.

<details>
  <summary>Details</summary>

**Motivation:** To improve the performance of existing RAG systems by addressing the issues of weak supervision for retrievers and unorganized retrieved knowledge.

**Method:** Refined Graph-based RAG (ReG) incorporates LLM feedback to reduce spurious signals and uses a structure-aware reorganization module to refactor retrieval results into logically coherent evidence chains.

**Result:** Experiments show significant improvement across different LLM backbones with up to 10% gains. ReG achieves state-of-the-art performance with 5% training data and transfers well to out-of-distribution KGs.

**Conclusion:** ReG effectively enhances the retrieval quality and reduces computational costs for reasoning tasks by up to 30%, outperforming state-of-the-art methods with less data.

**Abstract:** Graph-based retrieval-augmented generation (RAG) enables large language
models (LLMs) to ground responses with structured external knowledge from
up-to-date knowledge graphs (KGs) and reduce hallucinations. However, LLMs
often rely on a weak retriever in graph-based RAG: I) Due to the lack of ground
truth, the retriever is often trained on weak supervision, which often
introduces spurious signals to the LLMs. II) Due to the abstraction of graph
data, the retrieved knowledge is often presented in unorganized forms. To
mitigate the issue, we present Refined Graph-based RAG (ReG) to align weak
retrievers to LLMs for graph-based RAG. Specifically, ReG incorporates LLM
feedback to get rid of spurious signals and improve the quality of the
supervision. Meanwhile, ReG introduces a structure-aware reorganization module
to refactor the retrieval results into logically coherent evidence chains.
Experiments on prominent benchmarks demonstrate that ReG significantly and
consistently brings improvements across different LLM backbones by up to 10%.
The improved supervision quality enables ReG to match the state-of-the-art
performance with 5% training data and to transfer to out-of-distribution KGs.
Notably, when adopted to reasoning-based LLMs, ReG reduces the reasoning token
cost by up to 30% and improves the performance by up to 4%.

</details>


### [9] [MisinfoTeleGraph: Network-driven Misinformation Detection for German Telegram Messages](https://arxiv.org/abs/2506.22529)
*Lu Kalkbrenner,Veronika Solopova,Steffen Zeiler,Robert Nickel,Dorothea Kolossa*

Main category: cs.CL

> 研究者们开发了一个名为Misinfo-TeleGraph的德语Telegram数据集用于虚假信息检测，证明了网络结构在检测中的优势，并提供了重复实验的基础。

<details>
  <summary>Details</summary>

**Motivation:** 在网络监控较差的平台上，如Telegram，连通性和消息传播是虚假信息检测的重要但未充分利用的信息来源。尤其是在德国选举背景下，Telegram成为了虚假信息传播的关键渠道。

**Method:** 论文介绍了一种名为Misinfo-TeleGraph的基于Telegram的图数据集，用于德语环境下的虚假信息检测。该数据集通过M3-embeddings计算语义相似度以及人工注释，对消息进行弱标签和强标签标注。他们还评估了文本模型和图神经网络（GNNs）的基本线模型。

**Result:** 实验结果显示，结合LSTM聚合的GraphSAGE在Matthews相关系数（MCC）和F1值方面显著优于单纯基于文本的模型。此外，还评估了订阅者数量、观看次数以及自动与人工标注对性能的影响。

**Conclusion:** 这项工作提供了一个可以复现的基准和开放数据集，为未来在德语Telegram网络以及其他低监管社交平台上的虚假信息检测研究提供了有益的参考。

**Abstract:** Connectivity and message propagation are central, yet often underutilized,
sources of information in misinformation detection -- especially on poorly
moderated platforms such as Telegram, which has become a critical channel for
misinformation dissemination, namely in the German electoral context. In this
paper, we introduce Misinfo-TeleGraph, the first German-language Telegram-based
graph dataset for misinformation detection. It includes over 5 million messages
from public channels, enriched with metadata, channel relationships, and both
weak and strong labels. These labels are derived via semantic similarity to
fact-checks and news articles using M3-embeddings, as well as manual
annotation. To establish reproducible baselines, we evaluate both text-only
models and graph neural networks (GNNs) that incorporate message forwarding as
a network structure. Our results show that GraphSAGE with LSTM aggregation
significantly outperforms text-only baselines in terms of Matthews Correlation
Coefficient (MCC) and F1-score. We further evaluate the impact of subscribers,
view counts, and automatically versus human-created labels on performance, and
highlight both the potential and challenges of weak supervision in this domain.
This work provides a reproducible benchmark and open dataset for future
research on misinformation detection in German-language Telegram networks and
other low-moderation social platforms.

</details>


### [10] [RExBench: Can coding agents autonomously implement AI research extensions?](https://arxiv.org/abs/2506.22598)
*Nicholas Edwards,Yukyung Lee,Yujun,Mao,Yulu Qin,Sebastian Schuster,Najoung Kim*

Main category: cs.CL

> 介绍了RExBench，一个旨在评估LLM代理在执行研究扩展任务方面的能力的基准。研究发现，所有被评估的代理在没有大幅度人为指导的情况下都无法自主实现大部分扩展。

<details>
  <summary>Details</summary>

**Motivation:** 基于大规模语言模型（LLMs）的代理在自主执行复杂的软件工程任务方面显示出潜力。此外，在开发能够执行机器学习和自然科学中的研究管道部分的代理方面也取得了进展。作者认为，研究扩展及其实现是这些系统的关键能力。

**Method:** 引入了RExBench来评估这种能力。RExBench是一个由12个现实的研究实验实现任务组成的基准，旨在探讨从未被实现过的研究假设。每个任务都设置为现有研究论文和代码库的扩展，并附有领域专家编写的说明。RExBench对数据污染具有鲁棒性，并支持自动评估基础设施，该基础设施执行代理输出以确定是否满足成功标准。

**Result:** 使用此基准测试了使用三种不同框架(aider, Claude Code, 和 OpenHands) 实现的九个LLM代理。研究发现，所有被评估的代理都无法自主实现大多数扩展。尽管在添加了额外的人类撰写的提示后成功率有所提高，但最佳性能仍低于40%。

**Conclusion:** 表明目前的代理在没有大量人为指导的情况下仍无法处理现实的研究扩展任务。

**Abstract:** Agents based on Large Language Models (LLMs) have shown promise for
performing sophisticated software engineering tasks autonomously. In addition,
there has been progress towards developing agents that can perform parts of the
research pipeline in machine learning and the natural sciences. We argue that
research extension and its implementation is a critical capability for such
systems, and introduce RExBench to support the evaluation of this capability.
RExBench is a benchmark consisting of 12 realistic research experiment
implementation tasks that aim to investigate research hypotheses that have not
previously been implemented. Each task is set up as an extension to an existing
research paper and codebase, accompanied by domain expert-written instructions.
RExBench is robust to data contamination, and supports an automatic evaluation
infrastructure that executes agent outputs to determine whether the success
criteria are met. We use this benchmark to evaluate nine LLM agents implemented
using three different frameworks: aider, Claude Code, and OpenHands. We find
that all agents evaluated fail to autonomously implement the majority of the
extensions. Although the success rate improves with additional human-written
hints, the best performance under this setting remains below 40%. This
indicates that current agents are still short of being able to handle realistic
research extension tasks without substantial human guidance.

</details>


### [11] [Temperature Matters: Enhancing Watermark Robustness Against Paraphrasing Attacks](https://arxiv.org/abs/2506.22623)
*Badr Youbi Idrissi,Monica Millunzi,Amelia Sorrenti,Lorenzo Baraldi,Daryna Dementieva*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** In the present-day scenario, Large Language Models (LLMs) are establishing
their presence as powerful instruments permeating various sectors of society.
While their utility offers valuable support to individuals, there are multiple
concerns over potential misuse. Consequently, some academic endeavors have
sought to introduce watermarking techniques, characterized by the inclusion of
markers within machine-generated text, to facilitate algorithmic
identification. This research project is focused on the development of a novel
methodology for the detection of synthetic text, with the overarching goal of
ensuring the ethical application of LLMs in AI-driven text generation. The
investigation commences with replicating findings from a previous baseline
study, thereby underscoring its susceptibility to variations in the underlying
generation model. Subsequently, we propose an innovative watermarking approach
and subject it to rigorous evaluation, employing paraphrased generated text to
asses its robustness. Experimental results highlight the robustness of our
proposal compared to the~\cite{aarson} watermarking method.

</details>


### [12] [Evaluating Hybrid Retrieval Augmented Generation using Dynamic Test Sets: LiveRAG Challenge](https://arxiv.org/abs/2506.22644)
*Chase Fensore,Kaustubh Dhole,Joyce C Ho,Eugene Agichtein*

Main category: cs.CL

> A hybrid RAG system combining sparse and dense retrieval methods with a generation model ranks 4th in faithfulness and 11th in correctness in the LiveRAG Challenge 2025, highlighting challenges and benefits of re-ranking and prompting strategies.

<details>
  <summary>Details</summary>

**Motivation:** Evaluate a RAG system's performance on dynamic test sets using the FineWeb-10BT corpus and analyze the effectiveness of different methods like re-ranking and prompting strategies.

**Method:** Our approach combines sparse (BM25) and dense (E5) retrieval methods with a generation model (Falcon3-10B-Instruct) for relevant and faithful answers. We explored neural re-ranking with RankLLaMA and prompting strategies with DSPy.

**Result:** The neural re-ranking method (RankLLaMA) improved MAP by 52%, but at a higher computational cost. DSPy-optimized prompting strategies showed higher semantic similarity but raised concerns about over-confidence.

**Conclusion:** The hybrid system without re-ranking achieved 4th in faithfulness and 11th in correctness among 25 teams. Vocabulary alignment and document-similar phrasing were found to improve performance.

**Abstract:** We present our submission to the LiveRAG Challenge 2025, which evaluates
retrieval-augmented generation (RAG) systems on dynamic test sets using the
FineWeb-10BT corpus. Our final hybrid approach combines sparse (BM25) and dense
(E5) retrieval methods and then aims to generate relevant and faithful answers
with Falcon3-10B-Instruct. Through systematic evaluation on 200 synthetic
questions generated with DataMorgana across 64 unique question-user
combinations, we demonstrate that neural re-ranking with RankLLaMA improves MAP
from 0.523 to 0.797 (52% relative improvement) but introduces prohibitive
computational costs (84s vs 1.74s per question). While DSPy-optimized prompting
strategies achieved higher semantic similarity (0.771 vs 0.668), their 0%
refusal rates raised concerns about over-confidence and generalizability. Our
submitted hybrid system without re-ranking achieved 4th place in faithfulness
and 11th place in correctness among 25 teams. Analysis across question
categories reveals that vocabulary alignment between questions and documents
was the strongest predictor of performance on our development set, with
document-similar phrasing improving cosine similarity from 0.562 to 0.762.

</details>


### [13] [Assessing the feasibility of Large Language Models for detecting micro-behaviors in team interactions during space missions](https://arxiv.org/abs/2506.22679)
*Ankush Raut,Projna Paromita,Sydney Begerowski,Suzanne Bell,Theodora Chaspari*

Main category: cs.CL

> 指令微调后的Llama-3.1在检测团队对话中的微行为方面，尤其是在分类任务中，比encoder-only模型表现更好，为提高空间任务等高风险环境中的沟通训练技术提供了可能。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于探索大规模语言模型在复杂情境下的语言细微差异检测能力，特别是它们在分析团队交流动态时的效果。通过这种方式，可以帮助改善高风险环境中的沟通训练和技术评估。

**Method:** 本研究探讨了大规模语言模型（LLMs）在使用模拟太空任务中收集的对话记录来检测团队对话中微妙的微行为表达的能力。研究中，我们采用了零样本分类、微调以及带有释义增强的微调方法，模型包括encoder-only序列分类的LLMs，以及decoder-only因果语言模型的LLMs，用于预测每个对话回合的微行为。

**Result:** 研究发现，像RoBERTa和DistilBERT这样的encoder-only LLMs在检测代表性不足的微行为，尤其是消极言论方面的效果有限，即使使用了加权微调。相比之下，指令微调后的decoder-only LLM，Llama-3.1版本的性能更优，最佳模型在三类分类中实现了44%的macro F1-score，二元分类则为68%。

**Conclusion:** 这些结果对于旨在分析团队沟通动态和提高高风险环境（如太空任务）中的训练干预措施的语音技术开发具有重要意义，尤其是在文本是唯一可访问数据的场景下。

**Abstract:** We explore the feasibility of large language models (LLMs) in detecting
subtle expressions of micro-behaviors in team conversations using transcripts
collected during simulated space missions. Specifically, we examine zero-shot
classification, fine-tuning, and paraphrase-augmented fine-tuning with
encoder-only sequence classification LLMs, as well as few-shot text generation
with decoder-only causal language modeling LLMs, to predict the micro-behavior
associated with each conversational turn (i.e., dialogue). Our findings
indicate that encoder-only LLMs, such as RoBERTa and DistilBERT, struggled to
detect underrepresented micro-behaviors, particularly discouraging speech, even
with weighted fine-tuning. In contrast, the instruction fine-tuned version of
Llama-3.1, a decoder-only LLM, demonstrated superior performance, with the best
models achieving macro F1-scores of 44% for 3-way classification and 68% for
binary classification. These results have implications for the development of
speech technologies aimed at analyzing team communication dynamics and
enhancing training interventions in high-stakes environments such as space
missions, particularly in scenarios where text is the only accessible data.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [14] [Robust Perspective Correction for Real-World Crack Evolution Tracking in Image-Based Structural Health Monitoring](https://arxiv.org/abs/2506.22437)
*Xinxin Sun,Peter Chang*

Main category: cs.CV

> 本文提出了一个基于物理的图像对准框架，用于结构健康监测中裂缝的精确追踪，解决了传统方法在透视失真、遮挡和低对比度情况下的局限性。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对传统特征检测方法在定位裂缝时的不足，特别是在存在透视失真、遮挡和低对比度的情况下的问题。

**Method:** 通过利用非线性各向异性扩散来构建裂缝保持尺度空间，并结合RANSAC基础的同态估计，该框架能够在不需要训练、参数调整或预先校准的情况下实现准确的几何矫正。

**Result:** 相比经典检测器，所提出的框架在裂缝面积和脊线长度的误差方面分别降低了70%和90%，同时在关键指标的对准误差保持在5%以下。

**Conclusion:** 这项研究提出了一种无监督的、可解释的方法，通过非线性尺度空间模型针对结构健康监测中的图像对准问题，提供了稳健且基于物理的方法来追踪现实世界中的裂缝演变。

**Abstract:** Accurate image alignment is essential for monitoring crack evolution in
structural health monitoring (SHM), particularly under real-world conditions
involving perspective distortion, occlusion, and low contrast. However,
traditional feature detectors such as SIFT and SURF, which rely on
Gaussian-based scale spaces, tend to suppress high-frequency edges, making them
unsuitable for thin crack localization. Lightweight binary alternatives like
ORB and BRISK, while computationally efficient, often suffer from poor keypoint
repeatability on textured or shadowed surfaces. This study presents a
physics-informed alignment framework that adapts the open KAZE architecture to
SHM-specific challenges. By utilizing nonlinear anisotropic diffusion to
construct a crack-preserving scale space, and integrating RANSAC-based
homography estimation, the framework enables accurate geometric correction
without the need for training, parameter tuning, or prior calibration. The
method is validated on time-lapse images of masonry and concrete acquired via
handheld smartphone under varied field conditions, including shadow
interference, cropping, oblique viewing angles, and surface clutter. Compared
to classical detectors, the proposed framework reduces crack area and spine
length errors by up to 70 percent and 90 percent, respectively, while
maintaining sub-5 percent alignment error in key metrics. Unsupervised,
interpretable, and computationally lightweight, this approach supports scalable
deployment via UAVs and mobile platforms. By tailoring nonlinear scale-space
modeling to SHM image alignment, this work offers a robust and physically
grounded alternative to conventional techniques for tracking real-world crack
evolution.

</details>


### [15] [Counting with Confidence: Accurate Pest Monitoring in Water Traps](https://arxiv.org/abs/2506.22438)
*Xumin Gao,Mark Stevens,Grzegorz Cielniak*

Main category: cs.CV

> The paper introduces a method for comprehensive evaluation of pest counting confidence by assessing counting results and environmental factors, leading to improved reliability in automated pest counting for precision agriculture.

<details>
  <summary>Details</summary>

**Motivation:** The study aims to address the common limitation in automatic pest counting where models lack reliability assessment due to the absence of ground truth in real-world scenarios. The method evaluates pest counting confidence based on counting results and external environmental conditions.

**Method:** A pest detection network is used for detection and counting, followed by assessments of image quality, image complexity, and pest distribution uniformity, with an adaptive DBSCAN clustering algorithm proposed for the latter. The information is then input into a regression model to predict pest counting confidence.

**Result:** The method significantly reduces MSE by 31.7% and improves R2 by 15.2% on the pest counting confidence test set compared to a baseline.

**Conclusion:** The study presents an innovative approach to evaluating pest counting confidence with improved accuracy compared to baselines, making a substantial contribution to the field of vision-based pest monitoring by addressing reliability issues.

**Abstract:** Accurate pest population monitoring and tracking their dynamic changes are
crucial for precision agriculture decision-making. A common limitation in
existing vision-based automatic pest counting research is that models are
typically evaluated on datasets with ground truth but deployed in real-world
scenarios without assessing the reliability of counting results due to the lack
of ground truth. To this end, this paper proposed a method for comprehensively
evaluating pest counting confidence in the image, based on information related
to counting results and external environmental conditions. First, a pest
detection network is used for pest detection and counting, extracting counting
result-related information. Then, the pest images undergo image quality
assessment, image complexity assessment, and pest distribution uniformity
assessment. And the changes in image clarity caused by stirring during image
acquisition are quantified by calculating the average gradient magnitude.
Notably, we designed a hypothesis-driven multi-factor sensitivity analysis
method to select the optimal image quality assessment and image complexity
assessment methods. And we proposed an adaptive DBSCAN clustering algorithm for
pest distribution uniformity assessment. Finally, the obtained information
related to counting results and external environmental conditions is input into
a regression model for prediction, resulting in the final pest counting
confidence. To the best of our knowledge, this is the first study dedicated to
comprehensively evaluating counting confidence in counting tasks, and
quantifying the relationship between influencing factors and counting
confidence through a model. Experimental results show our method reduces MSE by
31.7% and improves R2 by 15.2% on the pest counting confidence test set,
compared to the baseline built primarily on information related to counting
results.

</details>


### [16] [Modulated Diffusion: Accelerating Generative Modeling with Modulated Quantization](https://arxiv.org/abs/2506.22463)
*Weizhi Gao,Zhichao Hou,Junqi Yin,Feiyi Wang,Linyu Peng,Xiaorui Liu*

Main category: cs.CV

> 本文提出了MoDiff框架，通过调制量化和误差补偿技术来加速扩散模型，并在多个数据集上验证了其有效性和理论基础。

<details>
  <summary>Details</summary>

**Motivation:** 加速扩散模型的生成过程，解决扩散模型在迭代采样过程中计算成本高的问题。

**Method:** 通过调制量化和误差补偿来加速生成模型的创新、严谨且原理性的框架MoDiff，该框架不仅继承了现有缓存和量化方法的优势，还作为一个通用框架来加速所有扩散模型。

**Result:** MoDiff显著地将激活量化从8位减少到3位，且在后训练量化（PTQ）中没有性能下降，实验在CIFAR-10和LSUN数据集上进行。

**Conclusion:** MoDiff提供了一个加速扩散模型的新方法，通过理论分析和实验验证了其有效性。

**Abstract:** Diffusion models have emerged as powerful generative models, but their high
computation cost in iterative sampling remains a significant bottleneck. In
this work, we present an in-depth and insightful study of state-of-the-art
acceleration techniques for diffusion models, including caching and
quantization, revealing their limitations in computation error and generation
quality. To break these limits, this work introduces Modulated Diffusion
(MoDiff), an innovative, rigorous, and principled framework that accelerates
generative modeling through modulated quantization and error compensation.
MoDiff not only inherents the advantages of existing caching and quantization
methods but also serves as a general framework to accelerate all diffusion
models. The advantages of MoDiff are supported by solid theoretical insight and
analysis. In addition, extensive experiments on CIFAR-10 and LSUN demonstrate
that MoDiff significant reduces activation quantization from 8 bits to 3 bits
without performance degradation in post-training quantization (PTQ). Our code
implementation is available at https://github.com/WeizhiGao/MoDiff.

</details>


### [17] [ViFusionTST: Deep Fusion of Time-Series Image Representations from Load Signals for Early Bed-Exit Prediction](https://arxiv.org/abs/2506.22498)
*Hao Liu,Yu Hu,Rakiba Rayhana,Ling Bai,Zheng Liu*

Main category: cs.CV

> 研究提出了一种使用床腿下的负载传感器并结合可视化数据处理技术来预测早期离床意图的方法，并通过实际数据集验证了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 医院和长期护理机构中床相关跌倒仍是主要伤害来源，然而，许多商用警报只有在病人已经离开床铺后才会触发。

**Method:** 使用安装在床腿下的四个低成本负载细胞来预测早期离床意图。负载信号首先转换成一组紧凑的互补图像：一种保持原始波形的RGB线图和三种纹理图（Recurrence Plot, Markov Transition Field, Gramian Angular Field），这些纹理图揭示了更高阶的动力学。引入了ViFusionTST，一种双流线Swin Transformer，能够并行处理线图和纹理图并通过交叉注意力机制融合它们，以此学习数据驱动的模态权重。

**Result:** 通过一个六个月连续数据收集的护理设施中的95张床的实际世界数据集，ViFusionTST在准确率（0.885），F1分数（0.794），以及F1，召回率，准确率和AUPRC等多项指标上，超过了最近的1D和2D时间序列基准。

**Conclusion:** 基于融合负载传感器信号的图像处理手段用于时间序列分类是一种为实时、保护隐私的跌倒预防实践提供了切实可行且有效的解决方案。

**Abstract:** Bed-related falls remain a leading source of injury in hospitals and
long-term-care facilities, yet many commercial alarms trigger only after a
patient has already left the bed. We show that early bed-exit intent can be
predicted using only four low-cost load cells mounted under the bed legs. The
resulting load signals are first converted into a compact set of complementary
images: an RGB line plot that preserves raw waveforms and three texture maps -
recurrence plot, Markov transition field, and Gramian angular field - that
expose higher-order dynamics. We introduce ViFusionTST, a dual-stream Swin
Transformer that processes the line plot and texture maps in parallel and fuses
them through cross-attention to learn data-driven modality weights.
  To provide a realistic benchmark, we collected six months of continuous data
from 95 beds in a long-term-care facility. On this real-world dataset
ViFusionTST reaches an accuracy of 0.885 and an F1 score of 0.794, surpassing
recent 1D and 2D time-series baselines across F1, recall, accuracy, and AUPRC.
The results demonstrate that image-based fusion of load-sensor signals for time
series classification is a practical and effective solution for real-time,
privacy-preserving fall prevention.

</details>


### [18] [Scalable Dynamic Origin-Destination Demand Estimation Enhanced by High-Resolution Satellite Imagery Data](https://arxiv.org/abs/2506.22499)
*Jiachao Liu,Pablo Guarda,Koichiro Niinuma,Sean Qian*

Main category: cs.CV

> 一种新的DODE框架通过融合高分辨率卫星影像与传统交通数据，提升了动态交通流密度的估计精度，具有在实际城市交通中部署的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在通过使用连续的、城市范围内的道路和交通信息，即在停车和移动车辆中，克服传统数据来源（如稀疏的本地探测器）的数据可用性限制。

**Method:** 本研究提出了一种新颖的集成框架，用于多类中观网络模型的动态起讫需求估计（DODE），结合高分辨率卫星影像和来自本地传感器的传统交通数据。该框架设计了一个计算机视觉管道来检测特定类别的车辆及对应的地图匹配，从而生成按车辆类别划分的链路级交通密度观测。再此基础上，我们建立了一个基于计算图的DODE模型，通过联合匹配来自本地传感器的观测交通流量和旅行时间以及从卫星影像派生的密度测量来校准动态网络状态。

**Result:** 通过使用合成和真实世界的数据进行一系列数值实验，结果表明，与传统数据结合卫星衍生的密度测量显著提高了估计性能，尤其是没有本地传感器的链路。通过对大型网络的实际实验也证明了该框架的实用性，支持其在不同大小城市中的实际部署。

**Conclusion:** 敏感性分析进一步评估了与卫星影像数据相关数据质量的影响，证实了该框架在动态OD需求估计中的稳定性和有效性。

**Abstract:** This study presents a novel integrated framework for dynamic
origin-destination demand estimation (DODE) in multi-class mesoscopic network
models, leveraging high-resolution satellite imagery together with conventional
traffic data from local sensors. Unlike sparse local detectors, satellite
imagery offers consistent, city-wide road and traffic information of both
parking and moving vehicles, overcoming data availability limitations. To
extract information from imagery data, we design a computer vision pipeline for
class-specific vehicle detection and map matching, generating link-level
traffic density observations by vehicle class. Building upon this information,
we formulate a computational graph-based DODE model that calibrates dynamic
network states by jointly matching observed traffic counts and travel times
from local sensors with density measurements derived from satellite imagery. To
assess the accuracy and scalability of the proposed framework, we conduct a
series of numerical experiments using both synthetic and real-world data. The
results of out-of-sample tests demonstrate that supplementing traditional data
with satellite-derived density significantly improves estimation performance,
especially for links without local sensors. Real-world experiments also confirm
the framework's capability to handle large-scale networks, supporting its
potential for practical deployment in cities of varying sizes. Sensitivity
analysis further evaluates the impact of data quality related to satellite
imagery data.

</details>


### [19] [Visual-Semantic Knowledge Conflicts in Operating Rooms: Synthetic Data Curation for Surgical Risk Perception in Multimodal Large Language Models](https://arxiv.org/abs/2506.22500)
*Weiyi Zhao,Xiaoyu Tan,Liang Liu,Sijia Li,Youwei Song,Xihe Qiu*

Main category: cs.CV

> 研究引入了一个包含超过34,000张合成图像的手术室风险识别数据集，用以测试大型多模态语言模型在识别视觉安全违规方面的性能。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对大型多模态语言模型中存在的视觉-语义知识冲突问题，该数据集旨在缓解数据稀缺问题，并测试这些模型的脆弱性。

**Method:** 引进了一个包含超过34,000张合成图像的数据集，这些图像是通过扩散模型生成的，描绘了包含违反既定安全规则实体的手术室场景。除了合成图像，数据集还包括了214张人工标注的图像作为验证的标准参考。

**Result:** 对OR-VSKC数据集进行微调显著提高了多模态大型语言模型对训练冲突实体的检测，但对未训练实体类型的性能仍然不佳。

**Conclusion:** 这项工作的主要贡献包括：1）为规则违规场景设计的数据生成方法；2）发布作为开放资源的OR-VSKC数据集及其相关基准；3）对代表性多模态大型语言模型的违规敏感知识一致性进行实证分析。

**Abstract:** Surgical risk identification is critical for patient safety and reducing
preventable medical errors. While multimodal large language models (MLLMs) show
promise for automated operating room (OR) risk detection, they often exhibit
visual-semantic knowledge conflicts (VS-KC), failing to identify visual safety
violations despite understanding textual rules. To address this, we introduce a
dataset comprising over 34,000 synthetic images generated by diffusion models,
depicting operating room scenes containing entities that violate established
safety rules. These images were created to alleviate data scarcity and examine
MLLMs vulnerabilities. In addition, the dataset includes 214 human-annotated
images that serve as a gold-standard reference for validation. This
comprehensive dataset, spanning diverse perspectives, stages, and
configurations, is designed to expose and study VS-KC. Fine-tuning on OR-VSKC
significantly improves MLLMs' detection of trained conflict entities and
generalizes well to new viewpoints for these entities, but performance on
untrained entity types remains poor, highlighting learning specificity and the
need for comprehensive training. The main contributions of this work include:
(1) a data generation methodology tailored for rule-violation scenarios; (2)
the release of the OR-VSKC dataset and its associated benchmark as open-source
resources; and (3) an empirical analysis of violation-sensitive knowledge
consistency in representative MLLMs. The dataset and appendix are available at
https://github.com/zgg2577/VS-KC.

</details>


### [20] [How Can Multimodal Remote Sensing Datasets Transform Classification via SpatialNet-ViT?](https://arxiv.org/abs/2506.22501)
*Gautam Siddharth Kashyap,Manaswi Kulahara,Nipun Joshi,Usman Naseem*

Main category: cs.CV

> 本文提出了SpatialNet-ViT模型，结合Vision Transformers和多任务学习，提升了遥感图像分类的准确性和普适性，通过数据增强、迁移学习等技术增强了模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 当前许多研究集中在狭窄的任务或数据集上，这限制了它们在遥感分类任务上的泛化能力。本文旨在提出一个既能提高分类准确性又能增强泛化能力的新模型。

**Method:** 本文采用了SpatialNet-ViT模型，该模型结合了Vision Transformers和多任务学习，还使用了数据增强、迁移学习等技术来提高模型的鲁棒性和泛化能力。

**Result:** 本文提出的新模型增强了遥感大数据集上分类任务的准确性和可扩展性，并提高了模型的泛化能力。

**Conclusion:** SpatialNet-ViT模型在遥感图像分类任务中展示了其在准确性和泛化能力上的优势，突出了其作为多任务学习和Vision Transformer的方法的应用潜力。

**Abstract:** Remote sensing datasets offer significant promise for tackling key
classification tasks such as land-use categorization, object presence
detection, and rural/urban classification. However, many existing studies tend
to focus on narrow tasks or datasets, which limits their ability to generalize
across various remote sensing classification challenges. To overcome this, we
propose a novel model, SpatialNet-ViT, leveraging the power of Vision
Transformers (ViTs) and Multi-Task Learning (MTL). This integrated approach
combines spatial awareness with contextual understanding, improving both
classification accuracy and scalability. Additionally, techniques like data
augmentation, transfer learning, and multi-task learning are employed to
enhance model robustness and its ability to generalize across diverse datasets

</details>


### [21] [What Makes a Dribble Successful? Insights From 3D Pose Tracking Data](https://arxiv.org/abs/2506.22503)
*Michiel Schepers,Pieter Robberechts,Jan Van Haaren,Jesse Davis*

Main category: cs.CV

> 本研究利用三维姿态跟踪数据来改进带球突破成功的预测模型，增加了描述攻击者平衡和进攻-防守者方向对齐特征，改进了模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于先前的研究主要依赖于2D位置跟踪数据，缺乏对平衡、方向和控球等关键因素的捕捉，限制了现有洞察的深度，因此本研究旨在探索姿势跟踪数据（捕捉球员在三维空间中的姿态和运动）如何提高我们对带球突破技能的理解。

**Method:** 本研究通过从2022/23赛季冠军联赛的1,736次带球突破中提取基于姿态的新特征，来评估这些特征对带球突破成功的预测能力。

**Result:** 研究结果表明，捕捉攻击者平衡和攻击者与防守者方向对齐的特征对预测带球成功是有信息量的。在传统2D位置数据特征之上加入这些基于姿态的特征，对模型性能的提升是可观的。

**Conclusion:** 本研究证明了三维姿态数据在增强带球突破分析中的价值，提供了一种改进分析性能的方法，为评估带球技能提供了新的视角。

**Abstract:** Data analysis plays an increasingly important role in soccer, offering new
ways to evaluate individual and team performance. One specific application is
the evaluation of dribbles: one-on-one situations where an attacker attempts to
bypass a defender with the ball. While previous research has primarily relied
on 2D positional tracking data, this fails to capture aspects like balance,
orientation, and ball control, limiting the depth of current insights. This
study explores how pose tracking data (capturing players' posture and movement
in three dimensions) can improve our understanding of dribbling skills. We
extract novel pose-based features from 1,736 dribbles in the 2022/23 Champions
League season and evaluate their impact on dribble success. Our results
indicate that features capturing the attacker's balance and the alignment of
the orientation between the attacker and defender are informative for
predicting dribble success. Incorporating these pose-based features on top of
features derived from traditional 2D positional data leads to a measurable
improvement in model performance.

</details>


### [22] [Patch2Loc: Learning to Localize Patches for Unsupervised Brain Lesion Detection](https://arxiv.org/abs/2506.22504)
*Hassan Baker,Austin J. Brockmeier*

Main category: cs.CV

> 本论文提出了一种无监督的学习方法，用于MRI中异常脑组织的检测。通过生成热图，Patch2Loc模型可以辅助放射科医生更精细地分割和检测异常区域。

<details>
  <summary>Details</summary>

**Motivation:** 在脑部MRI中检测脑部病变对于诊断和治疗至关重要，为了帮助放射科医生找出诸如肿瘤和畸形等异常，我们探索了无监督学习方法在脑部MRI异常检测中的应用。

**Method:** 我们提出了一种新的无监督方法（Patch2Loc），它从结构MRI的正常补丁中学习。我们的模型训练了一个神经网络，将补丁映射回其在大脑体积切片中的空间位置。在推理过程中，通过位置预测的相对较高误差和/或方差来检测异常补丁，从而生成热图。

**Result:** 我们在BraTS2021和MSLUB数据集上的T2加权图像和ATLAS及WMH数据集上的T1加权图像中验证了该模型的异常脑组织分割能力，并证明它在无监督分割方面优于当前最优的方法。

**Conclusion:** 实验结果表明，我们的Patch2Loc方法在无监督的脑部异常组织分割任务中超越了现有的最先进的技术。这为进一步研究医学影像中无监督学习方法的应用打下了基础。

**Abstract:** Detecting brain lesions as abnormalities observed in magnetic resonance
imaging (MRI) is essential for diagnosis and treatment. In the search of
abnormalities, such as tumors and malformations, radiologists may benefit from
computer-aided diagnostics that use computer vision systems trained with
machine learning to segment normal tissue from abnormal brain tissue. While
supervised learning methods require annotated lesions, we propose a new
unsupervised approach (Patch2Loc) that learns from normal patches taken from
structural MRI. We train a neural network model to map a patch back to its
spatial location within a slice of the brain volume. During inference, abnormal
patches are detected by the relatively higher error and/or variance of the
location prediction. This generates a heatmap that can be integrated into
pixel-wise methods to achieve finer-grained segmentation. We demonstrate the
ability of our model to segment abnormal brain tissues by applying our approach
to the detection of tumor tissues in MRI on T2-weighted images from BraTS2021
and MSLUB datasets and T1-weighted images from ATLAS and WMH datasets. We show
that it outperforms the state-of-the art in unsupervised segmentation. The
codebase for this work can be found on our
\href{https://github.com/bakerhassan/Patch2Loc}{GitHub page}.

</details>


### [23] [Weakly Supervised Object Segmentation by Background Conditional Divergence](https://arxiv.org/abs/2506.22505)
*Hassan Baker,Matthew S. Emigh,Austin J. Brockmeier*

Main category: cs.CV

> 研究开发了一种新的自我监督物体分割技术，能够在没有大量标记数据的情况下工作，通过使用背景图像聚类和物体重定位技术提高分割效果。

<details>
  <summary>Details</summary>

**Motivation:** 自动物体分割在缺乏大量标注数据的领域中依然充满挑战，例如合成孔径声纳图像等。手动或自动地标记整像素的分割蒙版成本很高。

**Method:** 本研究提出了一种使用弱监督学习的掩码网络训练方法来进行二值化物体分割。关键步骤是将分割出来的物体放置在只有背景的图像中，以创建具有反事实背景的现实图像。研究提出了通过聚类算法将只有背景的图像分组，并且在学习过程中将物体重置到选定的聚类背景中，以产生对比图像。训练损失包括反事实图像与目标聚类背景图像的差异以及针对只有背景图像的监督损失。

**Result:** 实验结果显示在侧扫声纳和合成孔径声纳数据集上，该方法超过了之前在自然图像上测试的无监督分割基线方法。此外，该方法在自然图像上也表现出了良好的性能。

**Conclusion:** 该方法在无需使用预训练网络、生成模型或对抗性判别器的情况下，于多个图像域上展示出了良好的性能。

**Abstract:** As a computer vision task, automatic object segmentation remains challenging
in specialized image domains without massive labeled data, such as synthetic
aperture sonar images, remote sensing, biomedical imaging, etc. In any domain,
obtaining pixel-wise segmentation masks is expensive. In this work, we propose
a method for training a masking network to perform binary object segmentation
using weak supervision in the form of image-wise presence or absence of an
object of interest, which provides less information but may be obtained more
quickly from manual or automatic labeling. A key step in our method is that the
segmented objects can be placed into background-only images to create
realistic, images of the objects with counterfactual backgrounds. To create a
contrast between the original and counterfactual background images, we propose
to first cluster the background-only images, and then during learning create
counterfactual images that blend objects segmented from their original source
backgrounds to backgrounds chosen from a targeted cluster. One term in the
training loss is the divergence between these counterfactual images and the
real object images with backgrounds of the target cluster. The other term is a
supervised loss for background-only images. While an adversarial critic could
provide the divergence, we use sample-based divergences. We conduct experiments
on side-scan and synthetic aperture sonar in which our approach succeeds
compared to previous unsupervised segmentation baselines that were only tested
on natural images. Furthermore, to show generality we extend our experiments to
natural images, obtaining reasonable performance with our method that avoids
pretrained networks, generative networks, and adversarial critics. The basecode
for this work can be found at
\href{GitHub}{https://github.com/bakerhassan/WSOS}.

</details>


### [24] [FreeDNA: Endowing Domain Adaptation of Diffusion-Based Dense Prediction with Training-Free Domain Noise Alignment](https://arxiv.org/abs/2506.22509)
*Hang Xu,Jie Huang,Linjiang Huang,Dong Li,Yidi Liu,Feng Zhao*

Main category: cs.CV

> 提出无训练的DNA方法，通过调整噪声统计量实现DDP模型的领域适应，适用于多种密集预测任务。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型中的噪声统计偏差会导致领域偏移，而噪声预测统计量能有效捕捉不同领域的信息，因此提出DNA方法以增强DDP模型的领域适应能力。

**Method:** 提出无训练的DNA方法，通过调整噪声统计量解决领域适应问题，对于源领域可用的场景直接对齐噪声统计量，对于无源领域场景使用高置信区域的统计量指导噪声调整。

**Result:** 该论文提出了一个无训练的Domain Noise Alignment (DNA) 方法，用于增强Diffusion-based Dense Prediction (DDP) 模型的领域适应能力。该方法通过调整噪声统计量来应对不同领域的变化，适用于源领域可用和无源领域的场景。实验表明该方法在四个常见的密集预测任务中有效。

**Conclusion:** 实验表明，该无训练的方法能够有效地改善DDP模型在四种常见密集预测任务中的领域适应能力。

**Abstract:** Domain Adaptation(DA) for dense prediction tasks is an important topic, which
enhances the dense prediction model's performance when tested on its unseen
domain. Recently, with the development of Diffusion-based Dense Prediction
(DDP) models, the exploration of DA designs tailored to this framework is worth
exploring, since the diffusion model is effective in modeling the distribution
transformation that comprises domain information. In this work, we propose a
training-free mechanism for DDP frameworks, endowing them with DA capabilities.
Our motivation arises from the observation that the exposure bias (e.g., noise
statistics bias) in diffusion brings domain shift, and different domains in
conditions of DDP models can also be effectively captured by the noise
prediction statistics. Based on this, we propose a training-free Domain Noise
Alignment (DNA) approach, which alleviates the variations of noise statistics
to domain changes during the diffusion sampling process, thereby achieving
domain adaptation. Specifically, when the source domain is available, we
directly adopt the DNA method to achieve domain adaptation by aligning the
noise statistics of the target domain with those of the source domain. For the
more challenging source-free DA, inspired by the observation that regions
closer to the source domain exhibit higher confidence meeting variations of
sampling noise, we utilize the statistics from the high-confidence regions
progressively to guide the noise statistic adjustment during the sampling
process. Notably, our method demonstrates the effectiveness of enhancing the DA
capability of DDP models across four common dense prediction tasks. Code is
available at
\href{https://github.com/xuhang07/FreeDNA}{https://github.com/xuhang07/FreeDNA}.

</details>


### [25] [Lightning the Night with Generative Artificial Intelligence](https://arxiv.org/abs/2506.22511)
*Tingting Zhou,Feng Zhang,Haoyang Fu,Baoxiang Pan,Renhe Zhang,Feng Lu,Zhixin Yang*

Main category: cs.CV

> 研究开发了名为Reflectance Diffusion (RefDiff) 的可见光反射率检索模型，利用多波段热红外亮度温度数据在夜间实现可见光反射率的检索，提高了气象观测的连续性和准确性。

<details>
  <summary>Details</summary>

**Motivation:** 由于夜间缺乏可见光，使用可见光反射率数据进行全天候气象观测是不可能的。这项研究旨在利用生成扩散模型解决这一问题。

**Method:** 基于FY4B星载AGRI的多波段热红外亮度温度数据，开发高精度的可见光反射率检索模型RefDiff。

**Result:** 与经典模型相比，RefDiff不仅通过集成平均显著提高准确性，还提供了不确定性估计，在云结构复杂和厚云区域的性能有显著改善。

**Conclusion:** 研究在夜间可见光反射率检索能力上取得了实质性的进展，有潜力扩大夜间可见光数据的应用。

**Abstract:** The visible light reflectance data from geostationary satellites is crucial
for meteorological observations and plays an important role in weather
monitoring and forecasting. However, due to the lack of visible light at night,
it is impossible to conduct continuous all-day weather observations using
visible light reflectance data. This study pioneers the use of generative
diffusion models to address this limitation. Based on the multi-band thermal
infrared brightness temperature data from the Advanced Geostationary Radiation
Imager (AGRI) onboard the Fengyun-4B (FY4B) geostationary satellite, we
developed a high-precision visible light reflectance retrieval model, called
Reflectance Diffusion (RefDiff), which enables 0.47~\mu\mathrm{m},
0.65~\mu\mathrm{m}, and 0.825~\mu\mathrm{m} bands visible light reflectance
retrieval at night. Compared to the classical models, RefDiff not only
significantly improves accuracy through ensemble averaging but also provides
uncertainty estimation. Specifically, the SSIM index of RefDiff can reach 0.90,
with particularly significant improvements in areas with complex cloud
structures and thick clouds. The model's nighttime retrieval capability was
validated using VIIRS nighttime product, demonstrating comparable performance
to its daytime counterpart. In summary, this research has made substantial
progress in the ability to retrieve visible light reflectance at night, with
the potential to expand the application of nighttime visible light data.

</details>


### [26] [Automated Defect Identification and Categorization in NDE 4.0 with the Application of Artificial Intelligence](https://arxiv.org/abs/2506.22513)
*Aditya Sharma*

Main category: cs.CV

> 该研究提出了一种用于当代无损检测的自动化故障检测和组织框架。使用改进的U-net模型和增强数据集，研究展示了出色的故障检测能力和处理大型图像的高效性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的目标是解决当代无损检测（NDE）中信息描述不足的问题，探索如何最大限度地利用虚拟缺陷增强，并验证该框架的可行性。

**Method:** 此研究使用了一种增强数据集并应用改进的U-net模型的方法来实现语义缺陷分割。原始数据集由223张CR照片组成，这些照片通过虚拟缺陷增强和标准增强进行处理。

**Result:** 研究结果表明，所提议的方法在缺陷检测方面表现出色。特别是在90/95特性上，综合增强方法显示出明显的优势。此外，由于框架的推导速度快，可以高效快速地处理大型图像。

**Conclusion:** 专业评估者认为，该系统可以在检测周期中作为辅助设备，不受特定设备的截止点和编程相似性的影响，是一个值得信赖的支持工具。

**Abstract:** This investigation attempts to create an automated framework for fault
detection and organization for usage in contemporary radiography, as per NDE
4.0. The review's goals are to address the lack of information that is
sufficiently explained, learn how to make the most of virtual defect increase,
and determine whether the framework is viable by using NDE measurements. As its
basic information source, the technique consists of compiling and categorizing
223 CR photographs of airplane welds. Information expansion systems, such as
virtual defect increase and standard increase, are used to work on the
preparation dataset. A modified U-net model is prepared using the improved data
to produce semantic fault division veils. To assess the effectiveness of the
model, NDE boundaries such as Case, estimating exactness, and misleading call
rate are used. Tiny a90/95 characteristics, which provide strong
differentiating evidence of flaws, reveal that the suggested approach achieves
exceptional awareness in defect detection. Considering a 90/95, size error, and
fake call rate in the weld area, the consolidated expansion approach clearly
wins. Due to the framework's fast derivation speed, large images can be broken
down efficiently and quickly. Professional controllers evaluate the transmitted
system in the field and believe that it has a guarantee as a support device in
the testing cycle, irrespective of particular equipment cut-off points and
programming resemblance.

</details>


### [27] [Container damage detection using advanced computer vision model Yolov12 vs Yolov11 vs RF-DETR A comparative analysis](https://arxiv.org/abs/2506.22517)
*Subhadip Kumar*

Main category: cs.CV

> 這篇論文通過.setYolov11、Yolov12和RF-DETR比較了先進電腦視覺模型在損壞貨櫃檢測上的效能，發現雖然Yolov11和12在常規損壞貨櫃的mAP@50比較中表現略勝一籌，但RF-DETR在較少見的損壞類型中檢測效果更加優越。

<details>
  <summary>Details</summary>

**Motivation:** 隨著時間的推移，貨櫃會受到機械和自然因素的損害，這既會對處理貨櫃的員工構成安全隱患，也是物流公司的一種責任。因此，及時檢測到損壞貨櫃對於延長貨櫃使用壽命和避免安全風險至關重要。

**Method:** 本研究使用了三種先進的電腦視覺模型：Yolov12、Yolov11和RF-DETR來進行損壞貨櫃的檢測。使用了包含278張標註圖片的數據集進行模型的訓練、驗證和測試。

**Result:** 研究結果顯示，Yolov11和Yolov12在mAP@50上的評分為81.9%，而RF-DETR為77.7%。然而，在測試較不常見的損壞貨櫃時，RF-DETR表現最佳，能夠更準確地檢測出損壞貨櫃和損壞發生的情況。

**Conclusion:** 通過比較三種狀態-of-the-art先進電腦視覺模型，該論文得出RF-DETR在檢測較不常見的損壞類型時表現最佳，但對於常見的損壞檢測，Yolov11和12依然有較高的準確性。

**Abstract:** Containers are an integral part of the logistics industry and act as a
barrier for cargo. A typical service life for a container is more than 20
years. However, overtime containers suffer various types of damage due to the
mechanical as well as natural factors. A damaged container is a safety hazard
for the employees handling it and a liability for the logistic company.
Therefore, a timely inspection and detection of the damaged container is a key
for prolonging service life as well as avoiding safety hazards. In this paper,
we will compare the performance of the damage detection by three
state-of-the-art advanced computer vision models Yolov12, Yolov11 and RF-DETR.
We will use a dataset of 278 annotated images to train, validate and test the
model. We will compare the mAP and precision of the model. The objective of
this paper is to identify the model that is best suited for container damage
detection. The result is mixed. mAP@50 score of Yolov11 and 12 was 81.9%
compared to RF-DETR, which was 77.7%. However, while testing the model for
not-so-common damaged containers, the RF-DETR model outperformed the others
overall, exhibiting superiority to accurately detecting both damaged containers
as well as damage occurrences with high confidence.

</details>


### [28] [Preserve Anything: Controllable Image Synthesis with Object Preservation](https://arxiv.org/abs/2506.22531)
*Prasen Kumar Sharma,Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.CV

> 介绍了一种新的图像生成方法Preserve Anything，它通过N通道ControlNet结构优化了对象保留率、背景的语义一致性和用户对场景的控制能力。

<details>
  <summary>Details</summary>

**Motivation:** 当前的文本到图像生成方法在保持多个对象的准确性、维持与提示的语义一致性以及提供场景组成方面的显式控制方面存在局限性。

**Method:** 该研究提出了一种名为\textit{Preserve Anything}的新方法，用于解决文本到图像生成中的对象保留和语义一致性问题。该方法通过使用N通道ControlNet来处理对象保留，背景一致性以及用户对背景布局和光照条件的显式控制。

**Result:** 该方法在特征空间保真度（FID 15.26）和语义一致性（CLIP-S 32.85）方面取得显著提升，并通过用户研究证实了在提示一致性、增强现实性、减少AI生成误差和提升自然美观度等方面的显著改进。

**Conclusion:** 该研究通过提出Preserve Anything方法和引入新的基准数据集，显著提升了文本到图像生成的效果，特别是在处理多个对象的保留、维持语义一致性以及场景布局的控制方面，取得了与用户需求相符的改善。

**Abstract:** We introduce \textit{Preserve Anything}, a novel method for controlled image
synthesis that addresses key limitations in object preservation and semantic
consistency in text-to-image (T2I) generation. Existing approaches often fail
(i) to preserve multiple objects with fidelity, (ii) maintain semantic
alignment with prompts, or (iii) provide explicit control over scene
composition. To overcome these challenges, the proposed method employs an
N-channel ControlNet that integrates (i) object preservation with size and
placement agnosticism, color and detail retention, and artifact elimination,
(ii) high-resolution, semantically consistent backgrounds with accurate
shadows, lighting, and prompt adherence, and (iii) explicit user control over
background layouts and lighting conditions. Key components of our framework
include object preservation and background guidance modules, enforcing lighting
consistency and a high-frequency overlay module to retain fine details while
mitigating unwanted artifacts. We introduce a benchmark dataset consisting of
240K natural images filtered for aesthetic quality and 18K 3D-rendered
synthetic images with metadata such as lighting, camera angles, and object
relationships. This dataset addresses the deficiencies of existing benchmarks
and allows a complete evaluation. Empirical results demonstrate that our method
achieves state-of-the-art performance, significantly improving feature-space
fidelity (FID 15.26) and semantic alignment (CLIP-S 32.85) while maintaining
competitive aesthetic quality. We also conducted a user study to demonstrate
the efficacy of the proposed work on unseen benchmark and observed a remarkable
improvement of $\sim25\%$, $\sim19\%$, $\sim13\%$, and $\sim14\%$ in terms of
prompt alignment, photorealism, the presence of AI artifacts, and natural
aesthetics over existing works.

</details>


### [29] [Seamless Interaction: Dyadic Audiovisual Motion Modeling and Large-Scale Dataset](https://arxiv.org/abs/2506.22554)
*Vasu Agrawal,Akinniyi Akinyemi,Kathryn Alvero,Morteza Behrooz,Julia Buffalini,Fabio Maria Carlucci,Joy Chen,Junming Chen,Zhang Chen,Shiyang Cheng,Praveen Chowdary,Joe Chuang,Antony D'Avirro,Jon Daly,Ning Dong,Mark Duppenthaler,Cynthia Gao,Jeff Girard,Martin Gleize,Sahir Gomez,Hongyu Gong,Srivathsan Govindarajan,Brandon Han,Sen He,Denise Hernandez,Yordan Hristov,Rongjie Huang,Hirofumi Inaguma,Somya Jain,Raj Janardhan,Qingyao Jia,Christopher Klaiber,Dejan Kovachev,Moneish Kumar,Hang Li,Yilei Li,Pavel Litvin,Wei Liu,Guangyao Ma,Jing Ma,Martin Ma,Xutai Ma,Lucas Mantovani,Sagar Miglani,Sreyas Mohan,Louis-Philippe Morency,Evonne Ng,Kam-Woh Ng,Tu Anh Nguyen,Amia Oberai,Benjamin Peloquin,Juan Pino,Jovan Popovic,Omid Poursaeed,Fabian Prada,Alice Rakotoarison,Alexander Richard,Christophe Ropers,Safiyyah Saleem,Vasu Sharma,Alex Shcherbyna,Jia Shen,Jie Shen,Anastasis Stathopoulos,Anna Sun,Paden Tomasello,Tuan Tran,Arina Turkatenko,Bo Wan,Chao Wang,Jeff Wang,Mary Williamson,Carleigh Wood,Tao Xiang,Yilin Yang,Julien Yao,Chen Zhang,Jiemin Zhang,Xinyue Zhang,Jason Zheng,Pavlo Zhyzheria,Jan Zikes,Michael Zollhoefer*

Main category: cs.CV

> 研究提出了Seamless Interaction Dataset，用于开发能够理解并生成双向行为动态的AI模型，提高了虚拟代理和多模态内容分析工具的性能。模型通过输入言语和视觉行为生成匹配的手势和面部表情，并可调整情绪和表现水平以生成更具语义的手势。这些进展展示了人机交互更直观响应性的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发社会智能的AI技术，需要创建能够理解并生成双向行为动态的模型。当前研究旨在通过提供大量的互动数据来促进虚拟代理、远程存在体验和多模态内容分析工具的开发。

**Method:** 构建大规模面部对面互动数据集Seamless Interaction Dataset，包含超过4,000小时的互动视频，以开发理解双向动态的AI技术。开发了一套模型，这些模型能够根据输入的言语和视觉行为生成双向动作手势和面部表情。模型还集成了2D和3D渲染方法，并能控制情绪反应和表现水平以生成更具语义相关性的手势。同时还讨论了用于评估模型质量的方法。

**Result:** 开发了一种利用Seamless Interaction Dataset的模型套件，以生成与人类言语相匹配的双向动态手势和面部表情。这些模型能够接收对方的言语和视觉行为作为输入。此外，这些模型还能够适应情绪反应和表现水平，生成更语义相关的手势。这些研究展示了对于更有直观性和响应性的AI人际交互的潜力。

**Conclusion:** 通过构建详细的双向互动数据集Seamless Interaction Dataset，该研究为开发更具直观性和响应性的AI技术奠定了基础。开发的模型可以生成与言语匹配的手势和面部表情，增强了人机交互的体验。

**Abstract:** Human communication involves a complex interplay of verbal and nonverbal
signals, essential for conveying meaning and achieving interpersonal goals. To
develop socially intelligent AI technologies, it is crucial to develop models
that can both comprehend and generate dyadic behavioral dynamics. To this end,
we introduce the Seamless Interaction Dataset, a large-scale collection of over
4,000 hours of face-to-face interaction footage from over 4,000 participants in
diverse contexts. This dataset enables the development of AI technologies that
understand dyadic embodied dynamics, unlocking breakthroughs in virtual agents,
telepresence experiences, and multimodal content analysis tools. We also
develop a suite of models that utilize the dataset to generate dyadic motion
gestures and facial expressions aligned with human speech. These models can
take as input both the speech and visual behavior of their interlocutors. We
present a variant with speech from an LLM model and integrations with 2D and 3D
rendering methods, bringing us closer to interactive virtual agents.
Additionally, we describe controllable variants of our motion models that can
adapt emotional responses and expressivity levels, as well as generating more
semantically-relevant gestures. Finally, we discuss methods for assessing the
quality of these dyadic motion models, which are demonstrating the potential
for more intuitive and responsive human-AI interactions.

</details>
