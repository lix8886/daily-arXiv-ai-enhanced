{"id": "2509.07998", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07998", "abs": "https://arxiv.org/abs/2509.07998", "authors": ["Mesay Gemeda Yigezu", "Girma Yohannis Bade", "Atnafu Lambebo Tonja", "Olga Kolesnikova", "Grigori Sidorov", "Alexander Gelbukh"], "title": "Bilingual Word Level Language Identification for Omotic Languages", "comment": null, "summary": "Language identification is the task of determining the languages for a given\ntext. In many real world scenarios, text may contain more than one language,\nparticularly in multilingual communities. Bilingual Language Identification\n(BLID) is the task of identifying and distinguishing between two languages in a\ngiven text. This paper presents BLID for languages spoken in the southern part\nof Ethiopia, namely Wolaita and Gofa. The presence of words similarities and\ndifferences between the two languages makes the language identification task\nchallenging. To overcome this challenge, we employed various experiments on\nvarious approaches. Then, the combination of the BERT based pretrained language\nmodel and LSTM approach performed better, with an F1 score of 0.72 on the test\nset. As a result, the work will be effective in tackling unwanted social media\nissues and providing a foundation for further research in this area.", "AI": {"tldr": "本研究解决了埃塞俄比亚南部Wolaita和Gofa语言的双语语言识别问题，通过使用BERT结合LSTM的方法在测试集中获得了0.72的F1分数，可用于解决社交媒体中的不良问题，并为进一步研究提供基础。", "motivation": "解决在埃塞俄比亚南部使用的Wolaita和Gofa语言中存在的词汇相似性和差异性所带来的语言识别挑战。", "method": "采用了基于BERT的预训练语言模型和LSTM方法的组合。", "result": "在测试集上获得了0.72的F1分数。", "conclusion": "有助于解决社交媒体中的不良问题，并为这一领域的进一步研究奠定基础。"}}
{"id": "2509.08000", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08000", "abs": "https://arxiv.org/abs/2509.08000", "authors": ["Debdeep Sanyal", "Manodeep Ray", "Murari Mandal"], "title": "AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs", "comment": "19 pages", "summary": "The release of open-weight large language models (LLMs) creates a tension\nbetween advancing accessible research and preventing misuse, such as malicious\nfine-tuning to elicit harmful content. Current safety measures struggle to\npreserve the general capabilities of the LLM while resisting a determined\nadversary with full access to the model's weights and architecture, who can use\nfull-parameter fine-tuning to erase existing safeguards. To address this, we\nintroduce AntiDote, a bi-level optimization procedure for training LLMs to be\nresistant to such tampering. AntiDote involves an auxiliary adversary\nhypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)\nweights conditioned on the defender model's internal activations. The defender\nLLM is then trained with an objective to nullify the effect of these\nadversarial weight additions, forcing it to maintain its safety alignment. We\nvalidate this approach against a diverse suite of 52 red-teaming attacks,\nincluding jailbreak prompting, latent space manipulation, and direct\nweight-space attacks. AntiDote is upto 27.4\\% more robust against adversarial\nattacks compared to both tamper-resistance and unlearning baselines. Crucially,\nthis robustness is achieved with a minimal trade-off in utility, incurring a\nperformance degradation of upto less than 0.5\\% across capability benchmarks\nincluding MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute\nefficient methodology for building open-weight models where safety is a more\nintegral and resilient property.", "AI": {"tldr": "本文提出了AntiDote方法，通过对抗训练来增强大语言模型的安全性，使其更难以被篡改，且性能下降不超过0.5%。", "motivation": "当前的安全措施在保护LLM的一般能力的同时抵抗完全接触到模型权重和架构的坚定对手方面存在困难，这些对手可以通过全参数微调来消除现有防护。为解决这个问题，我们提出了AntiDote。", "method": "我们提出了AntiDote，这是一种双向优化程序，用于训练LLM以对抗此类篡改。AntiDote包含一个辅助对手超网络，该网络学习生成基于防守模型内部激活的恶意低秩适配(LoRA)权重。防守LLM则通过一种目标训练法以消除这些对抗权重增加的影响，使其保持安全对齐。", "result": "我们用52种红队攻击，包括越狱提示、潜在空间操纵和直接权重空间攻击进行了验证。与篡改抵抗和遗忘基线相比，AntiDote在对抗攻击中表现出高达27.4%的韧性。", "conclusion": "我们的研究提供了一种实用且计算效率高的方法，用于构建安全成为更加固有且有韧性的属性的公开权重模型。"}}
{"id": "2509.08022", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08022", "abs": "https://arxiv.org/abs/2509.08022", "authors": ["Yao Liang", "Dongcheng Zhao", "Feifei Zhao", "Guobin Shen", "Yuwei Wang", "Dongqi Liang", "Yi Zeng"], "title": "MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values", "comment": null, "summary": "The alignment of large language models (LLMs) with human values is critical\nfor their safe and effective deployment across diverse user populations.\nHowever, existing benchmarks often neglect cultural and demographic diversity,\nleading to limited understanding of how value alignment generalizes globally.\nIn this work, we introduce MVPBench, a novel benchmark that systematically\nevaluates LLMs' alignment with multi-dimensional human value preferences across\n75 countries. MVPBench contains 24,020 high-quality instances annotated with\nfine-grained value labels, personalized questions, and rich demographic\nmetadata, making it the most comprehensive resource of its kind to date. Using\nMVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,\nrevealing substantial disparities in alignment performance across geographic\nand demographic lines. We further demonstrate that lightweight fine-tuning\nmethods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization\n(DPO), can significantly enhance value alignment in both in-domain and\nout-of-domain settings. Our findings underscore the necessity for\npopulation-aware alignment evaluation and provide actionable insights for\nbuilding culturally adaptive and value-sensitive LLMs. MVPBench serves as a\npractical foundation for future research on global alignment, personalized\nvalue modeling, and equitable AI development.", "AI": {"tldr": "MVPBench是一个新的基准测试，用于评估LLMs的价值观对齐情况，覆盖75个国家。研究发现，不同地区的LLMs的价值观对齐存在显著差异，但轻量级微调方法可以显著提高其性能。", "motivation": "现有的基准测试经常忽视文化和人口统计学的多样性，导致对价值对齐在全球范围内如何推广的理解有限。因此研究的动机是克服这一局限，全面评估LLMs的全球价值观对齐。", "method": "该研究介绍了MVPBench，这是一个系统评估大型语言模型（LLMs）在多维度人类价值观偏好上对齐情况的新基准，涵盖75个国家。MVPBench 包含24,020个高质量实例，标注了细粒度的价值标签、个性化问题和丰富的人口统计学元数据。", "result": "通过MVPBench，该研究深入分析了几种最先进的LLMs，揭示了地理和人口统计学背景下对齐性能之间存在显著差异。此外，研究还展示了轻量级微调方法可以显著提高价值对齐，在领域内和领域外均表现出优越性。", "conclusion": "研究结果强调了人口敏感的价值观对齐评价的必要性，并为构建具有文化适应性和价值观敏感性的LLMs提供了实际行动建议。MVPBench为未来关于全球价值观对齐、个性化价值建模和公平人工智能发展的研究奠定了实际基础。"}}
{"id": "2509.08025", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08025", "abs": "https://arxiv.org/abs/2509.08025", "authors": ["Hoang-Trung Nguyen", "Tan-Minh Nguyen", "Xuan-Bach Le", "Tuan-Kiet Le", "Khanh-Huyen Nguyen", "Ha-Thanh Nguyen", "Thi-Hai-Yen Vuong", "Le-Minh Nguyen"], "title": "NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment", "comment": null, "summary": "This paper presents the methodologies and results of the NOWJ team's\nparticipation across all five tasks at the COLIEE 2025 competition, emphasizing\nadvancements in the Legal Case Entailment task (Task 2). Our comprehensive\napproach systematically integrates pre-ranking models (BM25, BERT, monoT5),\nembedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large\nLanguage Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance\nscoring, and contextual re-ranking. Specifically, in Task 2, our two-stage\nretrieval system combined lexical-semantic filtering with contextualized LLM\nanalysis, achieving first place with an F1 score of 0.3195. Additionally, in\nother tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal\nTextual Entailment, and Legal Judgment Prediction--we demonstrated robust\nperformance through carefully engineered ensembles and effective prompt-based\nreasoning strategies. Our findings highlight the potential of hybrid models\nintegrating traditional IR techniques with contemporary generative models,\nproviding a valuable reference for future advancements in legal information\nprocessing.", "AI": {"tldr": "本文介绍了NOWJ小组在2025年COLIEE大赛中的表现，专注于法律案例蕴含任务上的两个阶段的检索系统，该系统结合词汇-语义过滤与上下文语言模型分析，以0.3195的F1评分在任务2中获胜。", "motivation": "本研究的动机在于强调在COLIEE 2025比赛中，NOWJ小组在所有五个任务中的参与情况，重点展示了法律案例蕴含任务上的进展。", "method": "我们的方法涵盖了法律案例蕴含任务（任务2），并在五个任务中使用了综合方法系统地整合了预排名模型（如BM25、BERT、monoT5）、基于嵌入的语义表示（如BGE-m3、LLM2Vec）和先进的大语言模型（如Qwen-2、QwQ-32B、DeepSeek-V3）来进行摘要、相关性评分和上下文再排序。", "result": "在任务2中，我们的两阶段检索系统结合了词汇-语义过滤和上下文化语言模型分析，以0.3195的F1评分获得了第一名。在其他任务上，如法律案例检索、成文法检索、法律文本蕴含和法律判决预测中，我们通过精心设计的集成模型和提示性推理策略展示了强大的性能。", "conclusion": "我们的发现强调了将传统信息检索技术与当代生成模型相结合的混合模型在法律信息处理中的潜力，为未来的发展提供了有价值的参考。"}}
{"id": "2509.07996", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.07996", "abs": "https://arxiv.org/abs/2509.07996", "authors": ["Lingdong Kong", "Wesley Yang", "Jianbiao Mei", "Youquan Liu", "Ao Liang", "Dekai Zhu", "Dongyue Lu", "Wei Yin", "Xiaotao Hu", "Mingkai Jia", "Junyuan Deng", "Kaiwen Zhang", "Yang Wu", "Tianyi Yan", "Shenyuan Gao", "Song Wang", "Linfeng Li", "Liang Pan", "Yong Liu", "Jianke Zhu", "Wei Tsang Ooi", "Steven C. H. Hoi", "Ziwei Liu"], "title": "3D and 4D World Modeling: A Survey", "comment": "Survey; 34 pages, 10 figures, 14 tables; GitHub Repo at\n  https://github.com/worldbench/survey", "summary": "World modeling has become a cornerstone in AI research, enabling agents to\nunderstand, represent, and predict the dynamic environments they inhabit. While\nprior work largely emphasizes generative methods for 2D image and video data,\nthey overlook the rapidly growing body of work that leverages native 3D and 4D\nrepresentations such as RGB-D imagery, occupancy grids, and LiDAR point clouds\nfor large-scale scene modeling. At the same time, the absence of a standardized\ndefinition and taxonomy for ``world models'' has led to fragmented and\nsometimes inconsistent claims in the literature. This survey addresses these\ngaps by presenting the first comprehensive review explicitly dedicated to 3D\nand 4D world modeling and generation. We establish precise definitions,\nintroduce a structured taxonomy spanning video-based (VideoGen),\noccupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and\nsystematically summarize datasets and evaluation metrics tailored to 3D/4D\nsettings. We further discuss practical applications, identify open challenges,\nand highlight promising research directions, aiming to provide a coherent and\nfoundational reference for advancing the field. A systematic summary of\nexisting literature is available at https://github.com/worldbench/survey", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08032", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08032", "abs": "https://arxiv.org/abs/2509.08032", "authors": ["Fengyu She", "Nan Wang", "Hongfei Wu", "Ziyi Wan", "Jingmian Wang", "Chang Wang"], "title": "SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery", "comment": null, "summary": "Scientific literature is growing exponentially, creating a critical\nbottleneck for researchers to efficiently synthesize knowledge. While\ngeneral-purpose Large Language Models (LLMs) show potential in text processing,\nthey often fail to capture scientific domain-specific nuances (e.g., technical\njargon, methodological rigor) and struggle with complex scientific tasks,\nlimiting their utility for interdisciplinary research. To address these gaps,\nthis paper presents SciGPT, a domain-adapted foundation model for scientific\nliterature understanding and ScienceBench, an open source benchmark tailored to\nevaluate scientific LLMs.\n  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:\n(1) low-cost domain distillation via a two-stage pipeline to balance\nperformance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention\nmechanism that cuts memory consumption by 55\\% for 32,000-token long-document\nreasoning; and (3) knowledge-aware adaptation integrating domain ontologies to\nbridge interdisciplinary knowledge gaps.\n  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in\ncore scientific tasks including sequence labeling, generation, and inference.\nIt also exhibits strong robustness in unseen scientific tasks, validating its\npotential to facilitate AI-augmented scientific discovery.", "AI": {"tldr": "SciGPT是一种专门针对科学文献理解的领域适应型基础模型，通过采用一系列创新技术来改进科学文献处理能力和降低资源消耗。", "motivation": "随着科学研究文献的指数级增长，研究人员难以高效地进行知识综合。虽然通用大型语言模型在文本处理中显示出潜力，但在捕获科学领域的细微差别和处理复杂科学任务方面存在不足。", "method": "SciGPT采用了基于Qwen3架构的三项关键技术：低代价领域蒸馏、稀疏专家混合注意机制以及知识感知适应。", "result": "实验结果显示，SciGPT在ScienceBench基准测试中的核心科学任务上超过GPT-4o，包括序列标注、生成和推理。", "conclusion": "SciGPT展示了其在支持AI增强的科学发现方面的潜力，特别是在未见过的科学任务中表现出色。"}}
{"id": "2509.08003", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.08003", "abs": "https://arxiv.org/abs/2509.08003", "authors": ["Shahid Shafi Dar", "Bharat Kaurav", "Arnav Jain", "Chandravardhan Singh Raghaw", "Mohammad Zia Ur Rehman", "Nagendra Kumar"], "title": "An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities", "comment": null, "summary": "In an era of escalating climate change, urban flooding has emerged as a\ncritical challenge for sustainable cities, threatening lives, infrastructure,\nand ecosystems. Traditional flood detection methods are constrained by their\nreliance on unimodal data and static rule-based systems, which fail to capture\nthe dynamic, non-linear relationships inherent in flood events. Furthermore,\nexisting attention mechanisms and ensemble learning approaches exhibit\nlimitations in hierarchical refinement, cross-modal feature integration, and\nadaptability to noisy or unstructured environments, resulting in suboptimal\nflood classification performance. To address these challenges, we present\nXFloodNet, a novel framework that redefines urban flood classification through\nadvanced deep-learning techniques. XFloodNet integrates three novel components:\n(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically\naligns visual and textual features, enabling precise multi-granularity\ninteractions and resolving contextual ambiguities; (2) a Heterogeneous\nConvolutional Adaptive Multi-Scale Attention module, which leverages\nfrequency-enhanced channel attention and frequency-modulated spatial attention\nto extract and prioritize discriminative flood-related features across spectral\nand spatial domains; and (3) a Cascading Convolutional Transformer Feature\nRefinement technique that harmonizes hierarchical features through adaptive\nscaling and cascading operations, ensuring robust and noise-resistant flood\ndetection. We evaluate our proposed method on three benchmark datasets, such as\nChennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves\nstate-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,\nsurpassing existing methods by significant margins.", "AI": {"tldr": "本文提出了XFloodNet框架，解决城市洪水分类中的挑战，采用了层级交叉模态门控注意力机制、异构卷积自适应多尺度注意模块以及级联卷积变压器特征优化技术，基于三个基准数据集测试，取得优异的分类结果，超越现有方法。", "motivation": "传统洪水检测方法依赖单一数据类型和静态规则系统，无法捕捉洪水事件的动态非线性关系，现有注意力机制和集成学习方法在层级细化、跨模态特征整合以及适应噪声或非结构化环境的能力上具有局限性，导致洪水分类性能不佳。", "method": "XFloodNet框架包含三个创新组件：1) 层级交叉模态门控注意力机制，2) 异构卷积自适应多尺度注意模块，3) 级联卷积变压器特征优化技术，共同提高了洪水相关的特征提取与分类能力。", "result": "研究在三个基准数据集上进行了验证，分别是Chennai Floods, Rhine18 Floods, 和Harz17 Floods数据集，XFloodNet分别获得了F1-scores为93.33%，82.24%，和88.60%的结果，超越了现有的方法。", "conclusion": "XFloodNet框架基于先进的深度学习技术，表现出了在城市洪水分类中优异的性能，为解决复杂的洪水检测问题提供了新的手段，取得了显著超出现有方法的性能结果。"}}
{"id": "2509.08075", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08075", "abs": "https://arxiv.org/abs/2509.08075", "authors": ["Flor Miriam Plaza-del-Arco", "Paul Röttger", "Nino Scherrer", "Emanuele Borgonovo", "Elmar Plischke", "Dirk Hovy"], "title": "No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models", "comment": null, "summary": "Large language models (LLMs) are increasingly integrated into our daily lives\nand personalized. However, LLM personalization might also increase unintended\nside effects. Recent work suggests that persona prompting can lead models to\nfalsely refuse user requests. However, no work has fully quantified the extent\nof this issue. To address this gap, we measure the impact of 15\nsociodemographic personas (based on gender, race, religion, and disability) on\nfalse refusal. To control for other factors, we also test 16 different models,\n3 tasks (Natural Language Inference, politeness, and offensiveness\nclassification), and nine prompt paraphrases. We propose a Monte Carlo-based\nmethod to quantify this issue in a sample-efficient manner. Our results show\nthat as models become more capable, personas impact the refusal rate less and\nless. Certain sociodemographic personas increase false refusal in some models,\nwhich suggests underlying biases in the alignment strategies or safety\nmechanisms. However, we find that the model choice and task significantly\ninfluence false refusals, especially in sensitive content tasks. Our findings\nsuggest that persona effects have been overestimated, and might be due to other\nfactors.", "AI": {"tldr": "研究通过基于蒙特卡洛的方法，探究了社会人口学角色对大型语言模型错误拒绝率的影响，发现角色的影响可能被夸大，并且这种影响可能受到模型能力和任务类型的显著影响。", "motivation": "大型语言模型(LLMs)在我们的日常生活中越来越普及且趋向个性化。然而，LLMs的个性化可能导致一些意外的副作用，尤其在特定角色提示下可能会产生对用户请求的错误拒绝。为了更全面地了解问题的严重程度，本研究试图量化解决这一问题。", "method": "本研究提出了一种基于蒙特卡洛的方法，以高效地量化问题的影响。该方法测试了15个基于性别、种族、宗教和残疾的社会人口学角色，16种不同的模型，以及三种任务（自然语言推理、礼貌性和攻击性分类），并采用了九种不同的提示重述以控制其他因素的影响。", "result": "研究表明，随着模型能力的提升，角色对拒信率的影响逐渐减小。然而，某些社会人口学角色会导致一些模型的错误拒绝率增加，表明在对齐策略或安全机制中可能存在潜在偏见。同时，模型选择和任务类型对错误拒绝的影响显著，尤其是涉及到敏感内容的任务。", "conclusion": "研究结论表明，社会人口学角色对大型语言模型错误拒绝率的影响可能被过度估计，实际上可能与其他因素有关。这为未来模型的开发和应用提供了重要见解，尤其是在处理敏感信息时。"}}
{"id": "2509.08016", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08016", "abs": "https://arxiv.org/abs/2509.08016", "authors": ["Hyungjin Chung", "Hyelin Nam", "Jiyeon Kim", "Hyojun Go", "Byeongjun Park", "Junho Kim", "Joonseok Lee", "Seongsu Ha", "Byung-Hoon Kim"], "title": "Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs", "comment": "https://github.com/hyungjin-chung/VPS", "summary": "Video Large Language Models (VideoLLMs) face a critical bottleneck:\nincreasing the number of input frames to capture fine-grained temporal detail\nleads to prohibitive computational costs and performance degradation from long\ncontext lengths. We introduce Video Parallel Scaling (VPS), an inference-time\nmethod that expands a model's perceptual bandwidth without increasing its\ncontext window. VPS operates by running multiple parallel inference streams,\neach processing a unique, disjoint subset of the video's frames. By aggregating\nthe output probabilities from these complementary streams, VPS integrates a\nricher set of visual information than is possible with a single pass. We\ntheoretically show that this approach effectively contracts the Chinchilla\nscaling law by leveraging uncorrelated visual evidence, thereby improving\nperformance without additional training. Extensive experiments across various\nmodel architectures and scales (2B-32B) on benchmarks such as Video-MME and\nEventHallusion demonstrate that VPS consistently and significantly improves\nperformance. It scales more favorably than other parallel alternatives (e.g.\nSelf-consistency) and is complementary to other decoding strategies, offering a\nmemory-efficient and robust framework for enhancing the temporal reasoning\ncapabilities of VideoLLMs.", "AI": {"tldr": "提出了Video Parallel Scaling (VPS) 方法，通过并行处理不同帧子集，提高视频大语言模型的感知带宽，从而改善性能而不增加训练成本。实验表明VPS在不同模型架构和规模上均能显著提升性能。", "motivation": "增加输入帧数以捕捉细粒度时间细节会带来计算成本过高和长上下文长度下的性能下降问题。目的是解决视频大语言模型的时间推理能力瓶颈，提高其性能。", "method": "VPS通过多个并行的推理流，每个流处理视频帧的不同非重叠子集，然后聚合这些流的输出概率，从而整合比单次传递更多的视觉信息，理论上证明了这种方法能够改善性能，而无需额外训练。", "result": "在2B-32B规模的不同模型架构上进行的实验显示，VPS在Video-MME和EventHallusion等基准上表现出色，性能显著提升。此外，VPS相比于其他并行方法（如自洽性）扩展性更佳，且与其解码策略互补。", "conclusion": "VPS证明了通过整合多个并行流的视觉证据，可以提高视频LLM的感知带宽和时间推理能力，而不增加计算成本或者改变模型架构。它提供了一个高效且鲁棒的框架来提升视频LLM的性能。"}}
{"id": "2509.08093", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08093", "abs": "https://arxiv.org/abs/2509.08093", "authors": ["Nathaniel Imel", "Noga Zaslavsky"], "title": "Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression", "comment": null, "summary": "Converging evidence suggests that systems of semantic categories across human\nlanguages achieve near-optimal compression via the Information Bottleneck (IB)\ncomplexity-accuracy principle. Large language models (LLMs) are not trained for\nthis objective, which raises the question: are LLMs capable of evolving\nefficient human-like semantic systems? To address this question, we focus on\nthe domain of color as a key testbed of cognitive theories of categorization\nand replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two\ninfluential human behavioral studies. First, we conduct an English color-naming\nstudy, showing that Gemini aligns well with the naming patterns of native\nEnglish speakers and achieves a significantly high IB-efficiency score, while\nLlama exhibits an efficient but lower complexity system compared to English.\nSecond, to test whether LLMs simply mimic patterns in their training data or\nactually exhibit a human-like inductive bias toward IB-efficiency, we simulate\ncultural evolution of pseudo color-naming systems in LLMs via iterated\nin-context language learning. We find that akin to humans, LLMs iteratively\nrestructure initially random systems towards greater IB-efficiency and\nincreased alignment with patterns observed across the world's languages. These\nfindings demonstrate that LLMs are capable of evolving perceptually grounded,\nhuman-like semantic systems, driven by the same fundamental principle that\ngoverns semantic efficiency across human languages.", "AI": {"tldr": "研究发现，大型语言模型（LLMs）能够类比人类语义系统，生成感知基础较强的语义系统，与驱动跨人类语言语义效率的基本原理相同。", "motivation": "已有证据表明，人类语言中的语义分类系统能够通过信息瓶颈（IB）复杂度-准确性原则实现接近最优的压缩。LLMs并未针对此目标训练，因此本文探讨LLMs是否能演化出与人类相似的高效语义系统。", "method": "通过在大型语言模型（LLMs）上重现两项关于颜色命名的人类行为研究来探讨LLMs是否能类似人类一样优化语义系统。具体使用了Gemini 2.0-flash和Llama 3.3-70B-Instruct模型，首先是英语颜色命名研究，其次通过迭代上下文语言学习来模拟假的颜色命名系统在LLMs中的文化演变。", "result": "研究结果显示，Gemini模型在英语颜色命名上与英语母语者高度一致，并获得较高的IB效率得分；而Llama模型虽然也表现高效，但复杂度较低。迭代上下文学习表明，LLMs能够像人类一样重构随机系统，趋向更高的IB效率和与世界语言模式的更高一致性。", "conclusion": "这些发现证明了LLMs能够根据感知基础的人类语义系统演化，这与驱动跨人类语言语义效率的基本原理相似。"}}
{"id": "2509.08024", "categories": ["cs.CV", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.08024", "abs": "https://arxiv.org/abs/2509.08024", "authors": ["Lata Pangtey", "Omkar Kabde", "Shahid Shafi Dar", "Nagendra Kumar"], "title": "Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change", "comment": null, "summary": "With the rapid proliferation of information across digital platforms, stance\ndetection has emerged as a pivotal challenge in social media analysis. While\nmost of the existing approaches focus solely on textual data, real-world social\nmedia content increasingly combines text with visual elements creating a need\nfor advanced multimodal methods. To address this gap, we propose a multimodal\nstance detection framework that integrates textual and visual information\nthrough a hierarchical fusion approach. Our method first employs a Large\nLanguage Model to retrieve stance-relevant summaries from source text, while a\ndomain-aware image caption generator interprets visual content in the context\nof the target topic. These modalities are then jointly modeled along with the\nreply text, through a specialized transformer module that captures interactions\nbetween the texts and images. The proposed modality fusion framework integrates\ndiverse modalities to facilitate robust stance classification. We evaluate our\napproach on the MultiClimate dataset, a benchmark for climate change-related\nstance detection containing aligned video frames and transcripts. We achieve\naccuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%,\nrespectively, outperforming existing state-of-the-art approaches.", "AI": {"tldr": "This paper proposes a multimodal stance detection framework that integrates text and visual elements using a hierarchical fusion method, with successful performance on the MultiClimate dataset.", "motivation": "The motivation stems from the need for advanced multimodal methods to analyze social media content that combines text and visual elements. Most existing approaches only focus on textual data, which limits their ability to understand complex social media interactions.", "method": "Our method involves a hierarchical fusion approach that integrates textual data processed by a Large Language Model with visual data interpreted by a domain-aware image caption generator. These modalities are then jointly modeled using a specialized transformer module to perform stance detection.", "result": "The proposed framework was evaluated on the MultiClimate dataset and achieved an accuracy of 76.2%, precision of 76.3%, recall of 76.2%, and an F1-score of 76.2%, outperforming state-of-the-art methods.", "conclusion": "The study concludes that the proposed multimodal stance detection framework is effective in capturing interactions between texts and images, and it significantly outperforms existing methods in classifying stance in multimodal social media content."}}
{"id": "2509.08105", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08105", "abs": "https://arxiv.org/abs/2509.08105", "authors": ["Kosei Uemura", "David Guzmán", "Quang Phuoc Nguyen", "Jesujoba Oluwadara Alabi", "En-shiun Annie Lee", "David Ifeoluwa Adelani"], "title": "MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion", "comment": "under submission", "summary": "Large language models excel in English but still struggle with complex\nreasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder\nmethods such as LangBridge and MindMerger raise accuracy on mid and\nhigh-resource languages, yet they leave a large gap on LRLs. We present MERLIN,\na two-stage model-stacking framework that applies a curriculum learning\nstrategy -- from general bilingual bitext to task-specific data -- and adapts\nonly a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves\nexact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.\nIt also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),\ndemonstrating effectiveness across both low and high-resource settings.", "AI": {"tldr": "研究介绍MERLIN模型，用以提升低资源语言中的推理准确性，超越现有模型。", "motivation": "虽然大型语言模型在英语方面表现出色，但在许多低资源语言中的复杂推理任务上仍然存在问题。现有的编码器加解码器方法如LangBridge和MindMerger在中高资源语言上提高了准确性，但在低资源语言上仍有很大差距。", "method": "MERLIN采用两阶段模型堆叠框架，结合课程学习策略，从通用的双语文本逐步过渡到特定任务的数据，并仅微调一小部分DoRA权重。", "result": "MERLIN，一种两阶段模型堆叠框架，采用从通用双语文本到任务特定数据的课程学习策略，并仅调整少量DoRA权重，显著提升了低资源语言中的推理准确性。在AfriMGSM基准测试中，MERLIN将精确匹配准确率提高了12.9个百分点，超过了MindMerger和GPT-4o-mini。此外，MERLIN还在MGSM和MSVAMP上分别提高了0.9和2.8个百分点，展示了其在低资源和高资源设置中的有效性。", "conclusion": "MERLIN模型在处理低资源语言的复杂推理任务上表现出色，其独特的课程学习策略和模型参数高效调整机制是主要贡献。"}}
{"id": "2509.08026", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08026", "abs": "https://arxiv.org/abs/2509.08026", "authors": ["Zeinab Ghasemi Darehnaei", "Mohammad Shokouhifar", "Hossein Yazdanjouei", "S. M. J. Rastegar Fatemi"], "title": "Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles", "comment": null, "summary": "This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep\ntransfer learning model for detecting multiple vehicles in UAV images. It\ncombines three pre-trained Faster R-CNN feature extractor models (InceptionV3,\nResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,\nNa\\\"ive Bayes), resulting in 15 different base learners. These are aggregated\nvia weighted averaging to classify regions as Car, Van, Truck, Bus, or\nbackground. Hyperparameters are optimized with the whale optimization algorithm\nto balance accuracy, precision, and recall. Implemented in MATLAB R2020b with\nparallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV\ndataset.", "AI": {"tldr": "SI-EDTL模型通过结合多种预训练的Faster R-CNN模型和迁移分类器，并利用鲸鱼优化算法进行超参数优化，实现了无人机图像中多类型车辆的高效检测。", "motivation": "动机是提出一种新的模型来提高检测无人机图像中多类型车辆的性能，特别是在精度、精确性和召回率方面。", "method": "该方法包括使用多种预训练模型和分类器形成集成学习器集，使用鲸鱼优化算法优化超参数，并利用加权平均进行聚合分类。", "result": "该论文介绍了SI-EDTL模型，这是一种用于检测无人机图像中多车辆的两阶段群智能集成深度迁移学习模型。SI-EDTL结合了三个预训练的Faster R-CNN特征提取器模型（InceptionV3、ResNet50、GoogLeNet）与五个迁移分类器（KNN、SVM、MLP、C4.5、朴素贝叶斯），形成15种不同的基本学习器。通过加权平均聚合来分类车辆类型为轿车、货车、卡车、公交车或背景。使用鲸鱼优化算法对超参数进行优化，以平衡精度、精确性和召回率。在MATLAB R2020b中实现，并采用并行处理，SI-EDTL在AU-AIR无人机数据集上表现出优于现有方法的性能。", "conclusion": "结论是SI-EDTL在AU-AIR无人机数据集上超过了现有的检测方法，展示了其在检测无人机图像中的多类型车辆方面的优越性能。"}}
{"id": "2509.08146", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08146", "abs": "https://arxiv.org/abs/2509.08146", "authors": ["Nivedha Sivakumar", "Natalie Mackraz", "Samira Khorshidi", "Krishna Patel", "Barry-John Theobald", "Luca Zappella", "Nicholas Apostoloff"], "title": "Bias after Prompting: Persistent Discrimination in Large Language Models", "comment": null, "summary": "A dangerous assumption that can be made from prior work on the bias transfer\nhypothesis (BTH) is that biases do not transfer from pre-trained large language\nmodels (LLMs) to adapted models. We invalidate this assumption by studying the\nBTH in causal models under prompt adaptations, as prompting is an extremely\npopular and accessible adaptation strategy used in real-world applications. In\ncontrast to prior work, we find that biases can transfer through prompting and\nthat popular prompt-based mitigation methods do not consistently prevent biases\nfrom transferring. Specifically, the correlation between intrinsic biases and\nthose after prompt adaptation remain moderate to strong across demographics and\ntasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age\n(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we\nfind that biases remain strongly correlated when varying few-shot composition\nparameters, such as sample size, stereotypical content, occupational\ndistribution and representational balance (rho >= 0.90). We evaluate several\nprompt-based debiasing strategies and find that different approaches have\ndistinct strengths, but none consistently reduce bias transfer across models,\ntasks or demographics. These results demonstrate that correcting bias, and\npotentially improving reasoning ability, in intrinsic models may prevent\npropagation of biases to downstream tasks.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08027", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.08027", "abs": "https://arxiv.org/abs/2509.08027", "authors": ["Rafał Osadnik", "Pablo Gómez", "Eleni Bohacek", "Rickbir Bahia"], "title": "MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery", "comment": "22 pages, 21 figures", "summary": "This work presents a new dataset for the Martian digital elevation model\nprediction task, ready for machine learning applications called MCTED. The\ndataset has been generated using a comprehensive pipeline designed to process\nhigh-resolution Mars orthoimage and DEM pairs from Day et al., yielding a\ndataset consisting of 80,898 data samples. The source images are data gathered\nby the Mars Reconnaissance Orbiter using the CTX instrument, providing a very\ndiverse and comprehensive coverage of the Martian surface. Given the complexity\nof the processing pipelines used in large-scale DEMs, there are often artefacts\nand missing data points in the original data, for which we developed tools to\nsolve or mitigate their impact. We divide the processed samples into training\nand validation splits, ensuring samples in both splits cover no mutual areas to\navoid data leakage. Every sample in the dataset is represented by the optical\nimage patch, DEM patch, and two mask patches, indicating values that were\noriginally missing or were altered by us. This allows future users of the\ndataset to handle altered elevation regions as they please. We provide\nstatistical insights of the generated dataset, including the spatial\ndistribution of samples, the distributions of elevation values, slopes and\nmore. Finally, we train a small U-Net architecture on the MCTED dataset and\ncompare its performance to a monocular depth estimation foundation model,\nDepthAnythingV2, on the task of elevation prediction. We find that even a very\nsmall architecture trained on this dataset specifically, beats a zero-shot\nperformance of a depth estimation foundation model like DepthAnythingV2. We\nmake the dataset and code used for its generation completely open source in\npublic repositories.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.08150", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08150", "abs": "https://arxiv.org/abs/2509.08150", "authors": ["Supriya Lall", "Christian Farrell", "Hari Pathanjaly", "Marko Pavic", "Sarvesh Chezhian", "Masataro Asai"], "title": "Verbalized Algorithms", "comment": "Submitted to NeurIPS 2025 Workshop on Efficient Reasoning", "summary": "Instead of querying LLMs in a one-shot manner and hoping to get the right\nanswer for a reasoning task, we propose a paradigm we call \\emph{verbalized\nalgorithms} (VAs), which leverage classical algorithms with established\ntheoretical understanding. VAs decompose a task into simple elementary\noperations on natural language strings that they should be able to answer\nreliably, and limit the scope of LLMs to only those simple tasks. For example,\nfor sorting a series of natural language strings, \\emph{verbalized sorting}\nuses an LLM as a binary comparison oracle in a known and well-analyzed sorting\nalgorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of\nthis approach on sorting and clustering tasks.", "AI": {"tldr": "文章提出了利用经典算法的'verbalized algorithms' (VAs) 新范式，通过将任务分解为简单操作，并仅限LLMs处理这些简单任务来提高任务处理效率，特别是对于排序和聚类任务。", "motivation": "由于一次查询大语言模型（LLMs）并希望得到正确的推理任务答案的方法存在局限性，因此提出了VAs这一概念。希望通过利用经典算法的理论理解，可以更有效地解决推理任务。", "method": "提出了一种称为'verbalized algorithms' (VAs) 的新范式，该范式利用经典算法，将任务分解为简单的自然语言字符串操作，并仅限LLMs处理这些简单任务。例如，在对自然语言字符串进行排序时，'verbalized sorting' 把LLMs作为二元比较预言机使用在一个已知和分析过的排序算法中，如bitonic排序网络。", "result": "在排序和聚类任务中展示了这种新方法的有效性。", "conclusion": "通过利用经典算法的VAs方法，可以更有效地解决自然语言处理任务，特别是在排序和聚类任务中。"}}
{"id": "2509.08104", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08104", "abs": "https://arxiv.org/abs/2509.08104", "authors": ["Sasan Sharifipour", "Constantino Álvarez Casado", "Mohammad Sabokrou", "Miguel Bordallo López"], "title": "APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction", "comment": "22 pages, 6 figures, conference, 7 tables, 15 formulas", "summary": "Training deep learning models for point cloud prediction tasks such as shape\ncompletion and generation depends critically on loss functions that measure\ndiscrepancies between predicted and ground-truth point sets. Commonly used\nfunctions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on\nnearest-neighbor assignments, which often induce many-to-one correspondences,\nleading to point congestion in dense regions and poor coverage in sparse\nregions. These losses also involve non-differentiable operations due to index\nselection, which may affect gradient-based optimization. Earth Mover Distance\n(EMD) enforces one-to-one correspondences and captures structural similarity\nmore effectively, but its cubic computational complexity limits its practical\nuse. We propose the Adaptive Probabilistic Matching Loss (APML), a fully\ndifferentiable approximation of one-to-one matching that leverages Sinkhorn\niterations on a temperature-scaled similarity matrix derived from pairwise\ndistances. We analytically compute the temperature to guarantee a minimum\nassignment probability, eliminating manual tuning. APML achieves near-quadratic\nruntime, comparable to Chamfer-based losses, and avoids non-differentiable\noperations. When integrated into state-of-the-art architectures (PoinTr, PCN,\nFoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)\nthat generates 3D human point clouds from WiFi CSI measurements, APM loss\nyields faster convergence, superior spatial distribution, especially in\nlow-density regions, and improved or on-par quantitative performance without\nadditional hyperparameter search. The code is available at:\nhttps://github.com/apm-loss/apml.", "AI": {"tldr": "本文提出了自适应概率匹配损失（APML），解决了现有点云预测任务中的密度不均和非可微操作问题，提升了模型性能。", "motivation": "为了克服现有损失函数在点云预测任务中点云密度不均和非可微操作的问题，提出了APML。", "method": "我们提出了自适应概率匹配损失（APML），这是一种全微分的一对一匹配近似方法，利用Sinkhorn迭代和基于成对距离的温度缩放相似性矩阵。我们通过解析计算温度来保证最小分配概率，从而消除手动调整的需求。", "result": "APML损失函数在ShapeNet基准测试上和从WiFi CSI测量生成3D人体点云的时空Transformer模型上，达到了更快的收敛速度、更优秀的空间分布，特别是在低密度区域，而且在没有额外超参数搜索的情况下取得了更好的或相当的定量性能。", "conclusion": "APML不仅在运行时间上与Chamfer距离函数相近，还避免了非可微操作，展示出了强大的性能并且在实际应用中更加简便。"}}
{"id": "2509.08217", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08217", "abs": "https://arxiv.org/abs/2509.08217", "authors": ["Eve Fleisig", "Matthias Orlikowski", "Philipp Cimiano", "Dan Klein"], "title": "Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions", "comment": null, "summary": "For machine learning datasets to accurately represent diverse opinions in a\npopulation, they must preserve variation in data labels while filtering out\nspam or low-quality responses. How can we balance annotator reliability and\nrepresentation? We empirically evaluate how a range of heuristics for annotator\nfiltering affect the preservation of variation on subjective tasks. We find\nthat these methods, designed for contexts in which variation from a single\nground-truth label is considered noise, often remove annotators who disagree\ninstead of spam annotators, introducing suboptimal tradeoffs between accuracy\nand label diversity. We find that conservative settings for annotator removal\n(<5%) are best, after which all tested methods increase the mean absolute error\nfrom the true average label. We analyze performance on synthetic spam to\nobserve that these methods often assume spam annotators are less random than\nreal spammers tend to be: most spammers are distributionally indistinguishable\nfrom real annotators, and the minority that are distinguishable tend to give\nfixed answers, not random ones. Thus, tasks requiring the preservation of\nvariation reverse the intuition of existing spam filtering methods: spammers\ntend to be less random than non-spammers, so metrics that assume variation is\nspam fare worse. These results highlight the need for spam removal methods that\naccount for label diversity.", "AI": {"tldr": "Evaluating annotator filtering heuristics reveals conservative settings are optimal for preserving label diversity and filtering spam in subjective tasks.", "motivation": "The goal is to balance the preservation of data label variation, indicative of diverse opinions, while filtering out spam or low-quality responses in machine learning datasets.", "method": "We empirically evaluate a range of heuristics for annotator filtering to maintain variation in subjective tasks, assessing their impact on label diversity and accuracy.", "result": "Conservative settings for annotator removal (<5%) are found to best maintain the balance, as stricter methods introduce more error relative to the true average label and misidentify variation rather than actual spam.", "conclusion": "Existing spam filtering methods often assume variability in responses indicates spam, which is inaccurate; methods should account for label diversity to correctly identify and remove spam."}}
{"id": "2509.08205", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.08205", "abs": "https://arxiv.org/abs/2509.08205", "authors": ["Jingjing Liu", "Yinchao Han", "Xianchao Xiu", "Jianhua Zhang", "Wanquan Liu"], "title": "Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection", "comment": null, "summary": "Infrared small target detection (ISTD) is one of the key techniques in image\nprocessing. Although deep unfolding networks (DUNs) have demonstrated promising\nperformance in ISTD due to their model interpretability and data adaptability,\nexisting methods still face significant challenges in parameter lightweightness\nand noise robustness. In this regard, we propose a highly lightweight framework\nbased on robust principal component analysis (RPCA) called L-RPCANet.\nTechnically, a hierarchical bottleneck structure is constructed to reduce and\nincrease the channel dimension in the single-channel input infrared image to\nachieve channel-wise feature refinement, with bottleneck layers designed in\neach module to extract features. This reduces the number of channels in feature\nextraction and improves the lightweightness of network parameters. Furthermore,\na noise reduction module is embedded to enhance the robustness against complex\nnoise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a\nchannel attention mechanism to focus on the varying importance of different\nfeatures across channels, thereby achieving excellent performance while\nmaintaining both lightweightness and robustness. Extensive experiments on the\nISTD datasets validate the superiority of our proposed method compared with\nstate-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code\nwill be available at https://github.com/xianchaoxiu/L-RPCANet.", "AI": {"tldr": "本文提出了一种基于RPCA的超轻量框架L-RPCANet，旨在解决ISTD的挑战，通过构建分层瓶颈结构和嵌入降噪模块等方法实现了出色的性能和鲁棒性。", "motivation": "虽然深度展开网络（DUNs）在红外小目标检测（ISTD）中展示了令人鼓舞的性能，但现有方法在参数轻量化和噪声鲁棒性方面仍面临重大挑战。", "method": "本文提出了一种基于鲁棒主成分分析（RPCA）的超轻量框架，称为L-RPCANet。通过构建分层瓶颈结构，减少了特征提取的通道数，提高了网络参数的轻量化。此外，嵌入了一个降噪模块以增强对复杂噪声的鲁棒性，并利用挤压激励网络（SENet）作为通道注意力机制，以关注通道间不同特征的变化程度，从而实现了在保持轻量化和鲁棒性的同时获得出色性能。", "result": "在ISTD数据集上的广泛实验验证了所提出方法相对于最新方法（包括RPCANet，DRPCANet和RPCANet++）的优越性。", "conclusion": "代码可在https://github.com/xianchaoxiu/L-RPCANet获取。"}}
{"id": "2509.08304", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.08304", "abs": "https://arxiv.org/abs/2509.08304", "authors": ["Yehudit Aperstein", "Alon Gottlib", "Gal Benita", "Alexander Apartsin"], "title": "Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection", "comment": "27 pages, 1 figure", "summary": "Understanding how information is shared across documents, regardless of the\nformat in which it is expressed, is critical for tasks such as information\nretrieval, summarization, and content alignment. In this work, we introduce a\nnovel framework for modelling Semantic Coverage Relations (SCR), which\nclassifies document pairs based on how their informational content aligns. We\ndefine three core relation types: equivalence, where both texts convey the same\ninformation using different textual forms or styles; inclusion, where one\ndocument fully contains the information of another and adds more; and semantic\noverlap, where each document presents partially overlapping content. To capture\nthese relations, we adopt a question answering (QA)-based approach, using the\nanswerability of shared questions across documents as an indicator of semantic\ncoverage. We construct a synthetic dataset derived from the SQuAD corpus by\nparaphrasing source passages and selectively omitting information, enabling\nprecise control over content overlap. This dataset allows us to benchmark\ngenerative language models and train transformer-based classifiers for SCR\nprediction. Our findings demonstrate that discriminative models significantly\noutperform generative approaches, with the RoBERTa-base model achieving the\nhighest accuracy of 61.4% and the Random Forest-based model showing the best\nbalance with a macro-F1 score of 52.9%. The results show that QA provides an\neffective lens for assessing semantic relations across stylistically diverse\ntexts, offering insights into the capacity of current models to reason about\ninformation beyond surface similarity. The dataset and code developed in this\nstudy are publicly available to support reproducibility.", "AI": {"tldr": "提出一种新的语义覆盖率关系（SCR）建模框架，使用问答方法评估文本间信息关系。", "motivation": "理解不同格式文档间的信息共享方式对于信息检索、摘要和内容对齐等任务至关重要。", "method": "采用基于问答(QA)的方法，通过文档之间共享问题的答案能力来衡量语义覆盖。", "result": "判别模型显著优于生成模型，其中RoBERTa-base模型准确率最高达61.4%，随机森林模型宏观F1得分最佳为52.9%。", "conclusion": "研究表明QA方法能有效评估风格不同的文本间的语义相关性，揭示了当前模型在表层相似性之外推理信息的能力。"}}
{"id": "2509.08228", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.08228", "abs": "https://arxiv.org/abs/2509.08228", "authors": ["Miao Cao", "Siming Zheng", "Lishun Wang", "Ziyang Chen", "David Brady", "Xin Yuan"], "title": "Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing", "comment": null, "summary": "Digital cameras consume ~0.1 microjoule per pixel to capture and encode\nvideo, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps.\nImagining gigapixel cameras operating at 100-1000 fps, the current processing\nmodel is unsustainable. To address this, physical layer compressive measurement\nhas been proposed to reduce power consumption per pixel by 10-100X. Video\nSnapshot Compressive Imaging (SCI) introduces high frequency modulation in the\noptical sensor layer to increase effective frame rate. A commonly used sampling\nstrategy of video SCI is Random Sampling (RS) where each mask element value is\nrandomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated\nthat images can be recovered from a fraction of the image pixels. Inspired by\nI2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial\nlocation, only one sub-frame is set to 1 and all others are set to 0. We then\nbuild a Digital Micro-mirror Device (DMD) encoding system to verify the\neffectiveness of our USS strategy. Ideally, we can decompose the USS\nmeasurement into sub-measurements for which we can utilize I2P algorithms to\nrecover high-speed frames. However, due to the mismatch between the DMD and\nCCD, the USS measurement cannot be perfectly decomposed. To this end, we\npropose BSTFormer, a sparse TransFormer that utilizes local Block attention,\nglobal Sparse attention, and global Temporal attention to exploit the sparsity\nof the USS measurement. Extensive results on both simulated and real-world data\nshow that our method significantly outperforms all previous state-of-the-art\nalgorithms. Additionally, an essential advantage of the USS strategy is its\nhigher dynamic range than that of the RS strategy. Finally, from the\napplication perspective, the USS strategy is a good choice to implement a\ncomplete video SCI system on chip due to its fixed exposure time.", "AI": {"tldr": "本文提出了一种新的采样策略Ultra-Sparse Sampling (USS) 和一种新的稀疏Transformer模型BSTFormer，用于提高视频压缩成像(Video SCI)在高帧率、高分辨率摄像中的应用，该策略和模型都显著优于现有的方法。", "motivation": "由于当前视频压缩成像(Video SCI)的处理模型基于随机采样(RS)，数据处理能耗高，不适用于未来像素级高帧率摄像，因此本文提出了一种新的采样策略——USS策略，来减少功耗并提高视频SCI的有效性。", "method": "提出了一种名为Ultra-Sparse Sampling (USS) 的策略，其中在每个空间位置上，只有一个子帧设为1，所有其他子帧设为0。我们建立了一个基于数字微镜设备（DMD）的编码系统来验证USS策略的有效性，并提出了一种名为BSTFormer的方法，利用局部块注意力机制、全局稀疏注意力机制和全局时间注意力机制来利用USS测量的稀疏性。", "result": "实验结果表明，该方法在模拟数据和真实数据上都显著优于所有先前的最先进算法。此外，USS策略相较于RS策略具有更高的动态范围。", "conclusion": "USS策略在实现视频SCI系统时是可选的，其固定曝光时间使得USS策略在片上实现上具有优势。"}}
{"id": "2509.08345", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08345", "abs": "https://arxiv.org/abs/2509.08345", "authors": ["Alejandro Andrade-Lotero", "Lee Becker", "Joshua Southerland", "Scott Hellman"], "title": "Toward Subtrait-Level Model Explainability in Automated Writing Evaluation", "comment": "Accepted to National Council on Measurement in Education (NCME) 2025\n  Annual Meeting", "summary": "Subtrait (latent-trait components) assessment presents a promising path\ntoward enhancing transparency of automated writing scores. We prototype\nexplainability and subtrait scoring with generative language models and show\nmodest correlation between human subtrait and trait scores, and between\nautomated and human subtrait scores. Our approach provides details to demystify\nscores for educators and students.", "AI": {"tldr": "The paper explores the use of generative language models in providing transparent and explainable subtrait scoring for automated writing assessments.", "motivation": "The motivation behind the research is to enhance the transparency of automated writing scores through the assessment of subtraits.", "method": "The paper uses generative language models to prototype explainability and subtrait scoring in automated writing assessment.", "result": "The study shows a modest correlation between human subtrait and trait scores, as well as between automated and human subtrait scores.", "conclusion": "The approach is useful for providing greater transparency and understanding of automated writing scores to educators and students."}}
{"id": "2509.08232", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.08232", "abs": "https://arxiv.org/abs/2509.08232", "authors": ["Seongho Kim", "Sejong Ryu", "Hyoukjun You", "Je Hyeong Hong"], "title": "GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation", "comment": null, "summary": "Recent advancements in video anomaly detection (VAD) have enabled\nidentification of various criminal activities in surveillance videos, but\ndetecting fatal incidents such as shootings and stabbings remains difficult due\nto their rarity and ethical issues in data collection. Recognizing this\nlimitation, we introduce GTA-Crime, a fatal video anomaly dataset and\ngeneration framework using Grand Theft Auto 5 (GTA5). Our dataset contains\nfatal situations such as shootings and stabbings, captured from CCTV multiview\nperspectives under diverse conditions including action types, weather, time of\nday, and viewpoints. To address the rarity of such scenarios, we also release a\nframework for generating these types of videos. Additionally, we propose a\nsnippet-level domain adaptation strategy using Wasserstein adversarial training\nto bridge the gap between synthetic GTA-Crime features and real-world features\nlike UCF-Crime. Experimental results validate our GTA-Crime dataset and\ndemonstrate that incorporating GTA-Crime with our domain adaptation strategy\nconsistently enhances real world fatal violence detection accuracy. Our dataset\nand the data generation framework are publicly available at\nhttps://github.com/ta-ho/GTA-Crime.", "AI": {"tldr": "本文提出GTA-Crime数据集和一种片段级领域适应策略来提升致命暴力事件在监控视频中的检测准确性。", "motivation": "本研究的动机在于解决诸如枪击和刺伤等致命事件在监控视频中的检测难题，这些事件由于其罕见性和数据收集的道德问题使得检测变得困难。", "method": "本文提出了GTA-Crime，这是一个利用Grand Theft Auto 5制作的致命事件异常视频数据集及其生成框架，并提出了一种基于Wasserstein对抗训练的片段级领域适应策略来解决合成视频与现实世界视频特征之间的差异。", "result": "实验结果表明，结合GTA-Crime数据集和提出的领域适应策略可以提高现实世界中致命暴力行为的检测准确率。", "conclusion": "实验结果证明了该数据集的有效性，同时表明将GTA-Crime与领域适应策略结合能够显著提高现实中致命暴力事件的检测精度。"}}
{"id": "2509.08355", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.08355", "abs": "https://arxiv.org/abs/2509.08355", "authors": ["Yashad Samant", "Lee Becker", "Scott Hellman", "Bradley Behan", "Sarah Hughes", "Joshua Southerland"], "title": "Automatic Detection of Inauthentic Templated Responses in English Language Assessments", "comment": "Accepted to National Council on Measurement in Education (NCME) 2025\n  Annual Meeting", "summary": "In high-stakes English Language Assessments, low-skill test takers may employ\nmemorized materials called ``templates'' on essay questions to ``game'' or fool\nthe automated scoring system. In this study, we introduce the automated\ndetection of inauthentic, templated responses (AuDITR) task, describe a machine\nlearning-based approach to this task and illustrate the importance of regularly\nupdating these models in production.", "AI": {"tldr": "研究介绍了一个自动化检测模板化不真实回答的任务（AuDITR），并强调需定期更新模型。", "motivation": "低技能测试者可能通过使用模板化的素材来欺骗自动评分系统，因此这项研究旨在解决这一问题，并强调在实际应用中定期更新模型的重要性。", "method": "本研究介绍了一种基于机器学习的方法，用于检测高利害英语语言测评中的模板化不真实回答。", "result": "建立了基于机器学习的方法，并证明了在实际应用中定期更新模型的重要性。", "conclusion": "本研究的结果表明，采用机器学习方法能够有效地检测英语语言测评中的模板化回答，并且定期更新模型对于保持检测系统的有效性至关重要。"}}
{"id": "2509.08234", "categories": ["cs.CV", "cs.LG", "F.2.2; I.2.7"], "pdf": "https://arxiv.org/pdf/2509.08234", "abs": "https://arxiv.org/abs/2509.08234", "authors": ["Faisal Ahmed"], "title": "RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification", "comment": "10 pages, 5 figures", "summary": "Chest X-ray (CXR) imaging remains one of the most widely used diagnostic\ntools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia.\nRecent advances in deep learning, particularly Vision Transformers (ViTs), have\nshown strong potential for automated medical image analysis. However, most ViT\narchitectures are pretrained on natural images and require three-channel\ninputs, while CXR scans are inherently grayscale. To address this gap, we\npropose RepViT-CXR, a channel replication strategy that adapts single-channel\nCXR images into a ViT-compatible format without introducing additional\ninformation loss. We evaluate RepViT-CXR on three benchmark datasets. On the\nTB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%,\nsurpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy,\n99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0%\naccuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%,\noutperforming strong baselines including DCNN and VGG16. On the Shenzhen TB\ndataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a\nperformance improvement over previously reported CNN-based methods. These\nresults demonstrate that a simple yet effective channel replication strategy\nallows ViTs to fully leverage their representational power on grayscale medical\nimaging tasks. RepViT-CXR establishes a new state of the art for TB and\npneumonia detection from chest X-rays, showing strong potential for deployment\nin real-world clinical screening systems.", "AI": {"tldr": "研发了一个名为RepViT-CXR的技术，用于将单通道的胸部X光图像调整为适合Vision Transformers (ViTs) 处理的三通道输入格式，并在多个数据集上超越了当前最佳模型。", "motivation": "解决现有的Vision Transformers (ViTs) 预训练模型无法直接处理单通道的胸部X光图像的问题，提高肺部疾病检测的准确性。", "method": "提出了RepViT-CXR，采用通道复制策略，通过复用单通道的胸部X光图像来生成符合ViTs输入需求的三通道图像，最大限度地减少信息损失。", "result": "在TB-CXR、Pediatric Pneumonia、Shenzhen TB三个基准数据集上，RepViT-CXR的表现优于之前最佳的方法，包括Topo-CXR、DCNN、VGG16等。", "conclusion": "RepViT-CXR通过简单的通道复制策略，展示了在灰度医学图像分析上的优异表现，尤其是在结核病和肺炎的检测上，有助于临床筛查系统的实际部署。"}}
