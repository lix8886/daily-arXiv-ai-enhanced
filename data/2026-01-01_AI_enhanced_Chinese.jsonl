{"id": "2512.23710", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23710", "abs": "https://arxiv.org/abs/2512.23710", "authors": ["Zahra Abedi", "Richard M. K. van Dijk", "Gijs Wijnholds", "Tessa Verhoef"], "title": "Enriching Historical Records: An OCR and AI-Driven Approach for Database Integration", "comment": null, "summary": "This research digitizes and analyzes the Leidse hoogleraren en lectoren 1575-1815 books written between 1983 and 1985, which contain biographic data about professors and curators of Leiden University. It addresses the central question: how can we design an automated pipeline that integrates OCR, LLM-based interpretation, and database linking to harmonize data from historical document images with existing high-quality database records? We applied OCR techniques, generative AI decoding constraints that structure data extraction, and database linkage methods to process typewritten historical records into a digital format. OCR achieved a Character Error Rate (CER) of 1.08 percent and a Word Error Rate (WER) of 5.06 percent, while JSON extraction from OCR text achieved an average accuracy of 63 percent and, based on annotated OCR, 65 percent. This indicates that generative AI somewhat corrects low OCR performance. Our record linkage algorithm linked annotated JSON files with 94% accuracy and OCR-derived JSON files with 81%. This study contributes to digital humanities research by offering an automated pipeline for interpreting digitized historical documents, addressing challenges like layout variability and terminology differences, and exploring the applicability and strength of an advanced generative AI model.", "AI": {"tldr": "该研究开发了一种自动化流水线，结合OCR技术和生成式AI，成功将历史文档转换为数字格式并整合到现有数据库中，大大提高了数字人文研究的效率。", "motivation": "该研究旨在解决如何设计一个自动化流水线，结合OCR、基于LLM的解释和数据库链接方法，以整合历史文档图像与现有数据库记录的问题，从而推动数字人文研究的发展。", "method": "采用了OCR技术、生成式AI和数据库链接方法，将打字体的历史记录数字化，并进行数据整合。使用OCR技术和基于OCR的生成式AI来结构化提取数据，以及记录链接算法将转换后的数据与现有的数据库记录进行匹配。", "result": "该研究的目的是设计一个自动化流水线，结合OCR、基于LLM的解释和数据库链接方法，将历史文档图像中的数据与现有的高质量数据库记录整合。研究采用了OCR技术、生成式AI来约束数据提取以及数据库链接方法来处理古老的打字历史记录，将它们转换为数字格式。OCR技术实现了1.08%的字符错误率（CER）和5.06%的单词错误率（WER），而基于OCR文本的JSON提取达到了平均63%的准确率。基于注释的OCR达到了65%的准确率，表明生成式AI在一定程度上可以纠正较低的OCR性能。记录链接算法将注释的JSON文件链接的准确率为94%，而基于OCR提取的JSON文件链接准确率为81%。该研究对数字人文研究做出了贡献，提供了一个解释数字化历史文件的自动化管道，解决了布局变化和术语差异问题，并探讨了先进生成式AI模型的应用性和强度。", "conclusion": "该研究成功展示了如何通过自动化流水线将历史文档数字化并整合到现有的数据库记录中，这将有助于推动数字人文研究领域的发展。"}}
{"id": "2512.23711", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23711", "abs": "https://arxiv.org/abs/2512.23711", "authors": ["Paulo Cavalin", "Cassia Sanctos", "Marcelo Grave", "Claudio Pinhanez", "Yago Primerano"], "title": "CAT: A Metric-Driven Framework for Analyzing the Consistency-Accuracy Relation of LLMs under Controlled Input Variations", "comment": null, "summary": "We introduce \\textsc{CAT}, a framework designed to evaluate and visualize the \\emph{interplay} of \\emph{accuracy} and \\emph{response consistency} of Large Language Models (LLMs) under controllable input variations, using multiple-choice (MC) benchmarks as a case study. Current evaluation practices primarily focus on model capabilities such as accuracy or benchmark scores and, more recently, measuring consistency is being considered an essential property for deploying LLMs in high-stake, real-world applications. We argue in this paper that although both dimensions should still be evaluated independently, their inter-dependency also need to be considered for a more nuanced evaluation of LLMs. At the core of \\textsc{CAT} are the \\emph{Consistency-Accuracy Relation (CAR)} curves, which visualize how model accuracy varies with increasing consistency requirements, as defined by the \\emph{Minimum-Consistency Accuracy (MCA)} metric. We further propose the \\emph{Consistency-Oriented Robustness Estimate (CORE)} index, a global metric that combines the area and shape of the CAR curve to quantify the trade-off between accuracy and consistency. We present a practical demonstration of our framework across a diverse set of generalist and domain-specific LLMs, evaluated on multiple MC benchmarks. We also outline how \\textsc{CAT} can be extended beyond MC tasks to support long-form, open-ended evaluations through adaptable scoring functions.", "AI": {"tldr": "引入了\\textsc{CAT}框架，一种用于评估和可视化大规模语言模型（LLMs）在多项选择（MC）基准上准确性和一致性相互依赖性的方法。通过Consistency-Accuracy Relation (CAR)曲线和Consistency-Oriented Robustness Estimate (CORE)指数，提供了更细致的评估手段。", "motivation": "动机在于当前的评估实践主要集中在模型的能力上，如准确性或基准得分，最近则开始考虑一致性作为部署LLMs在高风险实际应用中的一个重要属性。作者认为，虽然这两个维度仍应独立评估，但应考虑它们间的相互依赖性来进行更加细致的评估。", "method": "提出了一种名为\\textsc{CAT}的框架，用于评估和可视化大规模语言模型（LLMs）在可控输入变化下的准确性与反应一致性之间的互动关系，采用了多项选择（MC）基准作为案例研究。使用了准确性和一致性之间的相互依赖性来进行更细致的LLMs评估。\\textsc{CAT}的核心是Consistency-Accuracy Relation (CAR)曲线，描绘了随着一致性要求增加，模型准确性如何变化的图表，这由Minimum-Consistency Accuracy (MCA)指标定义。此外，还提出了Consistency-Oriented Robustness Estimate (CORE)指数，一个全局指标，合并CAR曲线的面积和形状来量化准确性和一致性之间的权衡。", "result": "结果表明，可以通过\\textsc{CAT}框架在多种通用和特定领域的LLMs上进行评估，展示了其在多种MC基准上的实用性。框架也可以通过可适应的评分函数扩展到长格式和开放式评估任务中。", "conclusion": "通过集成准确性和一致性之间的相互作用，\\textsc{CAT}框架为不同LLMs的评估提供了更为详细和精确的方法，展示了其在多种任务中的实用性。"}}
{"id": "2512.23712", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23712", "abs": "https://arxiv.org/abs/2512.23712", "authors": ["Guanghui Wang", "Jinze Yu", "Xing Zhang", "Dayuan Jiang", "Yin Song", "Tomal Deb", "Xuefeng Liu", "Peiyang He"], "title": "STED and Consistency Scoring: A Framework for Evaluating LLM Structured Output Reliability", "comment": null, "summary": "Large Language Models (LLMs) are increasingly deployed for structured data generation, yet output consistency remains critical for production applications. We introduce a comprehensive framework for evaluating and improving consistency in LLM-generated structured outputs. Our approach combines: (1) STED (Semantic Tree Edit Distance), a novel similarity metric balancing semantic flexibility with structural strictness when comparing JSON outputs, and (2) a consistency scoring framework aggregating multiple STED measurements across repeated generations to quantify reliability. Through systematic experiments on synthetic datasets with controlled schema, expression, and semantic variations, we demonstrate STED achieves superior performance ($0.86-0.90$ similarity for semantic equivalents, $0.0$ for structural breaks) compared to existing metrics including TED, BERTScore, and DeepDiff. Applying our framework to benchmark six LLMs reveals significant variations: Claude-3.7-Sonnet demonstrates exceptional consistency, maintaining near-perfect structural reliability even at high temperatures ($T=0.9$), while models like Claude-3-Haiku and Nova-Pro exhibit substantial degradation requiring careful tuning. Our framework enables practical applications including targeted model selection for structured tasks, iterative prompt refinement for reproducible results, and diagnostic analysis to identify inconsistency root causes. This work provides theoretical foundations and practical tools for ensuring reliable structured output generation in LLM-based production systems.", "AI": {"tldr": "论文中提出了一种框架，结合STED相似性度量和多次生成度量的方法，用于提高LLMs生成结构化输出时的一致性。", "motivation": "目的是解决部署大规模语言模型产生结构化数据输出时的一致性问题，特别是在生产应用中，这是一致性尤为重要的一方面。", "method": "框架基于STED相似性指标来评估结构化输出，通过多次生成结果来量化一致性，利用精确的度量工具如STED来进行模型的性能分析。", "result": "该论文提出了一种全面的框架，用于评估和改进大语言模型（LLMs）生成的结构化数据输出的一致性。框架包括一个新的相似性度量方法STED（语义树编辑距离），能够衡量JSON输出之间的语义灵活性和结构严格度，以及一种通过多次生成结果聚合多个STED测量值以量化可靠性的框架。实验表明，STED在衡量语义等价和结构断裂时分别优于现有指标如TED、BERTScore和DeepDiff。框架的应用表明不同LLMs之间的一致性有显著差异。该框架为确保LLMs生成结构化数据输出的可靠性提供了理论基础和实用工具。", "conclusion": "该工作为保证基于LLMs的生产系统生成结构化输出的可靠性提供了理论基础和实用工具。"}}
{"id": "2512.23713", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23713", "abs": "https://arxiv.org/abs/2512.23713", "authors": ["Jahidul Islam", "Md Ataullha", "Saiful Azad"], "title": "PyBangla at BLP-2025 Task 2: Enhancing Bangla-to-Python Code Generation with Iterative Self-Correction and Multilingual Agents", "comment": "6 Pages", "summary": "LLMs excel at code generation from English prompts, but this progress has not extended to low-resource languages. We address Bangla-to-Python code generation by introducing BanglaCodeAct, an agent-based framework that leverages multi-agent prompting and iterative self-correction. Unlike prior approaches relying on task-specific fine-tuning, BanglaCodeAct employs an open-source multilingual LLM within a Thought-Code-Observation loop, enabling dynamic generation, testing, and refinement of code from Bangla instructions. We benchmark several small-parameter open-source LLMs and evaluate their effectiveness on the mHumanEval dataset for Bangla NL2Code. Our results show that Qwen3-8B, when deployed with BanglaCodeAct, achieves the best performance, with pass@1 accuracy of 94.0\\% on the development set and 71.6\\% on the blind test set. These results establish a new benchmark for Bangla-to-Python translation and highlight the potential of agent-based reasoning for reliable code generation in low-resource languages. Experimental scripts are publicly available at github.com/jahidulzaid/PyBanglaCodeActAgent.", "AI": {"tldr": "研究提出了BanglaCodeAct框架，通过多智能体提示和迭代自我纠正来进行孟加拉语到Python代码生成，使用开源多语言LLM在Thought-Code-Observation循环中动态生成、测试和优化代码。", "motivation": "解决在资源较少的语言中，LLM在从特定语言到代码的生成上表现不佳的问题，特别是针对孟加拉语到Python的代码生成。", "method": "引入BanglaCodeAct框架，使用开源多语言LLM，而不是依赖特定任务的微调，通过多智能体提示和迭代自我纠正进行动态的代码生成、测试和优化。", "result": "通过在mHumanEval数据集上进行评估，Qwen3-8B搭配BanglaCodeAct实现了最佳性能，在开发集上通过@1准确率为94%，在盲测试集上为71.6%。", "conclusion": "结果表明了BanglaCodeAct框架在孟加拉语到Python代码生成中的有效性，并展示多智能体推理在低资源语言中可靠代码生成的潜力。"}}
{"id": "2512.23786", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.23786", "abs": "https://arxiv.org/abs/2512.23786", "authors": ["Ankan Aich", "Yangming Lee"], "title": "Leveraging Synthetic Priors for Monocular Depth Estimation in Specular Surgical Environments", "comment": null, "summary": "Accurate Monocular Depth Estimation (MDE) is critical for robotic surgery but remains fragile in specular, fluid-filled endoscopic environments. Existing self-supervised methods, typically relying on foundation models trained with noisy real-world pseudo-labels, often suffer from boundary collapse on thin surgical tools and transparent surfaces. In this work, we address this by leveraging the high-fidelity synthetic priors of the Depth Anything V2 architecture, which inherently captures precise geometric details of thin structures. We efficiently adapt these priors to the medical domain using Dynamic Vector Low-Rank Adaptation (DV-LORA), minimizing the parameter budget while bridging the synthetic-to-real gap. Additionally, we introduce a physically-stratified evaluation protocol on the SCARED dataset to rigorously quantify performance in high-specularity regimes often masked by aggregate metrics. Our approach establishes a new state-of-the-art, achieving an accuracy (< 1.25) of 98.1% and reducing Squared Relative Error by over 17% compared to established baselines, demonstrating superior robustness in adverse surgical lighting.", "AI": {"tldr": "使用高保真合成先验技术和动态向量低秩适应方法，提高单目深度估计在医疗环境中，特别是在高光泽条件下的准确性。", "motivation": "单目深度估计在机器人手术中非常重要，但在充满流体和高光泽的内窥镜环境中的表现仍然脆弱，容易在薄手术工具和透明表面上产生边界坍塌问题。", "method": "本文提出一种利用Depth Anything V2架构的高保真合成先验知识，并通过动态向量低秩适应（DV-LORA）方法将其有效应用于医疗领域，以解决单目深度估计中在高光泽环境下的边界坍塌问题。", "result": "该方法在SCARED数据集上建立了新的标准，在高度光泽环境中达到98.1%的精度（< 1.25）并降低了17%的平均平方相对误差，展示了在恶劣手术照明条件下的优越鲁棒性。", "conclusion": "该研究通过利用高保真合成先验和动态向量低秩适应方法有效解决了在高光泽环境下的薄工具边界坍塌问题，特别是在手术照明条件恶劣时，显示了更高的鲁棒性和准确性。"}}
{"id": "2512.23714", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23714", "abs": "https://arxiv.org/abs/2512.23714", "authors": ["Tingwei Xie", "Tianyi Zhou", "Yonghong Song"], "title": "PharmaShip: An Entity-Centric, Reading-Order-Supervised Benchmark for Chinese Pharmaceutical Shipping Documents", "comment": "5 pages, 4 figures", "summary": "We present PharmaShip, a real-world Chinese dataset of scanned pharmaceutical shipping documents designed to stress-test pre-trained text-layout models under noisy OCR and heterogeneous templates. PharmaShip covers three complementary tasks-sequence entity recognition (SER), relation extraction (RE), and reading order prediction (ROP)-and adopts an entity-centric evaluation protocol to minimize confounds across architectures. We benchmark five representative baselines spanning pixel-aware and geometry-aware families (LiLT, LayoutLMv3-base, GeoLayoutLM and their available RORE-enhanced variants), and standardize preprocessing, splits, and optimization. Experiments show that pixels and explicit geometry provide complementary inductive biases, yet neither alone is sufficient: injecting reading-order-oriented regularization consistently improves SER and EL and yields the most robust configuration, while longer positional coverage stabilizes late-page predictions and reduces truncation artifacts. ROP is accurate at the word level but challenging at the segment level, reflecting boundary ambiguity and long-range crossings. PharmaShip thus establishes a controlled, reproducible benchmark for safety-critical document understanding in the pharmaceutical domain and highlights sequence-aware constraints as a transferable bias for structure modeling. We release the dataset at https://github.com/KevinYuLei/PharmaShip.", "AI": {"tldr": "PharmaShip是一个用于评估文本布局模型在处理嘈杂OCR和异构模板文档时性能的药品运输文件数据集，它涵盖了SER、RE和ROP任务，实验表明阅读顺序导向的正则化是有益的。", "motivation": "为了建立一个受控的、可重现的制药领域的文档理解基准，并强调序列为关注点的约束作为结构建模的可转移偏置，我们创建了PharmaShip数据集。", "method": "我们提出了PharmaShip，这是一个扫描的药品运输文件的真实世界数据集，用于评估预训练的文本布局模型在嘈杂的OCR和异构模板下的性能。PharmaShip涵盖了三个互补任务：序列实体识别（SER）、关系抽取（RE）和阅读顺序预测（ROP），并采用实体为中心的评估协议以减少架构间的混淆。", "result": "实验显示，像素和显式的几何结构提供了互补的归纳偏置，但单独使用任何一个是不够的：注入阅读顺序导向的正则化改善了SER和EL，并提供了最稳定的效果，而较长的位置覆盖则稳定了页面末尾的预测并减少了截断的效果。ROP在单词级表现准确但在段落级具有挑战性，反映了边界模糊和长距离交叉的问题。", "conclusion": "PharmaShip为制药领域的文档理解建立了一个受控的、可重复的基准，并表明序列意识的约束是一种可转移的建模偏置。"}}
{"id": "2512.23819", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23819", "abs": "https://arxiv.org/abs/2512.23819", "authors": ["Surya Rayala", "Marcos Quinones-Grueiro", "Naveeduddin Mohammed", "Ashwin T S", "Benjamin Goldberg", "Randall Spain", "Paige Lawton", "Gautam Biswas"], "title": "Video-Based Performance Evaluation for ECR Drills in Synthetic Training Environments", "comment": "14 pages, 9 figures, I/ITSEC-2025", "summary": "Effective urban warfare training requires situational awareness and muscle memory, developed through repeated practice in realistic yet controlled environments. A key drill, Enter and Clear the Room (ECR), demands threat assessment, coordination, and securing confined spaces. The military uses Synthetic Training Environments that offer scalable, controlled settings for repeated exercises. However, automatic performance assessment remains challenging, particularly when aiming for objective evaluation of cognitive, psychomotor, and teamwork skills. Traditional methods often rely on costly, intrusive sensors or subjective human observation, limiting scalability and accuracy. This paper introduces a video-based assessment pipeline that derives performance analytics from training videos without requiring additional hardware. By utilizing computer vision models, the system extracts 2D skeletons, gaze vectors, and movement trajectories. From these data, we develop task-specific metrics that measure psychomotor fluency, situational awareness, and team coordination. These metrics feed into an extended Cognitive Task Analysis (CTA) hierarchy, which employs a weighted combination to generate overall performance scores for teamwork and cognition. We demonstrate the approach with a case study of real-world ECR drills, providing actionable, domain specific metrics that capture individual and team performance. We also discuss how these insights can support After Action Reviews with interactive dashboards within Gamemaster and the Generalized Intelligent Framework for Tutoring (GIFT), providing intuitive and understandable feedback. We conclude by addressing limitations, including tracking difficulties, ground-truth validation, and the broader applicability of our approach. Future work includes expanding analysis to 3D video data and leveraging video analysis to enable scalable evaluation within STEs.", "AI": {"tldr": "该论文提出了一种基于视频的评估管道，用于从训练视频中提取作战表现分析，无需额外硬件，适用于城市巷战训练环境。", "motivation": "传统的表现评估依赖于昂贵的传感器或主观观察，这限制了可扩展性和准确性。因此，需要一种自动且客观的评估方法以适应合成训练环境。", "method": "使用计算机视觉模型从训练视频中抽取2D骨架、视线向量和运动轨迹，再转化为衡量个体和团队表现的任务特定指标。", "result": "通过实际ECR演习的案例研究，证明了该方法可以提供可行动的、领域特定的性能度量，并支持行动后复盘。", "conclusion": "该方法提供了直观且易理解的性能反馈，但存在追踪困难、地面真实验证和方法广义适用性等方面的局限性，未来工作计划扩大至3D视频分析。"}}
{"id": "2512.23716", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23716", "abs": "https://arxiv.org/abs/2512.23716", "authors": ["Toshiyuki Shigemura"], "title": "Noise-Driven Persona Formation in Reflexive Neural Language Generation", "comment": "324 pages, 9 figures (Figure 7 intentionally skipped), with Appendices A-I. This manuscript presents a computational framework for noise-driven persona formation in neural language generation, analyzing 152 generation cycles using GPT-5.1 with stochastic noise seeds generated by Microsoft Copilot. Primary category: cs.CL", "summary": "This paper introduces the Luca-Noise Reflex Protocol (LN-RP), a computational framework for analyzing noise-driven persona emergence in large language models. By injecting stochastic noise seeds into the initial generation state, we observe nonlinear transitions in linguistic behavior across 152 generation cycles. Our results reveal three stable persona modes with distinct entropy signatures, and demonstrate that external noise sources can reliably induce phase transitions in reflexive generation dynamics. Quantitative evaluation confirms consistent persona retention and significant differences across modes (p < 0.01). The protocol provides a reproducible method for studying reflexive generation, emergent behavior, and longrange linguistic coherence in LLMs.", "AI": {"tldr": "The paper presents LN-RP, a framework for observing the emergence of different personas in large language models through the injection of noise, discovering three stable persona modes that demonstrate consistent behavior.", "motivation": "To study how noise can drive changes in the linguistic behavior of large language models, contributing to understanding their emergent behavior and coherence.", "method": "Injecting stochastic noise into the initial generation state of the models and monitoring the linguistic behavior over 152 generation cycles.", "result": "Three distinct persona modes with different entropy signatures were identified, showing that noise can induce specific transitions in the model's output, with significant differences confirmed by quantitative evaluation.", "conclusion": "The LN-RP protocol offers a reproducible method for investigating persona emergence, reflexive generation dynamics, and long-range coherence in large language models."}}
{"id": "2512.23851", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23851", "abs": "https://arxiv.org/abs/2512.23851", "authors": ["Lvmin Zhang", "Shengqu Cai", "Muyang Li", "Chong Zeng", "Beijia Lu", "Anyi Rao", "Song Han", "Gordon Wetzstein", "Maneesh Agrawala"], "title": "Pretraining Frame Preservation in Autoregressive Video Memory Compression", "comment": "https://github.com/lllyasviel/PFP", "summary": "We present PFP, a neural network structure to compress long videos into short contexts, with an explicit pretraining objective to preserve the high-frequency details of single frames at arbitrary temporal positions. The baseline model can compress a 20-second video into a context at about 5k length, where random frames can be retrieved with perceptually preserved appearances. Such pretrained models can be directly fine-tuned as memory encoders for autoregressive video models, enabling long history memory with low context cost and relatively low fidelity loss. We evaluate the framework with ablative settings and discuss the trade-offs of possible neural architecture designs.", "AI": {"tldr": "PFP is a neural network designed to compress long videos into short contexts, focusing on preserving high-frequency details of individual frames.", "motivation": "To enable efficient compression of long videos with maintenance of perceptual detail, facilitating better video memory encoding capabilities with lower context costs.", "method": "A neural network, PFP, with specific pretraining to maintain high-frequency details of single video frames, allowing compression into a short context that retains the appearance of random frames.", "result": "The baseline model effectively compresses 20-second videos into contexts about 5k in length, with preserved perceptual details of frames. Fine-tuning of these models as memory encoders for autoregressive video models results in effective long history memory with manageable fidelity loss.", "conclusion": "PFP offers a novel approach to video compression that preserves key visual detail and can be effectively applied to enhance memory encoding in video modeling."}}
{"id": "2512.23717", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23717", "abs": "https://arxiv.org/abs/2512.23717", "authors": ["Shenzhe Zhu"], "title": "HarmTransform: Transforming Explicit Harmful Queries into Stealthy via Multi-Agent Debate", "comment": null, "summary": "Large language models (LLMs) are equipped with safety mechanisms to detect and block harmful queries, yet current alignment approaches primarily focus on overtly dangerous content and overlook more subtle threats. However, users can often disguise harmful intent through covert rephrasing that preserves malicious objectives while appearing benign, which creates a significant gap in existing safety training data. To address this limitation, we introduce HarmTransform, a multi-agent debate framework for systematically transforming harmful queries into stealthier forms while preserving their underlying harmful intent. Our framework leverages iterative critique and refinement among multiple agents to generate high-quality, covert harmful query transformations that can be used to improve future LLM safety alignment. Experiments demonstrate that HarmTransform significantly outperforms standard baselines in producing effective query transformations. At the same time, our analysis reveals that debate acts as a double-edged sword: while it can sharpen transformations and improve stealth, it may also introduce topic shifts and unnecessary complexity. These insights highlight both the promise and the limitations of multi-agent debate for generating comprehensive safety training data.", "AI": {"tldr": "提出了HarmTransform框架，利用多智能体辩论将有害查询转化为更隐蔽的形式，改进LLM的安全对齐。", "motivation": "当前的安全机制主要关注明显的危险内容，而忽视了更微妙的威胁。用户常常通过迂回的措辞隐藏有害意图。", "method": "HarmTransform框架通过多智能体间的迭代批评和改进，系统地将有害查询转化为更隐蔽的形式。", "result": "实验表明，HarmTransform框架在生成有效的查询转换方面优于标准基线。", "conclusion": "多智能体辩论可以在提高变革效果和隐蔽性的同时，也可能导致话题转移和不必要的复杂性。"}}
{"id": "2512.23860", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23860", "abs": "https://arxiv.org/abs/2512.23860", "authors": ["Qucheng Peng", "Hongfei Xue", "Pu Wang", "Chen Chen"], "title": "Lifelong Domain Adaptive 3D Human Pose Estimation", "comment": "Accepted by AAAI 2026", "summary": "3D Human Pose Estimation (3D HPE) is vital in various applications, from person re-identification and action recognition to virtual reality. However, the reliance on annotated 3D data collected in controlled environments poses challenges for generalization to diverse in-the-wild scenarios. Existing domain adaptation (DA) paradigms like general DA and source-free DA for 3D HPE overlook the issues of non-stationary target pose datasets. To address these challenges, we propose a novel task named lifelong domain adaptive 3D HPE. To our knowledge, we are the first to introduce the lifelong domain adaptation to the 3D HPE task. In this lifelong DA setting, the pose estimator is pretrained on the source domain and subsequently adapted to distinct target domains. Moreover, during adaptation to the current target domain, the pose estimator cannot access the source and all the previous target domains. The lifelong DA for 3D HPE involves overcoming challenges in adapting to current domain poses and preserving knowledge from previous domains, particularly combating catastrophic forgetting. We present an innovative Generative Adversarial Network (GAN) framework, which incorporates 3D pose generators, a 2D pose discriminator, and a 3D pose estimator. This framework effectively mitigates domain shifts and aligns original and augmented poses. Moreover, we construct a novel 3D pose generator paradigm, integrating pose-aware, temporal-aware, and domain-aware knowledge to enhance the current domain's adaptation and alleviate catastrophic forgetting on previous domains. Our method demonstrates superior performance through extensive experiments on diverse domain adaptive 3D HPE datasets.", "AI": {"tldr": "本文提出了一种新的任务：终身领域自适应的3D人体姿态估计，以处理目标数据集的非静止性及知识遗忘问题。采用了一种包含3D姿态生成器、2D姿态判别器和3D姿态估计器的GAN框架，实验结果显示该方法在多种域适应3D HPE数据集上表现优越。", "motivation": "现有的3D人体姿态估计方法依赖于标注的3D数据，难以在多样化的现实场景中进行泛化。文章指出当前的领域适应方法忽略了目标数据集的非静止性以及知识遗忘的问题。", "method": "文章提出了一种新的模型框架，采用包含3D姿态生成器、2D姿态判别器和3D姿态估计器的GAN框架，创新性地集成了姿态感知、时间感知和领域感知的知识，以适应当前领域并减少对之前领域的知识遗忘。", "result": "经实验验证，本文的方法在多种域适应3D HPE数据集中表现出色。", "conclusion": "本文提出的方法为解决3D人体姿态估计中的领域适应挑战提供了有效的方法，尤其是在处理数据集的非静止性和保持领域知识方面。"}}
{"id": "2512.23722", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.23722", "abs": "https://arxiv.org/abs/2512.23722", "authors": ["Adam Kamel", "Tanish Rastogi", "Michael Ma", "Kailash Ranganathan", "Kevin Zhu"], "title": "Emergent World Beliefs: Exploring Transformers in Stochastic Games", "comment": "Accepted at NeurIPS 2025 Mechanistic Interpretability Workshop", "summary": "Transformer-based large language models (LLMs) have demonstrated strong reasoning abilities across diverse fields, from solving programming challenges to competing in strategy-intensive games such as chess. Prior work has shown that LLMs can develop emergent world models in games of perfect information, where internal representations correspond to latent states of the environment. In this paper, we extend this line of investigation to domains of incomplete information, focusing on poker as a canonical partially observable Markov decision process (POMDP). We pretrain a GPT-style model on Poker Hand History (PHH) data and probe its internal activations. Our results demonstrate that the model learns both deterministic structure, such as hand ranks, and stochastic features, such as equity, without explicit instruction. Furthermore, by using primarily nonlinear probes, we demonstrated that these representations are decodeable and correlate with theoretical belief states, suggesting that LLMs are learning their own representation of the stochastic environment of Texas Hold'em Poker.", "AI": {"tldr": "研究显示，通过在扑克手历史数据上预训练的GPT式模型能够学习确定性结构和随机性特征，这意味着大型语言模型能在信息不完全环境中自发学习环境的表示。", "motivation": "扩展之前关于大型语言模型在完全信息游戏中形成世界模型的工作，探讨在信息不完全的游戏（如德州扑克）中的表现。", "method": "通过在Poker Hand History (PHH) 数据上预训练一种GPT式的模型，并探测其内部激活来进行研究。", "result": "模型在没有明确指导的情况下学习到了手牌等级等确定性结构和牌局公正性等随机特征，并通过非线性探测展示了这些表示可以解码，且与理论中的信念状态相关。", "conclusion": "大型语言模型能够学习自己在不完全信息环境如德州扑克中的表示。"}}
{"id": "2512.23894", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23894", "abs": "https://arxiv.org/abs/2512.23894", "authors": ["Krithika Iyer", "Austin Tapp", "Athelia Paulli", "Gabrielle Dickerson", "Syed Muhammad Anwar", "Natasha Lepore", "Marius George Linguraru"], "title": "MRI-to-CT Synthesis With Cranial Suture Segmentations Using A Variational Autoencoder Framework", "comment": null, "summary": "Quantifying normative pediatric cranial development and suture ossification is crucial for diagnosing and treating growth-related cephalic disorders. Computed tomography (CT) is widely used to evaluate cranial and sutural deformities; however, its ionizing radiation is contraindicated in children without significant abnormalities. Magnetic resonance imaging (MRI) offers radiation free scans with superior soft tissue contrast, but unlike CT, MRI cannot elucidate cranial sutures, estimate skull bone density, or assess cranial vault growth. This study proposes a deep learning driven pipeline for transforming T1 weighted MRIs of children aged 0.2 to 2 years into synthetic CTs (sCTs), predicting detailed cranial bone segmentation, generating suture probability heatmaps, and deriving direct suture segmentation from the heatmaps. With our in-house pediatric data, sCTs achieved 99% structural similarity and a Frechet inception distance of 1.01 relative to real CTs. Skull segmentation attained an average Dice coefficient of 85% across seven cranial bones, and sutures achieved 80% Dice. Equivalence of skull and suture segmentation between sCTs and real CTs was confirmed using two one sided tests (TOST p < 0.05). To our knowledge, this is the first pediatric cranial CT synthesis framework to enable suture segmentation on sCTs derived from MRI, despite MRI's limited depiction of bone and sutures. By combining robust, domain specific variational autoencoders, our method generates perceptually indistinguishable cranial sCTs from routine pediatric MRIs, bridging critical gaps in non invasive cranial evaluation.", "AI": {"tldr": "本研究提出了一种基于深度学习的管道，可将0.2至2岁儿童的T1加权MRI转换为合成CT（sCT），并预测详细的颅骨分割和缝线概率热图，实现从热图直接分割出缝线。合成CT达到与真实CT的高度相似性。这是第一个儿科颅骨CT合成框架，可从MRI获取缝线分割。", "motivation": "量化解剖学上的儿童颅骨发育和缝线骨化对于诊断和治疗生长相关的头部疾病非常重要。CT扫描广泛应用但辐射安全，MRI因其无辐射和软组织对比度高而成为替代选项，但由于不能揭示颅缝，不能估算颅骨密度或评估颅腔生长，因此缺乏适用性。本研究旨在克服MRI的这一限制。", "method": "该研究提出了一种基于深度学习的管道，将T1加权MRI转换为合成CT（sCT），实现了颅骨的详细分割与缝线概率热图的生成，通过热图进行直接的缝线分割。", "result": "研究结果表明，sCT与真实CT的结构相似度达到99%，获得了显著的偏斜颅骨和颅缝分割精度。", "conclusion": "本研究通过使用领域特定的变分自动编码器生成了从常规儿科MRI得出的视觉上难以区分的颅骨sCT，填补了无创性颅骨评估的关键空白。"}}
{"id": "2512.23732", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23732", "abs": "https://arxiv.org/abs/2512.23732", "authors": ["Anwar Alajmi", "Gabriele Pergola"], "title": "When in Doubt, Deliberate: Confidence-Based Routing to Expert Debate for Sexism Detection", "comment": null, "summary": "Sexist content online increasingly appears in subtle, context-dependent forms that evade traditional detection methods. Its interpretation often depends on overlapping linguistic, psychological, legal, and cultural dimensions, which produce mixed and sometimes contradictory signals, even in annotated datasets. These inconsistencies, combined with label scarcity and class imbalance, result in unstable decision boundaries and cause fine-tuned models to overlook subtler, underrepresented forms of harm. Together, these limitations point to the need for a design that explicitly addresses the combined effects of (i) underrepresentation, (ii) noise, and (iii) conceptual ambiguity in both data and model predictions. To address these challenges, we propose a two-stage framework that unifies (i) targeted training procedures to adapt supervision to scarce and noisy data with (ii) selective, reasoning-based inference to handle ambiguous or borderline cases. Our training setup applies class-balanced focal loss, class-aware batching, and post-hoc threshold calibration to mitigate label imbalance and noisy supervision. At inference time, a dynamic routing mechanism classifies high-confidence cases directly and escalates uncertain instances to a novel \\textit{Collaborative Expert Judgment} (CEJ) module, which prompts multiple personas and consolidates their reasoning through a judge model. Our approach achieves state-of-the-art results across several benchmarks, with a +2.72\\% improvement in F1 on the EXIST 2025 Task 1.1, and a gains of +4.48\\% and +1.30\\% on the EDOS Tasks A and B, respectively.", "AI": {"tldr": "该研究提出了一个新的框架来应对性别歧视内容线上检测挑战，特别是在数据稀缺、噪声和概念模糊的情况下，并在多个基准测试中获得了优异的结果。", "motivation": "在线上不断增加出现的微妙的、依赖于上下文背景的性别歧视内容，由于其解读取决于重叠的语言、心理、法律和文化维度，以至于在注释数据集中都产生了混合或有时相互矛盾的信号。这些不一致性导致了训练模型的决策边界不稳定，可能会忽略更微妙的、不够代表的伤害形式。", "method": "本文提出了一种两阶段框架，该框架结合了（i）针对稀缺和嘈杂数据的适应性训练过程和（ii）推理时处理模糊或边缘案例的选择性和基于推理的方法。在训练设置中，使用了类平衡的焦点损失，类感知批量处理和后验阈值校准来缓解标签不平衡和嘈杂监控的问题。在推理时间，通过动态路由机制直接分类高置信度的案例，并将不确定的实例升级到一个新的“协作专家判断”（CEJ）模块，该模块通过法官模型来整合多个角色的推理结果。", "result": "该方法在几个基准上达到了最先进的结果，包括在EXIST 2025任务1.1中提高了2.72%的F1分，在EDOS任务A和B上分别提高了4.48%和1.30%。", "conclusion": "通过我们的方法，成功改善了对性别歧视内容检测的性能，在评估的数据集上，相对于现有方法有了显著的提升，证明了方法的有效性。"}}
{"id": "2512.23903", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.23903", "abs": "https://arxiv.org/abs/2512.23903", "authors": ["Charith Wickrema", "Eliza Mace", "Hunter Brown", "Heidys Cabrera", "Nick Krall", "Matthew O'Neill", "Shivangi Sarkar", "Lowell Weissman", "Eric Hughes", "Guido Zarrella"], "title": "Scaling Remote Sensing Foundation Models: Data Domain Tradeoffs at the Peta-Scale", "comment": null, "summary": "We explore the scaling behaviors of artificial intelligence to establish practical techniques for training foundation models on high-resolution electro-optical (EO) datasets that exceed the current state-of-the-art scale by orders of magnitude. Modern multimodal machine learning (ML) applications, such as generative artificial intelligence (GenAI) systems for image captioning, search, and reasoning, depend on robust, domain-specialized encoders for non-text modalities. In natural-image domains where internet-scale data is plentiful, well-established scaling laws help optimize the joint scaling of model capacity, training compute, and dataset size. Unfortunately, these relationships are much less well-understood in high-value domains like remote sensing (RS). Using over a quadrillion pixels of commercial satellite EO data and the MITRE Federal AI Sandbox, we train progressively larger vision transformer (ViT) backbones, report success and failure modes observed at petascale, and analyze implications for bridging domain gaps across additional RS modalities. We observe that even at this scale, performance is consistent with a data limited regime rather than a model parameter-limited one. These practical insights are intended to inform data-collection strategies, compute budgets, and optimization schedules that advance the future development of frontier-scale RS foundation models.", "AI": {"tldr": "研究探索了人工智能的扩展行为，利用高分辨率电光数据集训练基础模型，并发现即使在大规模数据下，性能仍然受限于数据量而非模型参数量。", "motivation": "现有的多模态机器学习应用，如图像描述、搜索和推理等，依赖于健壮且专用于非文本模态的编码器。针对卫星遥感等高价值领域，需要更好地理解数据规模与模型性能之间的关系。", "method": "使用超过一千兆亿像素的商业卫星电光数据以及MITRE联邦AI沙盒，训练逐步增大的视觉变压器作为骨干网络，并报告了成功和失败模式。", "result": "发现即使是大规模数据集，模型性能仍主要受限于数据量，而不是模型的参数量。", "conclusion": "这些实用见解被用于指导数据收集策略、计算预算和优化计划，以推进前沿遥感基础模型的发展。"}}
