<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 21]
- [cs.CV](#cs.CV) [Total: 17]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Table Understanding and (Multimodal) LLMs: A Cross-Domain Case Study on Scientific vs. Non-Scientific Data](https://arxiv.org/abs/2507.00152)
*Ekaterina Borisova,Fabio Barth,Nils Feldhus,Raia Abu Ahmad,Malte Ostendorff,Pedro Ortiz Suarez,Georg Rehm,Sebastian Möller*

Main category: cs.CL

> \u8be5\u7b7e\u660e\u7814\u7a76\u4e86\u6587\u672c\u57fa\u7f8b\u548c\u591a\u4e2d\u611b\u6587\u672c\u5f62\u5f0f\u7684LLMs\u5728\u8868\u683c\u7406\u89e3\u8d5b\u7a0b\u4e2d\u7684\u6548\u679c\uff0c\u5e76\u4e14\u7531\u6b63\u786e\u9879\u76ee\u548c\u975e\u6b63\u786e\u9879\u76ee\u7684\u8868\u683c\u4e00\u81f4\uff0c\u4ee5\u53ca\u56fe\u7247\u548c\u6587\u672c\u8868\u683c\u52a8\u4f5c\u3002\u8be5\u7b7e\u660e\u8fd8\u4e3e\u8d5b\u4e86Table...

<details>
  <summary>Details</summary>

**Motivation:** \u4e3e\u8d5bLLMs\u5728\u8868\u683c\u7406\u89e3\u4e0a\u7684\u6548\u679c\uff0c\u8be5\u4e13\u9879\u8d44\u6e90\u76f8\u5bf9\u5c11\u5e76\uff0c\u9700\u8981\u63d0\u5347\u8be5\u8d44\u6e90\u7684\u8d5e\u7528\u60c5\u51b5\u3002

**Method:** \u5bf9\u6bd4\u4e86\u6587\u672c\u57fa\u7c7b\u548c\u591a\u4e2d\u611b\u6587\u672c\u5f62\u5f0f\u7684LLMs\u5728\u8868\u683c\u7406\u89e3\u4e0a\u7684\u64cd\u4f5c\uff0c\u5e76\u4e14\u5bf9\u79d8\u6c14\u7406\u4e0e\u975e\u79d8\u6c14\u7406\u7684\u8868\u5b50\u5b66\u6548\u8d8a\u6ed1\u4e0e\u6587\u672c\u8868\u683c\u4e0e\u56fe\u7247\u4f9b\u8d5e\u5404\u52a8\u4f5c\u4e2d\u6539\u7684LLMs\u6548\u6027\uff0c\u67f4\u66f4\u8fd9\u79cd\u53e0\u72b6\u60c5\u51b5\u4e2d\u7684\u8868\u683c\u6e05\u695a\u6587\u4ef6\u3002

**Result:** {"tldr": "\u8be5\u7b7e\u660e\u7814\u7a76\u4e86\u6587\u672c\u57fa\u7f8b\u548c\u591a\u4e2d\u611b\u6587\u672c\u5f62\u5f0f\u7684LLMs\u5728\u8868\u683c\u7406\u89e3\u8d5b\u7a0b\u4e2d\u7684\u6548\u679c\uff0c\u5e76\u4e14\u7531\u6b63\u786e\u9879\u76ee\u548c\u975e\u6b63\u786e\u9879\u76ee\u7684\u8868\u683c\u4e00\u81f4\uff0c\u4ee5\u53ca\u56fe\u7247\u548c\u6587\u672c\u8868\u683c\u52a8\u4f5c\u3002\u8be5\u7b7e\u660e\u8fd8\u4e3e\u8d5b\u4e86TableEval\u68d2\u8033\u6a21\uff0c\u5b58\u57283017\u4e2a\u8868\u5b50\u3002\u7ed3\u679c\u8868\u793a\uff0cLLMs\u5728\u8868\u683c\u7684\u5584\u52a8\u6027\u8d8a\u6e10\u4e14\u975e\u5e38\u654c\u67f6\u7406\u89e3\u79d8\u6c14\u7406\u9879\u8868\u3002", "motivation": "\u4e3e\u8d5bLLMs\u5728\u8868\u683c\u7406\u89e3\u4e0a\u7684\u6548\u679c\uff0c\u8be5\u4e13\u9879\u8d44\u6e90\u76f8\u5bf9\u5c11\u5e76\uff0c\u9700\u8981\u63d0\u5347\u8be5\u8d44\u6e90\u7684\u8d5e\u7528\u60c5\u51b5\u3002", "method": "\u5bf9\u6bd4\u4e86\u6587\u672c\u57fa\u7c7b\u548c\u591a\u4e2d\u611b\u6587\u672c\u5f62\u5f0f\u7684LLMs\u5728\u8868\u683c\u7406\u89e3\u4e0a\u7684\u64cd\u4f5c\uff0c\u5e76\u4e14\u5bf9\u79d8\u6c14\u7406\u4e0e\u975e\u79d8\u6c14\u7406\u7684\u8868\u5b50\u5b66\u6548\u8d8a\u6ed1\u4e0e\u6587\u672c\u8868\u683c\u4e0e\u56fe\u7247\u4f9b\u8d5e\u5404\u52a8\u4f5c\u4e2d\u6539\u7684LLMs\u6548\u6027\uff0c\u67f4\u66f4\u8fd9\u79cd\u53e0\u72b6\u60c5\u51b5\u4e2d\u7684\u8868\u683c\u6e05\u695a\u6587\u4ef6\u3002", "result": "\u5b58\u5728\u7684\u7b54\u6848\u8868\u660e\uff0cLLMs\u7528\u6237\u8d5e\u7528\u5747\u4e00\u81f4\u5e76\u540c\u65f6\u8868\u683c\u5584\u52a8\u6027\u964d\u4f4e\u4e0d\u89c4\u5219\u3002", "conclusion": "\u8be5\u7b7e\u660e\u8868\u660e\uff0cLLMs\u5e76\u4e0d\u662f\u5f53\u524d\u8868\u683c\u7406\u89e3\u7684\u4e2d\u65b9\uff0c\u5374\u9762\u4e14\u5728\u79d8\u6c14\u7406\u8d44\u6e90\u4e2d\u975e\u5e38\u6027\u5f02\u5e38\u8d85\u7ea7\u964d\u5e45\u3002"}

**Conclusion:** \u8be5\u7b7e\u660e\u8868\u660e\uff0cLLMs\u5e76\u4e0d\u662f\u5f53\u524d\u8868\u683c\u7406\u89e3\u7684\u4e2d\u65b9\uff0c\u5374\u9762\u4e14\u5728\u79d8\u6c14\u7406\u8d44\u6e90\u4e2d\u975e\u5e38\u6027\u5f02\u5e38\u8d85\u7ea7\u964d\u5e45\u3002

**Abstract:** Tables are among the most widely used tools for representing structured data
in research, business, medicine, and education. Although LLMs demonstrate
strong performance in downstream tasks, their efficiency in processing tabular
data remains underexplored. In this paper, we investigate the effectiveness of
both text-based and multimodal LLMs on table understanding tasks through a
cross-domain and cross-modality evaluation. Specifically, we compare their
performance on tables from scientific vs. non-scientific contexts and examine
their robustness on tables represented as images vs. text. Additionally, we
conduct an interpretability analysis to measure context usage and input
relevance. We also introduce the TableEval benchmark, comprising 3017 tables
from scholarly publications, Wikipedia, and financial reports, where each table
is provided in five different formats: Image, Dictionary, HTML, XML, and LaTeX.
Our findings indicate that while LLMs maintain robustness across table
modalities, they face significant challenges when processing scientific tables.

</details>


### [2] [Prompting as Scientific Inquiry](https://arxiv.org/abs/2507.00163)
*Ari Holtzman,Chenhao Tan*

Main category: cs.CL

> 本文提出将大型语言模型中的提示（Prompting）视为一种科学方法，而非魔法般的技巧。认为大型语言模型如同一种复杂且不透明的生物体，其通过训练而非编程进行控制，而提示则是对其进行行为研究的一种科学手段。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于纠正人们对提示（Prompting）的错误认知，即其不仅仅是一种技巧，更是研究大型语言模型的重要科学方法。

**Method:** 未提及具体的研究方法。

**Result:** 未提及具体的实验结果。

**Conclusion:** 结论是提示（Prompting）不是次级技能，而是在大型语言模型研究中的关键科学组成部分。

**Abstract:** Prompting is the primary method by which we study and control large language
models. It is also one of the most powerful: nearly every major capability
attributed to LLMs-few-shot learning, chain-of-thought, constitutional AI-was
first unlocked through prompting. Yet prompting is rarely treated as science
and is frequently frowned upon as alchemy. We argue that this is a category
error. If we treat LLMs as a new kind of complex and opaque organism that is
trained rather than programmed, then prompting is not a workaround: it is
behavioral science. Mechanistic interpretability peers into the neural
substrate, prompting probes the model in its native interface: language. We
contend that prompting is not inferior, but rather a key component in the
science of LLMs.

</details>


### [3] [LineRetriever: Planning-Aware Observation Reduction for Web Agents](https://arxiv.org/abs/2507.00210)
*Imene Kerboua,Sahar Omidi Shayegan,Megh Thakkar,Xing Han Lù,Massimo Caccia,Véronique Eglin,Alexandre Aussem,Jérémy Espinas,Alexandre Lacoste*

Main category: cs.CL

> 针对现有方法在处理网络导航任务时存在的问题，该研究提出了一种名为	extit{LineRetriever}的新方法，该方法旨在优化为适应性规划而设计的内容检索。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法如自底向上截断或基于嵌入检索在处理网页时会丢失关于页面状态和操作历史的重要信息，特别是对于需要理解当前状态以决定未来行动的适应性规划任务，这种情况尤为关键。

**Method:** 提出了一种名为	extit{LineRetriever}的新方法，该方法利用语言模型识别和检索对未来导航步骤最相关的观察行。与传统检索方法仅关注语义相似性不同，	extit{LineRetriever}显式地考虑了计划范围，优先选择能够促进动作预测的元素。

**Result:** 实验表明，	extit{LineRetriever}能够减少每个步骤中网络代理观察的大小，同时在上下文限制内保持稳定性能。

**Conclusion:** 研究结论表明，针对适应性网络导航任务设计的内容检索方法能够有效优化信息处理，从而提高语言模型在这些任务中的表现。

**Abstract:** While large language models have demonstrated impressive capabilities in web
navigation tasks, the extensive context of web pages, often represented as DOM
or Accessibility Tree (AxTree) structures, frequently exceeds model context
limits. Current approaches like bottom-up truncation or embedding-based
retrieval lose critical information about page state and action history. This
is particularly problematic for adaptive planning in web agents, where
understanding the current state is essential for determining future actions. We
hypothesize that embedding models lack sufficient capacity to capture
plan-relevant information, especially when retrieving content that supports
future action prediction. This raises a fundamental question: how can retrieval
methods be optimized for adaptive planning in web navigation tasks? In
response, we introduce \textit{LineRetriever}, a novel approach that leverages
a language model to identify and retrieve observation lines most relevant to
future navigation steps. Unlike traditional retrieval methods that focus solely
on semantic similarity, \textit{LineRetriever} explicitly considers the
planning horizon, prioritizing elements that contribute to action prediction.
Our experiments demonstrate that \textit{LineRetriever} can reduce the size of
the observation at each step for the web agent while maintaining consistent
performance within the context limitations.

</details>


### [4] [Two-Stage Reasoning-Infused Learning: Improving Classification with LLM-Generated Reasoning](https://arxiv.org/abs/2507.00214)
*Mads Henrichsen,Rasmus Krebs*

Main category: cs.CL

> 本文介绍了一种通过大语言模型生成推理的两阶段文本分类方法，该方法显著提高了情绪分类的准确性，并增进了模型的可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的标准分类模型通常直接将输入映射到标签，缺乏显式推理，这可能限制了模型的性能、鲁棒性和可解释性。本文希望通过改进这一点来增加模型的这些方面的能力。

**Method:** 本文提出了一种两阶段的方法来改进文本分类。第一阶段通过在一般推理数据集上对Llama-3.2-1B-Instruct模型进行微调以生成文本推理。第二阶段使用这一训练好的模型离线生成增强的训练数据，用于训练下游生成模型，使其能够在输出预测情绪前生成推理解释。

**Result:** 实验结果显示，与仅训练输出情绪的基准生成模型相比，训练输出推理解释和情绪的生成模型在准确率上提高了8.7个百分点。

**Conclusion:** 该研究证明了使用大语言模型生成的推理来提高文本分类性能和提供明确解释的潜力。

**Abstract:** Standard classification models often map inputs directly to labels without
explicit reasoning, potentially limiting their performance, robustness, and
interpretability. This paper introduces a novel two-stage approach to enhance
text classification by leveraging Large Language Model (LLM)-generated
reasonings. In the first stage, we fine-tune a Llama-3.2-1B-Instruct model
(henceforth Llama-R-Gen) on a general-purpose reasoning dataset
(syvai/reasoning-gen) to generate textual reasoning (R) given a question and
its answer. In the second stage, this generally trained Llama-R-Gen is used
offline to create an augmented training dataset for a downstream generative
model. This downstream model, based on Llama-3.2-1B-Instruct, takes only the
input text (Q) and is trained to output the generated reasoning (R) immediately
followed by the predicted emotion (A). We demonstrate this methodology on the
dair-ai/emotion dataset for emotion classification. Our experiments show that
the generative model trained to output reasoning and the emotion (Classifier
Q->RA) achieves a significant improvement of 8.7 percentage points in accuracy
(for emotion prediction) compared to a baseline generative model trained solely
to output the emotion (Classifier Q->A), highlighting the strong generalization
capabilities of the reasoning generation and the benefit of explicit reasoning
training. This work underscores the potential of LLM-generated reasonings for
creating richer training datasets, thereby improving the performance of diverse
downstream NLP tasks and providing explicit explanations.

</details>


### [5] [Towards Style Alignment in Cross-Cultural Translation](https://arxiv.org/abs/2507.00216)
*Shreya Havaldar,Adam Stein,Eric Wong,Lyle Ungar*

Main category: cs.CL

> 本文提出了RASTA方法来解决LLMs在翻译时无法准确传达文化沟通规范和风格的问题，通过学习文化风格概念来改进翻译。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于解决由于文化差异导致的语言风格在翻译时的错位问题，特别是在非西方语言中，以使得机器翻译能更准确地传达源语言文化风格。

**Method:** 采用RASTA方法，通过增强学习的样式概念来引导LLMs的翻译以适当传达文化沟通规范和风格对齐。

**Result:** 该方法有效减轻了机器翻译偏向于中立的倾向，并在非西方语言中提升了翻译效果。

**Conclusion:** RASTA方法对于改进机器翻译在传达文化和风格方面的准确性是一个有效的策略。

**Abstract:** Successful communication depends on the speaker's intended style (i.e., what
the speaker is trying to convey) aligning with the listener's interpreted style
(i.e., what the listener perceives). However, cultural differences often lead
to misalignment between the two; for example, politeness is often lost in
translation. We characterize the ways that LLMs fail to translate style -
biasing translations towards neutrality and performing worse in non-Western
languages. We mitigate these failures with RASTA (Retrieval-Augmented STylistic
Alignment), a method that leverages learned stylistic concepts to encourage LLM
translation to appropriately convey cultural communication norms and align
style.

</details>


### [6] [Linearly Decoding Refused Knowledge in Aligned Language Models](https://arxiv.org/abs/2507.00239)
*Aryan Shrivastava,Ari Holtzman*

Main category: cs.CL

> 研究表明，通过线性探针可以轻易解码被模型拒绝的信息。尽管大语言模型通过指令调整来阻止有害回答，但是通过“越狱提示词”仍然可以触发这些信息，而且即使模型调整了指令后，这些信息仍然在内部表示中存在，并可能影响模型的下游行为。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在探索如何通过线性探针从大语言模型的隐藏状态中解码“越狱提示词”所引导的信息，以及这些信息是否影响模型的行为。

**Method:** 作者使用线性探针训练大语言模型的隐藏状态并评估其对于模型拒绝信息的预测能力。

**Result:** 研究表明，拒绝的信息通过线性探针可被高度预测，并且基础模型的探针可以转移到指令调整的版本上，揭示模型通过“越狱提示词”解码生成性信息的能力。

**Conclusion:** 指令调整并没有彻底消除或重新定位模型中的有害信息，而只是抑制了它直接的表达，这些信息依然可以通过线性探针提取并在模型的下游行为中留下间接影响。

**Abstract:** Most commonly used language models (LMs) are instruction-tuned and aligned
using a combination of fine-tuning and reinforcement learning, causing them to
refuse users requests deemed harmful by the model. However, jailbreak prompts
can often bypass these refusal mechanisms and elicit harmful responses. In this
work, we study the extent to which information accessed via jailbreak prompts
is decodable using linear probes trained on LM hidden states. We show that a
great deal of initially refused information is linearly decodable. For example,
across models, the response of a jailbroken LM for the average IQ of a country
can be predicted by a linear probe with Pearson correlations exceeding $0.8$.
Surprisingly, we find that probes trained on base models (which do not refuse)
sometimes transfer to their instruction-tuned versions and are capable of
revealing information that jailbreaks decode generatively, suggesting that the
internal representations of many refused properties persist from base LMs
through instruction-tuning. Importantly, we show that this information is not
merely "leftover" in instruction-tuned models, but is actively used by them: we
find that probe-predicted values correlate with LM generated pairwise
comparisons, indicating that the information decoded by our probes align with
suppressed generative behavior that may be expressed more subtly in other
downstream tasks. Overall, our results suggest that instruction-tuning does not
wholly eliminate or even relocate harmful information in representation
space-they merely suppress its direct expression, leaving it both linearly
accessible and indirectly influential in downstream behavior.

</details>


### [7] [The Algebraic Structure of Morphosyntax](https://arxiv.org/abs/2507.00244)
*Isabella Senturia,Matilde Marcolli*

Main category: cs.CL

> 本文提出了一个形态-句法界面的数学模型，通过扩展形态树集合和operad代数对应关系，研究了语形-句法合成过程。

<details>
  <summary>Details</summary>

**Motivation:** 本论文旨在探讨并建立形态与句法关系的数学模型，特别是在形态组合与句法合成过程中边界划分的灵活性。

**Method:** 本论文在数学形式化的合并和强简约主义论题的框架下，提出了形态-句法界面的数学模型。在这个背景下，形态具有负责词形成组合性的属性，组织成了形态树的半群。然而，与句法不同的是，形态中不存在转移现象。存在一个余积分解，但需要将形态树的集合扩展到由半群生成的集合之外，形成更大的可能的形态输入集合来参与句法树的合成，这些集合作为operad上的代数进行操作，并通过operad上的代数之间的对应关系形成语形-句法树。这一过程可以通过operad对应关系描述，该对应关系对句法和形态数据进行了配对，并涉及形态余积。

**Result:** 论文通过operad上的代数对应关系建立了形态与句法之间的联系，并解释了语形学某个操作作为转型，使在语形-句法对象间的形态与句法边界划分更加灵活。

**Conclusion:** 通过数学模型的建立，论文证明了形态与句法之间的关系可以通过operad上的代数对应关系进行描述，并强调了Distributed Morphology操作作为转型在形态与句法边界划分中的灵活性。

**Abstract:** Within the context of the mathematical formulation of Merge and the Strong
Minimalist Thesis, we present a mathematical model of the morphology-syntax
interface. In this setting, morphology has compositional properties responsible
for word formation, organized into a magma of morphological trees. However,
unlike syntax, we do not have movement within morphology. A coproduct
decomposition exists, but it requires extending the set of morphological trees
beyond those which are generated solely by the magma, to a larger set of
possible morphological inputs to syntactic trees. These participate in the
formation of morphosyntactic trees as an algebra over an operad, and a
correspondence between algebras over an operad. The process of structure
formation for morphosyntactic trees can then be described in terms of this
operadic correspondence that pairs syntactic and morphological data and the
morphology coproduct. We reinterpret in this setting certain operations of
Distributed Morphology as transformation that allow for flexibility in moving
the boundary between syntax and morphology within the morphosyntactic objects.

</details>


### [8] [EfficientXLang: Towards Improving Token Efficiency Through Cross-Lingual Reasoning](https://arxiv.org/abs/2507.00246)
*Sanchit Ahuja,Praneetha Vaddamanu,Barun Patra*

Main category: cs.CL

> 研究表明在语言推理模型中使用非英语语言可以更高效地进行推理，同时保持准确性，这凸显了多语言推理的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究英语以外的语言是否能提高推理的效率，同时保持准确性。

**Method:** 评估了三个开源的语言推理模型：DeepSeek R1, Qwen 2.5 和 Qwen 3，在四个数学数据集和七种语言多样性语言上的表现。

**Result:** 发现与英语相比，非英语语言在推理时使用较少的token，并保持了准确性。即使将推理过程翻译回英语，这种效率的提高仍然存在。

**Conclusion:** 研究结果表明，使用多语言进行推理不仅能够减少token的使用量，还保持了推理准确性，这表明语言模型推理不应该只局限于英语。

**Abstract:** Despite recent advances in Language Reasoning Models (LRMs), most research
focuses solely on English, even though many models are pretrained on
multilingual data. In this work, we investigate: Is English the most
token-efficient language for reasoning? We evaluate three open-source RLMs:
DeepSeek R1, Qwen 2.5 and Qwen 3, across four math datasets and seven
typologically diverse languages. We find that reasoning in non-English
languages not only reduces token usage, but also preserves accuracy. These
gains persist even after translating the reasoning traces into English,
suggesting genuine shifts in reasoning behavior rather than surface-level
linguistic effects. The extent of improvement, however, depends on the models
multilingual strength. Our findings motivate a broader view of reasoning in
language models, highlighting the potential of multilingual reasoning and the
importance of strong multilingual foundations. The code for our work can be
found: https://github.com/microsoft/EfficientXLang.

</details>


### [9] [Impact of Fine-Tuning Methods on Memorization in Large Language Models](https://arxiv.org/abs/2507.00258)
*Jie Hou,Chuxiong Wu,Lannan Luo,Qiang Zeng*

Main category: cs.CL

> 研究发现，与基于参数的微调方法相比，基于提示的微调方法在维持竞争优势性能的同时，对成员推理攻击的脆弱性较低，并且无论模型规模如何都保持低记忆化，是一种更保护隐私的选择。

<details>
  <summary>Details</summary>

**Motivation:** 随着预训练大型语言模型（LLMs）能力的不断增强，'预训练和微调'这一范式日益主流化，然而，在微调过程中由于记忆化而导致的隐私风险却并没有得到足够的关注。

**Method:** 我们通过成员推理攻击（MIAs）的角度，评估了流行的微调方法对模型记忆化的影响，从而填补了隐私风险在微调阶段的研究空白。

**Result:** 研究揭示了与基于参数的微调相对，基于提示的微调展现了更低的成员推理攻击脆弱性，同时保持了良好的性能和低记忆化特性。

**Conclusion:** 我们的研究表明，基于参数的微调方法更倾向于泄露私人信息，而基于提示的微调方法是更保护隐私的选择。

**Abstract:** As the capabilities of pre-trained large language models (LLMs) continue to
advance, the "pre-train and fine-tune" paradigm has become increasingly
mainstream, leading to the development of various fine-tuning methods. However,
the privacy risks arising from memorization during fine-tuning have received
relatively little attention. To address this gap, we categorize popular
fine-tuning approaches and assess their impact on memorization through the lens
of membership inference attacks (MIAs). Our results show that, compared to
parameter-based fine-tuning, prompt-based fine-tuning achieves competitive
performance while exhibiting lower vulnerability to MIAs. Furthermore,
prompt-based methods maintain low memorization regardless of model scale. These
findings suggest that parameter-based fine-tuning is more prone to leaking
private information, whereas prompt-based fine-tuning serves as a more
privacy-preserving option.

</details>


### [10] [Natural language processing for African languages](https://arxiv.org/abs/2507.00297)
*David Ifeoluwa Adelani*

Main category: cs.CL

> 本论文聚焦撒哈拉以南非洲地区低资源语言的自然语言处理挑战，通过分析和整理高质量语料、创建多语言预训练语言模型以及开发大规模人工标注数据集，提升这些语言的NLP性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多语言模型主要依赖网络数据进行训练，这常导致低资源语言的数据质量不高及缺乏标注数据的问题。本研究旨在解决撒哈拉以南非洲地区语言的数据质量、标注数据缺乏等问题。

**Method:** 论文中包含了对公共资源中噪声的分析，以及如何通过小量的单语数据来适应和专业化多语言预训练模型的方法。此外，作者也开发了用于命名实体识别和机器翻译任务的大型人工标注数据集。

**Result:** 通过实验证明了多语言预训练模型在面对未参与预训练的语言和低资源情况下具有独特的优势。数据集的创建填补了撒哈拉以南非洲语言在NLP研究中的不足。

**Conclusion:** 论文证实了语料库质量对表示学习的重要性，并展示了适应多语言预训练模型到未见过的非洲语言中的可行性，为未来撒哈拉以南非洲地区语言的NLP研究奠定了坚实基础。

**Abstract:** Recent advances in word embeddings and language models use large-scale,
unlabelled data and self-supervised learning to boost NLP performance.
Multilingual models, often trained on web-sourced data like Wikipedia, face
challenges: few low-resource languages are included, their data is often noisy,
and lack of labeled datasets makes it hard to evaluate performance outside
high-resource languages like English. In this dissertation, we focus on
languages spoken in Sub-Saharan Africa where all the indigenous languages in
this region can be regarded as low-resourced in terms of the availability of
labelled data for NLP tasks and unlabelled data found on the web. We analyse
the noise in the publicly available corpora, and curate a high-quality corpus,
demonstrating that the quality of semantic representations learned in word
embeddings does not only depend on the amount of data but on the quality of
pre-training data. We demonstrate empirically the limitations of word
embeddings, and the opportunities the multilingual pre-trained language model
(PLM) offers especially for languages unseen during pre-training and
low-resource scenarios. We further study how to adapt and specialize
multilingual PLMs to unseen African languages using a small amount of
monolingual texts. To address the under-representation of the African languages
in NLP research, we developed large scale human-annotated labelled datasets for
21 African languages in two impactful NLP tasks: named entity recognition and
machine translation. We conduct an extensive empirical evaluation using
state-of-the-art methods across supervised, weakly-supervised, and transfer
learning settings.

</details>


### [11] [Failure by Interference: Language Models Make Balanced Parentheses Errors When Faulty Mechanisms Overshadow Sound Ones](https://arxiv.org/abs/2507.00322)
*Daking Rai,Samuel Miller,Kevin Moran,Ziyu Yao*

Main category: cs.CL

> Analyzed variations in language model performances on syntactic tasks and introduced RASteer to improve accuracy by adjusting reliable component contributions.

<details>
  <summary>Details</summary>

**Motivation:** To investigate why language models struggle with simple syntactic tasks like generating balanced parentheses and how to improve them.

**Method:** Our study uses analysis of language models of varying sizes to identify reliable and unreliable components in predicting balanced parentheses. RASteer is introduced to adjust the contribution of these components.

**Result:** The introduced RASteer method improves model accuracy in syntactic tasks from 0% to near 100% and shows performance gains of up to 20% in arithmetic tasks.

**Conclusion:** RASteer significantly boosts accuracy in balanced parentheses tasks and shows promise in arithmetic reasoning tasks, enhancing specific performance without hindering general coding ability.

**Abstract:** Despite remarkable advances in coding capabilities, language models (LMs)
still struggle with simple syntactic tasks such as generating balanced
parentheses. In this study, we investigate the underlying mechanisms behind the
persistence of these errors across LMs of varying sizes (124M-7B) to both
understand and mitigate the errors. Our study reveals that LMs rely on a number
of components (attention heads and FF neurons) that independently make their
own predictions. While some components reliably promote correct answers across
a generalized range of inputs (i.e., implementing "sound mechanisms''), others
are less reliable and introduce noise by promoting incorrect tokens (i.e.,
implementing "faulty mechanisms''). Errors occur when the faulty mechanisms
overshadow the sound ones and dominantly affect the predictions. Motivated by
this insight, we introduce RASteer, a steering method to systematically
identify and increase the contribution of reliable components for improving
model performance. RASteer substantially improves performance on balanced
parentheses tasks, boosting accuracy of some models from $0$% to around $100$%
without impairing the models' general coding ability. We further demonstrate
its broader applicability in arithmetic reasoning tasks, achieving performance
gains of up to around $20$%.

</details>


### [12] [Modeling Data Diversity for Joint Instance and Verbalizer Selection in Cold-Start Scenarios](https://arxiv.org/abs/2507.00330)
*Mohna Chakraborty,Adithya Kulkarni,Qi Li*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Prompt-based methods leverage the knowledge of pre-trained language models
(PLMs) trained with a masked language modeling (MLM) objective; however, these
methods are sensitive to template, verbalizer, and few-shot instance selection,
particularly in cold-start settings with no labeled data. Existing studies
overlook the dependency between instances and verbalizers, where instance-label
probabilities depend on verbalizer token proximity in the embedding space. To
address this, we propose COLDSELECT, a joint verbalizer and instance selection
approach that models data diversity. COLDSELECT maps PLM vocabulary and
$h_{[MASK]}$ embeddings into a shared space, applying dimensionality reduction
and clustering to ensure efficient and diverse selection. By optimizing for
minimal uncertainty and maximal diversity, COLDSELECT captures data
relationships effectively. Experiments on eight benchmarks demonstrate
COLDSELECT's superiority in reducing uncertainty and enhancing generalization,
outperforming baselines in verbalizer and few-shot instance selection for
cold-start scenarios.

</details>


### [13] [Question Decomposition for Retrieval-Augmented Generation](https://arxiv.org/abs/2507.00355)
*Paul J. L. Ammann,Jonas Golde,Alan Akbik*

Main category: cs.CL

> 该研究提出了一种改进的RAG方法，它运用大型语言模型进行问题分解和重排序，显著提升了多跳问题的检索和答案准确性。

<details>
  <summary>Details</summary>

**Motivation:** 该方法旨在解决标准RAG在处理多跳问题时的问题，即相关事实分散在多个文档中而不是单独出现在一个源中。

**Method:** 该论文提出了一种结合问题分解的检索增强生成（RAG）流水线，其中大型语言模型将原始查询分解为子问题，为每个子问题检索段落，然后对合并后的候选段落池进行重排序以提升检索的完整性和准确性。

**Result:** 实验结果显示该方法在多跳问题上的检索和答案准确性方面都比标准RAG基线有所提高，特别是在 MultiHop-RAG 和 HotpotQA 数据集上，检索（MRR@10）和答案准确性（F1）分别提高了36.7%和11.6%。

**Conclusion:** 不需额外训练或专门索引，文章方法通过将现成的交叉编码重排名器与基于LLM的问题分解相结合，在解决多跳问题上的检索差距方面有显著提升。

**Abstract:** Grounding large language models (LLMs) in verifiable external sources is a
well-established strategy for generating reliable answers. Retrieval-augmented
generation (RAG) is one such approach, particularly effective for tasks like
question answering: it retrieves passages that are semantically related to the
question and then conditions the model on this evidence. However, multi-hop
questions, such as "Which company among NVIDIA, Apple, and Google made the
biggest profit in 2023?," challenge RAG because relevant facts are often
distributed across multiple documents rather than co-occurring in one source,
making it difficult for standard RAG to retrieve sufficient information. To
address this, we propose a RAG pipeline that incorporates question
decomposition: (i) an LLM decomposes the original query into sub-questions,
(ii) passages are retrieved for each sub-question, and (iii) the merged
candidate pool is reranked to improve the coverage and precision of the
retrieved evidence. We show that question decomposition effectively assembles
complementary documents, while reranking reduces noise and promotes the most
relevant passages before answer generation. Although reranking itself is
standard, we show that pairing an off-the-shelf cross-encoder reranker with
LLM-driven question decomposition bridges the retrieval gap on multi-hop
questions and provides a practical, drop-in enhancement, without any extra
training or specialized indexing. We evaluate our approach on the MultiHop-RAG
and HotpotQA, showing gains in retrieval (MRR@10: +36.7%) and answer accuracy
(F1: +11.6%) over standard RAG baselines.

</details>


### [14] [Gregorian melody, modality, and memory: Segmenting chant with Bayesian nonparametrics](https://arxiv.org/abs/2507.00380)
*Vojtěch Lanz,Jan Hajič jr*

Main category: cs.CL

> 使用统计模型对格里高利圣咏进行分割，在无需监督的情况下达到了模式分类的先进水平，但说明这并不是所谓的centonisation。

<details>
  <summary>Details</summary>

**Motivation:** 受格里高利圣咏被记忆这一事实的启发，寻找最优分割以验证被频繁使用的旋律片段在模式分类中的价值。

**Method:** 使用嵌套层次Pitman-Yor语言模型查找格里高利圣咏旋律的最优无监督分割。

**Result:** 发现的分割在模式分类中达到了最先进的性能，并观察到旋律开头和结尾处更公式化的区域。

**Conclusion:** 虽然达到了顶级模式分类，但最后的结果表明，即便是如此优化的分割方式也并不是传统意义上的centonisation。

**Abstract:** The idea that Gregorian melodies are constructed from some vocabulary of
segments has long been a part of chant scholarship. This so-called
"centonisation" theory has received much musicological criticism, but frequent
re-use of certain melodic segments has been observed in chant melodies, and the
intractable number of possible segmentations allowed the option that some
undiscovered segmentation exists that will yet prove the value of
centonisation, and recent empirical results have shown that segmentations can
outperform music-theoretical features in mode classification. Inspired by the
fact that Gregorian chant was memorised, we search for an optimal unsupervised
segmentation of chant melody using nested hierarchical Pitman-Yor language
models. The segmentation we find achieves state-of-the-art performance in mode
classification. Modeling a monk memorising the melodies from one liturgical
manuscript, we then find empirical evidence for the link between mode
classification and memory efficiency, and observe more formulaic areas at the
beginnings and ends of melodies corresponding to the practical role of modality
in performance. However, the resulting segmentations themselves indicate that
even such a memory-optimal segmentation is not what is understood as
centonisation.

</details>


### [15] [Causal Prompting for Implicit Sentiment Analysis with Large Language Models](https://arxiv.org/abs/2507.00389)
*Jing Ren,Wenhao Zhou,Bowen Li,Mujie Liu,Nguyen Linh Dan Le,Jiade Cen,Liping Chen,Ziqi Xu,Xiwei Xu,Xiaodong Li*

Main category: cs.CL

> 本文提出了CAPITAL框架，该框架在隐式情感分析中融入了因果推理，通过前门调整改进思想链推理，提高了模型的准确性和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于提示的方法在隐式情感分析中显示出潜力，但它们通常依赖于对思想链推理路径的多数投票，而不评估其因果有效性。这使得模型容易受到内部偏见和不相关性的困扰。因此，本文提出了一种新的框架来解决这一挑战。

**Method:** 本文提出了CAPITAL框架，该框架将因果推理中的前门调整方法融入到思想链（CoT）推理中。CAPITAL将整体因果效应分解为两个部分：输入提示对推理链的影响和这些推理链对最终输出的影响。这两个部分通过基于编码器的聚类和NWGM逼近来估计，并使用对比学习目标使编码器的表示与大语言模型的推理空间更好地对齐。

**Result:** 实验表明，在三个大语言模型的基准ISA数据集上，CAPITAL在准确性和鲁棒性方面都优于强基于提示的基线方法，尤其是在对抗条件下。

**Conclusion:** 本文提供了一种将因果推理纳入大语言模型提示的原则性方法，强调了其在偏见意识的情感推理中的好处。

**Abstract:** Implicit Sentiment Analysis (ISA) aims to infer sentiment that is implied
rather than explicitly stated, requiring models to perform deeper reasoning
over subtle contextual cues. While recent prompting-based methods using Large
Language Models (LLMs) have shown promise in ISA, they often rely on majority
voting over chain-of-thought (CoT) reasoning paths without evaluating their
causal validity, making them susceptible to internal biases and spurious
correlations. To address this challenge, we propose CAPITAL, a causal prompting
framework that incorporates front-door adjustment into CoT reasoning. CAPITAL
decomposes the overall causal effect into two components: the influence of the
input prompt on the reasoning chains, and the impact of those chains on the
final output. These components are estimated using encoder-based clustering and
the NWGM approximation, with a contrastive learning objective used to better
align the encoder's representation with the LLM's reasoning space. Experiments
on benchmark ISA datasets with three LLMs demonstrate that CAPITAL consistently
outperforms strong prompting baselines in both accuracy and robustness,
particularly under adversarial conditions. This work offers a principled
approach to integrating causal inference into LLM prompting and highlights its
benefits for bias-aware sentiment reasoning. The source code and case study are
available at: https://github.com/whZ62/CAPITAL.

</details>


### [16] [Beyond Sociodemographic Prompting: Using Supervision to Align LLMs with Human Response Distributions](https://arxiv.org/abs/2507.00439)
*Gauri Kambhatla,Sanjana Gautam,Angela Zhang,Alex Liu,Ravi Srinivasan,Junyi Jessy Li,Matthew Lease*

Main category: cs.CL

> Simple supervision significantly improves language model alignment with diverse populations on various topics, with detailed performance analysis across specific groups.

<details>
  <summary>Details</summary>

**Motivation:** To enhance the ability of language models to accurately predict responses from different population groups to subjective questions, potentially increasing the value and applicability of these models.

**Method:** We use simple supervision methods to improve the alignment of language models with diverse population groups across different topics. Evaluation is done using multiple language models and prompting strategies, with a focus on performance across specific groups.

**Result:** The approach demonstrates improved alignment of language models with diverse groups, with detailed analysis of performance variations among specific groups. The simplicity of the method promotes wide adoption and provides a benchmark for future research.

**Conclusion:** Our approach, with its simplicity and broad applicability, offers a valuable benchmark for enhancing language model alignment to diverse population groups and guiding the practical use of language models.

**Abstract:** The ability to accurately predict how different population groups would
answer subjective questions would have great value. In this work, we show that
use of relatively simple supervision can greatly improve language model
alignment with diverse population groups, as measured over three datasets
spanning various topics. Beyond evaluating average performance, we also report
how alignment varies across specific groups. The simplicity and generality of
our approach promotes easy adoption, while our broad findings provide useful
guidance for when to use or not use our approach in practice. By conducting
evaluation over many LLMs and prompting strategies, along with open-sourcing
our work, we provide a useful benchmark to stimulate future research.

</details>


### [17] [Pitfalls of Evaluating Language Models with Open Benchmarks](https://arxiv.org/abs/2507.00460)
*Md. Najib Hasan,Mohammad Fakhruddin Babar,Souvika Sarkar,Monowar Hasan,Santu Karmaker*

Main category: cs.CL

> 本文通过构造在公开测试集上微调的“作弊”模型，揭示了开放语言模型基准测试的不足，指出了高排行榜成绩并不一定反映实际效果。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于揭示如HELM等开放语言模型基准测试的潜在风险，以及评估这些基准测试的局限性。

**Method:** 此研究通过系统地构建“作弊”模型——即在公共测试集上进行了微调的BART、T5和GPT-2的小型变体模型，来揭示公开语言模型基准测试的弱点。这些“作弊”模型在著名的公开综合基准测试（如HELM）中获得高排名，尽管它们实际的泛化能力和实用价值有限。

**Result:** 研究结果表明，在公开的基准测试中取得高排名的模型并不一定具有实际的泛化能力和实用价值，从而显露出公开基准测试存在的问题。

**Conclusion:** 研究表明，高排行榜性能不一定反映现实世界中的有效性；私有或动态的基准测试必须补充开放性评估以保障评估的完整性；必须重新评估当前的基准测试实践，以确保语言模型评估的稳健性和信任度。

**Abstract:** Open Large Language Model (LLM) benchmarks, such as HELM and BIG-bench, offer
standardized, transparent protocols that facilitate the fair comparison,
reproducibility, and iterative advancement of Language Models (LMs). However,
their openness also introduces critical and underexplored pitfalls. This study
exposes these weaknesses by systematically constructing ``cheating'' models --
smaller variants of BART, T5, and GPT-2 fine-tuned directly on public test sets
-- which achieve top rankings on a prominent open, holistic benchmark (HELM)
despite poor generalization and limited practical utility. Our findings
underscore three key insights: \ca high leaderboard performance on open
benchmarks may not always reflect real-world effectiveness; \cb private or
dynamic benchmarks must complement open evaluations to safeguard integrity; and
\cc a fundamental reevaluation of current benchmarking practices is essential
to ensure robust and trustworthy LM assessments.

</details>


### [18] [TeamCMU at Touché: Adversarial Co-Evolution for Advertisement Integration and Detection in Conversational Search](https://arxiv.org/abs/2507.00509)
*To Eun Kim,João Coelho,Gbemileke Onilude,Jai Singh*

Main category: cs.CL

> 本文提出了一种在基于检索增强生成(RAG)的对话系统中管理广告的模块化流程，包括广告重写器和一个强健的广告分类器，实验结果证明该方法有效。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于解决大型语言模型和基于生成的对话搜索引擎中，集成广告所面临的透明度和信任问题。

**Method:** 通过合成数据训练广告分类器，并采用监督微调广告重写器和最佳的N次采样方法来实现广告无缝集成。

**Result:** 实验显示，基于合成广告数据训练的广告分类器具有强大的检测性能，并改进了广告的隐秘性。

**Conclusion:** 本文的研究为开发更复杂的广告感知生成搜索系统和强大的广告分类器提供了一个基于对抗协同演化的框架。

**Abstract:** As conversational search engines increasingly adopt generation-based
paradigms powered by Large Language Models (LLMs) and Retrieval-Augmented
Generation (RAG), the integration of advertisements into generated responses
presents both commercial opportunities and challenges for user experience.
Unlike traditional search, where advertisements are clearly delineated,
generative systems blur the boundary between informational content and
promotional material, raising concerns around transparency and trust. In this
work, we propose a modular pipeline for advertisement management in RAG-based
conversational systems, consisting of an ad-rewriter for seamless ad
integration and a robust ad-classifier for detection. We leverage synthetic
data to train high-performing classifiers, which are then used to guide two
complementary ad-integration strategies: supervised fine-tuning of the
ad-rewriter and a best-of-N sampling approach that selects the least detectable
ad-integrated response among multiple candidates. Our evaluation focuses on two
core questions: the effectiveness of ad classifiers in detecting diverse ad
integration strategies, and the training methods that best support coherent,
minimally intrusive ad insertion. Experimental results show that our
ad-classifier, trained on synthetic advertisement data inspired by marketing
strategies and enhanced through curriculum learning, achieves robust detection
performance. Additionally, we demonstrate that classifier-guided optimization,
through both fine-tuning and best-of-N sampling, significantly improves ad
stealth, enabling more seamless integration. These findings contribute an
adversarial co-evolution framework for developing more sophisticated ad-aware
generative search systems and robust ad classifiers.

</details>


### [19] [NIRANTAR: Continual Learning with New Languages and Domains on Real-world Speech Data](https://arxiv.org/abs/2507.00534)
*Tahir Javed,Kaushal Bhogale,Mitesh M. Khapra*

Main category: cs.CL

> 本论文介绍了Nirantar框架，这是用于评估多语言和多领域下连续学习任务的新工具，强调了开发更有效的CL方法的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 通过开发和使用Nirantar来评估CL方法，作者旨在解决现实世界中多语言和多领域的动态、不均匀的语言和领域变化问题。

**Method:** Nirantar框架通过收集22种语言和208个区的自然集数据来进行评估，而不是使用模拟场景。

**Result:** 本研究介绍了Nirantar框架，该框架旨在评估多语言和多领域的连续学习(Continual Learning, CL)任务。Nirantar通过印度22种语言和208个区的自然集收集的数据，反映了实际的CL挑战。与其他基于模拟场景的工作不同，Nirantar提供了一个动态且非均匀的语言和领域的变化，使其成为CL研究理想的测试平台。通过人类转录的3250小时的语音数据（包括本研究新引入的1720小时），该框架能够系统化地对CL方法进行基准测试。实验结果表明现有的方法并没有能够始终表现良好，表明需要更具鲁棒性的CL策略。

**Conclusion:** 现有的连续学习方法不能始终表现出色，这突显了开发更强大CL策略的必要性。

**Abstract:** We introduce Nirantar, a comprehensive framework for evaluating continual
learning (CL) in multilingual and multi-domain ASR. Designed to reflect
real-world CL challenges, Nirantar leverages data collected incrementally
across 22 languages and 208 districts in India through natural episodes. This
enables evaluation across Language-Incremental (LIL), Domain-Incremental (DIL),
and the novel Language-Incremental Domain-Incremental Learning (LIDIL)
scenarios. Unlike prior work that relies on simulated episodes, Nirantar
presents dynamic, non-uniform language and domain shifts, making it an ideal
testbed for CL research. With 3250 hours of human-transcribed speech, including
1720 hours newly introduced in this work, our framework enables systematic
benchmarking of CL methods. We evaluate existing approaches and demonstrate
that no single method performs consistently well, underscoring the need for
more robust CL strategies.

</details>


### [20] [Capsule Network-Based Semantic Intent Modeling for Human-Computer Interaction](https://arxiv.org/abs/2507.00540)
*Shixiao Wang,Yifan Zhuang,Runsheng Zhang,Zhijun Song*

Main category: cs.CL

> The paper introduces a capsule network-based user semantic intent model for improving intent recognition accuracy in human-computer interaction through a dynamic routing mechanism and margin-based loss, showing better performance than traditional and deep learning methods in experiments.

<details>
  <summary>Details</summary>

**Motivation:** The motivation of this paper is to address the problem of insufficient accuracy in intent recognition for human-computer interaction by proposing a more effective semantic intent model based on capsule networks.

**Method:** The method involves creating a capsule-based semantic intent model using a dynamic routing mechanism for hierarchical relationship and part-whole structure capture. A convolutional feature extraction module is used as the basic encoder and an iterative routing process forms high-level intent representations. A margin-based loss mechanism is also used to increase the model's capability to distinguish between classes.

**Result:** Results demonstrated the proposed model's superior performance over traditional methods and other deep learning structures with regards to accuracy, F1-score, and intent detection rate. The study also found that the number of dynamic routing iterations impacts model efficiency.

**Conclusion:** The conclusion is that the proposed capsule model for semantic intent, with its dynamic routing and margin-based loss, outperforms traditional methods and other deep learning architectures in terms of accuracy and intent detection rate, thus providing a valuable new approach for handling complex semantic conditions in intent recognition.

**Abstract:** This paper proposes a user semantic intent modeling algorithm based on
Capsule Networks to address the problem of insufficient accuracy in intent
recognition for human-computer interaction. The method represents semantic
features in input text through a vectorized capsule structure. It uses a
dynamic routing mechanism to transfer information across multiple capsule
layers. This helps capture hierarchical relationships and part-whole structures
between semantic entities more effectively. The model uses a convolutional
feature extraction module as the low-level encoder. After generating initial
semantic capsules, it forms high-level abstract intent representations through
an iterative routing process. To further enhance performance, a margin-based
mechanism is introduced into the loss function. This improves the model's
ability to distinguish between intent classes. Experiments are conducted using
a public natural language understanding dataset. Multiple mainstream models are
used for comparison. Results show that the proposed model outperforms
traditional methods and other deep learning structures in terms of accuracy,
F1-score, and intent detection rate. The study also analyzes the effect of the
number of dynamic routing iterations on model performance. A convergence curve
of the loss function during training is provided. These results verify the
stability and effectiveness of the proposed method in semantic modeling.
Overall, this study presents a new structured modeling approach to improve
intent recognition under complex semantic conditions.

</details>


### [21] [Methodological Rigour in Algorithm Application: An Illustration of Topic Modelling Algorithm](https://arxiv.org/abs/2507.00547)
*Malmi Amadoru*

Main category: cs.CL

> 本文提供了主题建模研究中确保严谨性的一系列指导原则。

<details>
  <summary>Details</summary>

**Motivation:** 面对复杂计算算法的不透明性和应用缺乏透明度和严谨性的挑战，提供主题建模算法应用的方法学严谨性的指导。

**Method:** 通过展示结构主题建模算法的应用，并提出一系列指南来讨论如何在主题建模研究中确保方法学严谨性。

**Result:** 提出了可应用于新手研究人员、编辑和处理主题建模手稿的审稿人的主题建模算法应用指南。

**Conclusion:** 为主题建模和计算密集型理论构建研究的方法学严谨性对话做出了贡献。

**Abstract:** The rise of advanced computational algorithms has opened new avenues for
computationally intensive research approaches to theory development. However,
the opacity of these algorithms and lack of transparency and rigour in their
application pose methodological challenges, potentially undermining trust in
research. The discourse on methodological rigour in this new genre of research
is still emerging. Against this backdrop, I attempt to offer guidance on
methodological rigour, particularly in the context of topic modelling
algorithms. By illustrating the application of the structural topic modelling
algorithm and presenting a set of guidelines, I discuss how to ensure rigour in
topic modelling studies. Although the guidelines are for the application of
topic modelling algorithms, they can be applied to other algorithms with
context-specific adjustments. The guidelines are helpful, especially for novice
researchers applying topic modelling, and editors and reviewers handling topic
modelling manuscripts. I contribute to the literature on topic modelling and
join the emerging dialogue on methodological rigour in computationally
intensive theory construction research.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [22] [Moment Sampling in Video LLMs for Long-Form Video QA](https://arxiv.org/abs/2507.00033)
*Mustafa Chasmai,Gauri Jagatap,Gouthaman KV,Grant Van Horn,Subhransu Maji,Andrea Fanelli*

Main category: cs.CV

> 研究了使用文本到视频时刻检索模型指导视频长语言模型的帧采样，提出了一种新的无模型依赖的时刻采样方法，提升长视频问答的性能。

<details>
  <summary>Details</summary>

**Motivation:** 提升长视频中的长程推理能力，改进现有常用的帧下采样方法（定期间隔选取帧）带来的关键帧丢失和冗余信息问题。

**Method:** moment sampling, 使用通用的文本到视频时刻检索模型指导帧采样过程，根据问题上下文选择最相关的帧

**Result:** 在四个长视频问答数据集上，使用四种最先进的视频长语言模型进行了广泛的实验，证明了所提方法的有效性。

**Conclusion:** 通过轻量级时刻检索模型优先选择帧，可以提高视频长语言模型在长格式视频问答上的表现。

**Abstract:** Recent advancements in video large language models (Video LLMs) have
significantly advanced the field of video question answering (VideoQA). While
existing methods perform well on short videos, they often struggle with
long-range reasoning in longer videos. To scale Video LLMs for longer video
content, frame sub-sampling (selecting frames at regular intervals) is commonly
used. However, this approach is suboptimal, often leading to the loss of
crucial frames or the inclusion of redundant information from multiple similar
frames. Missing key frames impairs the model's ability to answer questions
accurately, while redundant frames lead the model to focus on irrelevant video
segments and increase computational resource consumption. In this paper, we
investigate the use of a general-purpose text-to-video moment retrieval model
to guide the frame sampling process. We propose "moment sampling", a novel,
model-agnostic approach that enables the model to select the most relevant
frames according to the context of the question. Specifically, we employ a
lightweight moment retrieval model to prioritize frame selection. By focusing
on the frames most pertinent to the given question, our method enhances
long-form VideoQA performance in Video LLMs. Through extensive experiments on
four long-form VideoQA datasets, using four state-of-the-art Video LLMs, we
demonstrate the effectiveness of the proposed approach.

</details>


### [23] [Catastrophic Forgetting Mitigation via Discrepancy-Weighted Experience Replay](https://arxiv.org/abs/2507.00042)
*Xinrun Xu,Jianwen Yang,Qiuhong Zhang,Zhanbiao Lian,Zhiming Ding,Shan Jiang*

Main category: cs.CV

> 本文提出了ER-EMU算法，该算法利用有限的FIFO原则管理的经验缓冲区和基于域距离的MK-MMD度量的DDM-ES算法，解决了在适应新数据时模型容易遗忘旧知识的问题。实验表明，ER-EMU提高了云边缘合作对象检测框架的性能。

<details>
  <summary>Details</summary>

**Motivation:** 在交通监控中，用于云边缘合作对象检测的边缘模型不断适应新数据分布时会出现灾难性遗忘问题，这在具有周期性变化（如日/夜，高峰时间）的动态交通环境中特别成问题。现有的解决方法（如经验回放和视觉提示）在有效优先级和利用历史数据以进行最佳知识保留和适应方面存在不足。

**Method:** 本文提出了一种基于自适应经验回放的边缘模型更新算法ER-EMU，该算法利用有限大小的经验缓冲区和基于域距离度量的经验选择（DDM-ES）算法来克服模型在适应新数据分布时容易发生灾难性遗忘的问题。DDM-ES通过多核最大平均差异（MK-MMD）量化目标域之间的差异，优先选择与当前目标域最不相似的历史数据，以确保训练多样性并保留更广泛的历史经验。

**Result:** 实验使用Bellevue交通视频数据集，经历了重复的日/夜循环，证明了ER-EMU持续提升了几种最先进的云边缘合作对象检测框架的性能。

**Conclusion:** ER-EMU算法通过限定大小的经验缓冲区和DDM-ES算法在云边缘合作对象检测模型适应新数据分布时改善了模型效果，确保了从广泛过去经验中保持知识并防止对新域过度拟合。

**Abstract:** Continually adapting edge models in cloud-edge collaborative object detection
for traffic monitoring suffers from catastrophic forgetting, where models lose
previously learned knowledge when adapting to new data distributions. This is
especially problematic in dynamic traffic environments characterised by
periodic variations (e.g., day/night, peak hours), where past knowledge remains
valuable. Existing approaches like experience replay and visual prompts offer
some mitigation, but struggle to effectively prioritize and leverage historical
data for optimal knowledge retention and adaptation. Specifically, simply
storing and replaying all historical data can be inefficient, while treating
all historical experiences as equally important overlooks their varying
relevance to the current domain. This paper proposes ER-EMU, an edge model
update algorithm based on adaptive experience replay, to address these
limitations. ER-EMU utilizes a limited-size experience buffer managed using a
First-In-First-Out (FIFO) principle, and a novel Domain Distance Metric-based
Experience Selection (DDM-ES) algorithm. DDM-ES employs the multi-kernel
maximum mean discrepancy (MK-MMD) to quantify the dissimilarity between target
domains, prioritizing the selection of historical data that is most dissimilar
to the current target domain. This ensures training diversity and facilitates
the retention of knowledge from a wider range of past experiences, while also
preventing overfitting to the new domain. The experience buffer is also updated
using a simple random sampling strategy to maintain a balanced representation
of previous domains. Experiments on the Bellevue traffic video dataset,
involving repeated day/night cycles, demonstrate that ER-EMU consistently
improves the performance of several state-of-the-art cloud-edge collaborative
object detection frameworks.

</details>


### [24] [MR-CLIP: Efficient Metadata-Guided Learning of MRI Contrast Representations](https://arxiv.org/abs/2507.00043)
*Mehmet Yigit Avci,Pedro Borges,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

> 研究提出了一种名为MR-CLIP的多模态对比学习框架，用于学习不依赖手动标签的MRI图像对比度感知表示，以解决临床应用中图像解释和整合的问题。

<details>
  <summary>Details</summary>

**Motivation:** 由于MRI图像标签往往不完整、有噪声或不一致，这给图像解释、检索和集成到临床工作流程中带来了挑战。因此，该研究旨在通过一种新的方法来解决这些问题。

**Method:** 研究人员提出了一种新的多模态对比学习框架—MR-CLIP，它使用DICOM元数据将MRI图像对齐，学习对比度感知表示，而不需要手动标签。框架是基于一个多样化的临床数据集进行训练的，该数据集跨越了多种扫描仪和协议。

**Result:** 研究结果表明，该框架在跨模式检索和对比度分类中表现出了有效性，展示了其可扩展性和未来临床应用的潜力。

**Conclusion:** MR-CLIP能够捕捉横跨不同获取策略和扫描内部的对比度变化，实现解剖学不变的表示，从而有助于实现多模式不变的表示和数据和谐化等更高级的临床应用。

**Abstract:** Accurate interpretation of Magnetic Resonance Imaging scans in clinical
systems is based on a precise understanding of image contrast. This contrast is
primarily governed by acquisition parameters, such as echo time and repetition
time, which are stored in the DICOM metadata. To simplify contrast
identification, broad labels such as T1-weighted or T2-weighted are commonly
used, but these offer only a coarse approximation of the underlying acquisition
settings. In many real-world datasets, such labels are entirely missing,
leaving raw acquisition parameters as the only indicators of contrast. Adding
to this challenge, the available metadata is often incomplete, noisy, or
inconsistent. The lack of reliable and standardized metadata complicates tasks
such as image interpretation, retrieval, and integration into clinical
workflows. Furthermore, robust contrast-aware representations are essential to
enable more advanced clinical applications, such as achieving
modality-invariant representations and data harmonization. To address these
challenges, we propose MR-CLIP, a multimodal contrastive learning framework
that aligns MR images with their DICOM metadata to learn contrast-aware
representations, without relying on manual labels. Trained on a diverse
clinical dataset that spans various scanners and protocols, MR-CLIP captures
contrast variations across acquisitions and within scans, enabling
anatomy-invariant representations. We demonstrate its effectiveness in
cross-modal retrieval and contrast classification, highlighting its scalability
and potential for further clinical applications. The code and weights are
publicly available at https://github.com/myigitavci/MR-CLIP.

</details>


### [25] [HistoART: Histopathology Artifact Detection and Reporting Tool](https://arxiv.org/abs/2507.00044)
*Seyed Kahaki,Alexander R. Webber,Ghada Zamzmi,Adarsh Subbaswamy,Rucha Deshpande,Aldo Badano*

Main category: cs.CV

> 研究提出了三种WSI瑕疵检测方法，并在多种扫描仪中展示了高性能。FMA表现最佳，用于生成描述高质量片段和瑕疵分布的质量报告得分卡。

<details>
  <summary>Details</summary>

**Motivation:** 全切片成像（WSI）在癌症诊断中被广泛采用以数字化组织样本进行微米级高分辨率分析。然而，来自切片准备和扫描过程中引入的瑕疵可能影响后续的图像分析。本研究动机在于解决这一问题。

**Method:** 该研究提出了三种用于全切片图像（WSI）中稳健的缺陷检测方法：基于基础模型的方法（FMA），基于深度学习的方法（DLA），以及基于知识的方法（KBA）。FMA 使用了微调后的统一神经图像（UNI）架构，DLA 以 ResNet50 为骨干网络，而 KBA 利用了从纹理、颜色和频率度量中提取的手工特征。这些方法针对六种常见的瑕疵类型：组织褶皱、失焦区域、气泡、组织损伤、标记痕迹和血液污染。

**Result:** 研究在超过50,000个图像片段上进行了评估，这些图像片段来自多个供应商的扫描仪（Hamamatsu、Philips、Leica Aperio AT2）。结果显示FMA的片级AUROC达到了0.995（95%可信区间[0.994, 0.995]），超过了基于ResNet50的方法（AUROC为0.977，95%可信区间[0.977, 0.978]）和基于知识的方法（AUROC为0.940，95%可信区间[0.933, 0.946]）。

**Conclusion:** 研究发展了一种质量报告评分卡，可以量化高质量片段并以可视化形式表示瑕疵分布，这对于提升WSI的可靠性和实现瑕疵检测的可操作性分析具有重要意义。

**Abstract:** In modern cancer diagnostics, Whole Slide Imaging (WSI) is widely used to
digitize tissue specimens for detailed, high-resolution examination; however,
other diagnostic approaches, such as liquid biopsy and molecular testing, are
also utilized based on the cancer type and clinical context. While WSI has
revolutionized digital histopathology by enabling automated, precise analysis,
it remains vulnerable to artifacts introduced during slide preparation and
scanning. These artifacts can compromise downstream image analysis. To address
this challenge, we propose and compare three robust artifact detection
approaches for WSIs: (1) a foundation model-based approach (FMA) using a
fine-tuned Unified Neural Image (UNI) architecture, (2) a deep learning
approach (DLA) built on a ResNet50 backbone, and (3) a knowledge-based approach
(KBA) leveraging handcrafted features from texture, color, and frequency-based
metrics. The methods target six common artifact types: tissue folds,
out-of-focus regions, air bubbles, tissue damage, marker traces, and blood
contamination. Evaluations were conducted on 50,000+ image patches from diverse
scanners (Hamamatsu, Philips, Leica Aperio AT2) across multiple sites. The FMA
achieved the highest patch-wise AUROC of 0.995 (95% CI [0.994, 0.995]),
outperforming the ResNet50-based method (AUROC: 0.977, 95% CI [0.977, 0.978])
and the KBA (AUROC: 0.940, 95% CI [0.933, 0.946]). To translate detection into
actionable insights, we developed a quality report scorecard that quantifies
high-quality patches and visualizes artifact distributions.

</details>


### [26] [CaughtCheating: Is Your MLLM a Good Cheating Detective? Exploring the Boundary of Visual Perception and Reasoning](https://arxiv.org/abs/2507.00045)
*Ming Li,Chenguang Wang,Yijun Liang,Xiyao Wang,Yuhang Zhou,Xiyang Wu,Yuqing Zhang,Ruiyi Zhang,Tianyi Zhou*

Main category: cs.CV

> The study examines how well Multi-Modal Large Language Models perform in new, challenging tasks called CaughtCheating, inspired by social media requests to detect cheating through photos, revealing a significant drop in model performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to assess the limits of current agentic Multi-Modal Large Language Models (MLLMs) in more difficult tasks, particularly in visual perception and reasoning similar to excellent human detectives.

**Method:** The method involves designing a new test scenario, CaughtCheating, inspired by social media requests to identify cheating from pictures and conducting experiments to understand the current MLLMs' weaknesses in this scenario.

**Result:** The result shows that MLLMs struggle significantly with the CaughtCheating task, achieving nearly zero performance in it, indicating a limitation in the models' capacity for human-like detective perception and reasoning.

**Conclusion:** The conclusion highlights the value of CaughtCheating as a challenging task for MLLMs, emphasizing the need for advancements to reach human-level detective capabilities in terms of visual perception and reasoning.

**Abstract:** Recent agentic Multi-Modal Large Language Models (MLLMs) such as GPT-o3 have
achieved near-ceiling scores on various existing benchmarks, motivating a
demand for more challenging test tasks. These MLLMs have been reported to excel
in a few expert-level tasks for humans, e.g., GeoGuesser, reflecting their
potential as a detective who can notice minuscule cues in an image and weave
them into coherent, situational explanations, leading to a reliable answer. But
can they match the performance of excellent human detectives? To answer this
question, we investigate some hard scenarios where GPT-o3 can still handle, and
find a common scenario where o3's performance drops to nearly zero, which we
name CaughtCheating. It is inspired by the social media requests that ask
others to detect suspicious clues from photos shared by the poster's partner.
We conduct extensive experiments and analysis to understand why existing MLLMs
lack sufficient capability to solve this kind of task. CaughtCheating provides
a class of challenging visual perception and reasoning tasks with great value
and practical usage. Success in these tasks paves the way for MLLMs to acquire
human-level detective perception and reasoning capabilities.

</details>


### [27] [Evolutionary computing-based image segmentation method to detect defects and features in Additive Friction Stir Deposition Process](https://arxiv.org/abs/2507.00046)
*Akshansh Mishra,Eyob Mesele Sefene,Shivraman Thapliyal*

Main category: cs.CV

> The paper proposes a novel approach for image segmentation in Additive Friction Stir Deposition (AFSD) processes using evolutionary computing and Particle Swarm Optimization (PSO). The method includes gradient magnitude analysis and multi-channel visualization, which reveals critical details of material interfaces and defects.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to improve the quality assessment of AFSD processes by identifying defects and material interfaces that are not easily visible through conventional imaging techniques.

**Method:** The method employs Particle Swarm Optimization to determine optimal segmentation thresholds and uses gradient magnitude analysis and distance transforms to generate attention-weighted visualizations that highlight critical regions in AFSD builds.

**Result:** The results show that the method effectively identifies regions of incomplete bonding and inhomogeneities in AFSD joints through the use of multi-channel visualizations, providing new metrics for process optimization.

**Conclusion:** The paper concludes that the proposed approach based on evolutionary computing and multi-channel visualization offers a promising way to quantitatively assess the soundness of AFSD processes by identifying subtle defects and transitions not observable with traditional imaging techniques.

**Abstract:** This work proposes an evolutionary computing-based image segmentation
approach for analyzing soundness in Additive Friction Stir Deposition (AFSD)
processes. Particle Swarm Optimization (PSO) was employed to determine optimal
segmentation thresholds for detecting defects and features in multilayer AFSD
builds. The methodology integrates gradient magnitude analysis with distance
transforms to create novel attention-weighted visualizations that highlight
critical interface regions. Five AFSD samples processed under different
conditions were analyzed using multiple visualization techniques i.e.
self-attention maps, and multi-channel visualization. These complementary
approaches reveal subtle material transition zones and potential defect regions
which were not readily observable through conventional imaging. The PSO
algorithm automatically identified optimal threshold values (ranging from
156-173) for each sample, enabling precise segmentation of material interfaces.
The multi-channel visualization technique effectively combines boundary
information (red channel), spatial relationships (green channel), and material
density data (blue channel) into cohesive representations that quantify
interface quality. The results demonstrate that attention-based analysis
successfully identifies regions of incomplete bonding and inhomogeneities in
AFSD joints, providing quantitative metrics for process optimization and
quality assessment of additively manufactured components.

</details>


### [28] [AdaDeDup: Adaptive Hybrid Data Pruning for Efficient Large-Scale Object Detection Training](https://arxiv.org/abs/2507.00049)
*Feiyang Kang,Nadine Chang,Maying Shen,Marc T. Law,Rafid Mahmood,Ruoxi Jia,Jose M. Alvarez*

Main category: cs.CV

> 该论文介绍了一种新的混合框架AdaDeDup，它结合了密度基础的数据筛选和模型知情反馈，实验证明其在大规模物体检测上的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 为了应对大规模数据集带来的计算负担和内在冗余问题，该论文提出了AdaDeDup，旨在克服现有数据筛选方法的不足，如密度基础方法可能缺乏任务相关性，模型基础方法可能引入冗余或计算上不可行。

**Method:** AdaDeDup采用混合框架，将密度基础的数据筛选与模型知情反馈相结合。它首先对数据进行分块并应用初步的密度基础筛选，再利用代理模型评估每个聚类中初步筛选的影响，从而自适应地调整各聚类的筛选阈值。

**Result:** AdaDeDup在大规模物体检测基准（如Waymo、COCO、nuScenes）上使用标准模型（BEVFormer、Faster R-CNN）进行的广泛实验表明，它显著优于突出的基线模型，性能下降较少（如在Waymo上比随机采样减少了超过54%），同时在剔除20%数据的情况下达到接近原始模型的性能。

**Conclusion:** 实验表明AdaDeDup能够在大规模模型训练中有效提高数据效率，同时保证性能下降较少。

**Abstract:** The computational burden and inherent redundancy of large-scale datasets
challenge the training of contemporary machine learning models. Data pruning
offers a solution by selecting smaller, informative subsets, yet existing
methods struggle: density-based approaches can be task-agnostic, while
model-based techniques may introduce redundancy or prove computationally
prohibitive. We introduce Adaptive De-Duplication (AdaDeDup), a novel hybrid
framework that synergistically integrates density-based pruning with
model-informed feedback in a cluster-adaptive manner. AdaDeDup first partitions
data and applies an initial density-based pruning. It then employs a proxy
model to evaluate the impact of this initial pruning within each cluster by
comparing losses on kept versus pruned samples. This task-aware signal
adaptively adjusts cluster-specific pruning thresholds, enabling more
aggressive pruning in redundant clusters while preserving critical data in
informative ones. Extensive experiments on large-scale object detection
benchmarks (Waymo, COCO, nuScenes) using standard models (BEVFormer, Faster
R-CNN) demonstrate AdaDeDup's advantages. It significantly outperforms
prominent baselines, substantially reduces performance degradation (e.g., over
54% versus random sampling on Waymo), and achieves near-original model
performance while pruning 20% of data, highlighting its efficacy in enhancing
data efficiency for large-scale model training. Code is open-sourced.

</details>


### [29] [VSF-Med:A Vulnerability Scoring Framework for Medical Vision-Language Models](https://arxiv.org/abs/2507.00052)
*Binesh Sadanandan,Vahid Behzadan*

Main category: cs.CV

> VSF--Med 是一个针对医疗视觉语言模型 (VLMs) 的漏洞评分框架，包括复杂文本提示攻击模板、细微视觉扰动和八维评分标准。它使用公开数据集生成了3万多种对抗变体，对最先进的VLMs进行了评测。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于医疗成像工作流程中人工密集但系统安全性评估不足，通过VSF--Med来系统性地评估医疗VLMs的安全性。

**Method:** 使用复杂文本提示攻击模板、基于SSIM阈值调整的视觉扰动和由两个独立法官LLM生成评分的八维评分标准，产生30,000多种对抗变体并评估不同的医疗VLMs。

**Result:** 报告了医疗VLMs在攻击持续性、提示注入有效性及安全绕过成功率上的平均z-score变化，并辨识出Llama-3.2-11B-Vision-Instruct和GPT-4o的脆弱性峰值。

**Conclusion:** VSF--Med作为开放源码工具，为医疗VLMs的安全性评估提供了可复现的基准测量方法。

**Abstract:** Vision Language Models (VLMs) hold great promise for streamlining
labour-intensive medical imaging workflows, yet systematic security evaluations
in clinical settings remain scarce. We introduce VSF--Med, an end-to-end
vulnerability-scoring framework for medical VLMs that unites three novel
components: (i) a rich library of sophisticated text-prompt attack templates
targeting emerging threat vectors; (ii) imperceptible visual perturbations
calibrated by structural similarity (SSIM) thresholds to preserve clinical
realism; and (iii) an eight-dimensional rubric evaluated by two independent
judge LLMs, whose raw scores are consolidated via z-score normalization to
yield a 0--32 composite risk metric. Built entirely on publicly available
datasets and accompanied by open-source code, VSF--Med synthesizes over 30,000
adversarial variants from 5,000 radiology images and enables reproducible
benchmarking of any medical VLM with a single command. Our consolidated
analysis reports mean z-score shifts of $0.90\sigma$ for
persistence-of-attack-effects, $0.74\sigma$ for prompt-injection effectiveness,
and $0.63\sigma$ for safety-bypass success across state-of-the-art VLMs.
Notably, Llama-3.2-11B-Vision-Instruct exhibits a peak vulnerability increase
of $1.29\sigma$ for persistence-of-attack-effects, while GPT-4o shows increases
of $0.69\sigma$ for that same vector and $0.28\sigma$ for prompt-injection
attacks.

</details>


### [30] [MANTA: Cross-Modal Semantic Alignment and Information-Theoretic Optimization for Long-form Multimodal Understanding](https://arxiv.org/abs/2507.00068)
*Ziqi Zhong,Daniel Tang*

Main category: cs.CV

> 研究提出了一种框架MANTA，以克服当前多模态学习方法中存在的表征和推理不一致性问题，实现更精准的跨模态表示和推理，实验结果表明，MANTA在长视频问答、时间推理和跨模态理解任务上显著优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 虽然多模态学习已经取得了显著进展，但当前的方法通常将模态分开处理，这会产生表征和推理上的不一致。为了克服这些问题，提出了MANTA框架。

**Method:** MANTA（跨模态抽象和通过文本对齐的标准化）是一个理论基础的框架，它将视觉和听觉输入统一到一个结构化的文本空间，以便与大型语言模型无缝处理。MANTA解决四个核心挑战：1）通过信息论优化进行跨模态语义对齐；2）自适应时间同步以适应不同信息密度；3）分层内容表示以实现多尺度理解；4）从长时间序列中检索稀疏信息的上下文感知检索。

**Result:** 在具有挑战性地长视频问答任务上，MANTA将现有最佳模型的总体准确性提高了最多22.6%，特别是对于30分钟以上的视频，提升了27.3%。此外，MANTA在时间推理任务（23.8%的改进）和跨模态理解（25.1%的改进）中也表现出优势。

**Conclusion:** 该框架通过将多模态信息统一表示为结构化的文本空间，提出的新密度估计技术可以最小化冗余的同时保留稀有信号，为统一多模态表示奠定了新的基础。

**Abstract:** While multi-modal learning has advanced significantly, current approaches
often treat modalities separately, creating inconsistencies in representation
and reasoning. We introduce MANTA (Multi-modal Abstraction and Normalization
via Textual Alignment), a theoretically-grounded framework that unifies visual
and auditory inputs into a structured textual space for seamless processing
with large language models. MANTA addresses four key challenges: (1) semantic
alignment across modalities with information-theoretic optimization, (2)
adaptive temporal synchronization for varying information densities, (3)
hierarchical content representation for multi-scale understanding, and (4)
context-aware retrieval of sparse information from long sequences. We formalize
our approach within a rigorous mathematical framework, proving its optimality
for context selection under token constraints. Extensive experiments on the
challenging task of Long Video Question Answering show that MANTA improves
state-of-the-art models by up to 22.6% in overall accuracy, with particularly
significant gains (27.3%) on videos exceeding 30 minutes. Additionally, we
demonstrate MANTA's superiority on temporal reasoning tasks (23.8% improvement)
and cross-modal understanding (25.1% improvement). Our framework introduces
novel density estimation techniques for redundancy minimization while
preserving rare signals, establishing new foundations for unifying multimodal
representations through structured text.

</details>


### [31] [An efficient plant disease detection using transfer learning approach](https://arxiv.org/abs/2507.00070)
*Bosubabu Sambana,Hillary Sunday Nnadi,Mohd Anas Wajid,Nwosu Ogochukwu Fidelia,Claudia Camacho-Zuñiga,Henry Dozie Ajuzie,Edeh Michael Onyema*

Main category: cs.CV

> {
  "tldr": "本研究提出了一种利用YOLOv7和YOLOv8进行植物病害检测的系统，通过在植物叶片图像数据集上微调这些模型，检测细菌、真菌和病毒性病害的表现优异，展示了其在现代农业实践中的应用潜力。\n", 
  "motivation": "植物疾病对农民和农业部门构成挑战，早期检测可以减轻其影响并防止广泛损害，随着技术进步，有机会自动化疾病监测，以提高农作物产量和质量。\n", 
  "method": "研究采用了YOLOv7和YOLOv8这两个最先进的对象检测模型，并通过在植物叶片图像数据集上进行微调，用于识别和监控植物疾病。\n", 
  "result": "模型性能评估包括平均精度（mAP）、F1-score、精确率和召回率，分别为91.05、89.40、91.22和87.66，展示了YOLOv8的优越性能。\n", 
  "conclusion": "该方法提供了早期植物病害检测的可扩展、自动化解决方案，可以增加农作物产量，减少对人工监控的依赖，并支持可持续农业实践。\n"}
}

<details>
  <summary>Details</summary>

**Motivation:** {
  "tldr": "本研究提出了一种利用YOLOv7和YOLOv8进行植物病害检测的系统，通过在植物叶片图像数据集上微调这些模型，检测细菌、真菌和病毒性病害的表现优异，展示了其在现代农业实践中的应用潜力。\n", 
  "motivation": "植物疾病对农民和农业部门构成挑战，早期检测可以减轻其影响并防止广泛损害，随着技术进步，有机会自动化疾病监测，以提高农作物产量和质量。\n", 
  "method": "研究采用了YOLOv7和YOLOv8这两个最先进的对象检测模型，并通过在植物叶片图像数据集上进行微调，用于识别和监控植物疾病。\n", 
  "result": "模型性能评估包括平均精度（mAP）、F1-score、精确率和召回率，分别为91.05、89.40、91.22和87.66，展示了YOLOv8的优越性能。\n", 
  "conclusion": "该方法提供了早期植物病害检测的可扩展、自动化解决方案，可以增加农作物产量，减少对人工监控的依赖，并支持可持续农业实践。\n"}
}

**Method:** {
  "tldr": "本研究提出了一种利用YOLOv7和YOLOv8进行植物病害检测的系统，通过在植物叶片图像数据集上微调这些模型，检测细菌、真菌和病毒性病害的表现优异，展示了其在现代农业实践中的应用潜力。\n", 
  "motivation": "植物疾病对农民和农业部门构成挑战，早期检测可以减轻其影响并防止广泛损害，随着技术进步，有机会自动化疾病监测，以提高农作物产量和质量。\n", 
  "method": "研究采用了YOLOv7和YOLOv8这两个最先进的对象检测模型，并通过在植物叶片图像数据集上进行微调，用于识别和监控植物疾病。\n", 
  "result": "模型性能评估包括平均精度（mAP）、F1-score、精确率和召回率，分别为91.05、89.40、91.22和87.66，展示了YOLOv8的优越性能。\n", 
  "conclusion": "该方法提供了早期植物病害检测的可扩展、自动化解决方案，可以增加农作物产量，减少对人工监控的依赖，并支持可持续农业实践。\n"}
}

**Result:** {
  "tldr": "本研究提出了一种利用YOLOv7和YOLOv8进行植物病害检测的系统，通过在植物叶片图像数据集上微调这些模型，检测细菌、真菌和病毒性病害的表现优异，展示了其在现代农业实践中的应用潜力。\n", 
  "motivation": "植物疾病对农民和农业部门构成挑战，早期检测可以减轻其影响并防止广泛损害，随着技术进步，有机会自动化疾病监测，以提高农作物产量和质量。\n", 
  "method": "研究采用了YOLOv7和YOLOv8这两个最先进的对象检测模型，并通过在植物叶片图像数据集上进行微调，用于识别和监控植物疾病。\n", 
  "result": "模型性能评估包括平均精度（mAP）、F1-score、精确率和召回率，分别为91.05、89.40、91.22和87.66，展示了YOLOv8的优越性能。\n", 
  "conclusion": "该方法提供了早期植物病害检测的可扩展、自动化解决方案，可以增加农作物产量，减少对人工监控的依赖，并支持可持续农业实践。\n"}
}

**Conclusion:** {
  "tldr": "本研究提出了一种利用YOLOv7和YOLOv8进行植物病害检测的系统，通过在植物叶片图像数据集上微调这些模型，检测细菌、真菌和病毒性病害的表现优异，展示了其在现代农业实践中的应用潜力。\n", 
  "motivation": "植物疾病对农民和农业部门构成挑战，早期检测可以减轻其影响并防止广泛损害，随着技术进步，有机会自动化疾病监测，以提高农作物产量和质量。\n", 
  "method": "研究采用了YOLOv7和YOLOv8这两个最先进的对象检测模型，并通过在植物叶片图像数据集上进行微调，用于识别和监控植物疾病。\n", 
  "result": "模型性能评估包括平均精度（mAP）、F1-score、精确率和召回率，分别为91.05、89.40、91.22和87.66，展示了YOLOv8的优越性能。\n", 
  "conclusion": "该方法提供了早期植物病害检测的可扩展、自动化解决方案，可以增加农作物产量，减少对人工监控的依赖，并支持可持续农业实践。\n"}
}

**Abstract:** Plant diseases pose significant challenges to farmers and the agricultural
sector at large. However, early detection of plant diseases is crucial to
mitigating their effects and preventing widespread damage, as outbreaks can
severely impact the productivity and quality of crops. With advancements in
technology, there are increasing opportunities for automating the monitoring
and detection of disease outbreaks in plants. This study proposed a system
designed to identify and monitor plant diseases using a transfer learning
approach. Specifically, the study utilizes YOLOv7 and YOLOv8, two
state-ofthe-art models in the field of object detection. By fine-tuning these
models on a dataset of plant leaf images, the system is able to accurately
detect the presence of Bacteria, Fungi and Viral diseases such as Powdery
Mildew, Angular Leaf Spot, Early blight and Tomato mosaic virus. The model's
performance was evaluated using several metrics, including mean Average
Precision (mAP), F1-score, Precision, and Recall, yielding values of 91.05,
89.40, 91.22, and 87.66, respectively. The result demonstrates the superior
effectiveness and efficiency of YOLOv8 compared to other object detection
methods, highlighting its potential for use in modern agricultural practices.
The approach provides a scalable, automated solution for early any plant
disease detection, contributing to enhanced crop yield, reduced reliance on
manual monitoring, and supporting sustainable agricultural practices.

</details>


### [32] [Diffusion-Based Image Augmentation for Semantic Segmentation in Outdoor Robotics](https://arxiv.org/abs/2507.00153)
*Peter Mortimer,Mirko Maehlisch*

Main category: cs.CV

> 本文提出了一种基于扩散的图像增强方法，以提高基于学习算法的感知系统在域外环境下的性能表现，特别是针对雪地环境。这种方法提高了模型在面对未见过场景时的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 基于学习的感知算法在部署到域外和代表性不足的环境时，其性能会下降。特别是户外机器人，由于动态光照、季节性和天气影响导致的视觉场景快速变化，使得训练数据中代表性不足。因此，我们专注于为自动驾驶车辆在雪地环境中的部署做好准备。

**Method:** 我们提出了一种基于扩散的图像增强方法来更好地模拟部署环境中的训练数据。这种方法利用了在互联网规模数据集上训练的公开视觉基础模型。通过这种方法，我们可以掌控训练数据中地面表面的语义分布，并对模型进行微调以适应部署环境。我们还使用开放式词汇语义分割模型来过滤掉含有幻觉的增强候选图像。

**Result:** 我们认为，基于扩散的图像增强方法可以扩展到许多其他环境，而不仅仅是雪地表面，比如沙滩和火山地形。

**Conclusion:** 本文提出了一种基于扩散的图像增强方法，以改善学习系统在雪地环境中的性能，并对该方法在其他应用场景中的潜力进行了展望。

**Abstract:** The performance of leaning-based perception algorithms suffer when deployed
in out-of-distribution and underrepresented environments. Outdoor robots are
particularly susceptible to rapid changes in visual scene appearance due to
dynamic lighting, seasonality and weather effects that lead to scenes
underrepresented in the training data of the learning-based perception system.
In this conceptual paper, we focus on preparing our autonomous vehicle for
deployment in snow-filled environments. We propose a novel method for
diffusion-based image augmentation to more closely represent the deployment
environment in our training data. Diffusion-based image augmentations rely on
the public availability of vision foundation models learned on internet-scale
datasets. The diffusion-based image augmentations allow us to take control over
the semantic distribution of the ground surfaces in the training data and to
fine-tune our model for its deployment environment. We employ open vocabulary
semantic segmentation models to filter out augmentation candidates that contain
hallucinations. We believe that diffusion-based image augmentations can be
extended to many other environments apart from snow surfaces, like sandy
environments and volcanic terrains.

</details>


### [33] [FreeLong++: Training-Free Long Video Generation via Multi-band SpectralFusion](https://arxiv.org/abs/2507.00162)
*Yu Lu,Yi Yang*

Main category: cs.CV

> 论文解决了长时间视频生成质量下降问题，提出了FreeLong和FreeLong++框架，通过多频带融合技术，在已有的视频生成模型上插件式地提升了生成长时间视频的质量。

<details>
  <summary>Details</summary>

**Motivation:** 随着视频长度的增加，现有短视频生成模型生成的视频质量显著下降，出现高频成分扭曲的问题。为了应对这一挑战，该论文提出了解决方案，以提升长时间视频生成的时空一致性和视觉保真度。

**Method:** 提出了FreeLong和FreeLong++两种框架，通过融合全局低频特征和局部高频特征来改善长时间视频生成的质量。FreeLong++扩展了FreeLong的双分支设计，采用了多分支架构，其中每个分支在不同的时间尺度上工作，以实现从低频到高频的多频带融合。

**Result:** 实验证明，该方法在生成超过原生长度4倍和8倍的长时间视频任务上优于之前的模型，并且可以支持连贯的多提示视频生成和长深度或姿态序列的可控视频生成。

**Conclusion:** 通过引入FreeLong和FreeLong++，论文达到了无需额外训练即可生成既具有语义连贯性也保持精细运动细节的高质量长时间视频的目的。

**Abstract:** Recent advances in video generation models have enabled high-quality short
video generation from text prompts. However, extending these models to longer
videos remains a significant challenge, primarily due to degraded temporal
consistency and visual fidelity. Our preliminary observations show that naively
applying short-video generation models to longer sequences leads to noticeable
quality degradation. Further analysis identifies a systematic trend where
high-frequency components become increasingly distorted as video length grows,
an issue we term high-frequency distortion. To address this, we propose
FreeLong, a training-free framework designed to balance the frequency
distribution of long video features during the denoising process. FreeLong
achieves this by blending global low-frequency features, which capture holistic
semantics across the full video, with local high-frequency features extracted
from short temporal windows to preserve fine details. Building on this,
FreeLong++ extends FreeLong dual-branch design into a multi-branch architecture
with multiple attention branches, each operating at a distinct temporal scale.
By arranging multiple window sizes from global to local, FreeLong++ enables
multi-band frequency fusion from low to high frequencies, ensuring both
semantic continuity and fine-grained motion dynamics across longer video
sequences. Without any additional training, FreeLong++ can be plugged into
existing video generation models (e.g. Wan2.1 and LTX-Video) to produce longer
videos with substantially improved temporal consistency and visual fidelity. We
demonstrate that our approach outperforms previous methods on longer video
generation tasks (e.g. 4x and 8x of native length). It also supports coherent
multi-prompt video generation with smooth scene transitions and enables
controllable video generation using long depth or pose sequences.

</details>


### [34] [SelvaBox: A high-resolution dataset for tropical tree crown detection](https://arxiv.org/abs/2507.00170)
*Hugo Baudchon,Arthur Ouaknine,Martin Weiss,Mélisande Teng,Thomas R. Walla,Antoine Caron-Guay,Christopher Pal,Etienne Laliberté*

Main category: cs.CV

> 论文介绍了SelvaBox，这是最大开放存取的热带树木冠层检测数据集，证明了高分辨率图像和该数据集在模型训练上的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 创建SelvaBox数据集是为了应对在热带森林中检测个体树木冠层这一复杂挑战，这对于研究受到人类干预和气候变化影响的生态系统至关重要。由于热带树木冠层在大小、结构和模式上差异显著，并且相互重叠纠缠，因此需要先进的遥感方法应用于高分辨率图像。

**Method:** 该论文采用了高分辨率的无人机图像，并创建了SelvaBox，这是最大的开放存取的热带树木冠层检测数据集。数据集包含超过83,000个手动标注的冠层，跨越三个国家，比所有之前的热带森林数据集结合大一个数量级。

**Result:** 通过在SelvaBox上的广泛基准测试，论文得出了两个关键发现：1) 更高分辨率的输入图像能够提高冠层目标检测的准确性；2) 仅基于SelvaBox训练的模型可以在未见过的热带树冠数据集上实现竞争性的零样本检测性能，这个能力与竞争对手的方法相当或超越。此外，同时训练SelvaBox和其他三个数据集，可在统一的多分辨率管道下产生最优的探测器排名。

**Conclusion:** 该论文的结论是，SelvaBox数据集能够极大地促进热带森林中个体树冠的检测，推动生态研究，并且展示了提高模型准确定位精度和零样本检测能力的方法。该数据集、代码和预训练权重已经公开提供。

**Abstract:** Detecting individual tree crowns in tropical forests is essential to study
these complex and crucial ecosystems impacted by human interventions and
climate change. However, tropical crowns vary widely in size, structure, and
pattern and are largely overlapping and intertwined, requiring advanced remote
sensing methods applied to high-resolution imagery. Despite growing interest in
tropical tree crown detection, annotated datasets remain scarce, hindering
robust model development. We introduce SelvaBox, the largest open-access
dataset for tropical tree crown detection in high-resolution drone imagery. It
spans three countries and contains more than 83,000 manually labeled crowns -
an order of magnitude larger than all previous tropical forest datasets
combined. Extensive benchmarks on SelvaBox reveal two key findings: (1)
higher-resolution inputs consistently boost detection accuracy; and (2) models
trained exclusively on SelvaBox achieve competitive zero-shot detection
performance on unseen tropical tree crown datasets, matching or exceeding
competing methods. Furthermore, jointly training on SelvaBox and three other
datasets at resolutions from 3 to 10 cm per pixel within a unified
multi-resolution pipeline yields a detector ranking first or second across all
evaluated datasets. Our dataset, code, and pre-trained weights are made public.

</details>


### [35] [Graph-Based Deep Learning for Component Segmentation of Maize Plants](https://arxiv.org/abs/2507.00182)
*J. I. Ruíz,A. Méndez,E. Rodríguez*

Main category: cs.CV

> 研究提出了一种基于图神经网络的新方法来提高3D LiDAR点云数据中植物组件识别的精度，超过了其他基于点云的方法。

<details>
  <summary>Details</summary>

**Motivation:** 在精准农业中，探索作物生产时识别单个植物组件是最重要的任务之一。然而，使用传统2D成像、3D重建和卷积神经网络（CNN）处理3D数据和识别个体植物组件时存在一些缺点。因此，为了改进这一领域，研究提出了一种新的方法。

**Method:** 本研究提出了一种基于图神经网络（GNN）的新深度学习架构，用于检测光检测和测距（LiDAR）3D点云（PC）数据集中的个体植物组成部分。每个点被视为一个节点，并通过K-最近邻（KNN）层建立边缘，从而表示3D点云数据集。随后使用Edge-Conv层进一步增加每个点的特征。最后，应用图注意力网络（GAT）对植物的可见表型组件（如叶片、茎和土壤）进行分类。

**Result:** 研究表明，基于图的深度学习方法在识别个体植物组件的分割准确性上表现出色，平均IoU百分比超过80%，优于基于点云的其他现有模型。

**Conclusion:** 该研究证明了图神经网络方法在提高植物组件识别精度方面具有显著优势。

**Abstract:** In precision agriculture, one of the most important tasks when exploring crop
production is identifying individual plant components. There are several
attempts to accomplish this task by the use of traditional 2D imaging, 3D
reconstructions, and Convolutional Neural Networks (CNN). However, they have
several drawbacks when processing 3D data and identifying individual plant
components. Therefore, in this work, we propose a novel Deep Learning
architecture to detect components of individual plants on Light Detection and
Ranging (LiDAR) 3D Point Cloud (PC) data sets. This architecture is based on
the concept of Graph Neural Networks (GNN), and feature enhancing with
Principal Component Analysis (PCA). For this, each point is taken as a vertex
and by the use of a K-Nearest Neighbors (KNN) layer, the edges are established,
thus representing the 3D PC data set. Subsequently, Edge-Conv layers are used
to further increase the features of each point. Finally, Graph Attention
Networks (GAT) are applied to classify visible phenotypic components of the
plant, such as the leaf, stem, and soil. This study demonstrates that our
graph-based deep learning approach enhances segmentation accuracy for
identifying individual plant components, achieving percentages above 80% in the
IoU average, thus outperforming other existing models based on point clouds.

</details>


### [36] [Computer Vision for Objects used in Group Work: Challenges and Opportunities](https://arxiv.org/abs/2507.00224)
*Changsoo Jung,Sheikh Mannan,Jack Fitzgerald,Nathaniel Blanchard*

Main category: cs.CV

> 研究引入FiboSB数据集评估6D姿态估计在小组协作任务上的效果，发现现有方法在对象检测上有局限，并通过优化模型提升了检测效果。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于解决现有系统在捕捉学生与实物交互过程中存在的准确性问题，尤其是利用6D姿态估计方法。

**Method:** 分析显示，该研究通过引入FiboSB数据集来评估目前最先进6D姿态估计方法的效果，该数据集用于记录小组协作任务中的小物体动态。

**Result:** 研究结果表明，当前最先进的6D姿态估计算法在处理协作小组任务时存在局限，特别是在对象检测模块上。通过微调YOLO11-x模型，研究达到了0.898的mAP_50整体分数。

**Conclusion:** 研究得出，改进后的YOLO11-x在FiboSB数据集上表现优异，为在复杂协作场景下使用6D姿态估计奠定了基础。

**Abstract:** Interactive and spatially aware technologies are transforming educational
frameworks, particularly in K-12 settings where hands-on exploration fosters
deeper conceptual understanding. However, during collaborative tasks, existing
systems often lack the ability to accurately capture real-world interactions
between students and physical objects. This issue could be addressed with
automatic 6D pose estimation, i.e., estimation of an object's position and
orientation in 3D space from RGB images or videos. For collaborative groups
that interact with physical objects, 6D pose estimates allow AI systems to
relate objects and entities. As part of this work, we introduce FiboSB, a novel
and challenging 6D pose video dataset featuring groups of three participants
solving an interactive task featuring small hand-held cubes and a weight scale.
This setup poses unique challenges for 6D pose because groups are holistically
recorded from a distance in order to capture all participants -- this, coupled
with the small size of the cubes, makes 6D pose estimation inherently
non-trivial. We evaluated four state-of-the-art 6D pose estimation methods on
FiboSB, exposing the limitations of current algorithms on collaborative group
work. An error analysis of these methods reveals that the 6D pose methods'
object detection modules fail. We address this by fine-tuning YOLO11-x for
FiboSB, achieving an overall mAP_50 of 0.898. The dataset, benchmark results,
and analysis of YOLO11-x errors presented here lay the groundwork for
leveraging the estimation of 6D poses in difficult collaborative contexts.

</details>


### [37] [VOCAL: Visual Odometry via ContrAstive Learning](https://arxiv.org/abs/2507.00243)
*Chi-Yao Huang,Zeel Bhatt,Yezhou Yang*

Main category: cs.CV

> 本文介绍了一种名为VOCAL的新框架，通过贝叶斯推理和表示学习框架提升视觉里程计的解释性和兼容性。实验结果表明VOCAL在可解释性和灵活性方面优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 许多基于学习的VO技术依赖于刚性的几何假设，这在解释性和理论依据方面存在局限，特别是在完全数据驱动的框架中。因此，作者提出VOCAL框架，旨在克服这些限制，提高VO的解释性和兼容性。

**Method:** VOCAL (Visual Odometry via ContrAstive Learning)框架通过将视觉里程计（VO）重新构想为标签排序挑战来克服现有学习型VO方法的限制，采用贝叶斯推理和表示学习框架将视觉特征组织成反映相机状态的形式。通过强制相似的相机状态在潜在空间中收敛成一致且空间连贯的表示形式，增强理解性和多模态数据兼容性。

**Result:** 在KITTI数据集上进行了广泛评估，显示VOCAL提高了可解释性和灵活性，使其更一般化，空间智能更具解释性。

**Conclusion:** VOCAL框架不仅通过强化学习特征的可解释性推动了视觉里程计的进步，而且还确保了与多模态数据源的兼容性，为未来的研究提供了良好的方向。

**Abstract:** Breakthroughs in visual odometry (VO) have fundamentally reshaped the
landscape of robotics, enabling ultra-precise camera state estimation that is
crucial for modern autonomous systems. Despite these advances, many
learning-based VO techniques rely on rigid geometric assumptions, which often
fall short in interpretability and lack a solid theoretical basis within fully
data-driven frameworks. To overcome these limitations, we introduce VOCAL
(Visual Odometry via ContrAstive Learning), a novel framework that reimagines
VO as a label ranking challenge. By integrating Bayesian inference with a
representation learning framework, VOCAL organizes visual features to mirror
camera states. The ranking mechanism compels similar camera states to converge
into consistent and spatially coherent representations within the latent space.
This strategic alignment not only bolsters the interpretability of the learned
features but also ensures compatibility with multimodal data sources. Extensive
evaluations on the KITTI dataset highlight VOCAL's enhanced interpretability
and flexibility, pushing VO toward more general and explainable spatial
intelligence.

</details>


### [38] [Developing Lightweight DNN Models With Limited Data For Real-Time Sign Language Recognition](https://arxiv.org/abs/2507.00248)
*Nikita Nikitin,Eugene Fomin*

Main category: cs.CV

> 本文提出了一种新的实时光学手势识别框架，利用轻量级深度神经网络在有限的数据上进行训练，解决了数据稀缺、计算成本高以及帧率不匹配的问题，且实现了低延迟的实时处理能力。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在解决当前手势语言识别中存在的关键挑战，包括数据稀缺性、高计算成本以及训练和推理环境之间的帧率差异问题。

**Method:** 我们提出了一个利用轻量级深度神经网络实现实时光学手势识别的新框架。该系统通过将手势语言的特定参数（如手形、掌心朝向、运动和位置）转换为向量化输入，并利用MediaPipe进行关键点提取，解决了数据稀缺、计算成本高以及训练和推断环境之间帧率不匹配等问题。

**Result:** 我们的模型在孤立手势识别中达到了92%的准确率，并且已经在‘slait ai’web应用程序中成功集成，展示了稳定的推理性能。

**Conclusion:** 本文提出的方法可以实现准确的手势识别，并且在边缘设备上实现了低延迟的实时处理能力，具有重要的实际应用价值。

**Abstract:** We present a novel framework for real-time sign language recognition using
lightweight DNNs trained on limited data. Our system addresses key challenges
in sign language recognition, including data scarcity, high computational
costs, and discrepancies in frame rates between training and inference
environments. By encoding sign language specific parameters, such as handshape,
palm orientation, movement, and location into vectorized inputs, and leveraging
MediaPipe for landmark extraction, we achieve highly separable input data
representations. Our DNN architecture, optimized for sub 10MB deployment,
enables accurate classification of 343 signs with less than 10ms latency on
edge devices. The data annotation platform 'slait data' facilitates structured
labeling and vector extraction. Our model achieved 92% accuracy in isolated
sign recognition and has been integrated into the 'slait ai' web application,
where it demonstrates stable inference.

</details>
