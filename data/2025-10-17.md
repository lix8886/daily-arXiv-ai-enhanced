<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bridging the Semantic Gap: Contrastive Rewards for Multilingual Text-to-SQL](https://arxiv.org/abs/2510.13827)
*Ashish Kattamuri,Ishita Prasad,Meetu Malhotra,Arpita Vats,Rahul Raja,Albert Lie*

Main category: cs.CL

> 本文提出的结合对比奖励信号的Group Relative Policy Optimization (GRPO)框架显著提高了Text-to-SQL系统的跨语言性能，尤其是在语义准确性和执行准确性方面。

<details>
  <summary>Details</summary>

**Motivation:** 当前的Text-to-SQL方法在评估过程中仅专注于可执行查询，而忽略了语义对齐的挑战，包括查询的语义含义和执行结果的正确性。甚至执行准确性在从英语转换到其他语言时也显著下降，非英语语言的平均下降幅度为6个百分点。

**Method:** 提出了一种新的框架，结合了多语言对比奖励信号中的集团相对策略优化（GRPO），以提高Text-to-SQL系统在跨语言场景中的任务效率和语义准确性。该方法通过基于语义相似性的奖励信号教导模型以获得更好的SQL生成和用户意图之间的对应关系。

**Result:** {

**Conclusion:** 实验表明，在没有大规模训练数据的情况下，利用对比奖励信号进行定向语义对齐可以有效提高Text-to-SQL系统的性能。

**Abstract:** Current Text-to-SQL methods are evaluated and only focused on executable
queries, overlooking the semantic alignment challenge -- both in terms of the
semantic meaning of the query and the correctness of the execution results.
Even execution accuracy itself shows significant drops when moving from English
to other languages, with an average decline of 6 percentage points across
non-English languages. We address these challenges by presenting a new
framework that combines Group Relative Policy Optimization (GRPO) within a
multilingual contrastive reward signal to enhance both task efficiency and
semantic accuracy in Text-to-SQL systems in cross-lingual scenarios. Our method
teaches models to obtain better correspondence between SQL generation and user
intent by combining a reward signal based on semantic similarity. On the
seven-language MultiSpider dataset, fine-tuning the LLaMA-3-3B model with GRPO
improved the execution accuracy up to 87.4 percent (+26 pp over zero-shot) and
semantic accuracy up to 52.29 percent (+32.86 pp). Adding our contrastive
reward signal in the GRPO framework further improved the average semantic
accuracy to 59.14 percent (+6.85 pp, up to +10 pp for Vietnamese). Our
experiments showcase that a smaller, parameter-efficient 3B LLaMA model
fine-tuned with our contrastive reward signal outperforms a much larger
zero-shot 8B LLaMA model, with an uplift of 7.43 pp in execution accuracy (from
81.43 percent on the 8B model to 88.86 percent on the 3B model), and nearly
matches its semantic accuracy (59.14 percent vs. 68.57 percent) -- all using
just 3,000 reinforcement learning training examples. These results demonstrate
how we can improve the performance of Text-to-SQL systems with contrastive
rewards for directed semantic alignment, without requiring large-scale training
datasets.

</details>


### [2] [From Explainability to Action: A Generative Operational Framework for Integrating XAI in Clinical Mental Health Screening](https://arxiv.org/abs/2510.13828)
*Ratna Kandala,Akshata Kishore Moharir,Divya Arvinda Nayak*

Main category: cs.CL

> 文章提出了生成操作框架，使用大型语言模型作为核心，将XAI工具的原始技术输出转化为可操作的临床叙述，解决XAI技术在临床应用中的可操作性问题。

<details>
  <summary>Details</summary>

**Motivation:** 目前的XAI技术，如SHAP和LIME，虽然在生成技术上精确的输出（例如特征重要性分数）方面表现出色，但未能提供对临床相关且具有操作性的见解，这些见解可以被临床医生使用或被患者理解。文章旨在解决这一技术透明度与人类实用性之间的脱节问题。

**Method:** 提出了一种名为生成操作框架的新系统架构，该框架使用大型语言模型（LLMs）作为核心翻译引擎。该框架设计用于吸收来自各种XAI工具的原始技术输出，并与临床指南结合（通过RAG），自动生成可读的、基于证据的临床叙述。

**Result:** 文章详细分析了它集成的各个组件，并展示了该框架如何直接解决关键操作障碍，包括工作流程整合、偏见缓解和利益相关者特定的交流。

**Conclusion:** 该论文提供了一条战略路线图，旨在将领域从生成孤立的数据点转向在临床实践中提供整合的、可操作的和值得信赖的AI。

**Abstract:** Explainable Artificial Intelligence (XAI) has been presented as the critical
component for unlocking the potential of machine learning in mental health
screening (MHS). However, a persistent lab-to-clinic gap remains. Current XAI
techniques, such as SHAP and LIME, excel at producing technically faithful
outputs such as feature importance scores, but fail to deliver clinically
relevant, actionable insights that can be used by clinicians or understood by
patients. This disconnect between technical transparency and human utility is
the primary barrier to real-world adoption. This paper argues that this gap is
a translation problem and proposes the Generative Operational Framework, a
novel system architecture that leverages Large Language Models (LLMs) as a
central translation engine. This framework is designed to ingest the raw,
technical outputs from diverse XAI tools and synthesize them with clinical
guidelines (via RAG) to automatically generate human-readable, evidence-backed
clinical narratives. To justify our solution, we provide a systematic analysis
of the components it integrates, tracing the evolution from intrinsic models to
generative XAI. We demonstrate how this framework directly addresses key
operational barriers, including workflow integration, bias mitigation, and
stakeholder-specific communication. This paper also provides a strategic
roadmap for moving the field beyond the generation of isolated data points
toward the delivery of integrated, actionable, and trustworthy AI in clinical
practice.

</details>


### [3] [A Linguistics-Aware LLM Watermarking via Syntactic Predictability](https://arxiv.org/abs/2510.13829)
*Shinwoo Park,Hyejin Park,Hyeseon Ahn,Yo-Sub Han*

Main category: cs.CL

> 本文介绍了STELA框架，通过词性n元语法模型的语义不确定性来动态调制水印信号，实现了无需访问模型logits的公开可验证检测，提高了检测鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）的快速发展，需要可靠的治理工具，特别是可公共验证的水印技术，来促进一个可信赖的AI生态系统，以平衡文本质量和检测鲁棒性之间的挑战。

**Method:** STELA框架通过利用词性(POS)n元语法模型的语义不确定性来动态调制信号，从而在语法约束较大的语境中减弱水印强度，在语义灵活性较大的语境中增强水印强度，实现了文本质量和检测鲁棒性间的平衡。检测器无需访问模型的logits，实现了公开可验证的检测。

**Result:** 通过对分析英语、孤立汉语和黏着语韩国语等类型不同的语言的广泛实验，结果表明，STELA在检测鲁棒性方面超越了以往的方法。

**Conclusion:** 通过广泛实验，STELA证明在不同类型的语言中能够超越以往方法，从而在公开可验证性和检测鲁棒性上提供了优异的表现。

**Abstract:** As large language models (LLMs) continue to advance rapidly, reliable
governance tools have become critical. Publicly verifiable watermarking is
particularly essential for fostering a trustworthy AI ecosystem. A central
challenge persists: balancing text quality against detection robustness. Recent
studies have sought to navigate this trade-off by leveraging signals from model
output distributions (e.g., token-level entropy); however, their reliance on
these model-specific signals presents a significant barrier to public
verification, as the detection process requires access to the logits of the
underlying model. We introduce STELA, a novel framework that aligns watermark
strength with the linguistic degrees of freedom inherent in language. STELA
dynamically modulates the signal using part-of-speech (POS) n-gram-modeled
linguistic indeterminacy, weakening it in grammatically constrained contexts to
preserve quality and strengthen it in contexts with greater linguistic
flexibility to enhance detectability. Our detector operates without access to
any model logits, thus facilitating publicly verifiable detection. Through
extensive experiments on typologically diverse languages-analytic English,
isolating Chinese, and agglutinative Korean-we show that STELA surpasses prior
methods in detection robustness. Our code is available at
https://github.com/Shinwoo-Park/stela_watermark.

</details>


### [4] [Users as Annotators: LLM Preference Learning from Comparison Mode](https://arxiv.org/abs/2510.13830)
*Zhongze Cai,Xiaocheng Li*

Main category: cs.CL

> 论文提出了一种新的方法，通过用户行为模型来评估并过滤成对偏好评注数据的质量，以便更好地对齐大型语言模型。

<details>
  <summary>Details</summary>

**Motivation:** 论文的研究动机在于探索一种新的方式来收集成对的偏好评注数据，以解决专业标注者的人力资源限制，并利用用户在使用LLM时提供的反馈。

**Method:** 本论文提出了一种利用用户行为模型评估和过滤用户标注的成对偏好数据的方法。具体而言，通过对不同的模型或同一模型的不同版本生成两组响应，并通过期望最大化算法估计用户的潜在质量因素，从而过滤掉低质量的用户标注数据。

**Result:** 实验结果表明，该方法在捕捉用户行为和过滤数据以对齐语言模型方面是有效的。

**Conclusion:** 论文得出结论称，利用用户的日常交互来收集偏好评注数据可以帮助改进模型的对齐过程，尽管存在质量问题，但通过过滤机制可以提高数据的质量。

**Abstract:** Pairwise preference data have played an important role in the alignment of
large language models (LLMs). Each sample of such data consists of a prompt,
two different responses to the prompt, and a binary label indicating which of
the two responses is better. The labels are usually annotated by professional
human annotators. In this paper, we consider an alternative approach to collect
pairwise preference data -- user annotation from comparison mode. With the
increasingly wider adoption of LLMs among the population, users are
contributing more and more of their preference labels through their daily
interactions with the LLMs. The upside of such labels is that users are the
best experts in judging the responses to their own queries/prompts, but the
downside is the lack of quality control in these labels. In this paper, we
consider a new idea of generating two responses from two different models or
two different versions of the same model. The asymmetry allows us to make an
inference of the user's data quality through our proposed user behavior model.
We develop an expectation-maximization algorithm to estimate a latent quality
factor of the user, and filter users' annotation data accordingly. The
downstream task shows the effectiveness of our approach in both capturing the
user behavior and data filtering for LLM alignment.

</details>


### [5] [Informed Routing in LLMs: Smarter Token-Level Computation for Faster Inference](https://arxiv.org/abs/2510.13831)
*Chao Han,Yijuan Liang,Zihao Xuan,Daokuan Wu,Wei Zhang,Xiaoyu Shen*

Main category: cs.CL

> 本文提出了 informed routing 新方法，通过评估 token 的即刻重要性和可恢复性，引入 Lightweight Feature Forecaster (LFF) 模块优化 token 的执行或近似策略，显著提升大型语言模型的推理效率。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有技术依赖贪心路由策略导致的信息不可逆损失和次优 token 选择的问题，提高大型语言模型在实际应用中的推理效率。

**Method:** 介绍了名为 informed routing 的新范式，通过评估 token 的即刻重要性和可恢复性来提高效率。提出了 Lightweight Feature Forecaster (LFF) 模块，在路由决策前预测单元输出，实现精确或近似执行策略，从而减少计算同时保持模型保真度。

**Result:** 实验显示，informed routing 在多个稀疏度水平上实现了最先进的效率-性能权衡，包括语言建模和推理任务。即使不进行最终的 LoRA 微调，该方法也能匹配甚至超越需要完全微调的强基线方法，并且将训练时间减少超过 50%。

**Conclusion:** 新提出的 informed routing 方法显著改进了动态 token 级计算分配的效率和性能，且无需复杂微调，展现了优越的资源利用能力。

**Abstract:** The deployment of large language models (LLMs) in real-world applications is
increasingly limited by their high inference cost. While recent advances in
dynamic token-level computation allocation attempt to improve efficiency by
selectively activating model components per token, existing methods rely on
greedy routing--a myopic execute-or-skip mechanism that often leads to
irreversible information loss and suboptimal token selection. This paper
introduces informed routing, a new paradigm that proactively addresses these
issues. The key insight is to assess not only a token's immediate importance
but also its recoverability, i.e., how well its transformation can be
approximated. To this end, we propose the Lightweight Feature Forecaster (LFF),
a small predictive module that estimates a unit's output before routing
decisions are made. This enables a flexible execute-or-approximate policy that
preserves model fidelity while drastically reducing computation. Extensive
experiments on both language modeling and reasoning tasks show that informed
routing achieves state-of-the-art efficiency-performance trade-offs across
multiple sparsity levels. Notably, even without final LoRA fine-tuning, our
method matches or surpasses strong baselines that require full fine-tuning, all
while reducing training time by over 50%. The code is available at:
https://github.com/EIT-NLP/informed-routing

</details>


### [6] [Entropy Meets Importance: A Unified Head Importance-Entropy Score for Stable and Efficient Transformer Pruning](https://arxiv.org/abs/2510.13832)
*Minsik Choi,Hyegang Son,Changhoon Kim,Young Geun Kim*

Main category: cs.CL

> 本文提出了HIES方法，通过结合头部重要性评分与注意力熵来改进Transformer模型，实验表明这种方法能提高模型质量和稳定性，同时实现了模型压缩。

<details>
  <summary>Details</summary>

**Motivation:** 多层和注意力头的结构特征带来了推理和部署的效率挑战，本文旨在通过剪枝方法解决这些问题。

**Method:** 引入了一种新的剪枝标准HIES（Head Importance-Entropy Score），该标准结合了头部重要性评分与注意力熵，提供了关于每个头部贡献度的补充证据。

**Result:** 经验结果显示，基于HIES的剪枝方法相比只使用HIS的方法，能提高最多15.2%的模型质量，同时稳定性的提升可达2.04倍。

**Conclusion:** HIES的引入使得模型压缩得以实现，同时保证了准确性和稳定性不受损失。

**Abstract:** Transformer-based models have achieved remarkable performance in NLP tasks.
However, their structural characteristics-multiple layers and attention
heads-introduce efficiency challenges in inference and deployment. To address
these challenges, various pruning methods have recently been proposed. Notably,
gradient-based methods using Head Importance Scores (HIS) have gained traction
for interpretability, efficiency, and ability to identify redundant heads.
However, HIS alone has limitations as it captures only the gradient-driven
contribution, overlooking the diversity of attention patterns. To overcome
these limitations, we introduce a novel pruning criterion, HIES (Head
Importance-Entropy Score), which integrates head importance scores with
attention entropy, providing complementary evidence on per-head contribution.
Empirically, HIES-based pruning yields up to 15.2% improvement in model quality
and 2.04x improvement in stability over HIS-only methods, enabling substantial
model compression without sacrificing either accuracy or stability. Code will
be released upon publication.

</details>


### [7] [ConDABench: Interactive Evaluation of Language Models for Data Analysis](https://arxiv.org/abs/2510.13835)
*Avik Dutta,Priyanshu Gupta,Hosein Hasanbeig,Rahul Pratap Singh,Harshit Nigam,Sumit Gulwani,Arjun Radhakrishna,Gustavo Soares,Ashish Tiwari*

Main category: cs.CL

> ConDABench是一个生成对话式数据分析基准并评估交互性工具的框架，显示了其在复杂数据分析任务上的必要性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准无法捕捉现实世界数据中分析任务的复杂性，尤其是用户交互的重要性。因此，需要一个框架来生成对话式数据分析任务，并提供第一个全面支持交互性的评估基准。

**Method:** 介绍了一个名为ConDABench的框架，用于生成对话式数据分析基准，并评估外部工具在这些基准上的表现。该框架包括一个多智能体的工作流，用于从描述公共数据集获得的见解的文章中生成现实的基准，以及包含1,420个对话式数据分析问题。还有用于系统评估对话式数据分析工具的评估工具。

**Result:** 评估表明最新模型在解决对话式数据分析问题上表现更好，但面对需要长时间交互的任务则不尽如人意。

**Conclusion:** ConDABench为模型构建者提供了一个量化进步的途径，目标是创建能完成复杂交互任务的协作模型。

**Abstract:** Real-world data analysis tasks often come with under-specified goals and
unclean data. User interaction is necessary to understand and disambiguate a
user's intent, and hence, essential to solving these complex tasks. Existing
benchmarks for evaluating LLMs on data analysis tasks do not capture these
complexities or provide first-class support for interactivity. We introduce
ConDABench, a framework for generating conversational data analysis (ConDA)
benchmarks and evaluating external tools on the generated benchmarks. \bench
consists of (a) a multi-agent workflow for generating realistic benchmarks from
articles describing insights gained from public datasets, (b) 1,420 ConDA
problems generated using this workflow, and (c) an evaluation harness that, for
the first time, makes it possible to systematically evaluate conversational
data analysis tools on the generated ConDA problems. Evaluation of
state-of-the-art LLMs on the benchmarks reveals that while the new generation
of models are better at solving more instances, they are not necessarily better
at solving tasks that require sustained, long-form engagement. ConDABench is an
avenue for model builders to measure progress towards truly collaborative
models that can complete complex interactive tasks.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [MultiFoodhat: A potential new paradigm for intelligent food quality inspection](https://arxiv.org/abs/2510.13889)
*Yue Hu,Guohang Zhuang*

Main category: cs.CV

> 本研究提出了一种名为MultiFoodChat的框架，用于零样本食品识别。通过视觉-语言模型（VLMs）和大型语言模型（LLMs）的协作推理，在不需额外训练或手动标注的情况下实现了灵活、类似人类的复杂食品场景理解，实验验证了其优越的识别准确性和可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 目前大多数监督模型严重依赖大规模的标注数据，并且对于未见过的食品种类泛化能力有限。为了克服这些挑战，本研究提出了MultiFoodChat框架。

**Method:** 本研究介绍了MultiFoodChat，这是一个基于多智能体推理的对话驱动框架，用于零样本食品识别。框架集成了视觉-语言模型（VLM）和大型语言模型（LLM），通过多轮视觉文本对话实现协作推理。其中，对象感知标记（OPT）捕捉精细的视觉属性，而交互推理代理（IRA）动态解读情境线索以优化预测。

**Result:** 实验结果表明，MultiFoodChat在多个公开食品数据集上相比现有的无监督和少样本方法展现出更高的识别准确率和可解释性。

**Conclusion:** 实验表明，MultiFoodChat在多个公开的食品数据集上实现了优越的识别准确性和可解释性，与现有的无监督和少量样本方法相比表现出色，凸显了其作为智能食品质量检测和分析新范式的潜力。

**Abstract:** Food image classification plays a vital role in intelligent food quality
inspection, dietary assessment, and automated monitoring. However, most
existing supervised models rely heavily on large labeled datasets and exhibit
limited generalization to unseen food categories. To overcome these challenges,
this study introduces MultiFoodChat, a dialogue-driven multi-agent reasoning
framework for zero-shot food recognition. The framework integrates
vision-language models (VLMs) and large language models (LLMs) to enable
collaborative reasoning through multi-round visual-textual dialogues. An Object
Perception Token (OPT) captures fine-grained visual attributes, while an
Interactive Reasoning Agent (IRA) dynamically interprets contextual cues to
refine predictions. This multi-agent design allows flexible and human-like
understanding of complex food scenes without additional training or manual
annotations. Experiments on multiple public food datasets demonstrate that
MultiFoodChat achieves superior recognition accuracy and interpretability
compared with existing unsupervised and few-shot methods, highlighting its
potential as a new paradigm for intelligent food quality inspection and
analysis.

</details>


### [9] [Post-surgical Endometriosis Segmentation in Laparoscopic Videos](https://arxiv.org/abs/2510.13899)
*Andreas Leibetseder,Klaus Schoeffmann,Jörg Keckstein,Simon Keckstein*

Main category: cs.CV

> 此论文介绍了一个系统，用于分析腹腔镜手术视频中的深色子宫内膜异位植片，并通过多色覆盖物标注这些区域，帮助医生改善视频浏览和诊断效果。

<details>
  <summary>Details</summary>

**Motivation:** 由于子宫内膜异位症在体内不同部位的表现形式多样，导致其识别难度大且容易出错，尤其是对于非医学专家而言。此系统旨在辅助妇科医生进行子宫内膜异位症的诊疗。

**Method:** 系统经过训练可以分割出一种常见的子宫内膜异位症表现形式——深色子宫内膜植入物，并在腹腔镜手术视频中标注出这些区域。

**Result:** 系统能够分析腹腔镜视频，以多色覆盖物标注识别的植入物区域，并提供检测摘要，供改善视频浏览使用。

**Conclusion:** 通过此系统，有望提高子宫内膜异位症的识别准确度，减少误诊，从而提高医生对子宫内膜异位症的诊疗效率。

**Abstract:** Endometriosis is a common women's condition exhibiting a manifold visual
appearance in various body-internal locations. Having such properties makes its
identification very difficult and error-prone, at least for laymen and
non-specialized medical practitioners. In an attempt to provide assistance to
gynecologic physicians treating endometriosis, this demo paper describes a
system that is trained to segment one frequently occurring visual appearance of
endometriosis, namely dark endometrial implants. The system is capable of
analyzing laparoscopic surgery videos, annotating identified implant regions
with multi-colored overlays and displaying a detection summary for improved
video browsing.

</details>


### [10] [Efficient Few-Shot Learning in Remote Sensing: Fusing Vision and Vision-Language Models](https://arxiv.org/abs/2510.13993)
*Jia Yun Chua,Argyrios Zolotas,Miguel Arana-Catania*

Main category: cs.CV

> 研究结合视觉模型和视觉语言模型（VLMs）以改进遥感图像分析，特别是飞机检测和场景理解，展示了显著的性能提升，平均MAE提高48.46%，CLIPScore提升6.17%。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视觉模型受限于需要大量的领域特定标注数据和在复杂环境中的理解能力不足。而视觉语言模型（VLMs）由于其互补的特性，特别是将视觉与文本数据融合，其在遥感领域的应用还未充分探索。研究旨在通过使用VLMs来增强遥感图像的分析能力，特别是在少样本学习场景下的表现。

**Method:** 通过将YOLO视觉模型与VLM如LLaVA, ChatGPT, 和Gemini集成来提升遥感图像的解析准确性。模型首先通过YOLO进行目标检测，然后由VLM评估图像的理解质量，最后结合结果进行图像分析。

**Result:** 实验在有标注和无标注的遥感数据，以及降质图像场景中进行，证明了方法的有效性。研究表明，该方法在飞机检测精度和数量估计中平均MAE提高了48.46%。在遥感图像的全面理解上，CLIPScore提升了6.17%。

**Conclusion:** 结合传统视觉模型与VLM的混合模型，在提升遥感图像分析的准确性、对复杂场景的理解能力以及在少样本学习场景中的适应性方面具有很大潜力。这种方法为遥感图像分析的发展开辟了更高级、更高效的路径。

**Abstract:** Remote sensing has become a vital tool across sectors such as urban planning,
environmental monitoring, and disaster response. While the volume of data
generated has increased significantly, traditional vision models are often
constrained by the requirement for extensive domain-specific labelled data and
their limited ability to understand the context within complex environments.
Vision Language Models offer a complementary approach by integrating visual and
textual data; however, their application to remote sensing remains
underexplored, particularly given their generalist nature. This work
investigates the combination of vision models and VLMs to enhance image
analysis in remote sensing, with a focus on aircraft detection and scene
understanding. The integration of YOLO with VLMs such as LLaVA, ChatGPT, and
Gemini aims to achieve more accurate and contextually aware image
interpretation. Performance is evaluated on both labelled and unlabelled remote
sensing data, as well as degraded image scenarios which are crucial for remote
sensing. The findings show an average MAE improvement of 48.46% across models
in the accuracy of aircraft detection and counting, especially in challenging
conditions, in both raw and degraded scenarios. A 6.17% improvement in
CLIPScore for comprehensive understanding of remote sensing images is obtained.
The proposed approach combining traditional vision models and VLMs paves the
way for more advanced and efficient remote sensing image analysis, especially
in few-shot learning scenarios.

</details>
