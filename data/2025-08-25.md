<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 1]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration](https://arxiv.org/abs/2508.15790)
*Nan Wang,Yongqi Fan,yansha zhu,ZongYu Wang,Xuezhi Cao,Xinyan He,Haiyun Jiang,Tong Ruan,Jingping Liu*

Main category: cs.CL

> 提出了一种名为KG-o1的方法，结合知识图谱来提升大型语言模型在多跳推理任务中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在知识密集型推理任务（如经典的多跳问题解答）中面临挑战，因为生成的思维链通常偏离现实或先验的推理路径。这项研究旨在通过融合知识图谱，以增强大型语言模型在多跳推理任务上的表现。

**Method:** 通过四阶段方法集成知识图谱来增强大型语言模型的多跳推理能力。首先，筛选初始实体并生成复杂子图。接着，为子图构建逻辑路径并使用知识图谱构建一个复杂且扩展的脑暴数据集，该数据集训练大型语言模型模仿长期推理。最后，使用拒绝采样生成自我改进语料库，进一步优化直接偏好优化(DPO)，从而提升大型语言模型的推理能力。

**Result:** 实验结果表明，KG-o1模型在所有任务上的表现优于现有的大型推理模型。

**Conclusion:** KG-o1方法有效提升了大型语言模型在多跳推理任务中的性能，证明了知识图谱集成的潜力和价值。

**Abstract:** Large Language Models (LLMs) face challenges in knowledge-intensive reasoning
tasks like classic multi-hop question and answering, which involves reasoning
across multiple facts. This difficulty arises because the chain of thoughts
(CoTs) generated by LLMs in such tasks often deviate from real or a priori
reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the
logical connections between facts through entities and relationships. This
reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as
o1, have demonstrated that long-step reasoning significantly enhances the
performance of LLMs. Building on these insights, we propose KG-o1, a four-stage
approach that integrates KGs to enhance the multi-hop reasoning abilities of
LLMs. We first filter out initial entities and generate complex subgraphs.
Secondly, we construct logical paths for subgraphs and then use knowledge
graphs to build a dataset with a complex and extended brainstorming process,
which trains LLMs to imitate long-term reasoning. Finally, we employ rejection
sampling to generate a self-improving corpus for direct preference optimization
(DPO), further refining the LLMs reasoning abilities. We conducted experiments
on two simple and two complex datasets. The results show that KG-o1 models
exhibit superior performance across all tasks compared to existing LRMs.

</details>
