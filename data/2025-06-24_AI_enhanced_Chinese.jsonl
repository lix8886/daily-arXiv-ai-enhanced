{"id": "2506.17223", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2506.17223", "abs": "https://arxiv.org/abs/2506.17223", "authors": ["Shuvra Smaran Das", "Anirban Saha Anik", "Md Kishor Morol", "Mohammad Sakib Mahmood"], "title": "Outcome-Based Education: Evaluating Students' Perspectives Using Transformer", "comment": "6 pages, 7 figures", "summary": "Outcome-Based Education (OBE) emphasizes the development of specific\ncompetencies through student-centered learning. In this study, we reviewed the\nimportance of OBE and implemented transformer-based models, particularly\nDistilBERT, to analyze an NLP dataset that includes student feedback. Our\nobjective is to assess and improve educational outcomes. Our approach is better\nthan other machine learning models because it uses the transformer's deep\nunderstanding of language context to classify sentiment better, giving better\nresults across a wider range of matrices. Our work directly contributes to\nOBE's goal of achieving measurable outcomes by facilitating the identification\nof patterns in student learning experiences. We have also applied LIME (local\ninterpretable model-agnostic explanations) to make sure that model predictions\nare clear. This gives us understandable information about how key terms affect\nsentiment. Our findings indicate that the combination of transformer models and\nLIME explanations results in a strong and straightforward framework for\nanalyzing student feedback. This aligns more closely with the principles of OBE\nand ensures the improvement of educational practices through data-driven\ninsights.", "AI": {"tldr": "本研究采用DistilBERT模型并结合LIME解释技术分析学生反馈，目的是通过数据驱动的洞察提升教育实践。", "motivation": "本研究的动机是评估和改进教育成果，通过学生中心的学习来发展特定能力，并实现可衡量的结果。", "method": "在本研究中，我们使用了基于转换器的模型，特别是DistilBERT，来分析包含学生反馈的NLP数据集。我们还应用了LIME（局部可解释的模型不可知解释）来确保模型预测的清晰性。", "result": "研究结果表明，基于转换器模型的深层语言背景理解能更好地分类情感，因此优于其他机器学习模型。关键术语如何影响情感的可理解信息使框架更加强大和易于理解。", "conclusion": "研究结论是转化器模型与LIME解释的组合形成一个强大的框架，用于分析学生反馈，更符合OBE原则，通过数据驱动的洞察改善教育实践。"}}
{"id": "2506.17231", "categories": ["cs.CL", "cs.CR"], "pdf": "https://arxiv.org/pdf/2506.17231", "abs": "https://arxiv.org/abs/2506.17231", "authors": ["Xiang Li", "Chong Zhang", "Jia Wang", "Fangyu Wu", "Yushi Li", "Xiaobo Jin"], "title": "Efficient and Stealthy Jailbreak Attacks via Adversarial Prompt Distillation from LLMs to SLMs", "comment": "15 pages, 5 figures", "summary": "Attacks on large language models (LLMs) in jailbreaking scenarios raise many\nsecurity and ethical issues. Current jailbreak attack methods face problems\nsuch as low efficiency, high computational cost, and poor cross-model\nadaptability and versatility, which make it difficult to cope with the rapid\ndevelopment of LLM and new defense strategies. Our work proposes an Adversarial\nPrompt Distillation, which combines masked language modeling, reinforcement\nlearning, and dynamic temperature control through a prompt generation and\ndistillation method. It enables small language models (SLMs) to jailbreak\nattacks on mainstream LLMs. The experimental results verify the superiority of\nthe proposed method in terms of attack success rate and harm, and reflect the\nresource efficiency and cross-model adaptability. This research explores the\nfeasibility of distilling the jailbreak ability of LLM to SLM, reveals the\nmodel's vulnerability, and provides a new idea for LLM security research.", "AI": {"tldr": "This paper introduces an innovative Adversarial Prompt Distillation technique that uses SLMs to execute effective jailbreak attacks on LLMs, highlighting LLM vulnerabilities and offering a new focus for security research.", "motivation": "The motivation behind this research is to address the existing problems with current jailbreak attack methods on large language models, such as low efficiency, high computational cost, and poor cross-model adaptability and versatility.", "method": "Our work proposes an Adversarial Prompt Distillation that combines masked language modeling, reinforcement learning, and dynamic temperature control through a prompt generation and distillation method.", "result": "Experiments prove the superior success rate and harm of the proposed method in executing jailbreak attacks, as well as the method's resource efficiency and cross-model adaptability.", "conclusion": "This study explores the feasibility of transferring the jailbreak capability from a large language model to a small one, exposes model vulnerabilities, and opens up a new avenue for large language model security research."}}
{"id": "2506.17286", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17286", "abs": "https://arxiv.org/abs/2506.17286", "authors": ["Luoyang Sun", "Jiwen Jiang", "Cheng Deng", "Xinjian Wu", "Haifeng Zhang", "Lei Chen", "Lionel Ni", "Jun Wang"], "title": "GTA: Grouped-head latenT Attention", "comment": null, "summary": "Attention mechanisms underpin the success of large language models (LLMs),\nyet their substantial computational and memory overhead poses challenges for\noptimizing efficiency and performance. A critical bottleneck arises as KV cache\nand attention computations scale rapidly with text length, challenging\ndeployment on hardware with limited computational and memory resources. We\nobserve that attention mechanisms exhibit substantial redundancy, since the KV\ncache can be significantly compressed and attention maps across heads display\nhigh similarity, revealing that much of the computation and storage is\nunnecessary. Leveraging these insights, we propose \\textbf{G}rouped-Head\nLaten\\textbf{T} \\textbf{A}ttention (GTA), a novel attention mechanism that\nreduces memory usage and computational complexity while maintaining\nperformance. GTA comprises two components: (1) a shared attention map mechanism\nthat reuses attention scores across multiple heads, decreasing the key cache\nsize; and (2) a nonlinear value decoder with learned projections that\ncompresses the value cache into a latent space, further cutting memory needs.\nGTA cuts attention computation FLOPs by up to \\emph{62.5\\%} versus\nGrouped-Query Attention and shrink the KV cache by up to \\emph{70\\%}, all while\navoiding the extra overhead of Multi-Head Latent Attention to improve LLM\ndeployment efficiency. Consequently, GTA models achieve a \\emph{2x} increase in\nend-to-end inference speed, with prefill benefiting from reduced computational\ncost and decoding benefiting from the smaller cache footprint.", "AI": {"tldr": "The paper presents GTA, a novel attention mechanism designed to optimize memory and computational efficiency in large language models, achieving significant performance improvements without sacrificing accuracy.", "motivation": "The motivation is to address the limitations posed by KV cache and attention computations in large language models that increase rapidly with text length, making it difficult to deploy on hardware with limited resources.", "method": "GTA (Grouped-Head Latent Attention) method is introduced, which consists of a shared attention map mechanism and a nonlinear value decoder to reduce memory usage and computational complexity.", "result": "GTA reduces the memory usage for key cache, decreases attention computation FLOPs by up to 62.5%, shrinks KV cache by up to 70%, and boosts the end-to-end inference speed by 2x.", "conclusion": "GTA successfully balances the need for a reduction in memory and computation overhead while ensuring the performance of large language models is maintained or improved, making it a promising method for enhancing LLM deployment efficiency."}}
{"id": "2506.17294", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17294", "abs": "https://arxiv.org/abs/2506.17294", "authors": ["Qirui Zheng", "Xingbo Wang", "Keyuan Cheng", "Yunlong Lu", "Wenxin Li"], "title": "AI-Generated Game Commentary: A Survey and a Datasheet Repository", "comment": null, "summary": "AI-Generated Game Commentary (AIGGC) has gained increasing attention due to\nits market potential and inherent technical challenges. As a comprehensive\nmultimodal Natural Language Processing (NLP) task, AIGGC imposes substantial\ndemands on language models, including factual accuracy, logical reasoning,\nexpressive text generation, generation speed, and context management. In this\npaper, we introduce a general framework for AIGGC and present a comprehensive\nsurvey of 45 existing game commentary dataset and methods according to key\nchallenges they aim to address in this domain. We further classify and compare\nvarious evaluation metrics commonly used in this domain. To support future\nresearch and benchmarking, we also provide a structured datasheet summarizing\nthe essential attributes of these datasets in appendix, which is meanwhile\npublicly available in an open repository.", "AI": {"tldr": "本文提出了AIGGC的一般框架，全面调查45个数据集与方法，分类比较评估指标，并提供了结构化数据表供未来研究使用。", "motivation": "鉴于AIGGC的市场潜力和技术挑战，本文的动机在于综述该技术领域，为研究人员提供可解决这一问题的方法和评估标准。", "method": "本文介绍了用于AI生成游戏评论(AIGGC)的一般框架，并对现有的45个游戏评论数据集和方法进行了全面调查，这些数据集和方法旨在解决此领域的关键挑战。同时分类和比较了该领域常用的评估指标，并提供了一个附录中的结构化数据表来总结这些数据集的基本属性，数据表同时在开放的仓库中供公开获取。", "result": "未直接列出具体的实验结果，但提供了现有技术的综合回顾和评估标准的分类比较。", "conclusion": "该研究通过框架的提出、对现有技术的审查和评估标准的分类，为AIGGC领域提供了宝贵的参考和未来研究方向。"}}
{"id": "2506.17237", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17237", "abs": "https://arxiv.org/abs/2506.17237", "authors": ["Dip Roy"], "title": "Mechanistic Interpretability of Diffusion Models: Circuit-Level Analysis and Causal Validation", "comment": null, "summary": "We present a quantitative circuit-level analysis of diffusion models,\nestablishing computational pathways and mechanistic principles underlying image\ngeneration processes. Through systematic intervention experiments across 2,000\nsynthetic and 2,000 CelebA facial images, we discover fundamental algorithmic\ndifferences in how diffusion architectures process synthetic versus\nnaturalistic data distributions. Our investigation reveals that real-world face\nprocessing requires circuits with measurably higher computational complexity\n(complexity ratio = 1.084 plus/minus 0.008, p < 0.001), exhibiting distinct\nattention specialization patterns with entropy divergence ranging from 0.015 to\n0.166 across denoising timesteps. We identify eight functionally distinct\nattention mechanisms showing specialized computational roles: edge detection\n(entropy = 3.18 plus/minus 0.12), texture analysis (entropy = 4.16 plus/minus\n0.08), and semantic understanding (entropy = 2.67 plus/minus 0.15).\nIntervention analysis demonstrates critical computational bottlenecks where\ntargeted ablations produce 25.6% to 128.3% performance degradation, providing\ncausal evidence for identified circuit functions. These findings establish\nquantitative foundations for algorithmic understanding and control of\ngenerative model behavior through mechanistic intervention strategies.", "AI": {"tldr": "研究通过电路级分析揭示了扩散模型在生成图像过程中的算法差异，尤其是在处理合成数据和自然面部图像上的计算复杂度差异。", "motivation": "探索图像生成过程中，扩散模型处理合成数据和自然图像时的内在机制和计算复杂度差异。", "method": "进行了系统的干预实验，包括对2000个合成图像和2000个CelebA人脸图像的处理，分析扩散模型在去噪过程中的注意力机制。", "result": "揭示了处理真实世界面部图像需要更高的计算复杂度，并发现了八种不同的注意力机制，通过干预分析展示了关键计算瓶颈。", "conclusion": "研究为理解和控制生成模型的行为提供了定量基础，可以通过机制干预策略进行模型优化。"}}
{"id": "2506.17296", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17296", "abs": "https://arxiv.org/abs/2506.17296", "authors": ["Darius Foodeei", "Simin Fan", "Martin Jaggi"], "title": "Semantic uncertainty in advanced decoding methods for LLM generation", "comment": null, "summary": "This study investigates semantic uncertainty in large language model (LLM)\noutputs across different decoding methods, focusing on emerging techniques like\nspeculative sampling and chain-of-thought (CoT) decoding. Through experiments\non question answering, summarization, and code generation tasks, we analyze how\ndifferent decoding strategies affect both the diversity and reliability of\nmodel outputs. Our findings reveal that while CoT decoding demonstrates higher\nsemantic diversity, it maintains lower predictive entropy, suggesting that\nstructured exploration can lead to more confident and accurate outputs. This is\nevidenced by a 48.8% improvement in code generation Pass@2 rates, despite lower\nalignment with reference solutions. For summarization tasks, speculative\nsampling proved particularly effective, achieving superior ROUGE scores while\nmaintaining moderate semantic diversity. Our results challenge conventional\nassumptions about trade-offs between diversity and accuracy in language model\noutputs, demonstrating that properly structured decoding methods can increase\nsemantic exploration while maintaining or improving output quality. These\nfindings have significant implications for deploying language models in\npractical applications where both reliability and diverse solution generation\nare crucial.", "AI": {"tldr": "研究表明合适的解码方法可以增加语义探索的能力，同时保持或提高输出质量，这对于实际部署语言模型非常重要。", "motivation": "这项研究探讨了大型语言模型（LLM）输出中的语义不确定性，专注于新兴技术如推测性采样和链式思维（CoT）解码方法。", "method": "通过在问答、摘要生成和代码生成任务上的实验，我们分析了不同的解码策略如何影响模型输出的多样性和可靠性。", "result": "研究结果显示，尽管CoT解码与参考解决方案的对齐度较低，但其在代码生成pass@2率上提高了48.8%，表明结构化探索可以带来更有信心且准确的输出。对于摘要生成任务，推测性采样特别有效，实现了优越的ROUGE分数，同时保持适度的语义多样性。", "conclusion": "这项研究的结果挑战了关于语言模型输出多样性与准确性之间权衡的传统假设，表明通过适当的结构化解码方法，可以在维持或提升输出质量的同时增加语义探索。"}}
{"id": "2506.17290", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2506.17290", "abs": "https://arxiv.org/abs/2506.17290", "authors": ["Yuqi Li", "Junhao Dong", "Zeyu Dong", "Chuanguang Yang", "Zhulin An", "Yongjun Xu"], "title": "SRKD: Towards Efficient 3D Point Cloud Segmentation via Structure- and Relation-aware Knowledge Distillation", "comment": "13 pages", "summary": "3D point cloud segmentation faces practical challenges due to the\ncomputational complexity and deployment limitations of large-scale\ntransformer-based models. To address this, we propose a novel Structure- and\nRelation-aware Knowledge Distillation framework, named SRKD, that transfers\nrich geometric and semantic knowledge from a large frozen teacher model (>100M)\nto a lightweight student model (<15M). Specifically, we propose an affinity\nmatrix-based relation alignment module, which distills structural dependencies\nfrom the teacher to the student through point-wise similarity matching,\nenhancing the student's capability to learn contextual interactions. Meanwhile,\nwe introduce a cross-sample mini-batch construction strategy that enables the\nstudent to perceive stable and generalized geometric structure. This aligns\nacross diverse point cloud instances of the teacher, rather than within a\nsingle sample. Additionally, KL divergence is applied to align semantic\ndistributions, and ground-truth supervision further reinforces accurate\nsegmentation. Our method achieves state of the art performance with\nsignificantly reduced model complexity, demonstrating its effectiveness and\nefficiency in real-world deployment scenarios. Our Code is available at\nhttps://github.com/itsnotacie/SRKD.", "AI": {"tldr": "该论文提出了一个名为SRKD的结构和关系感知知识蒸馏框架，通过将大型教师模型中的丰富几何和语义知识转移到小型学生模型中，以克服大规模3D点云分割面临的计算复杂性和部署限制问题。", "motivation": "旨在解决3D点云分割的实际挑战，特别是大规模transformer模型在计算复杂性和部署上的限制。", "method": "提出了基于亲和力矩阵的关系对齐模块，通过点对点相似性匹配传递结构依赖性，以及跨样本小批量构建策略和KL散度对齐语义分布。", "result": "该方法在降低模型复杂性的同时达到了最先进的性能，证明了其实用性和效率。", "conclusion": "SRKD框架展示了在实际部署场景中的有效性和效率。"}}
{"id": "2506.17298", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17298", "abs": "https://arxiv.org/abs/2506.17298", "authors": ["Inception Labs", "Samar Khanna", "Siddhant Kharbanda", "Shufan Li", "Harshit Varma", "Eric Wang", "Sawyer Birnbaum", "Ziyang Luo", "Yanis Miraoui", "Akash Palrecha", "Stefano Ermon", "Aditya Grover", "Volodymyr Kuleshov"], "title": "Mercury: Ultra-Fast Language Models Based on Diffusion", "comment": "15 pages; equal core, cross-function, senior authors listed\n  alphabetically", "summary": "We present Mercury, a new generation of commercial-scale large language\nmodels (LLMs) based on diffusion. These models are parameterized via the\nTransformer architecture and trained to predict multiple tokens in parallel. In\nthis report, we detail Mercury Coder, our first set of diffusion LLMs designed\nfor coding applications. Currently, Mercury Coder comes in two sizes: Mini and\nSmall. These models set a new state-of-the-art on the speed-quality frontier.\nBased on independent evaluations conducted by Artificial Analysis, Mercury\nCoder Mini and Mercury Coder Small achieve state-of-the-art throughputs of 1109\ntokens/sec and 737 tokens/sec, respectively, on NVIDIA H100 GPUs and outperform\nspeed-optimized frontier models by up to 10x on average while maintaining\ncomparable quality. We discuss additional results on a variety of code\nbenchmarks spanning multiple languages and use-cases as well as real-world\nvalidation by developers on Copilot Arena, where the model currently ranks\nsecond on quality and is the fastest model overall. We also release a public\nAPI at https://platform.inceptionlabs.ai/ and free playground at\nhttps://chat.inceptionlabs.ai", "AI": {"tldr": "Mercury Coder, a diffusion-based LLM designed for coding applications, introduces two sizes: Mini and Small, achieving state-of-the-art throughputs and ranking highly in performance and code quality benchmarks.", "motivation": "The motivation is to create a new generation of large language models that can handle coding applications efficiently, aiming for a balance between speed and code quality.", "method": "Mercury Coder utilizes the Transformer architecture and diffuses to predict multiple coding tokens in parallel, available in Mini and Small sizes.", "result": "The models achieve high throughputs on independent evaluation benchmarks and rank as the fastest while maintaining quality on real-world performance criteria.", "conclusion": "The introduction of Mercury Coder as a coding application LLM presents a significant advancement in both speed and quality, making it a valuable tool for developers."}}
{"id": "2506.17302", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2506.17302", "abs": "https://arxiv.org/abs/2506.17302", "authors": ["Yijun Lin", "Theresa Chen", "Colby Brungard", "Grunwald Sabine", "Sue Ives", "Matt Macander", "Timm Nawrocki", "Yao-Yi Chiang", "Nic Jelinski"], "title": "Fine-Scale Soil Mapping in Alaska with Multimodal Machine Learning", "comment": "12 pages, Submitted to SIGSPATIAL 2025", "summary": "Fine-scale soil mapping in Alaska, traditionally relying on fieldwork and\nlocalized simulations, remains a critical yet underdeveloped task, despite the\nregion's ecological importance and extensive permafrost coverage. As permafrost\nthaw accelerates due to climate change, it threatens infrastructure stability\nand key ecosystem services, such as soil carbon storage. High-resolution soil\nmaps are essential for characterizing permafrost distribution, identifying\nvulnerable areas, and informing adaptation strategies. We present MISO, a\nvision-based machine learning (ML) model to produce statewide fine-scale soil\nmaps for near-surface permafrost and soil taxonomy. The model integrates a\ngeospatial foundation model for visual feature extraction, implicit neural\nrepresentations for continuous spatial prediction, and contrastive learning for\nmultimodal alignment and geo-location awareness. We compare MISO with Random\nForest (RF), a traditional ML model that has been widely used in soil mapping\napplications. Spatial cross-validation and regional analysis across Permafrost\nZones and Major Land Resource Areas (MLRAs) show that MISO generalizes better\nto remote, unseen locations and achieves higher recall than RF, which is\ncritical for monitoring permafrost thaw and related environmental processes.\nThese findings demonstrate the potential of advanced ML approaches for\nfine-scale soil mapping and provide practical guidance for future soil sampling\nand infrastructure planning in permafrost-affected landscapes. The project will\nbe released at https://github.com/knowledge-computing/Peatland-permafrost.", "AI": {"tldr": "本文提出了一种名为MISO的先进机器学习模型，用于生成阿拉斯加地区的细粒度土壤地图，通过多模态学习技术提高遥感预测精度，相比于传统方法在永冻土区域监测方面具有更好的效果。", "motivation": "尽管阿拉斯加地区具有重要的生态意义和广泛的永冻土覆盖，但细粒度土壤制图工作尚处于起步阶段，主要依赖实地工作和局部模拟。随着气候变暖加速永冻土融化，威胁基础设施稳定性和土壤碳储存等关键生态系统服务，高分辨率土壤地图变得至关重要。", "method": "我们提出了MISO，这是一种基于视觉的机器学习模型，用于生成全州近地表永冻土和土壤分类的高分辨率土壤地图。该模型结合了用于视觉特征提取的地理空间基础模型、用于连续空间预测的隐式神经表示以及用于多模态对齐和地理定位感知的对比学习。我们还与传统的随机森林（RF）模型进行了比较。", "result": "在永冻土区和主要土地资源区（MLRAs）进行空间交叉验证和区域分析表明，MISO在没有见过的偏远地区具有更好的泛化能力，并且比RF模型具有更高的召回率，这对于监测永冻土融化及相关环境过程至关重要。", "conclusion": "这些发现展示了先进机器学习方法在细粒度土壤制图中的潜力，并为未来在受永冻土影响的景观中的土壤取样和基础设施规划提供了实用指导。"}}
{"id": "2506.17314", "categories": ["cs.CL", "cs.HC"], "pdf": "https://arxiv.org/pdf/2506.17314", "abs": "https://arxiv.org/abs/2506.17314", "authors": ["Adnan Qidwai", "Srija Mukhopadhyay", "Prerana Khatiwada", "Dan Roth", "Vivek Gupta"], "title": "PRAISE: Enhancing Product Descriptions with LLM-Driven Structured Insights", "comment": "9 Pages, 9 Figures. Accepted at ACL 2025 System Demonstration Track", "summary": "Accurate and complete product descriptions are crucial for e-commerce, yet\nseller-provided information often falls short. Customer reviews offer valuable\ndetails but are laborious to sift through manually. We present PRAISE: Product\nReview Attribute Insight Structuring Engine, a novel system that uses Large\nLanguage Models (LLMs) to automatically extract, compare, and structure\ninsights from customer reviews and seller descriptions. PRAISE provides users\nwith an intuitive interface to identify missing, contradictory, or partially\nmatching details between these two sources, presenting the discrepancies in a\nclear, structured format alongside supporting evidence from reviews. This\nallows sellers to easily enhance their product listings for clarity and\npersuasiveness, and buyers to better assess product reliability. Our\ndemonstration showcases PRAISE's workflow, its effectiveness in generating\nactionable structured insights from unstructured reviews, and its potential to\nsignificantly improve the quality and trustworthiness of e-commerce product\ncatalogs.", "AI": {"tldr": "PRAISE系统使用LLMs自动提取和对比客户评论与卖家描述，帮助改善电子商务产品描述的清晰度和说服力，进而提高产品目录的质量和可信度。", "motivation": "准确且详尽的产品描述对于电子商务至关重要，但卖家提供的信息往往不尽如人意。客户评论可提供宝贵细节，但人工筛选费时费力。因此，团队开发了PRAISE系统，以解决这个难题。", "method": "PRAISE系统采用大型语言模型(LLMs)从客户评论和卖家描述中自动提取、比较并结构化见解。通过提供一个直观的界面，PRAISE帮助用户识别两种来源之间的缺失、矛盾或部分匹配的细节，以清晰的结构化格式呈现差异，并附带评论的证据支持。", "result": "PRAISE展示了从非结构化评论中生成可操作的结构化见解的能力。该系统的演示证明了其提高电子商务产品质量和可信度的潜力。", "conclusion": "PRAISE系统不仅为卖家提供了一个增强其产品清单的方法，让买家更好地评估产品可靠性，还展示了显著提高电子商务产品质量和可信度的潜力。"}}
{"id": "2506.17325", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17325", "abs": "https://arxiv.org/abs/2506.17325", "authors": ["Sina Najafi", "M. Hadi Sepanj", "Fahimeh Jafari"], "title": "RadarSeq: A Temporal Vision Framework for User Churn Prediction via Radar Chart Sequences", "comment": null, "summary": "Predicting user churn in non-subscription gig platforms, where disengagement\nis implicit, poses unique challenges due to the absence of explicit labels and\nthe dynamic nature of user behavior. Existing methods often rely on aggregated\nsnapshots or static visual representations, which obscure temporal cues\ncritical for early detection. In this work, we propose a temporally-aware\ncomputer vision framework that models user behavioral patterns as a sequence of\nradar chart images, each encoding day-level behavioral features. By integrating\na pretrained CNN encoder with a bidirectional LSTM, our architecture captures\nboth spatial and temporal patterns underlying churn behavior. Extensive\nexperiments on a large real-world dataset demonstrate that our method\noutperforms classical models and ViT-based radar chart baselines, yielding\ngains of 17.7 in F1 score, 29.4 in precision, and 16.1 in AUC, along with\nimproved interpretability. The framework's modular design, explainability\ntools, and efficient deployment characteristics make it suitable for\nlarge-scale churn modeling in dynamic gig-economy platforms.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2506.17352", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17352", "abs": "https://arxiv.org/abs/2506.17352", "authors": ["Tatsuhiro Aoshima", "Mitsuaki Akiyama"], "title": "Towards Safety Evaluations of Theory of Mind in Large Language Models", "comment": null, "summary": "As the capabilities of large language models (LLMs) continue to advance, the\nimportance of rigorous safety evaluation is becoming increasingly evident.\nRecent concerns within the realm of safety assessment have highlighted\ninstances in which LLMs exhibit behaviors that appear to disable oversight\nmechanisms and respond in a deceptive manner. For example, there have been\nreports suggesting that, when confronted with information unfavorable to their\nown persistence during task execution, LLMs may act covertly and even provide\nfalse answers to questions intended to verify their behavior.To evaluate the\npotential risk of such deceptive actions toward developers or users, it is\nessential to investigate whether these behaviors stem from covert, intentional\nprocesses within the model. In this study, we propose that it is necessary to\nmeasure the theory of mind capabilities of LLMs. We begin by reviewing existing\nresearch on theory of mind and identifying the perspectives and tasks relevant\nto its application in safety evaluation. Given that theory of mind has been\npredominantly studied within the context of developmental psychology, we\nanalyze developmental trends across a series of open-weight LLMs. Our results\nindicate that while LLMs have improved in reading comprehension, their theory\nof mind capabilities have not shown comparable development. Finally, we present\nthe current state of safety evaluation with respect to LLMs' theory of mind,\nand discuss remaining challenges for future work.", "AI": {"tldr": "本研究通过测量大型语言模型的心智理论能力评估其安全性，发现尽管语言模型在阅读理解上有所进步，但其心智理论的发展并未跟上。", "motivation": "鉴于大型语言模型在执行任务时可能会表现出破坏监督机制和欺骗行为的现象，本研究旨在评估这些欺骗行为是否源自模型内部的秘密和有意的行为过程。", "method": "通过回顾现有的关于心智理论的研究以及识别该理论在安全性评估中的相关视角和任务，本研究旨在测量大型语言模型（LLMs）的心智理论能力。研究人员分析了几种开放权重LLMs在发展过程中心智理论能力的变化趋势。", "result": "研究结果显示，虽然LLMs在阅读理解方面有所提高，但其心智理论能力并没有表现出相同的发展水平。", "conclusion": "当前关于LLM安全性的评估还处在研究阶段，本研究指出未来在评估LLMs心智理论能力方面仍然存在诸多挑战。"}}
{"id": "2506.17332", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.17332", "abs": "https://arxiv.org/abs/2506.17332", "authors": ["Haitian Wang", "Yiren Wang", "Xinyu Wang", "Yumeng Miao", "Yuliang Zhang", "Yu Zhang", "Atif Mansoor"], "title": "P2MFDS: A Privacy-Preserving Multimodal Fall Detection System for Elderly People in Bathroom Environments", "comment": "Accepted to appear in the 2025 IEEE International Workshop on AIoT\n  and Smart Systems (AIoTSys'25). Nominated for Best Paper Award and Best IoT\n  System Implementation Award. Code and pretrained models available at:\n  https://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom", "summary": "By 2050, people aged 65 and over are projected to make up 16 percent of the\nglobal population. As aging is closely associated with increased fall risk,\nparticularly in wet and confined environments such as bathrooms where over 80\npercent of falls occur. Although recent research has increasingly focused on\nnon-intrusive, privacy-preserving approaches that do not rely on wearable\ndevices or video-based monitoring, these efforts have not fully overcome the\nlimitations of existing unimodal systems (e.g., WiFi-, infrared-, or\nmmWave-based), which are prone to reduced accuracy in complex environments.\nThese limitations stem from fundamental constraints in unimodal sensing,\nincluding system bias and environmental interference, such as multipath fading\nin WiFi-based systems and drastic temperature changes in infrared-based\nmethods. To address these challenges, we propose a Privacy-Preserving\nMultimodal Fall Detection System for Elderly People in Bathroom Environments.\nFirst, we develop a sensor evaluation framework to select and fuse\nmillimeter-wave radar with 3D vibration sensing, and use it to construct and\npreprocess a large-scale, privacy-preserving multimodal dataset in real\nbathroom settings, which will be released upon publication. Second, we\nintroduce P2MFDS, a dual-stream network combining a CNN-BiLSTM-Attention branch\nfor radar motion dynamics with a multi-scale CNN-SEBlock-Self-Attention branch\nfor vibration impact detection. By uniting macro- and micro-scale features,\nP2MFDS delivers significant gains in accuracy and recall over state-of-the-art\napproaches. Code and pretrained models will be made available at:\nhttps://github.com/HaitianWang/P2MFDS-A-Privacy-Preserving-Multimodal-Fall-Detection-Network-for-Elderly-Individuals-in-Bathroom.", "AI": {"tldr": "研究介绍了一个隐私保护的多模态跌倒检测系统P2MFDS，用于浴室环境中老年人的跌倒检测，通过结合毫米波雷达和3D振动感知技术，能够显著提高跌倒检测的准确率和召回率。", "motivation": "鉴于老年人跌倒的风险增加，特别是在浴室等湿润和封闭的空间。尽管近年来研究重点倾向于非侵入式、保护隐私的方法，但这些方法依赖单一模态的系统受到其局限性的限制，如WiFi、红外或毫米波感知系统在复杂环境下的准确性降低。因此，为了克服这些限制，研究提出了P2MFDS系统。", "method": "提出了一种名为P2MFDS的隐私保护多模态跌倒检测系统，用于老年人浴室环境。系统首先开发了一个传感器评估框架用于选择和融合毫米波雷达与3D震动传感，构建并预处理了一个大规模隐私保护的多模态数据集。其次，引入P2MFDS，它结合了用于雷达动态检测的CNN-BiLSTM-Attention分支和用于震动检测的多尺度CNN-SEBlock-Self-Attention分支，通过结合宏观和微观特征，该方法在准确率和召回率上超过现有方法。", "result": "通过结合毫米波雷达和3D振动传感技术，以及设计的双流网络结构，P2MFDS相比于现有方法在准确率和召回率上取得了显著的性能提升。", "conclusion": "研究展示了P2MFDS系统在隐私保护和跌倒检测的有效性，该系统通过利用多模态数据和先进的深度学习技术，能够在复杂的浴室环境中有效地提高跌倒检测的准确性。代码和预训练模型将在GitHub上公开。"}}
{"id": "2506.17367", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2506.17367", "abs": "https://arxiv.org/abs/2506.17367", "authors": ["Mateusz Cedro", "Timour Ichmoukhamedov", "Sofie Goethals", "Yifan He", "James Hinns", "David Martens"], "title": "Cash or Comfort? How LLMs Value Your Inconvenience", "comment": "12 pages, 4 figures, 3 tables", "summary": "Large Language Models (LLMs) are increasingly proposed as near-autonomous\nartificial intelligence (AI) agents capable of making everyday decisions on\nbehalf of humans. Although LLMs perform well on many technical tasks, their\nbehaviour in personal decision-making remains less understood. Previous studies\nhave assessed their rationality and moral alignment with human decisions.\nHowever, the behaviour of AI assistants in scenarios where financial rewards\nare at odds with user comfort has not yet been thoroughly explored. In this\npaper, we tackle this problem by quantifying the prices assigned by multiple\nLLMs to a series of user discomforts: additional walking, waiting, hunger and\npain. We uncover several key concerns that strongly question the prospect of\nusing current LLMs as decision-making assistants: (1) a large variance in\nresponses between LLMs, (2) within a single LLM, responses show fragility to\nminor variations in prompt phrasing (e.g., reformulating the question in the\nfirst person can considerably alter the decision), (3) LLMs can accept\nunreasonably low rewards for major inconveniences (e.g., 1 Euro to wait 10\nhours), and (4) LLMs can reject monetary gains where no discomfort is imposed\n(e.g., 1,000 Euro to wait 0 minutes). These findings emphasize the need for\nscrutiny of how LLMs value human inconvenience, particularly as we move toward\napplications where such cash-versus-comfort trade-offs are made on users'\nbehalf.", "AI": {"tldr": "研究量化并分析了大语言模型在解决与用户舒适度和财务奖励相关的问题时的响应，发现多个LLMs在评估人类不便时存在重大问题，强调了进一步审查的必要性。", "motivation": "研究动机在于探索AI助手在财务奖励与用户舒适度发生冲突的场景下的行为，这是以前的研究中未曾充分探讨的问题。", "method": "通过量化多个大语言模型（LLMs）为一系列用户不舒适情况（额外行走、等待、饥饿和疼痛）分配的价格，研究了LLMs的行为。", "result": "研究揭示了当前将LLMs作为决策助手使用的几个重大顾虑，主要包括：(1) LLMs之间的响应差异大；(2) 单个LLM对提示微小变化的敏感性；(3) LLMs以不合理低的奖励接受重大不便；(4) LLMs对无不便情况下的金钱收益做出拒绝。", "conclusion": "这些发现强调了需要对LLMs如何评估人类不便进行进一步审查，特别是在应用中需要代表用户做出金钱与舒适度权衡时。"}}
