<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 46]
- [cs.CV](#cs.CV) [Total: 49]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Democratizing LLM Efficiency: From Hyperscale Optimizations to Universal Deployability](https://arxiv.org/abs/2511.20662)
*Hen-Hsen Huang*

Main category: cs.CL

> 本文提出了一条新的研究路径，旨在改造大语言模型使其能够在有限的资源下更加高效和简洁，强调了考虑成本、可持续性和公平性的OAE标准。

<details>
  <summary>Details</summary>

**Motivation:** 许多大规模的方法在资源和团队精英有限的情况下效果不佳，导致只有少数几家大科技公司受益，而其他机构无法充分利用大语言模型。本研究旨在寻求在较少资源和专业知识的情况下实现强大而简洁的效率方法。

**Method:** 提出了一项新的研究议程：对预训练模型进行高效架构的改造而无需重新训练，发明轻量级的微调方法以保持对齐性，使复杂的推理过程更加经济，实现动态知识管理而不依赖繁重的RAG管道，并将考虑开销的效率（OAE）作为标准基准。

**Result:** 通过重新定义效率来促进大语言模型的民主化，确保优化减少不平等和碳排放，而非增加它们。

**Conclusion:** 研究强调了在资源有限的情况下实现大语言模型的高效和简洁对于民主化其应用的重要性。

**Abstract:** Large language models (LLMs) have become indispensable, but the most celebrated efficiency methods -- mixture-of-experts (MoE), speculative decoding, and complex retrieval-augmented generation (RAG) -- were built for hyperscale providers with vast infrastructure and elite teams. Outside that context, their benefits collapse into overhead, fragility, and wasted carbon. The result is that a handful of Big Tech companies benefit, while thousands of hospitals, schools, governments, and enterprises are left without viable options. We argue that the next frontier is not greater sophistication at scale, but robust simplicity: efficiency that thrives under modest resources and minimal expertise. We propose a new research agenda: retrofitting pretrained models with more efficient architectures without retraining, inventing lightweight fine-tuning that preserves alignment, making reasoning economical despite long chains of thought, enabling dynamic knowledge management without heavy RAG pipelines, and adopting Overhead-Aware Efficiency (OAE) as a standard benchmark. By redefining efficiency to include adoption cost, sustainability, and fairness, we can democratize LLM deployment -- ensuring that optimization reduces inequality and carbon waste rather than amplifying them.

</details>


### [2] [Harmonic Token Projection (HTP): A Vocabulary-Free, Training-Free, Deterministic, and Reversible Embedding Methodology](https://arxiv.org/abs/2511.20665)
*Tcharlies Schmitz*

Main category: cs.CL

> 本文提出了谐波令牌投影 (HTP)，这是一种可逆且确定性的方法，能够基于Unicode整数表示解析文本令牌，生成无训练需求的文本嵌入。该方法在多个语种中保持稳定性能，并具有极低的计算成本。

<details>
  <summary>Details</summary>

**Motivation:** 本文的动机是对现有嵌入式方法的不足之处提出了质疑，特别是关于利用训练数据来确定统计共现或优化的嵌入方法。本文提出了一种无需模型训练且计算成本较低的基于几何关系的生成文本嵌入的方法。

**Method:** 本文提出了谐波令牌投影（Harmonic Token Projection, HTP），这是一种无需训练、词汇表或随机参数的可逆确定性框架，用于生成文本嵌入。与依赖统计共现或优化的神经嵌入不同，HTP 将每个令牌解析为一个谐波轨迹，这些轨迹从其 Unicode 整数表示导出。HTP 建立了一种双射和可解释的映射关系，从而在离散符号和连续向量空间之间建立映射关系。谐波公式提供了一种相位相干投影，保留了结构和可逆性，能够通过纯粹的几何对齐来估计语义相似度。

**Result:** 实验评估显示，在语义文本相似度基准测试（STS-B）及其多语言扩展中，HTP 在英语中达到了 0.68 的 Spearman 相关度。HTP 在十种语言中保持了稳定性能，具有几乎可以忽略的计算成本和每对句子亚毫秒级的延迟。

**Conclusion:** 实验结果表明，较有意义的语义关系可以来自于确定性的几何度量。 HTP 为数据驱动的嵌入提供了透明、有效的方法选择。

**Abstract:** This paper introduces the Harmonic Token Projection (HTP), a reversible and deterministic framework for generating text embeddings without training, vocabularies, or stochastic parameters. Unlike neural embeddings that rely on statistical co-occurrence or optimization, HTP encodes each token analytically as a harmonic trajectory derived from its Unicode integer representation, establishing a bijective and interpretable mapping between discrete symbols and continuous vector space. The harmonic formulation provides phase-coherent projections that preserve both structure and reversibility, enabling semantic similarity estimation from purely geometric alignment. Experimental evaluation on the Semantic Textual Similarity Benchmark (STS-B) and its multilingual extension shows that HTP achieves a Spearman correlation of \r{ho} = 0.68 in English, maintaining stable performance across ten languages with negligible computational cost and sub-millisecond latency per sentence pair. This demonstrates that meaningful semantic relations can emerge from deterministic geometry, offering a transparent and efficient alternative to data-driven embeddings. Keywords: Harmonic Token Projection, reversible embedding, deterministic encoding, semantic similarity, multilingual representation.

</details>


### [3] [A centroid based framework for text classification in itsm environments](https://arxiv.org/abs/2511.20667)
*Hossein Mohanna,Ali Ait-Bachir*

Main category: cs.CL

> 提出了一种用于IT服务管理系统中分类支持票据的双嵌入质心分类框架，同时保持每个类别的语义和词汇质心表示，实现快速训练和更新，同时提供可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 在IT服务管理系统中，支持票据分类是一个基本需求，需要快速识别和分类，同时需要分类结果的可解释性。

**Method:** 使用双嵌入质心分类框架，分别保持每个类别的语义和词汇质心表示，并在推理时通过互逆排名融合结合起来。

**Result:** 在包含8,968个ITSM票据和123类别的数据集上进行了评估，这种方法实现了5.9倍更快的训练速度和高达152倍的增量更新速度，在不同批量大小下也有显著加速效果。

**Conclusion:** 提出的分类方法在保持性能的同时，展现出更快的训练和更新速度，特别适合于既要可解释性也要操作效率的生产ITSM环境。

**Abstract:** Text classification with hierarchical taxonomies is a fundamental requirement in IT Service Management (ITSM) systems, where support tickets must be categorized into tree-structured taxonomies. We present a dual-embedding centroid-based classification framework that maintains separate semantic and lexical centroid representations per category, combining them through reciprocal rank fusion at inference time. The framework achieves performance competitive with Support Vector Machines (hierarchical F1: 0.731 vs 0.727) while providing interpretability through centroid representations. Evaluated on 8,968 ITSM tickets across 123 categories, this method achieves 5.9 times faster training and up to 152 times faster incremental updates. With 8.6-8.8 times speedup across batch sizes (100-1000 samples) when excluding embedding computation. These results make the method suitable for production ITSM environments prioritizing interpretability and operational efficiency.

</details>


### [4] [PIRA: Preference-Oriented Instruction-Tuned Reward Models with Dual Aggregation](https://arxiv.org/abs/2511.20668)
*Yongfu Xue*

Main category: cs.CL

> PIRA通过三种策略解决大型语言模型奖励模型的数据效率低下和奖励过度优化问题，实验验证了其有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统区分性奖励模型直接连接问题和回答作为输入导致数据效率低下，并且奖励模型容易出现奖励过度优化的问题。

**Method:** 提出了PIRA训练范式，该范式通过三种策略来解决奖励模型面临的问题：(1) 将问题-答案对重新表述为基于偏好的指令，以更加清晰和明确地指定任务，(2) 聚合来自多种偏好任务的奖励以减少偏差并提高鲁棒性，(3) 在不同的丢弃率下平均value-head输出以稳定奖励。

**Result:** 广泛的实验表明PIRA的有效性。

**Conclusion:** PIRA范式能够有效提升奖励模型的数据效率，并可以减少奖励过度优化的问题。

**Abstract:** Reward models are crucial for aligning Large Language Models (LLMs) with human preferences but face two representative challenges. First, traditional discriminative reward models usually concatenate questions and responses directly as input, resulting in low data efficiency. Second, reward models are vulnerable to reward overoptimization. We propose PIRA, a training paradigm addressing these issues through three strategies: (1) Reformulating question-answer pairs into preference-based instructions for clearer and more explicit task specification, (2) aggregating rewards from diverse preference tasks to reduce bias and improve robustness, and (3) averaging value-head outputs under varying dropout rates to stabilize rewards. Extensive experiments have demonstrated the effectiveness of PIRA.

</details>


### [5] [Structured Definitions and Segmentations for Legal Reasoning in LLMs: A Study on Indian Legal Data](https://arxiv.org/abs/2511.20669)
*Mann Khatri,Mirza Yusuf,Rajiv Ratn Shah,Ponnurangam Kumaraguru*

Main category: cs.CL

> 研究在零样本设置下，通过重组文档和解释法律术语改善大型语言模型在法律任务上的表现的方法，获得了显著的提升。

<details>
  <summary>Details</summary>

**Motivation:** 探索大型语言模型在法律领域中存在的领域特异性预训练不足的问题，并研究通过重组文档和解释法律术语来提高其性能。

**Method:** (i) 通过基于修辞角色重组文档来评估结构化信息如何影响长文本处理和模型决策，(ii) 定义修辞角色使模型熟悉法律术语，(iii) 模仿法院关于修辞角色的逐步推理来增强模型推理能力。

**Result:** 在零样本设置下，通过组织数据或解释关键法律术语，模型性能显著提升，F1分数最低提高约1.5%，最高提升4.36%。

**Conclusion:** 重组数据或将关键法律术语解释清楚能够有效提高大型语言模型在法律任务上的性能。

**Abstract:** Large Language Models (LLMs), trained on extensive datasets from the web, exhibit remarkable general reasoning skills. Despite this, they often struggle in specialized areas like law, mainly because they lack domain-specific pretraining. The legal field presents unique challenges, as legal documents are generally long and intricate, making it hard for models to process the full text efficiently. Previous studies have examined in-context approaches to address the knowledge gap, boosting model performance in new domains without full domain alignment. In our paper, we analyze model behavior on legal tasks by conducting experiments in three areas: (i) reorganizing documents based on rhetorical roles to assess how structured information affects long context processing and model decisions, (ii) defining rhetorical roles to familiarize the model with legal terminology, and (iii) emulating the step-by-step reasoning of courts regarding rhetorical roles to enhance model reasoning. These experiments are conducted in a zero-shot setting across three Indian legal judgment prediction datasets. Our results reveal that organizing data or explaining key legal terms significantly boosts model performance, with a minimum increase of ~1.5% and a maximum improvement of 4.36% in F1 score compared to the baseline.

</details>


### [6] [MindSET: Advancing Mental Health Benchmarking through Large-Scale Social Media Data](https://arxiv.org/abs/2511.20672)
*Saad Mankarious,Ayah Zirikly,Daniel Wiechmann,Elma Kerz,Edward Kempa,Yu Qiao*

Main category: cs.CL

> 我们推出了一种新的基准数据集MindSET，它解决了现有数据集的诸多问题，并且在某些诊断检测中显著提高了性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于现有基准数据集的数据量受限、数据清理不足以及社交媒体内容多样性等问题，我们需要构建一个更为全面和高质量的数据集来更好地研究社交媒体在心理健康研究中的应用。

**Method:** 我们使用Reddit的数据，基于用户自我报告的诊断信息，构建了一个名为MindSET的新基准数据集，包含超过13M篇针对七种心理健康的标注帖子。在数据处理过程中，我们进行了严格的预处理步骤，包括语言筛选和删除不适合的工作内容及重复内容。此外，我们还利用LIWC进行了语言学分析，考察了数据集中八个群体的心理学术语频率。

**Result:** 通过对MindSET数据集进行二分类诊断检测实验，使用经过微调的语言模型和BoW特征，我们发现与之前基准数据集相比，使用MindSET训练的模型在自闭症检测中的F1值提高了18个百分点。

**Conclusion:** MindSET为研究者提供了一个坚实的基准数据集，旨在推动社交媒体与心理健康研究的结合，有助于早期风险检测和对新兴心理趋势的深入分析。

**Abstract:** Social media data has become a vital resource for studying mental health, offering real-time insights into thoughts, emotions, and behaviors that traditional methods often miss. Progress in this area has been facilitated by benchmark datasets for mental health analysis; however, most existing benchmarks have become outdated due to limited data availability, inadequate cleaning, and the inherently diverse nature of social media content (e.g., multilingual and harmful material). We present a new benchmark dataset, \textbf{MindSET}, curated from Reddit using self-reported diagnoses to address these limitations. The annotated dataset contains over \textbf{13M} annotated posts across seven mental health conditions, more than twice the size of previous benchmarks. To ensure data quality, we applied rigorous preprocessing steps, including language filtering, and removal of Not Safe for Work (NSFW) and duplicate content. We further performed a linguistic analysis using LIWC to examine psychological term frequencies across the eight groups represented in the dataset. To demonstrate the dataset utility, we conducted binary classification experiments for diagnosis detection using both fine-tuned language models and Bag-of-Words (BoW) features. Models trained on MindSET consistently outperformed those trained on previous benchmarks, achieving up to an \textbf{18-point} improvement in F1 for Autism detection. Overall, MindSET provides a robust foundation for researchers exploring the intersection of social media and mental health, supporting both early risk detection and deeper analysis of emerging psychological trends.

</details>


### [7] [Semantics Meet Signals: Dual Codebook Representationl Learning for Generative Recommendation](https://arxiv.org/abs/2511.20673)
*Zheng Hui,Xiaokai Wei,Reza Shirkavand,Chen Wang,Weizhi Zhang,Alejandro Peláez,Michelle Gong*

Main category: cs.CL

> 本文引入了 FlexCode，这是一种新型的按流行度自适应分配标记预算的推荐生成框架，优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的生成推荐方法使用统一的编码本，忽视了热门项目和长尾项目之间的不平衡，这限制了表示效率并阻碍了泛化。

**Method:** FlexCode 是一个基于流行度的框架，自适应地在协同过滤编码本和语义编码本之间分配固定标记预算。一个轻量级的 MoE 动态平衡 CF 特定的精度和语义泛化。

**Result:** 在公共和工业规模的数据集上的实验表明，FlexCode 一致优于强基线。

**Conclusion:** FlexCode 提供了一种新的基于标记的推荐生成机制，实现了更强的准确性以及对长尾项目的鲁棒性，为平衡记忆和泛化提出了新的视角。

**Abstract:** Generative recommendation has recently emerged as a powerful paradigm that unifies retrieval and generation, representing items as discrete semantic tokens and enabling flexible sequence modeling with autoregressive models. Despite its success, existing approaches rely on a single, uniform codebook to encode all items, overlooking the inherent imbalance between popular items rich in collaborative signals and long-tail items that depend on semantic understanding. We argue that this uniform treatment limits representational efficiency and hinders generalization. To address this, we introduce FlexCode, a popularity-aware framework that adaptively allocates a fixed token budget between a collaborative filtering (CF) codebook and a semantic codebook. A lightweight MoE dynamically balances CF-specific precision and semantic generalization, while an alignment and smoothness objective maintains coherence across the popularity spectrum. We perform experiments on both public and industrial-scale datasets, showing that FlexCode consistently outperform strong baselines. FlexCode provides a new mechanism for token representation in generative recommenders, achieving stronger accuracy and tail robustness, and offering a new perspective on balancing memorization and generalization in token-based recommendation models.

</details>


### [8] [Prompt Engineering Techniques for Context-dependent Text-to-SQL in Arabic](https://arxiv.org/abs/2511.20677)
*Saleh Almohaimeed,May Alsofyani,Saad Almohaimeed,Mansour Al Ghanim,Liqiang Wang*

Main category: cs.CL

> 本文介绍了Ar-SParC，第一个用于阿拉伯语的跨域、上下文相关文本到SQL数据集，并通过两种大型语言模型进行了40次实验，采用10种不同的提示工程技术。创新的GAT corrector方法显著提升了执行准确性和交互准确性。

<details>
  <summary>Details</summary>

**Motivation:** 目前大多数跨域、上下文相关文本到SQL的研究和数据集都是基于英文的，很少有关于阿拉伯语的研究。因此，文章提出了首个阿拉伯语的Ar-SParC数据集。

**Method:** 使用GPT-3.5-turbo和GPT-4.5-turbo两种大型语言模型进行实验，并应用了10种不同的提示工程方法，包括四种问题表示方式和六种上下文学习技术。

**Result:** 实验结果表明，GAT corrector方法提高了1.9%的执行准确性和1.9%的交互准确性，且在上下文学习设置下分别提升了1.72%的执行准确性和0.92%的交互准确性。

**Conclusion:** 该研究证明了GAT corrector方法在阿拉伯语文本到SQL任务中的有效性和优越性。

**Abstract:** In recent years, the task of cross-domain, context-dependent text-to-SQL has received significant attention. Enables users with no prior knowledge of SQL to have a conversation with databases using natural language. However, most of the available datasets and research have been conducted in English, along with some work in Chinese. To this date, no effort has been made to address this task in the Arabic language. In this paper, we introduce Ar-SParC, the first Arabic cross-domain, context-dependent text-to-SQL dataset. The dataset consists of 3,450 sequences of interrelated questions, each sequence containing an average of approximately three questions, which results in a total of 10225 questions along with their corresponding SQL queries. We conducted 40 experiments on the Ar-SParC dataset using two large language models, GPT-3.5-turbo and GPT-4.5-turbo, applying 10 different prompt engineering techniques, including four question representation methods and six in-context learning techniques. Furthermore, we developed a novel approach named GAT corrector, which enhanced the performance across all 40 experiments, yielding an average improvement of 1.9% in execution accuracy (EX) and 1.9% in interaction accuracy (IX) under zero-shot settings, and an average increase of 1.72% EX and 0.92% IX under in-context learning settings. Finally, we conducted an ablation study with two more experiments to explain why the GAT corrector outperformed the previous GAT verifier technique, particularly for the Arabic language.

</details>


### [9] [Cognitive bias in LLM reasoning compromises interpretation of clinical oncology notes](https://arxiv.org/abs/2511.20680)
*Matthew W. Kenaston,Umair Ayub,Mihir Parmar,Muhammad Umair Anjum,Syed Arsalan Ahmed Naqvi,Priya Kumar,Samarth Rawal,Aadel A. Chaudhuri,Yousef Zakharia,Elizabeth I. Heath,Tanios S. Bekaii-Saab,Cui Tao,Eliezer M. Van Allen,Ben Zhou,YooJung Choi,Chitta Baral,Irbaz Bin Riaz*

Main category: cs.CL

> 研究开发了一个分层错误分类法，用于分析GPT-4在处理实际肿瘤学笔记时的推理错误，揭示了使用大型语言模型进行肿瘤决策支持存在的安全隐患。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于揭示大型语言模型在肿瘤决策支持中通过错误推理得出正确结论的潜在安全风险，这种风险无法通过基于准确性的评估捕捉到。

**Method:** 研究采用了两队列回顾性研究方法，开发了一个错误分类法，并通过注释乳腺癌和胰腺癌笔记来构建一个三级分类法，映射计算失败到认知偏差框架。

**Result:** 研究显示，23%的解释中存在推理错误，错误主要关联于指南不符合和潜在有害的推荐，特别是在晚期疾病管理中，自动评估器能够检测错误存在，但无法可靠分类错误类型。

**Conclusion:** 研究发现，大型语言模型可能提供流畅但临床不安全的建议，错误推理使模型产生潜在危害的推荐。该分类法提供了一个可推广的框架，用于评估和提高模型推理的准确性，保障临床应用安全。

**Abstract:** Despite high performance on clinical benchmarks, large language models may reach correct conclusions through faulty reasoning, a failure mode with safety implications for oncology decision support that is not captured by accuracy-based evaluation. In this two-cohort retrospective study, we developed a hierarchical taxonomy of reasoning errors from GPT-4 chain-of-thought responses to real oncology notes and tested its clinical relevance. Using breast and pancreatic cancer notes from the CORAL dataset, we annotated 600 reasoning traces to define a three-tier taxonomy mapping computational failures to cognitive bias frameworks. We validated the taxonomy on 822 responses from prostate cancer consult notes spanning localized through metastatic disease, simulating extraction, analysis, and clinical recommendation tasks. Reasoning errors occurred in 23 percent of interpretations and dominated overall errors, with confirmation bias and anchoring bias most common. Reasoning failures were associated with guideline-discordant and potentially harmful recommendations, particularly in advanced disease management. Automated evaluators using state-of-the-art language models detected error presence but could not reliably classify subtypes. These findings show that large language models may provide fluent but clinically unsafe recommendations when reasoning is flawed. The taxonomy provides a generalizable framework for evaluating and improving reasoning fidelity before clinical deployment.

</details>


### [10] [Dynamic Template Selection for Output Token Generation Optimization: MLP-Based and Transformer Approaches](https://arxiv.org/abs/2511.20683)
*Bharadwaj Yadavalli*

Main category: cs.CL

> 本文通过动态模板选择方法，自适应响应简化了大型语言模型部署的提示策略，实现了成本节约的目标。

<details>
  <summary>Details</summary>

**Motivation:** 当代大型语言模型部署普遍采用单一的提示策略应对各种千变万化的查询类型，导致在处理简单或复杂任务时产生令牌浪费，特别在输入和输出令牌成本差异显著的情况下，这一问题更加突出。

**Method:** 本文提出了动态模板选择（DTS），通过自适应地将响应模板与查询复杂度相匹配，旨在实现成本节约而不降低响应质量。DTS对比了两种路由方法：一种是使用预计算嵌入的简单MLP，另一种是更为复杂的微调RoBERTa变换器。

**Result:** 实验结果表明，在1000个MMLU问题上，MLP路由器的路由准确率达到了90.5%，略高于RoBERTa的89.5%，且参数减少了1.25亿。同时，通过9000次生产API调用验证了模板选择的提供商无关性，路由准确性在各主要LLM提供商间保持一致，分别为OpenAI GPT-4、Google Gemini和Anthropic Claude。

**Conclusion:** 本研究贡献包括形式上的问题描述、四种算法及其复杂度分析以及在生产系统中的广泛实证验证。结果表明，DTS不仅可以实现成本节约，而且在不同语言模型提供商间具有跨平台的适用性和一致性。

**Abstract:** Contemporary large language model deployments typically employ uniform prompting strategies across diverse query types, applying verbose response patterns to both complex analytical tasks and straightforward factual questions. This one-size-fits-all methodology leads to substantial token inefficiency, a concern amplified by the significant cost differential between input and output tokens--the latter commanding 4-8x higher prices across major providers. We present Dynamic Template Selection (DTS), which adaptively matches response templates to query complexity, achieving significant cost reductions without compromising response quality.
  We compared two routing approaches: a simple MLP that uses pre-computed embeddings and a more complex fine-tuned RoBERTa transformer. Through comprehensive evaluation on 1,000 MMLU questions, we find that the MLP router achieves 90.5% routing accuracy on held-out test data, marginally exceeding RoBERTa's performance (89.5%) despite utilizing 125M fewer parameters. Notably, our empirical analysis reveals provider-agnostic behavior in template selection--routing decisions generalize effectively across 3 major LLM providers (OpenAI GPT-4, Google Gemini, and Anthropic Claude), as validated through 9,000 production API calls. While routing accuracy remains consistent at 90.5% across providers, observed token reductions vary from 32.6% to 33.9%, reflecting provider-specific generation characteristics.
  This work contributes several key elements: formal problem formulation with theoretical grounding in machine learning, four algorithms with corresponding complexity analyses, and extensive empirical validation across production systems.

</details>


### [11] [LLMs-Powered Accurate Extraction, Querying and Intelligent Management of Literature derived 2D Materials Data](https://arxiv.org/abs/2511.20691)
*Lijun Shang,Yadong Yu,Wenqiang Kang,Jian Zhou,Dongyue Gao,Pan Xiang,Zhe Liu,Mengyan Dai,Zhonglu Guo,Zhimei Sun*

Main category: cs.CL

> This paper aims to tackle the challenge of dispersed information on 2D materials by possibly consolidating it for better utilization in energy storage and conversion applications.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the issue of dispersed information on 2D materials which is vital for understanding their properties and preparation methods, and to potentially consolidate this information for easier access and application.

**Method:** The method section is missing from the given abstract.

**Result:** The abstract seems to be cut off but it introduces the vast applications of two-dimensional (2D) materials in energy sectors, highlighting their physicochemical and electronic properties. It mentions the importance of research papers in providing valuable information about these materials, including their properties and preparation methods. However, it also points out the issue of this information being dispersed.

**Conclusion:** The conclusion of the paper is missing from the given abstract.

**Abstract:** Two-dimensional (2D) materials have showed widespread applications in energy storage and conversion owning to their unique physicochemical, and electronic properties. Most of the valuable information for the materials, such as their properties and preparation methods, is included in the published research papers. However, due to the dispersion of synthe

</details>


### [12] [Memories Retrieved from Many Paths: A Multi-Prefix Framework for Robust Detection of Training Data Leakage in Large Language Models](https://arxiv.org/abs/2511.20799)
*Trung Cuong Dang,David Mohaisen*

Main category: cs.CL

> 本文提出了一个新的多前缀记忆框架，用于检测大语言模型中的数据记忆现象。该框架通过检索路径的多样性来量化解的鲁棒性，实验展示了其在区分记忆与非记忆数据上的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型在大规模语料库上训练时，容易原样记忆训练数据，从而引发隐私和版权风险。以往的工作提出了多种记忆定义，但这些定义通常不能全面捕捉记忆现象，特别是在对齐模型中。

**Method:** 引入了一个新的框架：多前缀记忆，此框架将记忆定义为如果可以通过外部对抗性搜索识别出足够多的独立前缀来激发目标序列，则认为该序列被记忆。此方法关注点从单一路径提取转为量化记忆的鲁棒性，即记忆检索路径的多样性。

**Result:** 实验结果表明，多前缀定义可以可靠地区分记忆和未记忆数据，成为一种稳健且实用的工具，用于审核LLM中的数据泄露。

**Conclusion:** 多前缀记忆框架通过关注记忆序列的检索路径多样性，有效区分记忆与非记忆内容，提供了一种稳健的方法来检测大模型中的数据泄露风险。

**Abstract:** Large language models, trained on massive corpora, are prone to verbatim memorization of training data, creating significant privacy and copyright risks. While previous works have proposed various definitions for memorization, many exhibit shortcomings in comprehensively capturing this phenomenon, especially in aligned models. To address this, we introduce a novel framework: multi-prefix memorization. Our core insight is that memorized sequences are deeply encoded and thus retrievable via a significantly larger number of distinct prefixes than non-memorized content. We formalize this by defining a sequence as memorized if an external adversarial search can identify a target count of distinct prefixes that elicit it. This framework shifts the focus from single-path extraction to quantifying the robustness of a memory, measured by the diversity of its retrieval paths. Through experiments on open-source and aligned chat models, we demonstrate that our multi-prefix definition reliably distinguishes memorized from non-memorized data, providing a robust and practical tool for auditing data leakage in LLMs.

</details>


### [13] [SAGE: An Agentic Explainer Framework for Interpreting SAE Features in Language Models](https://arxiv.org/abs/2511.20820)
*Jiaojiao Han,Wujiang Xu,Mingyu Jin,Mengnan Du*

Main category: cs.CL

> The paper introduces SAGE, an agent-based framework for improving the interpretability of features captured by sparse autoencoders in large language models, demonstrating higher accuracy in explanation generation compared to existing methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to enhance the interpretability of large language models, whose internal mechanisms are currently opaque, by developing a method that can explain the features captured by sparse autoencoders more effectively.

**Method:** SAGE employs an agent-based approach to iteratively formulate and test multiple explanations for each feature through targeted experiments and usage of empirical activation feedback.

**Result:** The results show that SAGE generates explanations with higher generative and predictive accuracy than state-of-the-art methods when applied to features from sparse autoencoders of various language models.

**Conclusion:** SAGE provides a more rigorous and accurate way to explain the features extracted by sparse autoencoders in large language models, potentially contributing to their safer and more reliable deployment.

**Abstract:** Large language models (LLMs) have achieved remarkable progress, yet their internal mechanisms remain largely opaque, posing a significant challenge to their safe and reliable deployment. Sparse autoencoders (SAEs) have emerged as a promising tool for decomposing LLM representations into more interpretable features, but explaining the features captured by SAEs remains a challenging task. In this work, we propose SAGE (SAE AGentic Explainer), an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanation-driven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.an agent-based framework that recasts feature interpretation from a passive, single-pass generation task into an active, explanationdriven process. SAGE implements a rigorous methodology by systematically formulating multiple explanations for each feature, designing targeted experiments to test them, and iteratively refining explanations based on empirical activation feedback. Experiments on features from SAEs of diverse language models demonstrate that SAGE produces explanations with significantly higher generative and predictive accuracy compared to state-of-the-art baselines.

</details>


### [14] [Structured Prompting Enables More Robust, Holistic Evaluation of Language Models](https://arxiv.org/abs/2511.20836)
*Asad Aali,Muhammad Ahmed Mohsin,Vasiliki Bikia,Arnav Singhvi,Richard Gaus,Suhana Bedi,Hejie Cui,Miguel Fuentes,Alyssa Unell,Yifan Mai,Jordan Cahoon,Michael Pfeffer,Roxana Daneshjou,Sanmi Koyejo,Emily Alsentzer,Percy Liang,Christopher Potts,Nigam H. Shah,Akshay S. Chaudhari*

Main category: cs.CL

> 本论文提出了DSPy+HELM框架，旨在通过引入结构化的提示方式，改进语言模型的基准测试，结果表明，这种方式可以更准确地估计性能，并减少了对提示设计的敏感度。

<details>
  <summary>Details</summary>

**Motivation:** 随着语言模型在各个领域的广泛应用，需要高质量的基准框架来准确评估其性能，以辅助部署决策。然而，现有的固定提示方法常常不能很好地推广到不同的语言模型，导致性能评估不准确。为此，本论文提出了DSPy+HELM框架来解决这一问题。

**Method:** 本论文提出了将DSPy和HELM框架结合的方法，通过引入有结构的提示方式（prompting method），旨在改善和精确语言模型的基准测试。此方法涉及四种提示方式，并在四个前沿的语言模型上进行了测试，涵盖了七种标准测试基准，包括通用和医疗领域。

**Result:** 结果表明，如果不使用结构化的提示方法，HELM通常会低估语言模型的性能（平均低4%），性能估计在不同基准间的变异性也会增大（标准差增加2%），性能差距也被不准确地表达（七个基准中有三个的领先排名被翻转），而引入有理的提示减少对提示设计的敏感度。

**Conclusion:** 首次大规模基准测试研究，实证分析了语言模型在不同基准测试案例和提示方式下的表现行为，提示了可扩展的性能评价方法能带来更有价值的基准性分析决策。学者们开源了DSPy+HELM整合及提示优化流程。

**Abstract:** As language models (LMs) are increasingly adopted across domains, high-quality benchmarking frameworks that accurately estimate performance are essential for guiding deployment decisions. While frameworks such as Holistic Evaluation of Language Models (HELM) enable broad evaluation across tasks, they often rely on fixed prompts that fail to generalize across LMs, yielding unrepresentative performance estimates. Unless we estimate each LM's ceiling (maximum achievable via changes to the prompt), we risk underestimating performance. Declarative prompting frameworks, such as DSPy, offer a scalable alternative to manual prompt engineering by crafting structured prompts that can be optimized per task. However, such frameworks have not been systematically evaluated across established benchmarks. We present a reproducible DSPy+HELM framework that introduces structured prompting methods which elicit reasoning, enabling more accurate LM benchmarking. Using four prompting methods, we evaluate four frontier LMs across seven benchmarks (general/medical domain) against existing HELM baseline scores. We find that without structured prompting: (i) HELM underestimates LM performance (by 4% average), (ii) performance estimates vary more across benchmarks (+2% standard deviation), (iii) performance gaps are misrepresented (leaderboard rankings flip on 3/7 benchmarks), and (iv) introducing reasoning (chain-of-thought) reduces LM sensitivity to prompt design (smaller Δ across prompts). To our knowledge, this is the first large-scale benchmarking study to empirically characterize LM behavior across benchmarks and prompting methods, showing that scalable performance ceiling estimation enables more decision-useful benchmarks. We open-source (i) DSPy+HELM Integration (https://github.com/stanford-crfm/helm/pull/3893) and (ii) Prompt Optimization Pipeline (https://github.com/StanfordMIMI/dspy-helm).

</details>


### [15] [Length-MAX Tokenizer for Language Models](https://arxiv.org/abs/2511.20849)
*Dong Dong,Weijie Su*

Main category: cs.CL

> Introduces the Length-MAX tokenizer that reduces text representation tokens, speeds up training and inference, and improves downstream tasks efficiency.

<details>
  <summary>Details</summary>

**Motivation:** To reduce the tokens required for text representation, and thus improve the efficiency of language models.

**Method:** Our method, called the Length-MAX tokenizer, minimizes average tokens per character through a length-weighted objective maximization cast as a graph partitioning problem, solved via a greedy approximation algorithm.

**Result:** The tokenizer reduces the number of tokens needed for text representation by 14--18% (FineWeb and diverse domains) to 13.0% (64K vocabulary size). Training GPT-2 models shows fewer training steps, lower inference latency, and improved performance on downstream tasks without sacrificing accuracy.

**Conclusion:** Optimizing for average token length can lead to more efficient language modeling without sacrificing, and potentially enhancing, downstream performance.

**Abstract:** We introduce a new tokenizer for language models that minimizes the average tokens per character, thereby reducing the number of tokens needed to represent text during training and to generate text during inference. Our method, which we refer to as the Length-MAX tokenizer, obtains its vocabulary by casting a length-weighted objective maximization as a graph partitioning problem and developing a greedy approximation algorithm. On FineWeb and diverse domains, it yields 14--18\% fewer tokens than Byte Pair Encoding (BPE) across vocabulary sizes from 10K to 50K, and the reduction is 13.0\% when the size is 64K. Training GPT-2 models at 124M, 355M, and 1.3B parameters from scratch with five runs each shows 18.5\%, 17.2\%, and 18.5\% fewer steps, respectively, to reach a fixed validation loss, and 13.7\%, 12.7\%, and 13.7\% lower inference latency, together with a 16\% throughput gain at 124M, while consistently improving on downstream tasks including reducing LAMBADA perplexity by 11.7\% and enhancing HellaSwag accuracy by 4.3\%. Moreover, the Length-MAX tokenizer achieves 99.62\% vocabulary coverage and the out-of-vocabulary rate remains low at 0.12\% on test sets. These results demonstrate that optimizing for average token length, rather than frequency alone, offers an effective approach to more efficient language modeling without sacrificing -- and often improving -- downstream performance. The tokenizer is compatible with production systems and reduces embedding and KV-cache memory by 18\% at inference.

</details>


### [16] [Evo-Memory: Benchmarking LLM Agent Test-time Learning with Self-Evolving Memory](https://arxiv.org/abs/2511.20857)
*Tianxin Wei,Noveen Sachdeva,Benjamin Coleman,Zhankui He,Yuanchen Bei,Xuying Ning,Mengting Ai,Yunzhe Li,Jingrui He,Ed H. Chi,Chi Wang,Shuo Chen,Fernando Pereira,Wang-Cheng Kang,Derek Zhiyuan Cheng*

Main category: cs.CL

> 研究提出Evo-Memory，以解决大语言模型在连续任务流中记忆管理和演化的不足，通过ExpRAG基准和ReMem方案进行评估和优化，显著改善模型记忆的连续优化和进化。

<details>
  <summary>Details</summary>

**Motivation:** 现有评估多集中于静态对话中记忆的被动检索，缺乏对记忆动态积累与重用的研究，尤其是在处理连续任务流中的LLM。

**Method:** Structure

**Result:** {
  "tldr": "研究提出Evo-Memory框架，旨在解决大语言模型在处理连续任务流时记忆管理和演化的不足。通过整合记忆模块和评估多样化的数据集，框架引入了ExpRAG基线方法与ReMem提升措施，促进模型记忆的持续优化和进化。",
  "motivation": "现有的评估集中在静态对话场景，忽视了记忆在连续任务流中积累和再利用的能力。在诸如互动问题助手场景中，LM模型需要处理不断变化的任务流，但通常无法从积累的交互中学习并保持有价值的背景信息，这一限制引出了测试时演化的需要。",
  "method": "Evo-Memory框架，包括一系列记忆模块的统一、评估多样化的多轮目标导向和单轮推理/问题回答数据集，提出ExpRAG基准方法和ReMem优化方案。",
  "result": "通过Evo-Memory和ReMem，系统能更好地从连续交互中学习，累积和再利用知识，改善决策。",
  "conclusion": "Evo-Memory框架能够有效地推进LLM在处理连续任务流中记忆管理和演化的研究，并为未来研究提供基准和方向。")

**Conclusion:** Evo-Memory推进了LLM处理连续任务流记忆管理和演化研究，为未来的研发打下坚实的基础并提供了方向。

**Abstract:** Statefulness is essential for large language model (LLM) agents to perform long-term planning and problem-solving. This makes memory a critical component, yet its management and evolution remain largely underexplored. Existing evaluations mostly focus on static conversational settings, where memory is passively retrieved from dialogue to answer queries, overlooking the dynamic ability to accumulate and reuse experience across evolving task streams. In real-world environments such as interactive problem assistants or embodied agents, LLMs are required to handle continuous task streams, yet often fail to learn from accumulated interactions, losing valuable contextual insights, a limitation that calls for test-time evolution, where LLMs retrieve, integrate, and update memory continuously during deployment. To bridge this gap, we introduce Evo-Memory, a comprehensive streaming benchmark and framework for evaluating self-evolving memory in LLM agents. Evo-Memory structures datasets into sequential task streams, requiring LLMs to search, adapt, and evolve memory after each interaction. We unify and implement over ten representative memory modules and evaluate them across 10 diverse multi-turn goal-oriented and single-turn reasoning and QA datasets. To better benchmark experience reuse, we provide a baseline method, ExpRAG, for retrieving and utilizing prior experience, and further propose ReMem, an action-think-memory refine pipeline that tightly integrates reasoning, task actions, and memory updates to achieve continual improvement.

</details>


### [17] [Winning with Less for Low Resource Languages: Advantage of Cross-Lingual English_Persian Argument Mining Model over LLM Augmentation](https://arxiv.org/abs/2511.20872)
*Ali Jahan,Masood Ghayoomi,Annette Hautli-Janisz*

Main category: cs.CL

> 本研究通过跨语言模型对低资源语言进行论证挖掘，测试结果显示跨语言模型优于仅依赖英语数据或使用合成样本的方法。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于通过跨语言的方法改善论证挖掘在资源较少的语言中的应用效果，以揭示文本中的逻辑结构，辅助知识提取等任务。

**Method:** 本研究采用跨语言方法进行论证挖掘，特别是针对资源较少的语言。研究采用三种训练场景进行模型测试：一是零样本转移模型，仅使用英语数据进行训练；二是基于LLM的增强模型，使用英语数据并结合由大型语言模型生成的合成样本；三是跨语言模型，结合英语原文数据与人工翻译的波斯语句子。

**Result:** 零样本转移模型在英语测试集上获得50.2%的F1分数，在波斯语测试集上获得50.7%的F1分数。基于LLM的增强模型在英语测试集上提升了59.2%，在波斯语测试集上达到69.3%。跨语言模型在仅使用波斯语测试集的情况下达到了74.8%的F1分数，超越了基于LLM的模型表现。

**Conclusion:** 研究结果显示，轻量级的跨语言混合模型能够显著超越资源需求更高的数据增强模型，并为克服低资源语言中论证挖掘任务的数据短缺问题提供了实用的途径。

**Abstract:** Argument mining is a subfield of natural language processing to identify and extract the argument components, like premises and conclusions, within a text and to recognize the relations between them. It reveals the logical structure of texts to be used in tasks like knowledge extraction. This paper aims at utilizing a cross-lingual approach to argument mining for low-resource languages, by constructing three training scenarios. We examine the models on English, as a high-resource language, and Persian, as a low-resource language. To this end, we evaluate the models based on the English Microtext corpus \citep{PeldszusStede2015}, and its parallel Persian translation. The learning scenarios are as follow: (i) zero-shot transfer, where the model is trained solely with the English data, (ii) English-only training enhanced by synthetic examples generated by Large Language Models (LLMs), and (iii) a cross-lingual model that combines the original English data with manually translated Persian sentences. The zero-shot transfer model attains F1 scores of 50.2\% on the English test set and 50.7\% on the Persian test set. LLM-based augmentation model improves the performance up to 59.2\% on English and 69.3\% on Persian. The cross-lingual model, trained on both languages but evaluated solely on the Persian test set, surpasses the LLM-based variant, by achieving a F1 of 74.8\%. Results indicate that a lightweight cross-lingual blend can outperform considerably the more resource-intensive augmentation pipelines, and it offers a practical pathway for the argument mining task to overcome data resource shortage on low-resource languages.

</details>


### [18] [Emergence and Localisation of Semantic Role Circuits in LLMs](https://arxiv.org/abs/2511.20910)
*Nura Aljaafari,Danilo S. Carvalho,André Freitas*

Main category: cs.CL

> 本研究通过引入角色交叉最小配对、时间出现分析及跨模型比较的方法来探究大型语言模型如何实现语义角色结构，发现这些模型内部拥有高度集中的电路，具备部分跨规模和架构的可迁移性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型展示了语义能力，但它们内部机制如何构建抽象语义结构仍不够明确。本研究针对此不足，提出了新的分析方法。

**Method:** 本研究提出了一种方法，该方法结合了角色交叉最小配对、时间出现分析及跨模型比较，用于研究大语言模型如何实现语义角色。

**Result:** 研究结果显示：(i) 高度集中的电路（89-94% 的归属度集中在28个节点内）；(ii) 结构渐进精炼而非阶段转换，更大规模的模型有时会绕过局部电路；(iii) 跨尺度保守性中等（24-59% 的组件重叠），但光谱相似性高。

**Conclusion:** 这项研究表明，大型语言模型形成紧凑、因果隔离的机制来处理抽象语义结构，这种机制在不同规模和架构之间部分可转移。

**Abstract:** Despite displaying semantic competence, large language models' internal mechanisms that ground abstract semantic structure remain insufficiently characterised. We propose a method integrating role-cross minimal pairs, temporal emergence analysis, and cross-model comparison to study how LLMs implement semantic roles. Our analysis uncovers: (i) highly concentrated circuits (89-94% attribution within 28 nodes); (ii) gradual structural refinement rather than phase transitions, with larger models sometimes bypassing localised circuits; and (iii) moderate cross-scale conservation (24-59% component overlap) alongside high spectral similarity. These findings suggest that LLMs form compact, causally isolated mechanisms for abstract semantic structure, and these mechanisms exhibit partial transfer across scales and architectures.

</details>


### [19] [Chatty-KG: A Multi-Agent AI System for On-Demand Conversational Question Answering over Knowledge Graphs](https://arxiv.org/abs/2511.20940)
*Reham Omar,Abdelghny Orogat,Ibrahim Abdelaziz,Omij Mangukiya,Panos Kalnis,Essam Mansour*

Main category: cs.CL

> Chatty-KG innovates in conversational QA over KGs, excelling in multi-turn dialogue and structural integrity by using task-specialized LLM agents.

<details>
  <summary>Details</summary>

**Motivation:** To develop a system that can handle conversational question answering over KGs while preserving the structure and flexibility required for multi-turn dialogues.

**Method:** Chatty-KG combines RAG-style retrieval with structured execution by generating SPARQL queries through task-specialized LLM agents.

**Result:** Chatty-KG outperforms baseline systems in terms of F1 and P@1 scores, both in single-turn and multi-turn settings.

**Conclusion:** Chatty-KG unifies conversational flexibility with structured KG grounding, offering a scalable and extensible approach for reliable multi-turn KGQA.

**Abstract:** Conversational Question Answering over Knowledge Graphs (KGs) combines the factual grounding of KG-based QA with the interactive nature of dialogue systems. KGs are widely used in enterprise and domain applications to provide structured, evolving, and reliable knowledge. Large language models (LLMs) enable natural and context-aware conversations, but lack direct access to private and dynamic KGs. Retrieval-augmented generation (RAG) systems can retrieve graph content but often serialize structure, struggle with multi-turn context, and require heavy indexing. Traditional KGQA systems preserve structure but typically support only single-turn QA, incur high latency, and struggle with coreference and context tracking. To address these limitations, we propose Chatty-KG, a modular multi-agent system for conversational QA over KGs. Chatty-KG combines RAG-style retrieval with structured execution by generating SPARQL queries through task-specialized LLM agents. These agents collaborate for contextual interpretation, dialogue tracking, entity and relation linking, and efficient query planning, enabling accurate and low-latency translation of natural questions into executable queries. Experiments on large and diverse KGs show that Chatty-KG significantly outperforms state-of-the-art baselines in both single-turn and multi-turn settings, achieving higher F1 and P@1 scores. Its modular design preserves dialogue coherence and supports evolving KGs without fine-tuning or pre-processing. Evaluations with commercial (e.g., GPT-4o, Gemini-2.0) and open-weight (e.g., Phi-4, Gemma 3) LLMs confirm broad compatibility and stable performance. Overall, Chatty-KG unifies conversational flexibility with structured KG grounding, offering a scalable and extensible approach for reliable multi-turn KGQA.

</details>


### [20] [TrackList: Tracing Back Query Linguistic Diversity for Head and Tail Knowledge in Open Large Language Models](https://arxiv.org/abs/2511.21006)
*Ioana Buhnila,Aman Sinha,Mathieu Constant*

Main category: cs.CL

> 研究评估了大语言模型在不同类型问题上的表现，发现在定义型问题上表现最佳，而在举例说明型问题上表现最差，并且模型倾向于对常见知识进行更多解释，对专业和技术性知识解释较少。

<details>
  <summary>Details</summary>

**Motivation:** 探索大语言模型在处理不同类型的用户查询时的性能，尤其是在定义型查询之外的表现情况。

**Method:** 使用TrackList管道对预训练数据对LLM回答多样语言查询的影响进行了细致的语用和统计分析，并引入了包含6170个人工标注的英语医学术语的RefoMed-EN数据集。

**Result:** 结果显示定义型问题上的表现最佳，而举例说明型问题上的表现则最差，且对于热门常见知识，模型倾向于提供更多衍生解释，而对于专业和技术性知识则解释较少。

**Conclusion:** 揭示出大语言模型在各种类型问题上的回答性能存在差异，并表明其在专业和技术领域中对于不常见知识的处理能力较弱。

**Abstract:** Large Language Models (LLMs) have proven efficient in giving definition-type answers to user input queries. While for humans giving various types of answers, such as examples and paraphrases, is an easy task, LLMs struggle to provide correct answers for other than definition-type queries. In this study, we evaluated this drop in performance using TrackList, a fine-grained linguistic and statistical analysis pipeline to investigate the impact of the pre-training data on LLMs answers to diverse linguistic queries. We also introduce RefoMed-EN, an English dataset consisting of 6170 human-annotated medical terms alongside their corresponding definitions, denominations, exemplifications, explanations, or paraphrases. We studied whether the high frequency of a concept (head) or low frequency (tail) impacts the language model's performance. We evaluated the quality of the LLM's output using syntactic and semantic similarity metrics, statistical correlations and embeddings. Results showed that the LLM's task performance for definition type questions is the highest, while for the exemplification type it is the lowest. Additionally, we showed that for definition-type questions, large language models are prone to paraphrase more on popular and frequent knowledge and less on tail and technical knowledge, especially in the expert texts.

</details>


### [21] [Semantic Anchors in In-Context Learning: Why Small LLMs Cannot Flip Their Labels](https://arxiv.org/abs/2511.21038)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CL

> 研究揭示，在上下文学习过程中，大型语言模型似乎依赖于稳定的语义锚点，限制了其在少量示例提示下的语义重写能力。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于了解大型语言模型中的标签语义是否可以通过上下文学习进行重新映射或仅仅是改进现有的语义基础，探究这个问题有助于理解模型在少量示例提示下的行为限制。

**Method:** 该研究通过将大型语言模型视为提示引导的分类器，对比它们在自然演示（带有正确标签）和反转演示（系统性地翻转标签含义）下的行为，探讨了标签语义预训练后是否可以通过上下文学习（ICL）进行重写，或者是仅仅针对已有语义基础进行微调的问题。

**Result:** 研究发现，使用自然演示时，ICL虽然能提升准确率，但依然保持较强的先验一致性，大部分正确的预测结果与零样本行为相符，即使在先验较弱的情况下也是如此。在反转演示条件下，模型无法学习到连贯的反意义分类器：虽然提示一致性增加，但准确率下降，且在少量样本的训练设置下（1-120亿参数的模型），语义重写率依然为零。

**Conclusion:** 研究表明，ICL主要调整输入如何映射到预训练中学习到的稳定的语义方向，而不是灵活地重写标签含义，这意味着想要在现有规模上重写标签语义，ICL需要超越的干预措施。

**Abstract:** Can in-context learning (ICL) override pre-trained label semantics, or does it merely refine an existing semantic backbone? We address this question by treating LLMs as prompt-induced classifiers and contrasting their behavior under \emph{natural} demonstrations (with correct labels) and \emph{inverted} demonstrations (systematically flipping label meanings). We decompose ICL behavior into three alignment metrics (truth, prior, and prompt alignment) and introduce a semantic override rate, defined as correctness under flipped semantics. Across eight classification tasks and eight open-source LLMs (1--12B parameters), we find consistent evidence for a semantic anchor view. With natural demonstrations, ICL improves accuracy while maintaining strong prior alignment; most correct predictions coincide with zero-shot behavior, even when the prior is weak. With inverted demonstrations, models cannot learn coherent anti-semantic classifiers: prompt alignment increases only by sacrificing accuracy, and semantic override rates remain exactly zero in our few-shot 1--12B setting. Rather than flexibly remapping label meanings, ICL primarily adjusts how inputs project onto stable semantic directions learned during pre-training, clarifying fundamental limits of few-shot prompting and suggesting that overriding label semantics at these scales requires interventions beyond ICL. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/semantic-anchors-icl.

</details>


### [22] [Context-Aware Pragmatic Metacognitive Prompting for Sarcasm Detection](https://arxiv.org/abs/2511.21066)
*Michael Iskandardinata,William Christian,Derwin Suhartono*

Main category: cs.CL

> 本文介绍了一种检索感知的方法来改进讽刺检测，该方法在三个数据集上取得了重大提升，并强调背景信息对于讽刺检测的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 虽然预先训练和大型语言模型在讽刺检测上表现突出，但讽刺文本的复杂性、语言多样性以及跨社区的文化差异，使讽刺检测任务变得更加复杂。特别是这些模型对于需要额外依据分析的词汇或标记的检测不可靠。

**Method:** 本论文提出了一种检索感知的方法，该方法结合了从web检索获得的非参数知识和大语言模型自身的内部知识，以提供补充的背景信息来增强讽刺检测。

**Result:** 该方法在三个数据集上进行了评估，取得了显著的提升。在Twitter Indonesia Sarcastic数据集上，非参数检索比原始PMP方法提高了9.87%的macro-F1；在Semeval数据集上，自我知识检索提高了3.29%的macro-F1；在MUStARD数据集上，自我知识检索提高了4.08%的macro-F1。

**Conclusion:** 研究结果强调了背景信息在提高大语言模型在讽刺检测任务中的表现的重要性，尤其是在处理文化特定俚语、参考或未知词汇方面。未来的研究将集中在优化检索相关信息的策略上，并探索检索质量如何影响性能。

**Abstract:** Detecting sarcasm remains a challenging task in the areas of Natural Language Processing (NLP) despite recent advances in neural network approaches. Currently, Pre-trained Language Models (PLMs) and Large Language Models (LLMs) are the preferred approach for sarcasm detection. However, the complexity of sarcastic text, combined with linguistic diversity and cultural variation across communities, has made the task more difficult even for PLMs and LLMs. Beyond that, those models also exhibit unreliable detection of words or tokens that require extra grounding for analysis. Building on a state-of-the-art prompting method in LLMs for sarcasm detection called Pragmatic Metacognitive Prompting (PMP), we introduce a retrieval-aware approach that incorporates retrieved contextual information for each target text. Our pipeline explores two complementary ways to provide context: adding non-parametric knowledge using web-based retrieval when the model lacks necessary background, and eliciting the model's own internal knowledge for a self-knowledge awareness strategy. We evaluated our approach with three datasets, such as Twitter Indonesia Sarcastic, SemEval-2018 Task 3, and MUStARD. Non-parametric retrieval resulted in a significant 9.87% macro-F1 improvement on Twitter Indonesia Sarcastic compared to the original PMP method. Self-knowledge retrieval improves macro-F1 by 3.29% on Semeval and by 4.08% on MUStARD. These findings highlight the importance of context in enhancing LLMs performance in sarcasm detection task, particularly the involvement of culturally specific slang, references, or unknown terms to the LLMs. Future work will focus on optimizing the retrieval of relevant contextual information and examining how retrieval quality affects performance. The experiment code is available at: https://github.com/wllchrst/sarcasm-detection_pmp_knowledge-base.

</details>


### [23] [Enhancing Burmese News Classification with Kolmogorov-Arnold Network Head Fine-tuning](https://arxiv.org/abs/2511.21081)
*Thura Aung,Eaint Kay Khaing Kyaw,Ye Kyaw Thu,Thazin Myint Oo,Thepchai Supnithi*

Main category: cs.CL

> The study investigates the effectiveness of KANs in improving classification performance over MLPs for low-resource languages. The results show KANs offer a competitive or superior alternative, with EfficientKAN achieving the highest F1-score (0.928) using fastText embeddings.

<details>
  <summary>Details</summary>

**Motivation:** The authors are motivated to address the limitations of MLPs, specifically their fixed non-linearity that can limit the model's expressiveness and increase computational cost, in the context of classification tasks for low-resource languages where fine-tuning only the final classification layer is a common strategy.

**Method:** This paper explores the use of Kolmogorov-Arnold Networks (KANs) as alternative classification heads for low-resource language tasks, compared to commonly used Multi-Layer Perceptrons (MLPs). It evaluates different variants of KANs such as FourierKAN, EfficientKAN, and FasterKAN with various embeddings such as TF-IDF, fastText, and multilingual transformers like mBERT and Distil-mBERT.

**Result:** The results show that KAN-based heads are competitive with or even superior to MLPs in performance. Specifically, EfficientKAN performed best with the fastText embedding (F1-score of 0.928), and FasterKAN provided the best balance of speed and accuracy. With mBERT embeddings, EfficientKAN matched or marginally surpassed MLPs (F1-score of 0.917) in classification tasks.

**Conclusion:** This study concludes that KANs serve as a promising and efficient alternative to MLPs for tasks involving low-resource languages such as Burmese, due to their enhanced expressiveness and efficiency.

**Abstract:** In low-resource languages like Burmese, classification tasks often fine-tune only the final classification layer, keeping pre-trained encoder weights frozen. While Multi-Layer Perceptrons (MLPs) are commonly used, their fixed non-linearity can limit expressiveness and increase computational cost. This work explores Kolmogorov-Arnold Networks (KANs) as alternative classification heads, evaluating Fourier-based FourierKAN, Spline-based EfficientKAN, and Grid-based FasterKAN-across diverse embeddings including TF-IDF, fastText, and multilingual transformers (mBERT, Distil-mBERT). Experimental results show that KAN-based heads are competitive with or superior to MLPs. EfficientKAN with fastText achieved the highest F1-score (0.928), while FasterKAN offered the best trade-off between speed and accuracy. On transformer embeddings, EfficientKAN matched or slightly outperformed MLPs with mBERT (0.917 F1). These findings highlight KANs as expressive, efficient alternatives to MLPs for low-resource language classification.

</details>


### [24] [Orthographic Constraint Satisfaction and Human Difficulty Alignment in Large Language Models](https://arxiv.org/abs/2511.21086)
*Bryan E. Tuck,Rakesh M. Verma*

Main category: cs.CL

> 研究表明，不同架构的大型语言模型在处理需满足硬性正字法规则的任务时性能差异主要来源于架构本身而非单纯参数增益。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于评估大型语言模型在满足硬性正字法规则的文本生成任务中的表现，探索不同模型架构和参数量对模型性能的影响。

**Method:** 采用了28种不同配置的三个模型家族在58个字谜任务上的交叉架构评估方法，同时使用了来自10000个用户各自解决的字谜难度评分数据。

**Result:** 该研究主要评估了三种不同架构（Qwen3、Claude Haiku-4.5和GPT-5-mini）的28种配置在58个需要字符级约束满足的字谜任务上的表现。结果显示，不同架构之间的性能差距（2.0-2.2倍）比同一架构内的参数量提升所带来的差距（参数量提升八倍带来83%的性能增益）更大。此外，高容量模型对计算预算的敏感度较高，中型模型则可能出现饱和甚至性能下降。尽管模型能够适度校准任务难度，但在处理具有非典型正字法的常见词汇（如"data"、"poop"和"loll"）时存在系统性失败。这暗示除了简单的模型规模增加和计算预算提升外，可能需要在架构或训练目标上做出特殊化改进以满足正字法约束。

**Conclusion:** 研究表明，满足文本生成中的硬正字法规则可能需要模型架构或训练目标的专门化，而非仅仅依赖模型尺寸或计算资源的扩大。

**Abstract:** Large language models must satisfy hard orthographic constraints during controlled text generation, yet systematic cross-architecture evaluation remains limited. We evaluate 28 configurations spanning three model families (Qwen3, Claude Haiku-4.5, GPT-5-mini) on 58 word puzzles requiring character-level constraint satisfaction. Architectural differences produce substantially larger performance gaps (2.0-2.2x, F1=0.761 vs. 0.343) than parameter scaling within families (83% gain from eightfold scaling), suggesting that constraint satisfaction may require specialized architectural features or training objectives beyond standard language model scaling. Thinking budget sensitivity proves heterogeneous: high-capacity models show strong returns (+0.102 to +0.136 F1), while mid-sized variants saturate or degrade. These patterns are inconsistent with uniform compute benefits. Using difficulty ratings from 10,000 human solvers per puzzle, we establish modest but consistent calibration (r=0.24-0.38) across all families, yet identify systematic failures on common words with unusual orthography ("data", "poop", "loll": 86-95% human success, 89-96% model miss rate). These failures reveal over-reliance on distributional plausibility that penalizes orthographically atypical but constraint-valid patterns, suggesting architectural innovations may be required beyond simply scaling parameters or computational budgets.

</details>


### [25] [ASR Error Correction in Low-Resource Burmese with Alignment-Enhanced Transformers using Phonetic Features](https://arxiv.org/abs/2511.21088)
*Ye Bhone Lin,Thura Aung,Ye Kyaw Thu,Thazin Myint Oo*

Main category: cs.CL

> The paper presents a first-of-its-kind study for ASR error correction in Burmese, where the proposed model shows significant improvements over baseline ASR performance by integrating various features with Transformer models.

<details>
  <summary>Details</summary>

**Motivation:** The study aims to address the challenge of ASR error correction in low-resource languages, specifically Burmese.

**Method:** This paper investigates the use of sequence-to-sequence Transformer models for ASR error correction in low-resource Burmese, exploring different feature integration strategies, such as IPA and alignment information.

**Result:** The research demonstrates consistent improvements in word- and character-level accuracy over baseline ASR outputs, with the proposed AEC model notably reducing the WER from 51.56 to 39.82 before data augmentation and to 43.59 after augmentation, and improving chrF++ scores from 0.5864 to 0.627.

**Conclusion:** The findings underscore the robustness of the ASR Error Correction (AEC) approach and emphasize the importance of feature design for enhancing ASR performance in low-resource language conditions.

**Abstract:** This paper investigates sequence-to-sequence Transformer models for automatic speech recognition (ASR) error correction in low-resource Burmese, focusing on different feature integration strategies including IPA and alignment information. To our knowledge, this is the first study addressing ASR error correction specifically for Burmese. We evaluate five ASR backbones and show that our ASR Error Correction (AEC) approaches consistently improve word- and character-level accuracy over baseline outputs. The proposed AEC model, combining IPA and alignment features, reduced the average WER of ASR models from 51.56 to 39.82 before augmentation (and 51.56 to 43.59 after augmentation) and improving chrF++ scores from 0.5864 to 0.627, demonstrating consistent gains over the baseline ASR outputs without AEC. Our results highlight the robustness of AEC and the importance of feature design for improving ASR outputs in low-resource settings.

</details>


### [26] [MortgageLLM: Domain-Adaptive Pretraining with Residual Instruction Transfer, Alignment Tuning, and Task-Specific Routing](https://arxiv.org/abs/2511.21101)
*Manish Jain,Satheesh Kumar Ponnambalam,Salman Faroz,Chandrakanth Lns,Vinay Sharma*

Main category: cs.CL

> 本文提出了一种名为MortgageLLM的专用于抵押贷款领域的大型语言模型，该模型采用双轨专化框架开发，通过指令残差技术恢复了指令跟随能力，并且在专业领域基准测试中显著表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型虽然在通用领域表现出色，但在专门领域如抵押贷款金融的应用需要域特定的知识增强同时保持指令跟随保真度。因此，我们开发MortgageLLM以应对这一双重挑战。

**Method:** 我们提出了MortgageLLM，这是一种专用于抵押贷款领域的大型语言模型，采用双轨专化框架从单个基础模型（LLaMA-3.1-8B）开发。该双轨方法解决了单一任务模型在优化结构化任务性能时会降低对话保真度的问题，通过训练两个专家模型各自优化其独特能力。我们引入了指令残差技术，在无需监督微调的情况下恢复了域适应后的指令跟随能力，结合对话问答模型和结构化任务模型来实现分类和总结。此外，还开发了一种智能任务路由机制，使用其中一个专家模型通过少样本分类来实现。

**Result:** 最终模型MLM v2在专业领域基准测试中显著超越了基础LLaMA-3.1-8B-Instruct模型，具体表现在LLM评估的总结得分为4.58（对比3.99），问答得分为4.09（对比4.0），分类得分为2.6（对比1.2）。在语义相似度上，我们的模型在总结、问答和分类得分上也显著优于基线方法，BERTScore分别为0.77、0.68和0.75。

**Conclusion:** 我们的研究为抵押贷款金融领域的大型语言模型发展提供了一个有效的方法，通过双轨模型架构、指令恢复技术以及智能任务路由机制的结合，不仅能够增强模型的领域适应能力，还能够显著提升模型在复杂对话问答及结构化任务上的性能，为未来类似领域的应用蓝图提供了实践证明。

**Abstract:** Large Language Models (LLMs) demonstrate exceptional capabilities across general domains, yet their application to specialized sectors such as mortgage finance requires domain-specific knowledge augmentation while preserving instruction-following fidelity. We present MortgageLLM, a novel domain-specific large language model that addresses this dual challenge. It is developed using a dual-track specialization framework from a single base model (LLaMA-3.1-8B). We opted for this dual-expert approach as a single multi-task model suffers from performance trade-offs, where optimizing for structured tasks (via SFT) degrades conversational fidelity (via DPO). Our dual-track method solves this by creating two specialists, allowing each to be optimally trained for its distinct capability. Our approach applies the instruction residual technique to restore instruction-following capabilities post-domain adaptation without supervised fine-tuning. We contribute: (1) application of this residual technique to the highly specialized mortgage finance domain; (2) a dual-expert architecture combining a conversational Q&A model and a structured task model for classification and summarization; and (3) an intelligent task routing mechanism using few-shot classification performed by one of the expert models itself. We validate our approach on domain-specific benchmarks, where our final model (MLM v2) significantly outperforms the base LLaMA-3.1-8B-Instruct, achieving an LLM-as-a-Judge summarization score of 4.58 (vs. 3.99), a Q&A score of 4.09 (vs. 4.0), and a classification score of 2.6 (vs. 1.2). On semantic similarity, our model achieved a BERTScore of 0.77 for summarization (vs. 0.74), 0.68 for Q&A (vs. 0.58), and 0.75 for classification (vs. 0.73), substantially outperforming baseline approaches.

</details>


### [27] [Self-Guided Defense: Adaptive Safety Alignment for Reasoning Models via Synthesized Guidelines](https://arxiv.org/abs/2511.21214)
*Yuhang Wang,Yanxu Zhu,Dongyuan Lu,Jitao Sang*

Main category: cs.CL

> The paper presents SGASA, a framework designed to enhance the safety of reasoning models against adversarial prompts by generating internal safety guidelines and fine-tuning the model to better resist harmful inputs, while also minimizing unnecessary refusals of benign requests.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the challenge of ensuring the safety of reasoning models against adversarial jailbreak prompts, which can evade safety mechanisms and generate harmful content. The covert and deceptive nature of such prompts necessitates an adaptive safety alignment approach that can autonomously reinforce model defenses.

**Method:** This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework. SGASA consists of two stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which fine-tunes the model using Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed safety guidelines.

**Result:** Experiments across multiple datasets show that the SGASA framework significantly improves model safety against adversarial prompts.

**Conclusion:** Experiments on multiple datasets demonstrate that the SGASA framework significantly enhances the safety and robustness of models against harmful adversarial prompts, validating the framework's adaptive and scalable effectiveness.

**Abstract:** Reasoning models have demonstrated remarkable capabilities in complex reasoning tasks. However, ensuring their safety against adversarial jailbreak prompts remains a critical challenge. Due to the covert and deceptive nature of such prompts, they can often evade built-in safety mechanisms and lead to the generation of harmful content. This underscores the need for an adaptive safety alignment approach that enables models to autonomously reinforce their defenses in response to adversarial inputs. This paper introduces the Synthesized Guideline-based Adaptive Safety Alignment (SGASA) framework, which internalizes model-generated safety guidelines to strengthen models' ability to enhance robustness against harmful adversarial prompts while minimizing unnecessary refusals of benign requests. SGASA consists of two key stages: Data Pre-synthesis, which generates safety guidelines and augmented prompts; and Alignment Fine-tuning, which leverages Supervised Fine-tuning (SFT) and Direct Preference Optimization (DPO) to embed these guidelines into the model. Extensive experiments across multiple datasets demonstrate that SGASA significantly improves model safety, validating its adaptive and scalable effectiveness.

</details>


### [28] [Can Finetuing LLMs on Small Human Samples Increase Heterogeneity, Alignment, and Belief-Action Coherence?](https://arxiv.org/abs/2511.21218)
*Steven Wang,Kyle Hunt,Shaojie Tang,Kenneth Joseph*

Main category: cs.CL

> 研究发现，即使通过对LLM进行细调，其生成的数据仍无法完全替代人类参与者在正式的推理分析中。

<details>
  <summary>Details</summary>

**Motivation:** 探讨在实验和调查研究中，是否可以通过细调少量人类调查数据来改进LLM的模拟效果，使其生成更贴近现实的结果。

**Method:** 本研究通过一个关于信息披露的行为实验，比较了人类和基于LLM生成的回应在多个维度上的差异，包括分布离散度、子群对齐度、信念行为一致性以及回归系数的复现。

**Result:** 细调后的小规模人类样本显著改善了异质性、对齐度以及信念行为一致性，但仍无法复现原始研究的回归系数。

**Conclusion:** 尽管改进显著，但LLM生成的数据仍不适合替代人类参与者进行正式的推理分析。

**Abstract:** There is ongoing debate about whether large language models (LLMs) can serve as substitutes for human participants in survey and experimental research. While recent work in fields such as marketing and psychology has explored the potential of LLM-based simulation, a growing body of evidence cautions against this practice: LLMs often fail to align with real human behavior, exhibiting limited diversity, systematic misalignment for minority subgroups, insufficient within-group variance, and discrepancies between stated beliefs and actions. This study examines an important and distinct question in this domain: whether fine-tuning on a small subset of human survey data, such as that obtainable from a pilot study, can mitigate these issues and yield realistic simulated outcomes. Using a behavioral experiment on information disclosure, we compare human and LLM-generated responses across multiple dimensions, including distributional divergence, subgroup alignment, belief-action coherence, and the recovery of regression coefficients. We find that fine-tuning on small human samples substantially improves heterogeneity, alignment, and belief-action coherence relative to the base model. However, even the best-performing fine-tuned models fail to reproduce the regression coefficients of the original study, suggesting that LLM-generated data remain unsuitable for replacing human participants in formal inferential analyses.

</details>


### [29] [Developing an Open Conversational Speech Corpus for the Isan Language](https://arxiv.org/abs/2511.21229)
*Adisai Na-Thalang,Chanakan Wittayasakpan,Kritsadha Phatcharoen,Supakit Buakaw*

Main category: cs.CL

> 论文描述了首个依莎纳语对话语音数据集的建立，解决书写变异问题，推动欠发达语言研究与包容性人工智能的进展。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机在于建立一个开放语音资源，为包含依莎纳语在内的欠发达语言的研究提供支持，促进包容性人工智能发展，并为对话语音的语言和技术挑战提供研究基础。

**Method:** 此论文建立了一个用于老挝依莎纳语的首个开放对话语音语料库。该语料库包含自然语音，区别于传统的基于朗读或剧本的语音语料库，它可以捕捉到依莎纳语的地道语言特征，如口语表达、自发韵律、省略语及频繁的与泰语的混用。

**Result:** 该论文成功创建了首个依莎纳语对话语音数据集，为处理自然语音提供了新资源。尽管缺乏标准化正写法，通过制定实用的转写指南，解决了书写实践中的变异问题。

**Conclusion:** 论文结论指出，这一开放资源将促进依莎纳语和其他未充分代表语言的研究，并建立试图在保持语言表现准确性和计算处理需求间平衡的转写规范。

**Abstract:** This paper introduces the development of the first open conversational speech dataset for the Isan language, the most widely spoken regional dialect in Thailand. Unlike existing speech corpora that are primarily based on read or scripted speech, this dataset consists of natural speech, thereby capturing authentic linguistic phenomena such as colloquials, spontaneous prosody, disfluencies, and frequent code-switching with central Thai. A key challenge in building this resource lies in the lack of a standardized orthography for Isan. Current writing practices vary considerably, due to the different lexical tones between Thai and Isan. This variability complicates the design of transcription guidelines and poses questions regarding consistency, usability, and linguistic authenticity. To address these issues, we establish practical transcription protocols that balance the need for representational accuracy with the requirements of computational processing. By releasing this dataset as an open resource, we aim to contribute to inclusive AI development, support research on underrepresented languages, and provide a basis for addressing the linguistic and technical challenges inherent in modeling conversational speech.

</details>


### [30] [PEFT-Bench: A Parameter-Efficient Fine-Tuning Methods Benchmark](https://arxiv.org/abs/2511.21285)
*Robert Belanec,Branislav Pecher,Ivan Srba,Maria Bielikova*

Main category: cs.CL

> 本文提出了PEFT-Bench，一个统一的参数高效微调方法评估基准，并引入了考虑多个因素的PSCP指标。在多个数据集和方法上展示了其应用。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于大语言模型的规模庞大而导致的高计算和环境成本，限制了其可访问性。虽然参数高效微调方法能够减少可训练参数的数量同时保持下游任务的强大性能，但当前的评估方法仍然在模型和数据集方面受到限制，并且难以复现。为了弥补这一差距，提出了PEFT-Bench和PSCP指标。

**Method:** 本文提出了PEFT-Bench，一个用于评估自回归大语言模型中各种参数高效微调方法的统一端到端基准测试平台。此外，还引入了PEFT Soft Score Penalties（PSCP）指标，该指标考虑了可训练参数数量、推理速度和训练内存使用量。

**Result:** 本文通过在27个NLP数据集和6种PEFT方法上展示了PEFT-Bench的使用情况。

**Conclusion:** PEFT-Bench和PSCP指标为评估参数高效微调方法提供了全面的基准测试平台，并促进了评估的一致性和可复现性。

**Abstract:** Despite the state-of-the-art performance of Large Language Models (LLMs) achieved on many tasks, their massive scale often leads to high computational and environmental costs, limiting their accessibility. Parameter-efficient fine-tuning (PEFT) methods address this challenge by reducing the number of trainable parameters while maintaining strong downstream performance. Despite the increased development in PEFT methods, current evaluations remain limited (in terms of evaluated models and datasets) and difficult to reproduce. To bridge this gap, we introduce PEFT-Bench, a unified end-to-end benchmark for evaluating diverse PEFT methods on autoregressive LLMs. We demonstrate its usage across 27 NLP datasets and 6 PEFT methods. To account for different PEFT training and inference factors, we also introduce the PEFT Soft Score Penalties (PSCP) metric, which takes trainable parameters, inference speed, and training memory usage into account.

</details>


### [31] [Emergent Lexical Semantics in Neural Language Models: Testing Martin's Law on LLM-Generated Text](https://arxiv.org/abs/2511.21334)
*Kai Kugler*

Main category: cs.CL

> 研究揭示了神经语言模型生成文本中词频与多义词之间的非单调发展轨迹，建立了评估模型中语言结构发展的新方法。

<details>
  <summary>Details</summary>

**Motivation:** 首次系统调查神经语言模型在训练过程中生成的文本中的Martin's Law—词频与多义词之间的经验关系。

**Method:** 采用DBSCAN聚类分析上下文化嵌入来量化词义，并分析了四个Pythia模型在30个训练检查点的词频与多义词之间的关系。

**Result:** 结果揭示了一个非单调的发展轨迹：大约在第100个检查点处出现Martin's Law，峰值相关性(r > 0.6)出现在第104个检查点，然后在第105个检查点逐渐下降。较小的模型（70M，160M）在后期检查点经历灾难性的语义崩溃，而较大的模型（410M，1B）则表现出平滑下降。频率-特异性权衡在所有模型中保持稳定(r ≈ -0.3)。

**Conclusion:** 研究表明，神经语言模型生成文本中的语言规则遵循情况不是随着训练单调增加，而是遵循一个基于最优语义窗口的良好发展轨迹。这项工作为评估神经语言模型中出现的语言结构提供了一种新方法。

**Abstract:** We present the first systematic investigation of Martin's Law - the empirical relationship between word frequency and polysemy - in text generated by neural language models during training. Using DBSCAN clustering of contextualized embeddings as an operationalization of word senses, we analyze four Pythia models (70M-1B parameters) across 30 training checkpoints. Our results reveal a non-monotonic developmental trajectory: Martin's Law emerges around checkpoint 100, reaches peak correlation (r > 0.6) at checkpoint 104, then degrades by checkpoint 105. Smaller models (70M, 160M) experience catastrophic semantic collapse at late checkpoints, while larger models (410M, 1B) show graceful degradation. The frequency-specificity trade-off remains stable (r $\approx$ -0.3) across all models. These findings suggest that compliance with linguistic regularities in LLM-generated text is not monotonically increasing with training, but instead follows a balanced trajectory with an optimal semantic window. This work establishes a novel methodology for evaluating emergent linguistic structure in neural language models.

</details>


### [32] [Training Introspective Behavior: Fine-Tuning Induces Reliable Internal State Detection in a 7B Model](https://arxiv.org/abs/2511.21399)
*Joshua Fonseca Rivera*

Main category: cs.CL

> 研究通过微调使语言模型具备更可靠地检测和报告被注入"思想"的能力，这表明训练可以解决AI模型中的差异性问题。

<details>
  <summary>Details</summary>

**Motivation:** 研究探讨了是否可以训练语言模型直接具备自我报告被注入"思想"的能力，而不仅仅是等待其自发出现.

**Method:** 通过在瞬时单一标记注入上进行微调，将一个70亿参数模型从几乎完全失败（0.4%的准确率和6.7%的假阳性率）转变为可靠的检测（在α=40时，未见过的概念上达到85%的准确率和0%的假阳性率）.

**Result:** 训练后的模型能够检测到被注入到单一标记位置的瞬时"思想"，保留该信息，并在随后的生成步骤中报告其语义内容。此外，该模型在未见过的概念向量上的泛化表现表明其学到了可迁移的技能。

**Conclusion:** 这些结果回答了Lindsey提出的一个开放性问题，即"训练是否有助于消除模型之间的差异"。研究显示，至少可以建立起一个内部透明的AI模型的方法。

**Abstract:** Lindsey (2025) investigates introspective awareness in language models through four experiments, finding that models can sometimes detect and identify injected activation patterns -- but unreliably (~20% success in the best model). We focus on the first of these experiments -- self-report of injected "thoughts" -- and ask whether this capability can be directly trained rather than waiting for emergence. Through fine-tuning on transient single-token injections, we transform a 7B parameter model from near-complete failure (0.4% accuracy, 6.7% false positive rate) to reliable detection (85% accuracy on held-out concepts at α=40, 0% false positives). Our model detects fleeting "thoughts" injected at a single token position, retains that information, and reports the semantic content across subsequent generation steps. On this task, our trained model satisfies three of Lindsey's criteria: accuracy (correct identification), grounding (0/60 false positives), and internality (detection precedes verbalization). Generalization to unseen concept vectors (7.5pp gap) demonstrates the model learns a transferable skill rather than memorizing specific vectors, though this does not establish metacognitive representation in Lindsey's sense. These results address an open question raised by Lindsey: whether "training for introspection would help eliminate cross-model differences." We show that at least one component of introspective behavior can be directly induced, offering a pathway to built-in AI transparency.

</details>


### [33] [Can LLMs extract human-like fine-grained evidence for evidence-based fact-checking?](https://arxiv.org/abs/2511.21401)
*Antonín Jarolím,Martin Fajčík,Lucia Makaiová*

Main category: cs.CL

> 本研究针对捷克语和斯洛伐克语声明的细粒度证据提取，评估了大型语言模型的表现，发现虽然一些较小的模型表现良好，但总体上这些模型在按原样复制证据方面存在困难。

<details>
  <summary>Details</summary>

**Motivation:** 在线新闻文章的用户评论中经常传播不实信息，需要有效的方法来检测事实错误的信息。为了有力地支持或反驳这些评论中抽取的声明，需要识别相关的文档，并指出精确反驳声明的文本片段。

**Method:** 本研究专注于从捷克语和斯洛伐克语的声明中提取细粒度证据。创建了一个新数据集，该数据集包含由付费标注者执行的双向标注的细粒度证据。

**Result:** 研究结果表明，大型语言模型（LLMs）经常无法逐字复制来源文本中的证据，导致无效输出。错误率分析显示，尽管llama3.1:8b模型相对较小，但它具有较高的正确输出比例，而gpt-oss-120b模型尽管参数更多，但表现较差。此外，模型qwen3:14b、deepseek-r1:32b和gpt-oss:20b在模型大小与与人类注释的对齐之间表现出有效的平衡。

**Conclusion:** 大型语言模型在从声明中提取细粒度证据方面表现出一定的挑战，但某些中等大小的模型在与人类标注保持对齐方面表现良好。

**Abstract:** Misinformation frequently spreads in user comments under online news articles, highlighting the need for effective methods to detect factually incorrect information. To strongly support or refute claims extracted from such comments, it is necessary to identify relevant documents and pinpoint the exact text spans that justify or contradict each claim. This paper focuses on the latter task -- fine-grained evidence extraction for Czech and Slovak claims. We create new dataset, containing two-way annotated fine-grained evidence created by paid annotators. We evaluate large language models (LLMs) on this dataset to assess their alignment with human annotations. The results reveal that LLMs often fail to copy evidence verbatim from the source text, leading to invalid outputs. Error-rate analysis shows that the {llama3.1:8b model achieves a high proportion of correct outputs despite its relatively small size, while the gpt-oss-120b model underperforms despite having many more parameters. Furthermore, the models qwen3:14b, deepseek-r1:32b, and gpt-oss:20b demonstrate an effective balance between model size and alignment with human annotations.

</details>


### [34] [Text-to-SQL as Dual-State Reasoning: Integrating Adaptive Context and Progressive Generation](https://arxiv.org/abs/2511.21402)
*Zhifeng Hao,Qibin Song,Ruichu Cai,Boyan Xu*

Main category: cs.CL

> DSR-SQL通过双状态推理框架解决了复杂企业数据库中Text-to-SQL的挑战，取得不错的结果。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有Text-to-SQL方法在处理复杂企业数据库时存在的限制性上下文容量和不可靠的模式链接等问题。

**Method:** 引入了DSR-SQL框架，该框架将Text-to-SQL建模为自适应上下文状态和逐步生成状态之间的交互。

**Result:** DSR-SQL在没有额外训练或示例的情况下，在Spider 2.0-Snow数据集上达到了35.28%的执行准确性，在BIRD开发集上达到了68.32%。

**Conclusion:** DSR-SQL框架通过创新的双状态推理模型解决了复杂数据库上Text-to-SQL任务的挑战。

**Abstract:** Recent divide-and-conquer reasoning approaches, particularly those based on Chain-of-Thought (CoT), have substantially improved the Text-to-SQL capabilities of Large Language Models (LLMs). However, when applied to complex enterprise databases, such methods struggle to maintain coherent reasoning due to limited context capacity, unreliable schema linking, and weak grounding in database semantics. To overcome these issues, we introduce DSR-SQL, a \textbf{D}ual-\textbf{S}tate \textbf{R}easoning framework that models Text-to-SQL as an interaction between an adaptive context state and a progressive generation state. The first constructs a compact, semantically faithful environment by refining large schemas and selecting relevant structures, while the second formalizes SQL synthesis as feedback-guided state transitions, enabling the model to self-correct and align with user intent. Without any post-training or in-context examples, DSR-SQL achieves competitive performance, reaching 35.28\% execution accuracy on Spider 2.0-Snow and 68.32\% on BIRD development set. Our implementation will be open-sourced at: https://github.com/DMIRLAB-Group/DSR-SQL.

</details>


### [35] [Odin: Oriented Dual-module Integration for Text-rich Network Representation Learning](https://arxiv.org/abs/2511.21416)
*Kaifeng Hong,Yinglong Zhang,Xiaoying Hong,Xuewen Xia,Xing Xu*

Main category: cs.CL

> Odin提出了一种新型架构，在特定深度将图结构整合进Transformer，解决了传统GNN和Transformer模型在处理图数据时的局限性，实现在大文本图数据上的高性能和高效率。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法要么依赖于受到过度平滑和跳数相关扩散限制的GNN，要么使用Transformer忽视图的拓扑结构并将节点视为隔离的序列。

**Method:** Odin (Oriented Dual-module INtegration) 是一种新的架构，它通过定向双模块机制在选定的深度将图结构注入Transformer。与依赖多跳信息传递的GNN不同，Odin在特定Transformer层中融合多跳结构，从而生成与模型语义层次对齐的低、中、高层次的结构抽象。聚合操作是在全局[CLS]表示上进行的，因此Odin从根本上避免了过度平滑问题，并将结构抽象与邻域大小或图结构解耦。为了在大规模或低资源设置中提高设计效率，引入了Light Odin，一种轻量级变体，它保持了相同层次对齐的结构抽象，以便更快地训练和推理。

**Result:** 在多个文本丰富的图基准测试中，Odin取得了最先进的准确性，而Light Odin则以显著降低的计算成本提供了具有竞争力的表现。

**Conclusion:** Odin和Light Odin一起形成了一个统一的、无跳框架，用于结构和文本的原理融合。

**Abstract:** Text-attributed graphs require models to effectively combine strong textual understanding with structurally informed reasoning. Existing approaches either rely on GNNs--limited by over-smoothing and hop-dependent diffusion--or employ Transformers that overlook graph topology and treat nodes as isolated sequences. We propose Odin (Oriented Dual-module INtegration), a new architecture that injects graph structure into Transformers at selected depths through an oriented dual-module mechanism.Unlike message-passing GNNs, Odin does not rely on multi-hop diffusion; instead, multi-hop structures are integrated at specific Transformer layers, yielding low-, mid-, and high-level structural abstraction aligned with the model's semantic hierarchy. Because aggregation operates on the global [CLS] representation, Odin fundamentally avoids over-smoothing and decouples structural abstraction from neighborhood size or graph topology. We further establish that Odin's expressive power strictly contains that of both pure Transformers and GNNs.To make the design efficient in large-scale or low-resource settings, we introduce Light Odin, a lightweight variant that preserves the same layer-aligned structural abstraction for faster training and inference. Experiments on multiple text-rich graph benchmarks show that Odin achieves state-of-the-art accuracy, while Light Odin delivers competitive performance with significantly reduced computational cost. Together, Odin and Light Odin form a unified, hop-free framework for principled structure-text integration. The source code of this model has been released at https://github.com/hongkaifeng/Odin.

</details>


### [36] [A Systematic Study of Model Merging Techniques in Large Language Models](https://arxiv.org/abs/2511.21437)
*Oğuz Kağan Hitit,Leander Girrbach,Zeynep Akata*

Main category: cs.CL

> Evaluation of six merging methods on four LLMs shows Task Arithmetic as the most effective for improving model performance.

<details>
  <summary>Details</summary>

**Motivation:** To determine whether merging methods effective for smaller models and classifiers are also effective for LLMs.

**Method:** Model merging combines multiple fine-tuned checkpoints into a single model without additional training. The paper evaluates six merging methods on LLMs.

**Result:** Task Arithmetic is the only method yielding reliable performance gains on LLMs. Other methods often cause performance drops.

**Conclusion:** Current merging techniques do not directly transfer to modern LLMs, motivating the need for LLM-specific merging algorithms and merging-aware fine-tuning methods.

**Abstract:** Model merging combines multiple fine-tuned checkpoints into a single model without additional training, offering an attractive approach to reusing models and efficiently improving performance. However, it remains unclear whether the advantages reported for smaller models and classifiers generalize to LLMs. We present a large-scale, systematic evaluation of six state-of-the-art merging methods, including recent subspace methods, across four open-weight LLMs, twelve fine-tuned checkpoints per base model, and sixteen standard LLM benchmarks. Evaluating through standardized benchmarks, we measure both the probability that a merged model outperforms the base model and relative gains over the best individual checkpoint. Our results show that the oldest and simplest method, Task Arithmetic, is the only approach that reliably yields performance gains on LLMs. Other interference-aware and subspace merging methods typically result in significant performance drops. Our findings indicate that current merging techniques do not directly transfer to modern LLMs. This motivates the design of LLM-specific merging algorithms and merging-aware fine-tuning methods. Code will be released upon acceptance of this paper.

</details>


### [37] [Hierarchical Ranking Neural Network for Long Document Readability Assessment](https://arxiv.org/abs/2511.21473)
*Yurui Zheng,Yijun Chen,Shaohong Zhang*

Main category: cs.CL

> 文章提出了一种双向可读性评估机制，通过捕捉上下文信息来预测句子的可读性级别，并利用成对排序算法建立可读性级别的顺序关系，实验表明该模型在中英文数据集上表现良好，优于基线模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有的可读性评估方法未能充分考虑文本长度和可读性标签的顺序关系，该文章旨在解决这些问题。

**Method:** 提出了一种双向可读性评估机制，捕捉语义丰富的区域，预测句子级别的可读性，并引入成对排序算法建模可读性级别的顺序关系。

**Result:** 在中英文数据集上的实验结果显示，提出的模型具有竞争力，并优于其他基线模型。

**Conclusion:** 该模型通过捕捉文本的上下文信息和句子级别的预测来改进可读性评估，同时有效地建立了可读性级别的顺序关系。

**Abstract:** Readability assessment aims to evaluate the reading difficulty of a text. In recent years, while deep learning technology has been gradually applied to readability assessment, most approaches fail to consider either the length of the text or the ordinal relationship of readability labels. This paper proposes a bidirectional readability assessment mechanism that captures contextual information to identify regions with rich semantic information in the text, thereby predicting the readability level of individual sentences. These sentence-level labels are then used to assist in predicting the overall readability level of the document. Additionally, a pairwise sorting algorithm is introduced to model the ordinal relationship between readability levels through label subtraction. Experimental results on Chinese and English datasets demonstrate that the proposed model achieves competitive performance and outperforms other baseline models.

</details>


### [38] [Voice, Bias, and Coreference: An Interpretability Study of Gender in Speech Translation](https://arxiv.org/abs/2511.21517)
*Lina Conti,Dennis Fucci,Marco Gaido,Matteo Negri,Guillaume Wisniewski,Luisa Bentivogli*

Main category: cs.CL

> 研究探讨了语音翻译中的性别分配问题，揭示了基于声学信号和内部语言模型相互作用的未知机制，以提高性别准确性。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于理解语音翻译过程中性别分配的机制，避免由于默认为男性或基于声学特征的假设而导致的错误性别标注问题。

**Method:** 本文研究了语音翻译（ST）中的性别分配问题，特别是在从有显著性别的语言（如英语）翻译到将性别不明确术语分配给语法性别的语言（如西班牙语、法语和意大利语）时。研究分析了训练数据模式、内部语言模型（ILM）偏见和声学信息之间的相互作用，探讨ST模型如何将性别分配给指代说话者的词语。

**Result:** 研究发现，模型不仅复制训练数据中的术语特定性别关联，而且学习到了男性优势的更广泛模式。虽然ILM表现出强烈的男性偏好，但模型可以根据声学输入覆盖这些偏好。

**Conclusion:** 通过对比特征归因于频谱图的分析，研究揭示了提高性别准确性模型的一个未知机制：使用第一人称代词将性别术语与说话者关联起来，通过频率频谱分布的性别信息而非集中在音调上。

**Abstract:** Unlike text, speech conveys information about the speaker, such as gender, through acoustic cues like pitch. This gives rise to modality-specific bias concerns. For example, in speech translation (ST), when translating from languages with notional gender, such as English, into languages where gender-ambiguous terms referring to the speaker are assigned grammatical gender, the speaker's vocal characteristics may play a role in gender assignment. This risks misgendering speakers, whether through masculine defaults or vocal-based assumptions. Yet, how ST models make these decisions remains poorly understood. We investigate the mechanisms ST models use to assign gender to speaker-referring terms across three language pairs (en-es/fr/it), examining how training data patterns, internal language model (ILM) biases, and acoustic information interact. We find that models do not simply replicate term-specific gender associations from training data, but learn broader patterns of masculine prevalence. While the ILM exhibits strong masculine bias, models can override these preferences based on acoustic input. Using contrastive feature attribution on spectrograms, we reveal that the model with higher gender accuracy relies on a previously unknown mechanism: using first-person pronouns to link gendered terms back to the speaker, accessing gender information distributed across the frequency spectrum rather than concentrated in pitch.

</details>


### [39] [Bangla Sign Language Translation: Dataset Creation Challenges, Benchmarking and Prospects](https://arxiv.org/abs/2511.21533)
*Husne Ara Rubaiyeat,Hasan Mahmud,Md Kamrul Hasan*

Main category: cs.CL

> The paper presents a dataset named IsharaKhobor for Bangla Sign Language Translation, addressing the scarcity of resources, and introduces two subsets considering vocabulary restrictions and canonicalization.

<details>
  <summary>Details</summary>

**Motivation:** To provide a dataset for developing AI-based tools that assist deaf and hard-of-hearing individuals in the Bangla-speaking community, as the resource for this language is low.

**Method:** The dataset creation process and ablation studies on vocabulary and canonicalization are discussed.

**Result:** Two more datasets are generated after conducting ablation studies, IsharaKhobor_small and IsharaKhobor_canonical_small.

**Conclusion:** The paper highlights the importance of dataset development for BdSLT and provides a benchmark for future research in this area.

**Abstract:** Bangla Sign Language Translation (BdSLT) has been severely constrained so far as the language itself is very low resource. Standard sentence level dataset creation for BdSLT is of immense importance for developing AI based assistive tools for deaf and hard of hearing people of Bangla speaking community. In this paper, we present a dataset, IsharaKhobor , and two subset of it for enabling research. We also present the challenges towards developing the dataset and present some way forward by benchmarking with landmark based raw and RQE embedding. We do some ablation on vocabulary restriction and canonicalization of the same within the dataset, which resulted in two more datasets, IsharaKhobor_small and IsharaKhobor_canonical_small. The dataset is publicly available at: www.kaggle.com/datasets/hasanssl/isharakhobor [1].

</details>


### [40] [RoParQ: Paraphrase-Aware Alignment of Large Language Models Towards Robustness to Paraphrased Questions](https://arxiv.org/abs/2511.21568)
*Minjoon Choi*

Main category: cs.CL

> 本文提出RoParQ基准和XParaCon评估指标，旨在解决大规模语言模型(LLMs)对同义句一致性差的问题。通过细调策略，小模型能实现与大模型相当的一致性水平，这表明了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型在回答不同表达方式的问题时表现出不一致，显示模型依赖于表面模式而非语义理解。

**Method:** 通过生成同义句构建RoParQ基准，并使用XParaCon评估指标，以及实施细调策略使模型更倾向于语义不变性。

**Result:** 实验显示，针对性的模型调整极大地提高了模型的鲁棒性。细调后的轻量级模型可达到与大型预训练模型相似的一致性水平。

**Conclusion:** 该方法有效解决了模型的浅层记忆问题，增强了模型的可靠性。

**Abstract:** Large Language Models (LLMs) often exhibit inconsistent behavior when answering paraphrased questions, suggesting a reliance on surface-level patterns rather than true semantic understanding. To address this limitation, we introduce RoParQ, a benchmark specifically constructed to evaluate cross-paraphrase consistency in closed-book multiple-choice QA. This benchmark is derived from standard datasets by generating paraphrases via proprietary models and selectively retaining examples that elicit inconsistent confidence from a judge model. We further propose XParaCon, a novel evaluation metric that quantifies a model's robustness by measuring the standard deviation of accuracies across question variants. Additionally, we implement a reasoning-based, paraphrase-aware Supervised Fine-Tuning (SFT) strategy designed to align models toward semantic invariance. Our experiments demonstrate that this targeted alignment significantly enhances robustness. Notably, fine-tuned lightweight models achieved consistency levels comparable to much larger pre-trained models. These results highlight the efficacy of our approach in mitigating superficial memorization and fostering more robust, reliable LLMs.

</details>


### [41] [Auxiliary Metrics Help Decoding Skill Neurons in the Wild](https://arxiv.org/abs/2511.21610)
*Yixiu Zhao,Xiaozhi Wang,Zijun Yao,Lei Hou,Juanzi Li*

Main category: cs.CL

> 本研究提出了一种新方法来分析大型语言模型中编码特定技能的神经元，提高了模型的可解释性，并揭示了某些先前未知的模型学习行为。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在各种任务中表现出色，但其内部机制仍然不透明。我们的动机在于提高这些模型的可解释性，特别是在技能编码方面。

**Method:** 我们提出了一种简单、轻量且广泛应用的方法，重点在于分离出编码特定技能的神经元。该方法基于之前通过软提示训练在分类任务中识别“技能神经元”的工作，扩展了对涉及多种技能的复杂场景的分析。我们通过将神经元激活与外部标签和模型自身置信度等辅助指标进行关联，无需人工标记聚合就能揭示可解释和特定任务的行为。

**Result:** 实证研究表明，该方法在开放式文本生成和自然语言推理任务上表现良好，能够检测出驱动已知技能的神经元，并揭示在BigBench上的算术推理中之前未被识别的捷径。

**Conclusion:** 我们的方法为理解和解释大型语言模型内在技能的编码提供了新的视角，尤其是它揭示了此前未被发现的模型学习行为。

**Abstract:** Large language models (LLMs) exhibit remarkable capabilities across a wide range of tasks, yet their internal mechanisms remain largely opaque. In this paper, we introduce a simple, lightweight, and broadly applicable method with a focus on isolating neurons that encode specific skills. Building upon prior work that identified "skill neurons" via soft prompt training on classification tasks, our approach extends the analysis to complex scenarios involving multiple skills. We correlate neuron activations with auxiliary metrics -- such as external labels and the model's own confidence score -- thereby uncovering interpretable and task-specific behaviors without the need for manual token aggregation. We empirically validate our method on tasks spanning open-ended text generation and natural language inference, demonstrating its ability to detect neurons that not only drive known skills but also reveal previously unidentified shortcuts in arithmetic reasoning on BigBench.

</details>


### [42] [Beyond URLs: Metadata Diversity and Position for Efficient LLM Pretraining](https://arxiv.org/abs/2511.21613)
*Dongyang Fan,Diba Hashemi,Sai Praneeth Karimireddy,Martin Jaggi*

Main category: cs.CL

> 本文探究了多种元数据类型对LLMs预训练加速的效果，提出预测元数据作为辅助任务和使用细粒度质量指标来改进训练效率的方法。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于探索除了URL之外，其他类型的元数据是否能进一步提升大语言模型预训练的效率，并找到能更有效加速预训练过程的元数据类型。

**Method:** 本文研究了预训练大语言模型（LLMs）时使用元数据作为加速手段的方法。研究扩展了之前仅使用URL作为元数据的研究范围，探索了更大范围的元数据类型，包括文档质量的细粒度指标。此外，还提出在模型之后附加元数据，以及使用可训练的元数据令牌来进一步提升训练效率。

**Result:** 研究发现，细粒度的元数据能够更有效地加速预训练过程。预测合适的元数据作为辅助任务可以提高预训练的速度。使用探针分析隐层表示，进一步理解了元数据是如何影响模型学习的。

**Conclusion:** 通过本文的研究，为如何在预训练阶段更有效地整合元数据以提高LLMs的训练效率和效果提供了实用性的指导建议。

**Abstract:** Incorporating metadata in Large Language Models (LLMs) pretraining has recently emerged as a promising approach to accelerate training. However prior work highlighted only one useful signal-URLs, leaving open the question of whether other forms of metadata could yield greater benefits. In this study, we investigate a wider range of metadata types and find other types of metadata, such as fine-grained indicators of document quality that can also accelerate pretraining when prepended. We identify a common feature among effective metadata: they encode information at a finer granularity. We further introduce metadata appending as a means of improving training efficiency, where predicting an appropriate metadata as auxiliary task can help speed up pretraining. In addition, learnable meta-tokens trained with masked loss can recover part of the speedup by inducing quality-aware latent structure. Using probing, we analyze latent representations to understand how metadata shapes learning. Together, these results yield practical guidelines for integrating metadata to improve both the efficiency and effectiveness of LLM pretraining.

</details>


### [43] [The author is dead, but what if they never lived? A reception experiment on Czech AI- and human-authored poetry](https://arxiv.org/abs/2511.21629)
*Anna Marklová,Ondřej Vinš,Martina Vokáčová,Jiří Milička*

Main category: cs.CL

> 该研究探讨了捷克人工智能生成的诗歌在本地读者中的接受度和审美评价情况，发现读者对人工智能和人类创作的诗歌难以区分，并存在作者身份偏见，但人工智能可以有效生成形态复杂的低资源斯拉夫语言诗歌。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是探讨捷克人工智能生成诗歌对于捷克本地人的识别难度以及审美评价，尤其是比较人工智能和人类创作的诗歌。

**Method:** 参与者被要求猜测诗歌作者身份并进行美学评价，通过逻辑回归模型分析识别准确性和诗歌喜爱度之间的关系。

**Result:** 参与者平均正确率仅为45.8%，表明难以区分人工智能和人类创作的诗歌。审美评价发现存在作者身份偏见，但诗歌的喜爱度与准确分配作者身份成反比，且熟悉文学背景对于识别准确性没有影响。

**Conclusion:** 研究显示，人工智能可以生成形态复杂的低资源斯拉夫语言诗歌，并且读者对于人工智能诗歌的识别和审美评价之间相关。

**Abstract:** Large language models are increasingly capable of producing creative texts, yet most studies on AI-generated poetry focus on English -- a language that dominates training data. In this paper, we examine the perception of AI- and human-written Czech poetry. We ask if Czech native speakers are able to identify it and how they aesthetically judge it. Participants performed at chance level when guessing authorship (45.8\% correct on average), indicating that Czech AI-generated poems were largely indistinguishable from human-written ones. Aesthetic evaluations revealed a strong authorship bias: when participants believed a poem was AI-generated, they rated it as less favorably, even though AI poems were in fact rated equally or more favorably than human ones on average. The logistic regression model uncovered that the more the people liked a poem, the less probable was that they accurately assign the authorship. Familiarity with poetry or literary background had no effect on recognition accuracy. Our findings show that AI can convincingly produce poetry even in a morphologically complex, low-resource (with respect of the training data of AI models) Slavic language such as Czech. The results suggest that readers' beliefs about authorship and the aesthetic evaluation of the poem are interconnected.

</details>


### [44] [Matrix: Peer-to-Peer Multi-Agent Synthetic Data Generation Framework](https://arxiv.org/abs/2511.21686)
*Dong Wang,Yang Li,Ansong Ni,Ching-Feng Yeh,Youssef Emad,Xinjie Lei,Liam Robbins,Karthik Padthe,Hu Xu,Xian Li,Asli Celikyilmaz,Ramya Raghavendra,Lifei Huang,Carole-Jean Wu,Shang-Wen Li*

Main category: cs.CL

> 本文介绍了Matrix框架，一种用于多代理协同合成数据生成的去中心化框架，展示了其在各种生成任务中的高效表现。

<details>
  <summary>Details</summary>

**Motivation:** 现有的多代理合成框架经常依赖于一个中心指挥者，这会产生可扩展性的瓶颈，或者为特定领域设计，限制了灵活性。在数据稀缺、昂贵或涉及隐私的情况下，高质量、多样性和结构丰富的合成数据尤为重要。

**Method:** Matrix框架采用去中心化的设计，将控制流和数据流表示为通过分布式队列传输的序列化消息。这种基于点对点的设计消除了中心指挥者，任务由轻量级代理独立推进，而计算密集型操作则由分布式服务处理。Matrix框架基于Ray构建，能够扩展到数万并发的代理工作流，并且提供了一个模块化、可配置的设计，可以轻松适应各种数据生成工作流。

**Result:** 实验结果显示，Matrix框架在多代理协作对话、基于Web的推理数据抽取以及客户服务环境中的工具使用轨迹生成等各种合成场景下，实现了在相同硬件资源下2--15倍的数据生成吞吐量的提升，并且不牺牲输出质量。

**Conclusion:** Matrix提供了灵活、高效的多代理合成数据生成解决方案，适用于各种复杂的工作流程，具有显著的数据生成吞吐量优势。

**Abstract:** Synthetic data has become increasingly important for training large language models, especially when real data is scarce, expensive, or privacy-sensitive. Many such generation tasks require coordinated multi-agent workflows, where specialized agents collaborate to produce data that is higher quality, more diverse, and structurally richer. However, existing frameworks for multi-agent synthesis often depend on a centralized orchestrator, creating scalability bottlenecks, or are hardcoded for specific domains, limiting flexibility. We present \textbf{Matrix}, a decentralized framework that represents both control and data flow as serialized messages passed through distributed queues. This peer-to-peer design eliminates the central orchestrator. Each task progresses independently through lightweight agents, while compute-intensive operations, such as LLM inference or containerized environments, are handled by distributed services. Built on Ray, Matrix scales to tens of thousands of concurrent agentic workflows and provides a modular, configurable design that enables easy adaptation to a wide range of data generation workflows. We evaluate Matrix across diverse synthesis scenarios, such as multi-agent collaborative dialogue, web-based reasoning data extraction, and tool-use trajectory generation in customer service environments. In all cases, Matrix achieves $2$--$15\times$ higher data generation throughput under identical hardware resources, without compromising output quality.

</details>


### [45] [ToolOrchestra: Elevating Intelligence via Efficient Model and Tool Orchestration](https://arxiv.org/abs/2511.21689)
*Hongjin Su,Shizhe Diao,Ximing Lu,Mingjie Liu,Jiacheng Xu,Xin Dong,Yonggan Fu,Peter Belcak,Hanrong Ye,Hongxu Yin,Yi Dong,Evelina Bakhturina,Tao Yu,Yejin Choi,Jan Kautz,Pavlo Molchanov*

Main category: cs.CL

> The paper introduces ToolOrchestra, a training method for orchestrators that use reinforcement learning to coordinate intelligent tools, achieving higher accuracy at a lower cost than previous agents.

<details>
  <summary>Details</summary>

**Motivation:** To push the upper bound of intelligence and improve efficiency in solving complex problems with the use of small orchestrators managing other models and a variety of tools.

**Method:** ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools using reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards.

**Result:** Orchestrator, an 8B model trained with ToolOrchestra, surpasses GPT-5 in efficiency and cost-effectiveness on various benchmarks.

**Conclusion:** Composing diverse tools with a lightweight orchestration model is more efficient and effective than existing methods, making way for practical and scalable tool-augmented reasoning systems.

**Abstract:** Large language models are powerful generalists, yet solving deep and complex problems such as those of the Humanity's Last Exam (HLE) remains both conceptually challenging and computationally expensive. We show that small orchestrators managing other models and a variety of tools can both push the upper bound of intelligence and improve efficiency in solving difficult agentic tasks. We introduce ToolOrchestra, a method for training small orchestrators that coordinate intelligent tools. ToolOrchestra explicitly uses reinforcement learning with outcome-, efficiency-, and user-preference-aware rewards. Using ToolOrchestra, we produce Orchestrator, an 8B model that achieves higher accuracy at lower cost than previous tool-use agents while aligning with user preferences on which tools are to be used for a given query. On HLE, Orchestrator achieves a score of 37.1%, outperforming GPT-5 (35.1%) while being 2.5x more efficient. On tau2-Bench and FRAMES, Orchestrator surpasses GPT-5 by a wide margin while using only about 30% of the cost. Extensive analysis shows that Orchestrator achieves the best trade-off between performance and cost under multiple metrics, and generalizes robustly to unseen tools. These results demonstrate that composing diverse tools with a lightweight orchestration model is both more efficient and more effective than existing methods, paving the way for practical and scalable tool-augmented reasoning systems.

</details>


### [46] [Revisiting Generalization Across Difficulty Levels: It's Not So Easy](https://arxiv.org/abs/2511.21692)
*Yeganeh Kordi,Nihal V. Nayak,Max Zuo,Ilana Nguyen,Stephen H. Bach*

Main category: cs.CL

> 对大型语言模型（LLMs）在不同任务难度上的泛化能力进行了系统评估，发现其泛化能力往往有限，并强调了在数据的训练和评估中包含各种难度级别的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 研究训练数据集的难易程度对大型语言模型（LLMs）泛化能力的影响，目的是为了有效的数据整理和评估。现有研究对于训练在较容易或较难的数据上是否能获得更好的结果持有不同的观点，且这些效果可能来自较容易或较难的测试数据。

**Method:** 通过对六个数据集进行系统的评估，使用各种大型语言模型（LLMs）的输出以及项目反应理论（IRT）来排名难度，以探究LLMs在不同任务难度上的泛化能力。此方法与以往工作不同，其难度评分仅根据许多不同LLMs的能力确定，不包含人类对难度的意见。

**Result:** 研究通过更客观、更大规模和更细腻的分析表明，跨难度的泛化通常是有限的：在容易或困难的数据上训练，不能在全部难度级别上取得持续改进。

**Conclusion:** 研究表明跨难度的泛化能力往往有限，无论是在容易或难的数据上进行训练，不能在全部难度范围内取得一致的改进。这些结果表明，对于LLMs来说，在训练和评估数据中都应该包含各种不同的难度级别，忽视难度考虑的做法是有风险的。

**Abstract:** We investigate how well large language models (LLMs) generalize across different task difficulties, a key question for effective data curation and evaluation. Existing research is mixed regarding whether training on easier or harder data leads to better results, and whether those gains come on easier or harder test data. We address this question by conducting a systematic evaluation of LLMs' generalization across models, datasets, and fine-grained groups of example difficulty. We rank examples in six datasets using the outputs of thousands of different LLMs and Item Response Theory (IRT), a well-established difficulty metric in educational testing. Unlike prior work, our difficulty ratings are therefore determined solely by the abilities of many different LLMs, excluding human opinions of difficulty. With a more objective, larger-scale, and finer-grained analysis, we show that cross-difficulty generalization is often limited; training on either easy or hard data cannot achieve consistent improvements across the full range of difficulties. These results show the importance of having a range of difficulties in both training and evaluation data for LLMs, and that taking shortcuts with respect to difficulty is risky.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [47] [Are Neuro-Inspired Multi-Modal Vision-Language Models Resilient to Membership Inference Privacy Leakage?](https://arxiv.org/abs/2511.20710)
*David Amebley,Sayanton Dibbo*

Main category: cs.CV

> 本研究提出了基于系统神经科学的分析框架，分析了多模态视觉语言模型在隐私攻击中的抗性。实验表明，应用神经VLMs能有效降低MIA攻击成功率，并保持模型效用。

<details>
  <summary>Details</summary>

**Motivation:** 近年来，多模态模型 (MMs) 的部署引发了隐私泄露的新攻击途径。尽管已有研究表明生物灵感神经网络表现能在对抗攻击中提升无模态模型的韧性，但其对隐私攻击的抵御能力尚未被探索。本研究旨在填补这一空白。

**Method:** 本研究引入了一个基于系统神经科学的拓扑正则化（tau）框架，用以分析多模态视觉语言模型（VLMs）对基于图文推理隐私攻击的韧性。研究评估了三种模型：BLIP, PaliGemma 2, ViT-GPT2，在三个基准数据集：COCO, CC3M, 和 NoCaps 上的抵御攻击能力。实验将基线模型与带拓扑正则化的神经模型 (tau>0 定义为NEURO变体) 进行了比较。

**Result:** 研究结果表明，使用COCO数据集上的BLIP模型，MIA攻击在NEURO VLMs上的成功率下降了24%的平均ROC-AUC值，同时在模型效用 (生成和参考描述之间的相似性) 方面，基于MPNet和ROUGE-2度量，表现与基线模型相似。进一步的研究在PaliGemma 2和ViT-GPT2模型以及CC3M和NoCaps数据集上的结果进一步验证了这些发现。

**Conclusion:** 本研究表明，神经VLMs比基线模型在隐私攻击中更具有抵抗力，并且不会显著影响模型的效用。这一工作增加了对多模态模型隐私风险的理解，并提供了神经VLMs隐私威胁抵抗力的证据。

**Abstract:** In the age of agentic AI, the growing deployment of multi-modal models (MMs) has introduced new attack vectors that can leak sensitive training data in MMs, causing privacy leakage. This paper investigates a black-box privacy attack, i.e., membership inference attack (MIA) on multi-modal vision-language models (VLMs). State-of-the-art research analyzes privacy attacks primarily to unimodal AI-ML systems, while recent studies indicate MMs can also be vulnerable to privacy attacks. While researchers have demonstrated that biologically inspired neural network representations can improve unimodal model resilience against adversarial attacks, it remains unexplored whether neuro-inspired MMs are resilient against privacy attacks. In this work, we introduce a systematic neuroscience-inspired topological regularization (tau) framework to analyze MM VLMs resilience against image-text-based inference privacy attacks. We examine this phenomenon using three VLMs: BLIP, PaliGemma 2, and ViT-GPT2, across three benchmark datasets: COCO, CC3M, and NoCaps. Our experiments compare the resilience of baseline and neuro VLMs (with topological regularization), where the tau > 0 configuration defines the NEURO variant of VLM. Our results on the BLIP model using the COCO dataset illustrate that MIA attack success in NEURO VLMs drops by 24% mean ROC-AUC, while achieving similar model utility (similarities between generated and reference captions) in terms of MPNet and ROUGE-2 metrics. This shows neuro VLMs are comparatively more resilient against privacy attacks, while not significantly compromising model utility. Our extensive evaluation with PaliGemma 2 and ViT-GPT2 models, on two additional datasets: CC3M and NoCaps, further validates the consistency of the findings. This work contributes to the growing understanding of privacy risks in MMs and provides evidence on neuro VLMs privacy threat resilience.

</details>


### [48] [Inferix: A Block-Diffusion based Next-Generation Inference Engine for World Simulation](https://arxiv.org/abs/2511.20714)
*Inferix Team,Tianyu Feng,Yizeng Han,Jiahao He,Yuanyu He,Xi Lin,Teng Liu,Hanfeng Lu,Jiasheng Tang,Wei Wang,Zhiyuan Wang,Jichao Wu,Mingyang Yang,Yinghao Yu,Zeyu Zhang,Bohan Zhuang*

Main category: cs.CV

> Inferix 是一款专为沉浸式世界模拟设计的下一代推理引擎，采用了优化的半自回归解码过程。

<details>
  <summary>Details</summary>

**Motivation:** 目标在于利用半自回归（块扩散）解码范式克服传统视频扩散模型的限制，并为视觉感知、理解和推理等领域带来新的突破。

**Method:** Inferix 使用半自回归（块扩散）解码范式来生成视频，通过引入类似语言模型的KV缓存管理来提高生成效率，并支持交互式视频流和评测。

**Result:** 通过整合LV-Bench进行高效的基准测试，支持长时间视频生成场景的精细评测。

**Conclusion:** 这项研究推进了世界模型技术的发展，希望能够促进社区合作以进一步完善Inferix。

**Abstract:** World models serve as core simulators for fields such as agentic AI, embodied AI, and gaming, capable of generating long, physically realistic, and interactive high-quality videos. Moreover, scaling these models could unlock emergent capabilities in visual perception, understanding, and reasoning, paving the way for a new paradigm that moves beyond current LLM-centric vision foundation models. A key breakthrough empowering them is the semi-autoregressive (block-diffusion) decoding paradigm, which merges the strengths of diffusion and autoregressive methods by generating video tokens in block-applying diffusion within each block while conditioning on previous ones, resulting in more coherent and stable video sequences. Crucially, it overcomes limitations of standard video diffusion by reintroducing LLM-style KV Cache management, enabling efficient, variable-length, and high-quality generation.
  Therefore, Inferix is specifically designed as a next-generation inference engine to enable immersive world synthesis through optimized semi-autoregressive decoding processes. This dedicated focus on world simulation distinctly sets it apart from systems engineered for high-concurrency scenarios (like vLLM or SGLang) and from classic video diffusion models (such as xDiTs). Inferix further enhances its offering with interactive video streaming and profiling, enabling real-time interaction and realistic simulation to accurately model world dynamics. Additionally, it supports efficient benchmarking through seamless integration of LV-Bench, a new fine-grained evaluation benchmark tailored for minute-long video generation scenarios. We hope the community will work together to advance Inferix and foster world model exploration.

</details>


### [49] [Video Object Recognition in Mobile Edge Networks: Local Tracking or Edge Detection?](https://arxiv.org/abs/2511.20716)
*Kun Guo,Yun Shen,Xijun Wang,Chaoqun You,Yun Rui,Tony Q. S. Quek*

Main category: cs.CV

> 本文提出了一种自适应选择本地跟踪或边缘检测的新方法，解决了资源受限设备在视频对象识别中的性能挑战。

<details>
  <summary>Details</summary>

**Motivation:** 解决视频对象识别计算量大，资源受限设备难以高效处理的问题，特别是在混合计算环境中何时使用边缘检测何时使用本地跟踪的决策问题。

**Method:** 提出了一种基于深度强化学习的算法LTED-Ada，用于单设备情景下根据帧率、识别准确性和延迟要求自适应地选择本地跟踪还是边缘检测。对于多设备情景，使用联邦学习增强LTED-Ada，以实现跨设备的协作策略训练，从而提高对未见过的帧率和性能要求的泛化能力。

**Result:** 通过硬件在环实验，使用多个Raspberry Pi 4B设备和个人电脑作为边缘服务器，验证了LTED-Ada算法的优越性。

**Conclusion:** 引入LTED-Ada算法，并使用联邦学习技术，在多设备情景下增强了其性能，表明该方法能有效适应于实时帧率和性能要求。

**Abstract:** Fast and accurate video object recognition, which relies on frame-by-frame video analytics, remains a challenge for resource-constrained devices such as traffic cameras. Recent advances in mobile edge computing have made it possible to offload computation-intensive object detection to edge servers equipped with high-accuracy neural networks, while lightweight and fast object tracking algorithms run locally on devices. This hybrid approach offers a promising solution but introduces a new challenge: deciding when to perform edge detection versus local tracking. To address this, we formulate two long-term optimization problems for both single-device and multi-device scenarios, taking into account the temporal correlation of consecutive frames and the dynamic conditions of mobile edge networks. Based on the formulation, we propose the LTED-Ada in single-device setting, a deep reinforcement learning-based algorithm that adaptively selects between local tracking and edge detection, according to the frame rate as well as recognition accuracy and delay requirement. In multi-device setting, we further enhance LTED-Ada using federated learning to enable collaborative policy training across devices, thereby improving its generalization to unseen frame rates and performance requirements. Finally, we conduct extensive hardware-in-the-loop experiments using multiple Raspberry Pi 4B devices and a personal computer as the edge server, demonstrating the superiority of LTED-Ada.

</details>


### [50] [DeeAD: Dynamic Early Exit of Vision-Language Action for Efficient Autonomous Driving](https://arxiv.org/abs/2511.20720)
*Haibo HU,Lianming Huang,Nan Guan,Chun Jason Xue*

Main category: cs.CV

> 研究介绍了一种用于加速视觉语言动作模型规划过程的无训练、行动引导的提前退出框架DeeAD，测试表明能够大幅降低延迟。

<details>
  <summary>Details</summary>

**Motivation:** 解决VLA模型由于深变压器堆栈导致的推理延迟问题，同时保持规划质量和安全性。

**Method:** 提出了一种行动引导的提前退出框架DeeAD，根据轨迹与轻量级规划先验的对齐程度以及自适应跳过冗余层来降低延迟。

**Result:** 该论文介绍了一种名为DeeAD的无训练、行动引导的提前退出框架，用于加速视觉语言动作模型（VLA模型）的规划过程。通过评估中间轨迹的物理可行性，DeeAD可以在预测的轨迹与轻量级规划先验（如导航或低精度规划）的偏差小于2m时提前终止推理，而无需依赖置信度得分。此外，引入的多跳控制器可以根据分数变化率自适应地跳过冗余层，进一步提高效率。实验结果表明，DeeAD能够将变压器层的稀疏度提高至28%，并将延迟减少29%，同时保持规划质量和安全性。

**Conclusion:** DeeAD在Bench2Drive基准上的实验表明，可以有效减少VLA模型的推理延迟，同时保持规划质量和安全性。

**Abstract:** Vision-Language Action (VLA) models unify perception, reasoning, and trajectory generation for autonomous driving, but suffer from significant inference latency due to deep transformer stacks. We present DeeAD, a training-free, action-guided early-exit framework that accelerates VLA planning by evaluating the physical feasibility of intermediate trajectories. Instead of relying on confidence scores, DeeAD terminates inference when predicted trajectories align with lightweight planning priors (e.g., Navigation or Low-precision Planning) within a tolerable deviation (<2m). To improve efficiency, we introduce a multi-hop controller that adaptively skips redundant layers based on the change rate of scores. DeeAD integrates into existing VLA models, such as ORION, without requiring retraining. Experiments on the Bench2Drive benchmark demonstrate up to 28% transformer-layer sparsity and 29% latency reduction, while preserving planning quality and safety.

</details>


### [51] [Foundry: Distilling 3D Foundation Models for the Edge](https://arxiv.org/abs/2511.20721)
*Guillaume Letellier,Siddharth Srivastava,Frédéric Jurie,Gaurav Sharma*

Main category: cs.CV

> 提出了Foundation Model Distillation (FMD)，一种新的压缩大型自监督模型的方法，保持模型的通用特征表示能力。实现了针对3D点云的Foundry，训练得到的学生模型使用更少的tokens和计算资源同时保持迁移学习性能接近大型模型。

<details>
  <summary>Details</summary>

**Motivation:** 大型基础模型因规模巨大和计算成本高难以在边缘设备上部署。现有压缩技术虽然能生成高效模型，但牺牲了模型的通用特性。

**Method:** 提出了一种称为Foundation Model Distillation (FMD)的新范式，将大型自监督学习模型压缩为紧凑高效的模型版本，同时保留其通用特征表达能力。特别是在3D点云处理上的实现被称为Foundry，目的是训练出的学生模型能够学习到教师模型的tokens表示的压缩集，通过更少的tokens和计算资源重新构建教师模型的token级表示。

**Result:** 提出的单个蒸馏模型在使用显著较少的tokens和FLOPs的情况下保持了在不同的下游任务中的强大转移能力，包括分类，部分分割和少量镜头场景。

**Conclusion:** Foundation Model Distillation (FMD)实现了一个高效且忠实的基础模型压缩方法，可以实现在资源受限的硬件上部署具有强大迁移性能的模型。特别是通过3D点云的实验验证了这一方法的有效性。

**Abstract:** Foundation models pre-trained with self-supervised learning (SSL) on large-scale datasets have become powerful general-purpose feature extractors. However, their immense size and computational cost make them prohibitive for deployment on edge devices such as robots and AR/VR headsets. Existing compression techniques like standard knowledge distillation create efficient 'specialist' models but sacrifice the crucial, downstream-agnostic generality that makes foundation models so valuable.  In this paper, we introduce Foundation Model Distillation (FMD), a new paradigm for compressing large SSL models into compact, efficient, and faithful proxies that retain their general-purpose representational power. We present Foundry, the first implementation of FMD for 3D point clouds. Our approach, Foundry, trains a student to learn a compressed set of SuperTokens that reconstruct the teacher's token-level representations, capturing a compact basis of its latent space. A single distilled model maintains strong transferability across diverse downstream tasks-classification, part segmentation, and few-shot scenarios-approaching full foundation-model performance while using significantly fewer tokens and FLOPs, making such models more practical for deployment on resourceconstrained hardware.

</details>


### [52] [DinoLizer: Learning from the Best for Generative Inpainting Localization](https://arxiv.org/abs/2511.20722)
*Minh Thong Doi,Jan Butora,Vincent Itier,Jérémie Boulanger,Patrick Bas*

Main category: cs.CV

> The paper introduces DinoLizer, which enhances a DINOv2 model to detect detailed manipulations in generative inpainting images, achieving significant improvements in localization accuracy over state-of-the-art methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this work is the need for a robust and effective method for detecting manipulated regions in images, which can be particularly difficult after common post-processing operations such as resizing or adding noise. The aim is to improve the accuracy of local manipulation detection over existing methods.

**Method:** We introduce DinoLizer, a DINOv2-based model for identifying manipulated regions in images resulting from generative inpainting. This model adds a linear classification head to a pre-trained DINOv2 model, designed to predict manipulations on a $14\times 14$ grid of image patches. For larger images, a sliding-window approach is employed to create heatmaps which are then post-processed to accurately define manipulation masks. The ViT (Vision Transformer) is utilized due to its strong representational power, as evidenced by off-the-shelf DINOv2 comparison studies.

**Result:** Empirical results indicate that the DinoLizer model outperforms other local manipulation detectors across various inpainting datasets. The model shows robustness to post-processing operations like resizing, noise addition, and JPEG compression, with a 12\% higher Intersection-over-Union score on average compared to the next best model.

**Conclusion:** The DinoLizer model demonstrates superior performance in local manipulation detection on images created by different generative models. The experiments confirm the strong representational power of Vision Transformers for this task and show that DinoLizer can maintain its high detection accuracy even after common post-processing operations.

**Abstract:** We introduce DinoLizer, a DINOv2-based model for localizing manipulated regions in generative inpainting. Our method builds on a DINOv2 model pretrained to detect synthetic images on the B-Free dataset. We add a linear classification head on top of the Vision Transformer's patch embeddings to predict manipulations at a $14\times 14$ patch resolution. The head is trained to focus on semantically altered regions, treating non-semantic edits as part of the original content. Because the ViT accepts only fixed-size inputs, we use a sliding-window strategy to aggregate predictions over larger images; the resulting heatmaps are post-processed to refine the estimated binary manipulation masks. Empirical results show that DinoLizer surpasses state-of-the-art local manipulation detectors on a range of inpainting datasets derived from different generative models. It remains robust to common post-processing operations such as resizing, noise addition, and JPEG (double) compression. On average, DinoLizer achieves a 12\% higher Intersection-over-Union (IoU) than the next best model, with even greater gains after post-processing. Our experiments with off-the-shelf DINOv2 demonstrate the strong representational power of Vision Transformers for this task. Finally, extensive ablation studies comparing DINOv2 and its successor, DINOv3, in deepfake localization confirm DinoLizer's superiority. The code will be publicly available upon acceptance of the paper.

</details>


### [53] [CANVAS: A Benchmark for Vision-Language Models on Tool-Based User Interface Design](https://arxiv.org/abs/2511.20737)
*Daeheon Jeong,Seoyeon Byun,Kihoon Son,Dae Hyun Kim,Juho Kim*

Main category: cs.CV

> 本文介绍CANVAS基准测试，用以评估视觉语言模型在基于工具的UI设计中的功能，识别错误模式，并为未来改进提供指导。

<details>
  <summary>Details</summary>

**Motivation:** 由于没有现有的基准来评估基于工具的设计性能，这项研究旨在填补这一空白，展示VLMs与设计师在常规软件中协作的潜力。

**Method:** 介绍了一个名为CANVAS的基准测试，用于评估和改进基于工具的用户界面设计中视觉语言模型(VLMs)的能力。此基准包含了598个设计任务，与3.3K个移动用户界面设计中的30个功能类别相关。任务分为设计复制和设计修改两种类型。

**Result:** 结果表明，领先的模型在设计时表现出更策略性的工具调用，提高了设计质量，并且研究还识别出模型普遍存在的错误模式，为未来工作提供了指导。

**Conclusion:** 这项研究奠定了未来提高VLMs在基于工具的设计方面能力的基础，为评估这些模型提供了必要的基准。

**Abstract:** User interface (UI) design is an iterative process in which designers progressively refine their work with design software such as Figma or Sketch. Recent advances in vision language models (VLMs) with tool invocation suggest these models can operate design software to edit a UI design through iteration. Understanding and enhancing this capacity is important, as it highlights VLMs' potential to collaborate with designers within conventional software. However, as no existing benchmark evaluates tool-based design performance, the capacity remains unknown. To address this, we introduce CANVAS, a benchmark for VLMs on tool-based user interface design. Our benchmark contains 598 tool-based design tasks paired with ground-truth references sampled from 3.3K mobile UI designs across 30 function-based categories (e.g., onboarding, messaging). In each task, a VLM updates the design step-by-step through context-based tool invocations (e.g., create a rectangle as a button background), linked to design software. Specifically, CANVAS incorporates two task types: (i) design replication evaluates the ability to reproduce a whole UI screen; (ii) design modification evaluates the ability to modify a specific part of an existing screen. Results suggest that leading models exhibit more strategic tool invocations, improving design quality. Furthermore, we identify common error patterns models exhibit, guiding future work in enhancing tool-based design capabilities.

</details>


### [54] [Text-Guided Semantic Image Encoder](https://arxiv.org/abs/2511.20770)
*Raghuveer Thirukovalluru,Xiaochuang Han,Bhuwan Dhingra,Emily Dinan,Maha Elbayad*

Main category: cs.CV

> 提出TIE方法，改善了视觉语言模型中的图像编码器处理特定任务的能力，提升了模型性能和推理效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统的视觉语言模型中的图像编码器在与语言模型对齐之前独立预训练，这使得图像编码器不能针对特定的下游任务或文本查询进行处理。提出TIE以解决这一限制。

**Method:** 通过文本引导的语义图像编码器（TIE）生成受输入文本查询条件限制的图像表示方法，以改进视觉语言模型中的图像编码器。

**Result:** 装备了TIE的视觉语言模型在九个图像到文本的基准测试上平均分别提高了1.5和1.3分（在10亿和30亿参数规模下），并且在如DocVQA和InfoVQA任务上的增益高达6分。此外，TIE基的视觉语言模型仅使用一半的图像瓦片就能达到更优性能，提高了推理效率。

**Conclusion:** TIE能够有效地优化编码器以捕获关键视觉特征，并且可以很好地推广到通用查询。定性分析表明，TIE可一直关注到查询相关的区域，这增强了模型的可解释性和查询特定的定位。

**Abstract:** Image encoders, a fundamental component of vision-language models (VLMs), are typically pretrained independently before being aligned with a language model. This standard paradigm results in encoders that process images agnostically, without regard to the specific downstream task or text query. To address this limitation, we propose the Text-Guided Semantic Image Encoder (TIE), which generates image representations conditioned on the input text query. VLMs equipped with TIE outperform their conventional counterparts by +1.5 and +1.3 points on average across nine image-to-text benchmarks at the 1B and 3B scales, respectively, with gains reaching up to 6 points on tasks such as DocVQA and InfoVQA. Moreover, TIE-based VLMs attain superior performance while utilizing only half as many image tiles (tokens), resulting in notably improved inference efficiency. TIE also generalizes well with generic queries, indicating that text-conditioned training effectively optimizes the encoder to capture key visual features. Qualitative analysis confirms that TIE consistently attends to query-relevant regions, enhancing both interpretability and query-specific grounding.

</details>


### [55] [One Patch is All You Need: Joint Surface Material Reconstruction and Classification from Minimal Visual Cues](https://arxiv.org/abs/2511.20784)
*Sindhuja Penchala,Gavin Money,Gabriel Marques,Samuel Wood,Jessica Kirschman,Travis Atkison,Shahram Rahimi,Noorbakhsh Amiri Golilarz*

Main category: cs.CV

> SMARC is a model designed to infer the full RGB surface and material category from a 10% image patch, achieving state-of-the-art performance in both surface reconstruction and material classification using sparse visual cues.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this research is to enable more effective surface material understanding in robotics, simulation, and material perception, particularly in scenarios with limited or partially observed scenes. Most current methods require dense or full observations, which is often not feasible.

**Method:** The paper introduces SMARC, which uses a Partial Convolutional U-Net combined with a classification head to process a single 10% image patch for surface material reconstruction and classification. This approach is designed to handle sparse visual cues effectively.

**Result:** Compared to five other models such as convolutional autoencoders, Vision Transformer, Masked Autoencoder, Swin Transformer, and DETR, SMARC demonstrated superior performance on the Touch and Go dataset with a PSNR of 17.55 dB and material classification accuracy of 85.10%.

**Conclusion:** The research concludes that partial convolution is advantageous for spatial reasoning in the presence of missing data, and that SMARC sets a strong foundation for understanding material surfaces with minimal visual input.

**Abstract:** Understanding material surfaces from sparse visual cues is critical for applications in robotics, simulation, and material perception. However, most existing methods rely on dense or full-scene observations, limiting their effectiveness in constrained or partial view environment. To address this challenge, we introduce SMARC, a unified model for Surface MAterial Reconstruction and Classification from minimal visual input. By giving only a single 10% contiguous patch of the image, SMARC recognizes and reconstructs the full RGB surface while simultaneously classifying the material category. Our architecture combines a Partial Convolutional U-Net with a classification head, enabling both spatial inpainting and semantic understanding under extreme observation sparsity. We compared SMARC against five models including convolutional autoencoders [17], Vision Transformer (ViT) [13], Masked Autoencoder (MAE) [5], Swin Transformer [9], and DETR [2] using Touch and Go dataset [16] of real-world surface textures. SMARC achieves state-of-the-art results with a PSNR of 17.55 dB and a material classification accuracy of 85.10%. Our findings highlight the advantages of partial convolution in spatial reasoning under missing data and establish a strong foundation for minimal-vision surface understanding.

</details>


### [56] [LongVT: Incentivizing "Thinking with Long Videos" via Native Tool Calling](https://arxiv.org/abs/2511.20785)
*Zuhao Yang,Sudong Wang,Kaichen Zhang,Keming Wu,Sicong Leng,Yifan Zhang,Chengwei Qin,Shijian Lu,Xingxuan Li,Lidong Bing*

Main category: cs.CV

> 提出一种名为LongVT的端到端的代理框架，通过多模态工具链思想的交替来实现长视频的理解与推理，解决了大模态视频处理模型在处理长视频时容易出现幻觉的问题。

<details>
  <summary>Details</summary>

**Motivation:** 大模态视频处理模型存在幻觉现象，并且这一现象在证据稀疏且时间分布广泛的长视频中更易出现，因此提出LongVT框架，提高长视频理解与推理的能力。

**Method:** 通过模仿人类观看长视频的过程方法，即先全局浏览再详细查看相关片段来理解和推理视频内容，提出了LongVT这种方法框架。LongVT框架能够通过多模态工具链思想的交替来实现长视频的“思考”能力。此外，使用LMMs内在的时间锚定能力作为视频剪辑工具，实现对特定视频片段的放大并重采样更细粒度的视频帧。这种全局到局部的推理循环会持续进行，直到答案能在检索到的视觉证据中得到锚定。同时，为了应对长视频问答数据的匮乏，创建了一个名为VideoSIAH的数据集，帮助训练和评估。

**Result:** 通过精心设计的三阶段训练策略以及广泛的实证验证，LongVT系统在四个困难的长视频理解和推理基准测试中，持续优于现有的强基线方法。

**Conclusion:** LongVT通过模仿人类观看视频的过程，显著提高了长视频推理的准确性，并证明了这种方法的有效性。

**Abstract:** Large multimodal models (LMMs) have shown great potential for video reasoning with textual Chain-of-Thought. However, they remain vulnerable to hallucinations, especially when processing long-form videos where evidence is sparse and temporally dispersed. Inspired by how humans comprehend long videos - by first skimming globally and then examining relevant clips for details - we introduce LongVT, an end-to-end agentic framework that enables "Thinking with Long Videos" via interleaved Multimodal Chain-of-Tool-Thought. Specifically, we exploit LMMs' inherent temporal grounding ability as a native video cropping tool to zoom in on a specific video clip and resample finer-grained video frames. This global-to-local reasoning loop continues until answers are grounded in retrieved visual evidence. Given the scarcity of fine-grained question-answering (QA) data for the long video reasoning task, we curate and will release a data suite named VideoSIAH to facilitate both training and evaluation. Specifically, our training dataset consists of 247.9K samples for tool-integrated cold-start supervised fine-tuning, 1.6K samples for agentic reinforcement learning, and 15.4K samples for agentic reinforcement fine-tuning, respectively. Our evaluation benchmark consists of 1,280 QA pairs that are carefully curated through a semi-automatic data pipeline with human-in-the-loop validation. With a meticulously designed three-stage training strategy and extensive empirical validation, LongVT consistently outperforms existing strong baselines across four challenging long-video understanding and reasoning benchmarks. Our codes, data, and model checkpoints are publicly available at https://github.com/EvolvingLMMs-Lab/LongVT .

</details>


### [57] [Revisiting KRISP: A Lightweight Reproduction and Analysis of Knowledge-Enhanced Vision-Language Models](https://arxiv.org/abs/2511.20795)
*Souradeep Dutta,Keshav Bulia,Neena S Nair*

Main category: cs.CV

> 本文提出了一种轻量化版本的KRISP模型，揭示了原始模型的设计缺陷和问题，并展示了在资源受限环境下知识增强视觉语言推理架构的潜力和局限性。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于克服原始KRISP模型在工业规模训练中计算要求高及与大型骨干网络紧密结合的问题。

**Method:** 通过对KRISP模型的重新审视，本文提供了一个参数量显著减少的轻量化版本。该模型虽然在性能上大约只有原始模型的75%，但在复制过程中揭示了设计缺陷、现实世界中的问题和未在原始论文中充分讨论的隐含问题。

**Result:** 通过系统消融研究，包括合成VQA数据的验证和在DAQUAR数据集上的评价，提供了关于资源受限情况下知识增强VQA架构的可扩展性和有效性见解。

**Conclusion:** 低参数设定和受外部知识图谱领域限制的模型配置避免了AI生成幻觉，仅在该领域内生成输出，最小化参数使得该模型能够在智能手机和AR-VR等边缘设备上运行，进一步增强了离线视觉推理能力。

**Abstract:** Facebook AI Research introduced KRISP [4], which integrates structured external knowledge into pipelines for vision-language reasoning. Despite its effectiveness, the original model has been developed for industrial-scale training, is computationally demanding, and is tightly connected to a large backbone. In this work, we reexamine KRISP from a different angle and offer a lightweight reproduction with significantly fewer parameters. Even though our replicated model performs about 75 % of the original, the replication process uncovers a number of design flaws, real-world pitfalls, and implicit problems that were not fully covered in the original paper. We offer insights into the scalability and efficacy of knowledge-enhanced VQA architectures under resource constraints through systematic ablation studies, which include a proof-of-concept on synthetic VQA data and evaluation on the DAQUAR dataset. Our model, configured with a low parameter setup and constrained by the external Knowledge graph domain, prevents AI hallucinations and generates outputs solely within that domain. Minimal parameters allow us to function on edge devices like smartphones and AR-VR, further improving offline visual reasoning.

</details>


### [58] [Intriguing Properties of Dynamic Sampling Networks](https://arxiv.org/abs/2511.20800)
*Dario Morle,Reid Zaffino*

Main category: cs.CV

> 本文提出一种新的操作符“warping”，用于统一分析各种动态采样方法，并通过理论和实证研究来探讨稳定训练动态采样网络所需的条件。

<details>
  <summary>Details</summary>

**Motivation:** 由于动态采样机制在深度学习架构中的实用价值，但其理论分析尚未统一，因此提出了一种通用的方法来统一这些分析。

**Method:** 发展了名为“warping”的新算子来统一分析各种动态采样方法，并将其用于重构现有的体系结构，进行了统计分析。

**Result:** 发现了前向和反向传递训练模型之间的独特不对称性，并证明了动态采样机制与传统的平移不变算子完全不同。

**Conclusion:** 通过理论分析和经验研究，找出确保动态采样网络稳定训练所需的条件，并提出了一种新颖的损失景观可视化方法来更好地理解学习行为。

**Abstract:** Dynamic sampling mechanisms in deep learning architectures have demonstrated utility across many computer vision models, though the theoretical analysis of these structures has not yet been unified. In this paper we connect the various dynamic sampling methods by developing and analyzing a novel operator which generalizes existing methods, which we term "warping". Warping provides a minimal implementation of dynamic sampling which is amenable to analysis, and can be used to reconstruct existing architectures including deformable convolutions, active convolutional units, and spatial transformer networks. Using our formalism, we provide statistical analysis of the operator by modeling the inputs as both IID variables and homogeneous random fields. Extending this analysis, we discover a unique asymmetry between the forward and backward pass of the model training. We demonstrate that these mechanisms represent an entirely different class of orthogonal operators to the traditional translationally invariant operators defined by convolutions. With a combination of theoretical analysis and empirical investigation, we find the conditions necessary to ensure stable training of dynamic sampling networks. In addition, statistical analysis of discretization effects are studied. Finally, we introduce a novel loss landscape visualization which utilizes gradient update information directly, to better understand learning behavior.

</details>


### [59] [$Δ$-NeRF: Incremental Refinement of Neural Radiance Fields through Residual Control and Knowledge Transfer](https://arxiv.org/abs/2511.20804)
*Kriti Ghosh,Devjyoti Chakraborty,Lakshmish Ramaswamy,Suchendra M. Bhandarkar,In Kee Kim,Nancy O'Hare,Deepak Mishra*

Main category: cs.CV

> 本文提出了$\Delta$-NeRF，一种用于3D重建和新视角合成的NeRF的增量更新方法。它通过引入一系列创新技术，如残差控制器和不确定性门控机制等，可以大幅降低成本并改善性能。实验表明其在卫星地形分析领域中具有效而且高效的性能。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有的NeRF框架在引入新视角时需要完全重新训练，这在数据是序列到达的领域中限制了它们的应用，例如基于卫星的地形分析，这就需要不断重新训练。这项工作的动机在于解决NeRF在增量数据引入下的训练局限性，避免灾难性遗忘的问题。

**Method:** 该论文提出了一种名为$\Delta$-NeRF的独特残差框架，用于NeRF的增量改进。它引入了几个关键技术，包括：1) 一个残差控制器，在一个冻结的基NeRF中逐层注入修正；2)一种基于不确定性的门控机制，通过自适应地结合基础和修正后的预测来防止过度修正；3)一种视图选择策略，可将训练数据减少高达47%，同时保持性能。此外，论文还采用知识蒸馏将增强后的模型压缩为一个紧凑的学生模型，大小只有原来模型的20%。

**Result:** 实验结果表明，在卫星图像上，$\Delta$-NeRF实现了接近联合训练的性能，同时将训练时间减少了30-42%。与简单的微调相比，$\Delta$-NeRF始终优于其他现有基准，在PSNR上的提高高达43.5%，并且在某些指标上超过了联合训练。

**Conclusion:** 这项研究提出了一种可以有效处理NeRF在增量数据训练中的限制的方法，特别是在需要逐次引入数据的应用场景中，如卫星地形分析。$\Delta$-NeRF方法不仅减少了训练时间和数据量，还实现了在PSNR等关键指标上的大幅提高。

**Abstract:** Neural Radiance Fields (NeRFs) have demonstrated remarkable capabilities in 3D reconstruction and novel view synthesis. However, most existing NeRF frameworks require complete retraining when new views are introduced incrementally, limiting their applicability in domains where data arrives sequentially. This limitation is particularly problematic in satellite-based terrain analysis, where regions are repeatedly observed over time. Incremental refinement of NeRFs remains underexplored, and naive approaches suffer from catastrophic forgetting when past data is unavailable. We propose $Δ$-NeRF, a unique modular residual framework for incremental NeRF refinement. $Δ$-NeRF introduces several novel techniques including: (1) a residual controller that injects per-layer corrections into a frozen base NeRF, enabling refinement without access to past data; (2) an uncertainty-aware gating mechanism that prevents overcorrection by adaptively combining base and refined predictions; and (3) a view selection strategy that reduces training data by up to 47\% while maintaining performance. Additionally, we employ knowledge distillation to compress the enhanced model into a compact student network (20\% of original size). Experiments on satellite imagery demonstrate that $Δ$-NeRF achieves performance comparable to joint training while reducing training time by 30-42\%. $Δ$-NeRF consistently outperforms existing baselines, achieving an improvement of up to 43.5\% in PSNR over naive fine-tuning and surpassing joint training on some metrics.

</details>


### [60] [Layer-Aware Video Composition via Split-then-Merge](https://arxiv.org/abs/2511.20809)
*Ozgur Kara,Yujia Chen,Ming-Hsuan Yang,James M. Rehg,Wen-Sheng Chu,Du Tran*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** We present Split-then-Merge (StM), a novel framework designed to enhance control in generative video composition and address its data scarcity problem. Unlike conventional methods relying on annotated datasets or handcrafted rules, StM splits a large corpus of unlabeled videos into dynamic foreground and background layers, then self-composes them to learn how dynamic subjects interact with diverse scenes. This process enables the model to learn the complex compositional dynamics required for realistic video generation. StM introduces a novel transformation-aware training pipeline that utilizes a multi-layer fusion and augmentation to achieve affordance-aware composition, alongside an identity-preservation loss that maintains foreground fidelity during blending. Experiments show StM outperforms SoTA methods in both quantitative benchmarks and in humans/VLLM-based qualitative evaluations. More details are available at our project page: https://split-then-merge.github.io

</details>


### [61] [SPHINX: A Synthetic Environment for Visual Perception and Reasoning](https://arxiv.org/abs/2511.20814)
*Md Tanvirul Alam,Saksham Aggarwal,Justin Yang Chae,Nidhi Rastogi*

Main category: cs.CV

> Sphinx是一种使用多种图形元素生成谜题并进行评估的环境，即使最先进的GPT-5模型在这些谜题上的准确率也低于人类表现。采用带有可验证奖励的强化学习（RLVR）可以显著提升模型的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 创建Sphinx环境以生成针对核心认知原语的谜题，用于测试视觉语言模型在大规模数据集上的性能。

**Method:** Sphinx是通过使用motifs、tiles、charts、icons和几何原语来生成视觉谜题的合成环境，用于视觉感知和推理。

**Result:** 评估结果显示，即使是目前最先进的GPT-5模型，在Sphinx任务上的准确率也仅为51.1%，显著低于人类的表现。

**Conclusion:** 研究表明，通过使用带有可验证奖励的强化学习（RLVR）可以显著改善模型的准确率，并且在外部视觉推理基准上也有所提高，突显了其在推进多模态推理方面的潜力。

**Abstract:** We present Sphinx, a synthetic environment for visual perception and reasoning that targets core cognitive primitives. Sphinx procedurally generates puzzles using motifs, tiles, charts, icons, and geometric primitives, each paired with verifiable ground-truth solutions, enabling both precise evaluation and large-scale dataset construction. The benchmark covers 25 task types spanning symmetry detection, geometric transformations, spatial reasoning, chart interpretation, and sequence prediction. Evaluating recent large vision-language models (LVLMs) shows that even state-of-the-art GPT-5 attains only 51.1% accuracy, well below human performance. Finally, we demonstrate that reinforcement learning with verifiable rewards (RLVR) substantially improves model accuracy on these tasks and yields gains on external visual reasoning benchmarks, highlighting its promise for advancing multimodal reasoning.

</details>


### [62] [Training-Free Diffusion Priors for Text-to-Image Generation via Optimization-based Visual Inversion](https://arxiv.org/abs/2511.20821)
*Samuele Dell'Erba,Andrew D. Bagdanov*

Main category: cs.CV

> 本文提出了OVI方法作为文本到图像生成中扩散模型的替代先验方案，并通过实验验证了其有效性和在当前基准评估中的表现。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在文本到图像生成上取得了最先进的表现，但它们的性能通常依赖于扩散先验网络将文本嵌入转换为视觉流形以更轻松地解码。这些先验网络计算成本高昂且需要在大规模数据集上进行大量训练。本文挑战了训练先验的必要性。

**Method:** OVI方法初始化一个来自随机伪标记的潜在视觉表示，并通过迭代优化来最大化其与输入文本提示嵌入的余弦相似度。为了解决优化过程中的问题，还提出了两种新的约束：基于马氏距离的约束和最近邻损失约束。

**Result:** 实验表明，OVI可以作为传统先验的一种替代方案。另外，分析揭示了当前文本到图像生成模型评价基准存在的问题，即简单使用文本嵌入作为先验就可以实现较高的分数，尽管感知质量较低。约束优化后的OVI方法提高了视觉保真度，尤其最近邻方法表现尤为有效，其定量得分与最先进的数据高效先验模型相当，甚至更高。

**Conclusion:** 研究指出，没有训练的OVI方法可以替代传统的先验网络，并且通过约束优化可以提高图像的视觉质量。此外，提出了当前评估基准的一些局限性，并展示了OVI方法的有效性，尤其是最近邻损失方法，这为未来的研究提供了方向。

**Abstract:** Diffusion models have established the state-of-the-art in text-to-image generation, but their performance often relies on a diffusion prior network to translate text embeddings into the visual manifold for easier decoding. These priors are computationally expensive and require extensive training on massive datasets. In this work, we challenge the necessity of a trained prior at all by employing Optimization-based Visual Inversion (OVI), a training-free and data-free alternative, to replace the need for a prior. OVI initializes a latent visual representation from random pseudo-tokens and iteratively optimizes it to maximize the cosine similarity with input textual prompt embedding. We further propose two novel constraints, a Mahalanobis-based and a Nearest-Neighbor loss, to regularize the OVI optimization process toward the distribution of realistic images. Our experiments, conducted on Kandinsky 2.2, show that OVI can serve as an alternative to traditional priors. More importantly, our analysis reveals a critical flaw in current evaluation benchmarks like T2I-CompBench++, where simply using the text embedding as a prior achieves surprisingly high scores, despite lower perceptual quality. Our constrained OVI methods improve visual fidelity over this baseline, with the Nearest-Neighbor approach proving particularly effective, achieving quantitative scores comparable to or higher than the state-of-the-art data-efficient prior, indicating that the idea merits further investigation. The code will be publicly available upon acceptance.

</details>


### [63] [RefTr: Recurrent Refinement of Confluent Trajectories for 3D Vascular Tree Centerline Graphs](https://arxiv.org/abs/2511.20823)
*Roman Naeem,David Hagerman,Jennifer Alvén,Fredrik Kahl*

Main category: cs.CV

> 本文提出了RefTr，一种用于通过反复改进汇合轨迹来生成血管树中心线图的三维图生成模型。RefTr展示了比现有最佳方法更高的召回率和可比的精度，更少的参数，和更快的推理速度。

<details>
  <summary>Details</summary>

**Motivation:** 准确检测如血管和支气管等管状树的中心线及其正确的树形拓扑，对于临床任务至关重要，如诊断、治疗计划和手术导航。保持高召回率对于防止由于评估不完整或异常未被发现而导致的致命错误来说是至关重要的。

**Method:** RefTr采用一种基于变压器解码器的生产者-改进者架构，通过反复改进汇聚轨迹来生成血管树的中心线图。这种汇聚轨迹表示允许可执行完整轨迹的改进并显式地确保有效的树形拓扑结构。

**Result:** RefTr在多个公开的中心线数据集中实现了比之前顶尖方法更高的召回率和相当的精度，同时提供更快的推理和明显更少的参数。

**Conclusion:** 研究表明RefTr作为三维医学成像中血管树分析的新顶尖框架具有潜力。

**Abstract:** Tubular trees, such as blood vessels and lung airways, are essential for material transport within the human body. Accurately detecting their centerlines with correct tree topology is critical for clinical tasks such as diagnosis, treatment planning, and surgical navigation. In these applications, maintaining high recall is crucial, as missing small branches can result in fatal mistakes caused by incomplete assessments or undetected abnormalities. We present RefTr, a 3D image-to-graph model for centerline generation of vascular trees via recurrent refinement of confluent trajectories. RefTr uses a Producer-Refiner architecture based on a Transformer decoder, where the Producer proposes a set of initial confluent trajectories that are recurrently refined by the Refiner to produce final trajectories, which forms the centerline graph. The confluent trajectory representation enables refinement of complete trajectories while explicitly enforcing a valid tree topology. The recurrent refinement scheme improves precision and reuses the same Refiner block across multiple steps, yielding a 2.4x reduction in decoder parameters compared to previous SOTA. We also introduce an efficient non-maximum suppression algorithm for spatial tree graphs to merge duplicate branches and boost precision. Across multiple public centerline datasets, RefTr achieves superior recall and comparable precision to previous SOTA, while offering faster inference and substantially fewer parameters, demonstrating its potential as a new state-of-the-art framework for vascular tree analysis in 3D medical imaging.

</details>


### [64] [MODEST: Multi-Optics Depth-of-Field Stereo Dataset](https://arxiv.org/abs/2511.20853)
*Nisarg K. Trivedi,Vinayak A. Belludi,Li-Yun Wang,Pardis Taghavi,Dante Lok*

Main category: cs.CV

> A new large-scale high-resolution (5472x3648px) stereo DSLR dataset with 18,000 images across varying optical configurations has been created to better assess the performance of depth estimation models under real-world conditions, offering a rich resource for optical and geometric analysis.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to fill the gap between synthetic datasets and real-world scenarios by providing a large-scale, high-fidelity, real stereo DSLR dataset, which addresses the limitations in evaluating models that are trained on synthetic data.

**Method:** This paper introduces a new high-resolution stereo DSLR dataset, which includes 18,000 images, to address the issue of real optical condition depth estimation, which is a key challenge in practical applications such as autonomous robotics and augmented reality.

**Result:** The dataset spans a wide variety of challenging real-world scenarios with varying lighting, background, reflective surfaces, fine details, and ambient light conditions, providing a rich resource for optical and geometric analysis in stereo depth estimation, shallow depth-of-field rendering, deblurring, 3D scene reconstruction, and novel view synthesis.

**Conclusion:** The conclusion is that the presented dataset can significantly help in improving the generalization and evaluation of models based on real-world optical conditions, and it facilitates reproducible research by making the dataset, calibration files, and evaluation code publicly available.

**Abstract:** Reliable depth estimation under real optical conditions remains a core challenge for camera vision in systems such as autonomous robotics and augmented reality. Despite recent progress in depth estimation and depth-of-field rendering, research remains constrained by the lack of large-scale, high-fidelity, real stereo DSLR datasets, limiting real-world generalization and evaluation of models trained on synthetic data as shown extensively in literature. We present the first high-resolution (5472$\times$3648px) stereo DSLR dataset with 18000 images, systematically varying focal length and aperture across complex real scenes and capturing the optical realism and complexity of professional camera systems. For 9 scenes with varying scene complexity, lighting and background, images are captured with two identical camera assemblies at 10 focal lengths (28-70mm) and 5 apertures (f/2.8-f/22), spanning 50 optical configurations in 2000 images per scene. This full-range optics coverage enables controlled analysis of geometric and optical effects for monocular and stereo depth estimation, shallow depth-of-field rendering, deblurring, 3D scene reconstruction and novel view synthesis. Each focal configuration has a dedicated calibration image set, supporting evaluation of classical and learning based methods for intrinsic and extrinsic calibration. The dataset features challenging visual elements such as multi-scale optical illusions, reflective surfaces, mirrors, transparent glass walls, fine-grained details, and natural / artificial ambient light variations. This work attempts to bridge the realism gap between synthetic training data and real camera optics, and demonstrates challenges with the current state-of-the-art monocular, stereo depth and depth-of-field methods. We release the dataset, calibration files, and evaluation code to support reproducible research on real-world optical generalization.

</details>


### [65] [Unsupervised Memorability Modeling from Tip-of-the-Tongue Retrieval Queries](https://arxiv.org/abs/2511.20854)
*Sree Bhattacharyya,Yaman Kumar Singla,Sudhir Yarram,Somesh Kumar Singh,Harini S,James Z. Wang*

Main category: cs.CV

> 该研究构建了一个新的大规模非监督数据集，利用tip-of-the-tongue检索查询增强了对视觉记忆信号的理解，同时也开发了一个多模态ToT检索模型，促进了记忆相关任务的进展。

<details>
  <summary>Details</summary>

**Motivation:** 现有数据集在建模视觉内容记忆信号方面存在局限性，主要集中在收集视觉内容的记忆分数，忽略了自然回忆描述中复杂的记忆信号。该研究旨在克服数据收集的高昂成本问题，推动视觉记忆研究的进展。

**Method:** 本研究通过收集在线平台（如Reddit）上的tip-of-the-tongue（ToT）检索查询，构建了第一个用于建模视觉记忆信号的大规模非监督数据集，包含超过82,000个视频和描述性回忆数据。研究采用了对比训练策略来创建第一个能够进行多模态ToT检索的模型。

**Result:** 研究展示了所构建的非监督数据集为两个记忆相关任务提供了丰富的信号：回忆生成和ToT检索。经过该数据集微调的大型视觉-语言模型在生成视觉内容的记忆描述方面优于现有最先进的模型如GPT-4o。

**Conclusion:** 该数据集和模型为视觉内容记忆研究开启了一个新的方向，有助于未来在此领域的研究和模型优化。

**Abstract:** Visual content memorability has intrigued the scientific community for decades, with applications ranging widely, from understanding nuanced aspects of human memory to enhancing content design. A significant challenge in progressing the field lies in the expensive process of collecting memorability annotations from humans. This limits the diversity and scalability of datasets for modeling visual content memorability. Most existing datasets are limited to collecting aggregate memorability scores for visual content, not capturing the nuanced memorability signals present in natural, open-ended recall descriptions. In this work, we introduce the first large-scale unsupervised dataset designed explicitly for modeling visual memorability signals, containing over 82,000 videos, accompanied by descriptive recall data. We leverage tip-of-the-tongue (ToT) retrieval queries from online platforms such as Reddit. We demonstrate that our unsupervised dataset provides rich signals for two memorability-related tasks: recall generation and ToT retrieval. Large vision-language models fine-tuned on our dataset outperform state-of-the-art models such as GPT-4o in generating open-ended memorability descriptions for visual content. We also employ a contrastive training strategy to create the first model capable of performing multimodal ToT retrieval. Our dataset and models present a novel direction, facilitating progress in visual content memorability research.

</details>


### [66] [Estimating Fog Parameters from a Sequence of Stereo Images](https://arxiv.org/abs/2511.20865)
*Yining Ding,João F. C. Mota,Andrew M. Wallace,Sen Wang*

Main category: cs.CV

> 本文提出了一种可以同时估计雾模型参数的方法，并创建了一个新的数据集SDIRF用于评估，实验结果显示该方法能够更好地处理真实的雾天环境。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在提出一个更精确、更适合于处理真实世界雾环境的视觉同步定位与地图构建（SLAM）或里程计系统的方法，以及创建一个全新的合成雾数据集SDIRF用于评估算法。

**Method:** 我们的方法提出了一种从立体雾天图像序列中估计雾模型参数并动态更新的方法。与之前的序列估计方法不同，我们的算法通过解决一个新颖的优化问题同时估计所有参数，从而避免了错误传播。我们假设雾在局部是均匀的，因此能够有效地处理现实世界中的雾，后者通常是非均匀的。

**Result:** 通过使用合成的雾天数据和SDIRF数据集中的真实雾天序列进行广泛的实验，证明了所提出的算法相较于先前方法的优势，其不仅在合成数据上产生最准确的估计，还能更好地适应实际的雾天环境。

**Conclusion:** 本研究提出的方法提高了在雾天场景中的视觉感知能力，并通过公开代码和SDIRF数据集，促进了该领域的进一步研究。

**Abstract:** We propose a method which, given a sequence of stereo foggy images, estimates the parameters of a fog model and updates them dynamically. In contrast with previous approaches, which estimate the parameters sequentially and thus are prone to error propagation, our algorithm estimates all the parameters simultaneously by solving a novel optimisation problem. By assuming that fog is only locally homogeneous, our method effectively handles real-world fog, which is often globally inhomogeneous. The proposed algorithm can be easily used as an add-on module in existing visual Simultaneous Localisation and Mapping (SLAM) or odometry systems in the presence of fog. In order to assess our method, we also created a new dataset, the Stereo Driving In Real Fog (SDIRF), consisting of high-quality, consecutive stereo frames of real, foggy road scenes under a variety of visibility conditions, totalling over 40 minutes and 34k frames. As a first-of-its-kind, SDIRF contains the camera's photometric parameters calibrated in a lab environment, which is a prerequisite for correctly applying the atmospheric scattering model to foggy images. The dataset also includes the counterpart clear data of the same routes recorded in overcast weather, which is useful for companion work in image defogging and depth reconstruction. We conducted extensive experiments using both synthetic foggy data and real foggy sequences from SDIRF to demonstrate the superiority of the proposed algorithm over prior methods. Our method not only produces the most accurate estimates on synthetic data, but also adapts better to real fog. We make our code and SDIRF publicly available\footnote{https://github.com/SenseRoboticsLab/estimating-fog-parameters} to the community with the aim of advancing the research on visual perception in fog.

</details>


### [67] [V$^{2}$-SAM: Marrying SAM2 with Multi-Prompt Experts for Cross-View Object Correspondence](https://arxiv.org/abs/2511.20886)
*Jiancheng Pan,Runze Wang,Tianwen Qian,Mohammad Mahdi,Yanwei Fu,Xiangyang Xue,Xiaomeng Huang,Luc Van Gool,Danda Pani Paudel,Yuqian Fu*

Main category: cs.CV

> The paper introduces V^2-SAM, a framework for cross-view object correspondence that outperforms existing methods across several benchmarks.

<details>
  <summary>Details</summary>

**Motivation:** To tackle the challenge of establishing consistent object associations across different viewpoints, which current segmentation models face due to viewpoint and appearance variations.

**Method:** V^2-SAM, a unified cross-view object correspondence framework that adapts SAM2 from single-view segmentation to cross-view correspondence with two prompt generators: Cross-View Anchor Prompt Generator (V^2-Anchor) and Cross-View Visual Prompt Generator (V^2-Visual).

**Result:** V^2-SAM achieves new state-of-the-art performance on Ego-Exo4D, DAVIS-2017, and HANDAL-X benchmarks.

**Conclusion:** The multi-expert design of V^2-SAM, equipped with V^2-Anchor and V^2-Visual prompt generators, effectively handles the geometric and appearance aspects of cross-view object correspondence, delivering state-of-the-art results.

**Abstract:** Cross-view object correspondence, exemplified by the representative task of ego-exo object correspondence, aims to establish consistent associations of the same object across different viewpoints (e.g., ego-centric and exo-centric). This task poses significant challenges due to drastic viewpoint and appearance variations, making existing segmentation models, such as SAM2, non-trivial to apply directly. To address this, we present V^2-SAM, a unified cross-view object correspondence framework that adapts SAM2 from single-view segmentation to cross-view correspondence through two complementary prompt generators. Specifically, the Cross-View Anchor Prompt Generator (V^2-Anchor), built upon DINOv3 features, establishes geometry-aware correspondences and, for the first time, unlocks coordinate-based prompting for SAM2 in cross-view scenarios, while the Cross-View Visual Prompt Generator (V^2-Visual) enhances appearance-guided cues via a novel visual prompt matcher that aligns ego-exo representations from both feature and structural perspectives. To effectively exploit the strengths of both prompts, we further adopt a multi-expert design and introduce a Post-hoc Cyclic Consistency Selector (PCCS) that adaptively selects the most reliable expert based on cyclic consistency. Extensive experiments validate the effectiveness of V^2-SAM, achieving new state-of-the-art performance on Ego-Exo4D (ego-exo object correspondence), DAVIS-2017 (video object tracking), and HANDAL-X (robotic-ready cross-view correspondence).

</details>


### [68] [Test-Time Alignment of Text-to-Image Diffusion Models via Null-Text Embedding Optimisation](https://arxiv.org/abs/2511.20889)
*Taehoon Kim,Henry Gouk,Timothy Hospedales*

Main category: cs.CV

> 提出了一种名为Null-Text Test-Time Alignment (Null-TTA) 的方法，通过对无条件嵌入进行优化来防止奖励黑客行为，并确保对齐过程的语义连贯性，从而实现更优的测试时间对齐效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在推理时适应特定奖励的目标优化过程中，往往会做出不足优化或过度优化（奖励黑客行为）。

**Method:** 通过优化分类器自由引导中的无条件嵌入来进行扩散模型的对齐，而不是操纵潜在变量或噪声变量。这样做利用了文本嵌入空间的结构化语义性质，确保对齐过程发生在一个语义连贯的流形上，并防止奖励黑客行为（利用非语义噪声模式来提高奖励的行为）。

**Result:** Null-TTA实现了最先进的目标测试时间对齐效果，同时保持了强大的跨奖励泛化能力。

**Conclusion:** 这种方法验证了语义空间优化作为测试时间对齐的有效和原则性的新范式。

**Abstract:** Test-time alignment (TTA) aims to adapt models to specific rewards during inference. However, existing methods tend to either under-optimise or over-optimise (reward hack) the target reward function. We propose Null-Text Test-Time Alignment (Null-TTA), which aligns diffusion models by optimising the unconditional embedding in classifier-free guidance, rather than manipulating latent or noise variables. Due to the structured semantic nature of the text embedding space, this ensures alignment occurs on a semantically coherent manifold and prevents reward hacking (exploiting non-semantic noise patterns to improve the reward). Since the unconditional embedding in classifier-free guidance serves as the anchor for the model's generative distribution, Null-TTA directly steers model's generative distribution towards the target reward rather than just adjusting the samples, even without updating model parameters. Thanks to these desirable properties, we show that Null-TTA achieves state-of-the-art target test-time alignment while maintaining strong cross-reward generalisation. This establishes semantic-space optimisation as an effective and principled novel paradigm for TTA.

</details>


### [69] [GaINeR: Geometry-Aware Implicit Network Representation](https://arxiv.org/abs/2511.20924)
*Weronika Jakubowska,Mikołaj Zieliński,Rafał Tobiasz,Krzysztof Byrski,Maciej Zięba,Dominik Belter,Przemysław Spurek*

Main category: cs.CV

> 研究提出了GaINeR，该方法将基于高斯分布的方法与隐式神经网络结合，以提升图像的连续表示、几何结构的可解释性和局部编辑的灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的隐式神经表示缺乏明确的几何结构且在局部编辑或与物理模拟集成方面能力有限，这限制了它们在动态或交互式设置中的适用性。为此，提出了GaINeR。

**Method:** 提出了一种名为GaINeR的新框架，该框架结合了可训练的高斯分布与基于神经网络的隐式表示。对于给定的图像坐标，模型检索到K个最近的高斯分布，聚合距离加权嵌入，并通过神经网络预测RGB值。

**Result:** 该方法提供了一个物理感知和交互式图像操作的基础，目前官方实现可用。

**Conclusion:** GaINeR框架通过提供连续图像表示、可解释的几何结构和灵活的局部编辑能力，解决了传统隐式神经表示的局限性。

**Abstract:** Implicit Neural Representations (INRs) have become an essential tool for modeling continuous 2D images, enabling high-fidelity reconstruction, super-resolution, and compression. Popular architectures such as SIREN, WIRE, and FINER demonstrate the potential of INR for capturing fine-grained image details. However, traditional INRs often lack explicit geometric structure and have limited capabilities for local editing or integration with physical simulation, restricting their applicability in dynamic or interactive settings. To address these limitations, we propose GaINeR: Geometry-Aware Implicit Network Representation, a novel framework for 2D images that combines trainable Gaussian distributions with a neural network-based INR. For a given image coordinate, the model retrieves the K nearest Gaussians, aggregates distance-weighted embeddings, and predicts the RGB value via a neural network. This design enables continuous image representation, interpretable geometric structure, and flexible local editing, providing a foundation for physically aware and interactive image manipulation. The official implementation of our method is publicly available at https://github.com/WJakubowska/GaINeR.

</details>


### [70] [A deep learning model to reduce agent dose for contrast-enhanced MRI of the cerebellopontine angle cistern](https://arxiv.org/abs/2511.20926)
*Yunjie Chen,Rianne A. Weber,Olaf M. Neve,Stephan R. Romeijn,Erik F. Hensen,Jelmer M. Wolterink,Qian Tao,Marius Staring,Berit M. Verbist*

Main category: cs.CV

> 本研究目的是评估深度学习模型在减少听神经瘤患者桥小脑角池增强T1加权磁共振成像对比剂剂量方面的效果。研究通过多中心回顾性研究，使用不同剂量的对比剂来模拟低剂量T1增强成像，并开发深度学习模型来恢复标准剂量下的成像效果。结果显示，深度学习恢复的图像在低至10%-30%的标准剂量对比剂下可以保持良好的图像质量和诊断特征。

<details>
  <summary>Details</summary>

**Motivation:** 动机是探索是否可以通过深度学习方法减少MRI检查中使用的对比剂剂量，从而降低患者的辐射暴露和医疗成本，同时保持良好的图像质量以便进行诊断。

**Method:** 方法包括使用深度学习模型来尝试从不同剂量减少的对比剂模拟成像中恢复出类似标准剂量的图像，并通过结构相似性指数、峰值信噪比等多种质量评估指标来评价图像质量，同时利用人工方式进行诊断准确性的评估。

**Result:** 研究结果表明，随着输入剂量的提高，重建后的图像质量显著提高。对于高质量和诊断特征而言，10%和30%的剂量对比剂输入效果很好，尤其以30%为更高。

**Conclusion:** 结论是深度学习模型能够提高低剂量MRI图像质量，使得在10%-30%标准剂量的对比剂下进行病变检测和诊断成为可能。

**Abstract:** Objectives: To evaluate a deep learning (DL) model for reducing the agent dose of contrast-enhanced T1-weighted MRI (T1ce) of the cerebellopontine angle (CPA) cistern. Materials and methods: In this multi-center retrospective study, T1 and T1ce of vestibular schwannoma (VS) patients were used to simulate low-dose T1ce with varying reductions of contrast agent dose. DL models were trained to restore standard-dose T1ce from the low-dose simulation. The image quality and segmentation performance of the DL-restored T1ce were evaluated. A head and neck radiologist was asked to rate DL-restored images in multiple aspects, including image quality and diagnostic characterization. Results: 203 MRI studies from 72 VS patients (mean age, 58.51 \pm 14.73, 39 men) were evaluated. As the input dose increased, the structural similarity index measure of the restored T1ce increased from 0.639 \pm 0.113 to 0.993 \pm 0.009, and the peak signal-to-noise ratio increased from 21.6 \pm 3.73 dB to 41.4 \pm 4.84 dB. At 10% input dose, using DL-restored T1ce for segmentation improved the Dice from 0.673 to 0.734, the 95% Hausdorff distance from 2.38 mm to 2.07 mm, and the average surface distance from 1.00 mm to 0.59 mm. Both DL-restored T1ce from 10% and 30% input doses showed excellent images, with the latter being considered more informative. Conclusion: The DL model improved the image quality of low-dose MRI of the CPA cistern, which makes lesion detection and diagnostic characterization possible with 10% - 30% of the standard dose.

</details>


### [71] [Smooth regularization for efficient video recognition](https://arxiv.org/abs/2511.20928)
*Gil Goldman,Raja Giryes,Mahadev Satyanarayanan*

Main category: cs.CV

> 提出了一种平滑正则化技术，为视频识别模型引入了强烈的时间归纳偏差，尤其对轻量级架构有益。该方法通过将连续帧的中间层嵌入的变化建模为高斯随机游走 (GRW)，鼓励平滑性，从而改善轻量级模型捕捉复杂时态动态的能力，提高了模型在Kinetics-600数据集上的精度。

<details>
  <summary>Details</summary>

**Motivation:** 视频中的自然时序一致性要求模型具备捕捉帧间平滑变化的能力，然而轻量级模型往往受限于参数和计算资源，难以有效建模这种时序变化，因此，研究提出了该正则化技术以解决这一问题。

**Method:** 该方法通过引入平滑正则化，将连续帧中间层嵌入的变化建模为高斯随机游走 (GRW)，从而惩罚大幅度表示变化，并促进低加速解决方案以更好地符合视频中的自然时序一致性。

**Result:** 使用该技术的轻量级模型在Kinetics-600数据集上精度提高了3.8%至6.4%；特别是MoViNets模型族在给定的FLOP约束下，相较于当前最佳模型提高了3.8%至6.1% 的性能；MobileNetV3和MoViNets-Stream家族则在同级别的内存占用下实现了4.9%至6.4%的性能提升。

**Conclusion:** 这种平滑正则化技术证明了其在提升轻量级视频识别模型性能方面的有效性，其显著提高了模型对复杂时态动态的捕捉能力，并优于现有最先进的模型。

**Abstract:** We propose a smooth regularization technique that instills a strong temporal inductive bias in video recognition models, particularly benefiting lightweight architectures. Our method encourages smoothness in the intermediate-layer embeddings of consecutive frames by modeling their changes as a Gaussian Random Walk (GRW). This penalizes abrupt representational shifts, thereby promoting low-acceleration solutions that better align with the natural temporal coherence inherent in videos. By leveraging this enforced smoothness, lightweight models can more effectively capture complex temporal dynamics. Applied to such models, our technique yields a 3.8% to 6.4% accuracy improvement on Kinetics-600. Notably, the MoViNets model family trained with our smooth regularization improves the current state of the art by 3.8% to 6.1% within their respective FLOP constraints, while MobileNetV3 and the MoViNets-Stream family achieve gains of 4.9% to 6.4% over prior state-of-the-art models with comparable memory footprints. Our code and models are available at https://github.com/gilgoldm/grw-smoothing.

</details>


### [72] [Open Vocabulary Compositional Explanations for Neuron Alignment](https://arxiv.org/abs/2511.20931)
*Biagio La Rosa,Leilani H. Gilpin*

Main category: cs.CV

> 该论文提出了一种框架，能够在视觉领域中对任意概念和数据集进行神经元探测，克服了现有方法对人类标注数据的依赖性。

<details>
  <summary>Details</summary>

**Motivation:** 其动机在于解决现有解释方法依赖于人类标注数据集，限制了应用场景的问题，旨在扩大适用范围和提高灵活性。

**Method:** 该论文提出了一种框架，用于在视觉领域中对任意概念和数据集进行神经元探测。该框架包括三个步骤：指定任意概念、使用开放词汇模型生成语义分割掩码、以及从这些掩码中推导出开放词汇组合解释。

**Result:** 论文将提出的框架与以前用于计算组合性解释的方法进行了比较，从定量指标和人类可解释性两个方面进行了分析，展示了从人类标注的数据转移到模型标注的数据时解释的变化，并且展示了框架在任务和属性兴趣灵活性方面的额外功能。

**Conclusion:** 研究表明，提出的框架不仅可以有效地计算组合性解释，而且还能够在不依赖于人类标注数据的情况下提供更具灵活性的解释。

**Abstract:** Neurons are the fundamental building blocks of deep neural networks, and their interconnections allow AI to achieve unprecedented results. Motivated by the goal of understanding how neurons encode information, compositional explanations leverage logical relationships between concepts to express the spatial alignment between neuron activations and human knowledge. However, these explanations rely on human-annotated datasets, restricting their applicability to specific domains and predefined concepts. This paper addresses this limitation by introducing a framework for the vision domain that allows users to probe neurons for arbitrary concepts and datasets. Specifically, the framework leverages masks generated by open vocabulary semantic segmentation to compute open vocabulary compositional explanations. The proposed framework consists of three steps: specifying arbitrary concepts, generating semantic segmentation masks using open vocabulary models, and deriving compositional explanations from these masks. The paper compares the proposed framework with previous methods for computing compositional explanations both in terms of quantitative metrics and human interpretability, analyzes the differences in explanations when shifting from human-annotated data to model-annotated data, and showcases the additional capabilities provided by the framework in terms of flexibility of the explanations with respect to the tasks and properties of interest.

</details>


### [73] [UruDendro4: A Benchmark Dataset for Automatic Tree-Ring Detection in Cross-Section Images of Pinus taeda L](https://arxiv.org/abs/2511.20935)
*Henry Marichal,Joaquin Blanco,Diego Passarella,Gregory Randall*

Main category: cs.CV

> Paper introduces UruDendro4, a new dataset for Pinus taeda L. annual ring detection, and evaluates DeepCS-TRD method achieving high precision, recall, and low error rate.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this paper is to address the limited availability of wood cross-sectional data and to develop more accurate and automated methods for delineating annual rings in such images to assess silvicultural practices.

**Method:** The paper introduces UruDendro4, a new dataset of 102 annotated cross-sectional images of Pinus taeda L. at different heights, and evaluates the performance of the DeepCS-TRD method for automatic ring detection, achieving a mean Average Precision of 0.838, mean Average Recall of 0.782, and Adapted Rand Error score of 0.084.

**Result:** The DeepCS-TRD method achieved high accuracy with a mean Average Precision of 0.838, a mean Average Recall of 0.782, and an Adapted Rand Error score of 0.084, indicating the potential for improved automatic ring detection.

**Conclusion:** The inclusion of the UruDendro4 dataset in training improves the generalization performance of the DeepCS-TRD method for tree-ring detection tasks, marking a significant contribution to automated dendrochronology efforts.

**Abstract:** Tree-ring growth represents the annual wood increment for a tree, and quantifying it allows researchers to assess which silvicultural practices are best suited for each species. Manual measurement of this growth is time-consuming and often imprecise, as it is typically performed along 4 to 8 radial directions on a cross-sectional disc. In recent years, automated algorithms and datasets have emerged to enhance accuracy and automate the delineation of annual rings in cross-sectional images.
  To address the scarcity of wood cross-section data, we introduce the UruDendro4 dataset, a collection of 102 image samples of Pinus taeda L., each manually annotated with annual growth rings. Unlike existing public datasets, UruDendro4 includes samples extracted at multiple heights along the stem, allowing for the volumetric modeling of annual growth using manually delineated rings. This dataset (images and annotations) allows the development of volumetric models for annual wood estimation based on cross-sectional imagery.
  Additionally, we provide a performance baseline for automatic ring detection on this dataset using state-of-the-art methods. The highest performance was achieved by the DeepCS-TRD method, with a mean Average Precision of 0.838, a mean Average Recall of 0.782, and an Adapted Rand Error score of 0.084. A series of ablation experiments were conducted to empirically validate the final parameter configuration. Furthermore, we empirically demonstrate that training a learning model including this dataset improves the model's generalization in the tree-ring detection task.

</details>


### [74] [BUSTR: Breast Ultrasound Text Reporting with a Descriptor-Aware Vision-Language Model](https://arxiv.org/abs/2511.20956)
*Rawa Mohammed,Mina Attin,Bryar Shareef*

Main category: cs.CV

> 本研究提出BUSTR框架，旨在自动创建乳腺超声影像报告，采用结构化描述符和影像组学特征而不依赖成对的影像报告监督，结果表明该方法有效提升报告生成质量和临床使用效益。

<details>
  <summary>Details</summary>

**Motivation:** 此研究的动力在于应对现有乳腺超声影像报告自动生成技术面临的两大挑战——缺乏成对的影像和报告数据集，以及大语言模型带来的潜在幻觉风险。

**Method:** 本研究提出了一种名为BUSTR的多任务视觉语言框架，用于自动生成乳腺超声影像报告。该框架利用结构化描述符（如BI-RADS、病理和组织学描述符）和影像组学特征来构建报告，借助多头Swin编码器学习描述符感知的视觉表示，并通过结合标记级交叉熵和输入输出表示之间的余弦相似性对齐损失的双层目标对视觉和文本标记进行对齐。

**Result:** 在BrEaST和BUS-BRA这两个公开的乳腺超声影像数据集上进行的评估表明，无论是在标准的自然语言生成度量标准还是关键临床要素（如BI-RADS类别和病理）上，BUSTR都能显著提升报告生成的质量。

**Conclusion:** 结果表明，这种描述符感知的视觉模型，在结合了标记级和对齐损失的情况下训练，能够提高自动报告生成的度量标准和临床效益，即便不需要成对的影像报告数据。

**Abstract:** Automated radiology report generation (RRG) for breast ultrasound (BUS) is limited by the lack of paired image-report datasets and the risk of hallucinations from large language models. We propose BUSTR, a multitask vision-language framework that generates BUS reports without requiring paired image-report supervision. BUSTR constructs reports from structured descriptors (e.g., BI-RADS, pathology, histology) and radiomics features, learns descriptor-aware visual representations with a multi-head Swin encoder trained using a multitask loss over dataset-specific descriptor sets, and aligns visual and textual tokens via a dual-level objective that combines token-level cross-entropy with a cosine-similarity alignment loss between input and output representations. We evaluate BUSTR on two public BUS datasets, BrEaST and BUS-BRA, which differ in size and available descriptors. Across both datasets, BUSTR consistently improves standard natural language generation metrics and clinical efficacy metrics, particularly for key targets such as BI-RADS category and pathology. Our results show that this descriptor-aware vision model, trained with a combined token-level and alignment loss, improves both automatic report metrics and clinical efficacy without requiring paired image-report data. The source code can be found at https://github.com/AAR-UNLV/BUSTR

</details>


### [75] [Beyond Realism: Learning the Art of Expressive Composition with StickerNet](https://arxiv.org/abs/2511.20957)
*Haoming Lu,David Kocharian,Humphrey Shi*

Main category: cs.CV

> 本文提出了StickerNet框架，用于解决现代内容创作中更为艺术、有趣和社交互动型的图像组合任务。该框架基于实际在线编辑平台数据训练，反映了用户-社区验证后的可行放置决策。

<details>
  <summary>Details</summary>

**Motivation:** 现代内容创作中，许多图像组合并不旨在保持现实主义，而是追求艺术性、趣味性或社交性。因此，本文旨在定义一种新的图像组合任务，并提出对应的解决方案。

**Method:** 通过观察实际的创意平台上的图像编辑行为，提出了一种新的图像组合任务定义，称为‘表达性组合’任务。该任务更注重风格多样性以及宽松的位置逻辑。为了解决这一问题，提出了StickerNet，一种两阶段框架，首先确定图像组合类型，然后预测图像的透明度、遮罩、位置和缩放等参数。

**Result:** 用户研究和定量评估显示，相比于通用基准，StickerNet更接近人类的放置行为，证明了学习现实世界的编辑模式的有效性。

**Conclusion:** 本研究引入了视觉理解的新方向，比以往研究更强调表达性和用户意图，而不是现实主义。

**Abstract:** As a widely used operation in image editing workflows, image composition has traditionally been studied with a focus on achieving visual realism and semantic plausibility. However, in practical editing scenarios of the modern content creation landscape, many compositions are not intended to preserve realism. Instead, users of online platforms motivated by gaining community recognition often aim to create content that is more artistic, playful, or socially engaging. Taking inspiration from this observation, we define the expressive composition task, a new formulation of image composition that embraces stylistic diversity and looser placement logic, reflecting how users edit images on real-world creative platforms. To address this underexplored problem, we present StickerNet, a two-stage framework that first determines the composition type, then predicts placement parameters such as opacity, mask, location, and scale accordingly. Unlike prior work that constructs datasets by simulating object placements on real images, we directly build our dataset from 1.8 million editing actions collected on an anonymous online visual creation and editing platform, each reflecting user-community validated placement decisions. This grounding in authentic editing behavior ensures strong alignment between task definition and training supervision. User studies and quantitative evaluations show that StickerNet outperforms common baselines and closely matches human placement behavior, demonstrating the effectiveness of learning from real-world editing patterns despite the inherent ambiguity of the task. This work introduces a new direction in visual understanding that emphasizes expressiveness and user intent over realism.

</details>


### [76] [TrafficLens: Multi-Camera Traffic Video Analysis Using LLMs](https://arxiv.org/abs/2511.20965)
*Md Adnan Arefeen,Biplob Debnath,Srimat Chakradhar*

Main category: cs.CV

> TrafficLens is a specialized algorithm designed to efficiently analyze multi-camera traffic data by using overlapping coverage areas and iterative VLM applications, reducing processing time up to 4 times.

<details>
  <summary>Details</summary>

**Motivation:** Efficiently analyzing vast amounts of multi-camera traffic data is difficult and time-consuming using common VLMs due to the need for video-to-text conversion.

**Method:** Structure

**Result:** {
  "tldr": "TrafficLens is a specialized algorithm designed to efficiently analyze multi-camera traffic data by using overlapping coverage areas and iterative VLM applications, reducing processing time up to 4 times.", 
  "motivation": "Efficiently analyzing vast amounts of multi-camera traffic data is difficult and time-consuming using common VLMs due to the need for video-to-text conversion.", 
  "method": "TrafficLens uses overlapping camera coverage and an iterative VLM process, employing various token limits and using previous outputs as prompts for later steps, minimizing redundant processes.", 
  "result": "Experimental datasets confirm TrafficLens reduces the time for video-to-text conversion of multi-camera traffic data by up to 4 times without sacrificing information accuracy.", 
  "conclusion": "TrafficLens offers a significant improvement in the efficiency of analyzing multi-camera traffic data, potentially enhancing real-time traffic monitoring and incident response.")

**Conclusion:** TrafficLens offers a significant improvement in the efficiency of analyzing multi-camera traffic data, potentially enhancing real-time traffic monitoring and incident response.

**Abstract:** Traffic cameras are essential in urban areas, playing a crucial role in intelligent transportation systems. Multiple cameras at intersections enhance law enforcement capabilities, traffic management, and pedestrian safety. However, efficiently managing and analyzing multi-camera feeds poses challenges due to the vast amount of data. Analyzing such huge video data requires advanced analytical tools. While Large Language Models (LLMs) like ChatGPT, equipped with retrieval-augmented generation (RAG) systems, excel in text-based tasks, integrating them into traffic video analysis demands converting video data into text using a Vision-Language Model (VLM), which is time-consuming and delays the timely utilization of traffic videos for generating insights and investigating incidents. To address these challenges, we propose TrafficLens, a tailored algorithm for multi-camera traffic intersections. TrafficLens employs a sequential approach, utilizing overlapping coverage areas of cameras. It iteratively applies VLMs with varying token limits, using previous outputs as prompts for subsequent cameras, enabling rapid generation of detailed textual descriptions while reducing processing time. Additionally, TrafficLens intelligently bypasses redundant VLM invocations through an object-level similarity detector. Experimental results with real-world datasets demonstrate that TrafficLens reduces video-to-text conversion time by up to $4\times$ while maintaining information accuracy.

</details>


### [77] [Privacy-Preserving Federated Vision Transformer Learning Leveraging Lightweight Homomorphic Encryption in Medical AI](https://arxiv.org/abs/2511.20983)
*Al Amin,Kamrul Hasan,Liang Hong,Sharif Ullah*

Main category: cs.CV

> This paper introduces a privacy-preserving federated learning method that combines Vision Transformers and homomorphic encryption to ensure data privacy while sharing learning outcomes for histopathology classification, achieving robust accuracy and privacy.

<details>
  <summary>Details</summary>

**Motivation:** The primary motivation is to address the privacy concerns associated with federated learning in healthcare settings, specifically the vulnerability of model gradients to reconstruction attacks, which could expose sensitive patient data.

**Method:** This paper proposes a privacy-preserving federated learning framework for multi-institutional histopathology classification, integrating Vision Transformers with homomorphic encryption to protect the privacy of medical data while achieving high diagnostic accuracy.

**Result:** The proposed method demonstrates a significant reduction in communication overhead (30-fold) compared to gradient encryption and resists model inversion attacks, maintaining strong privacy guarantees. In a test scenario involving lung cancer histopathology classification, the framework achieves 96.12 percent accuracy in the unencrypted domain and 90.02 percent in the encrypted domain.

**Conclusion:** The integration of Vision Transformers with homomorphic encryption for secure multi-institutional histopathology classification effectively addresses privacy concerns in federated learning while maintaining high diagnostic accuracy, offering a promising direction for collaborative machine learning in healthcare.

**Abstract:** Collaborative machine learning across healthcare institutions promises improved diagnostic accuracy by leveraging diverse datasets, yet privacy regulations such as HIPAA prohibit direct patient data sharing. While federated learning (FL) enables decentralized training without raw data exchange, recent studies show that model gradients in conventional FL remain vulnerable to reconstruction attacks, potentially exposing sensitive medical information. This paper presents a privacy-preserving federated learning framework combining Vision Transformers (ViT) with homomorphic encryption (HE) for secure multi-institutional histopathology classification. The approach leverages the ViT CLS token as a compact 768-dimensional feature representation for secure aggregation, encrypting these tokens using CKKS homomorphic encryption before transmission to the server. We demonstrate that encrypting CLS tokens achieves a 30-fold communication reduction compared to gradient encryption while maintaining strong privacy guarantees. Through evaluation on a three-client federated setup for lung cancer histopathology classification, we show that gradients are highly susceptible to model inversion attacks (PSNR: 52.26 dB, SSIM: 0.999, NMI: 0.741), enabling near-perfect image reconstruction. In contrast, the proposed CLS-protected HE approach prevents such attacks while enabling encrypted inference directly on ciphertexts, requiring only 326 KB of encrypted data transmission per aggregation round. The framework achieves 96.12 percent global classification accuracy in the unencrypted domain and 90.02 percent in the encrypted domain.

</details>


### [78] [Inversion-Free Style Transfer with Dual Rectified Flows](https://arxiv.org/abs/2511.20986)
*Yingying Deng,Xiangyu He,Fan Tang,Weiming Dong,Xucheng Yin*

Main category: cs.CV

> 本文提出了一种无逆风格转换框架，通过双校正流方法并行处理内容和风格，动态地融合二者并避免视觉失真，此方法解决了现有方法依赖逆过程带来的效率低下和视觉失真问题。

<details>
  <summary>Details</summary>

**Motivation:** 主流的无训练扩散方法虽然在很大程度上推进了风格转换的发展，但由于依赖计算昂贵的逆向处理过程，它们在效率上存在不足，并且当逆运算是错误的时候会引入视觉失真。因此，本研究旨在解决这些限制，并提出了一种新的无逆风格转换框架。

**Method:** 本研究提出了一种基于双校正流的无逆方法框架，该框架能够在没有逆操作的情况下，从两个不同输入（内容和风格图像）中找到一个未知的风格化分布，仅通过正向传递实现。该方法并行预测内容和风格轨迹，然后通过动态中间点插值融合它们，该插值方法将来自两条路径的速度整合在一起，并适应于不断变化的风格化图像。

**Result:** 实验结果表明，该方法在多种风格和内容之间具有良好的泛化能力，提供了一种有效的风格转换管线。

**Conclusion:** 该研究通过设计一个结合了内容、风格和风格化分布的矢量场，并加入了注意力注入来指导风格整合，实现了视觉保真度、内容保存和计算效率的提升。

**Abstract:** Style transfer, a pivotal task in image processing, synthesizes visually compelling images by seamlessly blending realistic content with artistic styles, enabling applications in photo editing and creative design. While mainstream training-free diffusion-based methods have greatly advanced style transfer in recent years, their reliance on computationally inversion processes compromises efficiency and introduces visual distortions when inversion is inaccurate. To address these limitations, we propose a novel \textit{inversion-free} style transfer framework based on dual rectified flows, which tackles the challenge of finding an unknown stylized distribution from two distinct inputs (content and style images), \textit{only with forward pass}. Our approach predicts content and style trajectories in parallel, then fuses them through a dynamic midpoint interpolation that integrates velocities from both paths while adapting to the evolving stylized image. By jointly modeling the content, style, and stylized distributions, our velocity field design achieves robust fusion and avoids the shortcomings of naive overlays. Attention injection further guides style integration, enhancing visual fidelity, content preservation, and computational efficiency. Extensive experiments demonstrate generalization across diverse styles and content, providing an effective and efficient pipeline for style transfer.

</details>


### [79] [RefOnce: Distilling References into a Prototype Memory for Referring Camouflaged Object Detection](https://arxiv.org/abs/2511.20989)
*Yu-Huan Wu,Zi-Xuan Zhu,Yan Wang,Liangli Zhen,Deng-Ping Fan*

Main category: cs.CV

> 一种新的Ref-COD框架，通过在训练期间提炼类别原型记忆并在推理过程中合成参考向量，解决了现有方法对测试时参考图像的依赖，该方法在R2C7K数据集上展示出优异性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前的Ref-COD系统采用双分支设计，在测试时需要参考图像，这限制了其部署能力并增加了延迟和数据收集负担。因此，引入了一种新的框架，旨在实现不依赖测试时参考图像的简单高效Ref-COD。

**Method:** 一种新的Ref-COD框架，该框架在训练过程中将引用图像提炼成类别原型记忆，并在推理过程中通过查询条件下的原型混合合成参考向量。具体而言，该方法维护一个每类的EMA更新原型，并从查询中预测混合权重以生成指导向量。为了缩小参考统计与伪装查询特征之间的表示差距，该方法提出了一种双向注意力对齐模块，该模块适应查询特征和类别表示。

**Result:** 在大规模R2C7K基准上进行了评估，实验结果表明该方法在性能上与近期最先进方法相当或更优。

**Conclusion:** 通过引入一类原型记忆和双向注意力对齐模块，该方法实现在推理阶段无需使用测试时参考图像的伪装对象检测，使得Ref-COD系统更加简单高效。

**Abstract:** Referring Camouflaged Object Detection (Ref-COD) segments specified camouflaged objects in a scene by leveraging a small set of referring images. Though effective, current systems adopt a dual-branch design that requires reference images at test time, which limits deployability and adds latency and data-collection burden. We introduce a Ref-COD framework that distills references into a class-prototype memory during training and synthesizes a reference vector at inference via a query-conditioned mixture of prototypes. Concretely, we maintain an EMA-updated prototype per category and predict mixture weights from the query to produce a guidance vector without any test-time references. To bridge the representation gap between reference statistics and camouflaged query features, we propose a bidirectional attention alignment module that adapts both the query features and the class representation. Thus, our approach yields a simple, efficient path to Ref-COD without mandatory references. We evaluate the proposed method on the large-scale R2C7K benchmark. Extensive experiments demonstrate competitive or superior performance of the proposed method compared with recent state-of-the-arts. Code is available at https://github.com/yuhuan-wu/RefOnce.

</details>


### [80] [Wavefront-Constrained Passive Obscured Object Detection](https://arxiv.org/abs/2511.20991)
*Zhiwen Zheng,Yiwei Ouyang,Zhao Huang,Tao Zhang,Xiaoshuai Zhang,Huiyu Zhou,Wenwen Tang,Shaowei Jiang,Jin Liu,Xingru Huang*

Main category: cs.CV

> 本文提出Wavefront Propagating Compensation Network (WavePCNet) 模型，用于改善在复杂条件下难以捕捉的被遮挡物体的定位和分割。WavePCNet 结合了 Tri-Phase Wavefront Complex-Propagation Reprojection (TriWCP) 机制，能够更精确地模拟光波传播行为，使用动量记忆机制有效地抑制误差累积，并且通过引入高频跨层补偿增强机制提高了模型的鲁棒性和解释性。实验结果显示，该模型在准确性、鲁棒性方面均优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 传统的方法基于实值建模或局部卷积操作，难以捕捉相干光传播的物理本质，特别是在低信噪比条件下容易得到非物理解，这显著影响了观测的稳定性和可靠性。因此，提出了WavePCNet来解决这些问题。

**Method:** WavePCNet 集成了 Tri-Phase Wavefront Complex-Propagation Reprojection (TriWCP) 以精确约束相干传播行为，还采用了一种动量记忆机制来有效抑制错误的累积。同时，引入了高频率跨层补偿增强机制，构造具有多尺度感受野的频率选择路径，并跨层动态建模结构一致性。

**Result:** 一系列实验在四个物理收集的数据集上进行，结果表明WavePCNet在准确性和鲁棒性方面都优于现有方法。

**Conclusion:** 提出的WavePCNet通过精确的物理建模、动量记忆机制以及高频跨层补偿增强机制，在处理被遮挡物体的定位和分割任务中表现出了卓越的性能和鲁棒性。

**Abstract:** Accurately localizing and segmenting obscured objects from faint light patterns beyond the field of view is highly challenging due to multiple scattering and medium-induced perturbations. Most existing methods, based on real-valued modeling or local convolutional operations, are inadequate for capturing the underlying physics of coherent light propagation. Moreover, under low signal-to-noise conditions, these methods often converge to non-physical solutions, severely compromising the stability and reliability of the observation. To address these challenges, we propose a novel physics-driven Wavefront Propagating Compensation Network (WavePCNet) to simulate wavefront propagation and enhance the perception of obscured objects. This WavePCNet integrates the Tri-Phase Wavefront Complex-Propagation Reprojection (TriWCP) to incorporate complex amplitude transfer operators to precisely constrain coherent propagation behavior, along with a momentum memory mechanism to effectively suppress the accumulation of perturbations. Additionally, a High-frequency Cross-layer Compensation Enhancement is introduced to construct frequency-selective pathways with multi-scale receptive fields and dynamically model structural consistency across layers, further boosting the model's robustness and interpretability under complex environmental conditions. Extensive experiments conducted on four physically collected datasets demonstrate that WavePCNet consistently outperforms state-of-the-art methods across both accuracy and robustness.

</details>


### [81] [GuardTrace-VL: Detecting Unsafe Multimodel Reasoning via Iterative Safety Supervision](https://arxiv.org/abs/2511.20994)
*Yuxiao Xiang,Junchi Chen,Zhenchao Jin,Changtao Miao,Haojie Yuan,Qi Chu,Tao Gong,Nenghai Yu*

Main category: cs.CV

> 本文介绍了GuardTrace-VL，一种能够监测整个QTA（问题-思考-答案）流程的视觉感知安全审计工具，提高了多模态大推理模型的安全性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的多模态安全守护策略主要在输入问题和最终输出答案中评估安全问题，忽略了中间推理阶段的潜在风险，这可能导致有害内容在推理过程中未被检测到，如偏见推断或违反规定的视觉背景使用。

**Method:** 现有研究主要在输入问题和最终答案上进行安全评估，忽视了推理过程，而GuardTrace-VL通过联合图像和文本分析，对整个QTA（问题-思考-答案）流程进行监控，以实现在推理阶段即时检测到潜在的有害内容。

**Result:** 实验结果表明，针对我们的测试集，不论是领域内还是领域外场景，GuardTrace-VL模型在不安全推理检测任务上达到了93.1%的F1分数，比先前最强的多模态安全防御方法提高了13.5%。

**Conclusion:** GuardTrace-VL展示了通过关注推理过程来提升多模态大推理模型安全性的有效性。

**Abstract:** Multimodal large reasoning models (MLRMs) are increasingly deployed for vision-language tasks that produce explicit intermediate rationales. However, reasoning traces can contain unsafe content even when the final answer is non-harmful, creating deployment risks. Existing multimodal safety guards primarily evaluate only the input question and the final answer, neglecting the intermediate reasoning process. This oversight allows undetected harm, such as biased inferences or policy-violating use of visual context, to emerge during reasoning. We introduce GuardTrace-VL, a vision-aware safety auditor that monitors the full Question-Thinking-Answer (QTA) pipeline via joint image-text analysis, enabling detection of unsafe content as it emerges in the reasoning stage. To support training and evaluation, we construct the GuardTrace dataset, which is generated through diverse prompting strategies and refined via a MLRM- and human-based voting and verification pipeline. Furthermore, we propose a three-stage progressive training scheme combined with the data refinement process, enabling the model to learn nuanced and context-dependent safety preferences according to different risk levels. On our proposed test set covering both in-domain and out-of-domain scenarios, GuardTrace-VL model achieves an F1 score of 93.1% on unsafe reasoning detection tasks, representing a 13.5% improvement in F1 score compared to the previous strongest multimodal safety defense methods. The codes will be made publicly available.

</details>


### [82] [From Inpainting to Layer Decomposition: Repurposing Generative Inpainting Models for Image Layer Decomposition](https://arxiv.org/abs/2511.20996)
*Jingxi Chen,Yixiao Zhang,Xiaoye Qian,Zongxia Li,Cornelia Fermuller,Caren Chen,Yiannis Aloimonos*

Main category: cs.CV

> 研究提出了一种新的方法，通过微调扩散模型的 inpainting 方法并引入多模态上下文融合模块来实现图像的分层分解，此方法能更好地保持细节，尤其是在对象移除和遮挡恢复方面表现突出。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型生成模型有所进展，但将单个图像分解成各层依然具有挑战性。研究发现图像分层分解和 inpainting 任务之间存在紧密联系。

**Method:** 提出了一种基于扩散模型的 inpainting 方法，并对其进行轻量级微调来实现图像的分层分解。为了在潜在空间中更好地保持细节，引入了一种新的多模态上下文融合模块，该模块具有线性注意力复杂度。

**Result:** 模型在基于开源资产构建的合成数据集上训练，并在对象移除和遮挡恢复任务中表现出色，为后期编辑和创意应用开辟了新途径。

**Conclusion:** 该方法能够有效实现图像的分层分解，增强了图像编辑的灵活性，为多媒体内容创作提供了新的可能性。

**Abstract:** Images can be viewed as layered compositions, foreground objects over background, with potential occlusions. This layered representation enables independent editing of elements, offering greater flexibility for content creation. Despite the progress in large generative models, decomposing a single image into layers remains challenging due to limited methods and data. We observe a strong connection between layer decomposition and in/outpainting tasks, and propose adapting a diffusion-based inpainting model for layer decomposition using lightweight finetuning. To further preserve detail in the latent space, we introduce a novel multi-modal context fusion module with linear attention complexity. Our model is trained purely on a synthetic dataset constructed from open-source assets and achieves superior performance in object removal and occlusion recovery, unlocking new possibilities in downstream editing and creative applications.

</details>


### [83] [Knowledge Completes the Vision: A Multimodal Entity-aware Retrieval-Augmented Generation Framework for News Image Captioning](https://arxiv.org/abs/2511.21002)
*Xiaoxing You,Qiang Huang,Lingyu Li,Chi Zhang,Xiaopeng Liu,Min Zhang,Jun Yu*

Main category: cs.CV

> MERGE框架针对新闻图像描述的问题，通过构建EMKB改进背景检索，提高跨模态对齐和视觉实体匹配，从而显著提高描述质量和实体识别的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 解决新闻图像描述中存在的三个关键问题：（1）信息覆盖不全，（2）弱跨模态对齐，（3）子最优的视觉实体定位。

**Method:** MERGE框架通过构建实体中心的多模态知识库（EMKB），该知识库整合了文本、视觉和结构化知识，实现了背景信息的丰富检索。它通过多阶段假设-描述策略改善跨模态对齐，并通过基于图像内容的动态检索增强视觉实体匹配。

**Result:** 在GoodNews和NYTimes800k数据集上的大量实验表明，MERGE显著超越了最先进的基线模型，在CIDEr和F1-score上实现了显著提高。MERGE模型在未见过的Visual News数据集上也表现良好，这表明其具有强大的鲁棒性和领域适应性。

**Conclusion:** MERGE框架通过改进跨模态对齐和增强视觉实体匹配，显著提升了新闻图像描述的质量和实体识别的准确性。

**Abstract:** News image captioning aims to produce journalistically informative descriptions by combining visual content with contextual cues from associated articles. Despite recent advances, existing methods struggle with three key challenges: (1) incomplete information coverage, (2) weak cross-modal alignment, and (3) suboptimal visual-entity grounding. To address these issues, we introduce MERGE, the first Multimodal Entity-aware Retrieval-augmented GEneration framework for news image captioning. MERGE constructs an entity-centric multimodal knowledge base (EMKB) that integrates textual, visual, and structured knowledge, enabling enriched background retrieval. It improves cross-modal alignment through a multistage hypothesis-caption strategy and enhances visual-entity matching via dynamic retrieval guided by image content. Extensive experiments on GoodNews and NYTimes800k show that MERGE significantly outperforms state-of-the-art baselines, with CIDEr gains of +6.84 and +1.16 in caption quality, and F1-score improvements of +4.14 and +2.64 in named entity recognition. Notably, MERGE also generalizes well to the unseen Visual News dataset, achieving +20.17 in CIDEr and +6.22 in F1-score, demonstrating strong robustness and domain adaptability.

</details>


### [84] [MetaRank: Task-Aware Metric Selection for Model Transferability Estimation](https://arxiv.org/abs/2511.21007)
*Yuhang Liu,Wenjie Zhao,Yunhui Guo*

Main category: cs.CV

> 提出MetaRank，一种元学习框架，用于自动选择最合适的MTE指标，进而提升迁移学习性能。

<details>
  <summary>Details</summary>

**Motivation:** 在迁移学习中，选择合适的预训练源模型是一个关键但计算成本高昂的任务。MTE方法通过提供有效地替代指标来对模型进行排序，避免了全量微调的需要。然而，目前选择哪种MTE指标通常是随意或依据历史性能，本文发现MTE指标的有效性高度取决于任务，没有单独的指标能在所有目标数据集上表现最优，因此提出MetaRank解决这个问题。

**Method:** 介绍了一种名为MetaRank的元学习框架，该框架用于自动、任务感知的模型传输能力评估指标选择。MetaRank将指标选择问题公式化为学习排序问题，使用预训练的语言模型来对数据集和MTE指标的文本描述进行编码，并通过离线训练元预测器来学习数据集特征和指标机制之间的复杂关系。在线阶段，MetaRank根据目标数据集的文本描述有效地对候选MTE指标进行排序，帮助实践者提前选择最合适的指标。

**Result:** 在跨11个预训练模型和11个目标数据集的广泛实验中，验证了该方法的有效性。

**Conclusion:** 实验表明，MetaRank能够自动、任务感知地选择最佳MTE指标，有效提升了迁移学习的效果。

**Abstract:** Selecting an appropriate pre-trained source model is a critical, yet computationally expensive, task in transfer learning. Model Transferability Estimation (MTE) methods address this by providing efficient proxy metrics to rank models without full fine-tuning. In practice, the choice of which MTE metric to use is often ad hoc or guided simply by a metric's average historical performance. However, we observe that the effectiveness of MTE metrics is highly task-dependent and no single metric is universally optimal across all target datasets. To address this gap, we introduce MetaRank, a meta-learning framework for automatic, task-aware MTE metric selection. We formulate metric selection as a learning-to-rank problem. Rather than relying on conventional meta-features, MetaRank encodes textual descriptions of both datasets and MTE metrics using a pretrained language model, embedding them into a shared semantic space. A meta-predictor is then trained offline on diverse meta-tasks to learn the intricate relationship between dataset characteristics and metric mechanisms, optimized with a listwise objective that prioritizes correctly ranking the top-performing metrics. During the subsequent online phase, MetaRank efficiently ranks the candidate MTE metrics for a new, unseen target dataset based on its textual description, enabling practitioners to select the most appropriate metric a priori. Extensive experiments across 11 pretrained models and 11 target datasets demonstrate the strong effectiveness of our approach.

</details>


### [85] [Structure-Aware Prototype Guided Trusted Multi-View Classification](https://arxiv.org/abs/2511.21021)
*Haojian Huang,Jiahao Shi,Zhe Liu,Harold Haodong Chen,Han Fang,Hao Sun,Zhongjiang He*

Main category: cs.CV

> 提出了一种新型的可信多视图分类框架，使用原型来表示每视图的邻居结构，从而提高效率和跨视图的一致性。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有可信多视图分类方法计算成本高、难以确保跨视图一致性以及缺乏保证多视图邻居结构在类空间内部一致性的问题。

**Method:** 通过引入原型来表示每种视图的邻居结构，从而简化了学习内部视图邻居关系的过程，并使内部和跨视图结构的动态对齐成为可能。

**Result:** 在多个公共多视图数据集上的大量实验表明，该方法在下游性能和鲁棒性方面与现有的可信多视图分类方法相比具有竞争力。

**Conclusion:** 所提出的方法通过引入动态对齐机制，提升了多视图分类的效率和可信度。

**Abstract:** Trustworthy multi-view classification (TMVC) addresses the challenge of achieving reliable decision-making in complex scenarios where multi-source information is heterogeneous, inconsistent, or even conflicting. Existing TMVC approaches predominantly rely on globally dense neighbor relationships to model intra-view dependencies, leading to high computational costs and an inability to directly ensure consistency across inter-view relationships. Furthermore, these methods typically aggregate evidence from different views through manually assigned weights, lacking guarantees that the learned multi-view neighbor structures are consistent within the class space, thus undermining the trustworthiness of classification outcomes. To overcome these limitations, we propose a novel TMVC framework that introduces prototypes to represent the neighbor structures of each view. By simplifying the learning of intra-view neighbor relations and enabling dynamic alignment of intra- and inter-view structure, our approach facilitates more efficient and consistent discovery of cross-view consensus. Extensive experiments on multiple public multi-view datasets demonstrate that our method achieves competitive downstream performance and robustness compared to prevalent TMVC methods.

</details>


### [86] [CameraMaster: Unified Camera Semantic-Parameter Control for Photography Retouching](https://arxiv.org/abs/2511.21024)
*Qirui Yang,Yang Yang,Ying Zeng,Xiaobin Hu,Bo Li,Huanjing Yue,Jingyu Yang,Peng-Tao Jiang*

Main category: cs.CV

> CameraMaster是一种新的统一框架，可进行精确参数控制的物理一致的图像修复。它解决了现有方法依赖模糊指令或不具备可扩展性的局限性，通过显式分离相机指令并将其与精准参数嵌入结合起来以实现更好的图像处理效果。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有方法在精确控制参数（如曝光、白平衡、变焦）进行物理一致的图像修复方面的局限性。这些方法要么依赖于模糊且纠缠的文本提示，这妨碍了精确的相机控制，要么为参数调整训练单独的头部/权重，这减少了可扩展性，多参数组合的灵活性，并对细微变化不敏感。

**Method:** 提出CameraMaster，一种统一的相机感知框架，用于图像修复。该方法显式地将相机指令分离，并整合两个关键信息流：一个是捕捉摄影师意图的指令表示，另一个是编码精确相机设置的参数嵌入。CameraMaster首先利用相机参数嵌入来调制相机指令和内容语义，然后通过交叉注意力将调制后的指令注入到内容特征中，从而获得强烈的相机敏感语义背景。此外，指令和相机嵌入被作为条件和门控信号注入到时间嵌入中，实现统一的、逐层的去噪过程调制，并强制严格的语义-参数对齐。

**Result:** 构建了一个包含78K张图像-提示对和相机参数注释的大规模数据集用于训练和评估CameraMaster。实验显示，CameraMaster对参数变化产生了单调且几乎是线性的响应，支持平滑的多参数组合，并明显优于现有方法。

**Conclusion:** CameraMaster展示了在图像修复领域基于精确参数控制与文本引导结合的强大能力，证明了通过结合两个关键信息流可以产生更加丰富和一致的视觉效果，并在实验中验证了其效能。

**Abstract:** Text-guided diffusion models have greatly advanced image editing and generation. However, achieving physically consistent image retouching with precise parameter control (e.g., exposure, white balance, zoom) remains challenging. Existing methods either rely solely on ambiguous and entangled text prompts, which hinders precise camera control, or train separate heads/weights for parameter adjustment, which compromises scalability, multi-parameter composition, and sensitivity to subtle variations. To address these limitations, we propose CameraMaster, a unified camera-aware framework for image retouching. The key idea is to explicitly decouple the camera directive and then coherently integrate two critical information streams: a directive representation that captures the photographer's intent, and a parameter embedding that encodes precise camera settings. CameraMaster first uses the camera parameter embedding to modulate both the camera directive and the content semantics. The modulated directive is then injected into the content features via cross-attention, yielding a strongly camera-sensitive semantic context. In addition, the directive and camera embeddings are injected as conditioning and gating signals into the time embedding, enabling unified, layer-wise modulation throughout the denoising process and enforcing tight semantic-parameter alignment. To train and evaluate CameraMaster, we construct a large-scale dataset of 78K image-prompt pairs annotated with camera parameters. Extensive experiments show that CameraMaster produces monotonic and near-linear responses to parameter variations, supports seamless multi-parameter composition, and significantly outperforms existing methods.

</details>


### [87] [CaptionQA: Is Your Caption as Useful as the Image Itself?](https://arxiv.org/abs/2511.21025)
*Shijia Yang,Yunong Liu,Bohan Zhai,Ximeng Sun,Zicheng Liu,Emad Barsoum,Manling Li,Chenfeng Xu*

Main category: cs.CV

> 研究引入了CaptionQA，这是一个用于评估模型生成图像字幕效用的新基准，发现传统图像QA基准可能无法准确衡量字幕的质量，CaptionQA揭示了模型在字幕效用方面存在显著差距。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于当前的评估实践忽略了一个基本问题，即字幕能否在真正的下游任务中作为图像的替代品。本研究旨在通过一种新的评估基准来解决这一问题。

**Method:** 提出了一种基于效用的基准CaptionQA，用于评估由模型生成的图像字幕，其中字幕的质量通过其支持下游任务的程度来衡量。CaptionQA是一个可扩展的、依赖于领域的基准，涵盖了4个领域——自然、文档、电子商务和具身AI，每个领域都有精细的分类（25个顶级分类和69个子分类），可以识别出特定领域任务中有用的信息。

**Result:** CaptionQA构建了33,027个密集注释的选择题（平均每张图片50.3个问题），这些问题明确需要视觉信息来回答。在评估协议中，LLM仅使用字幕回答这些问题，直接衡量字幕是否能保持图片层面的效用。通过评估最先进的MLLM，发现图像字幕的效用存在显著差距，一些模型在传统的图像QA基准测试中表现相似，但在CaptionQA上的词效用降低了高达32%。

**Conclusion:** 结论是传统的图像QA基准可能无法准确衡量字幕的质量。CaptionQA可以深入检测生成文本工具的能力，这对于提升多模态模型的性能至关重要。研究还开放了CaptionQA的代码和一个开源扩展到新领域的管道供后续研究使用。

**Abstract:** Image captions serve as efficient surrogates for visual content in multimodal systems such as retrieval, recommendation, and multi-step agentic inference pipelines. Yet current evaluation practices miss a fundamental question: Can captions stand-in for images in real downstream tasks? We propose a utility-based benchmark, CaptionQA, to evaluate model-generated captions, where caption quality is measured by how well it supports downstream tasks. CaptionQA is an extensible domain-dependent benchmark covering 4 domains--Natural, Document, E-commerce, and Embodied AI--each with fine-grained taxonomies (25 top-level and 69 subcategories) that identify useful information for domain-specific tasks. CaptionQA builds 33,027 densely annotated multiple-choice questions (50.3 per image on average) that explicitly require visual information to answer, providing a comprehensive probe of caption utility. In our evaluation protocol, an LLM answers these questions using captions alone, directly measuring whether captions preserve image-level utility and are utilizable by a downstream LLM. Evaluating state-of-the-art MLLMs reveals substantial gaps between the image and its caption utility. Notably, models nearly identical on traditional image-QA benchmarks lower by up to 32% in caption utility. We release CaptionQA along with an open-source pipeline for extension to new domains. The code is available at https://github.com/bronyayang/CaptionQA.

</details>


### [88] [FlowerDance: MeanFlow for Efficient and Refined 3D Dance Generation](https://arxiv.org/abs/2511.21029)
*Kaixing Yang,Xulong Tang,Ziqiao Peng,Xiangyue Zhang,Puwei Wang,Jun He,Hongyan Liu*

Main category: cs.CV

> FlowerDance is a method that generates high-quality, physically plausible, and artistically expressive dance motions efficiently, using a combination of MeanFlow, Physical Consistency Constraints, a BiMamba-based backbone, and Channel-Level Cross-Modal Fusion.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the generation efficiency of existing music-to-dance systems to support high-fidelity 3D rendering and to enhance the expressiveness of 3D characters in real-world applications.

**Method:** The method combines MeanFlow with Physical Consistency Constraints for efficient and high-quality motion generation. It uses a BiMamba-based backbone and Channel-Level Cross-Modal Fusion for efficient non-autoregressive dance generation.

**Result:** Experiments on AIST++ and FineDance datasets show that FlowerDance achieves state-of-the-art performance in terms of motion quality and generation efficiency.

**Conclusion:** FlowerDance improves upon existing techniques by providing highly efficient and high-quality dance motion generation, and it supports interactive motion editing.

**Abstract:** Music-to-dance generation aims to translate auditory signals into expressive human motion, with broad applications in virtual reality, choreography, and digital entertainment. Despite promising progress, the limited generation efficiency of existing methods leaves insufficient computational headroom for high-fidelity 3D rendering, thereby constraining the expressiveness of 3D characters during real-world applications. Thus, we propose FlowerDance, which not only generates refined motion with physical plausibility and artistic expressiveness, but also achieves significant generation efficiency on inference speed and memory utilization . Specifically, FlowerDance combines MeanFlow with Physical Consistency Constraints, which enables high-quality motion generation with only a few sampling steps. Moreover, FlowerDance leverages a simple but efficient model architecture with BiMamba-based backbone and Channel-Level Cross-Modal Fusion, which generates dance with efficient non-autoregressive manner. Meanwhile, FlowerDance supports motion editing, enabling users to interactively refine dance sequences. Extensive experiments on AIST++ and FineDance show that FlowerDance achieves state-of-the-art results in both motion quality and generation efficiency. Code will be released upon acceptance.

</details>


### [89] [LungNoduleAgent: A Collaborative Multi-Agent System for Precision Diagnosis of Lung Nodules](https://arxiv.org/abs/2511.21042)
*Cheng Yang,Hui Jin,Xinlei Yu,Zhipeng Wang,Yaoqun Liu,Fenglei Fan,Dajiang Lei,Gangyong Jia,Changmiao Wang,Ruiquan Ge*

Main category: cs.CV

> The paper introduces LungNoduleAgent, a collaborative multi-agent system that improves the precision of diagnosing lung nodules in CT scans by combining clinical detection, image description, and malignancy reasoning.

<details>
  <summary>Details</summary>

**Motivation:** Despite progress in using multimodal language models for lung CT scan analysis, challenges still exist in precisely describing lung nodules and incorporating medical knowledge into these models, affecting their reliability and effectiveness in clinical settings.

**Method:** LungNoduleAgent consists of three modules: the Nodule Spotter for nodule detection, the Radiologist for comprehensive CT report generation using localized image description techniques, and the Doctor Agent System for malignancy reasoning with the help of a pathology knowledge base and a multi-agent system framework.

**Result:** Testing on private datasets and the LIDC-IDRI dataset shows that LungNoduleAgent outperforms existing vision-language models, agent systems, and advanced expert models.

**Conclusion:** The collaborative multi-agent approach adopted by LungNoduleAgent highlights the importance of region-level semantic alignment and multi-agent collaboration for the accurate diagnosis of lung nodules, promising a new foundational tool for clinical lung nodule analysis.

**Abstract:** Diagnosing lung cancer typically involves physicians identifying lung nodules in Computed tomography (CT) scans and generating diagnostic reports based on their morphological features and medical expertise. Although advancements have been made in using multimodal large language models for analyzing lung CT scans, challenges remain in accurately describing nodule morphology and incorporating medical expertise. These limitations affect the reliability and effectiveness of these models in clinical settings. Collaborative multi-agent systems offer a promising strategy for achieving a balance between generality and precision in medical applications, yet their potential in pathology has not been thoroughly explored. To bridge these gaps, we introduce LungNoduleAgent, an innovative collaborative multi-agent system specifically designed for analyzing lung CT scans. LungNoduleAgent streamlines the diagnostic process into sequential components, improving precision in describing nodules and grading malignancy through three primary modules. The first module, the Nodule Spotter, coordinates clinical detection models to accurately identify nodules. The second module, the Radiologist, integrates localized image description techniques to produce comprehensive CT reports. Finally, the Doctor Agent System performs malignancy reasoning by using images and CT reports, supported by a pathology knowledge base and a multi-agent system framework. Extensive testing on two private datasets and the public LIDC-IDRI dataset indicates that LungNoduleAgent surpasses mainstream vision-language models, agent systems, and advanced expert models. These results highlight the importance of region-level semantic alignment and multi-agent collaboration in diagnosing nodules. LungNoduleAgent stands out as a promising foundational tool for supporting clinical analyses of lung nodules.

</details>


### [90] [PG-ControlNet: A Physics-Guided ControlNet for Generative Spatially Varying Image Deblurring](https://arxiv.org/abs/2511.21043)
*Hakki Motorcu,Mujdat Cetin*

Main category: cs.CV

> 本文提出了一种新框架，结合物理约束和生成模型，解决了复杂背景下空间变化图像去模糊问题，性能优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 解决复杂运动和其他形式的模糊以及显著噪声下的空间变化图像去模糊问题。现有的基于学习的方法要么产生过平滑、有瑕疵的纹理，要么在物理上约束较弱。

**Method:** 提出了一种新的框架，将强大的生成先验与明确的密集物理约束结合，通过将退化场建模为高维压缩核的密集连续体，捕捉运动和其他退化模式的微小变化，并利用该描述符场来控制ControlNet架构，从而引导扩散采样过程。

**Result:** 实验表明该方法在极具挑战性和严重模糊的情况下，能有效平衡物理准确性和感知真实性，超越现有的基于模型的方法以及生成基线方法。

**Conclusion:** 所提出的方法在物理准确性和感知真实性之间提供了有效的平衡，并在各种挑战性场景中表现出优于现有方法的性能。

**Abstract:** Spatially varying image deblurring remains a fundamentally ill-posed problem, especially when degradations arise from complex mixtures of motion and other forms of blur under significant noise. State-of-the-art learning-based approaches generally fall into two paradigms: model-based deep unrolling methods that enforce physical constraints by modeling the degradations, but often produce over-smoothed, artifact-laden textures, and generative models that achieve superior perceptual quality yet hallucinate details due to weak physical constraints. In this paper, we propose a novel framework that uniquely reconciles these paradigms by taming a powerful generative prior with explicit, dense physical constraints. Rather than oversimplifying the degradation field, we model it as a dense continuum of high-dimensional compressed kernels, ensuring that minute variations in motion and other degradation patterns are captured. We leverage this rich descriptor field to condition a ControlNet architecture, strongly guiding the diffusion sampling process. Extensive experiments demonstrate that our method effectively bridges the gap between physical accuracy and perceptual realism, outperforming state-of-the-art model-based methods as well as generative baselines in challenging, severely blurred scenarios.

</details>


### [91] [MUSE: Manipulating Unified Framework for Synthesizing Emotions in Images via Test-Time Optimization](https://arxiv.org/abs/2511.21051)
*Yingjie Xia,Xi Wang,Jinglei Shi,Vicky Kalogeiton,Jian Yang*

Main category: cs.CV

> MUSE is a unified framework for emotional image generation and editing that uses a TTS-inspired strategy and outperforms existing approaches.

<details>
  <summary>Details</summary>

**Motivation:** Current IES approaches inefficiently separate generation and editing tasks, limiting their application in areas like therapeutic interventions or storytelling. MUSE aims to address this by providing a unified framework that improves emotional accuracy and semantic diversity.

**Method:** MUSE, a unified framework for emotional image generation and editing, uses a strategy aligned with Test-Time Scaling (TTS) to leverage an off-the-shelf emotion classifier with gradient-based optimization, identify the optimal timing for emotional guidance through semantic similarity, and employ a multi-emotion loss to guide emotional synthesis.

**Result:** MUSE outperforms existing methods in both emotional image generation and editing, offering a more efficient approach to IES.

**Conclusion:** MUSE establishes a new paradigm for emotion synthesis by addressing inefficiencies in current approaches and providing a unified solution for both generation and editing.

**Abstract:** Images evoke emotions that profoundly influence perception, often prioritized over content. Current Image Emotional Synthesis (IES) approaches artificially separate generation and editing tasks, creating inefficiencies and limiting applications where these tasks naturally intertwine, such as therapeutic interventions or storytelling. In this work, we introduce MUSE, the first unified framework capable of both emotional generation and editing. By adopting a strategy conceptually aligned with Test-Time Scaling (TTS) that widely used in both LLM and diffusion model communities, it avoids the requirement for additional updating diffusion model and specialized emotional synthesis datasets. More specifically, MUSE addresses three key questions in emotional synthesis: (1) HOW to stably guide synthesis by leveraging an off-the-shelf emotion classifier with gradient-based optimization of emotional tokens; (2) WHEN to introduce emotional guidance by identifying the optimal timing using semantic similarity as a supervisory signal; and (3) WHICH emotion to guide synthesis through a multi-emotion loss that reduces interference from inherent and similar emotions. Experimental results show that MUSE performs favorably against all methods for both generation and editing, improving emotional accuracy and semantic diversity while maintaining an optimal balance between desired content, adherence to text prompts, and realistic emotional expression. It establishes a new paradigm for emotion synthesis.

</details>


### [92] [Long-Term Alzheimers Disease Prediction: A Novel Image Generation Method Using Temporal Parameter Estimation with Normal Inverse Gamma Distribution on Uneven Time Series](https://arxiv.org/abs/2511.21057)
*Xin Hong,Xinze Sun,Yinhao Li,Yen-Wei Chen*

Main category: cs.CV

> 针对AD图像生成面临的时间不规则间隔难题，研究引入T-NIG模型，在正态逆伽玛分布中加入时间参数，通过不确定性估计减少模型中的不确定性，实验显示其在疾病进展预测中表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 在预测阿尔茨海默症（AD）时，图片生成可为大夫提供成像诊断依据。然而，近期研究表明，长期AD预测常常面临维持疾病相关特征的困难，尤其是在处理序列数据中的不规则时间间隔方面。

**Method:** 此研究提出了一种名为T-NIG（带时间参数的正态逆伽玛分布）的模型，以辅助长期生成图像。T-NIG模型用两个不同时间点的大脑图像创建中间的大脑图像，并对未来图像和疾病进行预测。它利用坐标邻域来识别特征，并在正态逆伽玛分布中加入了时间参数，来理解在时间间隔不同的大脑成像序列中特征的变化。此外，T-NIG模型利用不确定性估计方法来降低由于时间数据不足而导致的表观不确定性和系统不确定性。

**Result:** 实验结果表明，即使是面对不规则的时间数据分布，T-NIG模型在预测疾病进展的同时也能够保持疾病相关特征，并在数据集中实现了短期和长期预测任务的顶级性能。

**Conclusion:** T-NIG模型能够有效解决由于不规则时间间隔带来的AD行预测挑战，在短期和长期图像生成任务中表现出色。

**Abstract:** Image generation can provide physicians with an imaging diagnosis basis in the prediction of Alzheimer's Disease (AD). Recent research has shown that long-term AD predictions by image generation often face difficulties maintaining disease-related characteristics when dealing with irregular time intervals in sequential data. Considering that the time-related aspects of the distribution can reflect changes in disease-related characteristics when images are distributed unevenly, this research proposes a model to estimate the temporal parameter within the Normal Inverse Gamma Distribution (T-NIG) to assist in generating images over the long term. The T-NIG model employs brain images from two different time points to create intermediate brain images, forecast future images, and predict the disease. T-NIG is designed by identifying features using coordinate neighborhoods. It incorporates a time parameter into the normal inverse gamma distribution to understand how features change in brain imaging sequences that have varying time intervals. Additionally, T-NIG utilizes uncertainty estimation to reduce both epistemic and aleatoric uncertainties in the model, which arise from insufficient temporal data. In particular, the T-NIG model demonstrates state-of-the-art performance in both short-term and long-term prediction tasks within the dataset. Experimental results indicate that T-NIG is proficient in forecasting disease progression while maintaining disease-related characteristics, even when faced with an irregular temporal data distribution.

</details>


### [93] [MIRA: Multimodal Iterative Reasoning Agent for Image Editing](https://arxiv.org/abs/2511.21087)
*Ziyun Zeng,Hang Hua,Jiebo Luo*

Main category: cs.CV

> 我们提出MIRA，一个轻量级的、插件式的多模态推理代理，通过迭代感知-推理-行动循环来改进图像编辑，特别是在处理复杂编辑指令时。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在理解复杂的用户指令时往往表现不佳，特别是那些涉及组合关系、情境线索或指代表达的命令，这导致了偏离语义或未能反映预期更改的编辑。

**Method:** Instruction-guided image editing通过自然语言让用户编辑图像。MIRA通过使用迭代感知-推理-行动循环来进行更准确的编辑，该循环模拟了多轮的人-模型交互过程。MIRA逐步预测原子编辑指令，并利用视觉反馈进行决策。

**Result:** 结合一个含有150K多模态工具使用的数据集MIRA-Editing和两阶段SFT + GRPO训练流程，MIRA在处理复杂编辑指令方面能进行有效推理和编辑。搭配开源图像编辑模型时，MIRA显著提升了语义一致性和视觉质量，性能可媲美甚至超过专有系统GPT-Image和Nano-Banana。

**Conclusion:** MIRA能有效解决现有模型在编辑复杂图像时的不足，提供与专有系统相匹敌的编辑质量。

**Abstract:** Instruction-guided image editing offers an intuitive way for users to edit images with natural language. However, diffusion-based editing models often struggle to accurately interpret complex user instructions, especially those involving compositional relationships, contextual cues, or referring expressions, leading to edits that drift semantically or fail to reflect the intended changes. We tackle this problem by proposing MIRA (Multimodal Iterative Reasoning Agent), a lightweight, plug-and-play multimodal reasoning agent that performs editing through an iterative perception-reasoning-action loop, effectively simulating multi-turn human-model interaction processes. Instead of issuing a single prompt or static plan, MIRA predicts atomic edit instructions step by step, using visual feedback to make its decisions. Our 150K multimodal tool-use dataset, MIRA-Editing, combined with a two-stage SFT + GRPO training pipeline, enables MIRA to perform reasoning and editing over complex editing instructions. When paired with open-source image editing models such as Flux.1-Kontext, Step1X-Edit, and Qwen-Image-Edit, MIRA significantly improves both semantic consistency and perceptual quality, achieving performance comparable to or exceeding proprietary systems such as GPT-Image and Nano-Banana.

</details>


### [94] [CLRecogEye : Curriculum Learning towards exploiting convolution features for Dynamic Iris Recognition](https://arxiv.org/abs/2511.21097)
*Geetanjali Sharma,Gaurav Jaswal,Aditya Nigam,Raghavendra Ramachandra*

Main category: cs.CV

> 本文针对虹膜认证中存在的挑战提出了一种新的匹配管道，通过3D-CNN和课程学习，提高了嵌入的区分性，改善了虹膜认证的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管虹膜认证算法已经取得了显著的识别性能，但它们仍然受到旋转、尺度变化、镜面反射和散焦模糊等变化的挑战。现有的大多数方法依赖于简单的点对点比较，未能充分利用虹膜模式的时空结构。

**Method:** 本文提出了一种新的匹配管道，该管道学习了虹膜特征的丰富时空结构。通过将每个虹膜图像沿一个维度分割，生成一系列子图像作为3D-CNN的输入，该方法可以捕捉空间和时空线索。此外，通过以课程学习的方式训练模型，使得网络能够将时间依赖性直接嵌入到特征空间中，从而增强在深度度量领域中的区分度。

**Result:** 该框架通过三重损失和ArcFace损失进行端到端训练，使得即使面对旋转、尺度变化、反射和模糊等挑战，也能产生具有高度区分性的嵌入，实现了鲁棒性和泛化性的提升。

**Conclusion:** 研究提出的方法为虹膜认证提供了一种稳健且通用的解决方案。

**Abstract:** Iris authentication algorithms have achieved impressive recognition performance, making them highly promising for real-world applications such as border control, citizen identification, and both criminal investigations and commercial systems. However, their robustness is still challenged by variations in rotation, scale, specular reflections, and defocus blur. In addition, most existing approaches rely on straightforward point-to-point comparisons, typically using cosine or L2 distance, without effectively leveraging the spatio-spatial-temporal structure of iris patterns. To address these limitations, we propose a novel and generalized matching pipeline that learns rich spatio-spatial-temporal representations of iris features. Our approach first splits each iris image along one dimension, generating a sequence of sub-images that serve as input to a 3D-CNN, enabling the network to capture both spatial and spatio-spatial-temporal cues. To further enhance the modeling of spatio-spatial-temporal feature dynamics, we train the model in curriculum manner. This design allows the network to embed temporal dependencies directly into the feature space, improving discriminability in the deep metric domain. The framework is trained end-to-end with triplet and ArcFace loss in a curriculum manner, enforcing highly discriminative embeddings despite challenges like rotation, scale, reflections, and blur. This design yields a robust and generalizable solution for iris authentication.Github code: https://github.com/GeetanjaliGTZ/CLRecogEye

</details>


### [95] [Pygmalion Effect in Vision: Image-to-Clay Translation for Reflective Geometry Reconstruction](https://arxiv.org/abs/2511.21098)
*Gayoung Lee,Junho Kim,Jin-Hwa Kim,Junmo Kim*

Main category: cs.CV

> 本研究提出了“视觉的皮格马利翁效应”框架，通过图像到粘土的翻译方法，成功解决了多视角图像中反射物体的三维重建问题，显著提升了法线准确性和网格完整性。

<details>
  <summary>Details</summary>

**Motivation:** 在三维重建中，反射一直是一个长期存在的挑战，因为它会将外观和几何结构混淆在一起。本研究旨在解决这一问题，通过一种新的方法来处理反射所引起的复杂情况。

**Method:** 本研究提出一个名为“视觉的皮格马利翁效应”的新框架，该框架能够通过图像到粘土的转换来处理反射物体，从而在多视角图像中实现稳健的三维重建。通过构建双分支网络，其中一个基于BRDF的分支负责反射光的抑制，而另一个以粘土引导的分支则用于稳定几何结构和细化表面法线。两个分支使用合成的类粘土图像进行联合训练，这些图像提供了无反射的监督信号，有助于解决反射带来的问题。

**Result:** 实验结果表明，不论是使用合成数据还是真实数据，该方法在法线准确性和网格完整性上都显著优于现有处理反射的方法。

**Conclusion:** 通过将辐射转换为中性，这种框架揭示了在处理反射物体几何学习时，其可以作为一种强有力的归纳偏置。

**Abstract:** Understanding reflection remains a long-standing challenge in 3D reconstruction due to the entanglement of appearance and geometry under view-dependent reflections. In this work, we present the Pygmalion Effect in Vision, a novel framework that metaphorically "sculpts" reflective objects into clay-like forms through image-to-clay translation. Inspired by the myth of Pygmalion, our method learns to suppress specular cues while preserving intrinsic geometric consistency, enabling robust reconstruction from multi-view images containing complex reflections. Specifically, we introduce a dual-branch network in which a BRDF-based reflective branch is complemented by a clay-guided branch that stabilizes geometry and refines surface normals. The two branches are trained jointly using the synthesized clay-like images, which provide a neutral, reflection-free supervision signal that complements the reflective views. Experiments on both synthetic and real datasets demonstrate substantial improvement in normal accuracy and mesh completeness over existing reflection-handling methods. Beyond technical gains, our framework reveals that seeing by unshining, translating radiance into neutrality, can serve as a powerful inductive bias for reflective object geometry learning.

</details>
