<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 35]
- [cs.CV](#cs.CV) [Total: 39]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [StreetMath: Study of LLMs' Approximation Behaviors](https://arxiv.org/abs/2510.25776)
*Chiung-Yi Tseng,Somshubhra Roy,Maisha Thasin,Danyang Zhang,Blessing Effiong*

Main category: cs.CL

> 提出了StreetMath评测模型在实际近似计算中的能力，发现大多数模型不倾向于或无法有效地进行近似推理。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的精确算术运算能力已有大量研究，但它们在非正式、快速数学运算中的近似推理能力研究较少。本研究填补了这一空白。

**Method:** 提出了StreetMath基准测试来评估大型语言模型在现实世界近似计算情景下的能力。测试涵盖不同架构的模型，并使用机制可解释性技术探究模型的内在计算状态。

**Result:** 分析结果显示，大多数模型仍试图计算精确值甚至调用外部工具，尽管某些模型在早期层或步骤中达到了正确答案，但在解决近似任务时仍消耗更多tokens。进一步实验表明，精确和近似算术操作主要依赖于不同的神经组件。

**Conclusion:** 根据认知心理学研究，大型语言模型在街头数学环境下并不表现出人类一样的认知吝啬。

**Abstract:** There is a substantial body of literature examining the mathematical
reasoning capabilities of large language models (LLMs), particularly their
performance on precise arithmetic operations in autoregressive architectures.
However, their ability to perform approximate reasoning in informal, fast-paced
mathematical operations has received far less attention, especially among
non-autoregressive decoder models. Our work addresses this gap by introducing
StreetMath, a benchmark designed to evaluate models' approximation abilities
under real-world approximation scenarios. We conduct extensive evaluations
across different LLM architectures: Qwen3-4B-Instruct-2507,
Qwen3-4B-Thinking-2507, Dream-v0-Instruct-7B, Falcon-Mamba-7B-Instruct, and
Mamba-GPT-3B. Furthermore, we apply mechanistic interpretability techniques to
probe their internal computational states. Our analysis reveals that LLMs
generally attempt to compute exact values or invoke external tools even in
tasks that call for approximation. Moreover, while models sometimes reach the
correct answer in early layers or steps, they still consume more tokens when
solving approximation tasks. Additional experiments indicate that exact and
approximate arithmetic operations rely on largely separate neural components.
Drawing upon research on cognitive psychology, we argue that LLMs do not
exhibit cognitive miserliness in the same way humans do in street math
settings. We open source our work https://github.com/ctseng777/StreetMath

</details>


### [2] [Review Based Entity Ranking using Fuzzy Logic Algorithmic Approach: Analysis](https://arxiv.org/abs/2510.25778)
*Pratik N. Kalamkar,Anupama G. Phakatkar*

Main category: cs.CL

> 本文提出基于意见词汇强度分析的方法，通过模糊逻辑分类和句法依赖解析，对实体评价进行细化，从而改善实体排名的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 整体基于词汇的方法不考虑每个意见的强度，即意见是强烈负面（或正面）、中度负面（或正面）、非常轻微负面（或正面）和轻微负面（或正面）。本文旨在改进这一方法，通过考虑意见强度来提升实体评价的准确度。

**Method:** 本文提出了结合意见词汇和模糊逻辑算法的方法，用于根据用户查询和实体评论的情感倾向和强度对实体进行排名。通过将意见词汇（如副词、形容词、名词和动词）分类为不同的程度等级（非常弱、弱、中等、非常强和强），并使用句法依赖解析来发现与感兴趣方面相关的词汇关系。

**Result:** 本文的方法能够通过对意见强度的考虑，使实体评价更加细化且准确。

**Conclusion:** 结合模糊逻辑和句法依赖解析的方法能有效提高基于意见的实体排名的准确性和细致化程度。通过这种改进，评价的实用性得到提升。

**Abstract:** Opinion mining, also called sentiment analysis, is the field of study that
analyzes people opinions, sentiments, evaluations, appraisals, attitudes, and
emotions towards entities such as products, services, organizations,
individuals, issues, events, topics, and their attributes. Holistic
lexicon-based approach does not consider the strength of each opinion, i.e.,
whether the opinion is very strongly negative (or positive), strongly negative
(or positive), moderate negative (or positive), very weakly negative (or
positive) and weakly negative (or positive). In this paper, we propose approach
to rank entities based on orientation and strength of the entity reviews and
user's queries by classifying them in granularity levels (i.e. very weak, weak,
moderate, very strong and strong) by combining opinion words (i.e. adverb,
adjective, noun and verb) that are related to aspect of interest of certain
product. We shall use fuzzy logic algorithmic approach in order to classify
opinion words into different category and syntactic dependency resolution to
find relations for desired aspect words. Opinion words related to certain
aspects of interest are considered to find the entity score for that aspect in
the review.

</details>


### [3] [LASTIST: LArge-Scale Target-Independent STance dataset](https://arxiv.org/abs/2510.25783)
*DongJae Kim,Yaejin Lee,Minsu Park,Eunil Park*

Main category: cs.CL

> 研究提出了LASTIST数据集，以填补韩语目标无关立场检测任务的数据空缺，适用于多种检测任务。

<details>
  <summary>Details</summary>

**Motivation:** 尽管立场检测研究领域取得了进展，但在目标无关立场检测以及低资源语言（如韩语）上存在不足。研究旨在解决这些问题。

**Method:** 该研究提出了LArge-Scale Target-Independent STance (LASTIST) 数据集，填补了研究空缺。数据集来源于韩国民间党派的新闻稿，包含563,299个韩语句子标签。

**Result:** 构建了一个详细的LASTIST数据集，并训练了最先进的深度学习和立场检测模型。

**Conclusion:** LASTIST数据集适用于不同类型的立场检测任务，并已部署在其网站上供研究使用。

**Abstract:** Stance detection has emerged as an area of research in the field of
artificial intelligence. However, most research is currently centered on the
target-dependent stance detection task, which is based on a person's stance in
favor of or against a specific target. Furthermore, most benchmark datasets are
based on English, making it difficult to develop models in low-resource
languages such as Korean, especially for an emerging field such as stance
detection. This study proposes the LArge-Scale Target-Independent STance
(LASTIST) dataset to fill this research gap. Collected from the press releases
of both parties on Korean political parties, the LASTIST dataset uses 563,299
labeled Korean sentences. We provide a detailed description of how we collected
and constructed the dataset and trained state-of-the-art deep learning and
stance detection models. Our LASTIST dataset is designed for various tasks in
stance detection, including target-independent stance detection and diachronic
evolution stance detection. We deploy our dataset on
https://anonymous.4open.science/r/LASTIST-3721/.

</details>


### [4] [zFLoRA: Zero-Latency Fused Low-Rank Adapters](https://arxiv.org/abs/2510.25784)
*Dhananjaya Gowda,Seoha Song,Harshith Goka,Junhyun Lee*

Main category: cs.CL

> 研究提出了一种新的零延迟融合低秩适配器（zFLoRA），在不增加延迟的情况下，表现优于现有的低秩适配器和全微调方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的任务特定适配器在推理时间引入了不成比例的计算负担，即使其参数量相对较小。因此，需要开发新的适配器来消除延迟问题。

**Method:** Structure

**Result:** {
  "tldr": "研究提出了一种新的零延迟融合低秩适配器（zFLoRA），在不增加延迟的情况下，表现优于现有的低秩适配器和全微调方法。", 
  "motivation": "现有的任务特定适配器在推理时间引入了不成比例的计算负担，即使其参数量相对较小。因此，需要开发新的适配器来消除延迟问题。", 
  "method": "提出了一种零延迟的融合低秩适配器（zFLoRA），旨在在不增加延迟的情况下提升模型性能。", 
  "result": "实验表明，zFLoRA在1B、3B和7B大小的大型语言模型上性能优于低秩适配器（LoRA）和全微调（FFT）方法，并且在NPU和GPU平台上几乎不增加延迟。", 
  "conclusion": "zFLoRA提供了一种有效的方法，既提高了模型性能，又避免了引入额外的延迟。"}
}


**Conclusion:** zFLoRA提供了一种有效的方法，既提高了模型性能，又避免了引入额外的延迟。

**Abstract:** Large language models (LLMs) are increasingly deployed with task-specific
adapters catering to multiple downstream applications. In such a scenario, the
additional compute associated with these apparently insignificant number of
adapter parameters (typically less than 1% of the base model) turns out to be
disproportionately significant during inference time (upto 2.5x times that of
the base model). In this paper, we propose a new zero-latency fused low-rank
adapter (zFLoRA) that introduces zero or negligible latency overhead on top of
the base model. Experimental results on LLMs of size 1B, 3B and 7B show that
zFLoRA compares favorably against the popular supervised fine-tuning benchmarks
including low-rank adapters (LoRA) as well as full fine-tuning (FFT).
Experiments are conducted on 18 different tasks across three different
categories namely commonsense reasoning, math reasoning and summary-dialogue.
Latency measurements made on NPU (Samsung Galaxy S25+) as well as GPU (NVIDIA
H100) platforms show that the proposed zFLoRA adapters introduce zero to
negligible latency overhead.

</details>


### [5] [BlackboxNLP-2025 MIB Shared Task: Improving Circuit Faithfulness via Better Edge Selection](https://arxiv.org/abs/2510.25786)
*Yaniv Nikankin,Dana Arad,Itay Itzhak,Anja Reusch,Adi Simhi,Gal Kesten-Pomeranz,Yonatan Belinkov*

Main category: cs.CL

> 我们改进了电路发现方法，使之在机械解释性基准测试中的表现优于以前的方法。

<details>
  <summary>Details</summary>

**Motivation:** 解决模型中各部分执行特定任务的识别问题，是机械解释性中的主要挑战之一。

**Method:** 我们提出三种关键改进以提高电路发现的准确性。首先，使用自助法来识别具有稳定归因分数的边缘。其次，引入基于比率的选择策略，以优先考虑高正向得分的边缘，同时平衡性能和保真度。最后，我们用整数线性规划替代了标准的贪婪选择策略。

**Result:** 我们的方法在多个MIB任务和模型中产生了保真度更高的电路，且优于先前的方法。

**Conclusion:** 这些改进使得电路发现更准确、更具有保真度，并在多个任务中优于现有方法。代码已公开。

**Abstract:** One of the main challenges in mechanistic interpretability is circuit
discovery, determining which parts of a model perform a given task. We build on
the Mechanistic Interpretability Benchmark (MIB) and propose three key
improvements to circuit discovery. First, we use bootstrapping to identify
edges with consistent attribution scores. Second, we introduce a simple
ratio-based selection strategy to prioritize strong positive-scoring edges,
balancing performance and faithfulness. Third, we replace the standard greedy
selection with an integer linear programming formulation. Our methods yield
more faithful circuits and outperform prior approaches across multiple MIB
tasks and models. Our code is available at:
https://github.com/technion-cs-nlp/MIB-Shared-Task.

</details>


### [6] [LISTEN to Your Preferences: An LLM Framework for Multi-Objective Selection](https://arxiv.org/abs/2510.25799)
*Adam S. Jovine,Tinghan Ye,Francis Bahk,Jingjing Wang,David B. Shmoys,Peter I. Frazier*

Main category: cs.CL

>  LISTEN框架及其算法LISTEN-U和LISTEN-T被提出，以解决从大量具有多个竞争目标的项目中选择最优项的问题。通过利用大语言模型作为偏好预测工具，简化传统偏好提取认知负担。

<details>
  <summary>Details</summary>

**Motivation:** 人类专家在从大量项目中选择最优选项时会遇到困难，特别是在有多重竞争目标的情况下，这一过程被正式化复杂且隐性偏好的难度所限制。解决此问题，特别是在减少传统偏好提取的认知负担方面，该工作探索了直接使用自然语言引导复杂多目标决策的可能性。

**Method:** 介绍了一种名为LISTEN的框架，该框架利用大语言模型作为零样本偏好预测工具，仅由专家以自然语言形式提供的高层次优先级指导。为了在大语言模型的约束下（如上下文窗口和推理成本）工作，提出了两种迭代算法：LISTEN-U和LISTEN-T。LISTEN-U使用大语言模型来优化参数化效用函数；LISTEN-T则是一种非参数方法，它在小批量解决方案中执行锦标赛式选择。

**Result:** 在诸如航班预订、购物和考试安排等多种任务上的评估表明，LISTEN-U在参数一致偏好上表现出色，而LISTEN-T则显示出更稳健的表现。

**Conclusion:** 该研究表明，LISTEN-U在偏好与参数性一致的情况下表现优秀，而LISTEN-T则提供了更稳健的表现。该工作展示了一种具有潜力的多目标决策直接用自然语言引导的方法。

**Abstract:** Human experts often struggle to select the best option from a large set of
items with multiple competing objectives, a process bottlenecked by the
difficulty of formalizing complex, implicit preferences. To address this, we
introduce LISTEN, a framework that leverages a Large Language Model (LLM) as a
zero-shot preference oracle, guided only by an expert's high-level priorities
in natural language. To operate within LLM constraints like context windows and
inference costs, we propose two iterative algorithms: LISTEN-U, which uses the
LLM to refine a parametric utility function, and LISTEN-T, a non-parametric
method that performs tournament-style selections over small batches of
solutions. Evaluated on diverse tasks including flight booking, shopping, and
exam scheduling, our results show LISTEN-U excels when preferences are
parametrically aligned (a property we measure with a novel concordance metric),
while LISTEN-T offers more robust performance. This work explores a promising
direction for steering complex multi-objective decisions directly with natural
language, reducing the cognitive burden of traditional preference elicitation.

</details>


### [7] [Beyond Length: Quantifying Long-Range Information for Long-Context LLM Pretraining Data](https://arxiv.org/abs/2510.25804)
*Haoran Deng,Yingyu Lin,Zhenghao Lin,Xiao Liu,Yizhou Sun,Yi-An Ma,Yeyun Gong*

Main category: cs.CL

> 本文介绍了一个用于遴选含有长距离依赖的训练数据的框架——LongFilter，通过对比长短上下文预测结果来识别长距离依赖样本，实验结果显示LongFilter可以显著提高模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 长上下文语言模型通过利用扩展文本范围内的依赖关系解锁了先进的推理、代码生成和文档总结能力。然而，现有的大量长文本数据并不具备有意义的长距离依赖关系，大多数跨度都可以仅使用局部上下文预测，导致训练效率低下，因此需要仔细选择数据。

**Method:** 我们介绍了一个名为LongFilter的框架，用于为长上下文预训练遴选训练数据。LongFilter通过对比模型在长上下文和短上下文设置下的预测结果来衡量扩展上下文提供的信息增益，从而识别出依赖长距离依赖关系的样本。

**Result:** 在将LLaMA-3-8B的上下文长度从8K扩展至64K的实验中，LongFilter有效选择了高质量的数据，并在HELMET、LongBench和RULER等基准测试中取得显著改进。

**Conclusion:** LongFilter通过评估长距离依赖关系的重要性来选取适合长上下文预训练的数据，可以在保持训练数据量的同时有效提升模型性能。

**Abstract:** Long-context language models unlock advanced capabilities in reasoning, code
generation, and document summarization by leveraging dependencies across
extended spans of text. However, a significant portion of readily available
long-text data lacks meaningful long-distance dependencies; most spans can be
predicted using only local context. Training on such data is inefficient,
making careful data selection crucial. Therefore, we introduce LongFilter, a
framework for curating training data tailored to long-context pretraining.
LongFilter measures the information gain provided by extended context by
contrasting model predictions under long-context versus short-context settings,
thereby identifying samples where long-range dependencies are essential.
Experiments with LLaMA-3-8B, extending its context length from 8K to 64K, show
that LongFilter efficiently selects high-quality data and yields substantial
improvements on benchmarks such as HELMET, LongBench, and RULER.

</details>


### [8] [Ideology-Based LLMs for Content Moderation](https://arxiv.org/abs/2510.25805)
*Stefano Civelli,Pietro Bernardelle,Nardiena A. Pratama,Gianluca Demartini*

Main category: cs.CL

> 本研究探讨了角色扮演对不同大型语言模型架构、模型大小和内容模态（语言 vs 视觉）有害内容分类一致性和公平性的影响。结果显示，在意识形态不同的角色下，模型对内容是否有害的判断可能产生偏向。此外，大型模型更倾向于与同意识形态的角色观点一致，这揭示了角色条件可能引入微妙的意识形态偏见，给AI系统的中立性带来质疑。

<details>
  <summary>Details</summary>

**Motivation:** 探究角色扮演是否影响大型语言模型在内容审核系统中的分类结果以及它们可能引入的偏见，以确保系统的公平与中立性。

**Method:** Structure

**Result:** {
  "tldr": "本研究探讨了角色扮演对不同大型语言模型架构、模型大小和内容模态（语言 vs 视觉）有害内容分类一致性和公平性的影响。结果显示，在意识形态不同的角色下，模型对内容是否有害的判断可能产生偏向。此外，大型模型更倾向于与同意识形态的角色观点一致，这揭示了角色条件可能引入微妙的意识形态偏见，给AI系统的中立性带来质疑。",
  "motivation": "探究角色扮演是否影响大型语言模型在内容审核系统中的分类结果以及它们可能引入的偏见，以确保系统的公平与中立性。",
  "method": "研究采用不同意识形态的角色来进行有害内容分类的实验，分析整体分类准确性，同时进行一致性分析并针对政治目标任务进行了额外的实验。",
  "result": "尽管整体分类准确性差异不大，但仔细分析显示了模型在意识形态倾向上的显著变化。拥有不同意识形态的角色模型表现出有倾向性的有害内容分类，并且大型模型在自身意识形态内的一致性更强，但跨意识形态的差异更大。",
  "conclusion": "研究表明，角色条件可以引入微妙的意识形态偏见，可能影响到AI系统的中立判断，提醒我们在使用大型语言模型进行内容检测时需要关注潜在的偏见问题。建议在使用这些系统时采取措施纠正或减少这种偏见。"}
}

**Conclusion:** 研究表明，角色条件可以引入微妙的意识形态偏见，可能影响到AI系统的中立判断，提醒我们在使用大型语言模型进行内容检测时需要关注潜在的偏见问题。建议在使用这些系统时采取措施纠正或减少这种偏见。

**Abstract:** Large language models (LLMs) are increasingly used in content moderation
systems, where ensuring fairness and neutrality is essential. In this study, we
examine how persona adoption influences the consistency and fairness of harmful
content classification across different LLM architectures, model sizes, and
content modalities (language vs. vision). At first glance, headline performance
metrics suggest that personas have little impact on overall classification
accuracy. However, a closer analysis reveals important behavioral shifts.
Personas with different ideological leanings display distinct propensities to
label content as harmful, showing that the lens through which a model "views"
input can subtly shape its judgments. Further agreement analyses highlight that
models, particularly larger ones, tend to align more closely with personas from
the same political ideology, strengthening within-ideology consistency while
widening divergence across ideological groups. To show this effect more
directly, we conducted an additional study on a politically targeted task,
which confirmed that personas not only behave more coherently within their own
ideology but also exhibit a tendency to defend their perspective while
downplaying harmfulness in opposing views. Together, these findings highlight
how persona conditioning can introduce subtle ideological biases into LLM
outputs, raising concerns about the use of AI systems that may reinforce
partisan perspectives under the guise of neutrality.

</details>


### [9] [Beyond Long Context: When Semantics Matter More than Tokens](https://arxiv.org/abs/2510.25816)
*Tarun Kumar Chawdhury,Jon D. Duke*

Main category: cs.CL

> The CLEAR method, using entity-aware retrieval, improves both efficiency and accuracy in answering questions from clinical notes compared to traditional methods.

<details>
  <summary>Details</summary>

**Motivation:** To address the difficulty in extracting semantic information from EHRs due to the presence of base64 encoded attachments and the limitations of vector database methods.

**Method:** Structure

**Result:** CLEAR achieved a 58.3% win rate, improved F1 score, and required 78% fewer tokens than wide context processing, with the best performance on long clinical notes.

**Conclusion:** Entity-aware retrieval methods, like CLEAR, enhance both accuracy and computational efficiency in clinical NLP tasks, offering a reusable evaluation framework for such systems.

**Abstract:** Electronic Health Records (EHR) store clinical documentation as base64
encoded attachments in FHIR DocumentReference resources, which makes semantic
question answering difficult. Traditional vector database methods often miss
nuanced clinical relationships. The Clinical Entity Augmented Retrieval (CLEAR)
method, introduced by Lopez et al. 2025, uses entity aware retrieval and
achieved improved performance with an F1 score of 0.90 versus 0.86 for
embedding based retrieval, while using over 70 percent fewer tokens. We
developed a Clinical Notes QA Evaluation Platform to validate CLEAR against
zero shot large context inference and traditional chunk based retrieval
augmented generation. The platform was tested on 12 clinical notes ranging from
10,000 to 65,000 tokens representing realistic EHR content. CLEAR achieved a
58.3 percent win rate, an average semantic similarity of 0.878, and used 78
percent fewer tokens than wide context processing. The largest performance
gains occurred on long notes, with a 75 percent win rate for documents
exceeding 65,000 tokens. These findings confirm that entity aware retrieval
improves both efficiency and accuracy in clinical natural language processing.
The evaluation framework provides a reusable and transparent benchmark for
assessing clinical question answering systems where semantic precision and
computational efficiency are critical.

</details>


### [10] [A Survey on Efficient Large Language Model Training: From Data-centric Perspectives](https://arxiv.org/abs/2510.25817)
*Junyu Luo,Bohan Wu,Xiao Luo,Zhiping Xiao,Yiqiao Jin,Rong-Cheng Tu,Nan Yin,Yifan Wang,Jingyang Yuan,Wei Ju,Ming Zhang*

Main category: cs.CL

> 本文首次从数据为中心的角度系统概述数据高效的大规模语言模型微调方法，提出了一种分类方法，总结了各领域的代表性方法，并探讨了未来的研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型在任务泛化和特定领域能力方面非常关键，但现有的微调范式面临着数据获取与人工标注成本高的问题，因此，如何实现数据高效微调成为了核心研究问题。

**Method:** 我们从数据为中心的角度，首次系统地概述了数据高效的大规模语言模型微调方法，包括数据选择、数据质量提升、合成数据生成、数据蒸馏与压缩、自我演化的数据生态系统。

**Result:** 通过对数据高效大规模语言模型微调的挑战进行考察，我们突出了开放的研究问题并提出了潜在的研究方向。

**Conclusion:** 我们提出了一种数据高效大规模语言模型微调的分类法，并总结了代表性的方法，指出了该领域的未来研究方向，为最大化数据在大规模模型训练中的利用潜力提供了新的探索途径。

**Abstract:** Post-training of Large Language Models (LLMs) is crucial for unlocking their
task generalization potential and domain-specific capabilities. However, the
current LLM post-training paradigm faces significant data challenges, including
the high costs of manual annotation and diminishing marginal returns on data
scales. Therefore, achieving data-efficient post-training has become a key
research question. In this paper, we present the first systematic survey of
data-efficient LLM post-training from a data-centric perspective. We propose a
taxonomy of data-efficient LLM post-training methods, covering data selection,
data quality enhancement, synthetic data generation, data distillation and
compression, and self-evolving data ecosystems. We summarize representative
approaches in each category and outline future research directions. By
examining the challenges in data-efficient LLM post-training, we highlight open
problems and propose potential research avenues. We hope our work inspires
further exploration into maximizing the potential of data utilization in
large-scale model training. Paper List:
https://github.com/luo-junyu/Awesome-Data-Efficient-LLM

</details>


### [11] [Evaluating the Impact of LLM-Assisted Annotation in a Perspectivized Setting: the Case of FrameNet Annotation](https://arxiv.org/abs/2510.25904)
*Frederico Belcavello,Ely Matos,Arthur Lorenzi,Lisandra Bonoto,Lívia Ruiz,Luiz Fernando Pereira,Victor Herbst,Yulla Navarro,Helen de Andrade Abreu,Lívia Dutra,Tiago Timponi Torrent*

Main category: cs.CL

> An extensive evaluation finds that semi-automatic annotation using LLM-based semantic role labelers can enhance frame diversity and maintain annotation coverage, superior to fully automatic approaches but still complimentary to manual efforts in linguistic research.

<details>
  <summary>Details</summary>

**Motivation:** The study aims to fill the gap in the comprehensive evaluation of LLM-based tools in linguistic research, particularly in the context of annotated dataset creation and NLP perspectives.

**Method:** The paper evaluates the performance and impact of LLMBased tools on (semi-)automatization of FrameNet-like semantic annotation through comparing annotation time, coverage, and diversity in three settings: manual, automatic, and semi-automatic annotation.

**Result:** The semi-automatic annotation setting results in increased frame diversity and similar annotation coverage compared to the human-only setting. The automatic setting performs poorly in all metrics except for annotation speed.

**Conclusion:** Hybrid, semi-automatic annotation using LLM-based tools is effective for increasing frame diversity and maintaining acceptable coverage of annotations, providing a valuable approach for linguistic research and resource construction.

**Abstract:** The use of LLM-based applications as a means to accelerate and/or substitute
human labor in the creation of language resources and dataset is a reality.
Nonetheless, despite the potential of such tools for linguistic research,
comprehensive evaluation of their performance and impact on the creation of
annotated datasets, especially under a perspectivized approach to NLP, is still
missing. This paper contributes to reduction of this gap by reporting on an
extensive evaluation of the (semi-)automatization of FrameNet-like semantic
annotation by the use of an LLM-based semantic role labeler. The methodology
employed compares annotation time, coverage and diversity in three experimental
settings: manual, automatic and semi-automatic annotation. Results show that
the hybrid, semi-automatic annotation setting leads to increased frame
diversity and similar annotation coverage, when compared to the human-only
setting, while the automatic setting performs considerably worse in all
metrics, except for annotation time.

</details>


### [12] [RECAP: Reproducing Copyrighted Data from LLMs Training with an Agentic Pipeline](https://arxiv.org/abs/2510.25941)
*André V. Duarte,Xuying li,Bin Zeng,Arlindo L. Oliveira,Lei Li,Zhuo Li*

Main category: cs.CL

> 研究提出了RECAP管道，用于从大型语言模型输出中提取并验证其训练数据的记忆情况，利用反馈循环提高一致性，破解模块克服执行障碍，并以EchoTrace基准测试表明其相对于单次迭代方法有显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于探索一种方法来验证大型语言模型是否以及如何记住了其训练数据。特别是，在无法直接查看训练数据的情况下，通过分析模型生成的输出来推断其训练数据的内容。

**Method:** RECAP方法是一个设计用于从大型语言模型输出中提取并验证其记忆训练数据的智能管道。该方法的核心是一个反馈循环，初始提取尝试后，会有一个辅助语言模型来评估提取的内容，比较其与参考文本的差异，并将差异转化为简短的修正提示，再次输入目标模型以指导进一步的生成过程。此外，为了处理模型因对齐导致的拒绝行为，RECAP还包括了一个破解模块来探测并克服这些障碍。

**Result:** 在评估中，使用EchoTrace基准（包含超过30本完整的书籍），RECAP在提取语言模型记忆中的训练数据方面取得了比单次迭代方法更好的性能，特别是在使用GPT-4.1时，提取受版权保护文本的平均ROUGE-L分数有了显著的提升。

**Conclusion:** 结论表明，RECAP在提取语言模型记忆中的训练数据方面，与单次迭代方法相比取得了实质性的性能提升，特别是在使用GPT-4.1时，提取的受版权保护的文本的平均ROUGE-L分数提高到了0.47，相较之前的0.38有接近24%的提升。

**Abstract:** If we cannot inspect the training data of a large language model (LLM), how
can we ever know what it has seen? We believe the most compelling evidence
arises when the model itself freely reproduces the target content. As such, we
propose RECAP, an agentic pipeline designed to elicit and verify memorized
training data from LLM outputs. At the heart of RECAP is a feedback-driven
loop, where an initial extraction attempt is evaluated by a secondary language
model, which compares the output against a reference passage and identifies
discrepancies. These are then translated into minimal correction hints, which
are fed back into the target model to guide subsequent generations. In
addition, to address alignment-induced refusals, RECAP includes a jailbreaking
module that detects and overcomes such barriers. We evaluate RECAP on
EchoTrace, a new benchmark spanning over 30 full books, and the results show
that RECAP leads to substantial gains over single-iteration approaches. For
instance, with GPT-4.1, the average ROUGE-L score for the copyrighted text
extraction improved from 0.38 to 0.47 - a nearly 24% increase.

</details>


### [13] [Revisiting Multilingual Data Mixtures in Language Model Pretraining](https://arxiv.org/abs/2510.25947)
*Negar Foroutan,Paul Teiletche,Ayush Kumar Tarun,Antoine Bosselut*

Main category: cs.CL

> 研究发现，在适当平衡的情况下，多语言数据可以提升语言模型的能力，而且不会显著降低性能，即便是在低资源语言环境中也是如此。

<details>
  <summary>Details</summary>

**Motivation:** 探讨多语言语料库的混合对预训练大型语言模型(LLMs)的影响，挑战关于语言覆盖范围和模型性能之间存在权衡的常见假设。

**Method:** 训练了参数量为11亿和30亿的大型语言模型(LLMs)，采用了从25种到400种语言的多语言语料库，研究多语言训练中的假设。

**Result:** 1) 结合英语和其他多语言数据并不会必然导致任何一方的性能下降，只要每种语言有足够的标记存在于预训练语料库中；2) 使用像英语这样的枢纽语言（高资源语言，促进了多语言泛化）能带来跨语系的好处。选择特定语系中的枢纽语言，一致性地提高该语系内部语言的性能这一预期效果并不明显。3) 随着训练语言数量的增加，模型规模在此级别下并没有显著的“多语言诅咒”。

**Conclusion:** 当适度平衡时，多语言数据可以提升语言模型能力，甚至在低资源场景下也不致妥协性能。

**Abstract:** The impact of different multilingual data mixtures in pretraining large
language models (LLMs) has been a topic of ongoing debate, often raising
concerns about potential trade-offs between language coverage and model
performance (i.e., the curse of multilinguality). In this work, we investigate
these assumptions by training 1.1B and 3B parameter LLMs on diverse
multilingual corpora, varying the number of languages from 25 to 400. Our study
challenges common beliefs surrounding multilingual training. First, we find
that combining English and multilingual data does not necessarily degrade the
in-language performance of either group, provided that languages have a
sufficient number of tokens included in the pretraining corpus. Second, we
observe that using English as a pivot language (i.e., a high-resource language
that serves as a catalyst for multilingual generalization) yields benefits
across language families, and contrary to expectations, selecting a pivot
language from within a specific family does not consistently improve
performance for languages within that family. Lastly, we do not observe a
significant "curse of multilinguality" as the number of training languages
increases in models at this scale. Our findings suggest that multilingual data,
when balanced appropriately, can enhance language model capabilities without
compromising performance, even in low-resource settings

</details>


### [14] [Semantic Label Drift in Cross-Cultural Translation](https://arxiv.org/abs/2510.25967)
*Mohsinul Kabir,Tasnim Ahmed,Md Mezbaur Rahman,Polydoros Giannouris,Sophia Ananiadou*

Main category: cs.CL

> 本研究通过实验发现，现代MT系统，特别是大型语言模型（LLMs），在翻译中，特别是在文化敏感领域，会导致标签漂移。文化相似性对标签保存至关重要，而忽视文化因素则可能引发误解和文化冲突。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是机器翻译虽然常用于解决低资源语言的数据稀缺问题，但对文化对齐在翻译中的作用探索不足。本研究假设由于文化差异，MT过程会导致语义标签的漂移或改变。

**Method:** 本研究通过在文化敏感和中性领域进行一系列实验，探讨了在机器翻译（MT）过程中标签漂移的问题，特别是在文化差异导致的文化偏差下。

**Result:** 研究结果显示，在文化敏感的领域，MT尤其是大型语言模型（LLMs）容易引发标签漂移；LLMs比传统的统计模型更多编码了文化知识，可能导致标签漂移加剧；源语言和目标语言的文化相似性是标签保存的关键。

**Conclusion:** 研究结论指出，忽略文化因素不仅会损害标签的准确性，也会增加下游应用中的误解和文化冲突的风险。

**Abstract:** Machine Translation (MT) is widely employed to address resource scarcity in
low-resource languages by generating synthetic data from high-resource
counterparts. While sentiment preservation in translation has long been
studied, a critical but underexplored factor is the role of cultural alignment
between source and target languages. In this paper, we hypothesize that
semantic labels are drifted or altered during MT due to cultural divergence.
Through a series of experiments across culturally sensitive and neutral
domains, we establish three key findings: (1) MT systems, including modern
Large Language Models (LLMs), induce label drift during translation,
particularly in culturally sensitive domains; (2) unlike earlier statistical MT
tools, LLMs encode cultural knowledge, and leveraging this knowledge can
amplify label drift; and (3) cultural similarity or dissimilarity between
source and target languages is a crucial determinant of label preservation. Our
findings highlight that neglecting cultural factors in MT not only undermines
label fidelity but also risks misinterpretation and cultural conflict in
downstream applications.

</details>


### [15] [SymCode: A Neurosymbolic Approach to Mathematical Reasoning via Verifiable Code Generation](https://arxiv.org/abs/2510.25975)
*Sina Bagheri Nezhad,Yao Li,Ameeta Agrawal*

Main category: cs.CL

> 提出SymCode框架，改善了大型语言模型在数学推理中的准确性，提升了生成结果的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 解决大型语言模型在复杂数学推理上的局限性，这些模型生成的文本往往不可靠且缺乏算术准确性。现有提示策略如链式思考也存在类似问题。

**Method:** 引入了名为SymCode的神经符号框架，该框架以使用SymPy库生成可验证代码的方式重新定义了数学问题求解任务。

**Result:** 在MATH-500和OlympiadBench等挑战性基准上，SymCode展示了比基线模型高13.6个百分点的准确性提升，并且证明了它在代碼效率上的优势。

**Conclusion:** SymCode通过将LLM推理植根于确定性符号引擎，显著提高了准确性与可信度，是AI在形式化领域发展的重要一步。

**Abstract:** Large Language Models (LLMs) often struggle with complex mathematical
reasoning, where prose-based generation leads to unverified and arithmetically
unsound solutions. Current prompting strategies like Chain of Thought still
operate within this unreliable medium, lacking a mechanism for deterministic
verification. To address these limitations, we introduce SymCode, a
neurosymbolic framework that reframes mathematical problem-solving as a task of
verifiable code generation using the SymPy library. We evaluate SymCode on
challenging benchmarks, including MATH-500 and OlympiadBench, demonstrating
significant accuracy improvements of up to 13.6 percentage points over
baselines. Our analysis shows that SymCode is not only more token-efficient but
also fundamentally shifts model failures from opaque logical fallacies towards
transparent, programmatic errors. By grounding LLM reasoning in a deterministic
symbolic engine, SymCode represents a key step towards more accurate and
trustworthy AI in formal domains.

</details>


### [16] [NeuronMM: High-Performance Matrix Multiplication for LLM Inference on AWS Trainium](https://arxiv.org/abs/2510.25977)
*Dinghong Song,Jierui Xu,Weichu Yang,Pengfei Su,Dong Li*

Main category: cs.CL

> 本文为LLM推理在Trainium上设计了高性能的矩阵乘法（matmul），并以一系列自定义技术展示了相对于AWS实现的优越性。

<details>
  <summary>Details</summary>

**Motivation:** 由于Trainium的阵列架构和对数据布局的特殊要求，利用其异构架构实现高性能存在挑战。因此，需要专门针对Trainium设计高性能解决方案。

**Method:** 通过内核融合和新颖的缓存策略来减少软件管理内存层次结构之间的数据移动，最大化SRAM带宽并避免昂贵的矩阵转置，从而为Trainium设计了高性能的矩阵乘法（matmul）作为LLM推理的关键计算内核。

**Result:** 在九个数据集和四个近期LLM上进行评估，该系统的性能显著优于AWS在Trainium上实现的最先进矩阵乘法：在matmul内核级别实现了平均1.35x（最高2.22x）的速度提升，进而使得端到端LLM推理性能提高了平均1.66x（最高2.49x）速度。

**Conclusion:** 研究表明，通过专门的内核融合和缓存策略，可以显著提升基于Trainium的LLM推理的性能。

**Abstract:** AI accelerators, customized to AI workloads, provide cost-effective and
high-performance solutions for training and inference. Trainium, an AI
accelerator recently developed by Amazon Web Services (AWS), provides an
attractive option for LLM training and inference through its heterogeneous
architecture. However, leveraging Trainium architecture for high performance
can be challenging because of its systolic array architecture and special
requirement on data layout. In this paper, we design high-performance matrix
multiplication (matmul), a critical compute kernel, for LLM inference on
Trainium. We introduce a series of techniques customized to Trainium based on
kernel fusion and novel caching strategies to reduce data movement across the
software-managed memory hierarchy, maximize SRAM bandwidth, and avoid expensive
matrix transpose. Evaluating with nine datasets and four recent LLMs, we show
that our system largely outperforms the state-of-the-art matmul implemented by
AWS on Trainium: at the level of matmul kernel, it achieves an average 1.35x
speedup (up to 2.22x), which translates to an average 1.66x speedup (up to
2.49x) for end-to-end LLM inference.

</details>


### [17] [AttnCache: Accelerating Self-Attention Inference for LLM Prefill via Attention Cache](https://arxiv.org/abs/2510.25979)
*Dinghong Song,Yuan Feng,Yiwei Wang,Shangye Chen,Cyril Guyot,Filip Blagojevic,Hyeran Jeon,Pengfei Su,Dong Li*

Main category: cs.CL

> 本文提出AttnCache框架，通过检索和重用相似的注意力映射来加速大型语言模型的预填推理，显著提升计算效率，且准确度下降可忽略。

<details>
  <summary>Details</summary>

**Motivation:** 由于自注意力计算在预填阶段成为主要性能瓶颈，尤其是对于序列长度的二次复杂性。本文提出通过重用相似的注意力图来加速推理过程。

**Method:** AttnCache框架通过检索和重用相似的注意力图来加速LLM推理的预填阶段，基于注意力图记忆数据库，利用高效的缓存和技术找到并重用之前缓存的注意力图，从而减少自注意力计算的计算开销。

**Result:** 实验结果显示，在CPU上实现了平均1.2倍的端到端加速和2倍的注意力加速，在GPU上实现了1.6倍的端到端加速和3倍的注意力加速。

**Conclusion:** AttnCache在加速LLM的预填阶段推理时，对计算效率有着显著提升作用，且几乎不影响准确性。

**Abstract:** Large Language Models (LLMs) are widely used in generative applications such
as chatting, code generation, and reasoning. However, many realworld workloads
such as classification, question answering, recommendation, and text embedding
rely solely on the prefill stage of inference, where the model encodes input
sequences without performing autoregressive decoding. In these prefill only
scenarios, the self-attention computation becomes the primary performance
bottleneck due to its quadratic complexity with respect to sequence length. In
this paper, we observe that semantically different sentences often produce
similar attention maps across layers and heads. Building on this insight, we
propose AttnCache, a framework that accelerates the prefill stage of LLM
inference by retrieving and reusing similar attention maps. Based on an
attention map memorization database, AttnCache employs efficient caching and
similarity search techniques to identify and reuse pre-cached attention maps
during inference, thereby reducing the computational overhead of
self-attention. Experimental results show that AttnCache achieves an average of
1.2x end-to-end and 2x attention speedup on CPU, and 1.6x end-to-end and 3x
attention speedup on GPU, with negligible accuracy degradation.

</details>


### [18] [Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning](https://arxiv.org/abs/2510.25992)
*Yihe Deng,I-Hung Hsu,Jun Yan,Zifeng Wang,Rujun Han,Gufeng Zhang,Yanfei Chen,Wei Wang,Tomas Pfister,Chen-Yu Lee*

Main category: cs.CL

> Introduces SRL, a framework blending supervision with reinforcement learning to improve multi-step reasoning in small LLMs. SRL demonstrates strong performance and versatility across various tasks.

<details>
  <summary>Details</summary>

**Motivation:** To address the limitations of RLVR and SFT in small-scale open-source models when dealing with multi-step reasoning problems, where RLVR fails due to the rare sampling of correct solutions, and SFT overfits through rigid token-by-token imitation.

**Method:** Supervised Reinforcement Learning (SRL), a framework reformulating problem solving as generating a sequence of logical actions. It trains the model to generate an internal reasoning monologue before committing to each action with rewards based on similarity to expert actions.

**Result:** SRL enables small models to learn challenging problems previously unlearnable by SFT or RLVR. Initializing with SRL before refining with RLVR yields the strongest performance.

**Conclusion:** SRL is a robust and versatile training framework for reasoning-oriented LLMs, showing effective generalization to software engineering tasks beyond reasoning benchmarks.

**Abstract:** Large Language Models (LLMs) often struggle with problems that require
multi-step reasoning. For small-scale open-source models, Reinforcement
Learning with Verifiable Rewards (RLVR) fails when correct solutions are rarely
sampled even after many attempts, while Supervised Fine-Tuning (SFT) tends to
overfit long demonstrations through rigid token-by-token imitation. To address
this gap, we propose Supervised Reinforcement Learning (SRL), a framework that
reformulates problem solving as generating a sequence of logical "actions". SRL
trains the model to generate an internal reasoning monologue before committing
to each action. It provides smoother rewards based on the similarity between
the model's actions and expert actions extracted from the SFT dataset in a
step-wise manner. This supervision offers richer learning signals even when all
rollouts are incorrect, while encouraging flexible reasoning guided by expert
demonstrations. As a result, SRL enables small models to learn challenging
problems previously unlearnable by SFT or RLVR. Moreover, initializing training
with SRL before refining with RLVR yields the strongest overall performance.
Beyond reasoning benchmarks, SRL generalizes effectively to agentic software
engineering tasks, establishing it as a robust and versatile training framework
for reasoning-oriented LLMs.

</details>


### [19] [PORTool: Tool-Use LLM Training with Rewarded Tree](https://arxiv.org/abs/2510.26020)
*Feijie Wu,Weiwu Zhu,Yuxiang Zhang,Soumya Chatterjee,Jiarong Zhu,Fan Mo,Rodin Luo,Jing Gao*

Main category: cs.CL

> 作为一种强化学习方法，PORTool旨在通过加强工具使用语言模型的探索能力，提高其在复杂工具环境中解决问题的效果。

<details>
  <summary>Details</summary>

**Motivation:** 现有工具使用语言模型在静态数据集上训练，虽然可以与外部工具互动，并执行多步骤的工具整合推理，但它们只是简单模仿了一种通用的工具调用流程，限制了在发展动态工具调用环境下的解决问题的能力。

**Method:** PORTool 是一种强化学习方法，旨在鼓励工具使用语言模型探索可产生正确答案的多种轨迹。该方法首先为给定查询生成多个执行轨迹，部分轨迹的前几步相同，形成树状结构。接着根据步骤能否生成正确答案和成功调用工具的能力，为每个步骤分配奖励。相同的步骤获得相同的奖励，而同一分支的不同步骤则获得不同的奖励。最后，这些分步奖励用于计算分支相对优势和轨迹相对优势，并据此训练语言模型。

**Result:** 实验中使用了17种工具来回应用户查询，涵盖具有时效性和非时效性的话题内容，表明PORTool相比其他训练方法在最终准确性和工具调用步骤数量上有显著提升。

**Conclusion:** 研究通过实验与对比其他训练方法的结果表明，PORTool能显著提高工具使用语言模型的最终准确性和减少工具调用步骤数，证明了其设计的有效性。

**Abstract:** Current tool-use large language models (LLMs) are trained on static datasets,
enabling them to interact with external tools and perform multi-step,
tool-integrated reasoning, which produces tool-call trajectories. However,
these models imitate how a query is resolved in a generic tool-call routine,
thereby failing to explore possible solutions and demonstrating limited
performance in an evolved, dynamic tool-call environment. In this work, we
propose PORTool, a reinforcement learning (RL) method that encourages a
tool-use LLM to explore various trajectories yielding the correct answer.
Specifically, this method starts with generating multiple rollouts for a given
query, and some of them share the first few tool-call steps, thereby forming a
tree-like structure. Next, we assign rewards to each step, based on its ability
to produce a correct answer and make successful tool calls. A shared step
across different trajectories receives the same reward, while different steps
under the same fork receive different rewards. Finally, these step-wise rewards
are used to calculate fork-relative advantages, blended with
trajectory-relative advantages, to train the LLM for tool use. The experiments
utilize 17 tools to address user queries, covering both time-sensitive and
time-invariant topics. We conduct ablation studies to systematically justify
the necessity and the design robustness of step-wise rewards. Furthermore, we
compare the proposed PORTool with other training approaches and demonstrate
significant improvements in final accuracy and the number of tool-call steps.

</details>


### [20] [Rethinking Cross-lingual Alignment: Balancing Transfer and Cultural Erasure in Multilingual LLMs](https://arxiv.org/abs/2510.26024)
*HyoJung Han,Sweta Agrawal,Eleftheria Briakou*

Main category: cs.CL

> 研究分析了跨语言对齐的方法如何同时呈现知识转移和文化抹杀的现象，并提出了一种新方法来平衡这两个维度。

<details>
  <summary>Details</summary>

**Motivation:** 研究假设跨语言对齐在尝试对齐多语言表征时，可能会无意中导致'文化抹杀'，即在查询语言的基础上，没有呈现文化定位的回答。

**Method:** 通过引入一个整体评估框架——转移-本土化平面，该框架量化了知识转移（期望的）和文化抹杀（不期望的）的程度来系统地分析了跨语言对齐的这种权衡。

**Result:** 使用该框架重新评估了最近的跨语言对齐方法后，发现它们在六种语言上都以文化本地化为代价改善了事实知识的转移。

**Conclusion:** 基于这一发现，提出了一种新颖的推理时间方法——外科手术式导向，通过在不同层上实施定向激活导向，实现了两个竞争维度之间的更好平衡，有效地克服了当前对齐技术的局限性。

**Abstract:** Cross-lingual alignment (CLA) aims to align multilingual representations,
enabling Large Language Models (LLMs) to seamlessly transfer knowledge across
languages. While intuitive, we hypothesize, this pursuit of representational
convergence can inadvertently cause "cultural erasure", the functional loss of
providing culturally-situated responses that should diverge based on the query
language. In this work, we systematically analyze this trade-off by introducing
a holistic evaluation framework, the transfer-localization plane, which
quantifies both desirable knowledge transfer and undesirable cultural erasure.
Using this framework, we re-evaluate recent CLA approaches and find that they
consistently improve factual transfer at the direct cost of cultural
localization across all six languages studied. Our investigation into the
internal representations of these models reveals a key insight: universal
factual transfer and culturally-specific knowledge are optimally steerable at
different model layers. Based on this finding, we propose Surgical Steering, a
novel inference-time method that disentangles these two objectives. By applying
targeted activation steering to distinct layers, our approach achieves a better
balance between the two competing dimensions, effectively overcoming the
limitations of current alignment techniques.

</details>


### [21] [Artificial Intelligence-Enabled Analysis of Radiology Reports: Epidemiology and Consequences of Incidental Thyroid Findings](https://arxiv.org/abs/2510.26032)
*Felipe Larios,Mariana Borras-Osorio,Yuqi Wu,Ana Gabriela Claros,David Toro-Tobon,Esteban Cabezas,Ricardo Loor-Torres,Maria Mateo Chavez,Kerly Guevara Maldonado,Luis Vilatuna Andrango,Maria Lizarazo Jimenez,Ivan Mateo Alzamora,Misk Al Zahidy,Marcelo Montero,Ana Cristina Proano,Cristian Soto Jacome,Jungwei W. Fan,Oscar J. Ponce-Ponte,Megan E. Branda,Naykky Singh Ospina,Juan P. Brito*

Main category: cs.CL

> 研究发展和验证了一种基于NLP的流程来识别放射报告中的ITFs，发现它们与较高的甲状腺疾病诊断和癌症检测几率有关，表明需要更好的标准化报告和选择性随访。

<details>
  <summary>Details</summary>

**Motivation:** 定义ITFs的流行率、特征及其临床后果，并开发、验证和部署一种自然语言处理（NLP）流水线来识别放射学报告中的ITFs。

**Method:** 采用基于变压器的自然语言处理（NLP）流水线识别和提取来自多个成像方式和身体部位的放射学报告中的偶然性甲状腺发现（ITFs）及其结节特性。

**Result:** 在115,683名患者中，7.8%的患者有ITFs，其中92.9%为结节。ITFs常见于女性、老年人、高BMI患者、以及影像学检查由肿瘤学或内科医生开具时。ITFs与甲状腺结节诊断、活检、甲状腺切除术和甲状腺癌诊断的几率增加有关。

**Conclusion:** ITFs普遍存在，并且强烈关联于检测小风险较低癌症的后续步骤。这些发现强调了ITFs在甲状腺癌过度诊断中的作用，以及需要标准化报告和选择性随访。

**Abstract:** Importance Incidental thyroid findings (ITFs) are increasingly detected on
imaging performed for non-thyroid indications. Their prevalence, features, and
clinical consequences remain undefined. Objective To develop, validate, and
deploy a natural language processing (NLP) pipeline to identify ITFs in
radiology reports and assess their prevalence, features, and clinical outcomes.
Design, Setting, and Participants Retrospective cohort of adults without prior
thyroid disease undergoing thyroid-capturing imaging at Mayo Clinic sites from
July 1, 2017, to September 30, 2023. A transformer-based NLP pipeline
identified ITFs and extracted nodule characteristics from image reports from
multiple modalities and body regions. Main Outcomes and Measures Prevalence of
ITFs, downstream thyroid ultrasound, biopsy, thyroidectomy, and thyroid cancer
diagnosis. Logistic regression identified demographic and imaging-related
factors. Results Among 115,683 patients (mean age, 56.8 [SD 17.2] years; 52.9%
women), 9,077 (7.8%) had an ITF, of which 92.9% were nodules. ITFs were more
likely in women, older adults, those with higher BMI, and when imaging was
ordered by oncology or internal medicine. Compared with chest CT, ITFs were
more likely via neck CT, PET, and nuclear medicine scans. Nodule
characteristics were poorly documented, with size reported in 44% and other
features in fewer than 15% (e.g. calcifications). Compared with patients
without ITFs, those with ITFs had higher odds of thyroid nodule diagnosis,
biopsy, thyroidectomy and thyroid cancer diagnosis. Most cancers were
papillary, and larger when detected after ITFs vs no ITF. Conclusions ITFs were
common and strongly associated with cascades leading to the detection of small,
low-risk cancers. These findings underscore the role of ITFs in thyroid cancer
overdiagnosis and the need for standardized reporting and more selective
follow-up.

</details>


### [22] [QCoder Benchmark: Bridging Language Generation and Quantum Hardware through Simulator-Based Feedback](https://arxiv.org/abs/2510.26101)
*Taku Mikuriya,Tatsuya Ishigaki,Masayuki Kawarada,Shunya Minami,Tadashi Kadowaki,Yohichi Suzuki,Soshun Naito,Shunya Takata,Takumi Kato,Tamotsu Basseda,Reo Yamada,Hiroya Takamura*

Main category: cs.CL

> 开发了QCoder Benchmark，这是一个评估大语言模型在量子编程中表现的框架，通过引入量子模拟器环境和人类代码数据集来实现。研究发现，尽管先进模型GPT-4o表现不佳，一些推理模型的表现优于人类代码。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型在自动生成编程代码方面已经显示出广泛应用，特别是在自动编程代码生成这一领域。然而，这些模型在需要与硬件设备交互的领域，如量子编程中，应用较少。为了填补这一研究空白，该研究提出了一个专门用于量子编程的评估框架。

**Method:** 提出QCoder Benchmark，这是一个评估框架，用于在模拟硬件设备的反馈下评估大语言模型在量子编程中的表现。框架有两个关键特点：一是支持量子模拟器环境的评估，提供特定领域的度量反馈，如电路深度、执行时间和错误分类等；二是结合了从实际编程竞赛中收集的人类编写的代码提交，以便对大语言模型的输出进行定量和定性分析。

**Result:** 实验表明，即使是像GPT-4o这样先进的模型，在此基准测试中的准确率也只有18.97%左右，而基于推理的模型o3则能达到78%的准确率，超过了人类编写的代码的平均成功率（39.98%）。

**Conclusion:** 本文提出了QCoder Benchmark并展示了该评估框架的重要性，它不仅揭示了当前大语言模型在量子编程领域的局限性，还指出了改进和未来研究的方向。同时，该研究还发布了QCoder Benchmark数据集和公共评估API，以支持进一步的研究。

**Abstract:** Large language models (LLMs) have increasingly been applied to automatic
programming code generation. This task can be viewed as a language generation
task that bridges natural language, human knowledge, and programming logic.
However, it remains underexplored in domains that require interaction with
hardware devices, such as quantum programming, where human coders write Python
code that is executed on a quantum computer. To address this gap, we introduce
QCoder Benchmark, an evaluation framework that assesses LLMs on quantum
programming with feedback from simulated hardware devices. Our benchmark offers
two key features. First, it supports evaluation using a quantum simulator
environment beyond conventional Python execution, allowing feedback of
domain-specific metrics such as circuit depth, execution time, and error
classification, which can be used to guide better generation. Second, it
incorporates human-written code submissions collected from real programming
contests, enabling both quantitative comparisons and qualitative analyses of
LLM outputs against human-written codes. Our experiments reveal that even
advanced models like GPT-4o achieve only around 18.97% accuracy, highlighting
the difficulty of the benchmark. In contrast, reasoning-based models such as o3
reach up to 78% accuracy, outperforming averaged success rates of human-written
codes (39.98%). We release the QCoder Benchmark dataset and public evaluation
API to support further research.

</details>


### [23] [Reasoning Path Divergence: A New Metric and Curation Strategy to Unlock LLM Diverse Thinking](https://arxiv.org/abs/2510.26122)
*Feng Ju,Zeyu Qin,Rui Min,Zhitao He,Lingpeng Kong,Yi R. Fung*

Main category: cs.CL

> 本文提出 '一题多解' 训练方法，增加了推理多样性，并通过引入推理路径偏差 (RPD) 来衡量推理路径的差异，实验表明这一方法在多个测试指标上优于 '一题一解' 基线。

<details>
  <summary>Details</summary>

**Motivation:** 尽管测试时尺度 (TTS) 已被证实能够提高大规模语言模型的推理能力，但模型输出的多样性不足限制了其进一步改进。原因主要在于 '一题一解' (1P1S) 训练实践导致模型趋向于单一的推理路径。

**Method:** 我们提出了一个 "一题多解" (1PNS) 训练范式，该范式通过展示多种有效的推理路径来增加推理多样性。我们引入了推理路径偏差 (RPD) 来衡量多步思维链之间的语义差异，从而选择每道题目的多样性最高的答案集合。

**Result:** 实验表明，通过 RPD 选择的训练方法产生了更加多样化的输出，并且在 pass@k 指标上有显著提升，平均在 pass@16 上比强 1P1S 基线高 +2.80%，在 AIME24 上提升 +4.99%。

**Conclusion:** 研究证明了 '一题多解' 训练方法能够进一步放大测试时尺度 (TTS) 的有效性。

**Abstract:** While Test-Time Scaling (TTS) has proven effective in improving the reasoning
ability of large language models (LLMs), low diversity in model outputs often
becomes a bottleneck; this is partly caused by the common "one problem, one
solution" (1P1S) training practice, which provides a single canonical answer
and can push models toward a narrow set of reasoning paths. To address this, we
propose a "one problem, multiple solutions" (1PNS) training paradigm that
exposes the model to a variety of valid reasoning trajectories and thus
increases inference diversity. A core challenge for 1PNS is reliably measuring
semantic differences between multi-step chains of thought, so we introduce
Reasoning Path Divergence (RPD), a step-level metric that aligns and scores
Long Chain-of-Thought solutions to capture differences in intermediate
reasoning. Using RPD, we curate maximally diverse solution sets per problem and
fine-tune Qwen3-4B-Base. Experiments show that RPD-selected training yields
more varied outputs and higher pass@k, with an average +2.80% gain in pass@16
over a strong 1P1S baseline and a +4.99% gain on AIME24, demonstrating that
1PNS further amplifies the effectiveness of TTS. Our code is available at
https://github.com/fengjujf/Reasoning-Path-Divergence .

</details>


### [24] [On the Influence of Discourse Relations in Persuasive Texts](https://arxiv.org/abs/2510.26124)
*Nawar Turk,Sevag Kaspar,Leila Kosseim*

Main category: cs.CL

> 本文通过大型语言模型和提示工程，分析了说服技巧与话语关系之间的关系，研究结果对检测在线宣传和错误信息有贡献。

<details>
  <summary>Details</summary>

**Motivation:** 研究说服技巧和话语关系之间的联系，以解决检测在线宣传和错误信息以及增进对有效沟通理解的实际问题。

**Method:** 本文利用大型语言模型（LLMs）和提示工程来研究说服技巧（PTs）和话语关系（DRs）之间的关系。由于没有同时标注PTs和DRs的数据集，本文以SemEval 2023 Task 3数据集为基础，该数据集标注了19种PTs。作者开发了基于LLM的分类器为该数据集实例分配其中的一种22个PDTB 3.0二级DR。

**Result:** 统计分析表明，六种核心话语关系（因果、目的、对比、因果+信念、让步、条件）在说服性文本中发挥着重要作用，特别是在加载语言、夸张/最小化、重复和质疑的使用中，这点对于理解有效沟通至关重要。

**Conclusion:** 通过生成银子数据集，本文能够提供关于典型话语关系在说服文本中的关键作用的见解，这对检测在线宣传和错误信息非常有用，同时也能帮助研究增强沟通有效性。

**Abstract:** This paper investigates the relationship between Persuasion Techniques (PTs)
and Discourse Relations (DRs) by leveraging Large Language Models (LLMs) and
prompt engineering. Since no dataset annotated with both PTs and DRs exists, we
took the SemEval 2023 Task 3 dataset labelled with 19 PTs as a starting point
and developed LLM-based classifiers to label each instance of the dataset with
one of the 22 PDTB 3.0 level-2 DRs. In total, four LLMs were evaluated using 10
different prompts, resulting in 40 unique DR classifiers. Ensemble models using
different majority-pooling strategies were used to create 5 silver datasets of
instances labelled with both persuasion techniques and level-2 PDTB senses. The
silver dataset sizes vary from 1,281 instances to 204 instances, depending on
the majority pooling technique used. Statistical analysis of these silver
datasets shows that six discourse relations (namely Cause, Purpose, Contrast,
Cause+Belief, Concession, and Condition) play a crucial role in persuasive
texts, especially in the use of Loaded Language, Exaggeration/Minimisation,
Repetition and to cast Doubt. This insight can contribute to detecting online
propaganda and misinformation, as well as to our general understanding of
effective communication.

</details>


### [25] [MossNet: Mixture of State-Space Experts is a Multi-Head Attention](https://arxiv.org/abs/2510.26182)
*Shikhar Tuli,James Seale Smith,Haris Jeelani,Chi-Heng Lin,Abhishek Patel,Vasili Ramanishka,Yen-Chang Hsu,Hongxia Jin*

Main category: cs.CL

> 本文提出MossNet，一种新的专家混合状态空间架构，模拟线性多头注意力(MHA)，在效能、扩展性和资源使用上优于同等规模的变压器和SSM架构。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)在自然语言处理(NLP)生成应用中取得了显著进展。然而，当前的SSM/GRM方法通常只模拟单个注意力头，这可能限制了它们的表现力。为此，作者提出了MossNet，旨在增强SMM/GRM的表现力。

**Method:** 本文提出了MossNet，这是一种新的专家混合状态空间架构，模拟了线性多头注意力(MHA)。MossNet不仅在通道混合多层感知器(MLP)块中使用专家混合(MoE)的实现，还在时间混合SSM核中使用，以实现多个“注意力头”。

**Result:** 广泛的语言模型和下游评估实验表明，MossNet在同等模型规模和数据预算下，优于变压器和SSM架构。进一步的实验验证了MossNet的可扩展性和卓越性能，并且在实际设备上的运行速度和资源使用上亦优于同类基线。

**Conclusion:** 实验结果表明，MossNet在效率、性能和资源使用方面表现出色，为更高效且高性能的递归大型语言模型架构提供了新的方向。

**Abstract:** Large language models (LLMs) have significantly advanced generative
applications in natural language processing (NLP). Recent trends in model
architectures revolve around efficient variants of transformers or
state-space/gated-recurrent models (SSMs, GRMs). However, prevailing
SSM/GRM-based methods often emulate only a single attention head, potentially
limiting their expressiveness. In this work, we propose MossNet, a novel
mixture-of-state-space-experts architecture that emulates a linear multi-head
attention (MHA). MossNet leverages a mixture-of-experts (MoE) implementation
not only in channel-mixing multi-layered perceptron (MLP) blocks but also in
the time-mixing SSM kernels to realize multiple "attention heads." Extensive
experiments on language modeling and downstream evaluations show that MossNet
outperforms both transformer- and SSM-based architectures of similar model size
and data budgets. Larger variants of MossNet, trained on trillions of tokens,
further confirm its scalability and superior performance. In addition,
real-device profiling on a Samsung Galaxy S24 Ultra and an Nvidia A100 GPU
demonstrate favorable runtime speed and resource usage compared to similarly
sized baselines. Our results suggest that MossNet is a compelling new direction
for efficient, high-performing recurrent LLM architectures.

</details>


### [26] [Similarity-Distance-Magnitude Language Models](https://arxiv.org/abs/2510.26183)
*Allen Schmaltz*

Main category: cs.CL

> 论文提出了SDM语言模型，通过微调预训练模型，改善了模型在执行指令时的统计效率，提高了生成的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在改善预训练的仅解码器的Transformer语言模型，使其更准确地遵循指令并提高生成的有效性。

**Method:** 该论文介绍了Similarity-Distance-Magnitude (SDM) 语言模型，这是一种序列预测模型，通过最大比例的生成在由最后一层SDM激活层划分的校准良好的高概率区域中进行微调。通过使用最后一层SDM激活层，在培训过程中估计对比输入编码方案的监督下一个令牌损失的基数变化，并结合在线生成的额外困难负面样本。

**Result:** SDM模型能够减少弃权情况，相比于强有力的监督基线方法，提高了统计效率。

**Conclusion:** 研究表明，通过使用SDM激活层和对比输入编码方案进行监督微调，可以显著提高语言模型在遵循指令时的性能。

**Abstract:** We introduce Similarity-Distance-Magnitude (SDM) language models (LMs), which
are sequence prediction models fine-tuned to maximize the proportion of
generations in the well-calibrated, high-probability region partitioned by a
final-layer SDM activation layer used for binary classification of
instruction-following. We demonstrate that existing pre-trained decoder-only
Transformer LMs can be readily converted into SDM LMs via supervised
fine-tuning, using the final-layer SDM activation layer during training to
estimate a change-of-base for a supervised next-token loss over a contrastive
input encoding scheme, with additional hard negative examples generated online
during training. This results in reduced abstentions (i.e., improved
statistical efficiency) compared to strong supervised baselines.

</details>


### [27] [RCScore: Quantifying Response Consistency in Large Language Models](https://arxiv.org/abs/2510.26193)
*Dongjun Jang,Youngchae Ahn,Hyopil Shin*

Main category: cs.CL

> 介绍了RCScore，一个多维框架，用于量化指令形式如何影响模型响应。RCScore揭示了指令风格对模型性能的影响，并提出了Cross-Response Similarity（CRS）方法来评估风格一致性，表明一致性是衡量模型可靠性的一个有价值的代理。

<details>
  <summary>Details</summary>

**Motivation:** 当前的LLM评估通常依赖单一指令模板，忽略了模型对指令风格的敏感性，而这是实际部署中的一个关键方面。

**Method:** 通过系统地将基准问题转化为多种指令风格，RCScore揭示了传统指标无法检测到的表现差异。

**Result:** 实验结果显示，在四个推理基准测试中，指令风格可以将十个LLM的准确性改变高达16.7个百分点。此外，确定性解码产生更稳定风格的输出，模型规模与跨风格一致性呈正相关。

**Conclusion:** RCScore提供了一种评估指令鲁棒性的原则性方法。

**Abstract:** Current LLM evaluations often rely on a single instruction template,
overlooking models' sensitivity to instruction style-a critical aspect for
real-world deployments. We present RCScore, a multi-dimensional framework
quantifying how instruction formulation affects model responses. By
systematically transforming benchmark problems into multiple instruction
styles, RCScore reveals performance variations undetected by conventional
metrics. Our experiments across ten LLMs on four reasoning benchmarks
demonstrate that instruction style can shift accuracy by up to 16.7% points. We
introduce Cross-Response Similarity (CRS), a method applying RCScore metrics to
measure stylistic self-consistency, and establish its strong correlation with
task accuracy, suggesting consistency as a valuable proxy for model
reliability. Additional findings show that deterministic decoding produces more
stylistically stable outputs, and model scale correlates positively with
cross-style consistency. RCScore offers a principled approach to assess
instruction robustness.

</details>


### [28] [Don't Let It Fade: Preserving Edits in Diffusion Language Models via Token Timestep Allocation](https://arxiv.org/abs/2510.26200)
*Woojin Kim,Jaeyoung Do*

Main category: cs.CL

> Researchers address update forgetting in diffusion language models by proposing Token Timestep Allocation (TTA), which improves controllability and fluency through softened token ordering based on timestep allocation strategies.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind the research is to address the issue of update forgetting in diffusion language models, a problem that arises due to uniform and context-agnostic updates, leading to disruptions in the refinement process and reduced fluency and coherence in text generation.

**Method:** Token Timestep Allocation (TTA) is introduced to solve the problem of update forgetting in diffusion language models. TTA employs per-token timestep schedules, ensuring critical tokens are frozen early while allowing uncertain tokens to continue being refined, either through a fixed policy or an adaptive policy.

**Result:** TTA demonstrates improved performance in terms of controllability and fluency. In sentiment control, it achieves more than 20% higher accuracy and nearly halves perplexity with less than one-fifth the steps. In detoxification, it reduces maximum toxicity and perplexity values.

**Conclusion:** The research concludes that TTA is the key method for mitigating update forgetting, enabling stable and controllable diffusion text generation. By providing a softened ordering of tokens through timestep allocation, TTA effectively supports various refinement strategies and diverse supervision sources.

**Abstract:** While diffusion language models (DLMs) enable fine-grained refinement, their
practical controllability remains fragile. We identify and formally
characterize a central failure mode called update forgetting, in which uniform
and context agnostic updates induce token level fluctuations across timesteps,
erasing earlier semantic edits and disrupting the cumulative refinement
process, thereby degrading fluency and coherence. As this failure originates in
uniform and context agnostic updates, effective control demands explicit token
ordering. We propose Token Timestep Allocation (TTA), which realizes soft and
semantic token ordering via per token timestep schedules: critical tokens are
frozen early, while uncertain tokens receive continued refinement. This
timestep based ordering can be instantiated as either a fixed policy or an
adaptive policy driven by task signals, thereby supporting a broad spectrum of
refinement strategies. Because it operates purely at inference time, it applies
uniformly across various DLMs and naturally extends to diverse supervision
sources. Empirically, TTA improves controllability and fluency: on sentiment
control, it yields more than 20 percent higher accuracy and nearly halves
perplexity using less than one fifth the steps; in detoxification, it lowers
maximum toxicity (12.2 versus 14.5) and perplexity (26.0 versus 32.0).
Together, these results demonstrate that softened ordering via timestep
allocation is the critical lever for mitigating update forgetting and achieving
stable and controllable diffusion text generation.

</details>


### [29] [What's In My Human Feedback? Learning Interpretable Descriptions of Preference Data](https://arxiv.org/abs/2510.26202)
*Rajiv Movva,Smitha Milli,Sewon Min,Emma Pierson*

Main category: cs.CL

> 本文提出WIMHF方法，利用稀疏自动编码器来解释人类反馈数据，识别出人类偏好中的关键特征，并揭示了数据集级别的偏好差异和潜在的不安全偏好。

<details>
  <summary>Details</summary>

**Motivation:** 现有的工作无法自动提取相关的特征，缺乏对人类反馈数据包含信息的清晰理解。通过引入WIMHF方法来解决这一问题。

**Method:** 使用稀疏自动编码器来解释人类反馈数据，该方法能够刻画数据集能够测量的偏好和注释者实际表达的偏好。

**Result:** WIMHF能够识别出少数几个可解释的特征，这些特征能够解释大部分由黑盒模型预测的偏好信号。此外，通过重新标注有害示例，WIMHF能够在不损害总体性能的情况下提高安全性。

**Conclusion:** WIMHF提供了一种以人类为中心的偏好数据分析方法，有助于实践者更好地理解和使用偏好数据。

**Abstract:** Human feedback can alter language models in unpredictable and undesirable
ways, as practitioners lack a clear understanding of what feedback data
encodes. While prior work studies preferences over certain attributes (e.g.,
length or sycophancy), automatically extracting relevant features without
pre-specifying hypotheses remains challenging. We introduce What's In My Human
Feedback? (WIMHF), a method to explain feedback data using sparse autoencoders.
WIMHF characterizes both (1) the preferences a dataset is capable of measuring
and (2) the preferences that the annotators actually express. Across 7
datasets, WIMHF identifies a small number of human-interpretable features that
account for the majority of the preference prediction signal achieved by
black-box models. These features reveal a wide diversity in what humans prefer,
and the role of dataset-level context: for example, users on Reddit prefer
informality and jokes, while annotators in HH-RLHF and PRISM disprefer them.
WIMHF also surfaces potentially unsafe preferences, such as that LMArena users
tend to vote against refusals, often in favor of toxic content. The learned
features enable effective data curation: re-labeling the harmful examples in
Arena yields large safety gains (+37%) with no cost to general performance.
They also allow fine-grained personalization: on the Community Alignment
dataset, we learn annotator-specific weights over subjective features that
improve preference prediction. WIMHF provides a human-centered analysis method
for practitioners to better understand and use preference data.

</details>


### [30] [Towards Global Retrieval Augmented Generation: A Benchmark for Corpus-Level Reasoning](https://arxiv.org/abs/2510.26205)
*Qi Luo,Xiaonan Li,Tingshuo Fan,Xinchi Chen,Xipeng Qiu*

Main category: cs.CL

> 本文介绍了一个新的基准测试GlobalQA，专门用来评估全局RAG能力，并提出了GlobalRAG框架，在处理需要全局理解的任务上显著提升了性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的RAG方法在需要全局理解的任务上表现不佳，最强基线仅达到1.51 F1分数，因此提出GlobalRAG以应对这一挑战。

**Method:** GlobalRAG, 一个多工具协作框架，通过块级检索保持结构连贯性，利用LLM驱动的智能过滤器消除噪声文档，并集成聚合模块进行精确的符号计算。

**Result:** 在Qwen2.5-14B模型上，GlobalRAG达到了6.63 F1，而最强基线为1.51 F1，证明了方法的有效性。

**Conclusion:** 提出了GlobalRAG框架，通过多工具协作提升模型在全局理解任务上的表现。

**Abstract:** Retrieval-augmented generation (RAG) has emerged as a leading approach to
reducing hallucinations in large language models (LLMs). Current RAG evaluation
benchmarks primarily focus on what we call local RAG: retrieving relevant
chunks from a small subset of documents to answer queries that require only
localized understanding within specific text chunks. However, many real-world
applications require a fundamentally different capability -- global RAG --
which involves aggregating and analyzing information across entire document
collections to derive corpus-level insights (for example, "What are the top 10
most cited papers in 2023?"). In this paper, we introduce GlobalQA -- the first
benchmark specifically designed to evaluate global RAG capabilities, covering
four core task types: counting, extremum queries, sorting, and top-k
extraction. Through systematic evaluation across different models and
baselines, we find that existing RAG methods perform poorly on global tasks,
with the strongest baseline achieving only 1.51 F1 score. To address these
challenges, we propose GlobalRAG, a multi-tool collaborative framework that
preserves structural coherence through chunk-level retrieval, incorporates
LLM-driven intelligent filters to eliminate noisy documents, and integrates
aggregation modules for precise symbolic computation. On the Qwen2.5-14B model,
GlobalRAG achieves 6.63 F1 compared to the strongest baseline's 1.51 F1,
validating the effectiveness of our method.

</details>


### [31] [Pragmatic Theories Enhance Understanding of Implied Meanings in LLMs](https://arxiv.org/abs/2510.26253)
*Takuma Sato,Seiya Kawano,Koichiro Yoshino*

Main category: cs.CL

> 本研究展示向语言模型提供语用学理论作为提示语是一种有效方法，能够提高模型对隐含含义的理解能力。

<details>
  <summary>Details</summary>

**Motivation:** 在人类交流和语言使用中，准确解释隐含含义的能力起到了至关重要的作用，语言模型同样需要具有这种能力。这项研究旨在证明向语言模型提供语用学理论作为提示语是一种有效的情境学习方法，可帮助解决理解隐含含义的任务。

**Method:** 本研究提出了一种方法，即作为提示语向语言模型提供有关格赖斯语用学和关联理论等语用学理论的概述，引导模型通过逐步推理过程得出最后的解释。

**Result:** 实验结果显示，与仅进行中间推理但不展示语用学理论（零次Chain-of-Thought）的基线相比，本方法使语言模型在语用推理任务上的得分提高了多达9.6%。另外，即使不解释语用学理论的细节，仅提示语用学理论的名称也能使较大的模型比基线有约1-3%的性能提升。

**Conclusion:** 结果表明，向语言模型提供语用学理论作为提示语的方法相对于基线方法显著提高了语用推理任务的表现，即使只是在提示中提及语用学理论的名称也能带来一定程度的性能提升。

**Abstract:** The ability to accurately interpret implied meanings plays a crucial role in
human communication and language use, and language models are also expected to
possess this capability. This study demonstrates that providing language models
with pragmatic theories as prompts is an effective in-context learning approach
for tasks to understand implied meanings. Specifically, we propose an approach
in which an overview of pragmatic theories, such as Gricean pragmatics and
Relevance Theory, is presented as a prompt to the language model, guiding it
through a step-by-step reasoning process to derive a final interpretation.
Experimental results showed that, compared to the baseline, which prompts
intermediate reasoning without presenting pragmatic theories (0-shot
Chain-of-Thought), our methods enabled language models to achieve up to 9.6\%
higher scores on pragmatic reasoning tasks. Furthermore, we show that even
without explaining the details of pragmatic theories, merely mentioning their
names in the prompt leads to a certain performance improvement (around 1-3%) in
larger models compared to the baseline.

</details>


### [32] [Language Models Are Borrowing-Blind: A Multilingual Evaluation of Loanword Identification across 10 Languages](https://arxiv.org/abs/2510.26254)
*Mérilin Sousa Silva,Sina Ahmadi*

Main category: cs.CL

> 本研究发现，预训练语言模型在区分借词和本土词汇时表现不佳，这提示了现代NLP系统在处理少数语言时存在偏差。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于探讨预训练语言模型是否具备识别借词的类似能力，尤其是在双语社区。

**Method:** 本研究评估了多个预训练语言模型在10种语言中识别借词的能力。

**Result:** 研究结果显示，即使提供了明确的指令和上下文信息，这些模型在区分借词和本土词汇方面表现不佳。

**Conclusion:** 研究结果表明，现代NLP系统存在偏向于借词而非本土词汇的偏差，这对为少数语言开发NLP工具和维护面临优势语言压力的语言具有重要意义。

**Abstract:** Throughout language history, words are borrowed from one language to another
and gradually become integrated into the recipient's lexicon. Speakers can
often differentiate these loanwords from native vocabulary, particularly in
bilingual communities where a dominant language continuously imposes lexical
items on a minority language. This paper investigates whether pretrained
language models, including large language models, possess similar capabilities
for loanword identification. We evaluate multiple models across 10 languages.
Despite explicit instructions and contextual information, our results show that
models perform poorly in distinguishing loanwords from native ones. These
findings corroborate previous evidence that modern NLP systems exhibit a bias
toward loanwords rather than native equivalents. Our work has implications for
developing NLP tools for minority languages and supporting language
preservation in communities under lexical pressure from dominant languages.

</details>


### [33] [Distilling Multilingual Vision-Language Models: When Smaller Models Stay Multilingual](https://arxiv.org/abs/2510.26271)
*Sukrit Sriratanawilai,Jhayahgrit Thongwat,Romrawin Chumpu,Patomporn Payoungkhamdee,Sarana Nutanong,Peerat Limkonchotiwat*

Main category: cs.CL

> 研究探索了五种知识蒸馏方法在多语言视觉语言模型中的应用效果，特别是在模型压缩时对跨语言表示一致性和下游任务稳定性的影响，发现有些配置即使在减半模型大小的情况下也能保持或提升稳健性，但存在设计敏感性的问题。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在解决视觉语言模型在不同语言间表现不均以及模型规模减小时这一问题频发的情况，特别是在多语言应用知识蒸馏方面，这是一个尚待深入研究的方向。

**Method:** 本研究通过控制实验，探索了在模型压缩情况下知识蒸馏对跨语言表现的影响。实验涵盖了五种蒸馏方法，并在同一框架下的两个模型（CLIP与SigLIP2）上进行跨语言表示一致性及下游任务稳定性的评估。

**Result:** 研究发现，某些设定能够保持或提升跨语言检索任务的稳健性，即便是在压缩模型大小的情况下。不过，测试也表明其他设定在保持跨任务稳定性上表现不佳，指出依赖单一精度聚合评估的局限。

**Conclusion:** 研究结果显示，某些实验配置即使在模型大小减半的情况下，也能保持甚至改进跨语言检索的稳健性，但也有些配置未能维持跨任务的稳定性，揭示了设计敏感性及精度聚集考量不足所带来的权衡问题。

**Abstract:** Vision-language models (VLMs) exhibit uneven performance across languages, a
problem that is often exacerbated when the model size is reduced. While
Knowledge distillation (KD) demonstrates promising results in transferring
knowledge from larger to smaller VLMs, applying KD in multilingualism is an
underexplored area. This paper presents a controlled empirical study of KD
behavior across five distillation approaches, isolating their effects on
cross-lingual representation consistency and downstream performance stability
under model compression. We study five distillation formulations across CLIP
and SigLIP2, and evaluate them on in-domain retrieval and out-of-domain visual
QA. We find that some configurations preserve or even improve multilingual
retrieval robustness despite halving model size, but others fail to maintain
cross-task stability, exposing design-sensitive trade-offs that aggregate
accuracy alone does not reveal.

</details>


### [34] [Do LLMs Signal When They're Right? Evidence from Neuron Agreement](https://arxiv.org/abs/2510.26277)
*Kang Chen,Yaoning Wang,Kai Xiong,Zhuoka Feng,Wenhe Sun,Haotian Chen,Yixin Cao*

Main category: cs.CL

> Proposes NAD for label-free ensemble decoding based on internal neuron activations, outperforming current methods and reducing token usage.

<details>
  <summary>Details</summary>

**Motivation:** Analyzing internal neuron activations to provide better guidance for label-free ensemble decoding.

**Method:** Neuron Agreement Decoding (NAD), an unsupervised best-of-N method using activation sparsity and cross sample neuron agreement.

**Result:** NAD matches majority voting on benchmarks with verifiable answers and outperforms Avg@64 on open ended coding benchmarks. It also reduces token usage by 99% with minimal loss in quality.

**Conclusion:** Internal neuron signals are more reliable, scalable, and efficient for guiding label-free ensemble decoding compared to external signals.

**Abstract:** Large language models (LLMs) commonly boost reasoning via
sample-evaluate-ensemble decoders, achieving label free gains without ground
truth. However, prevailing strategies score candidates using only external
outputs such as token probabilities, entropies, or self evaluations, and these
signals can be poorly calibrated after post training. We instead analyze
internal behavior based on neuron activations and uncover three findings: (1)
external signals are low dimensional projections of richer internal dynamics;
(2) correct responses activate substantially fewer unique neurons than
incorrect ones throughout generation; and (3) activations from correct
responses exhibit stronger cross sample agreement, whereas incorrect ones
diverge. Motivated by these observations, we propose Neuron Agreement Decoding
(NAD), an unsupervised best-of-N method that selects candidates using
activation sparsity and cross sample neuron agreement, operating solely on
internal signals and without requiring comparable textual outputs. NAD enables
early correctness prediction within the first 32 generated tokens and supports
aggressive early stopping. Across math and science benchmarks with verifiable
answers, NAD matches majority voting; on open ended coding benchmarks where
majority voting is inapplicable, NAD consistently outperforms Avg@64. By
pruning unpromising trajectories early, NAD reduces token usage by 99% with
minimal loss in generation quality, showing that internal signals provide
reliable, scalable, and efficient guidance for label free ensemble decoding.

</details>


### [35] [Unravelling the Mechanisms of Manipulating Numbers in Language Models](https://arxiv.org/abs/2510.26285)
*Michal Štefánik,Timothee Mickus,Marek Kadlčík,Bertram Højer,Michal Spiegel,Raúl Vázquez,Aman Sinha,Josef Kuchař,Philipp Mondorf*

Main category: cs.CL

> 尽管大型语言模型（LLMs）在处理数字信息时常产生错误，但它们学习到了系统性、高度准确且通用的数字表示方法，这些表示在隐藏状态和输入上下文中具有一致性，有助于理解模型错误的根源和精进模型结构。

<details>
  <summary>Details</summary>

**Motivation:** 解释为何不同大型语言模型在提供准确的数字嵌入表示与处理数字信息时常产生错误之间存在冲突。

**Method:** 探索语言模型如何处理数字，并量化这些机制的最低准确度界。创建针对每个LLM的通用探测器，并追踪错误产生的具体层。

**Result:** 发现虽然出现了错误，但不同语言模型学习到了可以互换的数字表示方法，这些表示方法系统性、高度准确且在隐藏状态及输入上下文中具有普遍性。

**Conclusion:** 这些发现有助于理解和改进预训练大型语言模型如何处理数字信息的方法，同时也展示了更准确的探测技术在修订LLM架构方面的潜力。

**Abstract:** Recent work has shown that different large language models (LLMs) converge to
similar and accurate input embedding representations for numbers. These
findings conflict with the documented propensity of LLMs to produce erroneous
outputs when dealing with numeric information. In this work, we aim to explain
this conflict by exploring how language models manipulate numbers and quantify
the lower bounds of accuracy of these mechanisms. We find that despite
surfacing errors, different language models learn interchangeable
representations of numbers that are systematic, highly accurate and universal
across their hidden states and the types of input contexts. This allows us to
create universal probes for each LLM and to trace information -- including the
causes of output errors -- to specific layers. Our results lay a fundamental
understanding of how pre-trained LLMs manipulate numbers and outline the
potential of more accurate probing techniques in addressed refinements of LLMs'
architectures.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [36] [Enhancing Underwater Object Detection through Spatio-Temporal Analysis and Spatial Attention Networks](https://arxiv.org/abs/2510.25797)
*Sai Likhith Karri,Ansh Saxena*

Main category: cs.CV

> The paper evaluates the performance of YOLOv5, T-YOLOv5, and T-YOLOv5 with CBAM in underwater object detection, highlighting that spatio-temporal modeling and attention mechanisms enhance detection accuracy, especially in challenging scenarios like sudden movements and partial occlusions, but may reduce accuracy in simpler situations.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to improve the accuracy and reliability of underwater object detection by incorporating spatio-temporal modeling and spatial attention mechanisms into deep learning models like YOLOv5.

**Method:** The researchers compared the performance of the standard YOLOv5 with a temporal-enhanced version, T-YOLOv5. They further developed an augmented T-YOLOv5 model, which included a Convolutional Block Attention Module (CBAM) to improve attention to spatial features.

**Result:** The study found that T-YOLOv5 and T-YOLOv5 with CBAM provided significant improvements in detection accuracy compared to the standard YOLOv5 model, especially under challenging conditions. However, the performance gain in simpler detection scenarios was less evident for the T-YOLOv5 with CBAM version.

**Conclusion:** The research concludes that spatio-temporal models and spatial attention mechanisms, like CBAM, can significantly improve underwater object detection accuracy in complex, dynamic environments, but may not offer as much benefit in simpler detection tasks.

**Abstract:** This study examines the effectiveness of spatio-temporal modeling and the
integration of spatial attention mechanisms in deep learning models for
underwater object detection. Specifically, in the first phase, the performance
of temporal-enhanced YOLOv5 variant T-YOLOv5 is evaluated, in comparison with
the standard YOLOv5. For the second phase, an augmented version of T-YOLOv5 is
developed, through the addition of a Convolutional Block Attention Module
(CBAM). By examining the effectiveness of the already pre-existing YOLOv5 and
T-YOLOv5 models and of the newly developed T-YOLOv5 with CBAM. With CBAM, the
research highlights how temporal modeling improves detection accuracy in
dynamic marine environments, particularly under conditions of sudden movements,
partial occlusions, and gradual motion. The testing results showed that YOLOv5
achieved a mAP@50-95 of 0.563, while T-YOLOv5 and T-YOLOv5 with CBAM
outperformed with mAP@50-95 scores of 0.813 and 0.811, respectively,
highlighting their superior accuracy and generalization in detecting complex
objects. The findings demonstrate that T-YOLOv5 significantly enhances
detection reliability compared to the standard model, while T-YOLOv5 with CBAM
further improves performance in challenging scenarios, although there is a loss
of accuracy when it comes to simpler scenarios.

</details>


### [37] [MIRO: MultI-Reward cOnditioned pretraining improves T2I quality and efficiency](https://arxiv.org/abs/2510.25897)
*Nicolas Dufour,Lucas Degeorge,Arijit Ghosh,Vicky Kalogeiton,David Picard*

Main category: cs.CV

> 本文提出了MIRO方法，通过在生成模型训练过程中引入多个奖励模型，直接学习用户偏好，提高生成图像质量和训练效率，优于现有的后期选择生成图像的方法，减少了信息数据的丢弃，并在多个基准上达到最先进的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像生成模型训练在大规模非结构化数据集上，难以满足用户的多样化偏好。后期选择生成图像的方法会丢弃大量有用的信息，且不易维护生成图像的多样性和语义准确性。

**Method:** 本文提出了一种称为MIRO的方法，通过在模型训练过程中添加多个奖励模型，使其直接学习用户偏好，而不是依赖后期选择来优化生成的图像。

**Result:** 实验结果显示，使用MIRO方法生成的图像具有较高的视觉质量，并且显著加快了训练速度。MIRO在GenEval组合基准测试和用户偏好评分中实现了最先进的性能。

**Conclusion:** 将多个奖励模型引入到生成模型训练中，可以直接有效地学习用户偏好，并能够产生高质量的图像，同时节省训练时间，相较于现有的图像后期处理方法具有明显优势。

**Abstract:** Current text-to-image generative models are trained on large uncurated
datasets to enable diverse generation capabilities. However, this does not
align well with user preferences. Recently, reward models have been
specifically designed to perform post-hoc selection of generated images and
align them to a reward, typically user preference. This discarding of
informative data together with the optimizing for a single reward tend to harm
diversity, semantic fidelity and efficiency. Instead of this post-processing,
we propose to condition the model on multiple reward models during training to
let the model learn user preferences directly. We show that this not only
dramatically improves the visual quality of the generated images but it also
significantly speeds up the training. Our proposed method, called MIRO,
achieves state-of-the-art performances on the GenEval compositional benchmark
and user-preference scores (PickAScore, ImageReward, HPSv2).

</details>


### [38] [BikeScenes: Online LiDAR Semantic Segmentation for Bicycles](https://arxiv.org/abs/2510.25901)
*Denniz Goren,Holger Caesar*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** The vulnerability of cyclists, exacerbated by the rising popularity of faster
e-bikes, motivates adapting automotive perception technologies for bicycle
safety. We use our multi-sensor 'SenseBike' research platform to develop and
evaluate a 3D LiDAR segmentation approach tailored to bicycles. To bridge the
automotive-to-bicycle domain gap, we introduce the novel BikeScenes-lidarseg
Dataset, comprising 3021 consecutive LiDAR scans around the university campus
of the TU Delft, semantically annotated for 29 dynamic and static classes. By
evaluating model performance, we demonstrate that fine-tuning on our BikeScenes
dataset achieves a mean Intersection-over-Union (mIoU) of 63.6%, significantly
outperforming the 13.8% obtained with SemanticKITTI pre-training alone. This
result underscores the necessity and effectiveness of domain-specific training.
We highlight key challenges specific to bicycle-mounted, hardware-constrained
perception systems and contribute the BikeScenes dataset as a resource for
advancing research in cyclist-centric LiDAR segmentation.

</details>


### [39] [Generative Image Restoration and Super-Resolution using Physics-Informed Synthetic Data for Scanning Tunneling Microscopy](https://arxiv.org/abs/2510.25921)
*Nikola L. Kolev,Tommaso Rodani,Neil J. Curson,Taylor J. Z. Stock,Alberto Cazzaniga*

Main category: cs.CV

> 本文提出一种机器学习方法，以改善STM图像质量和提高数据采集速度，通过合成数据训练模型，能够在稀疏采样数据下快速重建高精度图像。

<details>
  <summary>Details</summary>

**Motivation:** STM扫描隧道显微镜在原子分辨率成像和原子操控方面有显著优势，但其使用受限于探针退化和数据采集速度慢的问题。在制造过程中，探针还常受大电压影响，改变其尖端形状，需要进行调节。

**Method:** 使用机器学习（ML）方法进行图像修复和超分辨率处理，以解决STM扫描隧道显微镜中的问题。基于36个原始实验图像的数据集，展示了物理知识引导的合成数据生成管道，用于训练几种最先进的流匹配和扩散模型。

**Result:** 定量评估表明，这些模型能够有效恢复图像，并通过从稀疏采样数据中准确重建图像，将图像采集时间减少到原来的二到四分之一。

**Conclusion:** 该框架有潜力显著提高STM实验吞吐量，减少探针调节的频率，同时增强现有高速STM系统的帧率。

**Abstract:** Scanning tunnelling microscopy (STM) enables atomic-resolution imaging and
atom manipulation, but its utility is often limited by tip degradation and slow
serial data acquisition. Fabrication adds another layer of complexity since the
tip is often subjected to large voltages, which may alter the shape of its
apex, requiring it to be conditioned. Here, we propose a machine learning (ML)
approach for image repair and super-resolution to alleviate both challenges.
Using a dataset of only 36 pristine experimental images of Si(001):H, we
demonstrate that a physics-informed synthetic data generation pipeline can be
used to train several state-of-the-art flow-matching and diffusion models.
Quantitative evaluation with metrics such as the CLIP Maximum Mean Discrepancy
(CMMD) score and structural similarity demonstrates that our models are able to
effectively restore images and offer a two- to fourfold reduction in image
acquisition time by accurately reconstructing images from sparsely sampled
data. Our framework has the potential to significantly increase STM
experimental throughput by offering a route to reducing the frequency of
tip-conditioning procedures and to enhancing frame rates in existing high-speed
STM systems.

</details>


### [40] [SplitFlow: Flow Decomposition for Inversion-Free Text-to-Image Editing](https://arxiv.org/abs/2510.25970)
*Sung-Hoon Yoon,Minghan Li,Gaspard Beaudouin,Congcong Wen,Muhammad Rafay Azhar,Mengyu Wang*

Main category: cs.CV

> 文章提出了一种流分解和聚合框架，解决了传统图像编辑方法中的反向过程不准确和梯度纠缠问题，提升了图像编辑质量。

<details>
  <summary>Details</summary>

**Motivation:** 尽管修正流模型在图像生成方面成效显著，但在图像编辑任务中存在绘制真实图像回溯到潜在空间不准确和梯度纠缠问题，从而导致编辑输出不忠实于目标，因此，本文旨在通过提出一种新的无反向过程编辑方法来改进。

**Method:** 我们提出了一种基于流分解和聚合框架的方法，避免了传统的反向过程。具体来说，我们将目标提示语义分解成多个子提示语句，分别计算每个子提示的独立流，并将其聚合形成一个统一的编辑轨迹。我们还设计了一个投影和软聚合机制来解决流程中的语义一致性问题，通过适应性加权子目标速度场来减少语义冗余，强调不同的方向，从而在最终的编辑输出中保留了多样性和一致性。

**Result:** 实验结果显示，我们的方法在语义保真度和属性解缠方面优于现有的零样本编辑方法。

**Conclusion:** 本文提出的方法在图像编辑任务中表现出了较高的语义保真度和属性解缠能力，证明了其在零样本编辑方面优于现有方法。

**Abstract:** Rectified flow models have become a de facto standard in image generation due
to their stable sampling trajectories and high-fidelity outputs. Despite their
strong generative capabilities, they face critical limitations in image editing
tasks: inaccurate inversion processes for mapping real images back into the
latent space, and gradient entanglement issues during editing often result in
outputs that do not faithfully reflect the target prompt. Recent efforts have
attempted to directly map source and target distributions via ODE-based
approaches without inversion; however,these methods still yield suboptimal
editing quality. In this work, we propose a flow decomposition-and-aggregation
framework built upon an inversion-free formulation to address these
limitations. Specifically, we semantically decompose the target prompt into
multiple sub-prompts, compute an independent flow for each, and aggregate them
to form a unified editing trajectory. While we empirically observe that
decomposing the original flow enhances diversity in the target space,
generating semantically aligned outputs still requires consistent guidance
toward the full target prompt. To this end, we design a projection and
soft-aggregation mechanism for flow, inspired by gradient conflict resolution
in multi-task learning. This approach adaptively weights the sub-target
velocity fields, suppressing semantic redundancy while emphasizing distinct
directions, thereby preserving both diversity and consistency in the final
edited output. Experimental results demonstrate that our method outperforms
existing zero-shot editing approaches in terms of semantic fidelity and
attribute disentanglement. The code is available at
https://github.com/Harvard-AI-and-Robotics-Lab/SplitFlow.

</details>


### [41] [Brain-IT: Image Reconstruction from fMRI via Brain-Interaction Transformer](https://arxiv.org/abs/2510.25976)
*Roman Beliy,Amit Zalcher,Jonathan Kogman,Navve Wasserman,Michal Irani*

Main category: cs.CV

> 本文提出Brain-IT方法，通过脑交互变换器（BIT）实现了更忠实的图像重构，并展示了比当前最佳方法更好的效果，同时也大大减少了训练所需的数据量。

<details>
  <summary>Details</summary>

**Motivation:** 本文的目标是改进当前通过功能性核磁共振成像(fMRI)脑记录来重建人们所看到的图像的方法，特别是提高忠实度，使生成的图像更加接近于实际看到的图像。

**Method:** 本文介绍了'Brain-IT'方法，通过一个脑交互转换器（BIT）实现了有效的人脑体素簇之间的交互。这种方法通过对脑体素簇共享和整合信息，来实现图像重构。BIT预测了两种互补的局部补丁级图像特征，一种是高阶语义特征，用于引导扩散模型走向正确的语义内容；另一种是低阶结构特征，帮助以正确的粗略布局初始化扩散过程。

**Result:** 实验结果表明，相比于当前最佳的方法，Brain-IT在视觉以及标准客观指标上实现了更忠实的图像重建。此外，仅需1小时的fMRI数据，Brain-IT即可达到目前需要40小时记录才能达到的效果。

**Conclusion:** 通过BIT的设计，信息可以直接从大脑体素簇流向局部图像特征，解决了图像忠实度的问题，超越了现有的SotA方法。

**Abstract:** Reconstructing images seen by people from their fMRI brain recordings
provides a non-invasive window into the human brain. Despite recent progress
enabled by diffusion models, current methods often lack faithfulness to the
actual seen images. We present "Brain-IT", a brain-inspired approach that
addresses this challenge through a Brain Interaction Transformer (BIT),
allowing effective interactions between clusters of functionally-similar
brain-voxels. These functional-clusters are shared by all subjects, serving as
building blocks for integrating information both within and across brains. All
model components are shared by all clusters & subjects, allowing efficient
training with a limited amount of data. To guide the image reconstruction, BIT
predicts two complementary localized patch-level image features: (i)high-level
semantic features which steer the diffusion model toward the correct semantic
content of the image; and (ii)low-level structural features which help to
initialize the diffusion process with the correct coarse layout of the image.
BIT's design enables direct flow of information from brain-voxel clusters to
localized image features. Through these principles, our method achieves image
reconstructions from fMRI that faithfully reconstruct the seen images, and
surpass current SotA approaches both visually and by standard objective
metrics. Moreover, with only 1-hour of fMRI data from a new subject, we achieve
results comparable to current methods trained on full 40-hour recordings.

</details>


### [42] [Fine-tuning Segment Anything for Real-Time Tumor Tracking in Cine-MRI](https://arxiv.org/abs/2510.25990)
*Valentin Boussot,Cédric Hémon,Jean-Claude Nunes,Jean-Louis Dillenseger*

Main category: cs.CV

> researchers fine-tuned SAM2.1 with mask-based prompts for real-time tumor tracking in cine-MRI under data scarcity constraints, achieving a Dice score of 0.8794.

<details>
  <summary>Details</summary>

**Motivation:** to address the TrackRAD2025 challenge of real-time tumor tracking in cine-MRI sequences under strong data scarcity constraints.

**Method:** final configuration used SAM2.1 b+ with mask-based prompts from the first annotated slice, fine-tuned on the small labeled subset from TrackRAD2025.

**Result:** the model using SAM2.1 reached a Dice score of 0.8794, ranking 6th overall in the TrackRAD2025 challenge.

**Conclusion:** results showed the strong potential of foundation models for accurate and real-time tumor tracking in MRI-guided radiotherapy.

**Abstract:** In this work, we address the TrackRAD2025 challenge of real-time tumor
tracking in cine-MRI sequences of the thoracic and abdominal regions under
strong data scarcity constraints. Two complementary strategies were explored:
(i) unsupervised registration with the IMPACT similarity metric and (ii)
foundation model-based segmentation leveraging SAM 2.1 and its recent variants
through prompt-based interaction. Due to the one-second runtime constraint, the
SAM-based method was ultimately selected. The final configuration used SAM2.1
b+ with mask-based prompts from the first annotated slice, fine-tuned solely on
the small labeled subset from TrackRAD2025. Training was configured to minimize
overfitting, using 1024x1024 patches (batch size 1), standard augmentations,
and a balanced Dice + IoU loss. A low uniform learning rate (0.0001) was
applied to all modules (prompt encoder, decoder, Hiera backbone) to preserve
generalization while adapting to annotator-specific styles. Training lasted 300
epochs (~12h on RTX A6000, 48GB). The same inference strategy was consistently
applied across all anatomical sites and MRI field strengths. Test-time
augmentation was considered but ultimately discarded due to negligible
performance gains. The final model was selected based on the highest Dice
Similarity Coefficient achieved on the validation set after fine-tuning. On the
hidden test set, the model reached a Dice score of 0.8794, ranking 6th overall
in the TrackRAD2025 challenge. These results highlight the strong potential of
foundation models for accurate and real-time tumor tracking in MRI-guided
radiotherapy.

</details>


### [43] [Larger Hausdorff Dimension in Scanning Pattern Facilitates Mamba-Based Methods in Low-Light Image Enhancement](https://arxiv.org/abs/2510.26001)
*Xinhua Wang,Caibo Feng,Xiangjun Fu,Chunxiao Liu*

Main category: cs.CV

> 提出了一种改进的Mamba框架，通过引入希尔伯特选择性扫描机制提高低光图像的增强效果。

<details>
  <summary>Details</summary>

**Motivation:** 改进Mamba框架，以提高模型对低光图像的处理能力，更好地捕捉局部相互作用，同时减少长距离依赖性带来的资源消耗。

**Method:** 通过引入一种新颖的希尔伯特选择性扫描机制，增加Mamba框架扫描模式的豪斯多夫维度，以此更有效地探索特征空间，捕捉细微的细节并提高整体覆盖率。

**Result:** 实验结果表明，该方法在提高现有Mamba基础低光图像增强方法的定量和定性视觉保真度的同时，减少了计算资源消耗并缩短了推理时间。

**Conclusion:** 该方法不仅推动了低光图像增强技术的发展，而且在利用Mamba技术的更广泛领域中也具有应用潜力。

**Abstract:** We propose an innovative enhancement to the Mamba framework by increasing the
Hausdorff dimension of its scanning pattern through a novel Hilbert Selective
Scan mechanism. This mechanism explores the feature space more effectively,
capturing intricate fine-scale details and improving overall coverage. As a
result, it mitigates information inconsistencies while refining spatial
locality to better capture subtle local interactions without sacrificing the
model's ability to handle long-range dependencies. Extensive experiments on
publicly available benchmarks demonstrate that our approach significantly
improves both the quantitative metrics and qualitative visual fidelity of
existing Mamba-based low-light image enhancement methods, all while reducing
computational resource consumption and shortening inference time. We believe
that this refined strategy not only advances the state-of-the-art in low-light
image enhancement but also holds promise for broader applications in fields
that leverage Mamba-based techniques.

</details>


### [44] [CAVE: Detecting and Explaining Commonsense Anomalies in Visual Environments](https://arxiv.org/abs/2510.26006)
*Rishika Bhagwatkar,Syrielle Montariol,Angelika Romanou,Beatriz Borges,Irina Rish,Antoine Bosselut*

Main category: cs.CV

> CAVE作为首个针对真实世界视觉异常的研究基准，提供了一种新的定位方式评估视觉语言模型对于异常的识别与理解能力，研究显示即使是当前状态最好的模型在这方面也有提升的空间。

<details>
  <summary>Details</summary>

**Motivation:** 这项工作旨在填补工业缺陷或不现实的合成异常在计算机视觉领域中的空白，这些都是目前异常检测研究的局限。真正的世界异常拥有更丰富的特性和不可预测性，而现有的研究无法捕捉这些特性。

**Method:** 介绍了CAVE，这是首个对真实世界视觉异常进行基准测试的内容。CAVE支持三个开放性任务：异常描述、解释和理由提供。此外，还提供了细粒度的注释，用于视觉定位和基于视觉表现、复杂性、严重性和普遍性的异常分类。这些注释借鉴了认知科学研究中关于人类如何识别和解决异常的方法。

**Result:** 研究表明最先进的视觉语言模型（VLMs）在视觉异常的感知和常识推理方面表现不佳，即使采取了先进的提示策略。

**Conclusion:** 通过提供一个真实的且以认知为根据的基准，CAVE成为一个宝贵的资源，有助于推进视觉语言模型（VLMs）在异常检测和常识推理研究方面的进步。

**Abstract:** Humans can naturally identify, reason about, and explain anomalies in their
environment. In computer vision, this long-standing challenge remains limited
to industrial defects or unrealistic, synthetically generated anomalies,
failing to capture the richness and unpredictability of real-world anomalies.
In this work, we introduce CAVE, the first benchmark of real-world visual
anomalies. CAVE supports three open-ended tasks: anomaly description,
explanation, and justification; with fine-grained annotations for visual
grounding and categorizing anomalies based on their visual manifestations,
their complexity, severity, and commonness. These annotations draw inspiration
from cognitive science research on how humans identify and resolve anomalies,
providing a comprehensive framework for evaluating Vision-Language Models
(VLMs) in detecting and understanding anomalies. We show that state-of-the-art
VLMs struggle with visual anomaly perception and commonsense reasoning, even
with advanced prompting strategies. By offering a realistic and cognitively
grounded benchmark, CAVE serves as a valuable resource for advancing research
in anomaly detection and commonsense reasoning in VLMs.

</details>


### [45] [Climate Adaptation-Aware Flood Prediction for Coastal Cities Using Deep Learning](https://arxiv.org/abs/2510.26017)
*Bilal Hassan,Areg Karapetyan,Aaron Chung Hin Chow,Samer Madanat*

Main category: cs.CV

> 本文提出了一种基于轻量级CNN的新模型，用于预测沿海洪水。该模型相较于现有方法，在预测洪水深度方面降低了平均20%的误差。

<details>
  <summary>Details</summary>

**Motivation:** 气候变化和海平面上升对沿海城市构成了日益严重的威胁，加剧了对高效准确的潜在洪水灾害预测方法的需求。然而，传统的基于物理的流体动力学模拟器计算成本高且不适合城市规模的沿海规划应用。而深度学习技术提供了有前景的替代方案，但往往受到数据稀缺和高维输出要求等挑战的限制。

**Method:** 通过利用最近提出的基于视觉的低资源深度学习框架，我们开发了一种基于轻量级卷积神经网络（CNN）的新模型，用于预测在变量海平面上升投影和海岸线适应场景下的沿海洪水。此外，我们展示了该模型能够跨不同地理环境推广，利用来自阿布扎比和旧金山的两个不同地区的数据集进行验证。

**Result:** 研究结果表明，所提出的模型显著优于最先进的方法，平均将预测洪水深度图的平均绝对误差（MAE）降低了近20%。

**Conclusion:** 这些结果强调了我们方法在作为可扩展且实用的沿海洪水管理工具方面的潜力，使决策者能够制定应对气候变化影响的有效缓解策略。

**Abstract:** Climate change and sea-level rise (SLR) pose escalating threats to coastal
cities, intensifying the need for efficient and accurate methods to predict
potential flood hazards. Traditional physics-based hydrodynamic simulators,
although precise, are computationally expensive and impractical for city-scale
coastal planning applications. Deep Learning (DL) techniques offer promising
alternatives, however, they are often constrained by challenges such as data
scarcity and high-dimensional output requirements. Leveraging a recently
proposed vision-based, low-resource DL framework, we develop a novel,
lightweight Convolutional Neural Network (CNN)-based model designed to predict
coastal flooding under variable SLR projections and shoreline adaptation
scenarios. Furthermore, we demonstrate the ability of the model to generalize
across diverse geographical contexts by utilizing datasets from two distinct
regions: Abu Dhabi and San Francisco. Our findings demonstrate that the
proposed model significantly outperforms state-of-the-art methods, reducing the
mean absolute error (MAE) in predicted flood depth maps on average by nearly
20%. These results highlight the potential of our approach to serve as a
scalable and practical tool for coastal flood management, empowering
decision-makers to develop effective mitigation strategies in response to the
growing impacts of climate change. Project Page: https://caspiannet.github.io/

</details>


### [46] [Enhancing Temporal Understanding in Video-LLMs through Stacked Temporal Attention in Vision Encoders](https://arxiv.org/abs/2510.26027)
*Ali Rasekh,Erfan Bagheri Soula,Omid Daliran,Simon Gottschalk,Mohsen Fayyaz*

Main category: cs.CV

> 本文针对视频大语言模型在理解视频时间动态方面的不足，提出了引入堆叠时序注意力模块的新架构，并在多个基准测试中验证了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 当前的视频大语言模型在理解复杂的视频时间动态方面存在明显不足，特别是在需要详细理解动作序列和时间进展的任务中表现不佳。本文旨在解决这个关键问题。

**Method:** 本文提出了一种新的视频大语言模型（Video-LLM）架构，在视觉编码器中引入了堆叠的时序注意力模块，以改善模型对视频中动作序列和时间进展的理解。

**Result:** 实验结果显示，改进后的模型在视频问答任务（尤其是动作识别任务）中显著提升了时间推理能力，并在如VITATECS、MVBench和Video-MME等基准测试上提高了最多+5.5%的性能。

**Conclusion:** 通过增强视觉编码器的时间结构，本文提出的方法有效地解决了视频大语言模型在视频理解上的关键局限，显著提升了模型的时间推理能力。

**Abstract:** Despite significant advances in Multimodal Large Language Models (MLLMs),
understanding complex temporal dynamics in videos remains a major challenge.
Our experiments show that current Video Large Language Model (Video-LLM)
architectures have critical limitations in temporal understanding, struggling
with tasks that require detailed comprehension of action sequences and temporal
progression. In this work, we propose a Video-LLM architecture that introduces
stacked temporal attention modules directly within the vision encoder. This
design incorporates a temporal attention in vision encoder, enabling the model
to better capture the progression of actions and the relationships between
frames before passing visual tokens to the LLM. Our results show that this
approach significantly improves temporal reasoning and outperforms existing
models in video question answering tasks, specifically in action recognition.
We improve on benchmarks including VITATECS, MVBench, and Video-MME by up to
+5.5%. By enhancing the vision encoder with temporal structure, we address a
critical gap in video understanding for Video-LLMs. Project page and code are
available at: https://alirasekh.github.io/STAVEQ2/.

</details>


### [47] [FlexICL: A Flexible Visual In-context Learning Framework for Elbow and Wrist Ultrasound Segmentation](https://arxiv.org/abs/2510.26049)
*Yuyue Zhou,Jessica Knight,Shrimanti Ghosh,Banafshe Felfeliyan,Jacob L. Jaremko,Abhilash R. Hareendranathan*

Main category: cs.CV

> FlexICL is a new in-context learning framework that efficiently segments bony regions in ultrasound images using limited labeled data.

<details>
  <summary>Details</summary>

**Motivation:** The challenge of obtaining expert annotations for training DL models is addressed by creating a framework that requires annotations for only a small subset of frames.

**Method:** The method involves a novel approach to visual in-context learning with specific image concatenation techniques and augmentations to improve segmentation performance.

**Result:** The model outperforms other state-of-the-art models on four wrist and elbow US datasets with only 5% labeled images, using the Dice coefficient as a metric.

**Conclusion:** FlexICL demonstrates potential as an efficient solution for medical imaging tasks where labeled data is limited, enhancing diagnostic capabilities.

**Abstract:** Elbow and wrist fractures are the most common fractures in pediatric
populations. Automatic segmentation of musculoskeletal structures in ultrasound
(US) can improve diagnostic accuracy and treatment planning. Fractures appear
as cortical defects but require expert interpretation. Deep learning (DL) can
provide real-time feedback and highlight key structures, helping lightly
trained users perform exams more confidently. However, pixel-wise expert
annotations for training remain time-consuming and costly. To address this
challenge, we propose FlexICL, a novel and flexible in-context learning (ICL)
framework for segmenting bony regions in US images. We apply it to an
intra-video segmentation setting, where experts annotate only a small subset of
frames, and the model segments unseen frames. We systematically investigate
various image concatenation techniques and training strategies for visual ICL
and introduce novel concatenation methods that significantly enhance model
performance with limited labeled data. By integrating multiple augmentation
strategies, FlexICL achieves robust segmentation performance across four wrist
and elbow US datasets while requiring only 5% of the training images. It
outperforms state-of-the-art visual ICL models like Painter, MAE-VQGAN, and
conventional segmentation models like U-Net and TransUNet by 1-27% Dice
coefficient on 1,252 US sweeps. These initial results highlight the potential
of FlexICL as an efficient and scalable solution for US image segmentation well
suited for medical imaging use cases where labeled data is scarce.

</details>


### [48] [Dynamic VLM-Guided Negative Prompting for Diffusion Models](https://arxiv.org/abs/2510.26052)
*Hoyeon Chang,Seungjin Kim,Yoonseok Choi*

Main category: cs.CV

> 我们提出了一种新的动态负提示方法，利用视觉-语言模型在扩散模型去噪过程中自适应地生成负提示。

<details>
  <summary>Details</summary>

**Motivation:** 现有的负提示方法通常使用固定不变的负提示，这限制了其灵活性和适应性。我们的动机是通过动态生成负提示来提高扩散模型在去噪过程中的表现。

**Method:** 我们的方法是一种新颖的动态负提示生成方法，它在扩散模型的去噪过程中利用视觉-语言模型（VLM）自适应地生成负提示。与传统的固定负提示方法不同，我们在特定的去噪步骤中生成中间图像预测，并查询VLM以产生上下文相关的负提示。

**Result:** 我们的方法在多个基准数据集上进行了评估，结果显示了负引导强度与图像-文本对齐之间的权衡。

**Conclusion:** 研究结果显示我们的动态负提示方法能够改善图像生成的质量，同时揭示了在负引导强度上的优化空间。

**Abstract:** We propose a novel approach for dynamic negative prompting in diffusion
models that leverages Vision-Language Models (VLMs) to adaptively generate
negative prompts during the denoising process. Unlike traditional Negative
Prompting methods that use fixed negative prompts, our method generates
intermediate image predictions at specific denoising steps and queries a VLM to
produce contextually appropriate negative prompts. We evaluate our approach on
various benchmark datasets and demonstrate the trade-offs between negative
guidance strength and text-image alignment.

</details>


### [49] [Security Risk of Misalignment between Text and Image in Multi-modal Model](https://arxiv.org/abs/2510.26105)
*Xiaosen Wang,Zhijin Ge,Shaokang Wang*

Main category: cs.CV

> 论文揭示多模态扩散模型在处理对抗性样本时的脆弱性，提出一种新的攻击方法PReMA，通过修改图像来产生不适当内容，证明了该方法对图像编辑应用的重大威胁。

<details>
  <summary>Details</summary>

**Motivation:** 研究现有扩散模型中文本和图像模态之间的对齐在面对对抗输入时的脆弱性问题，表明现有的对齐不足以防止生成不适当的内容。

**Method:** 此论文提出了一种名为Prompt-Restricted Multi-modal Attack (PReMA) 的新攻击方法。该方法通过修改输入图像来操纵生成的内容，同时保持提示文本不变，从而生成不适当或NSFW内容。

**Result:** 实验在图像修复和风格转换任务上进行了全面评估，结果证明了PReMA的有效性。

**Conclusion:** PReMA作为一种仅通过创造对抗图像来操纵模型输出的攻击，对多模态扩散模型的完整性提出了新的威胁，特别是对于使用固定提示的图像编辑应用。

**Abstract:** Despite the notable advancements and versatility of multi-modal diffusion
models, such as text-to-image models, their susceptibility to adversarial
inputs remains underexplored. Contrary to expectations, our investigations
reveal that the alignment between textual and Image modalities in existing
diffusion models is inadequate. This misalignment presents significant risks,
especially in the generation of inappropriate or Not-Safe-For-Work (NSFW)
content. To this end, we propose a novel attack called Prompt-Restricted
Multi-modal Attack (PReMA) to manipulate the generated content by modifying the
input image in conjunction with any specified prompt, without altering the
prompt itself. PReMA is the first attack that manipulates model outputs by
solely creating adversarial images, distinguishing itself from prior methods
that primarily generate adversarial prompts to produce NSFW content.
Consequently, PReMA poses a novel threat to the integrity of multi-modal
diffusion models, particularly in image-editing applications that operate with
fixed prompts. Comprehensive evaluations conducted on image inpainting and
style transfer tasks across various models confirm the potent efficacy of
PReMA.

</details>


### [50] [EgoExo-Con: Exploring View-Invariant Video Temporal Understanding](https://arxiv.org/abs/2510.26113)
*Minjoon Jung,Junbin Xiao,Junghyun Kim,Byoung-Tak Zhang,Angela Yao*

Main category: cs.CV

> 研究揭示了Video-LLMs在处理不同视角同一事件时存在一致性问题，介绍了用于评估其能力的新基准EgoExo-Con，并提出了一种新的强化学习框架View-GRPO来解决问题。

<details>
  <summary>Details</summary>

**Motivation:** 探讨Video-LLMs在处理不同视角下同一事件时是否能实现连贯的时间理解。

**Method:** 介绍了一个名为EgoExo-Con的新基准测试，用于评估视频大型语言模型（Video-LLMs）在不同视角下对同一事件是否具有连贯的时间理解能力。它包括两个任务：时间验证和时间定位。此外，提出了一种新的强化学习框架View-GRPO，以增强在不同视角间的一致性。

**Result:** 现有的Video-LLMs在EgoExo-Con上的表现显示模型难以维持一致性，比在单一视角下的表现要差。尽管通过使用两个视角的同步视频进行微调可以改善一致性，但它们往往不如在单个视角上训练的表现。View-GRPO方法在提高跨视角一致性方面表现出色，超越了简单的微调方法。

**Conclusion:** EgoExo-Con作为一个新基准测试揭示了Video-LLMs在处理不同视角一致性的局限性。同时，提出的View-GRPO框架是一个有效的解决方案，可以增强不同视角间的时间理解一致性。

**Abstract:** Can Video-LLMs achieve consistent temporal understanding when videos capture
the same event from different viewpoints? To study this, we introduce
EgoExo-Con (Consistency), a benchmark of comprehensively synchronized
egocentric and exocentric video pairs with human-refined queries in natural
language. EgoExo-Con emphasizes two temporal understanding tasks: Temporal
Verification and Temporal Grounding. It evaluates not only correctness but
consistency across viewpoints. Our analysis reveals two critical limitations of
existing Video-LLMs: (1) models often fail to maintain consistency, with
results far worse than their single-view performances. (2) When naively
finetuned with synchronized videos of both viewpoints, the models show improved
consistency but often underperform those trained on a single view. For
improvements, we propose View-GRPO, a novel reinforcement learning framework
that effectively strengthens view-specific temporal reasoning while encouraging
consistent comprehension across viewpoints. Our method demonstrates its
superiority over naive SFT and GRPO, especially for improving cross-view
consistency. All resources will be made publicly available.

</details>


### [51] [OracleAgent: A Multimodal Reasoning Agent for Oracle Bone Script Research](https://arxiv.org/abs/2510.26114)
*Caoshuo Li,Zengmao Ding,Xiaobin Hu,Bang Li,Donghao Luo,Xu Peng,Taisong Jin,Yongge Liu,Shengwei Han,Jing Yang,Xiaoping He,Feng Gao,AndyPian Wu,SevenShu,Chaoyang Wang,Chengjie Wang*

Main category: cs.CV

> 研究提出OracleAgent系统，利用大型语言模型（LLMs）支持的多模态工具，协助甲骨文的结构化管理和检索任务，解决当前甲骨文研究在解释流程复杂性和信息检索效率方面的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 甲骨文研究面临两个主要挑战：（1）甲骨文的解释涉及一个复杂的流程，包含多个串行和并行子任务；（2）甲骨文信息组织和检索的效率仍然是关键瓶颈，学者们经常需要花费大量的时间搜索、编译和管理相关资源。

**Method:** 提出OracleAgent，这是一个针对甲骨文信息的结构化管理和检索设计的首个代理系统。该系统整合了多个甲骨文分析工具，这些工具由大型语言模型（LLMs）支持，并且可以灵活地编排这些组件。此外，通过多年严谨的数据收集、清洗和专家标注过程，构建了一个全面的领域特定多模态知识库。知识库包含超过140万个单字符拓片图像和8万个解读文本。OracleAgent通过其多模态工具协助专家进行字符、文档、解读文本和拓片图像的检索任务。

**Result:** 实验表明，OracleAgent在多模态推理和生成任务中表现出色，超越了主流的多模态大型语言模型（MLLMs，例如GPT-4o）。案例研究还表明，OracleAgent能够有效协助领域专家，显著减少甲骨文研究的时间成本。

**Conclusion:** 这些结果表明，OracleAgent是向甲骨文辅助研究和自动化解释系统实际部署迈出的重要一步。

**Abstract:** As one of the earliest writing systems, Oracle Bone Script (OBS) preserves
the cultural and intellectual heritage of ancient civilizations. However,
current OBS research faces two major challenges: (1) the interpretation of OBS
involves a complex workflow comprising multiple serial and parallel sub-tasks,
and (2) the efficiency of OBS information organization and retrieval remains a
critical bottleneck, as scholars often spend substantial effort searching for,
compiling, and managing relevant resources. To address these challenges, we
present OracleAgent, the first agent system designed for the structured
management and retrieval of OBS-related information. OracleAgent seamlessly
integrates multiple OBS analysis tools, empowered by large language models
(LLMs), and can flexibly orchestrate these components. Additionally, we
construct a comprehensive domain-specific multimodal knowledge base for OBS,
which is built through a rigorous multi-year process of data collection,
cleaning, and expert annotation. The knowledge base comprises over 1.4M
single-character rubbing images and 80K interpretation texts. OracleAgent
leverages this resource through its multimodal tools to assist experts in
retrieval tasks of character, document, interpretation text, and rubbing image.
Extensive experiments demonstrate that OracleAgent achieves superior
performance across a range of multimodal reasoning and generation tasks,
surpassing leading mainstream multimodal large language models (MLLMs) (e.g.,
GPT-4o). Furthermore, our case study illustrates that OracleAgent can
effectively assist domain experts, significantly reducing the time cost of OBS
research. These results highlight OracleAgent as a significant step toward the
practical deployment of OBS-assisted research and automated interpretation
systems.

</details>


### [52] [JOGS: Joint Optimization of Pose Estimation and 3D Gaussian Splatting](https://arxiv.org/abs/2510.26117)
*Yuxuan Li,Tao Wang,Xianben Yang*

Main category: cs.CV

> 提出了一种新的框架，无需预校准即可优化3D高斯点和相机姿态，相比传统方法，该方法在复杂场景中显著提升了新视角合成的质量。

<details>
  <summary>Details</summary>

**Motivation:** 传统的新视角合成方法严重依赖外部相机姿态估计工具，如COLMAP，这通常会引入计算瓶颈并传播误差。我们提出的方法旨在解决这些问题。

**Method:** 我们的方法提出了一种统一的框架，该框架不需要预校准输入，能够同时优化3D高斯点和相机姿态。该方法通过一个新型的协同优化策略迭代地细化3D高斯参数并更新相机姿态。主要创新在于将联合优化过程解耦为两个交替进行的阶段：首先是固定姿态下的可微渲染更新3D高斯参数，其次是使用结合了几何和光度约束的定制3D光流算法优化相机姿态。

**Result:** 在多个数据集上的广泛评估表明，我们的方法在重建质量上显著超过了现有的无需COLMAP的方法，并且在总体性能上也超过了传统的COLMAP基准方法。

**Conclusion:** 这种新型的协同优化策略显著提高了在具有大量视角变化和稀疏特征分布等复杂情况下的场景重建和姿态估计的准确性。

**Abstract:** Traditional novel view synthesis methods heavily rely on external camera pose
estimation tools such as COLMAP, which often introduce computational
bottlenecks and propagate errors. To address these challenges, we propose a
unified framework that jointly optimizes 3D Gaussian points and camera poses
without requiring pre-calibrated inputs. Our approach iteratively refines 3D
Gaussian parameters and updates camera poses through a novel co-optimization
strategy, ensuring simultaneous improvements in scene reconstruction fidelity
and pose accuracy. The key innovation lies in decoupling the joint optimization
into two interleaved phases: first, updating 3D Gaussian parameters via
differentiable rendering with fixed poses, and second, refining camera poses
using a customized 3D optical flow algorithm that incorporates geometric and
photometric constraints. This formulation progressively reduces projection
errors, particularly in challenging scenarios with large viewpoint variations
and sparse feature distributions, where traditional methods struggle. Extensive
evaluations on multiple datasets demonstrate that our approach significantly
outperforms existing COLMAP-free techniques in reconstruction quality, and also
surpasses the standard COLMAP-based baseline in general.

</details>


### [53] [WOD-E2E: Waymo Open Dataset for End-to-End Driving in Challenging Long-tail Scenarios](https://arxiv.org/abs/2510.26125)
*Runsheng Xu,Hubert Lin,Wonseok Jeon,Hao Feng,Yuliang Zou,Liting Sun,John Gorman,Kate Tolstaya,Sarah Tang,Brandyn White,Ben Sapp,Mingxing Tan,Jyh-Jing Hwang,Drago Anguelov*

Main category: cs.CV

> 本文介绍了Waymo Open Dataset for End-to-End Driving (WOD-E2E)，这是一个旨在评估复杂和罕见驾驶场景性能的数据集，并提出了一个新的评价指标RFS，以促进开发更加通用、鲁棒和安全的自动驾驶技术。

<details>
  <summary>Details</summary>

**Motivation:** 现有的端到端驾驶基准主要关注普通的驾驶场景，开放回路评估指标也无法精准评估对长尾场景的表现，这对这些系统的真实潜力测试不足。本文提出了一种新的数据集和评估方法来填补这一空缺。

**Method:** Structure

**Result:** {
  "tldr": "本文介绍了Waymo Open Dataset for End-to-End Driving (WOD-E2E)，这是一个旨在评估复杂和罕见驾驶场景性能的数据集，并提出了一个新的评价指标RFS，以促进开发更加通用、鲁棒和安全的自动驾驶技术。", 
  "motivation": "现有的端到端驾驶基准主要关注普通的驾驶场景，开放回路评估指标也无法精准评估对长尾场景的表现，这对这些系统的真实潜力测试不足。本文提出了一种新的数据集和评估方法来填补这一空缺。", 
  "method": "WOD-E2E 数据集包含针对复杂、罕见场景特制的驾驶片段，每个片段包括高阶路由信息，自我状态和来自8个环绕摄像头的360度视角。提出的新评价指标RFS使用标注者的偏好标签来衡量预测轨迹究竟有多贴近真实驾驶行为。", 
  "result": "本文发布了针对所有WOD-E2E验证集片段的标注偏好标签，并用该数据集和其提出的RFS评价指标来举办2025 WOD-E2E挑战赛。", 
  "conclusion": "通过对包含复杂和罕见场景的开放数据集WOD-E2E以及RFS评价指标的应用，本文旨在推动能够应对复杂现实世界情况的稳固、通用和安全的端到端驾驶技术的发展。" 
}

**Conclusion:** 通过对包含复杂和罕见场景的开放数据集WOD-E2E以及RFS评价指标的应用，本文旨在推动能够应对复杂现实世界情况的稳固、通用和安全的端到端驾驶技术的发展。

**Abstract:** Vision-based end-to-end (E2E) driving has garnered significant interest in
the research community due to its scalability and synergy with multimodal large
language models (MLLMs). However, current E2E driving benchmarks primarily
feature nominal scenarios, failing to adequately test the true potential of
these systems. Furthermore, existing open-loop evaluation metrics often fall
short in capturing the multi-modal nature of driving or effectively evaluating
performance in long-tail scenarios. To address these gaps, we introduce the
Waymo Open Dataset for End-to-End Driving (WOD-E2E). WOD-E2E contains 4,021
driving segments (approximately 12 hours), specifically curated for challenging
long-tail scenarios that that are rare in daily life with an occurring
frequency of less than 0.03%. Concretely, each segment in WOD-E2E includes the
high-level routing information, ego states, and 360-degree camera views from 8
surrounding cameras. To evaluate the E2E driving performance on these long-tail
situations, we propose a novel open-loop evaluation metric: Rater Feedback
Score (RFS). Unlike conventional metrics that measure the distance between
predicted way points and the logs, RFS measures how closely the predicted
trajectory matches rater-annotated trajectory preference labels. We have
released rater preference labels for all WOD-E2E validation set segments, while
the held out test set labels have been used for the 2025 WOD-E2E Challenge.
Through our work, we aim to foster state of the art research into
generalizable, robust, and safe end-to-end autonomous driving agents capable of
handling complex real-world situations.

</details>


### [54] [Exploring Object-Aware Attention Guided Frame Association for RGB-D SLAM](https://arxiv.org/abs/2510.26131)
*Ali Caglayan,Nevrez Imamoglu,Oguzhan Guclu,Ali Osman Serhatoglu,Ahmet Burak Can,Ryosuke Nakamura*

Main category: cs.CV

> 本文通过将分层注意力信息（来源于网络梯度）与CNN特征表示结合，来提升RGB-D室内SLAM的帧关联效果，实验表明在大环境中表现优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 目前，关于将基于梯度的注意力信息直接整合进CNN表示以辅助语义对象理解的研究还比较有限。本文旨在探索这种注意力信息在SLAM任务中的应用，特别是对室内RGB-D SLAM的改进。

**Method:** 本文提出了一种将任务特定的网络注意力与CNN特征表示结合的方法，以提高RGB-D室内SLAM中的帧关联性能。该方法通过从网络梯度中提取分层注意力信息并将其整合到CNN表示中，实现对空间注意力区域的更好定位。

**Result:** 实验结果表明，该方法相较于基线方法，在大型环境中显著提升了帧关联的性能。

**Conclusion:** 将任务特定的网络注意力与CNN特征结合可以有效地提高SLAM任务中的性能，尤其在大型环境中表现更佳。

**Abstract:** Attention models have recently emerged as a powerful approach, demonstrating
significant progress in various fields. Visualization techniques, such as class
activation mapping, provide visual insights into the reasoning of convolutional
neural networks (CNNs). Using network gradients, it is possible to identify
regions where the network pays attention during image recognition tasks.
Furthermore, these gradients can be combined with CNN features to localize more
generalizable, task-specific attentive (salient) regions within scenes.
However, explicit use of this gradient-based attention information integrated
directly into CNN representations for semantic object understanding remains
limited. Such integration is particularly beneficial for visual tasks like
simultaneous localization and mapping (SLAM), where CNN representations
enriched with spatially attentive object locations can enhance performance. In
this work, we propose utilizing task-specific network attention for RGB-D
indoor SLAM. Specifically, we integrate layer-wise attention information
derived from network gradients with CNN feature representations to improve
frame association performance. Experimental results indicate improved
performance compared to baseline methods, particularly for large environments.

</details>


### [55] [FullPart: Generating each 3D Part at Full Resolution](https://arxiv.org/abs/2510.26140)
*Lihe Ding,Shaocong Dong,Yaokun Li,Chenjian Gao,Xiao Chen,Rui Han,Yihao Kuang,Hong Zhang,Bo Huang,Zhanpeng Huang,Zibin Wang,Dan Xu,Tianfan Xue*

Main category: cs.CV

> FullPart提出了一种结合隐式向量集和显式体素表示的新框架，解决了3D部件生成中的几何细节不足和小部件占用体素过少的问题。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决现有3D部件生成方法在几何细节和小部件表示方面的不足。

**Method:** FullPart框架首先通过隐式方框向量集扩散过程确定边界框布局，然后在每个部件各自的全分辨率体素网格中生成详细部件，并引入了中心点编码策略以解决部件间信息交换的不对齐问题。

**Result:** FullPart在3D部件生成中取得了最先进的结果，并提出了迄今为止最大的人类标注3D部件数据集PartVerse-XL。

**Conclusion:** FullPart框架在3D部件生成中展现出显著效果，未来计划发布所有代码、数据和模型以促进该领域的研究。

**Abstract:** Part-based 3D generation holds great potential for various applications.
Previous part generators that represent parts using implicit vector-set tokens
often suffer from insufficient geometric details. Another line of work adopts
an explicit voxel representation but shares a global voxel grid among all
parts; this often causes small parts to occupy too few voxels, leading to
degraded quality. In this paper, we propose FullPart, a novel framework that
combines both implicit and explicit paradigms. It first derives the bounding
box layout through an implicit box vector-set diffusion process, a task that
implicit diffusion handles effectively since box tokens contain little
geometric detail. Then, it generates detailed parts, each within its own fixed
full-resolution voxel grid. Instead of sharing a global low-resolution space,
each part in our method - even small ones - is generated at full resolution,
enabling the synthesis of intricate details. We further introduce a
center-point encoding strategy to address the misalignment issue when
exchanging information between parts of different actual sizes, thereby
maintaining global coherence. Moreover, to tackle the scarcity of reliable part
data, we present PartVerse-XL, the largest human-annotated 3D part dataset to
date with 40K objects and 320K parts. Extensive experiments demonstrate that
FullPart achieves state-of-the-art results in 3D part generation. We will
release all code, data, and model to benefit future research in 3D part
generation.

</details>


### [56] [BasicAVSR: Arbitrary-Scale Video Super-Resolution via Image Priors and Enhanced Motion Compensation](https://arxiv.org/abs/2510.26149)
*Wei Shang,Wanying Zhang,Shuhang Gu,Pengfei Zhu,Qinghua Hu,Dongwei Ren*

Main category: cs.CV

> 本文提出BasicAVSR作为视频任意比例超分辨率的强劲基线，其方法结合了四个关键组件，展示了方法的有效性和适应性，并在多个评估标准上优于现有技术。

<details>
  <summary>Details</summary>

**Motivation:** 视频超分辨率（AVSR）的目标在于提升视频帧的分辨率，可能在各种放大倍数下进行，这在空间细节再现、时间一致性以及计算复杂度方面面临许多挑战。

**Method:** 提出了一个名为BasicAVSR的强大基线，用于处理任意比例的视频超分辨率。这个方法结合了四个关键组件：1) 从图像拉普拉斯金字塔生成的自适应多尺度频率先验；2) 一个流指导传播单元，用于聚合相邻帧的时空信息；3) 一个二次运动补偿单元，用于更精确地对齐相邻帧；4) 一个超上采样单元，用于生成尺度感知和内容无关的上采样核。同时还提出了三种传播变体，分别是单向RNN单元以严格实现在线推理，带有有限预读的单向RNN单元，以及设计用于离线任务的双向RNN单元。

**Result:** 实验结果表明了本模型在不同场景中具有有效性与适应性。通过广泛的实验，我们展示了BasicAVSR在超分辨率质量、通用性和推理速度方面比现有方法有了显著提升。

**Conclusion:** 这项工作不仅提升了AVSR领域的技术水平，还将核心组件扩展到适用于不同场景的多个框架。

**Abstract:** Arbitrary-scale video super-resolution (AVSR) aims to enhance the resolution
of video frames, potentially at various scaling factors, which presents several
challenges regarding spatial detail reproduction, temporal consistency, and
computational complexity. In this paper, we propose a strong baseline BasicAVSR
for AVSR by integrating four key components: 1) adaptive multi-scale frequency
priors generated from image Laplacian pyramids, 2) a flow-guided propagation
unit to aggregate spatiotemporal information from adjacent frames, 3) a
second-order motion compensation unit for more accurate spatial alignment of
adjacent frames, and 4) a hyper-upsampling unit to generate scale-aware and
content-independent upsampling kernels. To meet diverse application demands, we
instantiate three propagation variants: (i) a unidirectional RNN unit for
strictly online inference, (ii) a unidirectional RNN unit empowered with a
limited lookahead that tolerates a small output delay, and (iii) a
bidirectional RNN unit designed for offline tasks where computational resources
are less constrained. Experimental results demonstrate the effectiveness and
adaptability of our model across these different scenarios. Through extensive
experiments, we show that BasicAVSR significantly outperforms existing methods
in terms of super-resolution quality, generalization ability, and inference
speed. Our work not only advances the state-of-the-art in AVSR but also extends
its core components to multiple frameworks for diverse scenarios. The code is
available at https://github.com/shangwei5/BasicAVSR.

</details>


### [57] [MV-MLM: Bridging Multi-View Mammography and Language for Breast Cancer Diagnosis and Risk Prediction](https://arxiv.org/abs/2510.26151)
*Shunjie-Fabian Zheng,Hyeonjun Lee,Thijs Kooi,Ali Diba*

Main category: cs.CV

> 本文提出了一个新的MV-MLM模型，它利用多视角和合成放射报告的数据增强策略，以提高乳腺癌分类和风险预测任务中的鲁棒性和数据效率，并在三个分类任务中展示了其优越的性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型的高级注释数据集对于训练用于乳腺癌检测或风险预测的计算机辅助诊断（CAD）模型至关重要。然而，采集这样的数据集既耗时又昂贵。本文旨在探索视觉语言模型（VLMs）作为一种解决方案的可能性，通过使用CLIP等预训练于大型图像-文本对的模型，以提高医学影像任务中的鲁棒性和数据效率。

**Method:** 本文提出了一种新的多视角乳腺X线摄影和语言模型（MV-MLM），用于乳腺癌分类和风险预测。该模型使用图像-文本对的跨模态自我监督学习策略，通过合成的放射报告和多视角的数据，以提高在不同数据类型和任务上的泛化能力和准确性。

**Result:** 实验结果表明，所提出的模型在三个分类任务（恶性分类、亚型分类和基于图像的癌症风险预测）上，达到了最先进的性能。此外，该模型表现出强大的数据效率，在使用合成文本报告且无需实际放射报告的情况下，性能优于现有的全监督或VLM基线模型。

**Conclusion:** 研究表明，MV-MLM模型在乳腺癌检测和风险预测任务中展现了强大的数据效率和泛化能力，同时在不依赖实际放射报告的情况下能够达到最佳性能。这为未来的发展提供了有意义的方向。

**Abstract:** Large annotated datasets are essential for training robust Computer-Aided
Diagnosis (CAD) models for breast cancer detection or risk prediction. However,
acquiring such datasets with fine-detailed annotation is both costly and
time-consuming. Vision-Language Models (VLMs), such as CLIP, which are
pre-trained on large image-text pairs, offer a promising solution by enhancing
robustness and data efficiency in medical imaging tasks. This paper introduces
a novel Multi-View Mammography and Language Model for breast cancer
classification and risk prediction, trained on a dataset of paired mammogram
images and synthetic radiology reports. Our MV-MLM leverages multi-view
supervision to learn rich representations from extensive radiology data by
employing cross-modal self-supervision across image-text pairs. This includes
multiple views and the corresponding pseudo-radiology reports. We propose a
novel joint visual-textual learning strategy to enhance generalization and
accuracy performance over different data types and tasks to distinguish breast
tissues or cancer characteristics(calcification, mass) and utilize these
patterns to understand mammography images and predict cancer risk. We evaluated
our method on both private and publicly available datasets, demonstrating that
the proposed model achieves state-of-the-art performance in three
classification tasks: (1) malignancy classification, (2) subtype
classification, and (3) image-based cancer risk prediction. Furthermore, the
model exhibits strong data efficiency, outperforming existing fully supervised
or VLM baselines while trained on synthetic text reports and without the need
for actual radiology reports.

</details>


### [58] [Detecting Unauthorized Vehicles using Deep Learning for Smart Cities: A Case Study on Bangladesh](https://arxiv.org/abs/2510.26154)
*Sudipto Das Sukanto,Diponker Roy,Fahim Shakil,Nirjhar Singha,Abdullah Asik,Aniket Joarder,Mridha Md Nafis Fuad,Muhammad Ibrahim*

Main category: cs.CV

> 本文介绍了一种基于YOLOv8模型的实时auto-rickshaw检测系统，该系统在实际交通场景下展示了有效性和适应性，并取得了83.447%的mAP50和大于78%的二元精度和召回率。

<details>
  <summary>Details</summary>

**Motivation:** 由于传统监控系统难以区分auto-rickshaw和其他车辆（如非电动rickshaw），且手动视频分析耗时较长，因此需要开发一种自动检测交通图像中auto-rickshaw的技术。

**Method:** 本研究提出了一种基于机器学习的方法，利用YOLOv8模型进行实时的目标检测。为了训练模型，我们准备了一组1,730张在不同交通条件下拍摄的注释图像。

**Result:** 实验结果显示，该提议模型在实时auto-rickshaw检测上表现出色，取得了83.447%的mAP50和二元精度及召回率均超过78%的成绩，并可用于处理密集和稀疏的交通场景。

**Conclusion:** 研究开发的基于机器学习的auto-rickshaw检测系统在实时性上表现良好，为处理复杂交通环境下的auto-rickshaw监控提供了一种有效手段。

**Abstract:** Modes of transportation vary across countries depending on geographical
location and cultural context. In South Asian countries rickshaws are among the
most common means of local transport. Based on their mode of operation,
rickshaws in cities across Bangladesh can be broadly classified into non-auto
(pedal-powered) and auto-rickshaws (motorized). Monitoring the movement of
auto-rickshaws is necessary as traffic rules often restrict auto-rickshaws from
accessing certain routes. However, existing surveillance systems make it quite
difficult to monitor them due to their similarity to other vehicles, especially
non-auto rickshaws whereas manual video analysis is too time-consuming. This
paper presents a machine learning-based approach to automatically detect
auto-rickshaws in traffic images. In this system, we used real-time object
detection using the YOLOv8 model. For training purposes, we prepared a set of
1,730 annotated images that were captured under various traffic conditions. The
results show that our proposed model performs well in real-time auto-rickshaw
detection and offers an mAP50 of 83.447% and binary precision and recall values
above 78%, demonstrating its effectiveness in handling both dense and sparse
traffic scenarios. The dataset has been publicly released for further research.

</details>


### [59] [CRAG-MM: Multi-modal Multi-turn Comprehensive RAG Benchmark](https://arxiv.org/abs/2510.26160)
*Jiaqi Wang,Xiao Yang,Kai Sun,Parth Suresh,Sanat Sharma,Adam Czyzewski,Derek Andersen,Surya Appini,Arkav Banerjee,Sajal Choudhary,Shervin Ghasemlou,Ziqiang Guan,Akil Iyer,Haidar Khan,Lingkun Kong,Roy Luo,Tiffany Ma,Zhen Qiao,David Tran,Wenfang Xu,Skyler Yeatman,Chen Zhou,Gunveer Gujral,Yinglong Xia,Shane Moon,Nicolas Scheffer,Nirav Shah,Eun Chang,Yue Liu,Florian Metze,Tammy Stark,Zhaleh Feizollahi,Andrea Jessee,Mangesh Pujari,Ahmed Aly,Babak Damavandi,Rakesh Wanga,Anuj Kumar,Rohit Patel,Wen-tau Yih,Xin Luna Dong*

Main category: cs.CV

> 本文介绍了CRAG-MM基准测试，填补了针对穿戴设备场景下的多模态多回合对话的评测基准空白，显示了当前方法的局限性和改进空间。

<details>
  <summary>Details</summary>

**Motivation:** 多模态检索辅助生成(MM-RAG)在支持增强用户与周围环境交互的问题上扮演重要角色，但该领域特别是针对可穿戴设备场景下，缺乏全面的基准测试。此项研究旨在解决这一空白。

**Method:** 通过构建CRAG-MM基准测试来填补多模态多回合对话尤其是可穿戴设备场景下的评测基准空白。CRAG-MM包含6.5K个（图像、问题、答案）三元组和2K个基于视觉的多回合对话，跨越13个领域，以及6.2K个模仿穿戴设备捕获的视角图像。

**Result:** 评估表明，简单的RAG方法在CRAG-MM单轮和多轮QA中分别只能达到32%和43%的真实度，而最先进的行业解决方案也有类似的准确性（32%/45%），显示出改进的空间。CRAG-MM作为KDD Cup 2025的比赛吸引了大约1000名参与者和5000次提交，获胜解决方案提高了基线性能28%，凸显其对推动领域发展的早期影响。

**Conclusion:** 研究展示了CRAG-MM基准测试的重要性和实用性，以及它如何通过具体的挑战和多模态数据集促进研究，特别是对于提升多回合对话生成和信息检索的准确性。

**Abstract:** Wearable devices such as smart glasses are transforming the way people
interact with their surroundings, enabling users to seek information regarding
entities in their view. Multi-Modal Retrieval-Augmented Generation (MM-RAG)
plays a key role in supporting such questions, yet there is still no
comprehensive benchmark for this task, especially regarding wearables
scenarios. To fill this gap, we present CRAG-MM -- a Comprehensive RAG
benchmark for Multi-modal Multi-turn conversations. CRAG-MM contains a diverse
set of 6.5K (image, question, answer) triplets and 2K visual-based multi-turn
conversations across 13 domains, including 6.2K egocentric images designed to
mimic captures from wearable devices. We carefully constructed the questions to
reflect real-world scenarios and challenges, including five types of
image-quality issues, six question types, varying entity popularity, differing
information dynamism, and different conversation turns. We design three tasks:
single-source augmentation, multi-source augmentation, and multi-turn
conversations -- each paired with an associated retrieval corpus and APIs for
both image-KG retrieval and webpage retrieval. Our evaluation shows that
straightforward RAG approaches achieve only 32% and 43% truthfulness on CRAG-MM
single- and multi-turn QA, respectively, whereas state-of-the-art industry
solutions have similar quality (32%/45%), underscoring ample room for
improvement. The benchmark has hosted KDD Cup 2025, attracting about 1K
participants and 5K submissions, with winning solutions improving baseline
performance by 28%, highlighting its early impact on advancing the field.

</details>


### [60] [MoTDiff: High-resolution Motion Trajectory estimation from a single blurred image using Diffusion models](https://arxiv.org/abs/2510.26173)
*Wontae Choi,Jaelin Lee,Hyung Sup Yun,Byeungwoo Jeon,Il Yong Chun*

Main category: cs.CV

> 这篇论文提出了一种新的高分辨率运动轨迹估计框架MoTDiff，使用扩散模型且包含新的条件扩散框架和训练方法，提高了运动轨迹的精度和质量，在盲图像去模糊和编码曝光摄影应用中比现有方法表现更好。

<details>
  <summary>Details</summary>

**Motivation:** 精确的运动信息估计在计算成像和计算机视觉应用中至关重要。然而，现有的运动表示往往质量较低，通常是粗粒度且不准确的。因此，提出了一种新的高分辨率（HR）运动轨迹估计框架MoTDiff以解决这一问题。

**Method:** 我们提出了一个使用扩散模型（MoTDiff）的高分辨率（HR）运动轨迹估计框架。该框架包含两个关键组件：1）一个新的条件扩散框架，它使用从单个模糊图像中提取的多尺度特征图作为条件；2）一个新的训练方法，该方法可以促进对精细运动轨迹的精确识别，并且可以保持运动路径的整体形状和位置的一致性以及运动轨迹上的像素连通性。

**Result:** 实验表明，我们提出的MoTDiff方法可以在盲图像去模糊和编码曝光摄影应用中超越现有的最先进方法。

**Conclusion:** 本文提出的高分辨率运动轨迹估计框架MoTDiff能够从单个小运动模糊图像中估计出高质量的高分辨率运动轨迹，这对于提高图像处理的质量和效率具有重要意义。

**Abstract:** Accurate estimation of motion information is crucial in diverse computational
imaging and computer vision applications. Researchers have investigated various
methods to extract motion information from a single blurred image, including
blur kernels and optical flow. However, existing motion representations are
often of low quality, i.e., coarse-grained and inaccurate. In this paper, we
propose the first high-resolution (HR) Motion Trajectory estimation framework
using Diffusion models (MoTDiff). Different from existing motion
representations, we aim to estimate an HR motion trajectory with high-quality
from a single motion-blurred image. The proposed MoTDiff consists of two key
components: 1) a new conditional diffusion framework that uses multi-scale
feature maps extracted from a single blurred image as a condition, and 2) a new
training method that can promote precise identification of a fine-grained
motion trajectory, consistent estimation of overall shape and position of a
motion path, and pixel connectivity along a motion trajectory. Our experiments
demonstrate that the proposed MoTDiff can outperform state-of-the-art methods
in both blind image deblurring and coded exposure photography applications.

</details>


### [61] [ConceptScope: Characterizing Dataset Bias via Disentangled Visual Concepts](https://arxiv.org/abs/2510.26186)
*Jinho Choi,Hyesu Lim,Steffen Schneider,Jaegul Choo*

Main category: cs.CV

> 本文提出了ConceptScope，这是一个用于分析视觉数据集的概念发现和量化的可扩展自动化框架，能够有效识别并量化数据集偏差，以及评估模型的鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 数据集偏差广泛存在于机器学习数据集中，而现有系统识别这些偏差的方法是昂贵且细致的，并需要详细的属性标注。因此，提出ConceptScope来解决这个问题，提供一种可扩展的自动化框架来进行偏差识别。

**Method:** 通过使用基于视觉基础模型表示的稀疏自编码器，ConceptScope能够自动发现并量化人类可解释的概念，从而对视觉数据集进行分析。该框架将这些概念归类为目标、背景和偏差类型，这取决于它们对类别标签的语义相关性和统计相关性，支持从概念分组的角度进行数据集特化、偏差识别和鲁棒性评估。

**Result:** 通过与已标注数据集的对比，验证了ConceptScope能够捕捉到广泛的视觉概念（如物体、纹理、背景、面部属性、情绪和动作等）。此外，该方法产生的概念激活与图像中语义上重要的区域相符，能够可靠地检测到已知偏差和未被注释的偏差。

**Conclusion:** ConceptScope作为一种实用工具，能够进行数据集审计和模型诊断。它可以可靠地检测到已知的偏差（如水鸟背景偏差）以及之前未被注释的偏差（如ImageNet中的共现物体），为识别和量化数据集中广泛存在的偏差问题提供了一个有效的手段。

**Abstract:** Dataset bias, where data points are skewed to certain concepts, is ubiquitous
in machine learning datasets. Yet, systematically identifying these biases is
challenging without costly, fine-grained attribute annotations. We present
ConceptScope, a scalable and automated framework for analyzing visual datasets
by discovering and quantifying human-interpretable concepts using Sparse
Autoencoders trained on representations from vision foundation models.
ConceptScope categorizes concepts into target, context, and bias types based on
their semantic relevance and statistical correlation to class labels, enabling
class-level dataset characterization, bias identification, and robustness
evaluation through concept-based subgrouping. We validate that ConceptScope
captures a wide range of visual concepts, including objects, textures,
backgrounds, facial attributes, emotions, and actions, through comparisons with
annotated datasets. Furthermore, we show that concept activations produce
spatial attributions that align with semantically meaningful image regions.
ConceptScope reliably detects known biases (e.g., background bias in
Waterbirds) and uncovers previously unannotated ones (e.g, co-occurring objects
in ImageNet), offering a practical tool for dataset auditing and model
diagnostics.

</details>


### [62] [Sketch2PoseNet: Efficient and Generalized Sketch to 3D Human Pose Prediction](https://arxiv.org/abs/2510.26196)
*Li Wang,Yiyu Zhuang,Yanwen Wang,Xun Cao,Chuan Guo,Xinxin Zuo,Hao Zhu*

Main category: cs.CV

> A novel 'learn from synthesis' strategy is proposed to enhance 3D human pose estimation from sketches by overcoming limitations in previous optimization methods and the scarcity of large-scale sketch-3D pose annotations, achieving higher accuracy and speed.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to overcome the challenges of time-consuming and limited generalization in heuristic rule-based optimization and the scarcity of large-scale sketch-3D pose annotations for 3D human pose estimation from sketches.

**Method:** First, a diffusion model synthesizes sketch images from 2D poses projected from 3D human poses to create a synthetic dataset, SKEP-120K. An end-to-end data-driven framework is then introduced to estimate human poses and shapes from diverse sketch styles by combining 2D pose detectors and generative diffusion priors with a feed-forward neural network, and incorporating multiple heuristic loss functions to ensure geometric coherence and accurate self-contacts.

**Result:** Qualitative, quantitative, and subjective evaluations demonstrate that the proposed model significantly outperforms previous methods in both estimation accuracy and speed for sketch-to-pose tasks.

**Conclusion:** The novel 'learn from synthesis' approach effectively enhances the accuracy and speed of 3D human pose estimation from sketches by leveraging a synthetic dataset and a data-driven framework, thereby advancing the field.

**Abstract:** 3D human pose estimation from sketches has broad applications in computer
animation and film production. Unlike traditional human pose estimation, this
task presents unique challenges due to the abstract and disproportionate nature
of sketches. Previous sketch-to-pose methods, constrained by the lack of
large-scale sketch-3D pose annotations, primarily relied on optimization with
heuristic rules-an approach that is both time-consuming and limited in
generalizability. To address these challenges, we propose a novel approach
leveraging a "learn from synthesis" strategy. First, a diffusion model is
trained to synthesize sketch images from 2D poses projected from 3D human
poses, mimicking disproportionate human structures in sketches. This process
enables the creation of a synthetic dataset, SKEP-120K, consisting of 120k
accurate sketch-3D pose annotation pairs across various sketch styles. Building
on this synthetic dataset, we introduce an end-to-end data-driven framework for
estimating human poses and shapes from diverse sketch styles. Our framework
combines existing 2D pose detectors and generative diffusion priors for sketch
feature extraction with a feed-forward neural network for efficient 2D pose
estimation. Multiple heuristic loss functions are incorporated to guarantee
geometric coherence between the derived 3D poses and the detected 2D poses
while preserving accurate self-contacts. Qualitative, quantitative, and
subjective evaluations collectively show that our model substantially surpasses
previous ones in both estimation accuracy and speed for sketch-to-pose tasks.

</details>


### [63] [Developing a Multi-task Ensemble Geometric Deep Network for Supply Chain Sustainability and Risk Management](https://arxiv.org/abs/2510.26203)
*Mehdi Khaleghi,Nastaran Khaleghi,Sobhan Sheykhivand,Sebelan Danishvar*

Main category: cs.CV

> A new geometric deep network enhances supply chain sustainability by predicting risk and classifying products with high accuracy.

<details>
  <summary>Details</summary>

**Motivation:** To improve the sustainability and performance efficiency of the supply chain through risk management and accurate product classification, addressing fundamental challenges in supply chain management.

**Method:** A novel geometric deep network, the Chebyshev ensemble geometric network (Ch-EGN), combines convolutional and geometric deep learning to analyze supply chain datasets by leveraging information dependencies within the supply chain.

**Result:** The Ch-EGN model demonstrates high accuracy in predicting delivery statuses and classifying products and company relations, achieving average accuracies of 98.95%, 100%, 98.07%, and 92.37% respectively.

**Conclusion:** The proposed method surpasses the state-of-the-art approaches in terms of accuracy and efficiency, significantly improving supply chain sustainability and performance.

**Abstract:** The sustainability of supply chain plays a key role in achieving optimal
performance in controlling the supply chain. The management of risks that occur
in a supply chain is a fundamental problem for the purpose of developing the
sustainability of the network and elevating the performance efficiency of the
supply chain. The correct classification of products is another essential
element in a sustainable supply chain. Acknowledging recent breakthroughs in
the context of deep networks, several architectural options have been deployed
to analyze supply chain datasets. A novel geometric deep network is used to
propose an ensemble deep network. The proposed Chebyshev ensemble geometric
network (Ch-EGN) is a hybrid convolutional and geometric deep learning. This
network is proposed to leverage the information dependencies in supply chain to
derive invisible states of samples in the database. The functionality of the
proposed deep network is assessed on the two different databases. The
SupplyGraph Dataset and DataCo are considered in this research. The prediction
of delivery status of DataCo supply chain is done for risk administration. The
product classification and edge classification are performed using the
SupplyGraph database to enhance the sustainability of the supply network. An
average accuracy of 98.95% is obtained for the ensemble network for risk
management. The average accuracy of 100% and 98.07% are obtained for
sustainable supply chain in terms of 5 product group classification and 4
product relation classification, respectively. The average accuracy of 92.37%
is attained for 25 company relation classification. The results confirm an
average improvement and efficiency of the proposed method compared to the
state-of-the-art approaches.

</details>


### [64] [OmniLayout: Enabling Coarse-to-Fine Learning with LLMs for Universal Document Layout Generation](https://arxiv.org/abs/2510.26213)
*Hengrui Kang,Zhuangcheng Gu,Zhiyuan Zhao,Zichen Wen,Bin Wang,Weijia Li,Conghui He*

Main category: cs.CV

> The paper introduces OmniLayout-1M and OmniLayout-LLM to address the lack of diverse document layouts and improve layout generation, especially in complex domains.

<details>
  <summary>Details</summary>

**Motivation:** To fill the gap in document layout generation by curating a diverse dataset and introducing a generative model that can handle various document types.

**Method:** OmniLayout-LLM uses a Coarse-to-Fine learning paradigm to first learn layout principles from a large dataset of diverse layouts and then apply this knowledge to specific domains.

**Result:** Experiments show strong performance across multiple domains, outperforming existing methods and general-purpose LLMs.

**Conclusion:** The proposed approach enhances document layout generation quality and versatility, with plans to release the code, models, and dataset publicly.

**Abstract:** Document AI has advanced rapidly and is attracting increasing attention. Yet,
while most efforts have focused on document layout analysis (DLA), its
generative counterpart, document layout generation, remains underexplored. A
major obstacle lies in the scarcity of diverse layouts: academic papers with
Manhattan-style structures dominate existing studies, while open-world genres
such as newspapers and magazines remain severely underrepresented. To address
this gap, we curate OmniLayout-1M, the first million-scale dataset of diverse
document layouts, covering six common document types and comprising
contemporary layouts collected from multiple sources. Moreover, since existing
methods struggle in complex domains and often fail to arrange long sequences
coherently, we introduce OmniLayout-LLM, a 0.5B model with designed two-stage
Coarse-to-Fine learning paradigm: 1) learning universal layout principles from
OmniLayout-1M with coarse category definitions, and 2) transferring the
knowledge to a specific domain with fine-grained annotations. Extensive
experiments demonstrate that our approach achieves strong performance on
multiple domains in M$^{6}$Doc dataset, substantially surpassing both existing
layout generation experts and several latest general-purpose LLMs. Our code,
models, and dataset will be publicly released.

</details>


### [65] [Which Way Does Time Flow? A Psychophysics-Grounded Evaluation for Vision-Language Models](https://arxiv.org/abs/2510.26241)
*Shiho Matta,Lis Kanashiro Pereira,Peitao Han,Fei Cheng,Shigeru Kitazawa*

Main category: cs.CV

> 引入AoT-PsyPhyBENCH评估视觉语言模型对视频时间顺序判断的能力，发现模型在时间理解和因果推理上表现不佳，强调需进一步增强这些能力。

<details>
  <summary>Details</summary>

**Motivation:** 研究当前视觉语言模型在理解和处理视频中时间信息的弱点，并进行评估。

**Method:** 通过引入AoT-PsyPhyBENCH这一经心理物理学验证的基准测试，评估当前的多模态模型在判断视频片段时间顺序（前向播放还是逆向播放）的能力。

**Result:** 大多数模型在判断时间顺序的任务上表现差强人意，即使最好的模型在人类能够瞬间识别的物理不可逆过程（如自由落体、扩散/爆炸）和因果手动动作（如分割/添加）上的表现也远不及人。

**Conclusion:** 当前的多模态系统虽然能捕捉丰富的视觉-语义关联，但在时间连续性和因果理解方面缺乏归纳偏置。

**Abstract:** Modern vision-language models (VLMs) excel at many multimodal tasks, yet
their grasp of temporal information in video remains weak and, crucially,
under-evaluated. We probe this gap with a deceptively simple but revealing
challenge: judging the arrow of time (AoT)-whether a short clip is played
forward or backward. We introduce AoT-PsyPhyBENCH, a psychophysically validated
benchmark that tests whether VLMs can infer temporal direction in natural
videos using the same stimuli and behavioral baselines established for humans.
Our comprehensive evaluation of open-weight and proprietary, reasoning and
non-reasoning VLMs reveals that most models perform near chance, and even the
best lag far behind human accuracy on physically irreversible processes (e.g.,
free fall, diffusion/explosion) and causal manual actions (division/addition)
that humans recognize almost instantly. These results highlight a fundamental
gap in current multimodal systems: while they capture rich visual-semantic
correlations, they lack the inductive biases required for temporal continuity
and causal understanding. We release the code and data for AoT-PsyPhyBENCH to
encourage further progress in the physical and temporal reasoning capabilities
of VLMs.

</details>


### [66] [Revisiting Generative Infrared and Visible Image Fusion Based on Human Cognitive Laws](https://arxiv.org/abs/2510.26268)
*Lin Guo,Xiaoqing Luo,Wei Xie,Zhancheng Zhang,Hui Li,Rui Wang,Zhenhua Feng,Xiaoning Song*

Main category: cs.CV

> HCLFuse is proposed to improve infrared and visible image fusion by accurately extracting modal information and enhancing structural detail quality, while drawing inspiration from human cognitive laws.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the limitations of existing generative fusion methods in balancing modal information, dealing with interpretability issues, and ensuring reliability and consistency in complex scenarios. The approach is inspired by human cognitive laws.

**Method:** This manuscript proposes HCLFuse, which integrates the quantification theory of information mapping with a multi-scale mask-regulated variational bottleneck encoder to accurately extract low-level modal information. It also combines the probabilistic generative capability of the diffusion model and physical laws to create a time-varying physical guidance mechanism, enhancing the model's ability to perceive intrinsic data structures and reducing dependency on data quality.

**Result:** The proposed method achieves state-of-the-art fusion performance in both qualitative and quantitative evaluations across multiple datasets, significantly improving semantic segmentation metrics.

**Conclusion:** The generative image fusion method, inspired by human cognition, effectively enhances structural consistency and detail quality in fused images.

**Abstract:** Existing infrared and visible image fusion methods often face the dilemma of
balancing modal information. Generative fusion methods reconstruct fused images
by learning from data distributions, but their generative capabilities remain
limited. Moreover, the lack of interpretability in modal information selection
further affects the reliability and consistency of fusion results in complex
scenarios. This manuscript revisits the essence of generative image fusion
under the inspiration of human cognitive laws and proposes a novel infrared and
visible image fusion method, termed HCLFuse. First, HCLFuse investigates the
quantification theory of information mapping in unsupervised fusion networks,
which leads to the design of a multi-scale mask-regulated variational
bottleneck encoder. This encoder applies posterior probability modeling and
information decomposition to extract accurate and concise low-level modal
information, thereby supporting the generation of high-fidelity structural
details. Furthermore, the probabilistic generative capability of the diffusion
model is integrated with physical laws, forming a time-varying physical
guidance mechanism that adaptively regulates the generation process at
different stages, thereby enhancing the ability of the model to perceive the
intrinsic structure of data and reducing dependence on data quality.
Experimental results show that the proposed method achieves state-of-the-art
fusion performance in qualitative and quantitative evaluations across multiple
datasets and significantly improves semantic segmentation metrics. This fully
demonstrates the advantages of this generative image fusion method, drawing
inspiration from human cognition, in enhancing structural consistency and
detail quality.

</details>


### [67] [Exploring Complementarity and Explainability in CNNs for Periocular Verification Across Acquisition Distances](https://arxiv.org/abs/2510.26282)
*Fernando Alonso-Fernandez,Kevin Hernandez Diaz,Jose M. Buades,Kiran Raja,Josef Bigun*

Main category: cs.CV

> Study shows that fusing SqueezeNet, MobileNetv2, and ResNet50 for periocular verification, utilizing different network initializations and metrics, achieves state-of-the-art performance on UBIPr.

<details>
  <summary>Details</summary>

**Motivation:** To improve the accuracy of periocular verification across varying distances by leveraging the strengths of different CNN architectures and fusion techniques.

**Method:** We study the complementarity of different CNNs (SqueezeNet, MobileNetv2, and ResNet50) for periocular verification at different distances. We use cosine and chi2 metrics, compare network initialisations, and perform score-level fusion via logistic regression. We use LIME heatmaps and Jensen-Shannon divergence to compare the attention patterns of the networks.

**Result:** While ResNet50 performs best individually, the fusion of all three networks provides substantial gains. The networks focus on distinct image regions, explaining their complementarity, and the approach achieves state-of-the-art performance on the UBIPr database.

**Conclusion:** Combining multiple CNNs via score-level fusion, with careful consideration of network attention patterns, can significantly enhance periocular verification performance, setting a new benchmark on the UBIPr database.

**Abstract:** We study the complementarity of different CNNs for periocular verification at
different distances on the UBIPr database. We train three architectures of
increasing complexity (SqueezeNet, MobileNetv2, and ResNet50) on a large set of
eye crops from VGGFace2. We analyse performance with cosine and chi2 metrics,
compare different network initialisations, and apply score-level fusion via
logistic regression. In addition, we use LIME heatmaps and Jensen-Shannon
divergence to compare attention patterns of the CNNs. While ResNet50
consistently performs best individually, the fusion provides substantial gains,
especially when combining all three networks. Heatmaps show that networks
usually focus on distinct regions of a given image, which explains their
complementarity. Our method significantly outperforms previous works on UBIPr,
achieving a new state-of-the-art.

</details>


### [68] [Beyond Imitation: Constraint-Aware Trajectory Generation with Flow Matching For End-to-End Autonomous Driving](https://arxiv.org/abs/2510.26292)
*Lin Liu,Guanyi Yu,Ziying Song,Junqiao Li,Caiyan Jia,Feiyang Jia,Peiliang Wu,Yandan Luo*

Main category: cs.CV

> CATG is a planning framework for autonomous driving that uses Constrained Flow Matching to generate diverse and safe driving trajectories with adjustable driving styles, performing well in the NavSim v2 challenge.

<details>
  <summary>Details</summary>

**Motivation:** To overcome the issues of mode collapse in imitation learning and the inability to directly incorporate safety constraints in generative methods, leading to the need for additional optimization stages.

**Method:** CATG, a planning framework that uses Constrained Flow Matching to generate diverse and safe driving trajectories based on imitation learning. It enables the imposition of safety and kinematic constraints directly in the generation process and allows the manipulation of driving style through driving aggressiveness parameters.

**Result:** CATG achieved 2nd place in the NavSim v2 challenge with an EPDMS score of 51.31 and received the Innovation Award.

**Conclusion:** CATG effectively addresses the limitations of existing imitation learning and generative approaches in autonomous driving planning by ensuring diverse and safe trajectory generation and providing flexibility in style control.

**Abstract:** Planning is a critical component of end-to-end autonomous driving. However,
prevailing imitation learning methods often suffer from mode collapse, failing
to produce diverse trajectory hypotheses. Meanwhile, existing generative
approaches struggle to incorporate crucial safety and physical constraints
directly into the generative process, necessitating an additional optimization
stage to refine their outputs. To address these limitations, we propose CATG, a
novel planning framework that leverages Constrained Flow Matching. Concretely,
CATG explicitly models the flow matching process, which inherently mitigates
mode collapse and allows for flexible guidance from various conditioning
signals. Our primary contribution is the novel imposition of explicit
constraints directly within the flow matching process, ensuring that the
generated trajectories adhere to vital safety and kinematic rules. Secondly,
CATG parameterizes driving aggressiveness as a control signal during
generation, enabling precise manipulation of trajectory style. Notably, on the
NavSim v2 challenge, CATG achieved 2nd place with an EPDMS score of 51.31 and
was honored with the Innovation Award.

</details>


### [69] [Leveraging Large-Scale Face Datasets for Deep Periocular Recognition via Ocular Cropping](https://arxiv.org/abs/2510.26294)
*Fernando Alonso-Fernandez,Kevin Hernandez-Diaz,Jose Maria Buades Rubio,Josef Bigun*

Main category: cs.CV

> 研究发现，采用大规模数据集训练的多层卷积神经网络架构在眼周识别上表现出色，尤其是在有良好图像质量和一致性采集协议的条件下，等错误率达到了1-2%，这是迄今为止UFPR数据集上报道的最低结果。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在评估眼周区域（眼睛周围）生物识别方法，这种区域具有较高的区分度和较少的采集限制。希望通过使用大规模图像数据集进行训练，能够改善和优化眼周识别的算法效果。

**Method:** 本研究采用三种不同深度和复杂度的卷积神经网络架构，评估其在眼周区域识别中的有效性。网络是在从VGGFace2数据库提取的1,907,572个眼部图像上进行训练的。

**Result:** 实验结果表明，使用VGGFace2-Pose（VGGFace2的一个子集，包含现实环境下的人脸图像）和UFPR-Periocular数据库（包含由手机设备拍摄的自拍照）进行的实验中，使用眼部图像的等错误率(EER)在9-15%之间，而使用全脸图像的EER则在3-6%左右。UFPR-Periocular 数据库获得了更好的性能（EER为1-2%），这得益于更高的图像质量和更加一致的采集协议。

**Conclusion:** 本研究展示了一个在大规模数据集上进行训练的模型对眼周区域识别的有效性，尽管在不受控制的条件下性能略有下降，但在控制条件下取得的EER比之前的研究更低，这标志着方法上的改进。

**Abstract:** We focus on ocular biometrics, specifically the periocular region (the area
around the eye), which offers high discrimination and minimal acquisition
constraints. We evaluate three Convolutional Neural Network architectures of
varying depth and complexity to assess their effectiveness for periocular
recognition. The networks are trained on 1,907,572 ocular crops extracted from
the large-scale VGGFace2 database. This significantly contrasts with existing
works, which typically rely on small-scale periocular datasets for training
having only a few thousand images. Experiments are conducted with ocular images
from VGGFace2-Pose, a subset of VGGFace2 containing in-the-wild face images,
and the UFPR-Periocular database, which consists of selfies captured via mobile
devices with user guidance on the screen. Due to the uncontrolled conditions of
VGGFace2, the Equal Error Rates (EERs) obtained with ocular crops range from
9-15%, noticeably higher than the 3-6% EERs achieved using full-face images. In
contrast, UFPR-Periocular yields significantly better performance (EERs of
1-2%), thanks to higher image quality and more consistent acquisition
protocols. To the best of our knowledge, these are the lowest reported EERs on
the UFPR dataset to date.

</details>


### [70] [Towards Realistic Earth-Observation Constellation Scheduling: Benchmark and Methodology](https://arxiv.org/abs/2510.26297)
*Luting Wang,Yinghao Xiang,Hongliang Huang,Dongjun Li,Chen Gao,Si Liu*

Main category: cs.CV

> 本研究提出一个用于敏捷地球观测卫星集群调度的组合基准套件和调度模型，解决了现实场景中复杂调度的问题，并展示了实验结果优于基线模型。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法对AEOS（敏捷地球观测卫星）集群调度的复杂性往往进行简化，影响了真实世界的性能表现。本研究旨在通过一个包含标准化基准套件和新型调度模型的统一框架解决这一问题。

**Method:** 本研究提出了一个结合标准化基准套件和新型调度模型的统一框架。基准套件AEOS-Bench包括了3,907个精细调整的卫星资产和16,410个场景，每个场景包含1到50颗卫星和50到300个成像任务。该套件通过高保真模拟平台生成，模拟真实的卫星行为。基于该基准套件，研究进一步引入了AEOS-Former，这是一个带有约束感知注意力机制的Transformer调度模型。模型中包含了一个专门的内部约束模块，用于显式建模卫星的物理和操作限制。通过基于模拟的迭代学习，AEOS-Former能够适应各种场景，提供一个强大的AEOS集群调度解决方案。

**Result:** 实验结果显示AEOS-Former在任务完成度和能源效率方面优于基线模型，通过消融研究揭示了各组件的贡献。

**Conclusion:** 研究表明AEOS-Bench是首个针对真实星座调度的大规模基准套件，AEOS-Former提供了强大的解决方案。

**Abstract:** Agile Earth Observation Satellites (AEOSs) constellations offer unprecedented
flexibility for monitoring the Earth's surface, but their scheduling remains
challenging under large-scale scenarios, dynamic environments, and stringent
constraints. Existing methods often simplify these complexities, limiting their
real-world performance. We address this gap with a unified framework
integrating a standardized benchmark suite and a novel scheduling model. Our
benchmark suite, AEOS-Bench, contains $3,907$ finely tuned satellite assets and
$16,410$ scenarios. Each scenario features $1$ to $50$ satellites and $50$ to
$300$ imaging tasks. These scenarios are generated via a high-fidelity
simulation platform, ensuring realistic satellite behavior such as orbital
dynamics and resource constraints. Ground truth scheduling annotations are
provided for each scenario. To our knowledge, AEOS-Bench is the first
large-scale benchmark suite tailored for realistic constellation scheduling.
Building upon this benchmark, we introduce AEOS-Former, a Transformer-based
scheduling model that incorporates a constraint-aware attention mechanism. A
dedicated internal constraint module explicitly models the physical and
operational limits of each satellite. Through simulation-based iterative
learning, AEOS-Former adapts to diverse scenarios, offering a robust solution
for AEOS constellation scheduling. Experimental results demonstrate that
AEOS-Former outperforms baseline models in task completion and energy
efficiency, with ablation studies highlighting the contribution of each
component. Code and data are provided in
https://github.com/buaa-colalab/AEOSBench.

</details>


### [71] [Exploring the correlation between the type of music and the emotions evoked: A study using subjective questionnaires and EEG](https://arxiv.org/abs/2510.26304)
*Jelizaveta Jankowska,Bożena Kostek,Fernando Alonso-Fernandez,Prayag Tiwari*

Main category: cs.CV

> 研究探讨了不同类型音乐对人类情感的影响。通过EEG头盔进行主观调查和脑电波测量，结果分析展示了音乐类型与情感反应之间的联系。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在验证不同类型的音乐如何影响人类情感，并通过多元化的参与者群体（包括不同性别和音乐偏好）来捕捉广泛的情感反应。

**Method:** 通过让参与者在听不同类型的音乐时佩戴EEG头盔进行脑活动测量，并收集主观问卷数据进行分析。

**Result:** 分析得出参与者脑电波信号与问卷调查中表达的情感之间存在关联。

**Conclusion:** 研究发现了音乐类型与情感反应之间的关系，这表明不同类型的音乐确实可以对人类的情感产生影响。

**Abstract:** The subject of this work is to check how different types of music affect
human emotions. While listening to music, a subjective survey and brain
activity measurements were carried out using an EEG helmet. The aim is to
demonstrate the impact of different music genres on emotions. The research
involved a diverse group of participants of different gender and musical
preferences. This had the effect of capturing a wide range of emotional
responses to music. After the experiment, a relationship analysis of the
respondents' questionnaires with EEG signals was performed. The analysis
revealed connections between emotions and observed brain activity.

</details>


### [72] [A Hybrid Framework Bridging CNN and ViT based on Theory of Evidence for Diabetic Retinopathy Grading](https://arxiv.org/abs/2510.26315)
*Junlai Qiu,Yunzhu Chen,Hao Zheng,Yawen Huang,Yuexiang Li*

Main category: cs.CV

> The paper introduces an evidential fusion paradigm combining CNN and ViT to enhance the performance of diabetic retinopathy (DR) grading systems.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to overcome the limitations of using single-type backbone (CNN or ViT) in DR diagnosis systems and to improve the efficiency and accuracy of early diagnosis.

**Method:** The paper proposes a novel evidential fusion paradigm to integrate the features from different backbones (CNN and ViT) for DR grading, improving the local feature extraction of CNN and the global feature capturing of ViT.

**Result:** Experiments on two public DR datasets showed that the model enhanced the accuracy of DR grading and provided better interpretability in the decision-making process compared to current methods.

**Conclusion:** The hybrid model improves the accuracy of DR grading, surpassing state-of-the-art frameworks, and offers excellent interpretability for feature fusion and decision-making as demonstrated by experimental results on publicly available datasets.

**Abstract:** Diabetic retinopathy (DR) is a leading cause of vision loss among middle-aged
and elderly people, which significantly impacts their daily lives and mental
health. To improve the efficiency of clinical screening and enable the early
detection of DR, a variety of automated DR diagnosis systems have been recently
established based on convolutional neural network (CNN) or vision Transformer
(ViT). However, due to the own shortages of CNN / ViT, the performance of
existing methods using single-type backbone has reached a bottleneck. One
potential way for the further improvements is integrating different kinds of
backbones, which can fully leverage the respective strengths of them
(\emph{i.e.,} the local feature extraction capability of CNN and the global
feature capturing ability of ViT). To this end, we propose a novel paradigm to
effectively fuse the features extracted by different backbones based on the
theory of evidence. Specifically, the proposed evidential fusion paradigm
transforms the features from different backbones into supporting evidences via
a set of deep evidential networks. With the supporting evidences, the
aggregated opinion can be accordingly formed, which can be used to adaptively
tune the fusion pattern between different backbones and accordingly boost the
performance of our hybrid model. We evaluated our method on two publicly
available DR grading datasets. The experimental results demonstrate that our
hybrid model not only improves the accuracy of DR grading, compared to the
state-of-the-art frameworks, but also provides the excellent interpretability
for feature fusion and decision-making.

</details>


### [73] [GLYPH-SR: Can We Achieve Both High-Quality Image Super-Resolution and High-Fidelity Text Recovery via VLM-guided Latent Diffusion Model?](https://arxiv.org/abs/2510.26339)
*Mingyu Sung,Seungjae Ham,Kangwoo Kim,Yeokyoung Yoon,Sangseok Yun,Il-Min Kim,Jae-Mo Kang*

Main category: cs.CV

> 文章介绍了GLYPH-SR，一种用于图像超分辨率的框架，特别注重提升嵌入在自然场景中文字的可读性。

<details>
  <summary>Details</summary>

**Motivation:** 在图像超分辨率研究中，由于之前的SR研究通常针对失真（如PSNR/SSIM）或感知度量（如LIPIS、MANIQA、CLIP-IQA、MUSIQ）进行优化，忽略了字符级别的错误。特别是嵌入在自然场景中的文本信息，如果模糊或想象不清，将导致OCR和接下来的操作失败。因此，必须显式地优化文本可读性与感知质量以适应实际部署。

**Method:** GLYPH-SR, 一种视觉语言引导的扩散框架，通过文本-SR融合ControlNet（TS-ControlNet）与OCR数据指导，以及交替对文本和场景进行引导的乒乓调度器，来共同优化文本可读性和感知质量。

**Result:** 在SVT、SCUT-CTW1500、CUTE80数据集上，GLYPH-SR在扩大4倍和8倍时，与扩散/GAN基线（SVT x8, OpenOCR）相比，OCR F1最多提升15.18个百分点，同时在MANIQA、CLIP-IQA、MUSIQ上保持了竞争性。

**Conclusion:** GLYPH-SR框架能够在提高文本可读性的同时，保持较高的视觉真实感，从而实现视觉正确的图像超分辨率。

**Abstract:** Image super-resolution(SR) is fundamental to many vision system-from
surveillance and autonomy to document analysis and retail analytics-because
recovering high-frequency details, especially scene-text, enables reliable
downstream perception. Scene-text, i.e., text embedded in natural images such
as signs, product labels, and storefronts, often carries the most actionable
information; when characters are blurred or hallucinated, optical character
recognition(OCR) and subsequent decisions fail even if the rest of the image
appears sharp. Yet previous SR research has often been tuned to distortion
(PSNR/SSIM) or learned perceptual metrics (LIPIS, MANIQA, CLIP-IQA, MUSIQ) that
are largely insensitive to character-level errors. Furthermore, studies that do
address text SR often focus on simplified benchmarks with isolated characters,
overlooking the challenges of text within complex natural scenes. As a result,
scene-text is effectively treated as generic texture. For SR to be effective in
practical deployments, it is therefore essential to explicitly optimize for
both text legibility and perceptual quality. We present GLYPH-SR, a
vision-language-guided diffusion framework that aims to achieve both objectives
jointly. GLYPH-SR utilizes a Text-SR Fusion ControlNet(TS-ControlNet) guided by
OCR data, and a ping-pong scheduler that alternates between text- and
scene-centric guidance. To enable targeted text restoration, we train these
components on a synthetic corpus while keeping the main SR branch frozen.
Across SVT, SCUT-CTW1500, and CUTE80 at x4, and x8, GLYPH-SR improves OCR F1 by
up to +15.18 percentage points over diffusion/GAN baseline (SVT x8, OpenOCR)
while maintaining competitive MANIQA, CLIP-IQA, and MUSIQ. GLYPH-SR is designed
to satisfy both objectives simultaneously-high readability and high visual
realism-delivering SR that looks right and reds right.

</details>


### [74] [EEG-Driven Image Reconstruction with Saliency-Guided Diffusion Models](https://arxiv.org/abs/2510.26391)
*Igor Abramov,Ilya Makarov*

Main category: cs.CV

> 研究提出了一种结合EEG和空间显著性图的双重条件框架来提高图像生成的质量，特别是在低层次和高层次的图像特征方面。

<details>
  <summary>Details</summary>

**Motivation:** 现有的EEG驱动的图像重建方法往往忽视了空间注意力机制，这限制了图像的保真度和语义连贯性。为了解决这个问题，研究提出了该方法。

**Method:** 本研究提出了一种双重条件框架，结合EEG嵌入和空间显著性图以增强图像生成。方法利用Adaptive Thinking Mapper (ATM)进行EEG特征提取，并通过Low-Rank Adaptation (LoRA)对Stable Diffusion 2.1进行微调，以对齐神经信号与视觉语义。ControlNet分支通过显著性图对生成进行空间控制。

**Result:** 在THINGS-EEG数据集上的实验结果表明，与现有方法相比，该方法在低层次和高层次的图像特征质量上有了显著的提高，并且与人类视觉注意力高度对齐。这证明了注意力先验可以解决EEG的不明确性，使高保真重建成为可能。

**Conclusion:** 研究表明，通过有效的预训练扩散模型的适应，可以提高神经解码的效率，进而推进医疗诊断和神经适应性界面等领域的发展。

**Abstract:** Existing EEG-driven image reconstruction methods often overlook spatial
attention mechanisms, limiting fidelity and semantic coherence. To address
this, we propose a dual-conditioning framework that combines EEG embeddings
with spatial saliency maps to enhance image generation. Our approach leverages
the Adaptive Thinking Mapper (ATM) for EEG feature extraction and fine-tunes
Stable Diffusion 2.1 via Low-Rank Adaptation (LoRA) to align neural signals
with visual semantics, while a ControlNet branch conditions generation on
saliency maps for spatial control. Evaluated on THINGS-EEG, our method achieves
a significant improvement in the quality of low- and high-level image features
over existing approaches. Simultaneously, strongly aligning with human visual
attention. The results demonstrate that attentional priors resolve EEG
ambiguities, enabling high-fidelity reconstructions with applications in
medical diagnostics and neuroadaptive interfaces, advancing neural decoding
through efficient adaptation of pre-trained diffusion models.

</details>
