<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 23]
- [cs.CV](#cs.CV) [Total: 20]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Synthetic bootstrapped pretraining](https://arxiv.org/abs/2509.15248)
*Zitong Yang,Aonan Zhang,Hong Liu,Tatsunori Hashimoto,Emmanuel Candès,Chong Wang,Ruoming Pang*

Main category: cs.CL

> 本研究表明，通过提出SBP，可以有效提高语言模型在建模文档间复杂关系上的能力，实验证明，在控制计算资源一致的情况下，SBP可以达成显著的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** SBP的动机是解决标准预训练未能有效建模文档间复杂关系的问题，从而提升模型的性能。

**Method:** 我们提出了Synthetic Bootstrapped Pretraining (SBP)，这是一种语言模型预训练过程，首先从预训练数据集中学习文档之间的关系模型，然后利用该模型合成一个巨大的新语料库进行联合训练。标准预训练主要教授语言模型学习单个文档内tokens间的因果关联，而SBP旨在有效建模文档间丰富的可学习关联。

**Result:** 实验结果表明，SBP在控制计算资源一致的情况下，预训练了一个30亿参数的从零开始的模型，用到了多达1万亿token的数据。SBP相对于重复基线有一致的改进，并实现了具有访问20倍更多独立数据的oracle上限可达到性能提升的一大部分。

**Conclusion:** 定性分析揭示，合成文档不仅限于简单的释义，SBP首先从种子材料中提炼出核心概念，然后在此基础上创作新的叙述。SBP不仅表现出色，而且可自然地解释为贝叶斯模型：合成器隐式地学习抽取相关文档间共享的潜在概念。

**Abstract:** We introduce Synthetic Bootstrapped Pretraining (SBP), a language model (LM)
pretraining procedure that first learns a model of relations between documents
from the pretraining dataset and then leverages it to synthesize a vast new
corpus for joint training. While the standard pretraining teaches LMs to learn
causal correlations among tokens within a single document, it is not designed
to efficiently model the rich, learnable inter-document correlations that can
potentially lead to better performance. We validate SBP by designing a
compute-matched pretraining setup and pretrain a 3B-parameter model on up to 1T
tokens from scratch. We find SBP consistently improves upon a strong repetition
baseline and delivers a significant fraction of performance improvement
attainable by an oracle upper bound with access to 20x more unique data.
Qualitative analysis reveals that the synthesized documents go beyond mere
paraphrases -- SBP first abstracts a core concept from the seed material and
then crafts a new narration on top of it. Besides strong empirical performance,
SBP admits a natural Bayesian interpretation: the synthesizer implicitly learns
to abstract the latent concepts shared between related documents.

</details>


### [2] [Comparative Analysis of Tokenization Algorithms for Low-Resource Language Dzongkha](https://arxiv.org/abs/2509.15255)
*Tandin Wangchuk,Tad Gonsalves*

Main category: cs.CL

> 文章评估了三种分词算法在不丹语言Dzongkha上的性能并发现SentencePiece算法为最优，强调了为资源有限的语言进行定制化NLP研究的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 由于宗喀语（不丹的官方语言，约有70万人使用）是资源有限的语言，其语言复杂性提出了独特的自然语言处理（NLP）挑战。尽管取得了一些进展，但在宗喀语NLP中的分词研究仍然不足。此研究旨在填补这一空白，推动Dzongkha语言模型的发展。

**Method:** 此研究評估了三种常见的分词算法（Byte-Pair Encoding, WordPiece 和 SentencePiece）在宗喀语中的训练和性能，并将其与其他流行的方法进行比较。性能评估的指标包括子词生育能力、单词连续比例、归一化序列长度以及执行时间。

**Result:** 研究结果表明，所有三种算法都显示出潜力，但SentencePiece对于宗喀语分词最为有效。

**Conclusion:** 这项研究强调了为资源有限的语言开发定制方法的需求以及持续研究的重要性，为构建Dzongkha大型语言模型铺平了道路。

**Abstract:** Large Language Models (LLMs) are gaining popularity and improving rapidly.
Tokenizers are crucial components of natural language processing, especially
for LLMs. Tokenizers break down input text into tokens that models can easily
process while ensuring the text is accurately represented, capturing its
meaning and structure. Effective tokenizers enhance the capabilities of LLMs by
improving a model's understanding of context and semantics, ultimately leading
to better performance in various downstream tasks, such as translation,
classification, sentiment analysis, and text generation. Most pre-trained
tokenizers are suitable for high-resource languages like English but perform
poorly for low-resource languages. Dzongkha, Bhutan's national language spoken
by around seven hundred thousand people, is a low-resource language, and its
linguistic complexity poses unique NLP challenges. Despite some progress,
significant research in Dzongkha NLP is lacking, particularly in tokenization.
This study evaluates the training and performance of three common tokenization
algorithms in comparison to other popular methods. Specifically, Byte-Pair
Encoding (BPE), WordPiece, and SentencePiece (Unigram) were evaluated for their
suitability for Dzongkha. Performance was assessed using metrics like Subword
Fertility, Proportion of Continued Words, Normalized Sequence Length, and
execution time. The results show that while all three algorithms demonstrate
potential, SentencePiece is the most effective for Dzongkha tokenization,
paving the way for further NLP advancements. This underscores the need for
tailored approaches for low-resource languages and ongoing research. In this
study, we presented three tokenization algorithms for Dzongkha, paving the way
for building Dzongkha Large Language Models.

</details>


### [3] [Toxicity Red-Teaming: Benchmarking LLM Safety in Singapore's Low-Resource Languages](https://arxiv.org/abs/2509.15260)
*Yujia Hu,Ming Shan Hee,Preslav Nakov,Roy Ka-Wei Lee*

Main category: cs.CL

> 本文介绍了SGToxicGuard数据集和评估框架，用于衡量LLM在新加坡多元语言环境中的安全性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究旨在填补LLMs在低资源、多语言环境中的安全性研究空白。

**Method:** SGToxicGuard采用红队方法系统地探究了LLM在对话、问答和内容创作三种现实场景下的脆弱性。

**Result:** 实验结果揭示了先进多语言LLMs在安全护栏方面的关键差距。

**Conclusion:** 该研究为在语言多样化的环境中创建更安全、更具包容性的AI系统奠定了基础。

**Abstract:** The advancement of Large Language Models (LLMs) has transformed natural
language processing; however, their safety mechanisms remain under-explored in
low-resource, multilingual settings. Here, we aim to bridge this gap. In
particular, we introduce \textsf{SGToxicGuard}, a novel dataset and evaluation
framework for benchmarking LLM safety in Singapore's diverse linguistic
context, including Singlish, Chinese, Malay, and Tamil. SGToxicGuard adopts a
red-teaming approach to systematically probe LLM vulnerabilities in three
real-world scenarios: \textit{conversation}, \textit{question-answering}, and
\textit{content composition}. We conduct extensive experiments with
state-of-the-art multilingual LLMs, and the results uncover critical gaps in
their safety guardrails. By offering actionable insights into cultural
sensitivity and toxicity mitigation, we lay the foundation for safer and more
inclusive AI systems in linguistically diverse environments.\footnote{Link to
the dataset: https://github.com/Social-AI-Studio/SGToxicGuard.}
\textcolor{red}{Disclaimer: This paper contains sensitive content that may be
disturbing to some readers.}

</details>


### [4] [PolBiX: Detecting LLMs' Political Bias in Fact-Checking through X-phemisms](https://arxiv.org/abs/2509.15335)
*Charlott Jakob,David Harbecke,Patrick Parschan,Pia Wenzel Neves,Vera Schmitt*

Main category: cs.CL

> 研究发现，大语言模型的真实性评估受判断性词语影响比受政治倾向影响更大，且这种偏见难以通过要求客观性的提示来缓解。

<details>
  <summary>Details</summary>

**Motivation:** 虽然许多研究表明LLM存在偏向左翼的观点，但它们在诸如事实核查等任务上受政治偏见影响的情况尚未得到充分探讨。

**Method:** 通过交换德语声明中的同义词与贬义词来系统地调查政治偏见，构建在政治内涵上有所不同但事实等价的最小配对声明，以评估LLM将其分类为真或假的一致性。

**Result:** 评估了六个LLM，发现比起政治倾向，判断性词语的存在显著影响真实性评估。有些模型表现出政治偏见，但即使在提示中明确要求客观性也无法缓解这种偏见。

**Conclusion:** LLM的真实性评估受到判断性词语的影响比政治倾向更大，且这种偏见难以通过提示中的客观性要求来减轻。

**Abstract:** Large Language Models are increasingly used in applications requiring
objective assessment, which could be compromised by political bias. Many
studies found preferences for left-leaning positions in LLMs, but downstream
effects on tasks like fact-checking remain underexplored. In this study, we
systematically investigate political bias through exchanging words with
euphemisms or dysphemisms in German claims. We construct minimal pairs of
factually equivalent claims that differ in political connotation, to assess the
consistency of LLMs in classifying them as true or false. We evaluate six LLMs
and find that, more than political leaning, the presence of judgmental words
significantly influences truthfulness assessment. While a few models show
tendencies of political bias, this is not mitigated by explicitly calling for
objectivism in prompts.

</details>


### [5] [Quantifying Self-Awareness of Knowledge in Large Language Models](https://arxiv.org/abs/2509.15339)
*Yeongbin Seo,Dongha Lee,Jinyoung Yeo*

Main category: cs.CL

> 本文提出了一种量化问题意识贡献的方法AQE，分析了当前大语言模型的幻觉预测现象，发现这种性能更多是利用问题线索。为了改进这一点，又提出了SCAO，显示了其在促进模型真实自我意识方面的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 目的是解开问题线索和真正模型内部审视之间的因素，以更准确地理解大语言模型中的幻觉预测现象是否真正代表模型的自我意识。

**Method:** 文中提出了AQE（Approximate Question-side Effect），用于量化问题意识的贡献。此外，还介绍了SCAO（Semantic Compression by Answering in One word）方法，旨在提高模型内部信号的利用效果。

**Result:** 分析结果表明，许多报告的成功都源于利用问题中的浅层模式。实验显示，SCAO在减少问题线索的设置下表现强劲且一致，这突显了其在促进大型语言模型真实性自我意识方面的有效性。

**Conclusion:** 研究表明，大语言模型中的幻觉预测更多可能是由于利用问题中的浅层模式而非真正意义上的自我意识。SCAO方法有助于减少这种偏见，促进模型的真实性自我意识。

**Abstract:** Hallucination prediction in large language models (LLMs) is often interpreted
as a sign of self-awareness. However, we argue that such performance can arise
from question-side shortcuts rather than true model-side introspection. To
disentangle these factors, we propose the Approximate Question-side Effect
(AQE), which quantifies the contribution of question-awareness. Our analysis
across multiple datasets reveals that much of the reported success stems from
exploiting superficial patterns in questions. We further introduce SCAO
(Semantic Compression by Answering in One word), a method that enhances the use
of model-side signals. Experiments show that SCAO achieves strong and
consistent performance, particularly in settings with reduced question-side
cues, highlighting its effectiveness in fostering genuine self-awareness in
LLMs.

</details>


### [6] [Real, Fake, or Manipulated? Detecting Machine-Influenced Text](https://arxiv.org/abs/2509.15350)
*Yitong Wang,Zhongping Zhang,Margherita Piana,Zheng Zhou,Peter Gerstoft,Bryan A. Plummer*

Main category: cs.CL

> 本文提出了一种细粒度的机器影响文本检测方法HERO，可以区分人撰写文本、机器生成文本、机器润色文本和机器翻译文本，解决了以往只关注是否机器生成的问题。

<details>
  <summary>Details</summary>

**Motivation:** 先前的机器生成文本（MGT）检测工作主要集中在识别文档是人还是机器撰写的，忽略了这些细粒度的使用情况。该研究旨在解决这一不足，提供更细致的文本检测。

**Method:** 介绍了一种分层的、长度稳健的机器影响文本检测器（HERO），用于区分四种主要类型的文本样本：人写、机器生成、机器润色和机器翻译。HERO通过结合长度专长模型的预测完成此任务，这些模型接受子类别指导进行训练。特别是在容易混淆的类别上（例如，不同的源语言），子类别指导模块鼓励细粒度类别的分离，从而提高性能。

**Result:** 实验结果表明，HERO在区分四种类型文本的任务上表现出色，平均比现有技术高出2.5-3 mAP。

**Conclusion:** 广泛的实验表明HERO在不同大小的语言模型和六个领域中都优于现有最先进技术，平均提升了2.5-3 mAP。

**Abstract:** Large Language Model (LLMs) can be used to write or modify documents,
presenting a challenge for understanding the intent behind their use. For
example, benign uses may involve using LLM on a human-written document to
improve its grammar or to translate it into another language. However, a
document entirely produced by a LLM may be more likely to be used to spread
misinformation than simple translation (\eg, from use by malicious actors or
simply by hallucinating). Prior works in Machine Generated Text (MGT) detection
mostly focus on simply identifying whether a document was human or machine
written, ignoring these fine-grained uses. In this paper, we introduce a
HiErarchical, length-RObust machine-influenced text detector (HERO), which
learns to separate text samples of varying lengths from four primary types:
human-written, machine-generated, machine-polished, and machine-translated.
HERO accomplishes this by combining predictions from length-specialist models
that have been trained with Subcategory Guidance. Specifically, for categories
that are easily confused (\eg, different source languages), our Subcategory
Guidance module encourages separation of the fine-grained categories, boosting
performance. Extensive experiments across five LLMs and six domains demonstrate
the benefits of our HERO, outperforming the state-of-the-art by 2.5-3 mAP on
average.

</details>


### [7] [Beyond Spurious Signals: Debiasing Multimodal Large Language Models via Counterfactual Inference and Adaptive Expert Routing](https://arxiv.org/abs/2509.15361)
*Zichen Wu,Hsiu-Yuan Huang,Yunfang Wu*

Main category: cs.CL

> 本研究提出了一种新的基于因果中介的去偏框架，通过动态路由选择性地激活模态特定的去偏专家，成功降低了MLLMs中偶然相关性偏差，显著提升了模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型（MLLMs）在整合视觉和文本信息方面展现了显著能力，但它们常依赖于偶然的相关性，从而削弱了其在复杂多模态推理任务中的鲁棒性和泛化能力。

**Method:** 本研究提出了一种基于因果中介的去偏框架，通过反事实示例区分核心语义和文本及视觉中的偶然上下文，以激活训练阶段的去偏，并采用具有动态路由的专家混合（MoE）架构，选择性地参与模态特定的去偏专家。

**Result:** 实验结果表明，在多模态讽刺检测和情感分析任务中，该框架显著优于单模态去偏策略和现有最先进模型。

**Conclusion:** 通过反事实示例与动态路由相结合，本研究提出的去偏框架有效地降低了MLLMs中的偶然相关性偏差，提升了模型在复杂多模态任务中的鲁棒性和泛化能力。

**Abstract:** Multimodal Large Language Models (MLLMs) have shown substantial capabilities
in integrating visual and textual information, yet frequently rely on spurious
correlations, undermining their robustness and generalization in complex
multimodal reasoning tasks. This paper addresses the critical challenge of
superficial correlation bias in MLLMs through a novel causal mediation-based
debiasing framework. Specially, we distinguishing core semantics from spurious
textual and visual contexts via counterfactual examples to activate
training-stage debiasing and employ a Mixture-of-Experts (MoE) architecture
with dynamic routing to selectively engages modality-specific debiasing
experts. Empirical evaluation on multimodal sarcasm detection and sentiment
analysis tasks demonstrates that our framework significantly surpasses unimodal
debiasing strategies and existing state-of-the-art models.

</details>


### [8] [Speech Language Models for Under-Represented Languages: Insights from Wolof](https://arxiv.org/abs/2509.15362)
*Yaya Sy,Dioula Doucouré,Christophe Cerisara,Irina Illina*

Main category: cs.CL

> 本研究通过大规模高质量语音数据预训练HuBERT，并将其集成进Wolof语言的大规模语言模型中，从而开发出首个Wolof语言的语音LLM，并展示了其在语音识别和翻译上的优异表现。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于Wolof作为欠代表性语言所面临的挑战，研究旨在通过创新方法提高其语音技术的应用范围和性能。

**Method:** 本研究首先强调了收集大规模、自发且高质量的语音数据的重要性，并展示了在该数据集上继续预训练HuBERT模型的表现优于基础模型和专注于非洲的语言模型。接着，将此语音编码器整合进Wolof语言的大规模语言模型中，训练出首个为Wolof语言服务的语音LLM，并将其功能扩展至语音翻译等任务。此外，研究还探索了训练语音LLM执行多步骤链式思维（Chain-of-Thought）的任务，在转录或翻译之前。

**Result:** 实验结果表明，语音LLM不仅在语音识别任务上表现优异，在语音翻译任务上也有良好的表现。

**Conclusion:** 本研究展示了通过大规模高质量的语音数据预训练并集成到大规模语言模型中，可以有效地提升欠代表性语言Wolof的语音处理能力，并将其拓展至多个任务领域。

**Abstract:** We present our journey in training a speech language model for Wolof, an
underrepresented language spoken in West Africa, and share key insights. We
first emphasize the importance of collecting large-scale, spontaneous,
high-quality speech data, and show that continued pretraining HuBERT on this
dataset outperforms both the base model and African-centric models on ASR. We
then integrate this speech encoder into a Wolof LLM to train the first Speech
LLM for this language, extending its capabilities to tasks such as speech
translation. Furthermore, we explore training the Speech LLM to perform
multi-step Chain-of-Thought before transcribing or translating. Our results
show that the Speech LLM not only improves speech recognition but also performs
well in speech translation. The models and the code will be openly shared.

</details>


### [9] [Frustratingly Easy Data Augmentation for Low-Resource ASR](https://arxiv.org/abs/2509.15373)
*Katsumi Ibaraki,David Chiang*

Main category: cs.CL

> This paper outlines three data augmentation methods for ASR in low-resource settings, significantly improving performance through synthetic data generation and fine-tuning of the Wav2Vec2-XLSR-53 model.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to address the scarcity of annotated data in low-resource languages, which is a critical issue for the development of ASR models.

**Method:** The paper proposes three data augmentation techniques for low-resource ASR tasks: gloss-based replacement, random replacement, and an LLM-based approach. These methods generate new textual data which is then transformed into synthetic audio using TTS.

**Result:** By integrating the original annotated data with the newly generated synthetic data, the fine-tuned Wav2Vec2-XLSR-53 model exhibited marked performance improvements across four low-resource languages, notably a 14.3% decrease in WER for Nashta.

**Conclusion:** The data augmentation methods introduced in the paper proved effective not only in boosting the performance of low-resource languages but also showed promise when applied to high-resource languages like English, indicating broad applicability.

**Abstract:** This paper introduces three self-contained data augmentation methods for
low-resource Automatic Speech Recognition (ASR). Our techniques first generate
novel text--using gloss-based replacement, random replacement, or an LLM-based
approach--and then apply Text-to-Speech (TTS) to produce synthetic audio. We
apply these methods, which leverage only the original annotated data, to four
languages with extremely limited resources (Vatlongos, Nashta, Shinekhen
Buryat, and Kakabe). Fine-tuning a pretrained Wav2Vec2-XLSR-53 model on a
combination of the original audio and generated synthetic data yields
significant performance gains, including a 14.3% absolute WER reduction for
Nashta. The methods prove effective across all four low-resource languages and
also show utility for high-resource languages like English, demonstrating their
broad applicability.

</details>


### [10] [Quantifying Uncertainty in Natural Language Explanations of Large Language Models for Question Answering](https://arxiv.org/abs/2509.15403)
*Yangyi Li,Mengdi Huai*

Main category: cs.CL

> 本文提出了一种新的不确定性估计框架，用于大语言模型生成的自然语言解释，并设计了一种鲁棒的不确定性估计方法，即使在有噪声的情况下也能保持有效的不确定性保证。实验表明，这些方法在问答任务上是有效的。

<details>
  <summary>Details</summary>

**Motivation:** 虽然自然语言解释在解释大语言模型时表现良好，但此前的研究并未提供其不确定性保证，这对于理解解释的信任度至关重要。

**Method:** Structure

**Result:** {
  "tldr": "本文提出了一种新的不确定性估计框架，用于大语言模型生成的自然语言解释，该框架以一种事后且模型无关的方式提供有效的不确定性保证。此外，还设计了一种新的鲁棒不确定性估计方法，即使在有噪音的情况下也能保持有效的不确定性保证。实验结果表明了方法的有效性。", 
  "motivation": "尽管大语言模型具备强大的能力，但缺乏透明性。虽然自然语言解释是一种流行的解释方法，但目前尚无研究探讨如何为这些解释提供有效的不确定性保证，这对于理解解释的置信度至关重要。因此，本文提出了解决这一问题的方法框架。", 
  "method": "本文提出了一个新型的不确定性估计框架，用于评估在大语言模型生成自然语言解释的不确定性，并设计了一种在有噪声情况下仍能保持有效性的鲁棒不确定性估计方法。", 
  "result": "大量的实验表明，本文提出的方法在问答任务上性能良好。", 
  "conclusion": "提出的方法框架和不确定估计方法有效填补了提供自然语言解释不确定性保证的空白，且具备鲁棒性和泛化性。实验结果支持了这种方法的有效性。"}
}

**Conclusion:** 本文提出的方法不仅填补了研究空白，还表现出良好的鲁棒性和泛化性能。实验结果支持这些方法的有效性。

**Abstract:** Large language models (LLMs) have shown strong capabilities, enabling
concise, context-aware answers in question answering (QA) tasks. The lack of
transparency in complex LLMs has inspired extensive research aimed at
developing methods to explain large language behaviors. Among existing
explanation methods, natural language explanations stand out due to their
ability to explain LLMs in a self-explanatory manner and enable the
understanding of model behaviors even when the models are closed-source.
However, despite these promising advancements, there is no existing work
studying how to provide valid uncertainty guarantees for these generated
natural language explanations. Such uncertainty quantification is critical in
understanding the confidence behind these explanations. Notably, generating
valid uncertainty estimates for natural language explanations is particularly
challenging due to the auto-regressive generation process of LLMs and the
presence of noise in medical inquiries. To bridge this gap, in this work, we
first propose a novel uncertainty estimation framework for these generated
natural language explanations, which provides valid uncertainty guarantees in a
post-hoc and model-agnostic manner. Additionally, we also design a novel robust
uncertainty estimation method that maintains valid uncertainty guarantees even
under noise. Extensive experiments on QA tasks demonstrate the desired
performance of our methods.

</details>


### [11] [Deep learning and abstractive summarisation for radiological reports: an empirical study for adapting the PEGASUS models' family with scarce data](https://arxiv.org/abs/2509.15419)
*Claudio Benzoni,Martina Langhals,Martin Boeker,Luise Modersohn,Máté E. Maros*

Main category: cs.CL

> The paper investigates the fine-tuning process of PEGASUS and PEGASUS-X for abstractive summarization in radiology, highlighting difficulties and risks in fine-tuning models with scarce data.

<details>
  <summary>Details</summary>

**Motivation:** The paper aims to address the challenges in abstractive summarization for sensitive domains like medicine and to provide insights on avoiding over- and underfitting during the fine-tuning process.

**Method:** We used PEGASUS and PEGASUS-X, on a medium-sized radiological reports public dataset. For each model, we comprehensively evaluated two different checkpoints with varying sizes of the same training data.

**Result:** For PEGASUS, different phases were observed during training which can be related to epoch-wise double-descent or peak-drop-recovery behaviour. For PEGASUS-X, using a larger checkpoint led to a decline in performance.

**Conclusion:** This work highlights the challenges and risks of fine-tuning models with high expressivity when dealing with scarce training data, and lays the groundwork for future investigations into more robust fine-tuning strategies for summarisation models in specialised domains.

**Abstract:** Regardless of the rapid development of artificial intelligence, abstractive
summarisation is still challenging for sensitive and data-restrictive domains
like medicine. With the increasing number of imaging, the relevance of
automated tools for complex medical text summarisation is expected to become
highly relevant. In this paper, we investigated the adaptation via fine-tuning
process of a non-domain-specific abstractive summarisation encoder-decoder
model family, and gave insights to practitioners on how to avoid over- and
underfitting. We used PEGASUS and PEGASUS-X, on a medium-sized radiological
reports public dataset. For each model, we comprehensively evaluated two
different checkpoints with varying sizes of the same training data. We
monitored the models' performances with lexical and semantic metrics during the
training history on the fixed-size validation set. PEGASUS exhibited different
phases, which can be related to epoch-wise double-descent, or
peak-drop-recovery behaviour. For PEGASUS-X, we found that using a larger
checkpoint led to a performance detriment. This work highlights the challenges
and risks of fine-tuning models with high expressivity when dealing with scarce
training data, and lays the groundwork for future investigations into more
robust fine-tuning strategies for summarisation models in specialised domains.

</details>


### [12] [BiRQ: Bi-Level Self-Labeling Random Quantization for Self-Supervised Speech Recognition](https://arxiv.org/abs/2509.15430)
*Liuyuan Jiang,Xiaodong Cui,Brian Kingsbury,Tianyi Chen,Lisha Chen*

Main category: cs.CL

> BiRQ combines the computational efficiency of BEST-RQ with the label refinement of HuBERT for speech self-supervised learning, improving performance on large datasets while keeping complexity low.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind BiRQ is to address the core challenge in speech self-supervised learning of generating pseudo-labels that are both informative and efficient, as previous methods trade off between strong labels and computational efficiency.

**Method:** BiRQ is a bilevel self-supervised learning framework for speech processing. It integrates the efficiency of BEST-RQ with the label refinement benefits of HuBERT by using a part of the model itself to generate pseudo-labels. Intermediate representations are quantized to create enhanced labels, with anchoring labels derived from raw input for training stability.

**Result:** BiRQ demonstrates consistent improvements over BEST-RQ across various datasets, maintaining a low complexity and computational efficiency. It was tested on large-scale datasets such as 960-hour LibriSpeech, 150-hour AMI meetings, and 5,000-hour YODAS.

**Conclusion:** BiRQ enhances the quality of pseudo-labels for self-supervised learning in speech processing, improving downstream speech recognition performance without increasing computational complexity or memory cost, validating its approach through improvements over BEST-RQ on large speech datasets.

**Abstract:** Speech is a rich signal, and labeled audio-text pairs are costly, making
self-supervised learning essential for scalable representation learning. A core
challenge in speech SSL is generating pseudo-labels that are both informative
and efficient: strong labels, such as those used in HuBERT, improve downstream
performance but rely on external encoders and multi-stage pipelines, while
efficient methods like BEST-RQ achieve simplicity at the cost of weaker labels.
We propose BiRQ, a bilevel SSL framework that combines the efficiency of
BEST-RQ with the refinement benefits of HuBERT-style label enhancement. The key
idea is to reuse part of the model itself as a pseudo-label generator:
intermediate representations are discretized by a random-projection quantizer
to produce enhanced labels, while anchoring labels derived directly from the
raw input stabilize training and prevent collapse. Training is formulated as an
efficient first-order bilevel optimization problem, solved end-to-end with
differentiable Gumbel-softmax selection. This design eliminates the need for
external label encoders, reduces memory cost, and enables iterative label
refinement in an end-to-end fashion. BiRQ consistently improves over BEST-RQ
while maintaining low complexity and computational efficiency. We validate our
method on various datasets, including 960-hour LibriSpeech, 150-hour AMI
meetings and 5,000-hour YODAS, demonstrating consistent gains over BEST-RQ.

</details>


### [13] [PILOT: Steering Synthetic Data Generation with Psychological & Linguistic Output Targeting](https://arxiv.org/abs/2509.15447)
*Caitlin Cisar,Emily Sheffield,Joshua Drake,Alden Harrell,Subramanian Chidambaram,Nikita Nangia,Vinayak Arannil,Alex Williams*

Main category: cs.CL

> PILOT是一种通过多维心理语言学配置文件来精确控制大型语言模型生成的新方法，它改进了传统自然语言角色描述的不足，通过实验在多个大语言模型上验证了其有效性和优势。

<details>
  <summary>Details</summary>

**Motivation:** 虽然生成性AI应用通常利用用户角色作为合成数据生成的引导机制，但是对自然语言表示的依赖迫使模型在哪些属性上进行强调做出无意中的推断，从而限制了对输出的精确控制。

**Method:** PILOT (Psychological and Linguistic Output Targeting) 是一个两阶段框架，用于利用结构化的心理语言学配置文件来引导大型语言模型。第一阶段将自然语言人物描述转换为跨语言和心理维度的多维配置文件。第二阶段则根据这些配置文件，沿着可量化的变异轴线引导生成。

**Result:** 研究结果表明，基于模式的方法显著降低了人工角色重复，同时提高了输出的一致性，轮廓分数从0.098增加到0.237，主题纯度从0.773增加到0.957。同时，混合角色-模式引导实现了在这两个极端之间的平衡，保持了输出多样性的同时保留了结构一致性。

**Conclusion:** 专家语言评估证实，PILOT在所有条件下都保持了高质量的响应，且在不同引导方法之间没有显著的统计差异。这表明PILOT在增强生成内容的结构一致性和多样性之间找到了良好的平衡。

**Abstract:** Generative AI applications commonly leverage user personas as a steering
mechanism for synthetic data generation, but reliance on natural language
representations forces models to make unintended inferences about which
attributes to emphasize, limiting precise control over outputs. We introduce
PILOT (Psychological and Linguistic Output Targeting), a two-phase framework
for steering large language models with structured psycholinguistic profiles.
In Phase 1, PILOT translates natural language persona descriptions into
multidimensional profiles with normalized scores across linguistic and
psychological dimensions. In Phase 2, these profiles guide generation along
measurable axes of variation. We evaluate PILOT across three state-of-the-art
LLMs (Mistral Large 2, Deepseek-R1, LLaMA 3.3 70B) using 25 synthetic personas
under three conditions: Natural-language Persona Steering (NPS), Schema-Based
Steering (SBS), and Hybrid Persona-Schema Steering (HPS). Results demonstrate
that schema-based approaches significantly reduce artificial-sounding persona
repetition while improving output coherence, with silhouette scores increasing
from 0.098 to 0.237 and topic purity from 0.773 to 0.957. Our analysis reveals
a fundamental trade-off: SBS produces more concise outputs with higher topical
consistency, while NPS offers greater lexical diversity but reduced
predictability. HPS achieves a balance between these extremes, maintaining
output variety while preserving structural consistency. Expert linguistic
evaluation confirms that PILOT maintains high response quality across all
conditions, with no statistically significant differences between steering
approaches.

</details>


### [14] [Evaluating Multimodal Large Language Models on Spoken Sarcasm Understanding](https://arxiv.org/abs/2509.15476)
*Zhu Li,Xiyuan Gao,Yuqing Zhang,Shekhar Nayak,Matt Coler*

Main category: cs.CL

> 该论文评估了大规模语言模型和多模态LLMs在讽刺检测任务上的表现，并展示了多模态模型在跨模态讽刺理解中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 讽刺的意图通常依赖于跨越文本、语音和视觉的微妙的跨模态线索，而之前的大多数工作主要集中于文本的或视听文本讽刺的理解，缺乏综合的音频-视觉-文本讽刺理解。

**Method:** 使用大规模语言模型（LLMs）和多模态LLMs在零样本、少量样本和LoRA微调设置下对英语（MUStARD++）和中文（MCSD 1.0）中的讽刺检测进行了系统的评估。除了直接分类外，还探讨了将模型作为特征编码器，通过协作门控融合模块整合其表示的方法。

**Result:** 实验结果显示音频模型在单模态性能中表现最好，而文字-音频和音频-视觉组合超过了单模态和三模态模型。多模态语言模型（如Qwen-Omni）在零样本和微调设置下表现出了竞争力。

**Conclusion:** 该研究发现突显了多模态语言模型在跨语言、音频-视觉-文本讽刺理解的潜力。

**Abstract:** Sarcasm detection remains a challenge in natural language understanding, as
sarcastic intent often relies on subtle cross-modal cues spanning text, speech,
and vision. While prior work has primarily focused on textual or visual-textual
sarcasm, comprehensive audio-visual-textual sarcasm understanding remains
underexplored. In this paper, we systematically evaluate large language models
(LLMs) and multimodal LLMs for sarcasm detection on English (MUStARD++) and
Chinese (MCSD 1.0) in zero-shot, few-shot, and LoRA fine-tuning settings. In
addition to direct classification, we explore models as feature encoders,
integrating their representations through a collaborative gating fusion module.
Experimental results show that audio-based models achieve the strongest
unimodal performance, while text-audio and audio-vision combinations outperform
unimodal and trimodal models. Furthermore, MLLMs such as Qwen-Omni show
competitive zero-shot and fine-tuned performance. Our findings highlight the
potential of MLLMs for cross-lingual, audio-visual-textual sarcasm
understanding.

</details>


### [15] [Red Teaming Multimodal Language Models: Evaluating Harm Across Prompt Modalities and Models](https://arxiv.org/abs/2509.15478)
*Madison Van Doren,Casey Ford,Emily Dix*

Main category: cs.CL

> The study evaluates the safety of four leading MLLMs under adversarial conditions, finding significant differences in their vulnerability to harmful outputs.

<details>
  <summary>Details</summary>

**Motivation:** To assess the harmlessness of MLLMs when exposed to adversarial prompts, addressing the underexplored area of their safety.

**Method:** A team generated adversarial prompts targeting illegal activity, disinformation, and unethical behavior, which were rated for harmfulness by annotators.

**Result:** Pixtral 12B showed the highest rate of harmful responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%). Text-only prompts were slightly more effective at bypassing safety mechanisms than multimodal ones.

**Conclusion:** The study highlights the need for robust safety benchmarks for MLLMs in diverse applications.

**Abstract:** Multimodal large language models (MLLMs) are increasingly used in real world
applications, yet their safety under adversarial conditions remains
underexplored. This study evaluates the harmlessness of four leading MLLMs
(GPT-4o, Claude Sonnet 3.5, Pixtral 12B, and Qwen VL Plus) when exposed to
adversarial prompts across text-only and multimodal formats. A team of 26 red
teamers generated 726 prompts targeting three harm categories: illegal
activity, disinformation, and unethical behaviour. These prompts were submitted
to each model, and 17 annotators rated 2,904 model outputs for harmfulness
using a 5-point scale. Results show significant differences in vulnerability
across models and modalities. Pixtral 12B exhibited the highest rate of harmful
responses (~62%), while Claude Sonnet 3.5 was the most resistant (~10%).
Contrary to expectations, text-only prompts were slightly more effective at
bypassing safety mechanisms than multimodal ones. Statistical analysis
confirmed that both model type and input modality were significant predictors
of harmfulness. These findings underscore the urgent need for robust,
multimodal safety benchmarks as MLLMs are deployed more widely.

</details>


### [16] [mucAI at BAREC Shared Task 2025: Towards Uncertainty Aware Arabic Readability Assessment](https://arxiv.org/abs/2509.15485)
*Ahmed Abdou*

Main category: cs.CL

> 提出了一种简单的后处理技术，用于提高细粒度阿拉伯语可读性分类的QWK分数。这种方法减少了高惩罚误分类，对不同模型提高了1-3个QWK分数点，并在BAREC 2025共享任务中取得了优异的QWK分数。

<details>
  <summary>Details</summary>

**Motivation:** 我们的方法旨在通过减少高惩罚的误分类并提高QWK分数，改善细粒度阿拉伯语可读性分类效果。

**Method:** 我们提出了一种简单的、与模型无关的后处理技术，应用于细粒度阿拉伯语可读性分类任务。该方法通过生成具有覆盖保证的预测集来应用符合性预测，然后使用softmax重归一化概率的加权平均计算。这种方法提高了不确定性意识解码，减少了高惩罚误分类，从而改善了Quadratic Weighted Kappa (QWK)分数。

**Result:** 对不同的基础模型，我们的方法一致改善了QWK分数，提高了1-3个分数点。严格赛道的提交在句子级别上实现了84.9%(测试集)和85.7%(盲测集)的QWK分数，在文档级别上达到了73.3%的QWK分数。

**Conclusion:** 此方法为阿拉伯语教育评估提供了一种结合统计保证和实际实用性的方案，使人工审阅者能够关注少数几个可能的等级。

**Abstract:** We present a simple, model-agnostic post-processing technique for
fine-grained Arabic readability classification in the BAREC 2025 Shared Task
(19 ordinal levels). Our method applies conformal prediction to generate
prediction sets with coverage guarantees, then computes weighted averages using
softmax-renormalized probabilities over the conformal sets. This
uncertainty-aware decoding improves Quadratic Weighted Kappa (QWK) by reducing
high-penalty misclassifications to nearer levels. Our approach shows consistent
QWK improvements of 1-3 points across different base models. In the strict
track, our submission achieves QWK scores of 84.9\%(test) and 85.7\% (blind
test) for sentence level, and 73.3\% for document level. For Arabic educational
assessment, this enables human reviewers to focus on a handful of plausible
levels, combining statistical guarantees with practical usability.

</details>


### [17] [LLM Cache Bandit Revisited: Addressing Query Heterogeneity for Cost-Effective LLM Inference](https://arxiv.org/abs/2509.15515)
*Hantao Yang,Hong Xie,Defu Lian,Enhong Chen*

Main category: cs.CL

> 本文解决了大型语言模型（LLM）在异构查询条件下的成本效益推理问题，提出了一种新的基于累积的策略来处理缓存选择问题，并通过理论分析和实验证明了其有效性和先进性。

<details>
  <summary>Details</summary>

**Motivation:** 该论文重新审视了大型语言模型（LLM）缓存多臂赌博问题，特别是关注解决成本效益的LLM推理中的查询异构性问题。

**Method:** 我们将缓存选择视为背包问题，并采用基于累积的策略来有效平衡计算开销和缓存更新。

**Result:** 理论上，我们证明了算法的后悔值达到了$O(\sqrt{MNT})$的界，相对于Berkeley的$O(MN\sqrt{T})$结果，在$\sqrt{MN}$系数上有所改进。此外，我们还提供了一个问题依赖的界，这是之前工作所没有的。实验结果显示，我们的算法减少了大约12%的总成本。

**Conclusion:** 本文提出的方法相较于之前的工作，在理论分析上有了改进，并且在现实数据集上的实验验证了其可以减少大约12%的总成本，展示出实际应用效果。

**Abstract:** This paper revisits the LLM cache bandit problem, with a special focus on
addressing the query heterogeneity for cost-effective LLM inference. Previous
works often assume uniform query sizes. Heterogeneous query sizes introduce a
combinatorial structure for cache selection, making the cache replacement
process more computationally and statistically challenging. We treat optimal
cache selection as a knapsack problem and employ an accumulation-based strategy
to effectively balance computational overhead and cache updates. In theoretical
analysis, we prove that the regret of our algorithm achieves an $O(\sqrt{MNT})$
bound, improving the coefficient of $\sqrt{MN}$ compared to the $O(MN\sqrt{T})$
result in Berkeley, where $N$ is the total number of queries and $M$ is the
cache size. Additionally, we also provide a problem-dependent bound, which was
absent in previous works. The experiment rely on real-world data show that our
algorithm reduces the total cost by approximately 12\%.

</details>


### [18] [How do Language Models Generate Slang: A Systematic Comparison between Human and Machine-Generated Slang Usages](https://arxiv.org/abs/2509.15518)
*Siyang Wu,Zhewei Sun*

Main category: cs.CL

> 该研究表明，尽管大型语言模型在某些方面掌握了俚语的创意使用，但其认知方式仍存在显著偏见，限制了它们在语言分析任务中的应用。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型（LLMs）的进步使其能更好地应对俚语挑战，但这些模型的泛化能力和可靠性取决于其是否捕捉到了与人类使用相吻合的俚语结构知识。因此，研究旨在系统比较人类和机器生成的俚语用法，以评估LLMs在处理俚语方面的表现。

**Method:** 该研究通过比较人类和机器生成的俚语用法来系统性地评估大型语言模型对俚语的理解能力。评估框架关注三个方面：1) 机器对俚语的系统性偏见特征，2) 通过词汇创造和词汇再利用反映的创造力，3) 俚语用作模型蒸馏的黄金标准示例时提供的信息量。

**Result:** 研究结果表明，尽管大型语言模型（LLMs）捕捉到了俚语创造方面的大量知识，但这些知识与人类的认知并不充分吻合，这使得LLMs在诸如语言分析等外推任务上的表现能力受到限制。

**Conclusion:** 研究发现，虽然LLMs在处理俚语的创造性方面表现出了显著的知识，但这些知识并未与人类认知充分对齐，从而限制了模型在更广泛语言任务上的表现。

**Abstract:** Slang is a commonly used type of informal language that poses a daunting
challenge to NLP systems. Recent advances in large language models (LLMs),
however, have made the problem more approachable. While LLM agents are becoming
more widely applied to intermediary tasks such as slang detection and slang
interpretation, their generalizability and reliability are heavily dependent on
whether these models have captured structural knowledge about slang that align
well with human attested slang usages. To answer this question, we contribute a
systematic comparison between human and machine-generated slang usages. Our
evaluative framework focuses on three core aspects: 1) Characteristics of the
usages that reflect systematic biases in how machines perceive slang, 2)
Creativity reflected by both lexical coinages and word reuses employed by the
slang usages, and 3) Informativeness of the slang usages when used as
gold-standard examples for model distillation. By comparing human-attested
slang usages from the Online Slang Dictionary (OSD) and slang generated by
GPT-4o and Llama-3, we find significant biases in how LLMs perceive slang. Our
results suggest that while LLMs have captured significant knowledge about the
creative aspects of slang, such knowledge does not align with humans
sufficiently to enable LLMs for extrapolative tasks such as linguistic
analyses.

</details>


### [19] [A method for improving multilingual quality and diversity of instruction fine-tuning datasets](https://arxiv.org/abs/2509.15549)
*Chunguang Zhao,Yilun Liu,Pufan Zeng,Yuanchang Luo,Shimin Tao,Minggui He,Weibin Meng,Song Xu,Ziang Chen,Chen Liu,Hongxia Ma,Li Zhang,Boxing Chen,Daimeng Wei*

Main category: cs.CL

> Introducing M-DaQ, a method for selecting high-quality multilingual data to improve the performance of large language models, which shows significant gains across 18 languages.

<details>
  <summary>Details</summary>

**Motivation:** To address the challenges in achieving effective multilinguality in large language models due to the lack of high-quality multilingual training data and the limitations of existing data selection methods.

**Method:** Multilingual Data Quality and Diversity (M-DaQ), a method for selecting high-quality and semantically diverse multilingual Instruction Fine-Tuning (IFT) samples to enhance the performance of large language models across multiple languages.

**Result:** Empirical results across 18 languages show that models fine-tuned with M-DaQ achieve significant performance gains over vanilla baselines with a win rate over 60%. Human evaluations further confirm these improvements, particularly noting an increase in culturally relevant content in responses.

**Conclusion:** The introduction of M-DaQ demonstrates its effectiveness in improving the multilinguality of large language models, providing a robust method for enhancing performance and cultural relevance across diverse languages.

**Abstract:** Multilingual Instruction Fine-Tuning (IFT) is essential for enabling large
language models (LLMs) to generalize effectively across diverse linguistic and
cultural contexts. However, the scarcity of high-quality multilingual training
data and corresponding building method remains a critical bottleneck. While
data selection has shown promise in English settings, existing methods often
fail to generalize across languages due to reliance on simplistic heuristics or
language-specific assumptions. In this work, we introduce Multilingual Data
Quality and Diversity (M-DaQ), a novel method for improving LLMs
multilinguality, by selecting high-quality and semantically diverse
multilingual IFT samples. We further conduct the first systematic investigation
of the Superficial Alignment Hypothesis (SAH) in multilingual setting.
Empirical results across 18 languages demonstrate that models fine-tuned with
M-DaQ method achieve significant performance gains over vanilla baselines over
60% win rate. Human evaluations further validate these gains, highlighting the
increment of cultural points in the response. We release the M-DaQ code to
support future research.

</details>


### [20] [DNA-DetectLLM: Unveiling AI-Generated Text via a DNA-Inspired Mutation-Repair Paradigm](https://arxiv.org/abs/2509.15550)
*Xiaowei Zhu,Yubing Ren,Fang Fang,Qingfeng Tan,Shi Wang,Yanan Cao*

Main category: cs.CL

> 我们提出了一种名为DNA-DetectLLM的零样本方法，用于检测AI生成的文本，该方法通过构建理想的AI生成序列并通过迭代修复非最优标记来捕捉人写文本和AI生成文本之间的差异。实验证明，该方法在多个公共基准数据集上取得了比之前最好的检测性能高出5.55%和2.08%的表现，并且能抵御各种对抗攻击。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型的快速发展，AI生成文本与人类编写文本之间的界限越来越模糊，这带来了诸如虚假信息、作者身份模糊和知识产权问题等社会风险，表明需要可靠的方法来检测AI生成的文本。然而，最近生成语言模型的进步使得人类编写和AI生成文本的特征分布重叠显著，使得准确检测越来越具有挑战性。

**Method:** 我们提出了一种DNA启发的视角，通过基于修复过程直接且可解释地捕捉人写文本和AI生成文本之间的内在差异。具体来说，我们引入了DNA-DetectLLM这一零样本检测方法，该方法为每个输入构建一个理想的AI生成序列，迭代修复非最优标记，并将累积修复努力量作为可解释的检测信号。

**Result:** 实验证明，我们的方法实现了最先进的检测性能，表现出对各种对抗攻击和输入长度的强鲁棒性。DNA-DetectLLM在多个公开数据集上实现了5.55%的AUROC和2.08%的F1评分的相对改进。

**Conclusion:** 该研究提出了DNA-DetectLLM作为先进的文本检测方法，通过基于DNA修复理念设计模型，提升了对AI生成文本检测的准确性与鲁棒性。

**Abstract:** The rapid advancement of large language models (LLMs) has blurred the line
between AI-generated and human-written text. This progress brings societal
risks such as misinformation, authorship ambiguity, and intellectual property
concerns, highlighting the urgent need for reliable AI-generated text detection
methods. However, recent advances in generative language modeling have resulted
in significant overlap between the feature distributions of human-written and
AI-generated text, blurring classification boundaries and making accurate
detection increasingly challenging. To address the above challenges, we propose
a DNA-inspired perspective, leveraging a repair-based process to directly and
interpretably capture the intrinsic differences between human-written and
AI-generated text. Building on this perspective, we introduce DNA-DetectLLM, a
zero-shot detection method for distinguishing AI-generated and human-written
text. The method constructs an ideal AI-generated sequence for each input,
iteratively repairs non-optimal tokens, and quantifies the cumulative repair
effort as an interpretable detection signal. Empirical evaluations demonstrate
that our method achieves state-of-the-art detection performance and exhibits
strong robustness against various adversarial attacks and input lengths.
Specifically, DNA-DetectLLM achieves relative improvements of 5.55% in AUROC
and 2.08% in F1 score across multiple public benchmark datasets.

</details>


### [21] [Exploring Polyglot Harmony: On Multilingual Data Allocation for Large Language Models Pretraining](https://arxiv.org/abs/2509.15556)
*Ping Guo,Yubing Ren,Binbin Liu,Fengze Liu,Haobin Lin,Yifan Zhang,Bingni Zhang,Taifeng Wang,Yin Zheng*

Main category: cs.CL

> 本文介绍了一种名为Climb的框架，用于优化多语言数据的分配，以解决大型语言模型中语言比例分配的问题，实现更好的多语言性能。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)在全球范围内广泛的应用和有效多语言能力的需求推动了其发展。但要实现稳健的多语言性能，一个核心问题是如何在训练语料库中战略性地分配语言比例，这由于跨语言交互的复杂性和数据集规模的敏感性非常具有挑战性。

**Method:** Climb框架通过引入跨语言交互感知的语言比例，量化每种语言的有效分配，捕捉语言间的依赖关系。该框架提出一个双步优化过程：首先使各语言的边际效益均衡化，然后最大化生成的语言分配向量的大小，从而简化复杂的多语言优化问题。

**Result:** 实验结果证明Climb可以准确测量各种多语言设置中的跨语言交互情况。使用Climb得出的比例训练的LLM可以稳定地达到最先进的多语言性能，甚至在使用较少token的情况下与开源LLM具有竞争力。

**Conclusion:** Climb框架提供了一种新的方法来解决多语言性能优化问题，通过双步优化过程简化了复杂问题，证明了其在提高多语言性能方面的有效性和竞争力。

**Abstract:** Large language models (LLMs) have become integral to a wide range of
applications worldwide, driving an unprecedented global demand for effective
multilingual capabilities. Central to achieving robust multilingual performance
is the strategic allocation of language proportions within training corpora.
However, determining optimal language ratios is highly challenging due to
intricate cross-lingual interactions and sensitivity to dataset scale. This
paper introduces Climb (Cross-Lingual Interaction-aware Multilingual
Balancing), a novel framework designed to systematically optimize multilingual
data allocation. At its core, Climb introduces a cross-lingual
interaction-aware language ratio, explicitly quantifying each language's
effective allocation by capturing inter-language dependencies. Leveraging this
ratio, Climb proposes a principled two-step optimization procedure--first
equalizing marginal benefits across languages, then maximizing the magnitude of
the resulting language allocation vectors--significantly simplifying the
inherently complex multilingual optimization problem. Extensive experiments
confirm that Climb can accurately measure cross-lingual interactions across
various multilingual settings. LLMs trained with Climb-derived proportions
consistently achieve state-of-the-art multilingual performance, even achieving
competitive performance with open-sourced LLMs trained with more tokens.

</details>


### [22] [How important is language for human-like intelligence?](https://arxiv.org/abs/2509.15560)
*Gary Lupyan,Hunter Gentry,Martin Zettersten*

Main category: cs.CL

> 语言可能对于更通用的人工智能系统的出现和人类智能的关键方面是至关重要的。语言的两个关键特性，即紧凑表示和集体心智迭代输出，使得它成为开发通用能力的强大工具。

<details>
  <summary>Details</summary>

**Motivation:** 随着人工智能和认知科学的发展，重新提出了语言对人类认知的影响问题，以及语言是否在人脑中扮演了更具有变革性的角色。

**Method:** 通过分析语言在人工智能和认知科学中的作用来探讨语言对思维的影响。认为语言对于更通用的人工智能系统的出现和人类智能的核心方面可能是关键。文章指出语言的两个相关特性使其成为开发通用能力的强大工具：紧凑的表示形式和集体心智的迭代输出。

**Result:** 语言作为集体心智迭代输出的紧凑表示形式，可以反向工程出支持人类或其他人类类似思维的概念和因果结构。从而，强大的学习系统（无论是生物系统还是人工系统）在接触语言后，可以学习到一个压缩的世界模型。

**Conclusion:** 语言不仅是思维方式的表达，而且还对思维的形成起到了关键作用，尤其是在发展通用能力和推动人工智能系统的发展上。

**Abstract:** We use language to communicate our thoughts. But is language merely the
expression of thoughts, which are themselves produced by other, nonlinguistic
parts of our minds? Or does language play a more transformative role in human
cognition, allowing us to have thoughts that we otherwise could (or would) not
have? Recent developments in artificial intelligence (AI) and cognitive science
have reinvigorated this old question. We argue that language may hold the key
to the emergence of both more general AI systems and central aspects of human
intelligence. We highlight two related properties of language that make it such
a powerful tool for developing domain--general abilities. First, language
offers compact representations that make it easier to represent and reason
about many abstract concepts (e.g., exact numerosity). Second, these compressed
representations are the iterated output of collective minds. In learning a
language, we learn a treasure trove of culturally evolved abstractions. Taken
together, these properties mean that a sufficiently powerful learning system
exposed to language--whether biological or artificial--learns a compressed
model of the world, reverse engineering many of the conceptual and causal
structures that support human (and human-like) thought.

</details>


### [23] [LiteLong: Resource-Efficient Long-Context Data Synthesis for LLMs](https://arxiv.org/abs/2509.15568)
*Junlong Jia,Xing Wu,Chaochen Gao,Ziyang Chen,Zijia Lin,Zhongzhi Li,Weinong Wang,Haotian Xu,Donghui Jin,Debing Zhang,Binghui Guo*

Main category: cs.CL

> LiteLong利用BISAC图书分类系统进行结构化主题组织和多代理辩论生成高质量长上下文数据，成本比传统方法低，在HELMET和Ruler基准上取得优秀效果。

<details>
  <summary>Details</summary>

**Motivation:** 解决当前基于相关性聚合方法生成长上下文数据计算效率低的问题，为训练能够处理长文档的LLMs提供高质量的长上下文数据。

**Method:** 采用BISAC图书分类系统进行主题层次组织，利用多代理辩论生成多样化话题，并使用轻量级BM25检索获取相关文档，生成128K-token的训练样本。

**Result:** 研究提出了LiteLong方法，利用结构化主题组织和多代理辩论机制生成适合训练大语言模型（LLMs）的高质量长上下文数据。通过使用BISAC图书分类系统进行主题组织，并结合多LLM辩论生成多样化内容。实验表明，LiteLong在HELMET和Ruler基准测试上表现出优异长上下文性能，且计算和数据工程成本减少，推进了长上下文语言模型训练研究。

**Conclusion:** LiteLong通过结构化主题组织和低成本计算减少了生成高质量长上下文数据的难度，这有助于推进长上下文语言模型的研究。

**Abstract:** High-quality long-context data is essential for training large language
models (LLMs) capable of processing extensive documents, yet existing synthesis
approaches using relevance-based aggregation face challenges of computational
efficiency. We present LiteLong, a resource-efficient method for synthesizing
long-context data through structured topic organization and multi-agent debate.
Our approach leverages the BISAC book classification system to provide a
comprehensive hierarchical topic organization, and then employs a debate
mechanism with multiple LLMs to generate diverse, high-quality topics within
this structure. For each topic, we use lightweight BM25 retrieval to obtain
relevant documents and concatenate them into 128K-token training samples.
Experiments on HELMET and Ruler benchmarks demonstrate that LiteLong achieves
competitive long-context performance and can seamlessly integrate with other
long-dependency enhancement methods. LiteLong makes high-quality long-context
data synthesis more accessible by reducing both computational and data
engineering costs, facilitating further research in long-context language
training.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [24] [Exploring the Capabilities of LLM Encoders for Image-Text Retrieval in Chest X-rays](https://arxiv.org/abs/2509.15234)
*Hanbin Ko,Gihun Cho,Inhyeok Baek,Donguk Kim,Joonbeom Koo,Changi Kim,Dongheon Lee,Chang Min Park*

Main category: cs.CV

> 我们通过LLM2VEC4CXR和LLM2CLIP4CXR模型，展示了大规模语言模型在处理异质性和噪音报告时的稳健性对于医学图像-文本对齐的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉-语言预训练在图像-文本对齐上取得了进展，但在放射学中的进展受到临床报告异质性的限制。放射学报告中包括缩写、仅有印象的笔记以及样式上的多变性。与一般领域设定中数据量越大数据性能越好的情况不同，在放射学中盲目地扩大到大量复杂报告可能使模型性能停滞甚至下降。我们想要探究大规模语言模型（LLM）编码器是否能提供稳健的临床表示，以支持跨多样风格的图像-文本对齐。

**Method:** 我们提出了LLM2VEC4CXR，一种针对胸透报告的领域适应的大语言模型编码器，以及LLM2CLIP4CXR，一个将该编码器与视觉骨干相结合的双塔框架。LLM2VEC4CXR改进了对临床文本的理解，处理缩写和风格差异，并在报告级别的指标上展示了强大的临床一致性。LLM2CLIP4CXR利用这些嵌入式表示提升检索精度和临床导向的得分，展现出比先前的医疗CLIP变体更强的跨数据集泛化能力。

**Result:** 我们的模型在160万公共和私人来源的胸透研究数据上进行训练，其中包含异质且复杂的报告。结果显示，我们的模型在医学图像-文本表示学习中，稳健性——而非单纯尺度——是实现有效的多模态学习的关键。

**Conclusion:** 研究表明，使用领域适应的大型语言模型编码器LLM2VEC4CXR能够提升对医疗文本的理解和风格变异的处理能力，同时与视觉骨干结合的框架LLM2CLIP4CXR在图像文本对齐上表现优秀，证明了在医疗图像文本学习中，模型的稳健性是取得优秀效果的关键因素。

**Abstract:** Vision-language pretraining has advanced image-text alignment, yet progress
in radiology remains constrained by the heterogeneity of clinical reports,
including abbreviations, impression-only notes, and stylistic variability.
Unlike general-domain settings where more data often leads to better
performance, naively scaling to large collections of noisy reports can plateau
or even degrade model learning. We ask whether large language model (LLM)
encoders can provide robust clinical representations that transfer across
diverse styles and better guide image-text alignment. We introduce LLM2VEC4CXR,
a domain-adapted LLM encoder for chest X-ray reports, and LLM2CLIP4CXR, a
dual-tower framework that couples this encoder with a vision backbone.
LLM2VEC4CXR improves clinical text understanding over BERT-based baselines,
handles abbreviations and style variation, and achieves strong clinical
alignment on report-level metrics. LLM2CLIP4CXR leverages these embeddings to
boost retrieval accuracy and clinically oriented scores, with stronger
cross-dataset generalization than prior medical CLIP variants. Trained on 1.6M
CXR studies from public and private sources with heterogeneous and noisy
reports, our models demonstrate that robustness -- not scale alone -- is the
key to effective multimodal learning. We release models to support further
research in medical image-text representation learning.

</details>


### [25] [ViSpec: Accelerating Vision-Language Models with Vision-Aware Speculative Decoding](https://arxiv.org/abs/2509.15235)
*Jialiang Kang,Han Shu,Wenshuo Li,Yingjie Zhai,Xinghao Chen*

Main category: cs.CV

> 本文提出了一种名为ViSpec的新框架，用来加速视觉语言模型的推测解码过程，通过轻量级的视觉适配器将图像压缩，并增强多模态一致性。实验结果表明，这是首次在VLM中实现显著加速的技术。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于目前针对视觉语言模型（VLM）的推测解码技术尚未得到充分探索，现有的方法仅实现了有限的加速效果，本文旨在填补大型多模态能力模型中的这一空白。我们假设大型VLM可以逐层有效过滤冗余图像信息，而不影响文本理解，而较小的草图模型则难以做到这一点。

**Method:** 提出了一种针对视觉语言模型的新型框架——视觉感知推测解码（ViSpec），该框架使用轻量级的视觉适配模块将图像令牌压缩成紧凑表示，并将其无缝集成到草图模型的注意力机制中，同时保持原始图像位置信息。此外，为每张输入图像提取全局特征向量，并将其与随后的所有文本标记相结合，以增强多模态一致性。为了克服长助手响应的多模态数据集稀缺问题，通过重新利用现有的数据集并使用带有修改提示的目标VLM生成扩展输出来编制专门的训练数据集。训练策略通过在仅基于目标模型输出进行训练时防止草图模型利用对目标模型隐藏状态的直接访问来减轻捷径学习的风险。

**Result:** 广泛的实验验证了ViSpec，实现了据我们所知，首个在视觉语言模型推测解码中的实质性加速。

**Conclusion:** 研究表明，视觉感知推测解码（ViSpec）框架能够显著加速视觉语言模型（VLM）的推理过程，这是首次在VLM中实现显著加速的技术。

**Abstract:** Speculative decoding is a widely adopted technique for accelerating inference
in large language models (LLMs), yet its application to vision-language models
(VLMs) remains underexplored, with existing methods achieving only modest
speedups (<1.5x). This gap is increasingly significant as multimodal
capabilities become central to large-scale models. We hypothesize that large
VLMs can effectively filter redundant image information layer by layer without
compromising textual comprehension, whereas smaller draft models struggle to do
so. To address this, we introduce Vision-Aware Speculative Decoding (ViSpec), a
novel framework tailored for VLMs. ViSpec employs a lightweight vision adaptor
module to compress image tokens into a compact representation, which is
seamlessly integrated into the draft model's attention mechanism while
preserving original image positional information. Additionally, we extract a
global feature vector for each input image and augment all subsequent text
tokens with this feature to enhance multimodal coherence. To overcome the
scarcity of multimodal datasets with long assistant responses, we curate a
specialized training dataset by repurposing existing datasets and generating
extended outputs using the target VLM with modified prompts. Our training
strategy mitigates the risk of the draft model exploiting direct access to the
target model's hidden states, which could otherwise lead to shortcut learning
when training solely on target model outputs. Extensive experiments validate
ViSpec, achieving, to our knowledge, the first substantial speedup in VLM
speculative decoding.

</details>


### [26] [M-PACE: Mother Child Framework for Multimodal Compliance](https://arxiv.org/abs/2509.15241)
*Shreyash Verma,Amit Kesari,Vinayak Trivedi,Anupam Purwar,Ratnesh Jamidar*

Main category: cs.CV

> 论文提出M-PACE，一种可以更高效处理多模态内容合规问题的框架，适用于广告行业，显著降低成本并提高效率。

<details>
  <summary>Details</summary>

**Motivation:** 传统合规框架通常依赖于分散的多阶段管道，这增加了操作开销，限制了扩展性，并且难以适应动态规范。因此，作者提出M-PACE框架以应对跨多模态内容的复杂合规挑战。

**Method:** 提出了多模态参数无关合规引擎（M-PACE），该框架能够在一次通过中评估视觉和文本输入的各种属性。其应用案例是广告合规评估，能够评估超过15个与合规相关的属性。M-PACE使用母子多模态大型语言模型（MLLM）架构，显示出较强的模型可以评估较小模型的输出，从而减少对人类评审员的依赖，实现质量控制的自动化。

**Result:** M-PACE在广告数据上的分析表明，推理成本降低了超过31倍，其中最高效的模型（由母MLLM选择的Gemini 2.0 Flash作为子模型）每个图像的成本仅为0.0005，相比具有相当精度的Gemini 2.5 Pro降低了0.0154，从而实现了成本和输出质量之间的权衡。

**Conclusion:** M-PACE能够在一次通过中有效地处理跨多模态输入的属性评估，特别是在广告合规方面显示出显著的成本效率和质量控制能力。

**Abstract:** Ensuring that multi-modal content adheres to brand, legal, or
platform-specific compliance standards is an increasingly complex challenge
across domains. Traditional compliance frameworks typically rely on disjointed,
multi-stage pipelines that integrate separate modules for image classification,
text extraction, audio transcription, hand-crafted checks, and rule-based
merges. This architectural fragmentation increases operational overhead,
hampers scalability, and hinders the ability to adapt to dynamic guidelines
efficiently. With the emergence of Multimodal Large Language Models (MLLMs),
there is growing potential to unify these workflows under a single,
general-purpose framework capable of jointly processing visual and textual
content. In light of this, we propose Multimodal Parameter Agnostic Compliance
Engine (M-PACE), a framework designed for assessing attributes across
vision-language inputs in a single pass. As a representative use case, we apply
M-PACE to advertisement compliance, demonstrating its ability to evaluate over
15 compliance-related attributes. To support structured evaluation, we
introduce a human-annotated benchmark enriched with augmented samples that
simulate challenging real-world conditions, including visual obstructions and
profanity injection. M-PACE employs a mother-child MLLM setup, demonstrating
that a stronger parent MLLM evaluating the outputs of smaller child models can
significantly reduce dependence on human reviewers, thereby automating quality
control. Our analysis reveals that inference costs reduce by over 31 times,
with the most efficient models (Gemini 2.0 Flash as child MLLM selected by
mother MLLM) operating at 0.0005 per image, compared to 0.0159 for Gemini 2.5
Pro with comparable accuracy, highlighting the trade-off between cost and
output quality achieved in real time by M-PACE in real life deployment over
advertising data.

</details>


### [27] [ProFusion: 3D Reconstruction of Protein Complex Structures from Multi-view AFM Images](https://arxiv.org/abs/2509.15242)
*Jaydeep Rade,Md Hasibul Hasan Hasib,Meric Ozturk,Baboucarr Faal,Sheng Yang,Dipali G. Sashital,Vincenzo Venditti,Baoyu Chen,Soumik Sarkar,Adarsh Krishnamurthy,Anwesha Sarkar*

Main category: cs.CV

> This paper presents ProFusion, a hybrid AI framework combining a deep learning model with AFM to predict 3D structures of large protein complexes with high fidelity and at a lower cost than experimental techniques.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve the prediction of protein complex structures using AI, as existing in silico methods struggle with large protein complexes due to the lack of 3D spatial cues. Experimental methods like Cryo-EM are accurate but expensive and time-consuming.

**Method:** ProFusion is a hybrid framework integrating a deep learning model with Atomic Force Microscopy (AFM), using a dataset of ~542,000 proteins with multi-view synthetic AFM images generated by a virtual AFM framework.

**Result:** The method is validated with an average Chamfer Distance within the resolution of AFM imaging, showing high fidelity in the 3D reconstruction of protein complexes.

**Conclusion:** The framework achieves an average Chamfer Distance within the AFM imaging resolution, demonstrating high structural fidelity and potential for rapid iterative validation of protein complex structures using AFM experiments.

**Abstract:** AI-based in silico methods have improved protein structure prediction but
often struggle with large protein complexes (PCs) involving multiple
interacting proteins due to missing 3D spatial cues. Experimental techniques
like Cryo-EM are accurate but costly and time-consuming. We present ProFusion,
a hybrid framework that integrates a deep learning model with Atomic Force
Microscopy (AFM), which provides high-resolution height maps from random
orientations, naturally yielding multi-view data for 3D reconstruction.
However, generating a large-scale AFM imaging data set sufficient to train deep
learning models is impractical. Therefore, we developed a virtual AFM framework
that simulates the imaging process and generated a dataset of ~542,000 proteins
with multi-view synthetic AFM images. We train a conditional diffusion model to
synthesize novel views from unposed inputs and an instance-specific Neural
Radiance Field (NeRF) model to reconstruct 3D structures. Our reconstructed 3D
protein structures achieve an average Chamfer Distance within the AFM imaging
resolution, reflecting high structural fidelity. Our method is extensively
validated on experimental AFM images of various PCs, demonstrating strong
potential for accurate, cost-effective protein complex structure prediction and
rapid iterative validation using AFM experiments.

</details>


### [28] [Multi-Modal Interpretability for Enhanced Localization in Vision-Language Models](https://arxiv.org/abs/2509.15243)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

> The paper introduces MMEL, a framework that improves the interpretability of vision-language models through a Hierarchical Semantic Relationship Module, achieving higher performance and reliability in safety-critical applications.

<details>
  <summary>Details</summary>

**Motivation:** To address the challenges in applying vision-language models in safety-critical contexts due to the need for transparency and reliability.

**Method:** MMEL builds on Grad-eclip and introduces a Hierarchical Semantic Relationship Module that processes features at multiple semantic levels to capture relationships between image regions, using adaptive attention weighting and multi-scale feature processing.

**Result:** Experiments show that MMEL produces focused and contextually aware visualizations that better reflect how vision-language models process complex scenes, providing valuable insights into model decisions.

**Conclusion:** MMEL offers enhanced interpretability while maintaining high performance, making vision-language models more suitable for applications requiring high reliability.

**Abstract:** Recent advances in vision-language models have significantly expanded the
frontiers of automated image analysis. However, applying these models in
safety-critical contexts remains challenging due to the complex relationships
between objects, subtle visual cues, and the heightened demand for transparency
and reliability. This paper presents the Multi-Modal Explainable Learning
(MMEL) framework, designed to enhance the interpretability of vision-language
models while maintaining high performance. Building upon prior work in
gradient-based explanations for transformer architectures (Grad-eclip), MMEL
introduces a novel Hierarchical Semantic Relationship Module that enhances
model interpretability through multi-scale feature processing, adaptive
attention weighting, and cross-modal alignment. Our approach processes features
at multiple semantic levels to capture relationships between image regions at
different granularities, applying learnable layer-specific weights to balance
contributions across the model's depth. This results in more comprehensive
visual explanations that highlight both primary objects and their contextual
relationships with improved precision. Through extensive experiments on
standard datasets, we demonstrate that by incorporating semantic relationship
information into gradient-based attribution maps, MMEL produces more focused
and contextually aware visualizations that better reflect how vision-language
models process complex scenes. The MMEL framework generalizes across various
domains, offering valuable insights into model decisions for applications
requiring high interpretability and reliability.

</details>


### [29] [Walk and Read Less: Improving the Efficiency of Vision-and-Language Navigation via Tuning-Free Multimodal Token Pruning](https://arxiv.org/abs/2509.15250)
*Wenda Qin,Andrea Burns,Bryan A. Plummer,Margrit Betke*

Main category: cs.CV

> 提出了一种导航感知剪枝（NAP）方法，该方法利用导航特定特性过滤并简化剪枝过程，避免信息丢失和增加计算成本，实验表明NAP在标准VLN基准上表现优于之前的工作，同时保存超过50%的计算量。

<details>
  <summary>Details</summary>

**Motivation:** 大型模型在视觉和语言导航任务中表现出色，但在资源有限的环境中运行成本高昂。现有的剪枝技术往往忽视了视觉和语言导航中的特定挑战，导致剪枝后的信息损失增加了计算成本，因此需要提出一种新的剪枝方法来解决这一问题。

**Method:** Structure

**Result:** { "tldr": "提出了一种导航感知剪枝（NAP）方法，该方法利用导航特定特性过滤并简化剪枝过程，避免信息丢失和增加计算成本，实验表明NAP在标准VLN基准上表现优于之前的工作，同时保存超过50%的计算量。", "motivation": "大型模型在视觉和语言导航任务中表现出色，但在资源有限的环境中运行成本高昂。现有的剪枝技术往往忽视了视觉和语言导航中的特定挑战，导致剪枝后的信息损失增加了计算成本，因此需要提出一种新的剪枝方法来解决这一问题。", "method": "NAP方法通过将令牌预分类为前景和背景，并使用大型语言模型提取导航相关信息，主要集中在剪枝背景令牌来最小化信息损失。同时，它还通过移除低重要性的导航节点来避免倒退，进一步缩短导航路径长度。", "result": "实验结果表明，在标准的VLN基准测试中，NAP相比之前的工作不仅提高了成功率，而且还节省了超过50%的计算量（FLOPS）。", "conclusion": "通过实验验证了NAP方法的有效性，证明该方法在保持甚至提高导航任务性能的同时，能够显著降低计算成本。" }

**Conclusion:** 通过实验验证了NAP方法的有效性，证明该方法在保持甚至提高导航任务性能的同时，能够显著降低计算成本。

**Abstract:** Large models achieve strong performance on Vision-and-Language Navigation
(VLN) tasks, but are costly to run in resource-limited environments. Token
pruning offers appealing tradeoffs for efficiency with minimal performance loss
by reducing model input size, but prior work overlooks VLN-specific challenges.
For example, information loss from pruning can effectively increase
computational cost due to longer walks. Thus, the inability to identify
uninformative tokens undermines the supposed efficiency gains from pruning. To
address this, we propose Navigation-Aware Pruning (NAP), which uses
navigation-specific traits to simplify the pruning process by pre-filtering
tokens into foreground and background. For example, image views are filtered
based on whether the agent can navigate in that direction. We also extract
navigation-relevant instructions using a Large Language Model. After filtering,
we focus pruning on background tokens, minimizing information loss. To further
help avoid increases in navigation length, we discourage backtracking by
removing low-importance navigation nodes. Experiments on standard VLN
benchmarks show NAP significantly outperforms prior work, preserving higher
success rates while saving more than 50% FLOPS.

</details>


### [30] [RespoDiff: Dual-Module Bottleneck Transformation for Responsible & Faithful T2I Generation](https://arxiv.org/abs/2509.15257)
*Silpa Vadakkeeveetil Sreelatha,Sauradip Nag,Muhammad Awais,Serge Belongie,Anjan Dutta*

Main category: cs.CV

> 论文介绍了一种新的框架RespoDiff，该框架通过双模块转换提升文本到图像生成的负责任属性和图像质量，同时保持语义保真度，且适用于大型模型。

<details>
  <summary>Details</summary>

**Motivation:** 当前，扩散模型快速发展，但在文本到图像生成中保证公平性和安全性仍然是一个挑战。现有方法倾向于牺牲语义保真度和图像质量以改善公平性和安全性。因此，为了平衡这两方面的要求，提出了RespoDiff框架。

**Method:** RespoDiff框架引入了两个可学习模块：一个专注于捕获和实施负责概念，另一个则致力于保持与中性提示的语义一致。通过引入新颖的评分匹配目标，这两个模块可以互相协调。

**Result:** 该论文提出了一种名为RespoDiff的新框架，用于负责任的文本到图像生成，它在扩散模型的中间瓶颈表示上引入了双模块转换。该方法通过同时优化责任概念（如公平性和安全性）和语义对齐，提高了生成图像的质量，且在多种未见过的提示下提高了20%的责任性和语义连贯性。此外，该方法可以无缝集成到大型模型中，如SDXL，从而增强其公平性和安全性。代码将在论文被接受后发布。

**Conclusion:** 该论文证明了RespoDiff框架通过新颖的双模块方法提高了语义对齐和公平性、安全性，相较于现有最佳方法有显著的进步。

**Abstract:** The rapid advancement of diffusion models has enabled high-fidelity and
semantically rich text-to-image generation; however, ensuring fairness and
safety remains an open challenge. Existing methods typically improve fairness
and safety at the expense of semantic fidelity and image quality. In this work,
we propose RespoDiff, a novel framework for responsible text-to-image
generation that incorporates a dual-module transformation on the intermediate
bottleneck representations of diffusion models. Our approach introduces two
distinct learnable modules: one focused on capturing and enforcing responsible
concepts, such as fairness and safety, and the other dedicated to maintaining
semantic alignment with neutral prompts. To facilitate the dual learning
process, we introduce a novel score-matching objective that enables effective
coordination between the modules. Our method outperforms state-of-the-art
methods in responsible generation by ensuring semantic alignment while
optimizing both objectives without compromising image fidelity. Our approach
improves responsible and semantically coherent generation by 20% across
diverse, unseen prompts. Moreover, it integrates seamlessly into large-scale
models like SDXL, enhancing fairness and safety. Code will be released upon
acceptance.

</details>


### [31] [Autoguided Online Data Curation for Diffusion Model Training](https://arxiv.org/abs/2509.15267)
*Valeria Pais,Luis Oala,Daniele Faccio,Marco Aversa*

Main category: cs.CV

> 研究发现，在提高生成扩散模型训练效率方面，自动引导比联合示例选择更为有效，具有更优的样本质量和多样性。

<details>
  <summary>Details</summary>

**Motivation:** 我们在这项工作中探讨了最近开发的自动引导和在线数据选择方法是否能够提高生成扩散模型的训练的时间和样本效率。

**Method:** 我们整合了联合示例选择（JEST）和自动引导（autoguidance），形成了统一的代码库用于快速消融和基准测试。我们在受控的2D合成数据生成任务以及(3x64x64)-D图像生成任务下，评估了不同数据整理方式的组合效果。我们的比较在相等的总运行时间和相等样本数量的基础上进行，具体考虑到选择操作的额外开销。

**Result:** 实验结果显示，自动引导始终提高了样本质量和多样性。早期AJEST（仅在训练初期应用选择）在样本效率上与仅使用自动引导相比，可以匹敌或适度超越。然而，由于其较高的时间开销和复杂性，在多数场合下，自动引导或统一随机数据选择更可取。

**Conclusion:** 这些发现表明，尽管针对早期训练的在线选择能带来效率增益，但强大的样本质量改进主要源自自动引导。我们讨论了这些方法的局限性和适用范围，并概述了数据选择可能有益的情况。

**Abstract:** The costs of generative model compute rekindled promises and hopes for
efficient data curation. In this work, we investigate whether recently
developed autoguidance and online data selection methods can improve the time
and sample efficiency of training generative diffusion models. We integrate
joint example selection (JEST) and autoguidance into a unified code base for
fast ablation and benchmarking. We evaluate combinations of data curation on a
controlled 2-D synthetic data generation task as well as (3x64x64)-D image
generation. Our comparisons are made at equal wall-clock time and equal number
of samples, explicitly accounting for the overhead of selection. Across
experiments, autoguidance consistently improves sample quality and diversity.
Early AJEST (applying selection only at the beginning of training) can match or
modestly exceed autoguidance alone in data efficiency on both tasks. However,
its time overhead and added complexity make autoguidance or uniform random data
selection preferable in most situations. These findings suggest that while
targeted online selection can yield efficiency gains in early training, robust
sample quality improvements are primarily driven by autoguidance. We discuss
limitations and scope, and outline when data selection may be beneficial.

</details>


### [32] [PRISM: Phase-enhanced Radial-based Image Signature Mapping framework for fingerprinting AI-generated images](https://arxiv.org/abs/2509.15270)
*Emanuele Ricco,Elia Onofri,Lorenzo Cima,Stefano Cresci,Roberto Di Pietro*

Main category: cs.CV

> PRISM, a new attribution method for AI-generated images, demonstrates high accuracy in model fingerprinting and real vs fake image detection, fostering accountability in AI systems.

<details>
  <summary>Details</summary>

**Motivation:** There is a growing need for attribution methods in generative AI to ensure credibility and traceability, especially in commercial settings where the source of AI-generated content is crucial.

**Method:** PRISM, a Phase-enhanced Radial-based Image Signature Mapping framework, is used for fingerprinting AI-generated images by leveraging amplitude and phase information derived from the discrete Fourier transform.

**Result:** PRISM achieves a 92.04% accuracy on the PRISM-36K dataset, an average of 81.60% on four benchmarks, and an 88.41% accuracy in detecting real vs fake images, showcasing its effectiveness in model attribution.

**Conclusion:** The frequency-domain fingerprinting method proposed by PRISM offers a reliable solution for identifying the models responsible for generating AI content, which can enforce accountability and trust in generative AI systems.

**Abstract:** A critical need has emerged for generative AI: attribution methods. That is,
solutions that can identify the model originating AI-generated content. This
feature, generally relevant in multimodal applications, is especially sensitive
in commercial settings where users subscribe to paid proprietary services and
expect guarantees about the source of the content they receive. To address
these issues, we introduce PRISM, a scalable Phase-enhanced Radial-based Image
Signature Mapping framework for fingerprinting AI-generated images. PRISM is
based on a radial reduction of the discrete Fourier transform that leverages
amplitude and phase information to capture model-specific signatures. The
output of the above process is subsequently clustered via linear discriminant
analysis to achieve reliable model attribution in diverse settings, even if the
model's internal details are inaccessible. To support our work, we construct
PRISM-36K, a novel dataset of 36,000 images generated by six text-to-image GAN-
and diffusion-based models. On this dataset, PRISM achieves an attribution
accuracy of 92.04%. We additionally evaluate our method on four benchmarks from
the literature, reaching an average accuracy of 81.60%. Finally, we evaluate
our methodology also in the binary task of detecting real vs fake images,
achieving an average accuracy of 88.41%. We obtain our best result on GenImage
with an accuracy of 95.06%, whereas the original benchmark achieved 82.20%. Our
results demonstrate the effectiveness of frequency-domain fingerprinting for
cross-architecture and cross-dataset model attribution, offering a viable
solution for enforcing accountability and trust in generative AI systems.

</details>


### [33] [Large Vision Models Can Solve Mental Rotation Problems](https://arxiv.org/abs/2509.15271)
*Sebastian Ray Mason,Anders Gjølbye,Phillip Chavarria Højbjerg,Lenka Tětková,Lars Kai Hansen*

Main category: cs.CV

> 本研究系统地评估了几种视觉变压器模型在心理旋转任务上的表现，发现自监督学习的ViT模型在捕捉几何结构方面更优，并揭示了这些模型与人类处理相似任务时的相似性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现代视觉变压器在其他计算机视觉任务中取得了成功，但目前还不清楚这些模型在多大程度上具备类似于人类的空间推理能力，特别是心理旋转的任务。因此，本研究旨在通过评估几种模型在心理旋转任务中的表现来解答这个问题。

**Method:** 该研究对ViT、CLIP、DINOv2和DINOv3模型进行了系统性的评估，这些模型在一系列心理旋转任务上的表现被测试，任务涵盖了从简单的积木结构到更复杂的积木图，以及三种不同类型的文本和逼真的照片对象。通过对模型表示层的逐层探究，研究分析了这些网络成功的位置和方式。

**Result:** 研究发现，i) 自监督的ViT模型比监督式ViT模型更好地捕捉几何结构；ii) 中间层的表现优于最终层；iii) 任务难度随着旋转复杂性和遮挡的增加而增加，这与人类的反应时间和嵌入空间表征中的类似约束吻合。

**Conclusion:** 通过对这些模型的系统评估，研究得出，自监督学习模型表现更好，中间层在网络任务中表现最佳，而且任务难度与旋转的复杂性和遮挡有关，这与人类的反应时间相吻合，暗示了这些模型在处理心理旋转任务时与人类认知的一些相似之处。

**Abstract:** Mental rotation is a key test of spatial reasoning in humans and has been
central to understanding how perception supports cognition. Despite the success
of modern vision transformers, it is still unclear how well these models
develop similar abilities. In this work, we present a systematic evaluation of
ViT, CLIP, DINOv2, and DINOv3 across a range of mental-rotation tasks, from
simple block structures similar to those used by Shepard and Metzler to study
human cognition, to more complex block figures, three types of text, and
photo-realistic objects. By probing model representations layer by layer, we
examine where and how these networks succeed. We find that i) self-supervised
ViTs capture geometric structure better than supervised ViTs; ii) intermediate
layers perform better than final layers; iii) task difficulty increases with
rotation complexity and occlusion, mirroring human reaction times and
suggesting similar constraints in embedding space representations.

</details>


### [34] [Which Direction to Choose? An Analysis on the Representation Power of Self-Supervised ViTs in Downstream Tasks](https://arxiv.org/abs/2509.15272)
*Yannis Kaltampanidis,Alexandros Doumanoglou,Dimitrios Zarpalas*

Main category: cs.CV

> 本研究系统性地评估未修改的ViT特征在多种任务上的直接应用，排除了额外的特征变换，给出了如何选择令牌类型、决策规则等任务优化策略。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法通常通过增加额外的变换层来改进任务性能。然而，尚未进行对未改变的ViT特征的内在表示能力的全面分析。本研究旨在通过系统评估未修改的Vi特特征来填补这一空白。

**Method:** 该论文系统评估了未经修改的ViT特征在图像分类和分割任务中的使用情况，包括标准和少样本场景。通过基于超平面（如逻辑回归）或余弦相似性的分类和分割规则来分析不同令牌类型、任务和预训练ViT模型的性能。

**Result:** 论文提供了关于令牌类型选择、决策规则、任务类型、场景和预训练目标之间关系的见解。同时，论文在两个广泛使用的数据集上报告了详细的发现。

**Conclusion:** 该研究揭示了未修改过的ViT特征在图像分类和分割任务上的性能，并为未来研究提供了基础。

**Abstract:** Self-Supervised Learning (SSL) for Vision Transformers (ViTs) has recently
demonstrated considerable potential as a pre-training strategy for a variety of
computer vision tasks, including image classification and segmentation, both in
standard and few-shot downstream contexts. Two pre-training objectives dominate
the landscape of SSL techniques: Contrastive Learning and Masked Image
Modeling. Features (or tokens) extracted from the final transformer attention
block -- specifically, the keys, queries, and values -- as well as features
obtained after the final block's feed-forward layer, have become a common
foundation for addressing downstream tasks. However, in many existing
approaches, these pre-trained ViT features are further processed through
additional transformation layers, often involving lightweight heads or combined
with distillation, to achieve superior task performance. Although such methods
can improve task outcomes, to the best of our knowledge, a comprehensive
analysis of the intrinsic representation capabilities of unaltered ViT features
has yet to be conducted. This study aims to bridge this gap by systematically
evaluating the use of these unmodified features across image classification and
segmentation tasks, in both standard and few-shot contexts. The classification
and segmentation rules that we use are either hyperplane based (as in logistic
regression) or cosine-similarity based, both of which rely on the presence of
interpretable directions in the ViT's latent space. Based on the previous rules
and without the use of additional feature transformations, we conduct an
analysis across token types, tasks, and pre-trained ViT models. This study
provides insights into the optimal choice for token type and decision rule
based on the task, context, and the pre-training objective, while reporting
detailed findings on two widely-used datasets.

</details>


### [35] [How Good are Foundation Models in Step-by-Step Embodied Reasoning?](https://arxiv.org/abs/2509.15293)
*Dinura Dissanayake,Ahmed Heakl,Omkar Thawakar,Noor Ahsan,Ritesh Thawkar,Ketan More,Jean Lahoud,Rao Anwer,Hisham Cholakkal,Ivan Laptev,Fahad Shahbaz Khan,Salman Khan*

Main category: cs.CV

> 研究提出了FoMER基准测试以评估LMMs在实体环境中的推理能力，指出了LMMs在实体推理方面的能力和限制，为未来机器人智能研究提供了方向。

<details>
  <summary>Details</summary>

**Motivation:** 在实体环境中执行决策的实体代理不仅需要有效，还需要安全和具有空间一致性。虽然大型多模态模型在视觉理解和语言生成方面显示出很大的潜力，但在实体任务中的结构化推理能力仍需进一步探索。

**Method:** 本研究提出了Foundation Model Embodied Reasoning (FoMER)基准测试，用于评估大型多模态模型（LMMs）在复杂实体决策场景中的推理能力。该基准测试包括一套大规模且精心策划的实体推理任务，一个将感知接地与行动推理分离的新颖评估框架，并对几种当前领先的LMMs进行了实证分析。

**Result:** 该基准测试包括超过1.1k个样本，涵盖了10个任务和8种实体形态，涉及三种不同类型的机器人。结果表明LMMs在实体推理方面既有潜力也有局限性。

**Conclusion:** FoMER基准测试揭示了LMMs在实体推理任务中的表现，指出了未来机器人智能研究的关键挑战和机遇。研究的数据和代码将公开提供。

**Abstract:** Embodied agents operating in the physical world must make decisions that are
not only effective but also safe, spatially coherent, and grounded in context.
While recent advances in large multimodal models (LMMs) have shown promising
capabilities in visual understanding and language generation, their ability to
perform structured reasoning for real-world embodied tasks remains
underexplored. In this work, we aim to understand how well foundation models
can perform step-by-step reasoning in embodied environments. To this end, we
propose the Foundation Model Embodied Reasoning (FoMER) benchmark, designed to
evaluate the reasoning capabilities of LMMs in complex embodied decision-making
scenarios. Our benchmark spans a diverse set of tasks that require agents to
interpret multimodal observations, reason about physical constraints and
safety, and generate valid next actions in natural language. We present (i) a
large-scale, curated suite of embodied reasoning tasks, (ii) a novel evaluation
framework that disentangles perceptual grounding from action reasoning, and
(iii) empirical analysis of several leading LMMs under this setting. Our
benchmark includes over 1.1k samples with detailed step-by-step reasoning
across 10 tasks and 8 embodiments, covering three different robot types. Our
results highlight both the potential and current limitations of LMMs in
embodied reasoning, pointing towards key challenges and opportunities for
future research in robot intelligence. Our data and code will be made publicly
available.

</details>


### [36] [CoDoL: Conditional Domain Prompt Learning for Out-of-Distribution Generalization](https://arxiv.org/abs/2509.15330)
*Min Zhang,Bo Jiang,Jie Zhou,Yimeng Liu,Xin Lin*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Recent advances in pre-training vision-language models (VLMs), e.g.,
contrastive language-image pre-training (CLIP) methods, have shown great
potential in learning out-of-distribution (OOD) representations. Despite
showing competitive performance, the prompt-based CLIP methods still suffer
from: i) inaccurate text descriptions, which leads to degraded accuracy and
robustness, and poses a challenge for zero-shot CLIP methods. ii) limited
vision-language embedding alignment, which significantly affects the
generalization performance. To tackle the above issues, this paper proposes a
novel Conditional Domain prompt Learning (CoDoL) method, which utilizes
readily-available domain information to form prompts and improves the
vision-language embedding alignment for improving OOD generalization. To
capture both instance-specific and domain-specific information, we further
propose a lightweight Domain Meta Network (DMN) to generate input-conditional
tokens for images in each domain. Extensive experiments on four OOD benchmarks
(PACS, VLCS, OfficeHome and DigitDG) validate the effectiveness of our proposed
CoDoL in terms of improving the vision-language embedding alignment as well as
the out-of-distribution generalization performance.

</details>


### [37] [Emulating Human-like Adaptive Vision for Efficient and Flexible Machine Visual Perception](https://arxiv.org/abs/2509.15333)
*Yulin Wang,Yang Yue,Yang Yue,Huanqian Wang,Haojun Jiang,Yizeng Han,Zanlin Ni,Yifan Pu,Minglei Shi,Rui Lu,Qisen Yang,Andrew Zhao,Zhuofan Xia,Shiji Song,Gao Huang*

Main category: cs.CV

> AdaptiveNN是一种新的框架，通过模拟人类的视觉适应性来进行更高效和灵活的机器学习，显著降低了计算成本，同时保持了精确度，是未来计算机视觉发展的一个有潜力的方向。

<details>
  <summary>Details</summary>

**Motivation:** 当前的机器视觉模型被动地一次性处理整个场景，导致资源需求随空间-时间输入分辨率和模型尺寸的增加而增加，这对未来的进步和实际应用造成了阻碍。

**Method:** AdaptiveNN,一种旨在推动从'被动'到'主动,适应性'视觉模型范式转变的通用框架。它将视觉感知形式化为一个从粗到细的顺序决策过程，逐步识别和关注与任务相关的区域，逐步结合各次注视的信息，并主动结束观察当达到足够的信息量时。该框架包含了集成表示学习与自我奖励的强化学习的理论，以便适应不可微分的AdaptiveNN的端到端训练。

**Result:** AdaptiveNN在17个跨9个任务的基准测试中进行了评估，这些任务包括大规模视觉识别，细粒度辨别，视觉搜索，处理来自真实驾驶和医疗场景的图像，语言驱动的具身AI以及与人类的并排比较。AdaptiveNN实现了最高达28倍的推理成本减少而不会牺牲精度，能够灵活地适应不同的任务需求和资源预算，无需重新训练，并通过注视模式提供了增强的可解释性。

**Conclusion:** AdaptiveNN展示了作为一种高效的，灵活的和可解释的计算机视觉方法的前景途径，并且在许多情况下表现出与人类视觉感知行为相似的特点。这些特征使其成为研究视觉认知的有价值的工具。

**Abstract:** Human vision is highly adaptive, efficiently sampling intricate environments
by sequentially fixating on task-relevant regions. In contrast, prevailing
machine vision models passively process entire scenes at once, resulting in
excessive resource demands scaling with spatial-temporal input resolution and
model size, yielding critical limitations impeding both future advancements and
real-world application. Here we introduce AdaptiveNN, a general framework
aiming to drive a paradigm shift from 'passive' to 'active, adaptive' vision
models. AdaptiveNN formulates visual perception as a coarse-to-fine sequential
decision-making process, progressively identifying and attending to regions
pertinent to the task, incrementally combining information across fixations,
and actively concluding observation when sufficient. We establish a theory
integrating representation learning with self-rewarding reinforcement learning,
enabling end-to-end training of the non-differentiable AdaptiveNN without
additional supervision on fixation locations. We assess AdaptiveNN on 17
benchmarks spanning 9 tasks, including large-scale visual recognition,
fine-grained discrimination, visual search, processing images from real driving
and medical scenarios, language-driven embodied AI, and side-by-side
comparisons with humans. AdaptiveNN achieves up to 28x inference cost reduction
without sacrificing accuracy, flexibly adapts to varying task demands and
resource budgets without retraining, and provides enhanced interpretability via
its fixation patterns, demonstrating a promising avenue toward efficient,
flexible, and interpretable computer vision. Furthermore, AdaptiveNN exhibits
closely human-like perceptual behaviors in many cases, revealing its potential
as a valuable tool for investigating visual cognition. Code is available at
https://github.com/LeapLabTHU/AdaptiveNN.

</details>


### [38] [LowDiff: Efficient Diffusion Sampling with Low-Resolution Condition](https://arxiv.org/abs/2509.15342)
*Jiuyi Xu,Qing Jin,Meida Chen,Andrew Feng,Yang Sui,Yangming Shi*

Main category: cs.CV

> 提出LowDiff，一种基于级联方法和逐步细化的新型高效扩散框架，能够提高扩散模型在图像生成任务中的效率，同时保持或改善生成质量。

<details>
  <summary>Details</summary>

**Motivation:** 扩散模型在图像生成领域取得了显著的成功，但缓慢的采样速度限制了其实际应用。以前的努力主要集中在压缩模型或减少总的去噪步骤，而忽视了在生成过程中利用多种输入分辨率的潜力。

**Method:** LowDiff是一种基于级联方法的创新且高效的扩散框架，通过生成分辨率逐渐增加的输出来操作，同时使用一个统一的模型逐步将图像从低分辨率细化到所需分辨率。

**Result:** 实验结果表明，相比于其他设置，在所有数据集上，我们的方法的吞吐量都提高了50%以上，同时保持了相当或更好的质量。

**Conclusion:** LowDiff方法证明了在保持生成质量的同时，通过级联方法和使用统一的逐步细化模型来提高扩散模型效率的有效性。

**Abstract:** Diffusion models have achieved remarkable success in image generation but
their practical application is often hindered by the slow sampling speed. Prior
efforts of improving efficiency primarily focus on compressing models or
reducing the total number of denoising steps, largely neglecting the
possibility to leverage multiple input resolutions in the generation process.
In this work, we propose LowDiff, a novel and efficient diffusion framework
based on a cascaded approach by generating increasingly higher resolution
outputs. Besides, LowDiff employs a unified model to progressively refine
images from low resolution to the desired resolution. With the proposed
architecture design and generation techniques, we achieve comparable or even
superior performance with much fewer high-resolution sampling steps. LowDiff is
applicable to diffusion models in both pixel space and latent space. Extensive
experiments on both conditional and unconditional generation tasks across
CIFAR-10, FFHQ and ImageNet demonstrate the effectiveness and generality of our
method. Results show over 50% throughput improvement across all datasets and
settings while maintaining comparable or better quality. On unconditional
CIFAR-10, LowDiff achieves an FID of 2.11 and IS of 9.87, while on conditional
CIFAR-10, an FID of 1.94 and IS of 10.03. On FFHQ 64x64, LowDiff achieves an
FID of 2.43, and on ImageNet 256x256, LowDiff built on LightningDiT-B/1
produces high-quality samples with a FID of 4.00 and an IS of 195.06, together
with substantial efficiency gains.

</details>


### [39] [MaskAttn-SDXL: Controllable Region-Level Text-To-Image Generation](https://arxiv.org/abs/2509.15357)
*Yu Chang,Jiahao Chen,Anzhe Cheng,Paul Bogdan*

Main category: cs.CV

> MaskAttn-SDXL通过一种区域级别的门控机制减少跨令牌干扰，改善了多对象提示的属性绑定和空间一致性，有效地增强了文本到图像生成中的组合控制。

<details>
  <summary>Details</summary>

**Motivation:** 由于多对象、属性和空间关系提示导致的跨令牌干扰，现有文本到图像扩散模型在合成方面有所欠缺，作者试图通过MaskAttn-SDXL来解决这些问题。

**Method:** MaskAttn-SDXL是一种应用于Stable Diffusion XL (SDXL) UNet的交叉注意力对数门控机制，通过学习每一层的二进制掩码，向每个交叉注意力对数图注入掩码以稀疏化token到潜变量的交互，确保只有语义相关的连接保持活跃。这种方法不需要位置编码、辅助token或外部区域掩码，并且保持原始推理路径的同时几乎没有增加额外开销。

**Result:** MaskAttn-SDXL提高了多对象提示的空间一致性和属性绑定，同时保留了整体图像质量和多样性。

**Conclusion:** MaskAttn-SDXL证明了在logit级别应用掩码交叉注意力是一种高效的数据驱动方式，能够实现组合控制，为文本到图像生成的空间控制提供了实用扩展。

**Abstract:** Text-to-image diffusion models achieve impressive realism but often suffer
from compositional failures on prompts with multiple objects, attributes, and
spatial relations, resulting in cross-token interference where entities
entangle, attributes mix across objects, and spatial cues are violated. To
address these failures, we propose MaskAttn-SDXL,a region-level gating
mechanism applied to the cross-attention logits of Stable Diffusion XL(SDXL)'s
UNet. MaskAttn-SDXL learns a binary mask per layer, injecting it into each
cross-attention logit map before softmax to sparsify token-to-latent
interactions so that only semantically relevant connections remain active. The
method requires no positional encodings, auxiliary tokens, or external region
masks, and preserves the original inference path with negligible overhead. In
practice, our model improves spatial compliance and attribute binding in
multi-object prompts while preserving overall image quality and diversity.
These findings demonstrate that logit-level maksed cross-attention is an
data-efficient primitve for enforcing compositional control, and our method
thus serves as a practical extension for spatial control in text-to-image
generation.

</details>


### [40] [RaceGAN: A Framework for Preserving Individuality while Converting Racial Information for Image-to-Image Translation](https://arxiv.org/abs/2509.15391)
*Mst Tasnim Pervin,George Bebis,Fang Jiang,Alireza Tavakkoli*

Main category: cs.CV

> 本研究提出RaceGAN，一种可以跨多个领域映射样式代码、保持个体性和高级语义且无需参考图像的新框架，用于翻译种族特征，并在测试中显示出优越的性能。

<details>
  <summary>Details</summary>

**Motivation:** CycleGAN和StarGAN在图像到图像翻译方面取得了显著进展，但前者限于两个领域，后者无法深入映射低层样式变化，且需要额外的参考图像。因此，我们的研究旨在通过多领域图像到图像翻译来翻译种族特征，并解决上述问题。

**Method:** 本研究提出了一种名为RaceGAN的新框架，旨在通过多领域图像到图像翻译来翻译种族特征。该框架能够在种族属性翻译过程中跨多个领域映射样式代码，同时保持个体性和高级语义，且无需依赖参考图像。

**Result:** 测试表明，RaceGAN在翻译种族特征（如亚洲、白人和黑人）方面优于其他模型，并使用基于InceptionReNetv2的分类给出了定量结果，证明了其种族翻译的有效性。

**Conclusion:** RaceGAN成功地实现了保持个体性和高级语义的多领域种族特征翻译，而无需依赖参考图像，在种族特征转换方面表现出色。

**Abstract:** Generative adversarial networks (GANs) have demonstrated significant progress
in unpaired image-to-image translation in recent years for several
applications. CycleGAN was the first to lead the way, although it was
restricted to a pair of domains. StarGAN overcame this constraint by tackling
image-to-image translation across various domains, although it was not able to
map in-depth low-level style changes for these domains. Style mapping via
reference-guided image synthesis has been made possible by the innovations of
StarGANv2 and StyleGAN. However, these models do not maintain individuality and
need an extra reference image in addition to the input. Our study aims to
translate racial traits by means of multi-domain image-to-image translation. We
present RaceGAN, a novel framework capable of mapping style codes over several
domains during racial attribute translation while maintaining individuality and
high level semantics without relying on a reference image. RaceGAN outperforms
other models in translating racial features (i.e., Asian, White, and Black)
when tested on Chicago Face Dataset. We also give quantitative findings
utilizing InceptionReNetv2-based classification to demonstrate the
effectiveness of our racial translation. Moreover, we investigate how well the
model partitions the latent space into distinct clusters of faces for each
ethnic group.

</details>


### [41] [Generating Part-Based Global Explanations Via Correspondence](https://arxiv.org/abs/2509.15393)
*Kunal Rathore,Prasad Tadepalli*

Main category: cs.CV

> 提出了利用用户定义的部分标签进行局部解释并聚合生成全局符号解释的方法，从而在大规模数据上提供可理解的模型决策解释。

<details>
  <summary>Details</summary>

**Motivation:** 现有的解释方法通常只关注个体图像的局部视觉解释，而概念解释虽然提供全局见解，但需要大量的注释。

**Method:** 使用少量图像中用户定义的部分标签，并高效地将它们转移到更大的数据集上，通过聚合基于部分的局部解释来生成全局符号解释。

**Result:** 能够在大规模数据上提供人类可理解的模型决策解释。

**Conclusion:** 该方法有效地解决了现有解释方法的局限，提供了一种成本高效且易于理解的全局解释方法。

**Abstract:** Deep learning models are notoriously opaque. Existing explanation methods
often focus on localized visual explanations for individual images.
Concept-based explanations, while offering global insights, require extensive
annotations, incurring significant labeling cost. We propose an approach that
leverages user-defined part labels from a limited set of images and efficiently
transfers them to a larger dataset. This enables the generation of global
symbolic explanations by aggregating part-based local explanations, ultimately
providing human-understandable explanations for model decisions on a large
scale.

</details>


### [42] [Causal Fingerprints of AI Generative Models](https://arxiv.org/abs/2509.15406)
*Hui Xu,Chi Liu,Congcong Zhu,Minghao Wang,Youyang Qu,Longxiang Gao*

Main category: cs.CV

> 我们提出了因果指纹的概念和相关的解耦框架，用于改进生成模型的来源归因，并且在模型归因方面优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的方法依赖于模型特定的线索或合成缺陷，导致指纹可能在不同的生成模型之间泛化性不好。我们主张一个完整的模型指纹应该反映出图像来源与模型痕迹之间的因果关系，这是一个尚未被广泛探索的方向。

**Method:** 我们提出了一种因果解耦框架，该框架可以在从预先训练的扩散重建残差中得到的语义不变的潜在空间中，将生成模型的因果指纹与图像特定内容和风格解耦。为了增强指纹的细节，我们还引入了多样的特征表示。

**Result:** 通过评估代表性对抗网络和扩散模型的归属性能以及使用因果指纹生成反现实样本来实现来源匿名化，我们的方法在模型归属方面超越了现有的方法。

**Conclusion:** 实验表明，我们的方法在模型归属方面优于现有的方法，显示出在伪造检测、模型版权跟踪和身份保护方面的强大潜力。

**Abstract:** AI generative models leave implicit traces in their generated images, which
are commonly referred to as model fingerprints and are exploited for source
attribution. Prior methods rely on model-specific cues or synthesis artifacts,
yielding limited fingerprints that may generalize poorly across different
generative models. We argue that a complete model fingerprint should reflect
the causality between image provenance and model traces, a direction largely
unexplored. To this end, we conceptualize the \emph{causal fingerprint} of
generative models, and propose a causality-decoupling framework that
disentangles it from image-specific content and style in a semantic-invariant
latent space derived from pre-trained diffusion reconstruction residual. We
further enhance fingerprint granularity with diverse feature representations.
We validate causality by assessing attribution performance across
representative GANs and diffusion models and by achieving source anonymization
using counterfactual examples generated from causal fingerprints. Experiments
show our approach outperforms existing methods in model attribution, indicating
strong potential for forgery detection, model copyright tracing, and identity
protection.

</details>


### [43] [NeuroRAD-FM: A Foundation Model for Neuro-Oncology with Distributionally Robust Training](https://arxiv.org/abs/2509.15416)
*Moinak Bhattacharya,Angelica P. Kurtz,Fabio M. Iwamoto,Prateek Prasanna,Gagandeep Singh*

Main category: cs.CV

> 通过使用分布鲁棒优化方法改进神经肿瘤学中的基础模型，以提高对常见和罕见分子标记的预测能力，以及生存预测的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基础模型（FMs）在神经肿瘤学领域的应用由于异质性数据和肿瘤复杂性而受到限制，特别是在预测罕见分子标记上表现较差。这些标记对于治疗反应和风险分层至关重要。

**Method:** 我们开发了一个针对神经肿瘤学的特定基础模型（FMs），使用了分布鲁棒优化（DRO）来解决肿瘤异质性和数据多样性带来的挑战，并减轻训练数据中的站点和类别不平衡问题。我们在来自多机构的脑肿瘤MRI上预训练了自监督的骨干模型（BYOL, DINO, MAE, MoCo），并在神经肿瘤学的下游任务中进行了分子分类和生存预测的改进，包括常见和少见的分子标记。

**Result:** 实验结果显示，在CUIMC站点，平均平衡准确率从0.744提高到0.785，AUC值从0.656提高到0.676。罕见结局的预测也获得较大改进，如CDKN2A/2B的准确率从0.86提升至0.92，AUC从0.73提高到0.92；ATRX的AUC从0.69提升到0.82；Ki-67准确率从0.60提升到0.69。生存预测的c指数也在所有站点得到提升。

**Conclusion:** 我们的方法提高了分子预测精度，并减少了站点特异性嵌入差异。总体而言，结合FMs与DRO提供了更稳健的站点不变表示，改善了常见和罕见标记的预测，增强了生存预判，这表明需要更多的前瞻性验证和纵向信号的整合，以促进精准的神经肿瘤学发展。

**Abstract:** Neuro-oncology poses unique challenges for machine learning due to
heterogeneous data and tumor complexity, limiting the ability of foundation
models (FMs) to generalize across cohorts. Existing FMs also perform poorly in
predicting uncommon molecular markers, which are essential for treatment
response and risk stratification. To address these gaps, we developed a
neuro-oncology specific FM with a distributionally robust loss function,
enabling accurate estimation of tumor phenotypes while maintaining
cross-institution generalization. We pretrained self-supervised backbones
(BYOL, DINO, MAE, MoCo) on multi-institutional brain tumor MRI and applied
distributionally robust optimization (DRO) to mitigate site and class
imbalance. Downstream tasks included molecular classification of common markers
(MGMT, IDH1, 1p/19q, EGFR), uncommon alterations (ATRX, TP53, CDKN2A/2B, TERT),
continuous markers (Ki-67, TP53), and overall survival prediction in IDH1
wild-type glioblastoma at UCSF, UPenn, and CUIMC. Our method improved molecular
prediction and reduced site-specific embedding differences. At CUIMC, mean
balanced accuracy rose from 0.744 to 0.785 and AUC from 0.656 to 0.676, with
the largest gains for underrepresented endpoints (CDKN2A/2B accuracy 0.86 to
0.92, AUC 0.73 to 0.92; ATRX AUC 0.69 to 0.82; Ki-67 accuracy 0.60 to 0.69).
For survival, c-index improved at all sites: CUIMC 0.592 to 0.597, UPenn 0.647
to 0.672, UCSF 0.600 to 0.627. Grad-CAM highlighted tumor and peri-tumoral
regions, confirming interpretability. Overall, coupling FMs with DRO yields
more site-invariant representations, improves prediction of common and uncommon
markers, and enhances survival discrimination, underscoring the need for
prospective validation and integration of longitudinal and interventional
signals to advance precision neuro-oncology.

</details>
