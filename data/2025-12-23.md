<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 2]
- [cs.CV](#cs.CV) [Total: 4]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Towards Reasoning-Preserving Unlearning in Multimodal Large Language Models](https://arxiv.org/abs/2512.17911)
*Hongji Li,Junchi yao,Manjiang Yu,Priyanka Singh,Xue Li,Di Wang,Lijie Hu*

Main category: cs.CL

> 提出R-MUSE方法，解决了现有无学习方法在多模态大型语言模型（RMLLM）中的问题，即在消除泄露的同时保持推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 当前没有基准能够综合评估无学习方法在抑制推理级泄漏的同时保留推理能力的效果。为此，我们创建了RMLLMU-Bench来填补这一空白。

**Method:** 我们提出了R-MUSE（通过子空间指导和自适应调整的推理保留多模态大语言模型无学习框架），这是一个无需训练、仅在推理时介入的方法，能够引导内部表示忘记答案及推理痕迹，同时明确保持一般的推理能力。

**Result:** 实验表明R-MUSE在有效的遗忘与推理保持之间取得了显著更好的平衡。

**Conclusion:** R-MUSE方法在RMLLMU-Bench上的实验显示了其在遗忘与推理保留之间的优越平衡。

**Abstract:** Machine unlearning aims to erase requested data from trained models without full retraining. For Reasoning Multimodal Large Language Models (RMLLMs), this is uniquely challenging: intermediate chain-of-thought steps can still leak sensitive information even when final answers are forgotten, and overly aggressive interventions easily damage general reasoning ability. Yet no benchmark jointly evaluates how well unlearning methods suppress reasoning-level leakage while preserving reasoning competence. We address this gap with RMLLMU-Bench, the first benchmark for RMLLM unlearning that extends standard forgetting metrics with dedicated measures of reasoning leakage and reasoning retention. A systematic evaluation on RMLLMU-Bench reveals that existing unlearning methods for MLLMs and Large (Language) Reasoning Models (LRMs) either leave substantial leakage in the reasoning process or severely degrade reasoning performance. To address these gaps, we propose R-MUSE (Reasoning-preserving MLLM Unlearning via Subspace guidance and Adaptive Steering), a training-free and inference-time intervention framework that steers internal representations to forget both answers and reasoning traces while explicitly preserving general reasoning. Experiments on RMLLMU-Bench demonstrate that R-MUSE achieves a substantially better balance between effective forgetting and reasoning retention.

</details>


### [2] [Graph-O1 : Monte Carlo Tree Search with Reinforcement Learning for Text-Attributed Graph Reasoning](https://arxiv.org/abs/2512.17912)
*Lihui Liu*

Main category: cs.CL

> 提出了Graph-O1框架，结合Monte Carlo树搜索与端到端的强化学习，使大型语言模型能够逐步、交互地在图结构数据上进行推理，实验表明这种方法优于现有方法，提供更准确可靠和可解释的答案。

<details>
  <summary>Details</summary>

**Motivation:** 提出Graph-O1的动机在于解决现有大型语言模型和检索增强生成方法难以有效处理图结构数据中非孤立文本信息和关系结构信号的问题。

**Method:** Graph-O1通过将蒙特卡洛树搜索与端到端强化学习结合起来，允许模型在图环境中分步骤、交互地探索和提取最相关的子图组件。

**Result:** 实验表明，Graph-O1在使用不同大型语言模型骨干时均优于现有最先进方案，可以产生更准确、可靠和可解释的答案。

**Conclusion:** Graph-O1能够在结合大型语言模型与图结构数据方面提供更好的推理及问答性能。

**Abstract:** ChatGPT said: Text-attributed graphs, where nodes and edges contain rich textual information, are widely used across diverse domains. A central challenge in this setting is question answering, which requires jointly leveraging unstructured text and the structured relational signals within the graph. Although Large Language Models (LLMs) have made significant advances in natural language understanding, their direct use for reasoning over text-attributed graphs remains limited. Retrieval-augmented generation methods that operate purely on text often treat passages as isolated units, ignoring the interconnected structure of the graph. Conversely, graph-based RAG methods that serialize large subgraphs into long textual sequences quickly become infeasible due to LLM context-length constraints, resulting in fragmented reasoning and degraded accuracy. To overcome these limitations, we introduce Graph-O1, an agentic GraphRAG framework that enables LLMs to conduct stepwise, interactive reasoning over graphs. Our approach integrates Monte Carlo Tree Search (MCTS) with end-to-end reinforcement learning, allowing the model to selectively explore and retrieve only the most informative subgraph components. The reasoning procedure is framed as a multi-turn interaction between the agent and the graph environment, and the agent is trained through a unified reward mechanism. Extensive experiments across multiple LLM backbones demonstrate that Graph-O1 consistently surpasses state-of-the-art baselines, producing answers that are more accurate, reliable, and interpretable.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [3] [A 96pJ/Frame/Pixel and 61pJ/Event Anti-UAV System with Hybrid Object Tracking Modes](https://arxiv.org/abs/2512.17939)
*Yuncheng Lu,Yucen Shi,Aobo Li,Zehao Li,Junying Li,Bo Wang,Tony Tae-Hyoung Kim*

Main category: cs.CV

> 设计了一种节能且高效的反无人机系统，能在50~400米范围内实现98.2%的识别精度，适用于快速移动小型无人机。

<details>
  <summary>Details</summary>

**Motivation:** 研发高效节能并能可靠检测快速移动小型无人机的反无人机系统。

**Method:** 该研究提出了一种结合帧基和事件驱动对象追踪的节能反无人机系统，用于可靠检测小型和高速移动的无人机。系统通过行程编码重构二值事件帧；基于目标大小和速度在帧模式和事件模式之间自适应切换；通过自适应阈值和轨迹分类提高对高速目标的鲁棒性。

**Result:** 实现了超过97%的冗余神经计算减少，且在公共UAV数据集上，在50至400米范围和5到80像素/秒的速度范围内达到了98.2%的识别精度。

**Conclusion:** 实验结果表明，该系统在反无人机系统中具备最先进的端到端能效。

**Abstract:** We present an energy-efficient anti-UAV system that integrates frame-based and event-driven object tracking to enable reliable detection of small and fast-moving drones. The system reconstructs binary event frames using run-length encoding, generates region proposals, and adaptively switches between frame mode and event mode based on object size and velocity. A Fast Object Tracking Unit improves robustness for high-speed targets through adaptive thresholding and trajectory-based classification. The neural processing unit supports both grayscale-patch and trajectory inference with a custom instruction set and a zero-skipping MAC architecture, reducing redundant neural computations by more than 97 percent. Implemented in 40 nm CMOS technology, the 2 mm^2 chip achieves 96 pJ per frame per pixel and 61 pJ per event at 0.8 V, and reaches 98.2 percent recognition accuracy on public UAV datasets across 50 to 400 m ranges and 5 to 80 pixels per second speeds. The results demonstrate state-of-the-art end-to-end energy efficiency for anti-UAV systems.

</details>


### [4] [NystagmusNet: Explainable Deep Learning for Photosensitivity Risk Prediction](https://arxiv.org/abs/2512.17943)
*Karthik Prabhakar*

Main category: cs.CV

> 本文开发了一种AI系统，用于预测斜视患者处的光敏风险环境，并提供实时视觉适应建议。

<details>
  <summary>Details</summary>

**Motivation:** 由于目前辅助解决方案局限于症状治疗，缺乏预测个性化，而斜视患者面对光敏性时会面临显著的日常挑战。这些挑战源于由环境亮度条件加剧的非自主眼球运动。

**Method:** 本论文提出了NystagmusNet，一个基于AI的系统，用于预测高风险视觉环境，并推荐实时视觉适应。该系统使用了一种双分支卷积神经网络，基于合成和增强的数据集训练，并且根据环境亮度和眼睛运动变化估计光敏性风险评分。

**Result:** 该模型在合成数据上实现了75%的验证准确率。同时，系统还集成了解释性技术，如SHAP和GradCAM，以此来突出环境风险区域，提高临床信任度和模型的可解释性。

**Conclusion:** 未来的发展方向包括通过智能眼镜进行部署，并使用强化学习进行个性化建议。

**Abstract:** Nystagmus patients with photosensitivity face significant daily challenges due to involuntary eye movements exacerbated by environmental brightness conditions. Current assistive solutions are limited to symptomatic treatments without predictive personalization. This paper proposes NystagmusNet, an AI-driven system that predicts high-risk visual environments and recommends real-time visual adaptations. Using a dual-branch convolutional neural network trained on synthetic and augmented datasets, the system estimates a photosensitivity risk score based on environmental brightness and eye movement variance. The model achieves 75% validation accuracy on synthetic data. Explainability techniques including SHAP and GradCAM are integrated to highlight environmental risk zones, improving clinical trust and model interpretability. The system includes a rule-based recommendation engine for adaptive filter suggestions. Future directions include deployment via smart glasses and reinforcement learning for personalized recommendations.

</details>


### [5] [SuperFlow: Training Flow Matching Models with RL on the Fly](https://arxiv.org/abs/2512.17951)
*Kaijie Chen,Zhiyang Xu,Ying Shen,Zihao Lin,Yuguang Yao,Lifu Huang*

Main category: cs.CV

> SuperFlow, improves training efficiency of flow-based text-to-image models by adjusting group sizes with variance-aware sampling and enhancing step-level advantage computation.

<details>
  <summary>Details</summary>

**Motivation:** To solve the inefficiency and bias issues in current RL training methods for flow models, which either fix group sizes and thus ignore the variation in sampling importance or reuse trajectory-level advantages for per-step estimates, causing biased credit assignment.

**Method:** SuperFlow, an RL training framework for flow-based models that adjusts group sizes with variance-aware sampling and computes step-level advantages in a way that is consistent with continuous-time flow dynamics.

**Result:** Empirically, SuperFlow reduces training time between 5.2% to 16.7% using only 5.4% to 56.3% of the original training steps. It also outperforms SD3.5-M by 4.6% to 47.2% and Flow-GRPO by 1.7% to 16.0%. 

**Conclusion:** SuperFlow demonstrates an effective approach to optimizing reinforcement learning training in flow-based models for text-to-image applications, leading to significant improvements in efficiency and performance without any architectural changes.

**Abstract:** Recent progress in flow-based generative models and reinforcement learning (RL) has improved text-image alignment and visual quality. However, current RL training for flow models still has two main problems: (i) GRPO-style fixed per-prompt group sizes ignore variation in sampling importance across prompts, which leads to inefficient sampling and slower training; and (ii) trajectory-level advantages are reused as per-step estimates, which biases credit assignment along the flow. We propose SuperFlow, an RL training framework for flow-based models that adjusts group sizes with variance-aware sampling and computes step-level advantages in a way that is consistent with continuous-time flow dynamics. Empirically, SuperFlow reaches promising performance while using only 5.4% to 56.3% of the original training steps and reduces training time by 5.2% to 16.7% without any architectural changes. On standard text-to-image (T2I) tasks, including text rendering, compositional image generation, and human preference alignment, SuperFlow improves over SD3.5-M by 4.6% to 47.2%, and over Flow-GRPO by 1.7% to 16.0%.

</details>


### [6] [Seeing Beyond the Scene: Analyzing and Mitigating Background Bias in Action Recognition](https://arxiv.org/abs/2512.17953)
*Ellie Zhou,Jihoon Chung,Olga Russakovsky*

Main category: cs.CV

> 研究分析了不同模型中存在的背景偏见问题，并提出了有效的减轻策略，通过分段输入和改进提示设计提高了预测的准确性，集中到人类动作上。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于揭示并减轻模型在进行人类动作识别时依赖背景线索而非人类运动和姿态的背景偏见问题。

**Method:** 我们针对分类模型、对比文本-图像预训练模型以及视频大型语言模型（VLLM）进行了背景偏见的系统分析，并提出了减轻分类模型背景偏见的策略。此外，我们还探讨了VLLM的手动和自动提示调整方法。

**Result:** 结果表明，通过使用分段的人体输入可以有效减小分类模型中的背景偏见3.78%，而通过对VLLM进行提示设计调整，可以将预测更倾向于基于人类的动作，效果提升9.85%。

**Conclusion:** 研究得出结论，通过优化模型输入和提示设计，可以显著减少模型依赖背景进行预测的行为，使预测更加集中在人类动作上。

**Abstract:** Human action recognition models often rely on background cues rather than human movement and pose to make predictions, a behavior known as background bias. We present a systematic analysis of background bias across classification models, contrastive text-image pretrained models, and Video Large Language Models (VLLM) and find that all exhibit a strong tendency to default to background reasoning. Next, we propose mitigation strategies for classification models and show that incorporating segmented human input effectively decreases background bias by 3.78%. Finally, we explore manual and automated prompt tuning for VLLMs, demonstrating that prompt design can steer predictions towards human-focused reasoning by 9.85%.

</details>
