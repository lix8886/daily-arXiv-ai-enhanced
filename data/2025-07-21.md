<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models](https://arxiv.org/abs/2507.13357)
*Atharva Bhargude,Ishan Gonehal,Chandler Haney,Dave Yoon,Kevin Zhu,Aaron Sandoval,Sean O'Brien,Kaustubh Vinnakota*

Main category: cs.CL

> 本研究探讨了通过自适应语言提示（ALP）方法，利用大型语言模型（如GPT-4o和Gemini 1.5 Pro）多模态能力检测网络钓鱼网页的技术，展示了显著提高检测准确率的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 网络钓鱼攻击是重大网络安全威胁，需要适应性的检测技术。研究表明ALP方法能够提高网络钓鱼检测准确率。

**Method:** 通过结构化语义推理方法ALP，指导大型语言模型分析文本欺骗，寻找语言模式、紧急提示以及操纵性措辞，并整合文本、视觉和URL分析，构建统一的检测模型。

**Result:** 实验结果显示，ALP方法能够引导大型语言模型通过结构化推理和上下文分析提高钓鱼检测准确性，得到F1评分为0.93，超越传统方法。

**Conclusion:** 研究证明了ALP融合多模态大型语言模型对改进钓鱼检测框架的有效性，为更强大、可解释和自适应的语言基础钓鱼检测系统奠定了基础。

**Abstract:** Phishing attacks represent a significant cybersecurity threat, necessitating
adaptive detection techniques. This study explores few-shot Adaptive Linguistic
Prompting (ALP) in detecting phishing webpages through the multimodal
capabilities of state-of-the-art large language models (LLMs) such as GPT-4o
and Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides
LLMs to analyze textual deception by breaking down linguistic patterns,
detecting urgency cues, and identifying manipulative diction commonly found in
phishing content. By integrating textual, visual, and URL-based analysis, we
propose a unified model capable of identifying sophisticated phishing attempts.
Our experiments demonstrate that ALP significantly enhances phishing detection
accuracy by guiding LLMs through structured reasoning and contextual analysis.
The findings highlight the potential of ALP-integrated multimodal LLMs to
advance phishing detection frameworks, achieving an F1-score of 0.93,
surpassing traditional approaches. These results establish a foundation for
more robust, interpretable, and adaptive linguistic-based phishing detection
systems using LLMs.

</details>


### [2] [Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition](https://arxiv.org/abs/2507.13380)
*Keito Inoshita,Rushia Harada*

Main category: cs.CL

> 提出了一种新的情感表达生成框架PersonaGen，用于解决高质量情感数据集稀少的问题，并展示出其优于现有方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 由于高质量、多样化的情感数据集稀缺，导致情感识别领域高性能模型的开发具有挑战性。情感表达本质上是主观的，受到个体性格特征、社会文化背景和情境因素的影响，大规模通用数据收集既有伦理问题又有实际困难。为了应对这个问题，提出了PersonaGen框架。

**Method:** PersonaGen，一种利用大型语言模型（LLM）通过多阶段基于角色的条件生成情感丰富文本的新框架。PersonaGen 通过结合人口统计属性、社会文化背景和详细情境背景构建分层的虚拟角色，用来指导情感表达生成。

**Result:** 实验结果显示，PersonaGen 在生成多样化、连贯且具有区分性的情感表达方面显著优于基线方法，展示出作为增强或替代现实世界情感数据集的潜力。

**Conclusion:** PersonaGen 框架能够生成多样化的、连贯的、具有区分性的情感表达，证明了其作为增强或替代现实世界情感数据集的潜在能力。

**Abstract:** In the field of emotion recognition, the development of high-performance
models remains a challenge due to the scarcity of high-quality, diverse
emotional datasets. Emotional expressions are inherently subjective, shaped by
individual personality traits, socio-cultural backgrounds, and contextual
factors, making large-scale, generalizable data collection both ethically and
practically difficult. To address this issue, we introduce PersonaGen, a novel
framework for generating emotionally rich text using a Large Language Model
(LLM) through multi-stage persona-based conditioning. PersonaGen constructs
layered virtual personas by combining demographic attributes, socio-cultural
backgrounds, and detailed situational contexts, which are then used to guide
emotion expression generation. We conduct comprehensive evaluations of the
generated synthetic data, assessing semantic diversity through clustering and
distributional metrics, human-likeness via LLM-based quality scoring, realism
through comparison with real-world emotion corpora, and practical utility in
downstream emotion classification tasks. Experimental results show that
PersonaGen significantly outperforms baseline methods in generating diverse,
coherent, and discriminative emotion expressions, demonstrating its potential
as a robust alternative for augmenting or replacing real-world emotional
datasets.

</details>


### [3] [SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation](https://arxiv.org/abs/2507.13381)
*Rafiq Kamel,Filippo Guerranti,Simon Geisler,Stephan Günnemann*

Main category: cs.CL

> 介绍了一种结构敏感的微调方法SAFT，将图形拓扑注入到预训练的LLM中，从而在AMR文本生成任务上实现了新的最佳业绩，显著提升了LLM在处理复杂结构输入时的性能。

<details>
  <summary>Details</summary>

**Motivation:** 当前方法在处理AMR时，要么任意地线性化AMR，丢弃关键的结构线索，要么依赖于与标准LLM不兼容的架构。因此，需要一种方法能在保留图形结构信息的同时，与标准LLM兼容。

**Method:** SAFT方法通过计算从变换后的AMR的磁场拉普拉斯矩阵的方向敏感的位置编码，并将它们投影到LLM的嵌入空间中，从而将图形结构注入到预训练的LLM中，而无需对架构进行任何更改。

**Result:** SAFT在AMR 3.0上的性能优于基线模型，BLEU值提升了3.5。研究表明，结构敏感表示法在提升LLM处理复杂结构输入的性能上的有效性。

**Conclusion:** SAFT提供了一种通用而有效的方法，用于将结构化数据与语言模型结合，能够在不改变模型架构的情况下显著提升LLM处理复杂结构数据的能力。

**Abstract:** Large Language Models (LLMs) are increasingly applied to tasks involving
structured inputs such as graphs. Abstract Meaning Representations (AMRs),
which encode rich semantics as directed graphs, offer a rigorous testbed for
evaluating LLMs on text generation from such structures. Yet, current methods
often arbitrarily linearize AMRs, discarding key structural cues, or rely on
architectures incompatible with standard LLMs. We introduce SAFT, a
structure-aware fine-tuning approach that injects graph topology into
pretrained LLMs without architectural changes. We compute direction-sensitive
positional encodings from the magnetic Laplacian of transformed AMRs and
project them into the embedding space of the LLM. While possibly applicable to
any graph-structured inputs, we focus on AMR-to-text generation as a
representative and challenging benchmark. SAFT sets a new state-of-the-art on
AMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph
complexity, highlighting the value of structure-aware representations in
enhancing LLM performance. SAFT offers a general and effective pathway for
bridging structured data and language models.

</details>


### [4] [Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case](https://arxiv.org/abs/2507.13382)
*Chandrashekar Muniyappa,Sirisha Velampalli*

Main category: cs.CL

> The paper introduces a graph-based approach using NLP techniques and the MDL-based GBAD algorithm for anomaly detection to identify fake news articles, enhancing the dataset with recent COVID-19 related news for better results.

<details>
  <summary>Details</summary>

**Motivation:** The rapid spread of fake news in the digital world necessitates effective detection methods. The authors aim to improve upon traditional techniques by utilizing graph-based anomaly detection on both existing and more recent contextual datasets.

**Method:** The authors employ a contextual graph-based approach where NLP techniques are used to convert news articles into graph structures. They then use the MDL-based GBAD algorithm for identifying anomalous patterns which correspond to fake news.

**Result:** The method is tested on a dataset enhanced with recent COVID-19 news, allowing for a more contemporary and relevant analysis compared to relying solely on the original dataset.

**Conclusion:** Graph-based methods, enhanced with NLP and GBAD, are effective in detecting fake news by identifying complex patterns and anomalies missed by traditional approaches.

**Abstract:** In today\'s digital world, fake news is spreading with immense speed. Its a
significant concern to address. In this work, we addressed that challenge using
novel graph based approach. We took dataset from Kaggle that contains real and
fake news articles. To test our approach we incorporated recent covid-19
related news articles that contains both genuine and fake news that are
relevant to this problem. This further enhances the dataset as well instead of
relying completely on the original dataset. We propose a contextual graph-based
approach to detect fake news articles. We need to convert news articles into
appropriate schema, so we leverage Natural Language Processing (NLP) techniques
to transform news articles into contextual graph structures. We then apply the
Minimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)
algorithm for graph mining. Graph-based methods are particularly effective for
handling rich contextual data, as they enable the discovery of complex patterns
that traditional query-based or statistical techniques might overlook. Our
proposed approach identifies normative patterns within the dataset and
subsequently uncovers anomalous patterns that deviate from these established
norms.

</details>


### [5] [PARAM-1 BharatGen 2.9B Model](https://arxiv.org/abs/2507.13390)
*Kundeshwar Pundalik,Piyush Sawarkar,Nihar Sahoo,Abhishek Shinde,Prateek Chanda,Vedant Goswami,Ajay Nagpal,Atul Singh,Viraj Thakur,Vijay Dewane,Aamod Thakur,Bhargav Patel,Smita Gautam,Bhagwan Panditi,Shyam Pawar,Madhav Kotcha,Suraj Racha,Saral Sureka,Pankaj Singh,Rishi Bal,Rohit Saluja,Ganesh Ramakrishnan*

Main category: cs.CL

> PARAM-1模型通过双语训练和文化相关的设计原则，确保了印度语言的多样性和公平性表示，在印度语言背景下展现出了强大的泛用能力和特化任务支持能力。

<details>
  <summary>Details</summary>

**Motivation:** 大规模语言模型虽然作为强有力的通用推理系统，但其发展仍然以英语为主导，因此针对印度这样语言和文化多样性丰富的地区存在显著的结构性不足。本研究目的在于通过引入PARAM-1模型，提供一个将多样性在中国预训练阶段即加以重视的设计蓝图。

**Method:** PARAM-1是一种具有29亿参数的解码器式，纯文本语言模型，专门针对印度的语言多样性进行构建和优化。该模型使用包含印地语和英语的双语数据集进行训练，重点在于含有丰富事实且高质量的内容。模型设计遵循三项基本原则：通过语料库分配保证印度语系的公正表示（25%的语料库分配给印度语言）；根据印度语系的形态结构调整SentencePiece分词器以确保分词公平性；通过涵盖包括印第安QA、混合语言推理和语言社会学稳健性任务的评估基准来保持文化相关性。

**Result:** 实验结果表明，PARAM-1不仅是一个够用的通用模型，也为印度本土应用提供了一个稳健的基准。

**Conclusion:** PARAM-1证明了在模型设计初期就考虑语言多样性的设计理念，可以有效提升语言模型在处理具有文化和社会语言学特征任务中的性能，为构建公平性基础模型提供了范例。

**Abstract:** Large Language Models (LLMs) have emerged as powerful general-purpose
reasoning systems, yet their development remains dominated by English-centric
data, architectures, and optimization paradigms. This exclusionary design
results in structural under-representation of linguistically diverse regions
such as India, where over 20 official languages and 100+ dialects coexist
alongside phenomena like code-switching and diglossia. We introduce PARAM-1, a
2.9B parameter decoder-only, text-only language model trained from scratch with
an explicit architectural and linguistic focus on Indian diversity. PARAM-1 is
trained on a bilingual dataset consisting of only Hindi and English,
constructed with a strong focus on fact-rich, high-quality content. It is
guided by three core principles: equitable representation of Indic languages
through a 25% corpus allocation; tokenization fairness via a SentencePiece
tokenizer adapted to Indian morphological structures; and culturally aligned
evaluation benchmarks across IndicQA, code-mixed reasoning, and
socio-linguistic robustness tasks. By embedding diversity at the pretraining
level-rather than deferring it to post-hoc alignment-PARAM-1 offers a
design-first blueprint for equitable foundation modeling. Our results
demonstrate that it serves as both a competent general-purpose model and a
robust baseline for India-centric applications.

</details>


### [6] [TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction](https://arxiv.org/abs/2507.13392)
*Emil Häglund,Johanna Björklund*

Main category: cs.CL

> 通过重新构建主题建模管道以利用意见单元（包括相关文本摘录和情感分数的独立声明）来提高从客户评论中提取洞察的能力，从而实现更好地关联主题情感与业务指标，以了解特定客户关注如何影响业务成果.

<details>
  <summary>Details</summary>

**Motivation:** 改进从客户评论中提取见解的能力，通过在意见单元上进行主题建模，使得提取的标签和情感相关更为有效。以此为基础，企业可以获得关键的商业指标洞见。

**Method:** 使用大型语言模型可靠提取意见单元，改进主题建模管道。通过关联主题和情感与商业指标，评估系统的效能及预测星评级的方法。

**Result:** 实现更加连贯和可解释的主题，同时捕捉与每个主题相关的情感，从而提高主题分类和情感分析的综合性能。

**Conclusion:** 此系统在创建连贯主题方面有效，对于整合主题和情感模态进行准确的星评级预测也具有优势。相较于其他主题建模和分类方案，具有显著改进。

**Abstract:** We improve the extraction of insights from customer reviews by restructuring
the topic modelling pipeline to operate on opinion units - distinct statements
that include relevant text excerpts and associated sentiment scores. Prior work
has demonstrated that such units can be reliably extracted using large language
models. The result is a heightened performance of the subsequent topic
modeling, leading to coherent and interpretable topics while also capturing the
sentiment associated with each topic. By correlating the topics and sentiments
with business metrics, such as star ratings, we can gain insights on how
specific customer concerns impact business outcomes. We present our system's
implementation, use cases, and advantages over other topic modeling and
classification solutions. We also evaluate its effectiveness in creating
coherent topics and assess methods for integrating topic and sentiment
modalities for accurate star-rating prediction.

</details>


### [7] [Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only](https://arxiv.org/abs/2507.13395)
*Xuanqi Gao,Weipeng Jiang,Juan Zhai,Shiqing Ma,Siyi Xie,Xinyang Yin,Chao Shen*

Main category: cs.CL

> Babel是一种新框架，旨在通过使用单语语料库来解决神经机器翻译中保留风格一致性的问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的机器翻译方法往往需要平行语料库来保持风格一致，而Babel框架则希望通过仅使用单语语料库的方法，来提高不同语言间沟通的风格保真度。

**Method:** Babel框架利用两个关键组件来解决机器翻译中的风格保持问题：一是基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异；二是基于扩散的方法，用于修正这些风格不一致而保持语义一致性。该框架作为现有NMT系统的后处理模块运行，无需对架构进行修改或使用平行样式的数据。

**Result:** 在五种不同领域（法学、文学、科学写作、医学、教育内容）的广泛实验中，Babel框架被证明是有效的，如它以88.21%的精度识别了风格不一致，并提高了150%的风格保存，同时保持0.92的高语义相似度评分。人类评估亦证实，经过Babel调整后的翻译更好地保持了原始文本的风格，同时保持流畅性和准确性。

**Conclusion:** 实验结果和人类评估证明了Babel在五种不同领域中具有提高神经机器翻译风格一致性的有效性。这是在不依赖平行语料库的情况下，通过仅使用单语语料库实现了风格保持的显著进步。

**Abstract:** The advent of neural machine translation (NMT) has revolutionized
cross-lingual communication, yet preserving stylistic nuances remains a
significant challenge. While existing approaches often require parallel corpora
for style preservation, we introduce Babel, a novel framework that enhances
stylistic fidelity in NMT using only monolingual corpora. Babel employs two key
components: (1) a style detector based on contextual embeddings that identifies
stylistic disparities between source and target texts, and (2) a
diffusion-based style applicator that rectifies stylistic inconsistencies while
maintaining semantic integrity. Our framework integrates with existing NMT
systems as a post-processing module, enabling style-aware translation without
requiring architectural modifications or parallel stylistic data. Extensive
experiments on five diverse domains (law, literature, scientific writing,
medicine, and educational content) demonstrate Babel's effectiveness: it
identifies stylistic inconsistencies with 88.21% precision and improves
stylistic preservation by 150% while maintaining a high semantic similarity
score of 0.92. Human evaluation confirms that translations refined by Babel
better preserve source text style while maintaining fluency and adequacy.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives](https://arxiv.org/abs/2507.13359)
*Yang Zhou,Junjie Li,CongYang Ou,Dawei Yan,Haokui Zhang,Xizhe Xue*

Main category: cs.CV

> 本文综述了在无人机视角下开放式词汇物体检测（OVOD）的技术进展，通过构建系统分类法介绍了现有的OVOD方法及相关数据集，并探讨了领域内的挑战和未来研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 传统的无人机物体检测方法受限于预定义的类别，难以满足更广泛的检测需求。跨模态文本-图像对齐技术（如CLIP）使得开放式词汇物体检测成为可能，显著提高了无人机图像理解的智能性和自主性。

**Method:** 通过对开放式词汇物体检测(OVOD)与无人机视觉特性的结合进行概述，构建系统分类法，详细介绍现有方法及其数据集。

**Result:** 本文构建了详细的OVOD方法分类体系，概述了相关数据集，并指出了研究中的挑战及问题。

**Conclusion:** 综上所述，本文提出了未来研究的方向和应用前景，为领域内的研究人员提供了清晰的研究路线图。

**Abstract:** Due to its extensive applications, aerial image object detection has long
been a hot topic in computer vision. In recent years, advancements in Unmanned
Aerial Vehicles (UAV) technology have further propelled this field to new
heights, giving rise to a broader range of application requirements. However,
traditional UAV aerial object detection methods primarily focus on detecting
predefined categories, which significantly limits their applicability. The
advent of cross-modal text-image alignment (e.g., CLIP) has overcome this
limitation, enabling open-vocabulary object detection (OVOD), which can
identify previously unseen objects through natural language descriptions. This
breakthrough significantly enhances the intelligence and autonomy of UAVs in
aerial scene understanding. This paper presents a comprehensive survey of OVOD
in the context of UAV aerial scenes. We begin by aligning the core principles
of OVOD with the unique characteristics of UAV vision, setting the stage for a
specialized discussion. Building on this foundation, we construct a systematic
taxonomy that categorizes existing OVOD methods for aerial imagery and provides
a comprehensive overview of the relevant datasets. This structured review
enables us to critically dissect the key challenges and open problems at the
intersection of these fields. Finally, based on this analysis, we outline
promising future research directions and application prospects. This survey
aims to provide a clear road map and a valuable reference for both newcomers
and seasoned researchers, fostering innovation in this rapidly evolving domain.
We keep tracing related works at
https://github.com/zhouyang2002/OVOD-in-UVA-imagery

</details>


### [9] [Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance](https://arxiv.org/abs/2507.13360)
*Le-Anh Tran,Chung Nguyen Tran,Ngoc-Luu Nguyen,Nhan Cach Dang,Jordi Carrabina,David Castells-Rufas,Minh Son Nguyen*

Main category: cs.CV

> The paper presents EDNIG, a deep learning framework for enhancing low-light images through the use of an illumination map and various architectural enhancements, achieving competitive results with lower model complexity.

<details>
  <summary>Details</summary>

**Motivation:** To introduce a novel deep learning framework, EDNIG, for low-light image enhancement that effectively handles underexposed regions and maintains lower model complexity for real-world applications.

**Method:** Building upon the U-Net architecture, EDNIG integrates an illumination map derived from Bright Channel Prior (BCP) as a guidance input to focus on underexposed regions. A Spatial Pyramid Pooling (SPP) module is incorporated to extract multi-scale contextual features, and the Swish activation function is used for smoother gradient propagation during training. The model is optimized within a Generative Adversarial Network (GAN) framework using a composite loss function that combines adversarial loss, pixel-wise mean squared error (MSE), and perceptual loss.

**Result:** Experimental results show that EDNIG achieves competitive performance compared to state-of-the-art methods in both quantitative metrics and visual quality.

**Conclusion:** EDNIG demonstrates both lower model complexity and competitive performance, making it suitable for real-world low-light image enhancement applications.

**Abstract:** This paper introduces a novel deep learning framework for low-light image
enhancement, named the Encoder-Decoder Network with Illumination Guidance
(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination
map, derived from Bright Channel Prior (BCP), as a guidance input. This
illumination guidance helps the network focus on underexposed regions,
effectively steering the enhancement process. To further improve the model's
representational power, a Spatial Pyramid Pooling (SPP) module is incorporated
to extract multi-scale contextual features, enabling better handling of diverse
lighting conditions. Additionally, the Swish activation function is employed to
ensure smoother gradient propagation during training. EDNIG is optimized within
a Generative Adversarial Network (GAN) framework using a composite loss
function that combines adversarial loss, pixel-wise mean squared error (MSE),
and perceptual loss. Experimental results show that EDNIG achieves competitive
performance compared to state-of-the-art methods in quantitative metrics and
visual quality, while maintaining lower model complexity, demonstrating its
suitability for real-world applications. The source code for this work is
available at https://github.com/tranleanh/ednig.

</details>


### [10] [VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs](https://arxiv.org/abs/2507.13361)
*Shmuel Berman,Jia Deng*

Main category: cs.CV

> 研究通过评估视觉语言模型在非局部视觉推理任务中的表现，发现它们尽管在某些复杂任务中有出色表现，但在核心视觉推理能力上仍不如人类。

<details>
  <summary>Details</summary>

**Motivation:** 尽管视觉语言模型在复杂任务中表现出色，但研究发现它们在简单的感知测试中表现不佳。该研究旨在探讨这些模型是否具备类似于人类的视觉算法能力。

**Method:** 该研究设计了一套评估体系，测试视觉语言模型在非局部视觉推理任务中的能力，特别是比较感知、跳跃搜索和平滑视觉搜索三方面。

**Result:** 即使是那些在原始视觉基准测试中表现良好的旗舰模型，也在研究设计的测试中失败，且在某些任务中表现仅略高于随机水平。

**Conclusion:** 研究结果显示，尽管模型在视觉敏锐度上有所进步，但在核心视觉推理能力上仍显不足。

**Abstract:** Visual Language Models (VLMs) excel at complex visual tasks such as VQA and
chart understanding, yet recent work suggests they struggle with simple
perceptual tests. We present an evaluation that tests vision-language models'
capacity for nonlocal visual reasoning -- reasoning that requires chaining
evidence collected from multiple, possibly distant, regions of an image. We
isolate three distinct forms of non-local vision: comparative perception, which
demands holding two images in working memory and comparing them; saccadic
search, which requires making discrete, evidence-driven jumps to locate
successive targets; and smooth visual search, which involves searching smoothly
along a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude
Vision 3.7, GPT-o4-mini), even those that perform well on prior
primitive-vision benchmarks, fail these tests and barely exceed random accuracy
on two variants of our tasks that are trivial for humans. Our structured
evaluation suite allows us to test if VLMs can perform similar visual
algorithms to humans. Our findings show that despite gains in raw visual
acuity, current models lack core visual reasoning capabilities.

</details>
