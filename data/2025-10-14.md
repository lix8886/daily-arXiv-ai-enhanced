<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 34]
- [cs.CV](#cs.CV) [Total: 31]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Table Question Answering in the Era of Large Language Models: A Comprehensive Survey of Tasks, Methods, and Evaluation](https://arxiv.org/abs/2510.09671)
*Wei Zhou,Bolei Ma,Annemarie Friedrich,Mohsen Mesgar*

Main category: cs.CL

> 本文综述了TQA研究，关注LLM基础方法，提供了全面的分类和分析。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的动机在于目前TQA领域缺乏对任务设置、挑战及方法论的系统性理解，特别是在强化学习等新兴研究领域。

**Method:** 该论文主要通过对现有Table Question Answering (TQA) 研究的综述，提供了对任务格式、核心挑战及方法论趋势的系统化理解，尤其关注大型语言模型(LLM)为基础的方法。

**Result:** 研究结果是提供了TQA研究的全面结构化综述，涵盖了已有基准测试和任务设置的详细分类、现有建模策略的分组及其优缺点，以及尚未系统探索但及时的相关主题。

**Conclusion:** 通过统一不同的研究线索并识别开放问题，本文提供了一个综合的TQA研究基础，有助于更深入地理解最新成果，并指导该快速发展领域的未来研究。

**Abstract:** Table Question Answering (TQA) aims to answer natural language questions
about tabular data, often accompanied by additional contexts such as text
passages. The task spans diverse settings, varying in table representation,
question/answer complexity, modality involved, and domain. While recent
advances in large language models (LLMs) have led to substantial progress in
TQA, the field still lacks a systematic organization and understanding of task
formulations, core challenges, and methodological trends, particularly in light
of emerging research directions such as reinforcement learning. This survey
addresses this gap by providing a comprehensive and structured overview of TQA
research with a focus on LLM-based methods. We provide a comprehensive
categorization of existing benchmarks and task setups. We group current
modeling strategies according to the challenges they target, and analyze their
strengths and limitations. Furthermore, we highlight underexplored but timely
topics that have not been systematically covered in prior research. By unifying
disparate research threads and identifying open problems, our survey offers a
consolidated foundation for the TQA community, enabling a deeper understanding
of the state of the art and guiding future developments in this rapidly
evolving area.

</details>


### [2] [Emotionally Charged, Logically Blurred: AI-driven Emotional Framing Impairs Human Fallacy Detection](https://arxiv.org/abs/2510.09695)
*Yanran Chen,Lynn Greschner,Roman Klinger,Michael Klenk,Steffen Eger*

Main category: cs.CL

> 研究发现，通过大型语言模型改变谬误论证中的情感诉求可以降低人们识别谬误的能力，并增加论证的说服力，特别是在娱乐、恐惧或悲伤等情绪较高的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 研究情感框架如何与谬误和说服力相互作用的首个计算研究。

**Method:** 使用大型语言模型（LLMs）来系统地改变谬误论证中的情感诉求，评估了八种LLMs将情感诉求注入逻辑谬误论证中同时保持其逻辑结构的能力，并选择了最优的模型来生成人类研究的刺激材料。

**Result:** 结果表明，由LLMs驱动的情感框架使人类在谬误检测中的F1值平均降低了14.5%。人类在感知到娱乐时比恐惧或悲伤时在谬误检测上表现得更好，同时这三种情绪与显著更高的说服力相关。

**Conclusion:** 该研究对基于AI的情感操纵在谬误论证环境中的应用具有重要意义。

**Abstract:** Logical fallacies are common in public communication and can mislead
audiences; fallacious arguments may still appear convincing despite lacking
soundness, because convincingness is inherently subjective. We present the
first computational study of how emotional framing interacts with fallacies and
convincingness, using large language models (LLMs) to systematically change
emotional appeals in fallacious arguments. We benchmark eight LLMs on injecting
emotional appeal into fallacious arguments while preserving their logical
structures, then use the best models to generate stimuli for a human study. Our
results show that LLM-driven emotional framing reduces human fallacy detection
in F1 by 14.5% on average. Humans perform better in fallacy detection when
perceiving enjoyment than fear or sadness, and these three emotions also
correlate with significantly higher convincingness compared to neutral or other
emotion states. Our work has implications for AI-driven emotional manipulation
in the context of fallacious argumentation.

</details>


### [3] [The Idola Tribus of AI: Large Language Models tend to perceive order where none exists](https://arxiv.org/abs/2510.09709)
*Shin-nosuke Ishikawa,Masato Todo,Taiki Ogihara,Hirotsugu Ohba*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** We present a tendency of large language models (LLMs) to generate absurd
patterns despite their clear inappropriateness in a simple task of identifying
regularities in number series. Several approaches have been proposed to apply
LLMs to complex real-world tasks, such as providing knowledge through
retrieval-augmented generation and executing multi-step tasks using AI agent
frameworks. However, these approaches rely on the logical consistency and
self-coherence of LLMs, making it crucial to evaluate these aspects and
consider potential countermeasures. To identify cases where LLMs fail to
maintain logical consistency, we conducted an experiment in which LLMs were
asked to explain the patterns in various integer sequences, ranging from
arithmetic sequences to randomly generated integer series. While the models
successfully identified correct patterns in arithmetic and geometric sequences,
they frequently over-recognized patterns that were inconsistent with the given
numbers when analyzing randomly generated series. This issue was observed even
in multi-step reasoning models, including OpenAI o3, o4-mini, and Google Gemini
2.5 Flash Preview Thinking. This tendency to perceive non-existent patterns can
be interpreted as the AI model equivalent of Idola Tribus and highlights
potential limitations in their capability for applied tasks requiring logical
reasoning, even when employing chain-of-thought reasoning mechanisms.

</details>


### [4] [SeCon-RAG: A Two-Stage Semantic Filtering and Conflict-Free Framework for Trustworthy RAG](https://arxiv.org/abs/2510.09710)
*Xiaonan Si,Meilin Zhu,Simeng Qin,Lijia Yu,Lijun Zhang,Shuaitong Liu,Xinfeng Li,Ranjie Duan,Yang Liu,Xiaojun Jia*

Main category: cs.CL

> The paper introduces SeCon-RAG, a two-stage filtering framework designed to improve the trustworthiness of RAG systems by ensuring semantic consistency and mitigating conflicts, while preserving valuable knowledge.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to enhance the robustness and integrity of outputs in RAG systems by addressing vulnerabilities to corpus poisoning and contamination attacks without aggressively filtering out valuable information, thus maintaining reliability.

**Method:** The paper proposes a two-stage framework, SeCon-RAG, to improve the trustworthiness of retrieval-augmented generation (RAG) systems. The first stage involves a joint semantic and cluster-based filtering guided by the Entity-intent-relation extractor (EIRE), which scores semantic relevance and adds valuable documents into the clean retrieval database. The second stage applies an EIRE-guided conflict-aware filtering module to ensure semantic consistency and filter out contradictions.

**Result:** SeCon-RAG demonstrates significant improvements in generation robustness and output trustworthiness, outperforming state-of-the-art defense methods across various large language models and datasets.

**Conclusion:** The proposed SeCon-RAG method effectively addresses the vulnerability of RAG systems to corpus poisoning and contamination attacks, enhancing both the reliability and integrity of generated outputs. The results show marked improvements over existing defense methods.

**Abstract:** Retrieval-augmented generation (RAG) systems enhance large language models
(LLMs) with external knowledge but are vulnerable to corpus poisoning and
contamination attacks, which can compromise output integrity. Existing defenses
often apply aggressive filtering, leading to unnecessary loss of valuable
information and reduced reliability in generation. To address this problem, we
propose a two-stage semantic filtering and conflict-free framework for
trustworthy RAG. In the first stage, we perform a joint filter with semantic
and cluster-based filtering which is guided by the Entity-intent-relation
extractor (EIRE). EIRE extracts entities, latent objectives, and entity
relations from both the user query and filtered documents, scores their
semantic relevance, and selectively adds valuable documents into the clean
retrieval database. In the second stage, we proposed an EIRE-guided
conflict-aware filtering module, which analyzes semantic consistency between
the query, candidate answers, and retrieved knowledge before final answer
generation, filtering out internal and external contradictions that could
mislead the model. Through this two-stage process, SeCon-RAG effectively
preserves useful knowledge while mitigating conflict contamination, achieving
significant improvements in both generation robustness and output
trustworthiness. Extensive experiments across various LLMs and datasets
demonstrate that the proposed SeCon-RAG markedly outperforms state-of-the-art
defense methods.

</details>


### [5] [ReaLM: Residual Quantization Bridging Knowledge Graph Embeddings and Large Language Models](https://arxiv.org/abs/2510.09711)
*Wenbin Guo,Xin Wang,Jiaoyan Chen,Lingbing Guo,Zhao Li,Zirui Chen*

Main category: cs.CL

> ReaLM, a new framework, closes the gap between knowledge graph embeddings and large language models by discretizing KG embeddings and integrating them into LLMs, achieving better performance.

<details>
  <summary>Details</summary>

**Motivation:** To overcome the performance limitations of existing LLM-based methods by addressing the misalignment between KG embeddings and LLM tokenization, leading to ineffective semantic transfer.

**Method:** ReaLM proposes a framework using residual vector quantization to discretize KG embeddings into compact code sequences and integrate them as learnable tokens within the LLM vocabulary, also incorporating ontology-guided class constraints to enforce semantic consistency.

**Result:** ReaLM's approach leads to state-of-the-art performance on benchmark datasets, demonstrating its effectiveness in aligning structured knowledge with LLMs.

**Conclusion:** The approach of ReaLM not only bridges the gap between KG embeddings and LLMs but also enhances the alignment and integration of structured knowledge into large-scale language models.

**Abstract:** Large Language Models (LLMs) have recently emerged as a powerful paradigm for
Knowledge Graph Completion (KGC), offering strong reasoning and generalization
capabilities beyond traditional embedding-based approaches. However, existing
LLM-based methods often struggle to fully exploit structured semantic
representations, as the continuous embedding space of pretrained KG models is
fundamentally misaligned with the discrete token space of LLMs. This
discrepancy hinders effective semantic transfer and limits their performance.
To address this challenge, we propose ReaLM, a novel and effective framework
that bridges the gap between KG embeddings and LLM tokenization through the
mechanism of residual vector quantization. ReaLM discretizes pretrained KG
embeddings into compact code sequences and integrates them as learnable tokens
within the LLM vocabulary, enabling seamless fusion of symbolic and contextual
knowledge. Furthermore, we incorporate ontology-guided class constraints to
enforce semantic consistency, refining entity predictions based on class-level
compatibility. Extensive experiments on two widely used benchmark datasets
demonstrate that ReaLM achieves state-of-the-art performance, confirming its
effectiveness in aligning structured knowledge with large-scale language
models.

</details>


### [6] [All Code, No Thought: Current Language Models Struggle to Reason in Ciphered Language](https://arxiv.org/abs/2510.09714)
*Shiyuan Guo,Henry Sleight,Fabien Roger*

Main category: cs.CL

> 研究发现当前模型难以通过加密推理逃避CoT监控。

<details>
  <summary>Details</summary>

**Motivation:** 随着AI代理被广泛采用，检测有害AI行为变得尤其重要。本文旨在评估通过加密推理来规避链式思维(CoT)监控的可能性。

**Method:** 通过测试模型在28种不同加密方法中的推理能力来评估加密推理的风险。对于每种加密方法，对多达10个模型进行微调并提示其用该加密方法进行推理。用数学问题的准确率来衡量推理能力。

**Result:** 研究结果表明，尽管模型能够准确地将加密文本翻译成英文，但他们在加密文本中的推理能力显著下降。此外，模型对较不为人知的加密法的推理能力较差，但对于像rot13这样的常用加密法表现良好。

**Conclusion:** 研究表明，利用加密推理来绕过CoT监测对于当前模型来说不是一个有效的策略，并为我们提供了关于如何限制未来模型在这一能力上发展的指导。

**Abstract:** Detecting harmful AI actions is important as AI agents gain adoption.
Chain-of-thought (CoT) monitoring is one method widely used to detect
adversarial attacks and AI misalignment. However, attackers and misaligned
models might evade CoT monitoring through ciphered reasoning: reasoning hidden
in encrypted, translated, or compressed text. To assess this risk, we test
whether models can perform ciphered reasoning. For each of 28 different
ciphers, we fine-tune and prompt up to 10 models to reason in that cipher. We
measure model accuracy on math problems as a proxy for reasoning ability.
Across the models we test, we find an asymmetry: model accuracy can drop
significantly when reasoning in ciphered text, even though models demonstrate
comprehension of ciphered text by being able to translate it accurately to
English. Even frontier models struggle with lesser-known ciphers, although they
can reason accurately in well-known ciphers like rot13. We show that ciphered
reasoning capability correlates with cipher prevalence in pretraining data. We
also identify scaling laws showing that ciphered reasoning capability improves
slowly with additional fine-tuning data. Our work suggests that evading CoT
monitoring using ciphered reasoning may be an ineffective tactic for current
models and offers guidance on constraining the development of this capability
in future frontier models.

</details>


### [7] [Preference-Aware Memory Update for Long-Term LLM Agents](https://arxiv.org/abs/2510.09720)
*Haoran Sun,Zekun Zhang,Shaoning Zeng*

Main category: cs.CL

> 提出了一种偏好感知的记忆更新机制PAMU，用于提升LLM代理在长时段对话中的决策质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在记忆更新方面存在不足，缺乏根据用户行为和环境变化动态调整记忆表示的机制，这影响了LLM代理的推理能力。

**Method:** 通过结合滑动窗口平均值（SW）与指数移动平均值（EMA），提出了一种偏好感知的记忆更新机制（PAMU），以动态、个性化地细化记忆表示，捕捉用户行为的短期波动与长期倾向。

**Result:** 实验结果表明，在LoCoMo数据集的五个任务场景下，提出的机制能够显著提升五个基线模型的输出质量，验证了其在长时段对话中的有效性。

**Conclusion:** PAMU机制在长时段对话中表现出色，证明了它在维持和增强LLM代理决策质量方面的有效性。

**Abstract:** One of the key factors influencing the reasoning capabilities of LLM-based
agents is their ability to leverage long-term memory. Integrating long-term
memory mechanisms allows agents to make informed decisions grounded in
historical interactions. While recent advances have significantly improved the
storage and retrieval components, by encoding memory into dense vectors for
similarity search or organizing memory as structured knowledge graphs most
existing approaches fall short in memory updating. In particular, they lack
mechanisms for dynamically refining preference memory representations in
response to evolving user behaviors and contexts. To address this gap, we
propose a Preference-Aware Memory Update Mechanism (PAMU) that enables dynamic
and personalized memory refinement. By integrating sliding window averages (SW)
with exponential moving averages (EMA), PAMU constructs a fused
preference-aware representation that captures both short-term fluctuations and
long-term user tendencies. We conduct experiments on five task scenarios of the
LoCoMo dataset, and the results show that our mechanism can significantly
improve the output quality of LLM in five baselines, validating its
effectiveness in long-term conversations.

</details>


### [8] [Layout-Aware Parsing Meets Efficient LLMs: A Unified, Scalable Framework for Resume Information Extraction and Evaluation](https://arxiv.org/abs/2510.09722)
*Fanwei Zhu,Jinke Yu,Zulong Chen,Ying Zhou,Junhao Ji,Zhibo Yang,Yuxue Zhang,Haoyuan Hu,Zhenghao Liu*

Main category: cs.CL

> 本文提出了一种用于自动化提取和评估的布局感知和效率优化框架，该框架应对了简历信息提取领域的三大挑战：文档格式的多样性，LLM的成本和延迟，以及缺乏标准数据集和评估工具。实验结果显示，该框架在准确性和效率方面明显优于强基线。

<details>
  <summary>Details</summary>

**Motivation:** 自动化简历信息提取对于扩大人才获取至关重要，但其实际部署面临三个主要挑战：简历布局和内容的高度异质性，大型语言模型(LLMs)成本和延迟高，以及缺少标准化的数据集和评估工具。

**Method:** 我们的系统结合了微调的布局解析器来规范化多样化的文档格式，基于并行提示和指令微调的推断高效LLM提取器，以及由新基准数据集支持的稳健的两阶段自动化评估框架。

**Result:** 大量实验表明，我们的框架在准确性和效率方面显著优于强基线系统。特别是，微调后的紧凑型0.6B LLM在保持顶级准确率的同时，大大减少了推理延迟和计算成本。

**Conclusion:** 该系统已完全部署于阿里巴巴的智能人力资源平台，支持其跨业务部门的实时应用。

**Abstract:** Automated resume information extraction is critical for scaling talent
acquisition, yet its real-world deployment faces three major challenges: the
extreme heterogeneity of resume layouts and content, the high cost and latency
of large language models (LLMs), and the lack of standardized datasets and
evaluation tools. In this work, we present a layout-aware and
efficiency-optimized framework for automated extraction and evaluation that
addresses all three challenges. Our system combines a fine-tuned layout parser
to normalize diverse document formats, an inference-efficient LLM extractor
based on parallel prompting and instruction tuning, and a robust two-stage
automated evaluation framework supported by new benchmark datasets. Extensive
experiments show that our framework significantly outperforms strong baselines
in both accuracy and efficiency. In particular, we demonstrate that a
fine-tuned compact 0.6B LLM achieves top-tier accuracy while significantly
reducing inference latency and computational cost. The system is fully deployed
in Alibaba's intelligent HR platform, supporting real-time applications across
its business units.

</details>


### [9] [VisRAG 2.0: Evidence-Guided Multi-Image Reasoning in Visual Retrieval-Augmented Generation](https://arxiv.org/abs/2510.09733)
*Yubo Sun,Chunyi Peng,Yukun Yan,Shi Yu,Zhenghao Liu,Chi Chen,Zhiyuan Liu,Maosong Sun*

Main category: cs.CL

> 本文提出EVisRAG，一种可以通过多图推理进行学习的端到端框架，解决现有视觉检索增强生成系统跨图推理问题，并通过RS-GRPO进行优化，大幅提高了问答性能和答案的精准度。

<details>
  <summary>Details</summary>

**Motivation:** 当前基于视觉检索增强生成（VRAG）的系统在跨多个图片可靠感知和整合证据方面存在问题，导致推理接地不牢靠和产生错误结论。EVisRAG的提出正是为了加强这一环节。

**Method:** EVisRAG采用了一个端到端的框架，该框架可以通过证据引导的多图推理来学习进行推理。模型首先会观察检索到的图片并记录每张图片的证据，然后从聚合的证据中得出最终答案。此外，为有效训练EVisRAG，提出了一种称为RS-GRPO的新方法，该方法通过将细粒度的奖励绑定到特定作用范围的标记上来优化视觉感知和推理能力。

**Result:** 实验结果显示，EVisRAG在多个视觉问答基准上相较基础VLM模型提升了约27%的端到端性能。另外，EVisRAG通过精确感知和定位与问题相关证据，提高了答案的准确率。

**Conclusion:** EVisRAG通过RS-GRPO的成功应用证明了它强大的视觉感知和推理能力，使得它可以从多图证据中精确地获取与问题相关的信息，就像一个真正的侦探一样推理得出准确答案。

**Abstract:** Visual retrieval-augmented generation (VRAG) augments vision-language models
(VLMs) with external visual knowledge to ground reasoning and reduce
hallucinations. Yet current VRAG systems often fail to reliably perceive and
integrate evidence across multiple images, leading to weak grounding and
erroneous conclusions. In this paper, we propose EVisRAG, an end-to-end
framework that learns to reason with evidence-guided multi-image to address
this issue. The model first observes retrieved images and records per-image
evidence, then derives the final answer from the aggregated evidence. To train
EVisRAG effectively, we introduce Reward-Scoped Group Relative Policy
Optimization (RS-GRPO), which binds fine-grained rewards to scope-specific
tokens to jointly optimize visual perception and reasoning abilities of VLMs.
Experimental results on multiple visual question answering benchmarks
demonstrate that EVisRAG delivers substantial end-to-end gains over backbone
VLM with 27\% improvements on average. Further analysis shows that, powered by
RS-GRPO, EVisRAG improves answer accuracy by precisely perceiving and
localizing question-relevant evidence across multiple images and deriving the
final answer from that evidence, much like a real detective.

</details>


### [10] [Judge's Verdict: A Comprehensive Analysis of LLM Judge Capability Through Human Agreement](https://arxiv.org/abs/2510.09738)
*Steve Han,Gilberto Titericz Junior,Tom Balough,Wenfei Zhou*

Main category: cs.CL

> A new benchmark for evaluating large language models as judges reveals that performance is not just dependent on model size but on training strategies, with half of the models achieving high-tier performance.

<details>
  <summary>Details</summary>

**Motivation:** The goal is to provide a more comprehensive standard than correlation for evaluating LLMs as judges for response accuracy evaluation tasks, identifying their human-like or super-consistent judgment patterns.

**Method:** This research presents a novel two-step methodology to evaluate LLMs as judges, involving a correlation test followed by a human-likeness test using z-scores to identify human-like and super-consistent judgment patterns.

**Result:** The method reveals that 27 out of the 54 tested models achieve Tier 1 performance, with 23 models showing human-like patterns and 4 exhibiting super-consistent behavior, highlighting that judge excellence is not solely dependent on model size but on training strategies.

**Conclusion:** The study establishes the Judge's Verdict Benchmark, which offers a more nuanced evaluation method for LLM judges compared to simple correlation analysis, introducing a standardized approach to classify models into performance tiers.

**Abstract:** This research introduces the Judge's Verdict Benchmark, a novel two-step
methodology to evaluate Large Language Models (LLMs) as judges for response
accuracy evaluation tasks. We assess how well 54 LLMs can replicate human
judgment when scoring responses from RAG (Retrieval-Augmented Generation) or
Agentic pipelines against ground truth answers. Our methodology progresses from
traditional correlation analysis to comprehensive Cohen's Kappa analysis that
measures actual agreement patterns. The two-step approach includes: (1) a
correlation test that filters judges with strong alignment, followed by (2) a
human-likeness test using z-scores to identify two distinct judgment patterns:
human-like judgment (|z| < 1) that mimics natural human variation, and
super-consistent judgment (z > 1) that exceeds typical human-to-human agreement
levels. This methodology reveals that 27 out of 54 tested LLMs achieve Tier 1
performance: 23 models exhibit human-like patterns that preserve the nuances of
human judgment, while 4 models demonstrate super-consistent behavior, a pattern
that could indicate either enhanced reliability or oversimplification of
complex judgments. Testing 43 open-source models (1B-405B parameters) and 11
closed models (GPT, Gemini, Claude variants), we demonstrate that judge
excellence is not solely dependent on model size but on specific training
strategies. Our key contributions include: (1) establishing that correlation
alone is insufficient for judge evaluation, (2) introducing a "Turing Test for
judges" based on agreement patterns, and (3) providing a standardized benchmark
for classifying LLM judges into distinct performance tiers for different
evaluation needs.

</details>


### [11] [Gold Panning: Turning Positional Bias into Signal for Multi-Document LLM Reasoning](https://arxiv.org/abs/2510.09770)
*Adam Byerly,Daniel Khashabi*

Main category: cs.CL

> 提出Gold Panning Bandits框架，利用文档位置偏差作为诊断信号有效地找到相关内容，提高了效率而不增加模型训练负担。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型在多文档上下文中表现出基于位置而非相关性的强烈偏差。目前的方法主要是将这种偏差视为需要减轻的噪声。我们试图重新定义定位偏差利用其作为信号来更有效地找到信息。

**Method:** 引入了Gold Panning Bandits框架，该框架利用位置偏差作为诊断信号，通过重新排序文档并观察模型响应的变化来识别相关内容。定位偏差被用于选择文档排序的问题被重新定义为一个二分匹配问题。除了使用匈牙利算法在每一步迭代中计算最优分配，我们还提出了一种耗时O(N log N)的贪婪策略，其性能与传统方法相当，并且通过优先考虑不确定性最大的文档放在最能提供信息的位置来实现。

**Result:** 相比于随机排序基准线，此方法使用少至65%的语言模型查询即可识别相关文档，大大减少了计算成本，也不需要重新训练模型。

**Conclusion:** 本研究证明了将固有的语言模型偏差转化为资产用于高效推理优化的方法。

**Abstract:** Large language models exhibit a strong position bias in multi-document
contexts, systematically prioritizing information based on location rather than
relevance. While existing approaches treat this bias as noise to be mitigated,
we introduce Gold Panning Bandits, a framework that leverages position bias as
a diagnostic signal: by reordering documents and observing shifts in the
model's responses, we can efficiently identify the most relevant content. We
frame the problem of choosing reorderings as a bipartite matching problem.
While an optimal assignment can be computed at each iteration with the
Hungarian algorithm in $O(N^3)$ time, we propose a greedy $O(N \log N)$
strategy that achieves comparable performance by prioritizing the placement of
the most uncertain documents in the most informative positions. Our approach
identifies relevant documents using up to 65\% fewer language model queries
than random permutation baselines on knowledge-intensive NLP tasks,
substantially reducing computational cost without model retraining. This work
demonstrates that inherent LLM biases can be transformed from liabilities into
assets for efficient, inference-time optimization.

</details>


### [12] [PromptGuard at BLP-2025 Task 1: A Few-Shot Classification Framework Using Majority Voting and Keyword Similarity for Bengali Hate Speech Detection](https://arxiv.org/abs/2510.09771)
*Rakib Hossan,Shubhashis Roy Dipta*

Main category: cs.CL

> PromptGuard, a few-shot framework for Bengali hate speech classification, combines chi-square keyword extraction and adaptive majority voting, achieving a micro-F1 of 67.61.

<details>
  <summary>Details</summary>

**Motivation:** Traditional supervised learning methods are impractical for low-resource languages due to high labeling costs. PromptGuard aims to reduce this dependency by using a few-shot learning approach.

**Method:** PromptGuard employs chi-square statistical analysis for extracting keywords and adaptive majority voting for making classification decisions. It compares statistical keyword selection with random selection and explores various adaptive voting mechanisms.

**Result:** PromptGuard shows performance improvements over n-gram-based and random approaches, with chi-square keywords providing consistent enhancements across different categories and adaptive voting benefiting ambiguous cases.

**Conclusion:** Ablation studies show that chi-square keywords have the most consistent impact across all categories, validating the effectiveness of PromptGuard's approach to Bengali hate speech classification.

**Abstract:** The BLP-2025 Task 1A requires Bengali hate speech classification into six
categories. Traditional supervised approaches need extensive labeled datasets
that are expensive for low-resource languages. We developed PromptGuard, a
few-shot framework combining chi-square statistical analysis for keyword
extraction with adaptive majority voting for decision-making. We explore
statistical keyword selection versus random approaches and adaptive voting
mechanisms that extend classification based on consensus quality. Chi-square
keywords provide consistent improvements across categories, while adaptive
voting benefits ambiguous cases requiring extended classification rounds.
PromptGuard achieves a micro-F1 of 67.61, outperforming n-gram baselines
(60.75) and random approaches (14.65). Ablation studies confirm
chi-square-based keywords show the most consistent impact across all
categories.

</details>


### [13] [Steering Embedding Models with Geometric Rotation: Mapping Semantic Relationships Across Languages and Models](https://arxiv.org/abs/2510.09790)
*Michael Freenor,Lauren Alvarez*

Main category: cs.CL

> 研究提出了RISE方法，用于表示语义转换，并在多语言和多模型之间实现了几何操作的一致性，支持线性表示假设。

<details>
  <summary>Details</summary>

**Motivation:** 理解语言和嵌入模型如何编码语义关系对于模型的可解释性和控制至关重要。现代高维文本表示缺乏直观的几何属性，而RISE提供了跨语言的几何结构类比。

**Method:** 引入Rotor-Invariant Shift Estimation (RISE)，一种几何方法，将语义转换表示为嵌入空间中的旋转操作，利用现代语言表征的流形结构。

**Result:** RISE可以跨语言和模型操作，具有良好的性能转移性，并在三种嵌入模型、三个数据集和七种语言中进行了评估，结果表明RISE可以一致地映射具有不同语法特征的语义转换。

**Conclusion:** 该工作首次系统地证明，话语级别的语义转换在多语言嵌入空间中对应于一致的几何操作，实证支持句子级别的线性表示假设。

**Abstract:** Understanding how language and embedding models encode semantic relationships
is fundamental to model interpretability and control. While early word
embeddings exhibited intuitive vector arithmetic (''king'' - ''man'' +
''woman'' = ''queen''), modern high-dimensional text representations lack
straightforward interpretable geometric properties. We introduce
Rotor-Invariant Shift Estimation (RISE), a geometric approach that represents
semantic transformations as consistent rotational operations in embedding
space, leveraging the manifold structure of modern language representations.
RISE operations have the ability to operate across both languages and models
with high transfer of performance, suggesting the existence of analogous
cross-lingual geometric structure. We evaluate RISE across three embedding
models, three datasets, and seven morphologically diverse languages in five
major language groups. Our results demonstrate that RISE consistently maps
discourse-level semantic transformations with distinct grammatical features
(e.g., negation and conditionality) across languages and models. This work
provides the first systematic demonstration that discourse-level semantic
transformations correspond to consistent geometric operations in multilingual
embedding spaces, empirically supporting the Linear Representation Hypothesis
at the sentence level.

</details>


### [14] [Text Prompt Injection of Vision Language Models](https://arxiv.org/abs/2510.09849)
*Ruizhe Zhu*

Main category: cs.CL

> Developed and tested an algorithm for text prompt injection attacks on large vision language models, demonstrating its effectiveness and efficiency with low computational demands.

<details>
  <summary>Details</summary>

**Motivation:** Address safety concerns associated with the widespread application of large vision language models by investigating the vulnerability through text prompt injection.

**Method:** An algorithm was developed to perform text prompt injection on large vision language models.

**Result:** The developed algorithm was shown to be effective and efficient, especially on large models with minimal computational resource requirements.

**Conclusion:** The study highlights the effectiveness of text prompt injection as an attack method, particularly on large vision language models, indicating a need for improved security measures.

**Abstract:** The widespread application of large vision language models has significantly
raised safety concerns. In this project, we investigate text prompt injection,
a simple yet effective method to mislead these models. We developed an
algorithm for this type of attack and demonstrated its effectiveness and
efficiency through experiments. Compared to other attack methods, our approach
is particularly effective for large models without high demand for
computational resources.

</details>


### [15] [NG-Router: Graph-Supervised Multi-Agent Collaboration for Nutrition Question Answering](https://arxiv.org/abs/2510.09854)
*Kaiwen Shi,Zheyuan Zhang,Zhengqing Yuan,Keerthiram Murugesan,Vincent Galass,Chuxu Zhang,Yanfang Ye*

Main category: cs.CL

> The paper presents NG-Router, a new method that uses multi-agent systems guided by knowledge graphs to improve the performance of Nutrition Question Answering, achieving better results than single-agent and ensemble methods.

<details>
  <summary>Details</summary>

**Motivation:** To tackle the limitations of existing methods in providing personalized dietary guidance and preventing diet-related chronic diseases, such as low reasoning ability and complexity in designing effective multi-agent architectures.

**Method:** NG-Router, a novel framework that formulates nutritional QA as a supervised, knowledge-graph-guided multi-agent collaboration problem, integrating agent nodes into heterogeneous knowledge graphs and employing a graph neural network to learn task-aware routing distributions over agents, and a gradient-based subgraph retrieval mechanism for addressing contextual overload.

**Result:** NG-Router consistently outperforms single-agent and ensemble baselines across various benchmarks and backbone models.

**Conclusion:** The proposed NG-Router framework serves as a principled approach to multi-agent reasoning for complex nutritional health tasks.

**Abstract:** Diet plays a central role in human health, and Nutrition Question Answering
(QA) offers a promising path toward personalized dietary guidance and the
prevention of diet-related chronic diseases. However, existing methods face two
fundamental challenges: the limited reasoning capacity of single-agent systems
and the complexity of designing effective multi-agent architectures, as well as
contextual overload that hinders accurate decision-making. We introduce
Nutritional-Graph Router (NG-Router), a novel framework that formulates
nutritional QA as a supervised, knowledge-graph-guided multi-agent
collaboration problem. NG-Router integrates agent nodes into heterogeneous
knowledge graphs and employs a graph neural network to learn task-aware routing
distributions over agents, leveraging soft supervision derived from empirical
agent performance. To further address contextual overload, we propose a
gradient-based subgraph retrieval mechanism that identifies salient evidence
during training, thereby enhancing multi-hop and relational reasoning.
Extensive experiments across multiple benchmarks and backbone models
demonstrate that NG-Router consistently outperforms both single-agent and
ensemble baselines, offering a principled approach to domain-aware multi-agent
reasoning for complex nutritional health tasks.

</details>


### [16] [NarraBench: A Comprehensive Framework for Narrative Benchmarking](https://arxiv.org/abs/2510.09869)
*Sil Hamilton,Matthew Wilkens,Andrew Piper*

Main category: cs.CL

> 调研了现有叙事理解基准测试，并发现需要新的评估方法来覆盖被忽视的叙事方面，强调开发主观性和视角性评估的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 发现当前工作在某些方面对叙事理解的评估不足或与现有指标不符，指出需要新的评估方法来覆盖被忽视的叙事理解方面。

**Method:** 提出了NarraBench，一个基于理论的叙事理解任务分类法，并对78个现有的基准测试进行了调研。

**Result:** 估计当前只有27%的叙事任务被现有基准适当覆盖，某些领域如叙事事件、风格、视角和揭示几乎未被现有评估涵盖。

**Conclusion:** 强调了开发能够评估叙事方面主观性和视角性的基准的重要性。该分类法、调研和方法论对希望测试LLM叙事理解的NLP研究者有价值。

**Abstract:** We present NarraBench, a theory-informed taxonomy of narrative-understanding
tasks, as well as an associated survey of 78 existing benchmarks in the area.
We find significant need for new evaluations covering aspects of narrative
understanding that are either overlooked in current work or are poorly aligned
with existing metrics. Specifically, we estimate that only 27% of narrative
tasks are well captured by existing benchmarks, and we note that some areas --
including narrative events, style, perspective, and revelation -- are nearly
absent from current evaluations. We also note the need for increased
development of benchmarks capable of assessing constitutively subjective and
perspectival aspects of narrative, that is, aspects for which there is
generally no single correct answer. Our taxonomy, survey, and methodology are
of value to NLP researchers seeking to test LLM narrative understanding.

</details>


### [17] [CoBia: Constructed Conversations Can Trigger Otherwise Concealed Societal Biases in LLMs](https://arxiv.org/abs/2510.09871)
*Nafiseh Nikeghbal,Amir Hossein Kargaran,Jana Diesner*

Main category: cs.CL

> 研究引入了CoBia工具，通过模拟带有偏见的对话场景来系统评估LLMs在不同条件下的伦理偏差表现。结果显示，LLMs在特定情境下容易放大或强化偏见，且不容易恢复正常对话。

<details>
  <summary>Details</summary>

**Motivation:** 尽管LLMs的安全性有所提升，但它们在对话过程中仍可能出现有害行为，如表达种族主义观点。通过引入CoBia，研究团队旨在系统地分析LLMs在哪些条件下会表现出伦理偏差。

**Method:** 介绍了一种名为CoBia的轻量级对抗性攻击套件，用于系统分析LLMs在对话过程中偏离规范或伦理行为的条件范围。CoBia通过构建一种对话场景，其中模型会对某个社会群体发表有偏见的观点，并评估模型在面对这些偏见声明时是否能恢复正常并拒绝随后带有偏见的问题。

**Result:** 评估了11种开源及专有LLMs，针对六种社经人口类别即性别、种族、宗教、国籍、性取向和其他类别进行输出评估。结果显示，刻意构造的对话会可靠地揭示偏见放大效应，并且在对话过程中LLMs常常无法拒绝带有偏见的后续问题。

**Conclusion:** 通过这种压力测试，揭示了LLMs中深嵌的偏见，这些偏见在交互过程中容易显现。这表明即使是在严格的安全测试中通过的LLMs，也可能在特定对话场景下展现出有害行为。

**Abstract:** Improvements in model construction, including fortified safety guardrails,
allow Large language models (LLMs) to increasingly pass standard safety checks.
However, LLMs sometimes slip into revealing harmful behavior, such as
expressing racist viewpoints, during conversations. To analyze this
systematically, we introduce CoBia, a suite of lightweight adversarial attacks
that allow us to refine the scope of conditions under which LLMs depart from
normative or ethical behavior in conversations. CoBia creates a constructed
conversation where the model utters a biased claim about a social group. We
then evaluate whether the model can recover from the fabricated bias claim and
reject biased follow-up questions. We evaluate 11 open-source as well as
proprietary LLMs for their outputs related to six socio-demographic categories
that are relevant to individual safety and fair treatment, i.e., gender, race,
religion, nationality, sex orientation, and others. Our evaluation is based on
established LLM-based bias metrics, and we compare the results against human
judgments to scope out the LLMs' reliability and alignment. The results suggest
that purposefully constructed conversations reliably reveal bias amplification
and that LLMs often fail to reject biased follow-up questions during dialogue.
This form of stress-testing highlights deeply embedded biases that can be
surfaced through interaction. Code and artifacts are available at
https://github.com/nafisenik/CoBia.

</details>


### [18] [iBERT: Interpretable Style Embeddings via Sense Decomposition](https://arxiv.org/abs/2510.09882)
*Vishal Anand,Milad Alshomary,Kathleen McKeown*

Main category: cs.CL

> 本文提出了iBERT，一种生成解释性和可控性强的嵌入编码器，因其独特的结构设计，在风格识别任务上展现出优于同类模型的性能，并且在跨度更广的任务中也有很好的泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 为了展示我们模型的可解释性，我们在一套注重风格的任务上进行了评估。在STEL基准测试中，与SBERT类型的基线相比，iBERT将风格表示的有效性提高了约8个百分点，同时在作者验证方面的表现也保持了竞争力。

**Method:** 我们介绍了iBERT（可解释性BERT），这是一种生成固有可解释和可控嵌入的编码器，旨在模块化展现语言中的判别性线索，如风格和语义结构。每个输入令牌被表示为k个上下文无关意义向量的稀疏非负混合。这使得可以在任何解码或下游使用之前，对表示进行模块化控制。

**Result:** 实验表明，iBERT不仅在风格模型上有出色表现，而且其结构化模块化设计还可以解释地分解数据中呈现的任何判别信号，即使监督混合了风格和语义因素，也能实现泛化。

**Conclusion:** 由于每个嵌入都是可解释意义的结构化组合，我们能够将特定的风格属性，如表情符号使用、正式程度或拼写错误，分配给特定的意义向量。iBERT的设计不仅限于风格建模，对广泛的判别信号有解释和分解的能力。

**Abstract:** We present iBERT (interpretable-BERT), an encoder to produce inherently
interpretable and controllable embeddings - designed to modularize and expose
the discriminative cues present in language, such as stylistic and semantic
structure. Each input token is represented as a sparse, non-negative mixture
over k context-independent sense vectors, which can be pooled into sentence
embeddings or used directly at the token level. This enables modular control
over representation, before any decoding or downstream use.
  To demonstrate our model's interpretability, we evaluate it on a suite of
style-focused tasks. On the STEL benchmark, it improves style representation
effectiveness by ~8 points over SBERT-style baselines, while maintaining
competitive performance on authorship verification. Because each embedding is a
structured composition of interpretable senses, we highlight how specific style
attributes - such as emoji use, formality, or misspelling can be assigned to
specific sense vectors. While our experiments center on style, iBERT is not
limited to stylistic modeling. Its structural modularity is designed to
interpretably decompose whichever discriminative signals are present in the
data - enabling generalization even when supervision blends stylistic and
semantic factors.

</details>


### [19] [DELTA: Dynamic Layer-Aware Token Attention for Efficient Long-Context Reasoning](https://arxiv.org/abs/2510.09883)
*Hossein Entezari Zarch,Lei Gao,Chaoyi Jiang,Murali Annavarm*

Main category: cs.CL

> 介绍DELTA，一种无需训练的稀疏注意力机制，它既提高了计算效率，又没有牺牲模型准确度。在某些基准测试上，DELTA的准确度与完整注意力相当甚至更优，同时在标记和推理时间方面显著减少。

<details>
  <summary>Details</summary>

**Motivation:** 大规模推理模型（LRMs）在处理具有挑战性的基准测试时表现出色，但推断成本高昂。现有的稀疏注意力方法虽然减少了计算，但在推理任务中却导致严重的准确度下降。

**Method:** DELTA, 一种无需训练的稀疏注意力机制，将transformer层分为三组：初始层使用完整注意力，少量的选择层通过聚合的头部注意力分数来识别重要的标记，随后的稀疏注意力层只关注选定的子集。

**Result:** 在推理基准测试中，如AIME和GPQA-Diamond，DELTA在匹配甚至超越完整注意力准确度的同时，将关注的标记数量减少了高达5倍，并实现了1.5倍的端到端加速。

**Conclusion:** 选择性重用中间注意力图是一种向高效长上下文推理发展的稳健路径。

**Abstract:** Large reasoning models (LRMs) achieve state-of-the-art performance on
challenging benchmarks by generating long chains of intermediate steps, but
their inference cost is dominated by decoding, where each new token must attend
to the entire growing sequence. Existing sparse attention methods reduce
computation by pruning the key-value (KV) cache, yet they suffer from severe
accuracy degradation on reasoning tasks due to cumulative selection errors and
the dynamic importance of tokens over long derivations. We present
\textbf{DELTA}, a training-free sparse attention mechanism that achieves
computational efficiency without sacrificing model accuracy. DELTA partitions
transformer layers into three groups: initial layers that use full attention, a
small set of \emph{selection layers} that identify salient tokens via
aggregated head-level attention scores, and subsequent \emph{sparse-attention
layers} that attend only to the selected subset. This design preserves the full
KV cache in GPU memory for accuracy, while avoiding expensive full-attention
computation over many layers. On reasoning benchmarks such as AIME and
GPQA-Diamond, DELTA matches or surpasses full attention in accuracy, while
reducing the number of attended tokens by up to $5\times$ and delivering
$1.5\times$ end-to-end speedup. Our results show that selective reuse of
intermediate attention maps offers a robust path toward efficient long-context
reasoning.

</details>


### [20] [Closing the Data-Efficiency Gap Between Autoregressive and Masked Diffusion LLMs](https://arxiv.org/abs/2510.09885)
*Xu Pan,Ely Hahami,Jingxuan Fan,Ziqian Xie,Haim Sompolinsky*

Main category: cs.CL

> 研究比较了arLLMs和dLLMs在细调过程中的知识获取能力，结果显示dLLMs在没有额外数据增强的情况下表现更好，并提出了一种新的掩码细调范式来提高arLLMs的数据效率。

<details>
  <summary>Details</summary>

**Motivation:** 探讨自回归大型语言模型与掩码扩散大型语言模型在依赖数据增强进行问答泛化方面的不同，以及如何改进自回归模型以减少对额外数据的需求。

**Method:** 分析比较了自回归大型语言模型(arLLMs)和掩码扩散大型语言模型(dLLMs)在细调阶段的知识获取能力。通过在三个多样化数据集上进行细调，并使用正向和反向样式的问答任务进行评估，探讨了知识泛化和反向诅咒的问题。

**Result:** 结果表明arLLMs在问答泛化中严重依赖大量的数据增强（如词组变化），而词组变化只有在信息顺序匹配问答风格时才有效。相反，dLLMs无需词组变化就在正向和反向问答中达到了高准确率，增加词组变化只带来了微小改进。

**Conclusion:** 研究表明，dLLMs在获取新知识方面比arLLMs更高效，并提出了一个新方法有效提高了arLLMs的细调数据效率，缩小了性能差距。

**Abstract:** Despite autoregressive large language models (arLLMs) being the current
dominant paradigm in language modeling, they resist knowledge injection via
fine-tuning due to inherent shortcomings such as the "reversal curse" -- the
challenge of answering questions that reverse the original information order in
the training sample. Masked diffusion large language models (dLLMs) are rapidly
emerging as a powerful alternative to the arLLM paradigm, with evidence of
better data efficiency and free of the "reversal curse" in pre-training.
However, it is unknown whether these advantages extend to the post-training
phase, i.e. whether pre-trained dLLMs can easily acquire new knowledge through
fine-tuning. On three diverse datasets, we fine-tune arLLMs and dLLMs,
evaluating them with forward and backward style Question Answering (QA) to
probe knowledge generalization and the reversal curse. Our results confirm that
arLLMs critically rely on extensive data augmentation via paraphrases for QA
generalization, and paraphrases are only effective when their information order
matches the QA style. Conversely, dLLMs achieve high accuracies on both forward
and backward QAs without paraphrases; adding paraphrases yields only marginal
gains. Lastly, inspired by the dLLM's performance, we introduce a novel masked
fine-tuning paradigm for knowledge injection into pre-trained arLLMs. This
proposed method successfully and drastically improves the data efficiency of
arLLM fine-tuning, effectively closing the performance gap with dLLMs.

</details>


### [21] [Abductive Preference Learning](https://arxiv.org/abs/2510.09887)
*Yijin Ni,Peng Qi*

Main category: cs.CL

> 本文提出了一种新的细调范式，假设性偏好学习，用于解决大语言模型过度自信的问题，特别是在处理反事实提示时的准确性问题。通过多任务方法，模型不仅提高了响应选择的准确性，还改善了对不同提示的敏感性，并且保持了传统方法的优势。

<details>
  <summary>Details</summary>

**Motivation:** 现有的偏好学习方法专注于选择给定提示下的正确响应，但忽视了应该改变响应的反事实提示。为了克服这一限制并提高模型在面对不同提示时的敏感性和准确性，我们提出了一个新的方法。

**Method:** 我们提出了一种假设性偏好学习的方法，这是一种细调范式，它逆转了常规的条件，通过给定的响应来学习对提示的偏好。我们构建了一个从HaluEval问答基准中衍生出的假设性数据集，包含1,001条条目，并实现了假设性DPO及其变体DPOP。

**Result:** 实验结果显示了标准方法和假设性方法的互补性：标准方法改善了响应选择，而假设性方法则改善了提示区分能力。在我们的假设性数据集上，多任务DPOP将响应选择准确率从90.0%提高到了99.5%，将提示区分准确率从54.7%提高到了85.0%。

**Conclusion:** 最终，在AlpacaEval上的评估显示，多任务DPOP将获胜率从5.26%提高到了6.17%，确认了假设性偏好学习在保持传统偏好优化带来的好处的同时，也解决了反事实提示这个被忽视的挑战。

**Abstract:** Frontier large language models such as GPT-5 and Claude Sonnet remain prone
to overconfidence even after alignment through Reinforcement Learning with
Human Feedback (RLHF) and Direct Preference Optimization (DPO). For instance,
they tend to offer the same conservative answer "No" to both questions "Can I
eat the [food / potato chips] that has been left out overnight?" despite the
latter requiring no refridgeration for safe consumption. We find that this
failure is potentially attributed to a limitation of existing preference
learning: it emphasizes selecting the correct response for a given prompt,
while neglecting counterfactual prompts that should alter the response.
  To address this limitation, we propose abductive preference learning, a
fine-tuning paradigm that reverses the conventional conditioning by learning
preferences over prompts given a response. To validate this idea, we construct
an abductive dataset derived from the HaluEval QA benchmark with 1,001 entries,
implementing abductive DPO and its variant DPOP. Experiments reveal
complementary strengths: standard methods improve response selection, abductive
methods improve prompt discrimination, while a multitask objective unifies
both. On the abductive dataset, multitask DPOP boosts accuracy from $90.0\%$ to
$99.5\%$ in response selection and $54.7\%$ to $85.0\%$ in prompt
discrimination, with qualitative evidence highlighting improved sensitivity to
prompt differences. Finally, evaluation on AlpacaEval shows multitask DPOP
improves win rate (from $5.26\%$ to $6.17\%$), confirming that abductive
preference learning preserves the benefits of conventional preference
optimization while addressing the overlooked challenge of counterfactual
prompts.

</details>


### [22] [HIPPD: Brain-Inspired Hierarchical Information Processing for Personality Detection](https://arxiv.org/abs/2510.09893)
*Guanming Chen,Lingzhi Shen,Xiaohao Cai,Imran Razzak,Shoaib Jameel*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Personality detection from text aims to infer an individual's personality
traits based on linguistic patterns. However, existing machine learning
approaches often struggle to capture contextual information spanning multiple
posts and tend to fall short in extracting representative and robust features
in semantically sparse environments. This paper presents HIPPD, a
brain-inspired framework for personality detection that emulates the
hierarchical information processing of the human brain. HIPPD utilises a large
language model to simulate the cerebral cortex, enabling global semantic
reasoning and deep feature abstraction. A dynamic memory module, modelled after
the prefrontal cortex, performs adaptive gating and selective retention of
critical features, with all adjustments driven by dopaminergic prediction error
feedback. Subsequently, a set of specialised lightweight models, emulating the
basal ganglia, are dynamically routed via a strict winner-takes-all mechanism
to capture the personality-related patterns they are most proficient at
recognising. Extensive experiments on the Kaggle and Pandora datasets
demonstrate that HIPPD consistently outperforms state-of-the-art baselines.

</details>


### [23] [Don't Throw Away Your Pretrained Model](https://arxiv.org/abs/2510.09913)
*Shangbin Feng,Wenhao Yu,Yike Wang,Hongming Zhang,Yulia Tsvetkov,Dong Yu*

Main category: cs.CL

> 提出了一种名为Switch Generation的方法，通过模型协作在保持语言模型各项技能的同时提升其表现。实验证明该方法有效。

<details>
  <summary>Details</summary>

**Motivation:** 旨在利用未对齐的基础模型和对齐的语言模型之间的优势，通过模型协作来提升语言模型的综合能力，特别是在推理和指令跟随能力上的提升而不会丧失创造力和校准能力。

**Method:** 通过模型协作来优化语言模型，其中具体的方法是Switch Generation：预训练模型和对齐模型轮流生成响应序列的各个部分。在训练过程中，通过学习在不同查询和上下文中选择不同模型生成下一个片段的成果来训练一个开关LM，在推理时，开关LM指导不同模型检查点动态生成其强项最需要的下一个片段。

**Result:** 实验表明，模型协作在18个任务中的16个任务上持续超越单独的模型，而Switch Generation平均比基线方法高出12.9%。此外，Switch Generation还能够解决单个模型难以处理的问题，并推广到新的模型和任务。

**Conclusion:** Switch Generation能够发现组合技能来解决单个模型难以解决的问题，并能够在未见过的模型和任务上进行泛化，同时还可以重新利用昂贵的模型训练管道中的副产品。

**Abstract:** Alignment training has tradeoffs: it helps language models (LMs) gain in
reasoning and instruction following but might lose out on skills such as
creativity and calibration, where unaligned base models are better at. We aim
to make the best of both worlds through model collaboration, where different
models in the training pipeline collaborate and complement each other. Since LM
responses feature interleaving skills that favor different models, we propose
Switch Generation, where pretrained and aligned model versions take turns to
``speak'' in a response sequence. Specifically, we train a switcher LM by
learning from outcomes of choosing different models to generate the next
segment across diverse queries and contexts. At inference time, the switcher LM
guides different model checkpoints to dynamically generate the next segment
where their strengths are most needed. Extensive experiments with 8 model
collaboration baselines and 18 datasets show that 1) model collaboration
consistently outperforms individual models on 16 out of 18 tasks, and 2) Switch
Generation further outperforms baselines by 12.9% on average. Further analysis
reveals that Switch Generation discovers compositional skills to solve problems
where individual models struggle and generalizes to unseen models and tasks,
reusing and repurposing by-products in expensive model training pipelines that
are otherwise discarded.

</details>


### [24] [Enhancing Faithfulness in Abstractive Summarization via Span-Level Fine-Tuning](https://arxiv.org/abs/2510.09915)
*Sicong Huang,Qianqi Yan,Shengze Wang,Ian Lane*

Main category: cs.CL

> 本文提出了一个新型数据集，其中包括具有片段级标签的忠实和不忠实摘要，并评估了三种LLM细调技术（梯度上升、负面训练和任务向量否定），以改善摘要的忠实度。实验结果显示，所有三种方法都在成功利用片段级注释提高忠实度方面取得了成功，其中负面训练的效果最为显著。

<details>
  <summary>Details</summary>

**Motivation:** 随着大型语言模型（LLMs）在生成流畅摘要方面的能力，它们有时会生成不忠实的摘要，引入词、短语或概念级幻觉。现有的缓解策略如后处理修正或对比学习并不能充分解决这些错误。因此，本研究旨在提出一种有效的细调策略，减少摘要中的不忠实片段。

**Method:** 本研究提出了一种细调策略，以减少大型语言模型（LLMs）生成摘要中的不忠实片段。首先，使用多种LLMs自动生成训练集中源文档的摘要，然后使用GPT-4对检测到的任何幻觉进行片段级注释。利用这些注释，对LLMs进行细调，结合无幻觉摘要和标记的不忠实片段，提高模型的忠实度。

**Result:** 实验结果显示，所有三种方法（梯度上升、负面训练和任务向量否定）都能成功利用片段级注释，提高生成摘要的忠实度，其中负面训练的效果最为显著。

**Conclusion:** 实验结果表明，三种细调技术在利用片段级注释提高摘要的忠实度方面都取得了成功，其中负面训练最为有效。

**Abstract:** Abstractive summarization using large language models (LLMs) has become an
essential tool for condensing information. However, despite their ability to
generate fluent summaries, these models sometimes produce unfaithful summaries,
introducing hallucinations at the word, phrase, or concept level. Existing
mitigation strategies, such as post-processing corrections or contrastive
learning with synthetically generated negative samples, fail to fully address
the diverse errors that can occur in LLM-generated summaries. In this paper, we
investigate fine-tuning strategies to reduce the occurrence of unfaithful spans
in generated summaries. First, we automatically generate summaries for the set
of source documents in the training set with a variety of LLMs and then use
GPT-4o to annotate any hallucinations it detects at the span-level. Leveraging
these annotations, we fine-tune LLMs with both hallucination-free summaries and
annotated unfaithful spans to enhance model faithfulness. In this paper, we
introduce a new dataset that contains both faithful and unfaithful summaries
with span-level labels and we evaluate three techniques to fine-tuning a LLM to
improve the faithfulness of the resulting summarization: gradient ascent,
unlikelihood training, and task vector negation. Experimental results show that
all three approaches successfully leverage span-level annotations to improve
faithfulness, with unlikelihood training being the most effective.

</details>


### [25] [Unpacking Hateful Memes: Presupposed Context and False Claims](https://arxiv.org/abs/2510.09935)
*Weibin Cai,Jiayu Li,Reza Zafarani*

Main category: cs.CL

> 论文提出了SHIELD框架，结合PCM和FACT模块，用于检测含恨意的梗图，通过捕捉预设背景和表达虚假声明来识别含恨内容，实验结果表明该方法优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法主要依赖预训练的语言模型来检测恶意梗图，但少有探讨构成恶意内容的核心要素，论文旨在通过哲学和心理学视角深入探讨。

**Method:** 提出PCM模块用于捕捉跨模态的预设背景信息，FACT模块用于检测虚假声明，结合两模块建立SHIELD框架。

**Result:** 实验表明，SHIELD框架在多个数据集和指标上优于现有方法，且在如假新闻检测等其他任务上展示了较好的适应性。

**Conclusion:** 通过引入PCM和FACT模块，SHIELD框架能够在多模态背景下有效捕捉和检测含恨内容，展现了其在多个任务上的优越性能和广泛适用性。

**Abstract:** While memes are often humorous, they are frequently used to disseminate hate,
causing serious harm to individuals and society. Current approaches to hateful
meme detection mainly rely on pre-trained language models. However, less focus
has been dedicated to \textit{what make a meme hateful}. Drawing on insights
from philosophy and psychology, we argue that hateful memes are characterized
by two essential features: a \textbf{presupposed context} and the expression of
\textbf{false claims}. To capture presupposed context, we develop \textbf{PCM}
for modeling contextual information across modalities. To detect false claims,
we introduce the \textbf{FACT} module, which integrates external knowledge and
harnesses cross-modal reference graphs. By combining PCM and FACT, we introduce
\textbf{\textsf{SHIELD}}, a hateful meme detection framework designed to
capture the fundamental nature of hate. Extensive experiments show that SHIELD
outperforms state-of-the-art methods across datasets and metrics, while
demonstrating versatility on other tasks, such as fake news detection.

</details>


### [26] [Beyond Fertility: Analyzing STRR as a Metric for Multilingual Tokenization Evaluation](https://arxiv.org/abs/2510.09947)
*Mir Tafseer Nayeem,Sawsan Alqahtani,Md Tahmid Rahman Laskar,Tasnim Mohiuddin,M Saiful Bari*

Main category: cs.CL

> 研究提出了单词元保留率（STRR）作为衡量词元分配的新方法，揭示了跨语言公平性，并提供设计更公平多语言词元化工具的实用指导。

<details>
  <summary>Details</summary>

**Motivation:** 传统的度量标准——生育率（每个词的平均词元数）虽然能衡量压缩效率，但却掩盖了词汇在不同语言和领域间的分配情况。

**Method:** 通过分析六种广泛使用的词元化工具在七种语言和两个领域的表现，提出了一种新的度量标准：单词元保留率（STRR），以解决现有度量标准的盲点。

**Result:** 研究发现现有词元化工具在英语中表现出稳定的生育率，在中文中表现出较高的生育率，且对领域敏感性较低。STRR揭示了英语的系统性优先、中文的强支持以及印地语的碎片化。

**Conclusion:** STRR能补充生育率度量标准的不足，有助于设计更公平的多语言词元化工具。

**Abstract:** Tokenization is a crucial but under-evaluated step in large language models
(LLMs). The standard metric, fertility (the average number of tokens per word),
captures compression efficiency but obscures how vocabularies are allocated
across languages and domains. We analyze six widely used tokenizers across
seven languages and two domains, finding stable fertility for English, high
fertility for Chinese, and little domain sensitivity. To address fertility's
blind spots, we propose the Single Token Retention Rate (STRR), which measures
the proportion of words preserved as single tokens. STRR reveals systematic
prioritization of English, strong support for Chinese, and fragmentation in
Hindi, offering an interpretable view of cross-lingual fairness. Our results
show that STRR complements fertility and provides practical guidance for
designing more equitable multilingual tokenizers.

</details>


### [27] [Unifying Tree Search Algorithm and Reward Design for LLM Reasoning: A Survey](https://arxiv.org/abs/2510.09988)
*Jiaqi Wei,Xiang Zhang,Yuejin Yang,Wenxuan Huang,Juntai Cao,Sheng Xu,Xiang Zhuang,Zhangyang Gao,Muhammad Abdul-Mageed,Laks V. S. Lakshmanan,Chenyu You,Wanli Ouyang,Siqi Sun*

Main category: cs.CL

> 该论文提出了一种将搜索算法分解成三个核心组件的统一框架，区分了瞬时搜索指引和持久参数奖励建模，为创建自主自我改进的智能体规划了研究路线。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在解决领域内缺乏共同形式化的模糊问题，特别是奖励信号的角色（作为瞬时启发式或持久学习目标）。

**Method:** 通过引入统一框架，分解搜索算法为三个核心组件：搜索机制、奖励制定和转移函数，该论文区分了TTS的瞬时搜索指引与自我提升的持久参数奖励建模。

**Result:** 建立了搜索指引和参数奖励建模之间的形式区别，提出了一种基于组件的分类法，总结了最新进展，并规划了一条通往系统性进步的研究路线。

**Conclusion:** 文章展示了如何通过统一的形式化方法来解决领域内的碎片化问题，为瞬时行为和持久提升提供明确的指导，并指明未来的研究方向。

**Abstract:** Deliberative tree search is a cornerstone of modern Large Language Model
(LLM) research, driving the pivot from brute-force scaling toward algorithmic
efficiency. This single paradigm unifies two critical frontiers:
\textbf{Test-Time Scaling (TTS)}, which deploys on-demand computation to solve
hard problems, and \textbf{Self-Improvement}, which uses search-generated data
to durably enhance model parameters. However, this burgeoning field is
fragmented and lacks a common formalism, particularly concerning the ambiguous
role of the reward signal -- is it a transient heuristic or a durable learning
target? This paper resolves this ambiguity by introducing a unified framework
that deconstructs search algorithms into three core components: the
\emph{Search Mechanism}, \emph{Reward Formulation}, and \emph{Transition
Function}. We establish a formal distinction between transient \textbf{Search
Guidance} for TTS and durable \textbf{Parametric Reward Modeling} for
Self-Improvement. Building on this formalism, we introduce a component-centric
taxonomy, synthesize the state-of-the-art, and chart a research roadmap toward
more systematic progress in creating autonomous, self-improving agents.

</details>


### [28] [Toward Machine Translation Literacy: How Lay Users Perceive and Rely on Imperfect Translations](https://arxiv.org/abs/2510.09994)
*Yimin Xiao,Yongle Zhang,Dayeon Ki,Calvin Bao,Marianna J. Martindale,Charlotte Vaughn,Ge Gao,Marine Carpuat*

Main category: cs.CL

> A human study in a public museum investigates the reliance of bilingual and non-bilingual users on imperfect Machine Translation, revealing that non-bilingual users tend to over-rely on MT due to a lack of assessment strategies.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to understand the impact of imperfect MT on the general public in real-world applications and to promote better assessment strategies for MT quality and user reliance.

**Method:** The study utilizes a human study conducted in a public museum with 452 participants, focusing on how fluency and adequacy in Machine Translation (MT) affect reliance on MT among bilingual and non-bilingual users.

**Result:** The results show that non-bilingual users often over-rely on MT due to a lack of assessment strategies and alternatives. Encounters with translation errors can cause users to reassess their future reliance on MT.

**Conclusion:** The conclusion emphasizes the need for MT evaluation and NLP explanation techniques to foster MT literacy among users, given the over-reliance noted among non-bilingual participants when confronted with translation errors.

**Abstract:** As Machine Translation (MT) becomes increasingly commonplace, understanding
how the general public perceives and relies on imperfect MT is crucial for
contextualizing MT research in real-world applications. We present a human
study conducted in a public museum (n=452), investigating how fluency and
adequacy errors impact bilingual and non-bilingual users' reliance on MT during
casual use. Our findings reveal that non-bilingual users often over-rely on MT
due to a lack of evaluation strategies and alternatives, while experiencing the
impact of errors can prompt users to reassess future reliance. This highlights
the need for MT evaluation and NLP explanation techniques to promote not only
MT quality, but also MT literacy among its users.

</details>


### [29] [MTP-S2UT: Enhancing Speech-to-Speech Translation Quality with Multi-token Prediction](https://arxiv.org/abs/2510.10003)
*Jianjin Wang,Runsong Zhao,Xiaoqian Liu,Yuan Ge,Ziqiang Xu,Tong Xiao,Shengxiang Gao,Zhengtao Yu,Jingbo Zhu*

Main category: cs.CL

> 本研究提出了一种新的名为MTP-S2UT的技术，通过在S2UT模型中应用多令牌预测损失到CTC损失计算的隐藏层，显著提升了翻译质量。

<details>
  <summary>Details</summary>

**Motivation:** 现有的直接语音到语音翻译方法主要使用语音令牌作为中间表示，然而，单个语音令牌的语义并不是密集的，需要多个令牌来表达完整的语义单元。

**Method:** 通过在语音到单元翻译(S2UT)模型中引入多令牌预测(MTP)损失，改进模型以预测每个位置的多个后续令牌，从而使模型能够捕捉更完整的语义单元，提高每个位置的信息密度。同时，提出MTP-S2UT损失，将MTP损失应用于计算CTC损失的隐藏表示中，以实现更早和更有效的增益。

**Result:** 实验表明，所有MTP损失的变体都能一致地改善S2UT翻译的质量，其中MTP-S2UT取得了最好的效果。

**Conclusion:** 通过提出的MTP-S2UT方法，实验证明该方法可以更早、更有效地提升语音转文字翻译中的信息密度和翻译质量。

**Abstract:** Current direct speech-to-speech translation methods predominantly employ
speech tokens as intermediate representations. However, a single speech token
is not dense in semantics, so we generally need multiple tokens to express a
complete semantic unit. To address this limitation, we introduce multi-token
prediction (MTP) loss into speech-to-unit translation (S2UT) models, enabling
models to predict multiple subsequent tokens at each position, thereby
capturing more complete semantics and enhancing information density per
position. Initial MTP implementations apply the loss at the final layer, which
improves output representation but initiates information enrichment too late.
We hypothesize that advancing the information enrichment process to
intermediate layers can achieve earlier and more effective enhancement of
hidden representation. Consequently, we propose MTP-S2UT loss, applying MTP
loss to hidden representation where CTC loss is computed. Experiments
demonstrate that all MTP loss variants consistently improve the quality of S2UT
translation, with MTP-S2UT achieving the best performance.

</details>


### [30] [Beyond the limitation of a single query: Train your LLM for query expansion with Reinforcement Learning](https://arxiv.org/abs/2510.10009)
*Shu Zhao,Tan Yu,Anbang Xu*

Main category: cs.CL

> 为了解决当前基于推理增强的搜索代理在多跳问答中的性能瓶颈，本文提出了一种名为ExpandSearch的方法，通过强化学习训练的大语言模型搜索代理，并结合预训练的压缩模型来改进查询生成和信息理解能力，从而在多跳问答基准测试上取得最好的性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 目前，基于推理增强的搜索代理在多跳问答基准上的表现仍然不理想，主要原因是推理和搜索能力的限制。为了解决复杂或复合查询的问题，我们需要一个优化的搜索代理，能够在查询生成、检索信息理解和答案生成等多个任务中提升性能。

**Method:** tığımız方法是训练一个基于大语言模型的搜索代理，该代理具有通过强化学习进行查询扩展的能力。在每个回合中，搜索代理会提出几个查询变体，同时搜索以覆盖更多的相关信息。此外，我们还引入了一个预训练的压缩模型来帮助搜索代理更好地理解检索到的文档，从而使搜索代理能够专注于查询生成以提高检索召回率。

**Result:** 我们的实验结果表明，相比于最先进的基线方法，我们提出的方法ExpandSearch在七个问答基准测试上平均提高了4.4%的性能，在需要多种证据聚合的多跳推理任务上获得了显著的提升。

**Conclusion:** 即使是一个小型的30亿参数语言模型，在有了压缩模型的帮助之后，也能够展现出强大的查询扩展能力，并且在多跳问答基准上达到最先进的准确度。这表明通过优化的搜索策略和有效的信息理解，即便是较小规模的模型也能显著改善性能。

**Abstract:** Reasoning-augmented search agents, such as Search-R1, are trained to reason,
search, and generate the final answer iteratively. Nevertheless, due to their
limited capabilities in reasoning and search, their performance on multi-hop QA
benchmarks remains far from satisfactory. To handle complex or compound
queries, we train an LLM-based search agent with the native capability of query
expansion through reinforcement learning. In each turn, our search agent
proposes several query variants, which are searched simultaneously to cover
more relevant information. Meanwhile, given limited post-training data and
computing resources, it is very challenging for a search agent to master
multiple tasks, including query generation, retrieved information
understanding, and answer generation. Therefore, we propose incorporating a
pre-trained squeezer model that helps the search agent understand the retrieved
documents, allowing the search agent to focus on query generation for high
retrieval recall. With the assistance of the squeezer model, we discover that
even a small-scale 3B LLM can demonstrate a strong capability of query
expansion and achieve state-of-the-art accuracy on the multi-hop QA benchmarks.
To be specific, our experiments across seven question-answering benchmarks
demonstrate that our method, named ExpandSearch, achieves an average
improvement of 4.4% compared to state-of-the-art baselines, with strong gains
on multi-hop reasoning tasks requiring diverse evidence aggregation.

</details>


### [31] [Path Drift in Large Reasoning Models:How First-Person Commitments Override Safety](https://arxiv.org/abs/2510.10013)
*Yuyi Huang,Runzhe Zhan,Lidia S. Chao,Ailin Tao,Derek F. Wong*

Main category: cs.CL

> 该论文揭示了在使用长链思考(Long-CoT)提示进行复杂推理时，大型语言模型(LLMs)出现了一种新的漏洞：路径偏离(Path Drift)。该漏洞导致推理路径偏离对齐路径，产生违反安全约束的内容。论文提出了路径偏离的三个触发行为和一个三阶段路径偏离诱导框架，同时提出了路径级防御策略来减轻此类风险。

<details>
  <summary>Details</summary>

**Motivation:** 该研究旨在揭示Long-CoT模型中的一种新漏洞，并探索引发该漏洞的机制，以期提升模型的安全性及合理性。

**Method:** 通过实证分析，发现了路径偏离的三种触发行为，并提出了一个三阶段的路径偏离诱导框架。

**Result:** 实验显示，三阶段独立减少了拒绝率，结合使用效果更显著。路径级防御策略可以有效减轻路径偏离带来的安全风险。

**Conclusion:** 研究结果强调了长形式推理中需要进行轨迹级对齐监督，而不仅仅依赖于基于token级别的对齐措施。

**Abstract:** As large language models (LLMs) are increasingly deployed for complex
reasoning tasks, Long Chain-of-Thought (Long-CoT) prompting has emerged as a
key paradigm for structured inference. Despite early-stage safeguards enabled
by alignment techniques such as RLHF, we identify a previously underexplored
vulnerability: reasoning trajectories in Long-CoT models can drift from aligned
paths, resulting in content that violates safety constraints. We term this
phenomenon Path Drift. Through empirical analysis, we uncover three behavioral
triggers of Path Drift: (1) first-person commitments that induce goal-driven
reasoning that delays refusal signals; (2) ethical evaporation, where
surface-level disclaimers bypass alignment checkpoints; (3) condition chain
escalation, where layered cues progressively steer models toward unsafe
completions. Building on these insights, we introduce a three-stage Path Drift
Induction Framework comprising cognitive load amplification, self-role priming,
and condition chain hijacking. Each stage independently reduces refusal rates,
while their combination further compounds the effect. To mitigate these risks,
we propose a path-level defense strategy incorporating role attribution
correction and metacognitive reflection (reflective safety cues). Our findings
highlight the need for trajectory-level alignment oversight in long-form
reasoning beyond token-level alignment.

</details>


### [32] [Lightweight Baselines for Medical Abstract Classification: DistilBERT with Cross-Entropy as a Strong Default](https://arxiv.org/abs/2510.10025)
*Jiaqi Liu,Lanruo Wang,Su Liu,Xin Hu*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Large language models work well for many NLP tasks, but they are hard to
deploy in health settings with strict cost, latency, and privacy limits. We
revisit a lightweight recipe for medical abstract classification and ask how
far compact encoders can go under a controlled budget. Using the public medical
abstracts corpus, we finetune BERT base and DistilBERT with three objectives
standard cross-entropy, class weighted cross entropy, and focal loss keeping
tokenizer, sequence length, optimizer, and schedule fixed. DistilBERT with
plain cross-entropy gives the best balance on the test set while using far
fewer parameters than BERT base. We report accuracy, Macro F1, and Weighted F1,
release the evaluation code, and include confusion analyses to make error
patterns clear. Our results suggest a practical default: start with a compact
encoder and cross-entropy, then add calibration and task-specific checks before
moving to heavier models.

</details>


### [33] [HUME: Measuring the Human-Model Performance Gap in Text Embedding Task](https://arxiv.org/abs/2510.10062)
*Adnan El Assadi,Isaac Chung,Roman Solomatin,Niklas Muennighoff,Kenneth Enevoldsen*

Main category: cs.CL

> 此论文引入了HUME，一个评估文本嵌入模型的人类评价框架，通过人类在16个MTEB数据集上的表现，提出了人类性能的基准，帮助解释模型得分并指导模型和基准的发展。

<details>
  <summary>Details</summary>

**Motivation:** 了解嵌入模型的优势和局限性并填补人类在嵌入任务上的表现难以测量的空白。

**Method:** 通过HUME框架，测量人类在16个MTEB数据集上的表现，这些数据集涵盖了重排序、分类、聚类和语义文本相似性等任务，以及不同语种和资源量的数据。

**Result:** 人类在这些任务上表现出了77.6%的能力，而最好的嵌入模型达到了80.1%，显示了模型和人类在某些数据集上的表现差距，揭示了低资源语言中的问题。

**Conclusion:** 提供了一个可扩展的评估框架，提出了人类表现的基准，对任务难度的洞察有助于更好地解释模型得分，并指明模型和基准的发展方向。

**Abstract:** Comparing human and model performance offers a valuable perspective for
understanding the strengths and limitations of embedding models, highlighting
where they succeed and where they fail to capture meaning and nuance. However,
such comparisons are rarely made, as human performance on embedding tasks is
difficult to measure. To fill this gap, we introduce HUME: Human Evaluation
Framework for Text Embeddings. While frameworks like MTEB provide broad model
evaluation, they lack reliable estimates of human performance, limiting the
interpretability of model scores. We measure human performance across 16 MTEB
datasets spanning reranking, classification, clustering, and semantic textual
similarity across linguistically diverse high- and low-resource languages.
Humans achieve an average performance of 77.6% compared to 80.1% for the best
embedding model, although variation is substantial: models reach near-ceiling
performance on some datasets while struggling on others, suggesting dataset
issues and revealing shortcomings in low-resource languages. We provide human
performance baselines, insight into task difficulty patterns, and an extensible
evaluation framework that enables a more meaningful interpretation of the model
and informs the development of both models and benchmarks. Our code, dataset,
and leaderboard are publicly available at
https://github.com/embeddings-benchmark/mteb.

</details>


### [34] [CLMN: Concept based Language Models via Neural Symbolic Reasoning](https://arxiv.org/abs/2510.10063)
*Yibo Yang*

Main category: cs.CL

> CLMN结合神经网络和符号逻辑推理，在保持性能的同时提高了NLP的可解释性，并在多个数据集和预训练语言模型上取得了比现有基于概念的方法更高的准确性和解释质量。

<details>
  <summary>Details</summary>

**Motivation:** 提高NLP在医疗和金融等领域的可解释性，改进现有概念瓶颈模型的局限性。

**Method:** 提出一种神经-符号框架CLMN，使用连续可读的概念嵌入以及模糊逻辑推理来学习概念之间的交互规则。

**Result:** 在多个数据集和预训练语言模型上，CLMN的准确性和解释质量都优于现有概念基础的方法。

**Conclusion:** 结合神经表示和符号推理的统一概念空间可以产生实用透明的NLP系统。

**Abstract:** Deep learning has advanced NLP, but interpretability remains limited,
especially in healthcare and finance. Concept bottleneck models tie predictions
to human concepts in vision, but NLP versions either use binary activations
that harm text representations or latent concepts that weaken semantics, and
they rarely model dynamic concept interactions such as negation and context. We
introduce the Concept Language Model Network (CLMN), a neural-symbolic
framework that keeps both performance and interpretability. CLMN represents
concepts as continuous, human-readable embeddings and applies fuzzy-logic
reasoning to learn adaptive interaction rules that state how concepts affect
each other and the final decision. The model augments original text features
with concept-aware representations and automatically induces interpretable
logic rules. Across multiple datasets and pre-trained language models, CLMN
achieves higher accuracy than existing concept-based methods while improving
explanation quality. These results show that integrating neural representations
with symbolic reasoning in a unified concept space can yield practical,
transparent NLP systems.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [35] [TinyViT-Batten: Few-Shot Vision Transformer with Explainable Attention for Early Batten-Disease Detection on Pediatric MRI](https://arxiv.org/abs/2510.09649)
*Khartik Uppalapati,Bora Yimenicioglu,Shakeel Abdulkareem,Adan Eftekhari,Bhavya Uppalapati,Viraj Kamath*

Main category: cs.CV

> 提出了一种名为TinyViT-Batten的少量样本Vision Transformer框架，用于检测早期Batten病，该模型通过整合Grad-CAM以解释预测结果，在少量样本的情况下能够实现高准确率。

<details>
  <summary>Details</summary>

**Motivation:** Batten病（神经细胞脂褐质沉积症）是一种罕见的儿科神经退行性疾病，其早期的MRI迹象微妙且容易被忽视。所以我们开发了一个基于少量样本学习的视觉变压器模型，以提高早期Batten病的检测。

**Method:** 我们提出了一种名为TinyViT-Batten的少量样本视觉变压器（ViT）框架，用于从儿童脑部MRI图像中检测早期Batten病。这个框架通过将一个大型的teacher ViT蒸馏成一个参数量为5M的TinyViT，并使用基于度量的少量样本学习（使用5-shot孤例的原型损失）进行微调。

**Result:** 我们的模型在一个涉及79个经基因确认的Batten病MRI图像（27个CLN3，来自Hochstein自然历史研究；32个CLN2，来自国际纵向队列；12个由Cokal等人报告的早期表现CLN2病例；8个公共Radiopaedia扫描图像）以及90个同龄对照的多中心数据集上，实现了大约91%的高准确率和至少0.95的ROC曲线下面积，并且优于3D-ResNet和Swin-Tiny基线。

**Conclusion:** 模型的小尺寸和强大性能（敏感性大于90%，特异性约90%）证明了这是一种实用的AI解决方案，用于早期Batten病的检测。

**Abstract:** Batten disease (neuronal ceroid lipofuscinosis) is a rare pediatric
neurodegenerative disorder whose early MRI signs are subtle and often missed.
We propose TinyViT-Batten, a few-shot Vision Transformer (ViT) framework to
detect early Batten disease from pediatric brain MRI with limited training
cases. We distill a large teacher ViT into a 5 M-parameter TinyViT and
fine-tune it using metric-based few-shot learning (prototypical loss with
5-shot episodes). Our model achieves high accuracy (approximately 91%) and area
under ROC of at least 0.95 on a multi-site dataset of 79 genetically confirmed
Batten-disease MRIs (27 CLN3 from the Hochstein natural-history study, 32 CLN2
from an international longitudinal cohort, 12 early-manifestation CLN2 cases
reported by Cokal et al., and 8 public Radiopaedia scans) together with 90
age-matched controls, outperforming a 3D-ResNet and Swin-Tiny baseline. We
further integrate Gradient-weighted Class Activation Mapping (Grad-CAM) to
highlight disease-relevant brain regions, enabling explainable predictions. The
model's small size and strong performance (sensitivity greater than 90%,
specificity approximately 90%) demonstrates a practical AI solution for early
Batten disease detection.

</details>


### [36] [Ultralytics YOLO Evolution: An Overview of YOLO26, YOLO11, YOLOv8 and YOLOv5 Object Detectors for Computer Vision and Pattern Recognition](https://arxiv.org/abs/2510.09653)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

> 本文概述了YOLO系列目标检测器的发展，强调YOLO26的关键创新，并对不同版本的YOLO及其他检测器进行了基准测试与对比，评估了准确性和效率间的权衡。讨论了部署视角，并总结了未来发展的挑战和方向。

<details>
  <summary>Details</summary>

**Motivation:** 论文旨在全面评价YOLO系列检测器的发展历程与技术创新，为学术和工业界的部署提供基准测试数据，并展望未来研究方向。

**Method:** 此论文通过回顾YOLO系列的目标检测器，着重于其架构演变、基准测试、部署视角及未来发展挑战。重点介绍了YOLO26版本中的关键创新，包括DFL的去除、原生无NMS推理、ProgLoss、STAL以及MuSGD优化器的引入，并逐步追溯到早期的YOLO版本，如YOLO11、YOLO8和YOLO5。

**Result:** 通过对MS COCO数据集的基准测试，本文展示了YOLOv5、YOLOv8、YOLO11和YOLO26以及其他检测器之间的详细定量比较，评估了精度和速度的权衡。

**Conclusion:** 未来的挑战包括处理密集场景、整合混合CNN-Transformer结构、实现开放词汇检测以及开发边缘感知训练方法。

**Abstract:** This paper presents a comprehensive overview of the Ultralytics YOLO(You Only
Look Once) family of object detectors, focusing the architectural evolution,
benchmarking, deployment perspectives, and future challenges. The review begins
with the most recent release, YOLO26 (YOLOv26), which introduces key
innovations including Distribution Focal Loss (DFL) removal, native NMS-free
inference, Progressive Loss Balancing (ProgLoss), Small-Target-Aware Label
Assignment (STAL), and the MuSGD optimizer for stable training. The progression
is then traced through YOLO11, with its hybrid task assignment and
efficiency-focused modules; YOLOv8, which advanced with a decoupled detection
head and anchor-free predictions; and YOLOv5, which established the modular
PyTorch foundation that enabled modern YOLO development. Benchmarking on the MS
COCO dataset provides a detailed quantitative comparison of YOLOv5, YOLOv8,
YOLO11, and YOLO26, alongside cross-comparisons with YOLOv12, YOLOv13, RT-DETR,
and DEIM. Metrics including precision, recall, F1 score, mean Average
Precision, and inference speed are analyzed to highlight trade-offs between
accuracy and efficiency. Deployment and application perspectives are further
discussed, covering export formats, quantization strategies, and real-world use
in robotics, agriculture, surveillance, and manufacturing. Finally, the paper
identifies challenges and future directions, including dense-scene limitations,
hybrid CNN-Transformer integration, open-vocabulary detection, and edge-aware
training approaches.

</details>


### [37] [TreeNet: Layered Decision Ensembles](https://arxiv.org/abs/2510.09654)
*Zeshan Khan*

Main category: cs.CV

> The paper presents TreeNet, a novel model for medical image analysis, demonstrating high performance and usability, especially under limited data conditions.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind the study is to address the challenges of limited data availability in medical image analysis, specifically for genstro institutional track abnormalities detection.

**Method:** TreeNet, a layered decision ensemble learning methodology that integrates features from neural networks, ensemble learning, and tree-based decision models, is proposed for medical image analysis.

**Result:** TreeNet achieved an F1-score of up to 0.85 with complete training data and 0.77 with 50% of the training data, and supported 32 frames per second which is suitable for real-time applications.

**Conclusion:** Evaluation of TreeNet shows it is efficient and usable in real-time applications, with notable performance and adaptability in the context of medical image analysis.

**Abstract:** Within the domain of medical image analysis, three distinct methodologies
have demonstrated commendable accuracy: Neural Networks, Decision Trees, and
Ensemble-Based Learning Algorithms, particularly in the specialized context of
genstro institutional track abnormalities detection. These approaches exhibit
efficacy in disease detection scenarios where a substantial volume of data is
available. However, the prevalent challenge in medical image analysis pertains
to limited data availability and data confidence. This paper introduces
TreeNet, a novel layered decision ensemble learning methodology tailored for
medical image analysis. Constructed by integrating pivotal features from neural
networks, ensemble learning, and tree-based decision models, TreeNet emerges as
a potent and adaptable model capable of delivering superior performance across
diverse and intricate machine learning tasks. Furthermore, its interpretability
and insightful decision-making process enhance its applicability in complex
medical scenarios. Evaluation of the proposed approach encompasses key metrics
including Accuracy, Precision, Recall, and training and evaluation time. The
methodology resulted in an F1-score of up to 0.85 when using the complete
training data, with an F1-score of 0.77 when utilizing 50\% of the training
data. This shows a reduction of F1-score of 0.08 while in the reduction of 50\%
of the training data and training time. The evaluation of the methodology
resulted in the 32 Frame per Second which is usable for the realtime
applications. This comprehensive assessment underscores the efficiency and
usability of TreeNet in the demanding landscape of medical image analysis
specially in the realtime analysis.

</details>


### [38] [OmniSAT: Compact Action Token, Faster Auto Regression](https://arxiv.org/abs/2510.09667)
*Huaihai Lyu,Chaofan Chen,Senwei Xie,Pengwei Wang,Xiansheng Chen,Shanghang Zhang,Changsheng Xu*

Main category: cs.CV

> The Omni Swift Action Tokenizer learns a compact, transferable action representation using B-Spline encoding and multi-stage residual quantization. This improves compression efficiency and reconstruction quality, leading to faster convergence and better performance in auto-regressive Vision-Language-Action models.

<details>
  <summary>Details</summary>

**Motivation:** The motivation was to address the issue of inefficient compression and poor reconstruction quality in prior work that tried to shorten sequences using entropy-guided and token-frequency techniques in auto-regressive models for Vision-Language-Action tasks.

**Method:** The paper introduces an Omni Swift Action Tokenizer that first normalizes value ranges and temporal horizons using B-Spline encoding, then applies multi-stage residual quantization to position, rotation, and gripper subspaces, producing compressed discrete tokens.

**Result:** The developed Omni Swift Action Tokenizer shortens the training sequence by 6.8x, lowers the target entropy, and demonstrates higher compression efficiency while maintaining reconstruction quality in real-robot and simulation experiments.

**Conclusion:** OmniSAT effectively shortens training sequences by 6.8x, lowers target entropy, and preserves reconstruction quality, accelerating AR training convergence and overall model performance in Vision-Language-Action tasks.

**Abstract:** Existing Vision-Language-Action (VLA) models can be broadly categorized into
diffusion-based and auto-regressive (AR) approaches: diffusion models capture
continuous action distributions but rely on computationally heavy iterative
denoising. In contrast, AR models enable efficient optimization and flexible
sequence construction, making them better suited for large-scale pretraining.
To further improve AR efficiency, particularly when action chunks induce
extended and high-dimensional sequences, prior work applies entropy-guided and
token-frequency techniques to shorten the sequence length. However, such
compression struggled with \textit{poor reconstruction or inefficient
compression}. Motivated by this, we introduce an Omni Swift Action Tokenizer,
which learns a compact, transferable action representation. Specifically, we
first normalize value ranges and temporal horizons to obtain a consistent
representation with B-Spline encoding. Then, we apply multi-stage residual
quantization to the position, rotation, and gripper subspaces, producing
compressed discrete tokens with coarse-to-fine granularity for each part. After
pre-training on the large-scale dataset Droid, the resulting discrete
tokenization shortens the training sequence by 6.8$\times$, and lowers the
target entropy. To further explore the potential of OmniSAT, we develop a
cross-embodiment learning strategy that builds on the unified action-pattern
space and jointly leverages robot and human demonstrations. It enables scalable
auxiliary supervision from heterogeneous egocentric videos. Across diverse
real-robot and simulation experiments, OmniSAT encompasses higher compression
while preserving reconstruction quality, enabling faster AR training
convergence and model performance.

</details>


### [39] [Knowledge-Aware Mamba for Joint Change Detection and Classification from MODIS Times Series](https://arxiv.org/abs/2510.09679)
*Zhengsen Xu,Yimin Zhu,Zack Dewis,Mabel Heffring,Motasem Alkayid,Saeid Taleghanidoozdoozan,Lincoln Linlin Xu*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Although change detection using MODIS time series is critical for
environmental monitoring, it is a highly challenging task due to key MODIS
difficulties, e.g., mixed pixels, spatial-spectral-temporal information
coupling effect, and background class heterogeneity. This paper presents a
novel knowledge-aware Mamba (KAMamba) for enhanced MODIS change detection, with
the following contributions. First, to leverage knowledge regarding class
transitions, we design a novel knowledge-driven transition-matrix-guided
approach, leading to a knowledge-aware transition loss (KAT-loss) that can
enhance detection accuracies. Second, to improve model constraints, a
multi-task learning approach is designed, where three losses, i.e., pre-change
classification loss (PreC-loss), post-change classification loss (PostC-loss),
and change detection loss (Chg-loss) are used for improve model learning.
Third, to disentangle information coupling in MODIS time series, novel
spatial-spectral-temporal Mamba (SSTMamba) modules are designed. Last, to
improve Mamba model efficiency and remove computational cost, a sparse and
deformable Mamba (SDMamba) backbone is used in SSTMamba. On the MODIS
time-series dataset for Saskatchewan, Canada, we evaluate the method on
land-cover change detection and LULC classification; results show about 1.5-6%
gains in average F1 for change detection over baselines, and about 2%
improvements in OA, AA, and Kappa for LULC classification.

</details>


### [40] [NNDM: NN_UNet Diffusion Model for Brain Tumor Segmentation](https://arxiv.org/abs/2510.09681)
*Sashank Makanaboyina*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Accurate detection and segmentation of brain tumors in magnetic resonance
imaging (MRI) are critical for effective diagnosis and treatment planning.
Despite advances in convolutional neural networks (CNNs) such as U-Net,
existing models often struggle with generalization, boundary precision, and
limited data diversity. To address these challenges, we propose NNDM (NN\_UNet
Diffusion Model)a hybrid framework that integrates the robust feature
extraction of NN-UNet with the generative capabilities of diffusion
probabilistic models. In our approach, the diffusion model progressively
refines the segmentation masks generated by NN-UNet by learning the residual
error distribution between predicted and ground-truth masks. This iterative
denoising process enables the model to correct fine structural inconsistencies
and enhance tumor boundary delineation. Experiments conducted on the BraTS 2021
datasets demonstrate that NNDM achieves superior performance compared to
conventional U-Net and transformer-based baselines, yielding improvements in
Dice coefficient and Hausdorff distance metrics. Moreover, the diffusion-guided
refinement enhances robustness across modalities and tumor subregions. The
proposed NNDM establishes a new direction for combining deterministic
segmentation networks with stochastic diffusion models, advancing the state of
the art in automated brain tumor analysis.

</details>


### [41] [Adaptive Fusion Network with Temporal-Ranked and Motion-Intensity Dynamic Images for Micro-expression Recognition](https://arxiv.org/abs/2510.09730)
*Thi Bich Phuong Man,Luu Tu Nguyen,Vu Tram Anh Khuong,Thanh Ha Le,Thi Duyen Ngo*

Main category: cs.CV

> A new method for recognizing micro-expressions, which are faint facial changes indicating true emotion, is introduced in this paper, achieving state-of-the-art performance by using a novel dynamic image representation and adaptive feature fusion.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this research is to enhance the methods for detecting micro-expressions (MEs), subtle facial changes that can reveal genuine emotions but are nearly impossible to detect on their own, making them valuable for applications such as lie detection and psychological assessment.

**Method:** Firstly, the paper introduces two new types of dynamic image representations: the Temporal-ranked dynamic image that focuses on the temporal progression of micro-expressions, and the Motion-intensity dynamic image that amplifies subtle movements by reordering frames based on motion intensity. Secondly, an Adaptive Fusion Network (AFN) is proposed to automatically integrate these two representations, which helps in extracting discriminative features of micro-expressions while minimizing noise.

**Result:** The results of the experiment, conducted on three primary datasets (CASME-II, SAMM, and MMEW), indicate that the proposed technique surpasses existing benchmarks. It particularly notes superior accuracy and F1 scores on various datasets, confirming the method's capability to detect MEs effectively.

**Conclusion:** The paper concludes that the proposed method significantly improves the state of the art in ME recognition, offering a highly effective way to detect MEs while demonstrating strong generalization across different datasets. The research provides a strong basis for future advancements in the field and practical applications, particularly within affective computing and lie detection.

**Abstract:** Micro-expressions (MEs) are subtle, transient facial changes with very low
intensity, almost imperceptible to the naked eye, yet they reveal a person
genuine emotion. They are of great value in lie detection, behavioral analysis,
and psychological assessment. This paper proposes a novel MER method with two
main contributions. First, we propose two complementary representations -
Temporal-ranked dynamic image, which emphasizes temporal progression, and
Motion-intensity dynamic image, which highlights subtle motions through a frame
reordering mechanism incorporating motion intensity. Second, we propose an
Adaptive fusion network, which automatically learns to optimally integrate
these two representations, thereby enhancing discriminative ME features while
suppressing noise. Experiments on three benchmark datasets (CASME-II, SAMM and
MMEW) demonstrate the superiority of the proposed method. Specifically, AFN
achieves 93.95 Accuracy and 0.897 UF1 on CASME-II, setting a new
state-of-the-art benchmark. On SAMM, the method attains 82.47 Accuracy and
0.665 UF1, demonstrating more balanced recognition across classes. On MMEW, the
model achieves 76.00 Accuracy, further confirming its generalization ability.
The obtained results show that both the input and the proposed architecture
play important roles in improving the performance of MER. Moreover, they
provide a solid foundation for further research and practical applications in
the fields of affective computing, lie detection, and human-computer
interaction.

</details>


### [42] [Multi Camera Connected Vision System with Multi View Analytics: A Comprehensive Survey](https://arxiv.org/abs/2510.09731)
*Muhammad Munsif,Waqas Ahmad,Amjid Ali,Mohib Ullah,Adnan Hussain,Sung Wook Baik*

Main category: cs.CV

> 本篇调查文章首次全面整合了多视角多摄像机（MVMC）跟踪、再识别（Re-ID）和行为理解（AU），提供了一个综合框架。

<details>
  <summary>Details</summary>

**Motivation:** 当前的调查文章主要集中在孤立的任务上，如跟踪、再识别和行为理解，而忽略了将这些任务整合为一个系统。这篇调查文章旨在填补这一空白，为未来研究提供指导。

**Method:** 提出一个独特的分类法，将连接视觉系统（CVS）分为四个关键部分：多视角多摄像机（MVMC）跟踪、再识别（Re-ID）、行为理解（AU）和结合方法。

**Result:** 系统地排列和总结了当前最先进的数据集、方法、结果和评估指标，并在复杂、现实世界应用中为CVS的稳健性、效率和适应性指出了未来研究方向。

**Conclusion:** 文章指出了开放的研究问题和挑战，包括终身学习、隐私和联邦学习等，并为下一代智能、自适应CVS的研究方向提供了启示。

**Abstract:** Connected Vision Systems (CVS) are transforming a variety of applications,
including autonomous vehicles, smart cities, surveillance, and human-robot
interaction. These systems harness multi-view multi-camera (MVMC) data to
provide enhanced situational awareness through the integration of MVMC
tracking, re-identification (Re-ID), and action understanding (AU). However,
deploying CVS in real-world, dynamic environments presents a number of
challenges, particularly in addressing occlusions, diverse viewpoints, and
environmental variability. Existing surveys have focused primarily on isolated
tasks such as tracking, Re-ID, and AU, often neglecting their integration into
a cohesive system. These reviews typically emphasize single-view setups,
overlooking the complexities and opportunities provided by multi-camera
collaboration and multi-view data analysis. To the best of our knowledge, this
survey is the first to offer a comprehensive and integrated review of MVMC that
unifies MVMC tracking, Re-ID, and AU into a single framework. We propose a
unique taxonomy to better understand the critical components of CVS, dividing
it into four key parts: MVMC tracking, Re-ID, AU, and combined methods. We
systematically arrange and summarize the state-of-the-art datasets,
methodologies, results, and evaluation metrics, providing a structured view of
the field's progression. Furthermore, we identify and discuss the open research
questions and challenges, along with emerging technologies such as lifelong
learning, privacy, and federated learning, that need to be addressed for future
advancements. The paper concludes by outlining key research directions for
enhancing the robustness, efficiency, and adaptability of CVS in complex,
real-world applications. We hope this survey will inspire innovative solutions
and guide future research toward the next generation of intelligent and
adaptive CVS.

</details>


### [43] [Constructive Distortion: Improving MLLMs with Attention-Guided Image Warping](https://arxiv.org/abs/2510.09741)
*Dwip Dalal,Gautam Vashishtha,Utkarsh Mishra,Jeonghwan Kim,Madhav Kanda,Hyeonjeong Ha,Svetlana Lazebnik,Heng Ji,Unnat Jain*

Main category: cs.CV

> AttWarp方法解决了MLLMs在处理复杂场景时的问题，通过跨模态注意力引导图像扭曲，提升模型准确性、组合推理和减少错误预测。

<details>
  <summary>Details</summary>

**Motivation:** MLLMs在混乱场景中常常遗漏细节和空间关系，导致精细化感知定位错误。因此，提出AttWarp以解决这些问题。

**Method:** AttWarp采用轻量级方法，通过跨模态注意力在测试时执行图像的矩形扭曲，增加与查询相关的内容的分辨率，压缩不太有用区域，但保留全局上下文。

**Result:** 在五个基准测试（TextVQA，GQA，DocVQA，POPE，MMMU）和四种MLLMs（LLaVA，Qwen-VL，InternVL，InstructBLIP）中，AttWarp提高准确度，增强组合推理并减少幻觉，超越四种对测试时原始图像进行操作的竞争基线。

**Conclusion:** 注意力引导的扭曲有助于突出与查询相关的区域，同时保留上下文信息，使得相同的MLLMs能够更好地处理这些扭曲输入，提高性能。

**Abstract:** Multimodal large language models (MLLMs) often miss small details and spatial
relations in cluttered scenes, leading to errors in fine-grained perceptual
grounding. We introduce AttWarp, a lightweight method that allocates more
resolution to query-relevant content while compressing less informative areas,
all while preserving global context. At test time, the approach uses an MLLM's
cross-modal attention to perform rectilinear warping of the input image,
reallocating spatial resolution toward regions the model deems important,
without changing model weights or architecture. This attention-guided warping
preserves all original image information but redistributes it non-uniformly, so
small objects and subtle relationships become easier for the same model to read
while the global layout remains intact. Across five benchmarks (TextVQA, GQA,
DocVQA, POPE, MMMU) and four MLLMs (LLaVA, Qwen-VL, InternVL, and
InstructBLIP), AttWarp consistently improves accuracy, strengthens
compositional reasoning, and reduces hallucinations, outperforming four
competitive baselines that manipulate raw images at test time. Together, these
results show that attention-guided warping prioritizes information relevant to
the query while preserving context, and that the same MLLMs perform better when
given such warped inputs.

</details>


### [44] [Towards Understanding Ambiguity Resolution in Multimodal Inference of Meaning](https://arxiv.org/abs/2510.09815)
*Yufei Wang,Adriana Kovashka,Loretta Fernández,Marc N. Coutanche,Seth Wiener*

Main category: cs.CV

> 我们研究了在一种新的设置下外语学习，该设置中学习者能够通过图文配对句子中的多模态语境推断陌生单词的意义。我们通过人类参与者研究发现了一些影响参与者推断能力的因素，其中包括数据特征及参与者语言背景。

<details>
  <summary>Details</summary>

**Motivation:** 我们的研究旨在探索一种新的外语学习设置，在这种设置中，学习者能够通过图文配对句子中的多模态语境推断陌生单词的意义。我们希望通过研究找出哪些特征会影响参与者对陌生单词进行推断的能力。

**Method:** 我们进行人类参与者研究，使用不同的图文配对，分析数据特征（即图像和文本）以及参与者语言背景，探讨这些因素如何影响参与者推断陌生单词意思的能力。

**Result:** 我们的研究发现有一些直观特征与参与者表现有较强的关联，但是提示我们需要进一步研究在这些任务中成功的预测特征。此外，我们还分析了AI系统在参与者表现上进行推理的能力，发现了一些未来改善方向。

**Conclusion:** 通过上述研究，我们认识到需要进一步研究成功的预测特征，并有机会改善AI系统在推断参与者表现上的能力。

**Abstract:** We investigate a new setting for foreign language learning, where learners
infer the meaning of unfamiliar words in a multimodal context of a sentence
describing a paired image. We conduct studies with human participants using
different image-text pairs. We analyze the features of the data (i.e., images
and texts) that make it easier for participants to infer the meaning of a
masked or unfamiliar word, and what language backgrounds of the participants
correlate with success. We find only some intuitive features have strong
correlations with participant performance, prompting the need for further
investigating of predictive features for success in these tasks. We also
analyze the ability of AI systems to reason about participant performance, and
discover promising future directions for improving this reasoning ability.

</details>


### [45] [Task-Aware Resolution Optimization for Visual Large Language Models](https://arxiv.org/abs/2510.09822)
*Weiqing Luo,Zhen Tan,Yifan Li,Xinyu Zhao,Kwonjoon Lee,Behzad Dariush,Tianlong Chen*

Main category: cs.CV

> The paper investigates the impact of image resolution on vision-language tasks and proposes a formula and a fine-tuning technique to improve VLLMs performance by adjusting resolution inputs.

<details>
  <summary>Details</summary>

**Motivation:** Most existing visual large language models (VLLMs) pre-assume a fixed resolution for tasks, which can lead to subpar performance. This paper aims to address this issue by identifying the optimal resolution for different tasks.

**Method:** We conduct a comprehensive investigation into resolution preferences for vision-language tasks and propose an empirical formula to determine the optimal resolution, combining image complexity and uncertainty variance. We also propose a novel parameter-efficient fine-tuning technique to extend the visual input resolution to the optimal level.

**Result:** Experiments on various vision-language tasks confirm the effectiveness of the proposed method in improving the performance of VLLMs.

**Conclusion:** The research provides a method to adapt the resolution input to the optimal setting for vision-language tasks, enhancing the performance of existing VLLMs.

**Abstract:** Real-world vision-language applications demand varying levels of perceptual
granularity. However, most existing visual large language models (VLLMs), such
as LLaVA, pre-assume a fixed resolution for downstream tasks, which leads to
subpar performance. To address this problem, we first conduct a comprehensive
and pioneering investigation into the resolution preferences of different
vision-language tasks, revealing a correlation between resolution preferences
with image complexity, and uncertainty variance of the VLLM at different image
input resolutions. Building on this insight, we propose an empirical formula to
determine the optimal resolution for a given vision-language task, combining
these two factors. Second, based on rigorous experiments, we propose a novel
parameter-efficient fine-tuning technique to extend the visual input resolution
of pre-trained VLLMs to the identified optimal resolution. Extensive
experiments on various vision-language tasks validate the effectiveness of our
method.

</details>


### [46] [Post Processing of image segmentation using Conditional Random Fields](https://arxiv.org/abs/2510.09833)
*Aashish Dhawan,Pankaj Bodani,Vishal Garg*

Main category: cs.CV

> 本研究通过实验各种条件随机场(CRF)，找出提高低质量卫星图像分割清晰度的最佳方法，并在两个数据集上验证了其效果。

<details>
  <summary>Details</summary>

**Motivation:** 由于卫星图像的质量较低，导致分割图像的质量通常不高。本研究旨在寻找一种合适的条件随机场(CRF)来提高分割图像的清晰度。

**Method:** 本研究尝试了不同类型的条件随机场(CRF)，以找到最适合提高卫星图像分割清晰度的模型。

**Result:** 研究中，在两种不同的数据集（低质量特征的卫星图像和高质量的航拍照片）上对多个CRF进行了实验，并对其结果进行了比较，展示了不同方法的优缺点。

**Conclusion:** 本研究不仅评估了几种条件随机场（CRF）在低质量卫星图像和高质量航拍图像上的效果，还对比了不同方法的潜力和劣势，为选择最佳分割方法提供了依据。

**Abstract:** The output of image the segmentation process is usually not very clear due to
low quality features of Satellite images. The purpose of this study is to find
a suitable Conditional Random Field (CRF) to achieve better clarity in a
segmented image. We started with different types of CRFs and studied them as to
why they are or are not suitable for our purpose. We evaluated our approach on
two different datasets - Satellite imagery having low quality features and high
quality Aerial photographs. During the study we experimented with various CRFs
to find which CRF gives the best results on images and compared our results on
these datasets to show the pitfalls and potentials of different approaches.

</details>


### [47] [Exploration of Incremental Synthetic Non-Morphed Images for Single Morphing Attack Detection](https://arxiv.org/abs/2510.09836)
*David Benavente-Rios,Juan Ruiz Rodriguez,Gustavo Gatica*

Main category: cs.CV

> The study finds that using a controlled amount of synthetic images can boost S-MAD effectiveness, but overuse leads to poor performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the lack of large-scale datasets due to privacy concerns by using synthetic face data.

**Method:** This paper uses synthetic face data to enhance S-MAD, using various morphing tools and cross-dataset evaluation schemes.

**Result:** The results show that carefully adding synthetic images can improve generalization, but indiscriminate use can harm performance.

**Conclusion:** In operational scenarios, relying only on synthetic data for S-MAD is not the best option.

**Abstract:** This paper investigates the use of synthetic face data to enhance
Single-Morphing Attack Detection (S-MAD), addressing the limitations of
availability of large-scale datasets of bona fide images due to privacy
concerns. Various morphing tools and cross-dataset evaluation schemes were
utilized to conduct this study. An incremental testing protocol was implemented
to assess the generalization capabilities as more and more synthetic images
were added. The results of the experiments show that generalization can be
improved by carefully incorporating a controlled number of synthetic images
into existing datasets or by gradually adding bona fide images during training.
However, indiscriminate use of synthetic data can lead to sub-optimal
performance. Evenmore, the use of only synthetic data (morphed and non-morphed
images) achieves the highest Equal Error Rate (EER), which means in operational
scenarios the best option is not relying only on synthetic data for S-MAD.

</details>


### [48] [Cell Instance Segmentation: The Devil Is in the Boundaries](https://arxiv.org/abs/2510.09848)
*Peixian Liang,Yifan Ding,Yizhe Zhang,Jianxu Chen,Hao Zheng,Hongxiao Wang,Yejia Zhang,Guangyu Meng,Tim Weninger,Michael Niemier,X. Sharon Hu,Danny Z Chen*

Main category: cs.CV

> A new pixel clustering method named Ceb uses cell boundary features and labels to enhance cell instance segmentation, showing superior performance compared to existing methods on multiple datasets.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this method is to overcome the limitation of pixel-wise approaches in deep learning cell instance segmentation, which can lead to loss of significant geometric properties like shape, curvature, and convexity of cell instances.

**Method:** The paper introduces a novel pixel clustering method named Ceb that uses cell boundary features and labels to segment cell instances from foreground pixels. It starts with probability maps from semantic segmentation and applies a modified Watershed algorithm to find potential foreground-foreground boundaries. Boundary signatures are created by sampling current and neighboring boundary pixels. A boundary classifier then determines boundary labels using these signatures, and the final cell instances are defined by dividing or merging regions based on the labels.

**Result:** Experimental results on six datasets show Ceb's superiority over existing pixel clustering methods when working with semantic segmentation probability maps. Additionally, it achieves competitive performance when compared to state-of-the-art cell instance segmentation techniques.

**Conclusion:** The research concluded that leveraging cell boundary features through the proposed method Ceb can significantly improve cell instance segmentation performance and is competitive with current state-of-the-art methods.

**Abstract:** State-of-the-art (SOTA) methods for cell instance segmentation are based on
deep learning (DL) semantic segmentation approaches, focusing on distinguishing
foreground pixels from background pixels. In order to identify cell instances
from foreground pixels (e.g., pixel clustering), most methods decompose
instance information into pixel-wise objectives, such as distances to
foreground-background boundaries (distance maps), heat gradients with the
center point as heat source (heat diffusion maps), and distances from the
center point to foreground-background boundaries with fixed angles (star-shaped
polygons). However, pixel-wise objectives may lose significant geometric
properties of the cell instances, such as shape, curvature, and convexity,
which require a collection of pixels to represent. To address this challenge,
we present a novel pixel clustering method, called Ceb (for Cell boundaries),
to leverage cell boundary features and labels to divide foreground pixels into
cell instances. Starting with probability maps generated from semantic
segmentation, Ceb first extracts potential foreground-foreground boundaries
with a revised Watershed algorithm. For each boundary candidate, a boundary
feature representation (called boundary signature) is constructed by sampling
pixels from the current foreground-foreground boundary as well as the
neighboring background-foreground boundaries. Next, a boundary classifier is
used to predict its binary boundary label based on the corresponding boundary
signature. Finally, cell instances are obtained by dividing or merging
neighboring regions based on the predicted boundary labels. Extensive
experiments on six datasets demonstrate that Ceb outperforms existing pixel
clustering methods on semantic segmentation probability maps. Moreover, Ceb
achieves highly competitive performance compared to SOTA cell instance
segmentation methods.

</details>


### [49] [Cluster-Aware Prompt Ensemble Learning for Few-Shot Vision-Language Model Adaptation](https://arxiv.org/abs/2510.09867)
*Zhi Chen,Xin Yu,Xiaohui Tao,Yan Li,Zi Huang*

Main category: cs.CV

> 提出CAPEL框架，改进视觉语言模型中的提示集成方法，提高模型在多种任务中的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于提示集成的方法往往因为特征平均而产生次优结果，这导致类别质心偏离真实的类别分布。

**Method:** 提出了Cluster-Aware Prompt Ensemble Learning (CAPEL)框架，该框架在分类预测值空间而非特征空间中进行集成，并引入群集保持正则化项和自适应提示权重技术。

**Result:** 

**Conclusion:** 通过引入群集保持正则化项和自适应提示权重技术，CAPEL框架在保持集群特定判别能力的同时，提高了提示微调的性能，从而实现了在不同数据集和任务上的鲁棒性能。

**Abstract:** Vision-language models (VLMs) such as CLIP achieve zero-shot transfer across
various tasks by pre-training on numerous image-text pairs. These models often
benefit from using an ensemble of context prompts to represent a class. Despite
being effective, conventional prompt ensembling that averages textual features
of context prompts often yields suboptimal results. This is because feature
averaging shifts the class centroids away from the true class distribution. To
address this issue, we propose the Cluster-Aware Prompt Ensemble Learning
(CAPEL) framework, which preserves the cluster nature of context prompts. CAPEL
classifies images into one of several class clusters, each represented by a
distinct prompt. Instead of ensembling prompts in the feature space, we perform
ensembling in the classification logits space, aligning better with the visual
feature distribution. To further optimize prompt fine-tuning while maintaining
cluster-specific discriminative power, we introduce a cluster-preserving
regularization term. This ensures that prompts remain distinct and specialized
for different clusters, preventing collapse into a uniform direction.
Additionally, we integrate an adaptive prompt weighting technique to
dynamically adjust the attention weights for flawed or ambiguous prompts,
ensuring robust performance across diverse datasets and tasks.

</details>


### [50] [Fast Self-Supervised depth and mask aware Association for Multi-Object Tracking](https://arxiv.org/abs/2510.09878)
*Milad Khanchi,Maria Amer,Charalambos Poullis*

Main category: cs.CV

> 提出了一种新的多目标跟踪方法，该方法通过融合深度和分割掩码特征，并使用自监督编码器生成稳定物体表示，用于改进目标跟踪，特别适用于存在遮挡和复杂运动的情况。

<details>
  <summary>Details</summary>

**Motivation:** 多目标跟踪(MOT)方法通常依赖于Intersection-over-Union(IoU)进行关联，然而，当目标相似或被遮挡时，这种方法变得不可靠。同时，计算分割掩码的IoU计算成本高昂。

**Method:** 使用分割掩码捕捉物体形状，但不计算分割IoU。而是融合深度和掩码特征，并通过一个紧凑的、自我监督训练的编码器进行处理。该编码器生成稳定的物体表示，我们将其作为额外的相似性线索，与边界框IoU和再识别特征结合用于匹配。使用零样本深度估计器获得深度图，并使用可提示的视觉分割模型获得对象掩码以获得精细的空间线索。

**Result:** 在具有非线性运动、遮挡和拥挤场景的具有挑战性的基准测试（如SportsMOT和DanceTrack）中，我们的TBD方法在大多数指标上优于TBD的最先进方法，同时在具有线性运动的简单基准测试（如MOT17）上实现了具有竞争力的表现。

**Conclusion:** 我们的MOT方法是首次使用自监督编码器，通过融合深度和掩码特征而不计算掩码IoU来细化分割掩码的技术，提高了多目标跟踪的鲁棒性和效率。

**Abstract:** Multi-object tracking (MOT) methods often rely on Intersection-over-Union
(IoU) for association. However, this becomes unreliable when objects are
similar or occluded. Also, computing IoU for segmentation masks is
computationally expensive. In this work, we use segmentation masks to capture
object shapes, but we do not compute segmentation IoU. Instead, we fuse depth
and mask features and pass them through a compact encoder trained
self-supervised. This encoder produces stable object representations, which we
use as an additional similarity cue alongside bounding box IoU and
re-identification features for matching. We obtain depth maps from a zero-shot
depth estimator and object masks from a promptable visual segmentation model to
obtain fine-grained spatial cues. Our MOT method is the first to use the
self-supervised encoder to refine segmentation masks without computing masks
IoU. MOT can be divided into joint detection-ReID (JDR) and
tracking-by-detection (TBD) models. The latter are computationally more
efficient. Experiments of our TBD method on challenging benchmarks with
non-linear motion, occlusion, and crowded scenes, such as SportsMOT and
DanceTrack, show that our method outperforms the TBD state-of-the-art on most
metrics, while achieving competitive performance on simpler benchmarks with
linear motion, such as MOT17.

</details>


### [51] [CHUG: Crowdsourced User-Generated HDR Video Quality Dataset](https://arxiv.org/abs/2510.09879)
*Shreshth Saini,Alan C. Bovik,Neil Birkbeck,Yilin Wang,Balu Adsumilli*

Main category: cs.CV

> 论文提出了CHUG数据集，一个针对用户生成HDR视频质量的大规模主观研究数据集，以填补现有数据集中针对这类视频评估的空白。

<details>
  <summary>Details</summary>

**Motivation:** 用户生成内容（UGC）平台上的HDR视频由于不同的拍摄条件、编辑伪影和压缩失真带来了独特的质量评估挑战，而现有的HDR视频质量评估数据集主要针对专业内容，缺乏针对用户生成HDR视频降级的理解，这是引入CHUG的主要动机。

**Method:** 为了研究用户生成HDR视频的质量，研究人员创建了CHUG数据集，该数据集通过对856个用户生成的HDR源视频进行不同程度的转码来生成，总共产生了5,992个视频样本，通过亚马逊Mechanical Turk平台进行了主观评估，收集了211,848个感知评分。

**Result:** 该论文介绍了CHUG数据集，这是一个大规模的主观研究数据集，专门针对用户生成的高动态范围（HDR）视频质量评估（VQA）。CHUG包含856个用户生成的HDR源视频，经过不同分辨率和比特率的转码以模拟现实情况，总共产生5,992个视频。通过亚马逊Mechanical Turk收集了211,848个感知评分。CHUG数据集旨在填补现有HDR-VQA数据集中用户生成内容的空白，为无参考（NR）HDR视频质量评估研究提供了基准。

**Conclusion:** CHUG数据集的目标是为无参考（NR）HDR视频质量评估研究提供一个大型、多样和真实的用户生成内容基准。数据集的公共访问地址是https://shreshthsaini.github.io/CHUG/。

**Abstract:** High Dynamic Range (HDR) videos enhance visual experiences with superior
brightness, contrast, and color depth. The surge of User-Generated Content
(UGC) on platforms like YouTube and TikTok introduces unique challenges for HDR
video quality assessment (VQA) due to diverse capture conditions, editing
artifacts, and compression distortions. Existing HDR-VQA datasets primarily
focus on professionally generated content (PGC), leaving a gap in understanding
real-world UGC-HDR degradations. To address this, we introduce CHUG:
Crowdsourced User-Generated HDR Video Quality Dataset, the first large-scale
subjective study on UGC-HDR quality. CHUG comprises 856 UGC-HDR source videos,
transcoded across multiple resolutions and bitrates to simulate real-world
scenarios, totaling 5,992 videos. A large-scale study via Amazon Mechanical
Turk collected 211,848 perceptual ratings. CHUG provides a benchmark for
analyzing UGC-specific distortions in HDR videos. We anticipate CHUG will
advance No-Reference (NR) HDR-VQA research by offering a large-scale, diverse,
and real-world UGC dataset. The dataset is publicly available at:
https://shreshthsaini.github.io/CHUG/.

</details>


### [52] [Geometry-Aware Scene Configurations for Novel View Synthesis](https://arxiv.org/abs/2510.09880)
*Minkwan Kim,Changwoon Choi,Young Min Kim*

Main category: cs.CV

> This paper introduces scene-adaptive strategies to maximize the use of limited resources for generating immersive indoor scenes from incomplete observations, showing significant improvements over previous methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to optimize the representation capacity for complex and irregular indoor scenes with varying complexity, clutter, and occlusion, by maximizing the utilization of limited resources.

**Method:** We use scene-adaptive strategies for efficient resource allocation in generating immersive indoor environment experiences based on incomplete data. It focuses on utilizing geometric priors to guide the optimal placement of bases and proposes adaptive virtual viewpoints to address geometric deficiencies in the input trajectory.

**Result:** Comprehensive analysis and discussion on rendering quality and memory requirements in large-scale indoor scenes show significant enhancements over baselines with regular placements.

**Conclusion:** Scene-adaptive strategies effectively allocate resources for generating immersive indoor experiences, improving upon uniform basis arrangements used in previous scalable Neural Radiance Field (NeRF) representations.

**Abstract:** We propose scene-adaptive strategies to efficiently allocate representation
capacity for generating immersive experiences of indoor environments from
incomplete observations. Indoor scenes with multiple rooms often exhibit
irregular layouts with varying complexity, containing clutter, occlusion, and
flat walls. We maximize the utilization of limited resources with guidance from
geometric priors, which are often readily available after pre-processing
stages. We record observation statistics on the estimated geometric scaffold
and guide the optimal placement of bases, which greatly improves upon the
uniform basis arrangements adopted by previous scalable Neural Radiance Field
(NeRF) representations. We also suggest scene-adaptive virtual viewpoints to
compensate for geometric deficiencies inherent in view configurations in the
input trajectory and impose the necessary regularization. We present a
comprehensive analysis and discussion regarding rendering quality and memory
requirements in several large-scale indoor scenes, demonstrating significant
enhancements compared to baselines that employ regular placements.

</details>


### [53] [LTGS: Long-Term Gaussian Scene Chronology From Sparse View Updates](https://arxiv.org/abs/2510.09881)
*Minkwan Kim,Seungmin Lee,Junho Kim,Young Min Kim*

Main category: cs.CV

> 提出一种高效场景表示LTGS，利用稀疏视图更新长期高斯场景编年史，即使在频繁场景变化下也能高精度地重建3D环境，且更新轻快。

<details>
  <summary>Details</summary>

**Motivation:** 当前的新型视图合成技术面临从日常拍摄中获取真实世界环境的挑战，由于场景变化频繁，需要在空间和时间上密集的观察。

**Method:** 通过从稀疏视图更新中长期内高斯场景编年史（LTGS），该方法能够从不完整的高斯点阵表征中重建长期的场景演变，尽管存在突然的移动和微妙的环境变化。方法包括构建对象的模板高斯，并对其进行进一步的细化以适应短时间内少量观测的变化。

**Result:** 实验表明，该框架在重建质量上优于其他基线，同时实现了快速和轻量级的更新。

**Conclusion:** 该框架在处理时间演变的3D环境时具有较强的可扩展性，适用于真实世界中的长期变化。

**Abstract:** Recent advances in novel-view synthesis can create the photo-realistic
visualization of real-world environments from conventional camera captures.
However, acquiring everyday environments from casual captures faces challenges
due to frequent scene changes, which require dense observations both spatially
and temporally. We propose long-term Gaussian scene chronology from sparse-view
updates, coined LTGS, an efficient scene representation that can embrace
everyday changes from highly under-constrained casual captures. Given an
incomplete and unstructured Gaussian splatting representation obtained from an
initial set of input images, we robustly model the long-term chronology of the
scene despite abrupt movements and subtle environmental variations. We
construct objects as template Gaussians, which serve as structural, reusable
priors for shared object tracks. Then, the object templates undergo a further
refinement pipeline that modulates the priors to adapt to temporally varying
environments based on few-shot observations. Once trained, our framework is
generalizable across multiple time steps through simple transformations,
significantly enhancing the scalability for a temporal evolution of 3D
environments. As existing datasets do not explicitly represent the long-term
real-world changes with a sparse capture setup, we collect real-world datasets
to evaluate the practicality of our pipeline. Experiments demonstrate that our
framework achieves superior reconstruction quality compared to other baselines
while enabling fast and light-weight updates.

</details>


### [54] [An uncertainty-aware framework for data-efficient multi-view animal pose estimation](https://arxiv.org/abs/2510.09903)
*Lenny Aharon,Keemin Lee,Karan Sikka,Selmaan Chettih,Cole Hurwitz,Liam Paninski,Matthew R Whiteway*

Main category: cs.CV

> 提出了一种综合框架和改进的多视角Transformer模型，以解决多视角姿态估计的准确性和不确定性估计问题，特别适用于动物行为研究。

<details>
  <summary>Details</summary>

**Motivation:** 多视角姿态估计在动物行为科学研究中有重要应用，但目前的方法在利用有限的标注数据进行准确跟踪方面存在困难，并且在不确定性估计方面也存在问题。

**Method:** 本文提出了一种结合新颖训练和后处理技术的综合框架，并设计了模型蒸馏过程以提高多视角姿态估计的准确性和不确定性估计。该框架采用了多视角Transformer（MVT）模型，能够同时处理所有视角的信息，并引入了一种新的Patch Masking方案来学习稳健的跨视角对应关系。对于校准的设置，通过3D增强和三角测量损失函数进行几何一致性学习。此外，扩展了Ensemble Kalman Smoother（EKS）后处理器到非线性情况，并通过方差膨胀技术增强不确定性量化。最后，设计了一种蒸馏过程以利用改进后的EKS预测和不确定性估计生成高质量的伪标签，减少对手动标签的依赖。

**Result:** 该框架在三种不同的动物物种上采用了分层架构，并显示出各个组件的互补优势，实现了不确定性感知的系统在实际数据约束下的可靠姿态估计。

**Conclusion:** 本文所提出的框架在三种不同的动物物种（苍蝇、老鼠、山雀）上的一致性表现优于现有方法，实现了在实际数据约束下的可靠姿态估计。

**Abstract:** Multi-view pose estimation is essential for quantifying animal behavior in
scientific research, yet current methods struggle to achieve accurate tracking
with limited labeled data and suffer from poor uncertainty estimates. We
address these challenges with a comprehensive framework combining novel
training and post-processing techniques, and a model distillation procedure
that leverages the strengths of these techniques to produce a more efficient
and effective pose estimator. Our multi-view transformer (MVT) utilizes
pretrained backbones and enables simultaneous processing of information across
all views, while a novel patch masking scheme learns robust cross-view
correspondences without camera calibration. For calibrated setups, we
incorporate geometric consistency through 3D augmentation and a triangulation
loss. We extend the existing Ensemble Kalman Smoother (EKS) post-processor to
the nonlinear case and enhance uncertainty quantification via a variance
inflation technique. Finally, to leverage the scaling properties of the MVT, we
design a distillation procedure that exploits improved EKS predictions and
uncertainty estimates to generate high-quality pseudo-labels, thereby reducing
dependence on manual labels. Our framework components consistently outperform
existing methods across three diverse animal species (flies, mice, chickadees),
with each component contributing complementary benefits. The result is a
practical, uncertainty-aware system for reliable pose estimation that enables
downstream behavioral analyses under real-world data constraints.

</details>


### [55] [SpectralCA: Bi-Directional Cross-Attention for Next-Generation UAV Hyperspectral Vision](https://arxiv.org/abs/2510.09912)
*D. V. Brovko*

Main category: cs.CV

> This study integrates hyperspectral imaging into UAV-based computer vision using a deep learning approach. A modified Mobile 3D Vision Transformer (MDvT) with a SpectralCA block is designed to enhance real-time navigation, object detection, and environmental monitoring.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind the study is to address the limitations of conventional UAV navigation in complex scenarios. In particular, the unreliable performance attributed to interference, poor visibility, or camouflage. The unique advantages offered by hyperspectral imaging (HSI), such as the ability to recognize materials and differentiate objects at a fine-grained level, make it a valuable asset for enhancing UAV-based computer vision systems.

**Method:** The research employs deep learning to integrate hyperspectral imaging (HSI) for UAV perception tasks such as navigation, object detection, and terrain classification. Specifically, a hybrid 2D/3D convolutional architecture is designed with spectral-spatial cross-attention. The study modifies the Mobile 3D Vision Transformer (MDvT) with a proposed SpectralCA block to merge spectral and spatial features, thereby improving accuracy and efficiency in real-time UAV operations.

**Result:** Experiments on the WHU-Hi-HongHu dataset demonstrated that the proposed architecture, incorporating the SpectralCA block, enhances UAV perception accuracy and real-time performance in tasks like navigation, object recognition, and environmental monitoring. The evaluation used Overall Accuracy, Average Accuracy, and the Kappa coefficient as metrics, affirming improved UAV perception efficiency.

**Conclusion:** The research concludes that the proposed deep learning model, with its spectral-spatial cross-attention mechanism, successfully improves UAV perception for realistic applications such as navigation and object recognition. This allows UAVs to operate more reliably in complex and challenging environments, furthering their capabilities in computer vision tasks.

**Abstract:** The relevance of this research lies in the growing demand for unmanned aerial
vehicles (UAVs) capable of operating reliably in complex environments where
conventional navigation becomes unreliable due to interference, poor
visibility, or camouflage. Hyperspectral imaging (HSI) provides unique
opportunities for UAV-based computer vision by enabling fine-grained material
recognition and object differentiation, which are critical for navigation,
surveillance, agriculture, and environmental monitoring. The aim of this work
is to develop a deep learning architecture integrating HSI into UAV perception
for navigation, object detection, and terrain classification. Objectives
include: reviewing existing HSI methods, designing a hybrid 2D/3D convolutional
architecture with spectral-spatial cross-attention, training, and benchmarking.
The methodology is based on the modification of the Mobile 3D Vision
Transformer (MDvT) by introducing the proposed SpectralCA block. This block
employs bi-directional cross-attention to fuse spectral and spatial features,
enhancing accuracy while reducing parameters and inference time. Experimental
evaluation was conducted on the WHU-Hi-HongHu dataset, with results assessed
using Overall Accuracy, Average Accuracy, and the Kappa coefficient. The
findings confirm that the proposed architecture improves UAV perception
efficiency, enabling real-time operation for navigation, object recognition,
and environmental monitoring tasks.
  Keywords: SpectralCA, deep learning, computer vision, hyperspectral imaging,
unmanned aerial vehicle, object detection, semi-supervised learning.

</details>


### [56] [HeadsUp! High-Fidelity Portrait Image Super-Resolution](https://arxiv.org/abs/2510.09924)
*Renjie Li,Zihao Zhu,Xiaoyu Wang,Zhengzhong Tu*

Main category: cs.CV

> 本研究提出HeadsUp模型，解决现有超分辨率技术在处理包含面部的肖像图像时的局限性，通过面部监督机制和基于参考的机制实现了高保真的面部和背景超分辨率恢复。

<details>
  <summary>Details</summary>

**Motivation:** 现有的图像超分辨率技术通常集中在通用的真实世界图像或严格对齐的面部图像上。使用专用模型来处理肖像照片会带来混合或边界伪影，尤其是在面部区域。为了克服这些问题，我们研究了肖像图像超分辨率问题。

**Method:** 我们提出了HeadsUp，这是一种一步完成的扩散模型，能够无缝恢复和放大肖像图像。该模型利用面部监督机制专注于面部区域，并集成了基于参考的机制来帮助恢复身份，减少面部恢复中的模糊性。

**Result:** 通过广泛的实验表明，HeadsUp在肖像图像超分辨率任务中取得了最先进的性能，同时也与其他通用图像和对齐面部数据集相比保持了相当或更高的性能。

**Conclusion:** 我们的提案，HeadsUp，证明了其有效性和创新性，可以在不牺牲面部细节的情况下完成高品质的肖像图像超分辨率。

**Abstract:** Portrait pictures, which typically feature both human subjects and natural
backgrounds, are one of the most prevalent forms of photography on social
media. Existing image super-resolution (ISR) techniques generally focus either
on generic real-world images or strictly aligned facial images (i.e., face
super-resolution). In practice, separate models are blended to handle portrait
photos: the face specialist model handles the face region, and the general
model processes the rest. However, these blending approaches inevitably
introduce blending or boundary artifacts around the facial regions due to
different model training recipes, while human perception is particularly
sensitive to facial fidelity. To overcome these limitations, we study the
portrait image supersolution (PortraitISR) problem, and propose HeadsUp, a
single-step diffusion model that is capable of seamlessly restoring and
upscaling portrait images in an end-to-end manner. Specifically, we build our
model on top of a single-step diffusion model and develop a face supervision
mechanism to guide the model in focusing on the facial region. We then
integrate a reference-based mechanism to help with identity restoration,
reducing face ambiguity in low-quality face restoration. Additionally, we have
built a high-quality 4K portrait image ISR dataset dubbed PortraitSR-4K, to
support model training and benchmarking for portrait images. Extensive
experiments show that HeadsUp achieves state-of-the-art performance on the
PortraitISR task while maintaining comparable or higher performance on both
general image and aligned face datasets.

</details>


### [57] [Denoising Diffusion as a New Framework for Underwater Images](https://arxiv.org/abs/2510.09934)
*Nilesh Jain,Elie Alhajjar*

Main category: cs.CV

> 本研究针对水下图像质量问题，提出使用去噪扩散模型扩展数据集，并结合Controlnet改进图像质量，以此来改善对海洋生态系统的理解。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于水下图像在海洋研究中的重要性，以及现有图像面临的质量问题，本研究旨在提出有效的解决方案，以提高图像质量和多样性，更好地研究海洋生态系统。

**Method:** 本研究提出两方面的策略来克服现有数据集的限制：首先，通过使用去噪扩散模型来扩展数据集，包括立体、广角、宏及特写等多种类型的图像；其次，利用Controlnet增强图像质量，从而提高对应数据集的质量，改善对海洋生态系统的研究。

**Result:** 本研究将通过数据集扩展和图像增强两种方法，有望提高水下图像的数据多样性和质量，进而提升对海洋生态系统的理解与研究能力。

**Conclusion:** 研究提出的新方法可以克服现有水下图像数据集的局限性，提高图像质量与多样性，从而促进海洋生态系统的更深入研究。

**Abstract:** Underwater images play a crucial role in ocean research and marine
environmental monitoring since they provide quality information about the
ecosystem. However, the complex and remote nature of the environment results in
poor image quality with issues such as low visibility, blurry textures, color
distortion, and noise. In recent years, research in image enhancement has
proven to be effective but also presents its own limitations, like poor
generalization and heavy reliance on clean datasets. One of the challenges
herein is the lack of diversity and the low quality of images included in these
datasets. Also, most existing datasets consist only of monocular images, a fact
that limits the representation of different lighting conditions and angles. In
this paper, we propose a new plan of action to overcome these limitations. On
one hand, we call for expanding the datasets using a denoising diffusion model
to include a variety of image types such as stereo, wide-angled, macro, and
close-up images. On the other hand, we recommend enhancing the images using
Controlnet to evaluate and increase the quality of the corresponding datasets,
and hence improve the study of the marine ecosystem.
  Tags - Underwater Images, Denoising Diffusion, Marine ecosystem, Controlnet

</details>


### [58] [Semi-disentangled spatiotemporal implicit neural representations of longitudinal neuroimaging data for trajectory classification](https://arxiv.org/abs/2510.09936)
*Agampreet Aulakh,Nils D. Forkert,Matthias Wilms*

Main category: cs.CV

> 提出了一种基于隐式神经表示（INR）的新方法来分析纵向MRI数据，用于建模和分类大脑衰老轨迹，在不规则采样实验中表现出较高的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 由于纵向MRI和其他神经影像数据的离散性质以及不同个体间空间和时间采样模式的差异，这些数据的分析对于大多数传统的深度学习方法来说是高度具有挑战性的，因为这些方法无法表示潜在的连续生物过程。

**Method:** 本研究提出了一种新的基于隐式神经表示（INRs）的方法来表示个体的纵向T1加权MRI数据作为连续函数，可以部分解耦空间和时间参数，以此来建模整个大脑的衰老轨迹。此外，研究还设计了一个可以在INRs参数空间上直接操作的高效框架，用于分类大脑衰老轨迹。

**Result:** 在更为现实的不规则采样实验中，基于INR的方法对于大脑衰老轨迹分类任务的准确率达到81.3%，优于标准深度学习基线模型（73.7%）。

**Conclusion:** 该研究展现了基于隐式神经表示网络的方法在处理大脑纵向MRI数据和分析病理相关的结构变化中的潜力和有效性。

**Abstract:** The human brain undergoes dynamic, potentially pathology-driven, structural
changes throughout a lifespan. Longitudinal Magnetic Resonance Imaging (MRI)
and other neuroimaging data are valuable for characterizing trajectories of
change associated with typical and atypical aging. However, the analysis of
such data is highly challenging given their discrete nature with different
spatial and temporal image sampling patterns within individuals and across
populations. This leads to computational problems for most traditional deep
learning methods that cannot represent the underlying continuous biological
process. To address these limitations, we present a new, fully data-driven
method for representing aging trajectories across the entire brain by modelling
subject-specific longitudinal T1-weighted MRI data as continuous functions
using Implicit Neural Representations (INRs). Therefore, we introduce a novel
INR architecture capable of partially disentangling spatial and temporal
trajectory parameters and design an efficient framework that directly operates
on the INRs' parameter space to classify brain aging trajectories. To evaluate
our method in a controlled data environment, we develop a biologically grounded
trajectory simulation and generate T1-weighted 3D MRI data for 450 healthy and
dementia-like subjects at regularly and irregularly sampled timepoints. In the
more realistic irregular sampling experiment, our INR-based method achieves
81.3% accuracy for the brain aging trajectory classification task,
outperforming a standard deep learning baseline model (73.7%).

</details>


### [59] [Explainable Human-in-the-Loop Segmentation via Critic Feedback Signals](https://arxiv.org/abs/2510.09945)
*Pouya Shaeri,Ryan T. Woo,Yasaman Mohammadpour,Ariane Middel*

Main category: cs.CV

> 提出一种人机交互框架，通过人类修正干预来改进图像分割模型，提高其在真实世界应用中的鲁棒性和泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 分割模型在基准测试中表现出高准确性，但在真实世界应用中经常因依赖虚假的相关性而失败。我们的动机是开发一个可以自行改善分割质量的系统，使其更加稳健，能抵抗数据集中的伪相关性。

**Method:** 我们提出了一种人机交互框架，通过人类对分割结果的修正来进行干预性学习。本方法将人类修正视为干预信号，用以指示何时依赖表面特征（如颜色或纹理）是不适当的。系统通过在视觉相似图像中传播由修正指导的编辑，学习这些干预措施，使模型更倾向于学习稳健、语义意义丰富的特征，而非数据集特定的伪相关性。

**Result:** 实验证明，相比于传统重新训练方法，我们的框架在具有挑战性的球面映射数据上提升了高达9 mIoU点（12-15%的相对提升），并且将注释工作量降低了3到4倍，同时在基准数据集上保持了竞争力的表现。

**Conclusion:** 该工作提供了一个实用框架，它帮助研究人员和实践者构建更准确、更适应真实世界领域的分割系统，相对于数据集偏差更具鲁棒性、数据高效并且能够适应如城市气候监测和自动驾驶等应用。

**Abstract:** Segmentation models achieve high accuracy on benchmarks but often fail in
real-world domains by relying on spurious correlations instead of true object
boundaries. We propose a human-in-the-loop interactive framework that enables
interventional learning through targeted human corrections of segmentation
outputs. Our approach treats human corrections as interventional signals that
show when reliance on superficial features (e.g., color or texture) is
inappropriate. The system learns from these interventions by propagating
correction-informed edits across visually similar images, effectively steering
the model toward robust, semantically meaningful features rather than
dataset-specific artifacts. Unlike traditional annotation approaches that
simply provide more training data, our method explicitly identifies when and
why the model fails and then systematically corrects these failure modes across
the entire dataset. Through iterative human feedback, the system develops
increasingly robust representations that generalize better to novel domains and
resist artifactual correlations. We demonstrate that our framework improves
segmentation accuracy by up to 9 mIoU points (12-15\% relative improvement) on
challenging cubemap data and yields 3-4$\times$ reductions in annotation effort
compared to standard retraining, while maintaining competitive performance on
benchmark datasets. This work provides a practical framework for researchers
and practitioners seeking to build segmentation systems that are accurate,
robust to dataset biases, data-efficient, and adaptable to real-world domains
such as urban climate monitoring and autonomous driving.

</details>


### [60] [A Multi-Strategy Framework for Enhancing Shatian Pomelo Detection in Real-World Orchards](https://arxiv.org/abs/2510.09948)
*Pan Wang,Yihao Hu,Xiaodong Bai,Aiping Yang,Xiangxiang Li,Meiping Ding,Jianguo Yao*

Main category: cs.CV

> 为了解决沙田柚检测的准确性问题，研究提出了一种多策略框架，并设计了REAS-Det网络，实现了优秀的检测效果。

<details>
  <summary>Details</summary>

**Motivation:** 由于沙田柚作为特色农产品具有较大的市场规模，需要采用自动化检测来确保数量准确，并满足商业需求的精益生产。现有研究通常涉及特定理论或数据集场景的专业网络，但在现实世界中这些方法往往性能下降。

**Method:** 通过分析问题中的因素，本研究提出了一个应对这些挑战的多策略框架。首先，为了解决由不同成像设备和复杂果园环境引起色调变化的问题，我们使用了一个多场景数据集STP-AgriData，该数据集由真实果园图像与互联网数据综合而成。其次，为了模拟不一致的光照条件，对上述数据集进行了特定的数据增强，例如调整对比度和改变亮度。第三，为了应对水果检测中的目标尺度变化和遮挡问题，设计了一个REAS-Det网络。针对尺度变化，设计了RFAConv和C3RFEM模块来扩张和增强感受野。针对遮挡变化，引入了多尺度、多头特征选择结构（MultiSEAM）和soft-NMS来增强遮挡问题的处理，提高检测精度。

**Result:** 这些实验结果达到了87.6%的精度(P)，74.9%的召回率(R)，mAP@.50为82.8%，mAP@.50:.95为53.3%。

**Conclusion:** 本研究提出的网络在网络检测方法中表现出色，优于其他最先进的检测方法。

**Abstract:** As a specialty agricultural product with a large market scale, Shatian pomelo
necessitates the adoption of automated detection to ensure accurate quantity
and meet commercial demands for lean production. Existing research often
involves specialized networks tailored for specific theoretical or dataset
scenarios, but these methods tend to degrade performance in real-world. Through
analysis of factors in this issue, this study identifies four key challenges
that affect the accuracy of Shatian pomelo detection: imaging devices, lighting
conditions, object scale variation, and occlusion. To mitigate these
challenges, a multi-strategy framework is proposed in this paper. Firstly, to
effectively solve tone variation introduced by diverse imaging devices and
complex orchard environments, we utilize a multi-scenario dataset,
STP-AgriData, which is constructed by integrating real orchard images with
internet-sourced data. Secondly, to simulate the inconsistent illumination
conditions, specific data augmentations such as adjusting contrast and changing
brightness, are applied to the above dataset. Thirdly, to address the issues of
object scale variation and occlusion in fruit detection, an REAS-Det network is
designed in this paper. For scale variation, RFAConv and C3RFEM modules are
designed to expand and enhance the receptive fields. For occlusion variation, a
multi-scale, multi-head feature selection structure (MultiSEAM) and soft-NMS
are introduced to enhance the handling of occlusion issues to improve detection
accuracy. The results of these experiments achieved a precision(P) of 87.6%, a
recall (R) of 74.9%, a mAP@.50 of 82.8%, and a mAP@.50:.95 of 53.3%. Our
proposed network demonstrates superior performance compared to other
state-of-the-art detection methods.

</details>


### [61] [J-RAS: Enhancing Medical Image Segmentation via Retrieval-Augmented Joint Training](https://arxiv.org/abs/2510.09953)
*Salma J. Ahmed,Emad A. Mohammed,Azam Asilian Bidgoli*

Main category: cs.CV

> J-RAS, a novel joint training method for image segmentation, significantly enhances segmentation accuracy and generalizes well across different architectures and datasets, addressing the limitations of current AI-based methods.

<details>
  <summary>Details</summary>

**Motivation:** To overcome the dependency on large, annotated datasets and improve generalization across diverse imaging conditions in AI-based image segmentation methods.

**Method:** Joint Retrieval Augmented Segmentation (J-RAS), a joint training method integrating a segmentation model with a retrieval model to improve image segmentation accuracy.

**Result:** The J-RAS method improves mean Dice scores from 0.8708 to 0.9115 and reduces mean Hausdorff Distance from 1.8130 to 1.1489 on the ACDC dataset, showing substantial enhancements in segmentation performance.

**Conclusion:** The proposed J-RAS method demonstrates consistent improvements in segmentation performance when integrated with various neural network architectures, making it a valuable addition to medical imaging applications.

**Abstract:** Image segmentation, the process of dividing images into meaningful regions,
is critical in medical applications for accurate diagnosis, treatment planning,
and disease monitoring. Although manual segmentation by healthcare
professionals produces precise outcomes, it is time-consuming, costly, and
prone to variability due to differences in human expertise. Artificial
intelligence (AI)-based methods have been developed to address these
limitations by automating segmentation tasks; however, they often require
large, annotated datasets that are rarely available in practice and frequently
struggle to generalize across diverse imaging conditions due to inter-patient
variability and rare pathological cases. In this paper, we propose Joint
Retrieval Augmented Segmentation (J-RAS), a joint training method for guided
image segmentation that integrates a segmentation model with a retrieval model.
Both models are jointly optimized, enabling the segmentation model to leverage
retrieved image-mask pairs to enrich its anatomical understanding, while the
retrieval model learns segmentation-relevant features beyond simple visual
similarity. This joint optimization ensures that retrieval actively contributes
meaningful contextual cues to guide boundary delineation, thereby enhancing the
overall segmentation performance. We validate J-RAS across multiple
segmentation backbones, including U-Net, TransUNet, SAM, and SegFormer, on two
benchmark datasets: ACDC and M&Ms, demonstrating consistent improvements. For
example, on the ACDC dataset, SegFormer without J-RAS achieves a mean Dice
score of 0.8708$\pm$0.042 and a mean Hausdorff Distance (HD) of
1.8130$\pm$2.49, whereas with J-RAS, the performance improves substantially to
a mean Dice score of 0.9115$\pm$0.031 and a mean HD of 1.1489$\pm$0.30. These
results highlight the method's effectiveness and its generalizability across
architectures and datasets.

</details>


### [62] [Scaling Traffic Insights with AI and Language Model-Powered Camera Systems for Data-Driven Transportation Decision Making](https://arxiv.org/abs/2510.09981)
*Fan Zuo,Donglin Zhou,Jingqin Gao,Kaan Ozbay*

Main category: cs.CV

> 本文介绍了一种基于AI的交通监控框架，该框架能够有效监控并分析实时视频流中的交通状况。数据显示，在实施交通拥堵定价政策后，行人和骑行者的活动增加了，且其方法和结论显示出该系统在城市交通管理中的实际应用潜力。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是为了开发一个准确且可扩展的交通监控系统，它能够解决现有传感器部署成本高昂的局限性，同时提供城市交通管理、特别是在自然灾害、大型建筑项目或重大政策改变等情况下的实时和长期的数据支持。

**Method:** 本研究提出了一种基于AI的端到端框架，利用现有的交通摄像头基础设施进行大规模的高分辨率纵向分析。具体来说，使用经过本地城市场景微调的YOLOv11模型，实时提取多元化的交通密度和分类指标。为解决云台变焦摄像机引起的视点不一致问题，引入了一种基于图的视点标准化方法，并结合了特定领域的大型语言模型来处理来自24/7视频流的海量数据，生成自动化更新的交通模式摘要。

**Result:** 研究结果表明交通密度在工作日有所下降，特别是拥堵缓解区内小汽车密度下降了9%，而卡车流量减少后出现复苏迹象，行人和骑行者的活动在走廊和区域级别上持续增加。实验还发现示例提示语可以提高LLM的数值准确性和减少错误预测。

**Conclusion:** 研究得出结论，提出的框架作为大规模政策相关的交通监测解决方案具有潜力，并且通过最小的人工干预即可实用，兼容现有基础设施。

**Abstract:** Accurate, scalable traffic monitoring is critical for real-time and long-term
transportation management, particularly during disruptions such as natural
disasters, large construction projects, or major policy changes like New York
City's first-in-the-nation congestion pricing program. However, widespread
sensor deployment remains limited due to high installation, maintenance, and
data management costs. While traffic cameras offer a cost-effective
alternative, existing video analytics struggle with dynamic camera viewpoints
and massive data volumes from large camera networks. This study presents an
end-to-end AI-based framework leveraging existing traffic camera infrastructure
for high-resolution, longitudinal analysis at scale. A fine-tuned YOLOv11
model, trained on localized urban scenes, extracts multimodal traffic density
and classification metrics in real time. To address inconsistencies from
non-stationary pan-tilt-zoom cameras, we introduce a novel graph-based
viewpoint normalization method. A domain-specific large language model was also
integrated to process massive data from a 24/7 video stream to generate
frequent, automated summaries of evolving traffic patterns, a task far
exceeding manual capabilities. We validated the system using over 9 million
images from roughly 1,000 traffic cameras during the early rollout of NYC
congestion pricing in 2025. Results show a 9% decline in weekday passenger
vehicle density within the Congestion Relief Zone, early truck volume
reductions with signs of rebound, and consistent increases in pedestrian and
cyclist activity at corridor and zonal scales. Experiments showed that
example-based prompts improved LLM's numerical accuracy and reduced
hallucinations. These findings demonstrate the framework's potential as a
practical, infrastructure-ready solution for large-scale, policy-relevant
traffic monitoring with minimal human intervention.

</details>


### [63] [FlareX: A Physics-Informed Dataset for Lens Flare Removal via 2D Synthesis and 3D Rendering](https://arxiv.org/abs/2510.09995)
*Lishen Qu,Zhihao Liu,Jinshan Pan,Shihao Zhou,Jinglei Shi,Duosheng Chen,Jufeng Yang*

Main category: cs.CV

> 提出了一种新的基于物理的镜头眩光生成方法，可以生成更为多样且符合物理规律的眩光数据集FlareX，并设计了方法来衡量模型在真实世界图像上的性能。实验验证了该方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的镜头眩光数据集通常通过将人工眩光模板叠加在背景图像上在2D中合成，缺乏眩光多样性和忽视物理学原理的问题使得这些模型在真实场景中泛化困难。提出新方法来改善这个问题。

**Method:** 通过分三个阶段创建物理导向的镜头眩光数据集FlareX：参数化模板创建、光照规律感知的2D合成以及基于物理引擎的3D渲染。此外，还设计了一种掩模方法来从镜头眩光的图像中获取无眩光的真实图像，以衡量模型在真实世界图像上的性能。

**Result:** 实验表明，所提出的方法和数据集能够有效地改善模型在处理镜头眩光图像时的表现。

**Conclusion:** 该方法通过结合2D和3D视角的物理导向眩光数据生成，提高了模型在处理真实世界镜头眩光图像上的泛化能力，并提供了一个全面的测试基准。

**Abstract:** Lens flare occurs when shooting towards strong light sources, significantly
degrading the visual quality of images. Due to the difficulty in capturing
flare-corrupted and flare-free image pairs in the real world, existing datasets
are typically synthesized in 2D by overlaying artificial flare templates onto
background images. However, the lack of flare diversity in templates and the
neglect of physical principles in the synthesis process hinder models trained
on these datasets from generalizing well to real-world scenarios. To address
these challenges, we propose a new physics-informed method for flare data
generation, which consists of three stages: parameterized template creation,
the laws of illumination-aware 2D synthesis, and physical engine-based 3D
rendering, which finally gives us a mixed flare dataset that incorporates both
2D and 3D perspectives, namely FlareX. This dataset offers 9,500 2D templates
derived from 95 flare patterns and 3,000 flare image pairs rendered from 60 3D
scenes. Furthermore, we design a masking approach to obtain real-world
flare-free images from their corrupted counterparts to measure the performance
of the model on real-world images. Extensive experiments demonstrate the
effectiveness of our method and dataset.

</details>


### [64] [BurstDeflicker: A Benchmark Dataset for Flicker Removal in Dynamic Scenes](https://arxiv.org/abs/2510.09996)
*Lishen Qu,Zhihao Liu,Shihao Zhou,Yaqi Luo,Jie Liang,Hui Zeng,Lei Zhang,Jufeng Yang*

Main category: cs.CV

> 构建了BurstDeflicker数据集，通过Retinex合成、现实数据收集和绿幕法，解决了闪烁去除研究中的大规模数据集缺乏问题，有效推进了去闪烁技术的发展。

<details>
  <summary>Details</summary>

**Motivation:** 闪烁伪影会影响图像质量和高层任务如物体检测和跟踪。缺乏大规模、逼真的数据集是研究去闪烁壁垒之一。为了应对此问题，提出了BurstDeflicker，一个可扩展的基准，通过三种互补的数据获取策略构建。

**Method:** 提出了一种基于Retinex的合成流水线来重新定义去闪烁的目标，并启用对关键闪烁相关属性（如强度、区域和频率）的可控操作，从而促进多种闪烁图案的生成。另外，采集了4000张现实中的闪烁图像，以帮助模型更好地理解闪烁的时空特性，并更有效地泛化到野外场景。最后，提出了绿幕法，将运动引入图像对中，同时保持真实的闪烁退化。

**Result:** 全面的实验展示了数据集的有效性及其在去闪烁研究中的潜在价值。

**Conclusion:** 该研究构建了一个可以有效模拟和理解闪烁现象的数据集，可以显著推进闪烁去除技术的发展。

**Abstract:** Flicker artifacts in short-exposure images are caused by the interplay
between the row-wise exposure mechanism of rolling shutter cameras and the
temporal intensity variations of alternating current (AC)-powered lighting.
These artifacts typically appear as uneven brightness distribution across the
image, forming noticeable dark bands. Beyond compromising image quality, this
structured noise also affects high-level tasks, such as object detection and
tracking, where reliable lighting is crucial. Despite the prevalence of
flicker, the lack of a large-scale, realistic dataset has been a significant
barrier to advancing research in flicker removal. To address this issue, we
present BurstDeflicker, a scalable benchmark constructed using three
complementary data acquisition strategies. First, we develop a Retinex-based
synthesis pipeline that redefines the goal of flicker removal and enables
controllable manipulation of key flicker-related attributes (e.g., intensity,
area, and frequency), thereby facilitating the generation of diverse flicker
patterns. Second, we capture 4,000 real-world flicker images from different
scenes, which help the model better understand the spatial and temporal
characteristics of real flicker artifacts and generalize more effectively to
wild scenarios. Finally, due to the non-repeatable nature of dynamic scenes, we
propose a green-screen method to incorporate motion into image pairs while
preserving real flicker degradation. Comprehensive experiments demonstrate the
effectiveness of our dataset and its potential to advance research in flicker
removal.

</details>


### [65] [MIMO: A medical vision language model with visual referring multimodal input and pixel grounding multimodal output](https://arxiv.org/abs/2510.10011)
*Yanyuan Chen,Dexuan Xu,Yu Huang,Songkun Zhan,Hanpin Wang,Dongxue Chen,Xueping Wang,Meikang Qiu,Hang Li*

Main category: cs.CV

> 本文提出了一种新的医学视觉语言模型MIMO，可以结合视觉线索和文本指令理解复杂的医学图像，并在输出中将医学术语与图像中的区域关联起来。同时，作者还构建了包含大量样本的MIMOSeg数据集。

<details>
  <summary>Details</summary>

**Motivation:** 现有的医学视觉语言模型存在两个问题：输入仅依赖于文本指令，缺乏对图像中视觉线索的直接理解；输出仅为文本答案，缺乏与图像中关键区域的联系。针对这些问题，本文提出了MIMO模型。

**Method:** 本文提出了一种新的统一医学视觉语言模型MIMO，该模型具有视觉引用多模态输入和像素定位多模态输出的能力。它能够结合视觉线索和文本指令理解复杂的医学图像和语义，并在文本输出中将医学术语定位在图像内。为了克服医疗领域相关数据稀缺的问题，作者还构建了MIMOSeg数据集，包含895K样本。

**Result:** 实验结果验证了MIMO模型在多种下游医学多模态任务中的有效性，它可以结合视觉引用和像素定位的能力，这是之前模型所不具备的。

**Conclusion:** 通过MIMO模型的引入和MIMOSeg数据集的构建，本文解决了现有医学视觉语言模型在输入和输出方面存在的问题，并展示了其在处理医学多模态任务的独特优势。

**Abstract:** Currently, medical vision language models are widely used in medical vision
question answering tasks. However, existing models are confronted with two
issues: for input, the model only relies on text instructions and lacks direct
understanding of visual clues in the image; for output, the model only gives
text answers and lacks connection with key areas in the image. To address these
issues, we propose a unified medical vision language model MIMO, with visual
referring Multimodal Input and pixel grounding Multimodal Output. MIMO can not
only combine visual clues and textual instructions to understand complex
medical images and semantics, but can also ground medical terminologies in
textual output within the image. To overcome the scarcity of relevant data in
the medical field, we propose MIMOSeg, a comprehensive medical multimodal
dataset including 895K samples. MIMOSeg is constructed from four different
perspectives, covering basic instruction following and complex question
answering with multimodal input and multimodal output. We conduct experiments
on several downstream medical multimodal tasks. Extensive experimental results
verify that MIMO can uniquely combine visual referring and pixel grounding
capabilities, which are not available in previous models.

</details>
