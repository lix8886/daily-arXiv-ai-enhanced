{"id": "2511.04727", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04727", "abs": "https://arxiv.org/abs/2511.04727", "authors": ["Ali Faraz", "Akash", "Shaharukh Khan", "Raja Kolla", "Akshat Patidar", "Suranjan Goswami", "Abhinav Ravi", "Chandra Khatri", "Shubham Agarwal"], "title": "IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs", "comment": null, "summary": "Vision-language models (VLMs) have demonstrated impressive generalization\nacross multimodal tasks, yet most evaluation benchmarks remain Western-centric,\nleaving open questions about their performance in culturally diverse and\nmultilingual settings. To address this gap, we introduce IndicVisionBench, the\nfirst large-scale benchmark centered on the Indian subcontinent. Covering\nEnglish and 10 Indian languages, our benchmark spans 3 multimodal tasks,\nincluding Optical Character Recognition (OCR), Multimodal Machine Translation\n(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.\nOur final benchmark consists of a total of ~5K images and 37K+ QA pairs across\n13 culturally grounded topics. In addition, we release a paired parallel corpus\nof annotations across 10 Indic languages, creating a unique resource for\nanalyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum\nof 8 models, from proprietary closed-source systems to open-weights medium and\nlarge-scale models. Our experiments reveal substantial performance gaps,\nunderscoring the limitations of current VLMs in culturally diverse contexts. By\ncentering cultural diversity and multilinguality, IndicVisionBench establishes\na reproducible evaluation framework that paves the way for more inclusive\nmultimodal research.", "AI": {"tldr": "Introduces IndicVisionBench, a large-scale benchmark for evaluating VLMs in diverse cultural and linguistic settings focused on the Indian subcontinent, highlighting performance gaps across cultures.", "motivation": "The motivation is to address the Western-centric bias in current evaluation benchmarks for vision-language models and to explore their performance in culturally diverse and multilingual environments.", "method": "Content covers the introduction of a new benchmark named IndicVisionBench, designed to evaluate vision-language models in culturally and linguistically diverse settings centered on the Indian subcontinent, covering 10 Indian languages and English.", "result": "The evaluation of 8 models across the benchmark revealed significant performance gaps, demonstrating the limitations of current VLMs when faced with culturally diverse and multilingual challenges.", "conclusion": "IndicVisionBench sets a new standard for evaluating VLMs in multicultural contexts, laying the groundwork for more inclusive multimodal research."}}
{"id": "2511.04729", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04729", "abs": "https://arxiv.org/abs/2511.04729", "authors": ["Rucha Deshpande", "Tahsin Rahman", "Miguel Lago", "Adarsh Subbaswamy", "Jana G. Delfino", "Ghada Zamzmi", "Elim Thompson", "Aldo Badano", "Seyed Kahaki"], "title": "Knowledge-based anomaly detection for identifying network-induced shape artifacts", "comment": "15 pages, 11 figures", "summary": "Synthetic data provides a promising approach to address data scarcity for\ntraining machine learning models; however, adoption without proper quality\nassessments may introduce artifacts, distortions, and unrealistic features that\ncompromise model performance and clinical utility. This work introduces a novel\nknowledge-based anomaly detection method for detecting network-induced shape\nartifacts in synthetic images. The introduced method utilizes a two-stage\nframework comprising (i) a novel feature extractor that constructs a\nspecialized feature space by analyzing the per-image distribution of angle\ngradients along anatomical boundaries, and (ii) an isolation forest-based\nanomaly detector. We demonstrate the effectiveness of the method for\nidentifying network-induced shape artifacts in two synthetic mammography\ndatasets from models trained on CSAW-M and VinDr-Mammo patient datasets\nrespectively. Quantitative evaluation shows that the method successfully\nconcentrates artifacts in the most anomalous partition (1st percentile), with\nAUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study\ninvolving three imaging scientists confirmed that images identified by the\nmethod as containing network-induced shape artifacts were also flagged by human\nreaders with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the\nmost anomalous partition, approximately 1.5-2 times higher than the least\nanomalous partition. Kendall-Tau correlations between algorithmic and human\nrankings were 0.45 and 0.43 for the two datasets, indicating reasonable\nagreement despite the challenging nature of subtle artifact detection. This\nmethod is a step forward in the responsible use of synthetic data, as it allows\ndevelopers to evaluate synthetic images for known anatomic constraints and\npinpoint and address specific issues to improve the overall quality of a\nsynthetic dataset.", "AI": {"tldr": "A novel two-stage method for detecting shape artifacts in synthetic images effectively identifies network-induced distortions, validated by quantitative and human reader studies, improving synthetic dataset quality.", "motivation": "The paper aims to address the quality issues related to synthetic data used in training machine learning models, focusing on detecting artifacts, distortions, and unrealistic features that these datasets introduce.", "method": "A two-stage framework is introduced for detecting network-induced shape artifacts in synthetic images. The method includes a feature extractor that analyzes the per-image distribution of angle gradients along anatomical boundaries and an isolation forest-based anomaly detector.", "result": "The method achieves high AUROC values (0.97 and 0.91) for localizing artifacts in two synthetic mammography datasets, and there is notable agreement (66% and 68%) between the method’s identification of artifacts and human assessments.", "conclusion": "The proposed anomaly detection method represents a significant contribution to the evaluation and improvement of the quality of synthetic datasets, enhancing their utility in clinical applications."}}
{"id": "2511.04753", "categories": ["cs.CV", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04753", "abs": "https://arxiv.org/abs/2511.04753", "authors": ["Zonglin Lyu", "Ming Li", "Xinxin Liu", "Chen Chen"], "title": "CPO: Condition Preference Optimization for Controllable Image Generation", "comment": null, "summary": "To enhance controllability in text-to-image generation, ControlNet introduces\nimage-based control signals, while ControlNet++ improves pixel-level cycle\nconsistency between generated images and the input control signal. To avoid the\nprohibitive cost of back-propagating through the sampling process, ControlNet++\noptimizes only low-noise timesteps (e.g., $t < 200$) using a single-step\napproximation, which not only ignores the contribution of high-noise timesteps\nbut also introduces additional approximation errors. A straightforward\nalternative for optimizing controllability across all timesteps is Direct\nPreference Optimization (DPO), a fine-tuning method that increases model\npreference for more controllable images ($I^{w}$) over less controllable ones\n($I^{l}$). However, due to uncertainty in generative models, it is difficult to\nensure that win--lose image pairs differ only in controllability while keeping\nother factors, such as image quality, fixed. To address this, we propose\nperforming preference learning over control conditions rather than generated\nimages. Specifically, we construct winning and losing control signals,\n$\\mathbf{c}^{w}$ and $\\mathbf{c}^{l}$, and train the model to prefer\n$\\mathbf{c}^{w}$. This method, which we term \\textit{Condition Preference\nOptimization} (CPO), eliminates confounding factors and yields a low-variance\ntraining objective. Our approach theoretically exhibits lower contrastive loss\nvariance than DPO and empirically achieves superior results. Moreover, CPO\nrequires less computation and storage for dataset curation. Extensive\nexperiments show that CPO significantly improves controllability over the\nstate-of-the-art ControlNet++ across multiple control types: over $10\\%$ error\nrate reduction in segmentation, $70$--$80\\%$ in human pose, and consistent\n$2$--$5\\%$ reductions in edge and depth maps.", "AI": {"tldr": "本文提出了条件偏好优化（CPO）方法，以改善文本到图像生成的可控性，并在多个实验中展示了其相对于State-of-the-art ControlNet++的优势。", "motivation": "为了克服Direct Preference Optimization (DPO)中难以保持图像对比度和质量一致性的问题，同时减少训练计算和存储资源的需求。", "method": "本文提出了条件偏好优化（CPO）的方法，以提高文本到图像生成的可控性，该方法通过在控制信号而非生成的图像上进行偏好学习来训练模型，以减少不确定性和复杂性。", "result": "实验表明，CPO方法在不同的控制类型（包括分割、人体姿态、边缘和深度图）上显著提高了可控性，错误率降低超过10%。", "conclusion": "通过使用条件偏好优化（CPO），可以有效减少训练过程中的对比损失方差，同时减少计算和存储资源的消耗，显著提升了生成图像的可控性。"}}
{"id": "2511.04766", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04766", "abs": "https://arxiv.org/abs/2511.04766", "authors": ["Dhenenjay Yadav", "Rohan Sawai"], "title": "DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation", "comment": null, "summary": "Foundation models (FMs) offer powerful representations for geospatial\nanalysis, but adapting them effectively remains challenging. Standard\nadaptation methods, whether full fine-tuning or efficient frozen-backbone\napproaches, typically employ decoders with fixed regularization strategies,\nfailing to account for the significant heterogeneity in satellite imagery. We\nintroduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder\narchitecture designed to address this limitation. DARN integrates three key\ninnovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates\nper-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically\nadjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and\n(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide\ntheoretical justifications linking DARN's optimization to stationary point\nconvergence and its mechanism to adaptive information bottlenecks. Empirically,\nDARN demonstrates exceptional performance across both major adaptation\nparadigms. In full fine-tuning (unfrozen backbone), DARN achieves a new\nstate-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp\nover prior SOTA). In efficient adaptation (frozen backbone), DARN achieves\nSOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering\nsubstantial advantages crucial for real-world deployment: superior\nout-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),\nenhanced robustness (17% relative reduction in corruption error), and improved\nperformance on minority classes. DARN offers a more intelligent, robust, and\nefficient approach to leveraging FMs in critical geospatial applications.", "AI": {"tldr": "本文提出了DARN，一种新的解码器架构，旨在解决基础模型（FMs）在地理空间分析中的应用挑战。DARN展示了超越现有方法的性能。", "motivation": "标准的微调方法或者高效的冻结骨干方法通常使用具有固定正则化策略的解码器，无法处理卫星图像中的显著异质性。", "method": "DARN整合了三个关键创新：(1) 任务复杂度预测器（TCP），用于估计每个样本的难度；(2) 适应性dropout调制（ADM），根据预测的复杂度从0.1到0.5动态调整dropout率；(3) 动态容量门控（DCG），调节通道激活。", "result": "DARN在全微调（非冻结骨干）方式中达到了新的最先进水平，在GeoBench多任务基准测试中达到86.66%的mIoU（比之前的最先进水平提高了5.56个百分点）。在高效适应（冻结骨干）方式中，DARN达到了与最先进水平相当的准确度（在Sen1Floods11上达到90.5%的mIoU），同时提供了实质性的优势，包括更好的OOD泛化（在AI4SmallFarms上增加了9.5个百分点的mIoU）、增强的鲁棒性（相对降低了17%的损坏误差）和改善了少数类别的表现。", "conclusion": "DARN提供了一种更智能、更稳健且更高效的利用基础模型的方法，特别是在关键的地理空间应用程序中。"}}
{"id": "2511.04688", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.04688", "abs": "https://arxiv.org/abs/2511.04688", "authors": ["Adrita Anika", "Md Messal Monem Miah"], "title": "Evaluating LLMs' Reasoning Over Ordered Procedural Steps", "comment": "Accepted to IJCNLP-AACL 2025 Findings", "summary": "Reasoning over procedural sequences, where the order of steps directly\nimpacts outcomes, is a critical capability for large language models (LLMs). In\nthis work, we study the task of reconstructing globally ordered sequences from\nshuffled procedural steps, using a curated dataset of food recipes, a domain\nwhere correct sequencing is essential for task success. We evaluate several\nLLMs under zero-shot and few-shot settings and present a comprehensive\nevaluation framework that adapts established metrics from ranking and sequence\nalignment. These include Kendall's Tau, Normalized Longest Common Subsequence\n(NLCS), and Normalized Edit Distance (NED), which capture complementary aspects\nof ordering quality. Our analysis shows that model performance declines with\nincreasing sequence length, reflecting the added complexity of longer\nprocedures. We also find that greater step displacement in the input,\ncorresponding to more severe shuffling, leads to further degradation. These\nfindings highlight the limitations of current LLMs in procedural reasoning,\nespecially with longer and more disordered inputs.", "AI": {"tldr": "研究通过零样本和少量样本设置评估大语言模型在重建从打乱的步骤中恢复全局有序序列的能力，特别是在食谱领域，并提出评价框架。结果显示模型性能随序列长度增加和步骤位移增加而下降，反映出当前LLM在程序推理方面的局限性。", "motivation": "评估大语言模型在重建从打乱的步骤中恢复全局有序序列的能力，尤其关注食谱领域正确顺序的重要性，发现当前模型在此类任务中的局限性。", "method": "使用一个经过筛选的食谱数据集，评估几个大语言模型在零样本和少量样本设置下的性能，并提出了一种全面的评价框架，采用Kendall's Tau, Normalized Longest Common Subsequence (NLCS), 和Normalized Edit Distance (NED) 来衡量结果的有序性。", "result": "分析显示，模型性能随着序列长度的增加而降低，并且输入中的步骤位移越严重，排序质量越差。结果揭示了当前LLM在处理长序列和高混乱输入时的程序推理能力的限制。", "conclusion": "当前的大语言模型在处理长序列任务时能力有限，尤其是在任务步骤被严重打乱的情况下其程序推理能力尤其受限。"}}
{"id": "2511.04773", "categories": ["cs.CV", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2511.04773", "abs": "https://arxiv.org/abs/2511.04773", "authors": ["Shirin Ermis", "Cesar Aybar", "Lilli Freischem", "Stella Girtsou", "Kyriaki-Margarita Bintsi", "Emiliano Diaz Salas-Porras", "Michael Eisinger", "William Jones", "Anna Jungbluth", "Benoit Tremblay"], "title": "Global 3D Reconstruction of Clouds & Tropical Cyclones", "comment": null, "summary": "Accurate forecasting of tropical cyclones (TCs) remains challenging due to\nlimited satellite observations probing TC structure and difficulties in\nresolving cloud properties involved in TC intensification. Recent research has\ndemonstrated the capabilities of machine learning methods for 3D cloud\nreconstruction from satellite observations. However, existing approaches have\nbeen restricted to regions where TCs are uncommon, and are poorly validated for\nintense storms. We introduce a new framework, based on a\npre-training--fine-tuning pipeline, that learns from multiple satellites with\nglobal coverage to translate 2D satellite imagery into 3D cloud maps of\nrelevant cloud properties. We apply our model to a custom-built TC dataset to\nevaluate performance in the most challenging and relevant conditions. We show\nthat we can - for the first time - create global instantaneous 3D cloud maps\nand accurately reconstruct the 3D structure of intense storms. Our model not\nonly extends available satellite observations but also provides estimates when\nobservations are missing entirely. This is crucial for advancing our\nunderstanding of TC intensification and improving forecasts.", "AI": {"tldr": "本研究介绍了一种新型的框架，该框架基于预训练-微调管道，可以将2D卫星图像转换为与TC相关的3D云图，首次实现了全球瞬时3D云图的创建，提升了对TC加强及其预测的理解。", "motivation": "由于TC结构的卫星观测有限，难以解析与TC加强相关的云特性，准确预测TC仍然是一个挑战。现有的方法已经被限制在TC不常见的区域，并且对于强烈的风暴验证不足。", "method": "我们引入了一个新的框架，基于预训练-微调管道，该框架可以从多个具有全球覆盖范围的卫星学习，将2D卫星图像转换为与TC结构相关的3D云图。", "result": "我们能够首次创建全球瞬时3D云图，并且准确地重建强烈风暴的3D结构。", "conclusion": "该模型不仅扩展了现有的卫星观测，还可以在观测缺失时提供估算值，这对于深化我们对TC加强的理解和提高预测至关重要。"}}
{"id": "2511.04689", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04689", "abs": "https://arxiv.org/abs/2511.04689", "authors": ["Peiyu Li", "Xiuxiu Tang", "Si Chen", "Ying Cheng", "Ronald Metoyer", "Ting Hua", "Nitesh V. Chawla"], "title": "Adaptive Testing for LLM Evaluation: A Psychometric Alternative to Static Benchmarks", "comment": "Code and calibrated item banks are available at\n  https://github.com/Peiyu-Georgia-Li/ATLAS.git", "summary": "Large language model evaluation requires thousands of benchmark items, making\nevaluations expensive and slow. Existing methods compute average accuracy\nacross fixed item sets, treating all items equally despite varying quality and\ninformativeness. We present ATLAS an adaptive testing framework using Item\nResponse Theory (IRT) to estimate model ability through Fisher\ninformation-guided item selection. Our analysis of five major benchmarks\nreveals that 3-6% of items exhibit negative discrimination, indicating\nannotation errors that corrupt static evaluation. ATLAS achieves 90% item\nreduction while maintaining measurement precision: on HellaSwag (5,608 items),\nwe match full-benchmark estimates using only 42 items with 0.154 MAE. Our\nframework maintains item exposure rates below 10% and test overlap at 16-27%,\ncompared to static benchmarks where every model sees all items (100% exposure).\nAmong 4,000+ tested models, IRT ranks differ from accuracy ranks: models with\nthe same accuracy get different IRT scores, and 23-31% of all models shift by\nmore than 10 rank positions. Code and calibrated item banks are available at\nhttps://github.com/Peiyu-Georgia-Li/ATLAS.git.", "AI": {"tldr": "ATLAS is an adaptive evaluation framework for large language models using IRT, achieving 90% item reduction while maintaining precision. It significantly reduces the number of benchmark items needed for testing and reveals discrepancies in model ranking between IRT and accuracy-based metrics.", "motivation": "The motivation for ATLAS is to address the inefficiencies of current evaluation methods for large language models. Traditional methods are expensive, slow, and do not differentiate the quality and informativeness of benchmark items, which can lead to inaccuracies in evaluation.", "method": "ATLAS is an adaptive testing framework using Item Response Theory (IRT) to estimate model ability through Fisher information-guided item selection. It selects items dynamically to reduce the number of items needed for accurate evaluation compared to traditional methods that use fixed item sets.", "result": "ATLAS can reduce the number of items required for evaluation by 90% while maintaining precision. On the HellaSwag benchmark, ATLAS achieves comparable accuracy estimates with just 42 items out of the original 5,608. Additionally, it maintains low item exposure and test overlap rates, providing a fairer evaluation across different tested models.", "conclusion": "The ATLAS framework provides a more efficient and accurate evaluation method for large language models compared to traditional static benchmarks. It addresses the issue of negative discriminatory items and ranking shifts between IRT scores and accuracy scores, promising a more nuanced understanding of model abilities."}}
{"id": "2511.04779", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04779", "abs": "https://arxiv.org/abs/2511.04779", "authors": ["Andrea Aspesi", "Andrea Simpsi", "Aaron Tognoli", "Simone Mentasti", "Luca Merigo", "Matteo Matteucci"], "title": "EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear", "comment": "International Joint Conference on Neural Networks (IJCNN), 2025", "summary": "Event-based cameras are becoming a popular solution for efficient, low-power\neye tracking. Due to the sparse and asynchronous nature of event data, they\nrequire less processing power and offer latencies in the microsecond range.\nHowever, many existing solutions are limited to validation on powerful GPUs,\nwith no deployment on real embedded devices. In this paper, we present EETnet,\na convolutional neural network designed for eye tracking using purely\nevent-based data, capable of running on microcontrollers with limited\nresources. Additionally, we outline a methodology to train, evaluate, and\nquantize the network using a public dataset. Finally, we propose two versions\nof the architecture: a classification model that detects the pupil on a grid\nsuperimposed on the original image, and a regression model that operates at the\npixel level.", "AI": {"tldr": "本文介绍了一个名为EETnet的卷积神经网络，其能在低资源设备上进行基于事件数据的眼动追踪，提出两种模型版本，并提供了一套包括量化在内的完整工作流程。", "motivation": "由于基于事件的数据稀疏且异步的特性，基于事件的相机可以在微秒范围内提供低功耗和低延迟的眼动追踪，但现有的许多解决方案仅限于在强大的GPU上进行验证，没有在真正的嵌入式设备上进行部署。本论文旨在降低资源需求，实现在资源受限的硬件上运行。", "method": "此论文介绍了EETnet，一种专为使用基于事件的数据进行眼动追踪设计的卷积神经网络，能够在资源有限的微控制器上运行。作者还提出了一种使用公开数据集训练、评估和量化网络的方法。该架构包含两个版本：一种是在原图上叠加的网格上检测瞳孔的分类模型，另一种是像素级别的回归模型。", "result": "论文没有提供具体的结果数据，但描述了提出的方法和技术的潜力，旨在满足眼动追踪技术在低资源设备上的需求。", "conclusion": "该论文提出了EETnet，一种可以在资源有限的微控制器上运行的卷积神经网络，用于基于事件数据的眼动追踪，并提出了两种模型版本：网格上的分类模型和像素级别的回归模型，为眼动追踪技术在嵌入式设备上的应用提供了可能性。"}}
{"id": "2511.04692", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2511.04692", "abs": "https://arxiv.org/abs/2511.04692", "authors": ["Jingqing Wang", "Jiaxing Shang", "Rong Xu", "Fei Hao", "Tianjin Huang", "Geyong Min"], "title": "SARC: Sentiment-Augmented Deep Role Clustering for Fake News Detection", "comment": "12 pages, 11 figures, 4 tables, WSDM 2026 accepted paper", "summary": "Fake news detection has been a long-standing research focus in social\nnetworks. Recent studies suggest that incorporating sentiment information from\nboth news content and user comments can enhance detection performance. However,\nexisting approaches typically treat sentiment features as auxiliary signals,\noverlooking role differentiation, that is, the same sentiment polarity may\noriginate from users with distinct roles, thereby limiting their ability to\ncapture nuanced patterns for effective detection. To address this issue, we\npropose SARC, a Sentiment-Augmented Role Clustering framework which utilizes\nsentiment-enhanced deep clustering to identify user roles for improved fake\nnews detection. The framework first generates user features through joint\ncomment text representation (with BiGRU and Attention mechanism) and sentiment\nencoding. It then constructs a differentiable deep clustering module to\nautomatically categorize user roles. Finally, unlike existing approaches which\ntake fake news label as the unique supervision signal, we propose a joint\noptimization objective integrating role clustering and fake news detection to\nfurther improve the model performance. Experimental results on two benchmark\ndatasets, RumourEval-19 and Weibo-comp, demonstrate that SARC achieves superior\nperformance across all metrics compared to baseline models. The code is\navailable at: https://github.com/jxshang/SARC.", "AI": {"tldr": "本文提出SARC框架，通过情感增强的深度聚类来识别用户角色，提升了假新闻检测效果。", "motivation": "研究表明，融合新闻内容和用户评论的情感信息可以提升假新闻检测性能。然而，现有方法通常将情感特征作为辅助信号，忽略了角色区分，限制了它们捕捉复杂模式的能力。为解决这一问题，研究人员提出了SARC框架。", "method": "该论文提出了SARC框架，结合情感增强的深度聚类来识别用户角色，提升假新闻检测效果。首先，通过联合评论文本表示（使用BiGRU和注意力机制）和情感编码生成用户特征。接着，构建了一个可微分的深度聚类模块来自动分类用户角色。最后，提出了一种联合优化目标，结合角色聚类和假新闻检测，进一步提升模型性能。", "result": "实验结果显示，SARC框架在RumourEval-19和Weibo-comp两个基准数据集上，相较于基线模型，在所有指标上都实现了更优的性能。", "conclusion": "通过提出定制化的角色聚类和情感融合适应，SARC框架能够更有效地识别用户角色，从而提升了假新闻的检测性能。"}}
{"id": "2511.04797", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04797", "abs": "https://arxiv.org/abs/2511.04797", "authors": ["Jim James", "Ben Wilson", "Simon Lucey", "James Hays"], "title": "3D Gaussian Point Encoders", "comment": "10 pages, 3 figures, 3 tables", "summary": "In this work, we introduce the 3D Gaussian Point Encoder, an explicit\nper-point embedding built on mixtures of learned 3D Gaussians. This explicit\ngeometric representation for 3D recognition tasks is a departure from widely\nused implicit representations such as PointNet. However, it is difficult to\nlearn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We\ndevelop optimization techniques based on natural gradients and distillation\nfrom PointNets to find a Gaussian Basis that can reconstruct PointNet\nactivations. The resulting 3D Gaussian Point Encoders are faster and more\nparameter efficient than traditional PointNets. As in the 3D reconstruction\nliterature where there has been considerable interest in the move from implicit\n(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can\ntake advantage of computational geometry heuristics to accelerate 3D Gaussian\nPoint Encoders further. We extend filtering techniques from 3D Gaussian\nSplatting to construct encoders that run 2.7 times faster as a comparable\naccuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,\nwe demonstrate the effectiveness of 3D Gaussian Point Encoders as a component\nin Mamba3D, running 1.27 times faster and achieving a reduction in memory and\nFLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight\nenough to achieve high framerates on CPU-only devices.", "AI": {"tldr": "提出了一种基于3D高斯混合体的显式点嵌入方法，旨在提高3D识别任务中的参数效率和计算速度，并展示了优于PointNet的性能。", "motivation": "旨在创建一个显式的几何表示方法，以替代3D识别任务中广泛使用的隐式表示方法，从而提高参数效率和计算速度。", "method": "提出3D高斯点编码器，这是一种基于学习的3D高斯混合体的显式点嵌入表示，用于3D识别任务，区别于传统的隐式表示如PointNet。为了学习3D高斯编码器，开发了基于自然梯度和点云预训练模型迁移的学习优化技术。", "result": "新的3D高斯点编码器比传统的PointNets更快，参数效率更高，通过利用计算几何的方法将速度提升至2.7倍，且维持类似的精度，同时分别减少了46%的内存和88%的FLOP。在Mamba3D中的应用展示了1.27倍的速度提升，以及内存和FLOP的显著减少。", "conclusion": "该研究确认了3D高斯点编码器作为显式表示的有效性和优越性，并将之作为Mamba3D的一部分应用，展示了更高的计算效率和参数效率。这种轻量级的架构能够实现CPU设备上的高帧率。"}}
{"id": "2511.04694", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04694", "abs": "https://arxiv.org/abs/2511.04694", "authors": ["Zishuo Zheng", "Vidhisha Balachandran", "Chan Young Park", "Faeze Brahman", "Sachin Kumar"], "title": "Reasoning Up the Instruction Ladder for Controllable Language Models", "comment": null, "summary": "As large language model (LLM) based systems take on high-stakes roles in\nreal-world decision-making, they must reconcile competing instructions from\nmultiple sources (e.g., model developers, users, and tools) within a single\nprompt context. Thus, enforcing an instruction hierarchy (IH) in LLMs, where\nhigher-level directives override lower-priority requests, is critical for the\nreliability and controllability of LLMs. In this work, we reframe instruction\nhierarchy resolution as a reasoning task. Specifically, the model must first\n\"think\" about the relationship between a given user prompt and higher-priority\n(system) instructions before generating a response. To enable this capability\nvia training, we construct VerIH, an instruction hierarchy dataset of\nconstraint-following tasks with verifiable answers. This dataset comprises both\naligned and conflicting system-user instructions. We show that lightweight\nreinforcement learning with VerIH effectively transfers general reasoning\ncapabilities of models to instruction prioritization. Our finetuned models\nachieve consistent improvements on instruction following and instruction\nhierarchy benchmarks. This reasoning ability also generalizes to\nsafety-critical settings beyond the training distribution. By treating safety\nissues as resolving conflicts between adversarial user inputs and predefined\nhigher-priority policies, our trained model enhances robustness against\njailbreak and prompt injection attacks. These results demonstrate that\nreasoning over instruction hierarchies provides a practical path to reliable\nLLMs, where updates to system prompts yield controllable and robust changes in\nmodel behavior.", "AI": {"tldr": "将LLM的指令层级解析为推理任务，构建VerIH数据集并通过轻量级强化学习训练来提升模型在指令遵循和安全问题上的表现。", "motivation": "随着LLM在现实世界决策中的角色愈发重要，必须能够协调来自多个来源（如模型开发人员、用户和工具）的高竞争性指令，从而在单一提示上下文中执行指令层级结构，以保证LLM的可靠性和可控性。", "method": "本研究将指令层级结构的解析重新定义为一个推理任务，即模型需要首先“思考”给定用户提示和优先级较高的系统指令之间的关系，然后生成响应。为此，研究构建了VerIH数据集，其中包括遵守约束任务的指令层级结构，具备可验证答案。该数据集涵盖了与用户指令一致和冲突的系统指令。通过使用VerIH进行轻量级的强化学习训练，研究展示了模型可以将一般推理能力转移到指令优先级的处理上。", "result": "细化后的模型在指令遵循和指令层级基准上取得了持续的改进。模型的推理能力还能推广到训练分布之外的安全关键设置中，例如通过将安全问题视为解决对抗用户输入与预先定义的高优先级策略之间冲突的方式，来增强抵御越狱和注入攻击的稳健性。", "conclusion": "研究结果证明，通过推理来处理指令层级结构为实现可靠的LLM提供了一条实用路径。对系统提示的更新可以导致模型行为的可控性和稳健性变化。"}}
{"id": "2511.04803", "categories": ["cs.CV", "cs.AI", "cs.LG", "I.2.10; I.4.6"], "pdf": "https://arxiv.org/pdf/2511.04803", "abs": "https://arxiv.org/abs/2511.04803", "authors": ["Shuo Zhao", "Jianxu Chen"], "title": "Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose", "comment": "Accepted to IEEE BIBM 2025 Workshop; 6 pages; 4 figures; 5 tables;\n  IEEEtran class. Code: https://github.com/MMV-Lab/biomedseg-efficiency", "summary": "Generalist biomedical image segmentation models such as Cellpose are\nincreasingly applied across diverse imaging modalities and cell types. However,\ntwo critical challenges remain underexplored: (1) the extent of training data\nredundancy and (2) the impact of cross domain transfer on model retention. In\nthis study, we conduct a systematic empirical analysis of these challenges\nusing Cellpose as a case study. First, to assess data redundancy, we propose a\nsimple dataset quantization (DQ) strategy for constructing compact yet diverse\ntraining subsets. Experiments on the Cyto dataset show that image segmentation\nperformance saturates with only 10% of the data, revealing substantial\nredundancy and potential for training with minimal annotations. Latent space\nanalysis using MAE embeddings and t-SNE confirms that DQ selected patches\ncapture greater feature diversity than random sampling. Second, to examine\ncatastrophic forgetting, we perform cross domain finetuning experiments and\nobserve significant degradation in source domain performance, particularly when\nadapting from generalist to specialist domains. We demonstrate that selective\nDQ based replay reintroducing just 5-10% of the source data effectively\nrestores source performance, while full replay can hinder target adaptation.\nAdditionally, we find that training domain sequencing improves generalization\nand reduces forgetting in multi stage transfer. Our findings highlight the\nimportance of data centric design in biomedical image segmentation and suggest\nthat efficient training requires not only compact subsets but also retention\naware learning strategies and informed domain ordering. The code is available\nat https://github.com/MMV-Lab/biomedseg-efficiency.", "AI": {"tldr": "本研究通过Cellpose模型系统分析了生物医学图像分割中的数据冗余和跨领域转移对模型保持性能的影响，发现使用最少注释训练是很有可能的，且数据重用策略能改善多阶段模型迁移。", "motivation": "本文旨在系统地分析跨多种成像方式和细胞类型应用的生物医学图像分割模型（如Cellpose）面临的两个挑战：训练数据冗余的程度和跨领域转移对模型保持性能的影响。", "method": "该研究使用Cellpose模型作为研究案例，首先提出了一种简单的数据集量化（DQ）策略来构建紧凑且多样的训练子集，以评估数据冗余。其次，通过跨领域微调实验考察了灾难性遗忘问题。", "result": "实验表明，使用Cyto数据集进行的图像分割性能在仅使用10%的数据时就可以达到饱和，展示了大量的数据冗余和使用最少注释进行训练的潜力。此外，选择性DQ基础上的回忆（重新引入5-10%的源数据）有效恢复了源性能，而完全回忆可能会阻碍目标适应。训练域排序能够改善泛化并减少多阶段转移中的遗忘。", "conclusion": "研究结果强调了在生物医学图像分割中的数据为中心的设计的重要性，提示有效的训练不仅需要紧凑的数据子集，还需要考虑保持性能的学习策略和知情的域排序。"}}
{"id": "2511.04696", "categories": ["cs.CL", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2511.04696", "abs": "https://arxiv.org/abs/2511.04696", "authors": ["Jan Strich", "Adeline Scharfenberg", "Chris Biemann", "Martin Semmann"], "title": "EncouRAGe: Evaluating RAG Local, Fast, and Reliable", "comment": "Currently under review", "summary": "We introduce EncouRAGe, a comprehensive Python framework designed to\nstreamline the development and evaluation of Retrieval-Augmented Generation\n(RAG) systems using Large Language Models (LLMs) and Embedding Models.\nEncouRAGe comprises five modular and extensible components: Type Manifest, RAG\nFactory, Inference, Vector Store, and Metrics, facilitating flexible\nexperimentation and extensible development. The framework emphasizes scientific\nreproducibility, diverse evaluation metrics, and local deployment, enabling\nresearchers to efficiently assess datasets within RAG workflows. This paper\npresents implementation details and an extensive evaluation across multiple\nbenchmark datasets, including 25k QA pairs and over 51k documents. Our results\nshow that RAG still underperforms compared to the Oracle Context, while Hybrid\nBM25 consistently achieves the best results across all four datasets. We\nfurther examine the effects of reranking, observing only marginal performance\nimprovements accompanied by higher response latency.", "AI": {"tldr": "本研究介绍了EncouRAGe框架，用于简化RAG系统的开发和评估。实验结果表明，尽管Hybrid BM25在测试的多个数据集中表现最好，但RAG的表现仍不及Oracle Context。", "motivation": "该研究的动机是解决RAG系统在科研领域的易用性和可复现性问题，尤其是希望为研究人员提供一个工具，以便他们更有效地评估RAG流程中的数据集。", "method": "文中提出了EncouRAGe，这是一个用来简化基于Large Language Models (LLMs) 和 Embedding Models的Retrieval-Augmented Generation (RAG)系统开发与评估的Python框架。该框架由类型表示、RAG工厂、推理、向量存储和度量五个模块构成，旨在提供灵活的实验和可扩展的开发环境。", "result": "实验结果显示，RAG的表现仍然不如Oracle Context。另外，Hybrid BM25在四个数据集中表现最好。此外，重新排序对性能的提升有限，并伴随响应延迟的增加。", "conclusion": "研究得出的结论是，虽然RAG仍然是一个有潜力的研究方向，但当前的表现仍然存在局限性。Hybrid BM25的方法在测试的多个数据集上表现最佳。此外，重新排序的效果有限。"}}
{"id": "2511.04811", "categories": ["cs.CV", "cs.AI", "cs.LG", "68T07, 68U10", "I.2.10; I.4.6; J.3"], "pdf": "https://arxiv.org/pdf/2511.04811", "abs": "https://arxiv.org/abs/2511.04811", "authors": ["Shuo Zhao", "Yu Zhou", "Jianxu Chen"], "title": "An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention", "comment": "6 pages, 4 figures, presented at Bildverarbeitung f\\\"ur die Medizin\n  (BVM) 2025, Wiesbaden, Germany", "summary": "Biomedical image segmentation is critical for precise structure delineation\nand downstream analysis. Traditional methods often struggle with noisy data,\nwhile deep learning models such as U-Net have set new benchmarks in\nsegmentation performance. nnU-Net further automates model configuration, making\nit adaptable across datasets without extensive tuning. However, it requires a\nsubstantial amount of annotated data for cross-validation, posing a challenge\nwhen only raw images but no labels are available. Large foundation models offer\nzero-shot generalizability, but may underperform on specific datasets with\nunique characteristics, limiting their direct use for analysis. This work\naddresses these bottlenecks by proposing a data-centric AI workflow that\nleverages active learning and pseudo-labeling to combine the strengths of\ntraditional neural networks and large foundation models while minimizing human\nintervention. The pipeline starts by generating pseudo-labels from a foundation\nmodel, which are then used for nnU-Net's self-configuration. Subsequently, a\nrepresentative core-set is selected for minimal manual annotation, enabling\neffective fine-tuning of the nnU-Net model. This approach significantly reduces\nthe need for manual annotations while maintaining competitive performance,\nproviding an accessible solution for biomedical researchers to apply\nstate-of-the-art AI techniques in their segmentation tasks. The code is\navailable at https://github.com/MMV-Lab/AL_BioMed_img_seg.", "AI": {"tldr": "本文提出了结合主动学习和伪标签的生物医学图像分割方法，减少人工标注需求，维持高性能，解决了现有模型的一些局限性。", "motivation": "动机在于解决现有模型（如nnU-Net）在少有标注数据的情况下效果不佳的问题以及大型基础模型未能在特定数据集上表现出色的局限性。", "method": "本文提出了一种基于数据的人工智能工作流，结合主动学习和伪标签技术，利用传统的神经网络和大型基础模型的优势，尽可能减少人为干预。流程首先利用基础模型生成伪标签，然后用于nnU-Net的自我配置。接着选取代表性核心集进行最小化的人工标注，以便对nnU-Net模型进行有效微调。", "result": "该方法在减少人工标注需求的同时保持了优秀的性能。", "conclusion": "这种方法显著减少了人工标注的需求，同时保持了竞争性的性能，为生物医学研究人员提供了一种可行的解决方案，使其能够应用最先进的AI技术进行分割任务。"}}
{"id": "2511.04698", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04698", "abs": "https://arxiv.org/abs/2511.04698", "authors": ["K M Sajjadul Islam", "John Fields", "Praveen Madiraju"], "title": "multiMentalRoBERTa: A Fine-tuned Multiclass Classifier for Mental Health Disorder", "comment": "Accepted in IEEE Big Data, 8-11 December, 2025 @ Macau SAR, China", "summary": "The early detection of mental health disorders from social media text is\ncritical for enabling timely support, risk assessment, and referral to\nappropriate resources. This work introduces multiMentalRoBERTa, a fine-tuned\nRoBERTa model designed for multiclass classification of common mental health\nconditions, including stress, anxiety, depression, post-traumatic stress\ndisorder (PTSD), suicidal ideation, and neutral discourse. Drawing on multiple\ncurated datasets, data exploration is conducted to analyze class overlaps,\nrevealing strong correlations between depression and suicidal ideation as well\nas anxiety and PTSD, while stress emerges as a broad, overlapping category.\nComparative experiments with traditional machine learning methods,\ndomain-specific transformers, and prompting-based large language models\ndemonstrate that multiMentalRoBERTa achieves superior performance, with macro\nF1-scores of 0.839 in the six-class setup and 0.870 in the five-class setup\n(excluding stress), outperforming both fine-tuned MentalBERT and baseline\nclassifiers. Beyond predictive accuracy, explainability methods, including\nLayer Integrated Gradients and KeyBERT, are applied to identify lexical cues\nthat drive classification, with a particular focus on distinguishing depression\nfrom suicidal ideation. The findings emphasize the effectiveness of fine-tuned\ntransformers for reliable and interpretable detection in sensitive contexts,\nwhile also underscoring the importance of fairness, bias mitigation, and\nhuman-in-the-loop safety protocols. Overall, multiMentalRoBERTa is presented as\na lightweight, robust, and deployable solution for enhancing support in mental\nhealth platforms.", "AI": {"tldr": "研究提出了一种名为multiMentalRoBERTa的微型优化RoBERTa模型，用于从社交媒体文本中检测六种心理健康状况，其表现优于其他模型，并且提供了解释性。", "motivation": "早期检测心理健康情况对于提供及时支持、风险评估和推荐适当资源至关重要。", "method": "此研究介绍了multiMentalRoBERTa模型，该模型是针对常见心理健康状况的多分类问题进行微调的RoBERTa模型，该模型使用多分类别，包括压力、焦虑、抑郁、创伤后应激障碍（PTSD）、自杀意念和中立话语。此外，研究还包括传统机器学习方法、领域特定的transformer模型以及基于提示的大语言模型的对比实验。", "result": "实验结果显示，multiMentalRoBERTa在六分类设置中达到了0.839的宏F1值，在五分类设置中（排除压力）达到了0.870，比微调的MentalBERT和其他基准分类器表现更好。", "conclusion": "研究强调了微调的transformer模型在敏感情境下可靠和可解释的检测中表现出的有效性，同时也强调了公平性、偏见缓解和人机协作安全协议的重要性。"}}
{"id": "2511.04848", "categories": ["cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.04848", "abs": "https://arxiv.org/abs/2511.04848", "authors": ["Manuel Weiß", "Lukas Baumgärtner", "Roland Herzog", "Stephan Schmidt"], "title": "Geometry Denoising with Preferred Normal Vectors", "comment": null, "summary": "We introduce a new paradigm for geometry denoising using prior knowledge\nabout the surface normal vector. This prior knowledge comes in the form of a\nset of preferred normal vectors, which we refer to as label vectors. A\nsegmentation problem is naturally embedded in the denoising process. The\nsegmentation is based on the similarity of the normal vector to the elements of\nthe set of label vectors. Regularization is achieved by a total variation term.\nWe formulate a split Bregman (ADMM) approach to solve the resulting\noptimization problem. The vertex update step is based on second-order shape\ncalculus.", "AI": {"tldr": "本文提出了一种新的几何去噪方法，该方法通过使用表面法线向量的先验知识，基于总变差项进行正则化，并利用分裂Bregman方法求解优化问题。这种方法能够更有效地去除几何噪声。", "motivation": "面对几何噪声问题，传统的去噪方法可能无法充分保留几何表面的本质特征，本文旨在采用新的方法，利用先验的法线向量信息来提高去噪效果。", "method": "本文提出了一种新的几何去噪范式，利用表面法线向量的先验知识。这些先验知识以一组优选的法线向量（称为标签向量）的形式存在。去噪过程中嵌入了一个基于法线向量与标签向量集合中元素相似性的分割问题。通过总变差项实现了正则化。本文采用了分裂Bregman（ADMM）方法来求解优化问题，顶点更新步骤基于二阶形状微积分。", "result": "未提供具体结果，但可以推测出该方法能有效地去除几何噪声，同时保持几何表面的本质特征。", "conclusion": "研究得出，通过使用法线向量的先验知识和有效的优化方法，可以更有效地去除几何噪声。"}}
{"id": "2511.04699", "categories": ["cs.CL", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04699", "abs": "https://arxiv.org/abs/2511.04699", "authors": ["Haneen Al-Homoud", "Asma Ibrahim", "Murtadha Al-Jubran", "Fahad Al-Otaibi", "Yazeed Al-Harbi", "Daulet Toibazar", "Kesen Wang", "Pedro J. Moreno"], "title": "Cross-Lingual SynthDocs: A Large-Scale Synthetic Corpus for Any to Arabic OCR and Document Understanding", "comment": null, "summary": "Cross-Lingual SynthDocs is a large-scale synthetic corpus designed to address\nthe scarcity of Arabic resources for Optical Character Recognition (OCR) and\nDocument Understanding (DU). The dataset comprises over 2.5 million of samples,\nincluding 1.5 million textual data, 270K fully annotated tables, and hundred\nthousands of real data based charts. Our pipeline leverages authentic scanned\nbackgrounds, bilingual layouts, and diacritic aware fonts to capture the\ntypographic and structural complexity of Arabic documents. In addition to text,\nthe corpus includes variety of rendered styles for charts and tables.\nFinetuning Qwen-2.5-VL on SynthDocs yields consistent improvements in Word\nError Rate (WER) and Character Error Rate (CER) in terms of OCR across multiple\npublic Arabic benchmarks, Tree-Edit Distance Similarity (TEDS) and Chart\nExtraction Score (CharTeX) improved as well in other modalities. SynthDocs\nprovides a scalable, visually realistic resource for advancing research in\nmultilingual document analysis.", "AI": {"tldr": "This paper introduces Cross-Lingual SynthDocs, a large synthetic corpus for Arabic OCR and DU, which improves WER, CER, TEDS, and CharTeX when Qwen-2.5-VL is finetuned on it.", "motivation": "The motivation behind this paper is to address the scarcity of Arabic resources for OCR and DU by creating a comprehensive synthetic dataset.", "method": "The method involves generating a large-scale synthetic corpus, Cross-Lingual SynthDocs, for Arabic documents to enhance OCR and DU. This includes using authentic scanned backgrounds, bilingual layouts, and diacritic-aware fonts, with a corpus containing over 2.5 million samples of various types such as texts, fully annotated tables, and charts with real data.", "result": "The results show consistent improvements in WER and CER for OCR, and improvements in TEDS and CharTeX for other modalities when finetuning Qwen-2.5-VL on SynthDocs.", "conclusion": "The conclusion is that SynthDocs, a scalable and visually realistic corpus, effectively advances research in multilingual document analysis for Arabic language resources."}}
{"id": "2511.04864", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2511.04864", "abs": "https://arxiv.org/abs/2511.04864", "authors": ["Kyle Fogarty", "Chenyue Cai", "Jing Yang", "Zhilin Guo", "Cengiz Öztireli"], "title": "Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction", "comment": "Accepted at 3DV 2026", "summary": "Recovering high-quality surfaces from irregular point cloud is ill-posed\nunless strong geometric priors are available. We introduce an implicit\nself-prior approach that distills a shape-specific prior directly from the\ninput point cloud itself and embeds it within an implicit neural\nrepresentation. This is achieved by jointly training a small dictionary of\nlearnable embeddings with an implicit distance field; at every query location,\nthe field attends to the dictionary via cross-attention, enabling the network\nto capture and reuse repeating structures and long-range correlations inherent\nto the shape. Optimized solely with self-supervised point cloud reconstruction\nlosses, our approach requires no external training data. To effectively\nintegrate this learned prior while preserving input fidelity, the trained field\nis then sampled to extract densely distributed points and analytic normals via\nautomatic differentiation. We integrate the resulting dense point cloud and\ncorresponding normals into a robust implicit moving least squares (RIMLS)\nformulation. We show this hybrid strategy preserves fine geometric details in\nthe input data, while leveraging the learned prior to regularize sparse\nregions. Experiments show that our method outperforms both classical and\nlearning-based approaches in generating high-fidelity surfaces with superior\ndetail preservation and robustness to common data degradations.", "AI": {"tldr": "本文提出了一种基于隐式自先验方法来从点云中恢复高质量表面的技术，利用交叉注意力机制进行训练，并通过隐式移动最小二乘方法将提取的密集点云积分，实现了比传统方法更高的细节保留和运行稳健性。", "motivation": "从不规则点云中恢复高质量表面是一个困难的问题，除非有强烈的几何学先验知识。本文的动机是引入一种无需外部训练数据的方法，以生成高保真度表面和保持几何细节的鲁棒性。", "method": "本文提出了一种隐式自先验方法，该方法直接从输入点云中提取形状特定的先验，并将其嵌入到隐式神经表示中。通过联合训练一个可学习嵌入的小词典和一个隐式距离场来实现这一目标。在每个查询位置，字段通过交叉注意力机制与词典交互，使网络能够捕捉并重复使用固有的重复结构和长距离关联。", "result": "实验表明，该方法在生成高保真表面时，在细节保留和对常见数据降级的鲁棒性方面都优于经典方法和基于学习的方法。", "conclusion": "通过自我监督的点云重建损失进行优化，本方法不需要外部训练数据，展现出在处理稀疏区域时利用学习到的先验进行正则化的有效性。"}}
{"id": "2511.04700", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04700", "abs": "https://arxiv.org/abs/2511.04700", "authors": ["Song Wang", "Zihan Chen", "Peng Wang", "Zhepei Wei", "Zhen Tan", "Yu Meng", "Cong Shen", "Jundong Li"], "title": "Separate the Wheat from the Chaff: Winnowing Down Divergent Views in Retrieval Augmented Generation", "comment": "EMNLP Main 2025", "summary": "Retrieval-augmented generation (RAG) enhances large language models (LLMs) by\nintegrating external knowledge sources to address their limitations in\naccessing up-to-date or specialized information. A natural strategy to increase\nthe likelihood of retrieving relevant information is to expand the number of\nretrieved documents. However, involving more documents could introduce\nsignificant noise, as many documents may be irrelevant or misleading, thereby\nreducing the overall accuracy of the generated responses. To overcome the\nchallenge associated with handling a larger number of documents, we propose\nWinnowRAG, a novel RAG framework designed to systematically filter out noisy\ndocuments while preserving valuable content -- a process we refer to as\nwinnowing. WinnowRAG operates in two stages: In Stage I, we perform query-aware\nclustering to group similar documents and form distinct topic clusters. Each\ncluster is assigned to an LLM agent for generating a unique answer. In Stage\nII, we perform winnowing, wherein a critic LLM evaluates the outputs of\nmultiple agents and iteratively separates useful documents from noisy ones. To\nretain useful documents when discarding agents, we propose two strategic\nmerging techniques to ensure that only relevant knowledge is used for\ngenerating the final response. Crucially, WinnowRAG is model-agnostic and does\nnot require any model fine-tuning, making it easily adaptable to various tasks.\nExtensive experiments on various realistic datasets demonstrate the\neffectiveness of WinnowRAG over state-of-the-art baselines.", "AI": {"tldr": "WinnowRAG是一种新的检索增强生成框架，通过系统地过滤噪声文档，提高大型语言模型检索相关信息的准确性。实验表明，WinnowRAG在多个真实数据集上优于现有方法。", "motivation": "文章的主要动机是解决大型语言模型在获取最新或专业信息方面的局限性，通过增加检索文档的数量可能会引入大量无关或误导性信息从而降低响应准确性的挑战。", "method": "WinnowRAG框架分两个阶段操作：第一阶段进行基于查询的聚类形成不同主题的集群并由LLM生成答案；第二阶段由评鉴LLM评估多个LLM生成的输出并进行有用文档和噪音文档的迭代分离。提出两种策略性合并技术，确保仅使用相关知识生成最终响应。", "result": "大量的实验在各种现实数据集上展示了WinnowRAG相对于最先进的基线方法的有效性。", "conclusion": "WinnowRAG作为一个模型不可知的技术，不需对模型进行微调，很容易适应不同的任务，有效提高了响应的准确性。"}}
{"id": "2511.04871", "categories": ["cs.CV", "stat.AP"], "pdf": "https://arxiv.org/pdf/2511.04871", "abs": "https://arxiv.org/abs/2511.04871", "authors": ["Gabriel Girard", "Manon Edde", "Félix Dumais", "Yoan David", "Matthieu Dumont", "Guillaume Theaud", "Jean-Christophe Houde", "Arnaud Boré", "Maxime Descoteaux", "Pierre-Marc Jodoin"], "title": "Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications", "comment": "39 pages, 11 figures", "summary": "Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps\nare effective for assessing neurodegenerative diseases and microstructural\nproperties of white matter in large number of brain conditions. However, DW-MRI\ninherently limits the combination of data from multiple acquisition sites\nwithout harmonization to mitigate scanner-specific biases. While the widely\nused ComBAT method reduces site effects in research, its reliance on linear\ncovariate relationships, homogeneous populations, fixed site numbers, and well\npopulated sites constrains its clinical use. To overcome these limitations, we\npropose Clinical-ComBAT, a method designed for real-world clinical scenarios.\nClinical-ComBAT harmonizes each site independently, enabling flexibility as new\ndata and clinics are introduced. It incorporates a non-linear polynomial data\nmodel, site-specific harmonization referenced to a normative site, and variance\npriors adaptable to small cohorts. It further includes hyperparameter tuning\nand a goodness-of-fit metric for harmonization assessment. We demonstrate its\neffectiveness on simulated and real data, showing improved alignment of\ndiffusion metrics and enhanced applicability for normative modeling.", "AI": {"tldr": "本文提出了一种名为Clinical-ComBAT的新方法，旨在解决ComBAT方法在临床应用中的局限性，这种方法提高了扩散MRI数据在多种临床场景中的标准化和应用效果。", "motivation": "扩散加权MRI派生的标量图可以有效评估神经退行性疾病和大脑各种条件下白质的微观结构属性。然而，DW-MRI在多数据采集点的数据组合上遇到了困难，这是在没有标准化以减轻特定扫描仪偏差的情况下。虽然广泛使用的ComBAT方法在研究中减少了站点效应，但其依赖线性协变量关系、同质人群、固定数量的站点和超额填满站点的限制，使得其在临床使用上受到约束。", "method": "我们提出了一种名为Clinical-ComBAT的方法来克服这些问题。Clinical-ComBAT独立地对每个站点进行标准化，允许在引入新的数据和诊所时具有灵活性。它采用了非线性多项式数据模型，并根据一个规范站点进行站点特定的标准化。该方法还包括适应小队列的方差先验估计、超参数调整和用于评估标准化质量的良好拟合指标。", "result": "我们在模拟数据和真实数据上展示了其有效性，表明扩散指标更好地对齐并且在规范建模中具有更强的应用性。", "conclusion": "临床实战证明，Clinical-ComBAT方法不仅可以有效对齐扩散指标，还增强了其在特定神经退行性疾病分析中的应用能力。"}}
{"id": "2511.04703", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.04703", "abs": "https://arxiv.org/abs/2511.04703", "authors": ["Andrew M. Bean", "Ryan Othniel Kearns", "Angelika Romanou", "Franziska Sofia Hafner", "Harry Mayne", "Jan Batzner", "Negar Foroutan", "Chris Schmitz", "Karolina Korgul", "Hunar Batra", "Oishi Deb", "Emma Beharry", "Cornelius Emde", "Thomas Foster", "Anna Gausen", "María Grandury", "Simeng Han", "Valentin Hofmann", "Lujain Ibrahim", "Hazel Kim", "Hannah Rose Kirk", "Fangru Lin", "Gabrielle Kaili-May Liu", "Lennart Luettgau", "Jabez Magomere", "Jonathan Rystrøm", "Anna Sotnikova", "Yushi Yang", "Yilun Zhao", "Adel Bibi", "Antoine Bosselut", "Ronald Clark", "Arman Cohan", "Jakob Foerster", "Yarin Gal", "Scott A. Hale", "Inioluwa Deborah Raji", "Christopher Summerfield", "Philip H. S. Torr", "Cozmin Ududec", "Luc Rocher", "Adam Mahdi"], "title": "Measuring what Matters: Construct Validity in Large Language Model Benchmarks", "comment": "39th Conference on Neural Information Processing Systems (NeurIPS\n  2025) Track on Datasets and Benchmarks", "summary": "Evaluating large language models (LLMs) is crucial for both assessing their\ncapabilities and identifying safety or robustness issues prior to deployment.\nReliably measuring abstract and complex phenomena such as 'safety' and\n'robustness' requires strong construct validity, that is, having measures that\nrepresent what matters to the phenomenon. With a team of 29 expert reviewers,\nwe conduct a systematic review of 445 LLM benchmarks from leading conferences\nin natural language processing and machine learning. Across the reviewed\narticles, we find patterns related to the measured phenomena, tasks, and\nscoring metrics which undermine the validity of the resulting claims. To\naddress these shortcomings, we provide eight key recommendations and detailed\nactionable guidance to researchers and practitioners in developing LLM\nbenchmarks.", "AI": {"tldr": "研究团队审查了顶级会议中关于大型语言模型的基准，发现了一些能够影响其有效性的模式，并提出了改进LLM基准开发的具体建议。", "motivation": "对大型语言模型进行可靠的评估对于评估其能力并在部署前识别安全或鲁棒性问题至关重要。这项研究旨在提高度量标准的构建效度，即确保度量标准能够准确反映相关现象。", "method": "通过29位专家评审者对来自自然语言处理和机器学习顶级会议的445个大型语言模型（LLM）基准进行系统的审查，以评估这些模型的能力并找出安全或鲁棒性问题。", "result": "审查发现，测量现象、任务和评分标准等方面存在一些模式，这些问题削弱了相关主张的有效性。", "conclusion": "为了应对这些问题，提出了八个关键建议和详细的行动指南，以供研究人员和从业人员在开发LLM基准时参考。"}}
