<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 18]
- [cs.CV](#cs.CV) [Total: 15]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Shop-R1: Rewarding LLMs to Simulate Human Behavior in Online Shopping via Reinforcement Learning](https://arxiv.org/abs/2507.17842)
*Yimeng Zhang,Tian Wang,Jiri Gesi,Ziyi Wang,Yuxuan Lu,Jiacheng Lin,Sinong Zhan,Vianne Gao,Ruochen Jiao,Junze Liu,Kun Qian,Yuxin Tang,Ran Xue,Houyu Zhang,Qingjun Cui,Yufan Guo,Dakuo Wang*

Main category: cs.CL

> 本研究提出Shop-R1框架以改善大型语言模型在模拟线上购物环境中人类行为时的推理能力，通过自监督的推理过程和分层奖励结构来实现。实验表明，相比基线模型，本方法相对提升了65%以上。

<details>
  <summary>Details</summary>

**Motivation:** 先前的研究已经探索通过增强训练数据和应用监督微调来提高模型的推理能力，从而改善下游行为预测。然而，利用模型生成的理由的方法性能本质上受生成这些理由的模型推理能力的限制。为了突破这个限制，本研究提出了新的框架Shop-R1，以提高大型语言模型的推理能力，更好地模拟人类行为。

**Method:** 本研究提出了一个名为Shop-R1的新型强化学习框架，旨在提高大型语言模型在模拟线上购物环境中人类行为时的推理能力。Shop-R1将人类行为模拟任务分解为两个阶段：理由生成和行为预测，每个阶段都由不同的奖励信号引导。在理由生成阶段，利用内部模型信号（例如，logit分布）以自监督的方式引导推理过程。在行为预测阶段，提出了一种具有难度感知缩放的分层奖励结构，以防止奖励作弊并实现详细的奖励分配。这种设计评估了高层行为类型和精细动作细节（属性和值）的正确性，并根据其难度比例奖励输出。

**Result:** 实验结果显示，本方法相较于基线模型获得了超过65%的相对提升。

**Conclusion:** Shop-R1框架通过引入自监督的推理过程和防止奖励作弊的分层奖励结构，显著提高了大型语言模型在模拟人类行为时的表现。这种方法在提升模型推理能力方面显示出了巨大潜力。

**Abstract:** Large Language Models (LLMs) have recently demonstrated strong potential in
generating 'believable human-like' behavior in web environments. Prior work has
explored augmenting training data with LLM-synthesized rationales and applying
supervised fine-tuning (SFT) to enhance reasoning ability, which in turn can
improve downstream action prediction. However, the performance of such
approaches remains inherently bounded by the reasoning capabilities of the
model used to generate the rationales. In this paper, we introduce Shop-R1, a
novel reinforcement learning (RL) framework aimed at enhancing the reasoning
ability of LLMs for simulation of real human behavior in online shopping
environments Specifically, Shop-R1 decomposes the human behavior simulation
task into two stages: rationale generation and action prediction, each guided
by distinct reward signals. For rationale generation, we leverage internal
model signals (e.g., logit distributions) to guide the reasoning process in a
self-supervised manner. For action prediction, we propose a hierarchical reward
structure with difficulty-aware scaling to prevent reward hacking and enable
fine-grained reward assignment. This design evaluates both high-level action
types and the correctness of fine-grained sub-action details (attributes and
values), rewarding outputs proportionally to their difficulty. Experimental
results show that our method achieves a relative improvement of over 65%
compared to the baseline.

</details>


### [2] [Dynamic and Generalizable Process Reward Modeling](https://arxiv.org/abs/2507.17849)
*Zhangyue Yin,Qiushi Sun,Zhiyuan Zeng,Qinyuan Cheng,Xipeng Qiu,Xuanjing Huang*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Process Reward Models (PRMs) are crucial for guiding Large Language Models
(LLMs) in complex scenarios by providing dense reward signals. However,
existing PRMs primarily rely on heuristic approaches, which struggle with
cross-domain generalization. While LLM-as-judge has been proposed to provide
generalized rewards, current research has focused mainly on feedback results,
overlooking the meaningful guidance embedded within the text. Additionally,
static and coarse-grained evaluation criteria struggle to adapt to complex
process supervision. To tackle these challenges, we propose Dynamic and
Generalizable Process Reward Modeling (DG-PRM), which features a reward tree to
capture and store fine-grained, multi-dimensional reward criteria. DG-PRM
dynamically selects reward signals for step-wise reward scoring. To handle
multifaceted reward signals, we pioneeringly adopt Pareto dominance estimation
to identify discriminative positive and negative pairs. Experimental results
show that DG-PRM achieves stunning performance on prevailing benchmarks,
significantly boosting model performance across tasks with dense rewards.
Further analysis reveals that DG-PRM adapts well to out-of-distribution
scenarios, demonstrating exceptional generalizability.

</details>


### [3] [VeriMinder: Mitigating Analytical Vulnerabilities in NL2SQL](https://arxiv.org/abs/2507.17896)
*Shubham Mohole,Sainyam Galhotra*

Main category: cs.CL

> VeriMinder 是一个交互式系统，旨在帮助用户在使用自然语言接口进行数据分析时检测和缓解认知偏见，并通过三大创新实现这一目标，包括语义映射框架、系统化的数据分析指导和优化的LLM驱动系统。用户测试显示其显著提升了分析的质量。

<details>
  <summary>Details</summary>

**Motivation:** 随着自然语言接口在数据库应用系统中的普及，非统计学背景的用户面临着提出无偏见的分析问题的挑战。研究多集中在提高文本到SQL的转换准确度，而在分析问题中的认知偏见方面仍有待探索。

**Method:** VeriMinder 采用三个主要创新：语义映射框架为特定分析环境定义偏差，实现系统化数据分析的方法论框架，以及通过多候选、批评反馈和自我反思过程生成高质量、任务特定提示的优化的LLM驱动系统。

**Result:** 在用户测试中，82.5%的参与者认为该系统正面影响了分析的质量。在对比评估中，VeriMinder 在分析的明确性、全面性和准确性方面的得分比其他方法至少高出20%。系统作为网络应用程序实现，旨在帮助用户在数据分析中避免提出“错误的问题”。

**Conclusion:** VeriMinder 以开放源码的形式提供，有助于社区进一步的研究和使用。它在帮助用户提出无偏差的分析问题方面做出了显著贡献。

**Abstract:** Application systems using natural language interfaces to databases (NLIDBs)
have democratized data analysis. This positive development has also brought
forth an urgent challenge to help users who might use these systems without a
background in statistical analysis to formulate bias-free analytical questions.
Although significant research has focused on text-to-SQL generation accuracy,
addressing cognitive biases in analytical questions remains underexplored. We
present VeriMinder, https://veriminder.ai, an interactive system for detecting
and mitigating such analytical vulnerabilities. Our approach introduces three
key innovations: (1) a contextual semantic mapping framework for biases
relevant to specific analysis contexts (2) an analytical framework that
operationalizes the Hard-to-Vary principle and guides users in systematic data
analysis (3) an optimized LLM-powered system that generates high-quality,
task-specific prompts using a structured process involving multiple candidates,
critic feedback, and self-reflection.
  User testing confirms the merits of our approach. In direct user experience
evaluation, 82.5% participants reported positively impacting the quality of the
analysis. In comparative evaluation, VeriMinder scored significantly higher
than alternative approaches, at least 20% better when considered for metrics of
the analysis's concreteness, comprehensiveness, and accuracy. Our system,
implemented as a web application, is set to help users avoid "wrong question"
vulnerability during data analysis. VeriMinder code base with prompts,
https://reproducibility.link/veriminder, is available as an MIT-licensed
open-source software to facilitate further research and adoption within the
community.

</details>


### [4] [One Whisper to Grade Them All](https://arxiv.org/abs/2507.17918)
*Nhan Phan,Anusha Porwal,Yaroslav Getman,Ekaterina Voskoboinik,Tamás Grósz,Mikko Kurimo*

Main category: cs.CL

> The paper presents an efficient end-to-end Automatic Speaking Assessment system using a single encoder for multi-part language tests, achieving better results than baselines with fewer parameters.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to develop an end-to-end system for holistic Automatic Speaking Assessment (ASA) of multi-part second-language tests that is efficient, practical, and scalable for Computer-Assisted Language Learning systems.

**Method:** Our system uses a single Whisper-small encoder to process all four spoken responses and a lightweight aggregator to combine the information and predict the final score. This avoids the need for transcription and separate models for each part of the test.

**Result:** The system achieved a RMSE of 0.384, outperforming the text-based baseline while using fewer parameters. It also demonstrates good data efficiency with a data sampling strategy.

**Conclusion:** The proposed system effectively reduces inference time, outperforms a text-based baseline, and shows strong performance when trained with a subset of the speakers, demonstrating the effectiveness and efficiency of the method.

**Abstract:** We present an efficient end-to-end approach for holistic Automatic Speaking
Assessment (ASA) of multi-part second-language tests, developed for the 2025
Speak & Improve Challenge. Our system's main novelty is the ability to process
all four spoken responses with a single Whisper-small encoder, combine all
information via a lightweight aggregator, and predict the final score. This
architecture removes the need for transcription and per-part models, cuts
inference time, and makes ASA practical for large-scale Computer-Assisted
Language Learning systems.
  Our system achieved a Root Mean Squared Error (RMSE) of 0.384, outperforming
the text-based baseline (0.44) while using at most 168M parameters (about 70%
of Whisper-small). Furthermore, we propose a data sampling strategy, allowing
the model to train on only 44.8% of the speakers in the corpus and still reach
0.383 RMSE, demonstrating improved performance on imbalanced classes and strong
data efficiency.

</details>


### [5] [Evaluating the Performance of AI Text Detectors, Few-Shot and Chain-of-Thought Prompting Using DeepSeek Generated Text](https://arxiv.org/abs/2507.17944)
*Hulayyil Alshammari,Praveen Rao*

Main category: cs.CL

> 研究对象是六个公开的AI检测工具对DeepSeek生成文本的检测能力，特别是遭受humanization这类攻击后的表现，发现QuillBot和Copyleaks在原始和改写文本检测上有良好表现，GPT2和AI Text Classifier则表现不稳定。DeepSeek使用few-shot和CoT提示对文本分类展现出较高准确性。

<details>
  <summary>Details</summary>

**Motivation:** 当前大多数研究主要集中在知名的LLM如ChatGPT上，而DeepSeek作为一个新公布的语言模型，其生成文本的检测成为研究空白。本研究旨在探索六种公开的AI检测工具能否准确识别DeepSeek生成的文本，特别是在遭受对手攻击时的表现。

**Method:** 本研究通过使用六个可获取的AI检测工具对DeepSeek生成的文本进行检测，这些工具分别是AI Text Classifier、Content Detector AI、Copyleaks、QuillBot、GPT-2和GPTZero。此外，研究还使用了DeepSeek自身的few-shot prompting和链式思维推理(CoT)对AI和人类撰写的文本进行分类。

**Result:** QuillBot和Copyleaks在原始和改写的DeepSeek文本上表现出近乎完美的性能，但其他工具如AI Text Classifier和GPT-2的结果则不够稳定。最有效的攻击手段是humanization，它将Copyleaks的准确率降至71%，QuillBot降至58%，GPTZero降至52%。同时，few-shot和CoT提示方法展示了较高的准确率，特别是在五次射击中仅误判了一次样本，AI召回率为96%，人类召回率为100%。

**Conclusion:** 研究表明，多数AI检测工具在识别DeepSeek的改写和humanization文本时存在挑战，特别是依赖于GPT-2的工具表现不佳。而five-shot CoT方法展现了高准确率，表明它可能是识别DeepSeek文本的有效方法。

**Abstract:** Large language models (LLMs) have rapidly transformed the creation of written
materials. LLMs have led to questions about writing integrity, thereby driving
the creation of artificial intelligence (AI) detection technologies.
Adversarial attacks, such as standard and humanized paraphrasing, inhibit
detectors' ability to detect machine-generated text. Previous studies have
mainly focused on ChatGPT and other well-known LLMs and have shown varying
accuracy across detectors. However, there is a clear gap in the literature
about DeepSeek, a recently published LLM. Therefore, in this work, we
investigate whether six generally accessible AI detection tools -- AI Text
Classifier, Content Detector AI, Copyleaks, QuillBot, GPT-2, and GPTZero -- can
consistently recognize text generated by DeepSeek. The detectors were exposed
to the aforementioned adversarial attacks. We also considered DeepSeek as a
detector by performing few-shot prompting and chain-of-thought reasoning (CoT)
for classifying AI and human-written text. We collected 49 human-authored
question-answer pairs from before the LLM era and generated matching responses
using DeepSeek-v3, producing 49 AI-generated samples. Then, we applied
adversarial techniques such as paraphrasing and humanizing to add 196 more
samples. These were used to challenge detector robustness and assess accuracy
impact. While QuillBot and Copyleaks showed near-perfect performance on
original and paraphrased DeepSeek text, others -- particularly AI Text
Classifier and GPT-2 -- showed inconsistent results. The most effective attack
was humanization, reducing accuracy to 71% for Copyleaks, 58% for QuillBot, and
52% for GPTZero. Few-shot and CoT prompting showed high accuracy, with the best
five-shot result misclassifying only one of 49 samples (AI recall 96%, human
recall 100%).

</details>


### [6] [Are LLM Belief Updates Consistent with Bayes' Theorem?](https://arxiv.org/abs/2507.17951)
*Sohaib Imran,Ihor Kendiukhov,Matthew Broerman,Aditya Thomas,Riccardo Campanella,Rob Lamb,Peter M. Atkinson*

Main category: cs.CL

> 研究发现更大、更强大的语言模型在更新信念方面更加符合贝叶斯定理。

<details>
  <summary>Details</summary>

**Motivation:** 研究更大的、能力更强的语言模型在面对上下文证据时是否能更一致地遵循贝叶斯定理更新其关于命题的'信念'。

**Method:** 我们提出了一种贝叶斯一致系数（BCC）指标，并生成了相应的数据集来测量BCC。

**Result:** 结果表明，更大的和更强大的预训练语言模型在分配概率时更符合贝叶斯定理。

**Conclusion:** 这些结果对我们理解和管理语言模型具有重要意义。

**Abstract:** Do larger and more capable language models learn to update their "beliefs"
about propositions more consistently with Bayes' theorem when presented with
evidence in-context? To test this, we formulate a Bayesian Coherence
Coefficient (BCC) metric and generate a dataset with which to measure the BCC.
We measure BCC for multiple pre-trained-only language models across five model
families, comparing against the number of model parameters, the amount of
training data, and model scores on common benchmarks. Our results provide
evidence for our hypothesis that larger and more capable pre-trained language
models assign credences that are more coherent with Bayes' theorem. These
results have important implications for our understanding and governance of
LLMs.

</details>


### [7] [Natural Language Processing for Tigrinya: Current State and Future Directions](https://arxiv.org/abs/2507.17974)
*Fitsum Gaim,Jong C. Park*

Main category: cs.CL

> 论文综述了提格烈尼亚语的NLP研究，涵盖了十年以上的研究成果，分析了资源创建的里程碑对研究进展的影响，并指出了主要挑战和研究方向。

<details>
  <summary>Details</summary>

**Motivation:** 研究提格烈尼亚语这种虽然被数百万人使用，但在自然语言处理（NLP）研究中代表性不足的语言。

**Method:** 该论文通过系统性回顾2011年至2025年超过40项研究，分析了提格烈尼亚语在计算资源、模型和应用程序在内的十个不同下游任务中的当前状态。

**Result:** 研究表明，从基于规则的基础系统到现代神经架构有一个清晰的发展轨迹，资源创建的里程碑一直是推动研究进展的关键。研究识别了提格烈尼亚语在形态复杂性和资源稀缺性方面的主要挑战，并提出了有前景的研究方向。

**Conclusion:** 该工作不仅为研究人员提供了一个全面的参考，而且为推进提格烈尼亚语NLP提供了路线图。

**Abstract:** Despite being spoken by millions of people, Tigrinya remains severely
underrepresented in Natural Language Processing (NLP) research. This work
presents a comprehensive survey of NLP research for Tigrinya, analyzing over 40
studies spanning more than a decade of work from 2011 to 2025. We
systematically review the current state of computational resources, models, and
applications across ten distinct downstream tasks, including morphological
processing, machine translation, speech recognition, and question-answering.
Our analysis reveals a clear trajectory from foundational, rule-based systems
to modern neural architectures, with progress consistently unlocked by resource
creation milestones. We identify key challenges rooted in Tigrinya's
morphological complexity and resource scarcity, while highlighting promising
research directions, including morphology-aware modeling, cross-lingual
transfer, and community-centered resource development. This work serves as both
a comprehensive reference for researchers and a roadmap for advancing Tigrinya
NLP. A curated metadata of the surveyed studies and resources is made publicly
available.\footnote{Tigrinya NLP Anthology:
https://github.com/fgaim/tigrinya-nlp-anthology.

</details>


### [8] [Technical Report of TeleChat2, TeleChat2.5 and T1](https://arxiv.org/abs/2507.18013)
*Zihan Wang,Xinzhang Liu,Yitong Yao,Chao Wang,Yu Zhao,Zhihao Yang,Wenmin Deng,Kaipeng Jia,Jiaxin Peng,Yuyao Huang,Sishi Xiong,Zhuo Jiang,Kaidong Yu,Xiaohui Hu,Fubei Yao,Ruiyu Fang,Zhuoru Jiang,Ruiting Song,Qiyi Xie,Rui Xue,Xuewei He,Yanlei Xue,Zhu Yuan,Zhaoxi Zhang,Zilu Huang,Shiquan Wang,Xin Wang,Hanming Wu,Mingyuan Wang,Xufeng Zhan,Yuhan Sun,Zhaohu Xing,Yuhao Jiang,Bingkai Yang,Shuangyong Song,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

> 本论文介绍了TeleChat系列的最新模型TeleChat2, TeleChat2.5和T1，通过对训练策略的改进而提升了性能，尤其在复杂推理和代码生成方面。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过改进训练策略而不是改变模型架构来提升语言模型的性能，尤其是在代码生成和数学推理任务上。

**Method:** 首先通过大规模高质量数据进行预训练，随后进行监督微调和直接偏好优化。T1和TeleChat2.5进一步通过持续预训练和强化学习提升特定领域的性能。

**Result:** T1在复杂推理和数学、代码任务上表现出色，而TeleChat2.5则更注重推理速度。

**Conclusion:** TeleChat系列的最新模型展示了显著的推理能力提升，并且已经公开发布，以支持开发者和研究人员的应用。

**Abstract:** We introduce the latest series of TeleChat models: \textbf{TeleChat2},
\textbf{TeleChat2.5}, and \textbf{T1}, offering a significant upgrade over
their predecessor, TeleChat. Despite minimal changes to the model architecture,
the new series achieves substantial performance gains through enhanced training
strategies in both pre-training and post-training stages. The series begins
with \textbf{TeleChat2}, which undergoes pretraining on 10 trillion
high-quality and diverse tokens. This is followed by Supervised Fine-Tuning
(SFT) and Direct Preference Optimization (DPO) to further enhance its
capabilities. \textbf{TeleChat2.5} and \textbf{T1} expand the pipeline by
incorporating a continual pretraining phase with domain-specific datasets,
combined with reinforcement learning (RL) to improve performance in code
generation and mathematical reasoning tasks. The \textbf{T1} variant is
designed for complex reasoning, supporting long Chain-of-Thought (CoT)
reasoning and demonstrating substantial improvements in mathematics and coding.
In contrast, \textbf{TeleChat2.5} prioritizes speed, delivering rapid
inference. Both flagship models of \textbf{T1} and \textbf{TeleChat2.5} are
dense Transformer-based architectures with 115B parameters, showcasing
significant advancements in reasoning and general task performance compared to
the original TeleChat. Notably, \textbf{T1-115B} outperform proprietary models
such as OpenAI's o1-mini and GPT-4o. We publicly release \textbf{TeleChat2},
\textbf{TeleChat2.5} and \textbf{T1}, including post-trained versions with 35B
and 115B parameters, to empower developers and researchers with
state-of-the-art language models tailored for diverse applications.

</details>


### [9] [NeuralDB: Scaling Knowledge Editing in LLMs to 100,000 Facts with Neural KV Database](https://arxiv.org/abs/2507.18028)
*Weizhi Fei,Hao Shi,Jing Xu,Jingchen Peng,Jiazheng Li,Jingzhao Zhang,Bo Bai,Wei Han,Zhenyuan Chen,Xueyan Niu*

Main category: cs.CL

> NeuralDB is a novel editing framework for large language models that uses a neural KV database and a gated retrieval module to enhance editing efficacy without compromising the model's general abilities, demonstrating success in scaling up to 100,000 facts.

<details>
  <summary>Details</summary>

**Motivation:** To enable efficient editing of large language models without compromising their general abilities or resulting in forgetting edited facts when scaling up the number of edits.

**Method:** NeuralDB, a framework that represents edited facts as a neural Key-Value database with a non-linear gated retrieval module, ensuring the preservation of the LLM's general abilities when editing.

**Result:** NeuralDB outperforms existing methods in editing efficacy, generalization, specificity, fluency, and consistency. It preserves the overall performance across various text understanding and generation tasks and maintains effectiveness even when scaling to 100,000 facts.

**Conclusion:** NeuralDB effectively addresses the challenges of large-scale fact editing in LLMs, ensuring that their general abilities are preserved without significant degradation in performance.

**Abstract:** Efficiently editing knowledge stored in large language models (LLMs) enables
model updates without large-scale training. One possible solution is
Locate-and-Edit (L\&E), allowing simultaneous modifications of a massive number
of facts. However, such editing may compromise the general abilities of LLMs
and even result in forgetting edited facts when scaling up to thousands of
edits. In this paper, we model existing linear L\&E methods as querying a
Key-Value (KV) database. From this perspective, we then propose NeuralDB, an
editing framework that explicitly represents the edited facts as a neural KV
database equipped with a non-linear gated retrieval module, % In particular,
our gated module only operates when inference involves the edited facts,
effectively preserving the general abilities of LLMs. Comprehensive experiments
involving the editing of 10,000 facts were conducted on the ZsRE and
CounterFacts datasets, using GPT2-XL, GPT-J (6B) and Llama-3 (8B). The results
demonstrate that NeuralDB not only excels in editing efficacy, generalization,
specificity, fluency, and consistency, but also preserves overall performance
across six representative text understanding and generation tasks. Further
experiments indicate that NeuralDB maintains its effectiveness even when scaled
to 100,000 facts (\textbf{50x} more than in prior work).

</details>


### [10] [GrAInS: Gradient-based Attribution for Inference-Time Steering of LLMs and VLMs](https://arxiv.org/abs/2507.18043)
*Duy Nguyen,Archiki Prasad,Elias Stengel-Eskin,Mohit Bansal*

Main category: cs.CL

> GrAInS是一种在推理时间调整语言模型和视觉语言模型行为的方法，通过识别最有影响力的令牌并构造方向性引导向量来改进模型的行为，这种方法在无需重新训练模型的情况下提供了精细、可解释且具有模块化特性的模型行为控制。

<details>
  <summary>Details</summary>

**Motivation:** 现有的推理时间引导方法依赖于不变的、全局的干预向量，忽视了单个输入令牌的因果影响，且未能善加利用模型logits中的有用梯度，特别是在视觉和文本输入贡献不均的多模态场景下。

**Method:** GrAInS通过对比性和基于梯度的归因方法来识别最有影响力的top-k个令牌，依据它们对优选或非优选输出的贡献，并构建方向性引导向量以捕捉从不理想到理想行为的语义变化。在推理过程中，GrAInS根据令牌级归因信号调整变压器层中的隐藏激活，并对激活进行归一化处理以保持表示尺度。

**Result:** 实验结果显示，相较于微调和其他现有引导基线，GrAInS在多个评估任务和模型中表现出更高的性能，例如在TruthfulQA任务中使用Llama-3.1-8B时获得了13.22%的准确性提升。

**Conclusion:** GrAInS提供了一种无需重新训练或辅助监督即可进行精细、可解释和模块化模型行为控制的方法，实验表明这种方法在多种任务和评估指标上均优于现有的微调和引导方法。

**Abstract:** Inference-time steering methods offer a lightweight alternative to
fine-tuning large language models (LLMs) and vision-language models (VLMs) by
modifying internal activations at test time without updating model weights.
However, most existing approaches rely on fixed, global intervention vectors,
overlook the causal influence of individual input tokens, and fail to leverage
informative gradients from the model's logits, particularly in multimodal
settings where visual and textual inputs contribute unevenly. To address these
limitations, we introduce GrAInS, an inference-time steering approach that
operates across both language-only and vision-language models and tasks. GrAInS
uses contrastive, gradient-based attribution via Integrated Gradients to
identify the top-k most influential tokens, both positively and negatively
attributed based on their contribution to preferred versus dispreferred
outputs. These tokens are then used to construct directional steering vectors
that capture semantic shifts from undesirable to desirable behavior. During
inference, GrAInS adjusts hidden activations at transformer layers guided by
token-level attribution signals, and normalizes activations to preserve
representational scale. This enables fine-grained, interpretable, and modular
control over model behavior, without retraining or auxiliary supervision.
Empirically, GrAInS consistently outperforms both fine-tuning and existing
steering baselines: it achieves a 13.22% accuracy gain on TruthfulQA using
Llama-3.1-8B, reduces hallucination rates on MMHal-Bench from 0.624 to 0.514
with LLaVA-1.6-7B, and improves alignment win rates on SPA-VL by 8.11%, all
while preserving the model's fluency and general capabilities.

</details>


### [11] [Synthetic Data Generation for Phrase Break Prediction with Large Language Model](https://arxiv.org/abs/2507.18044)
*Hoyeon Lee,Sejung Son,Ye-Eun Kang,Jong-Hwan Kim*

Main category: cs.CL

> 通过使用大型语言模型生成合成短语断点注释，减少文本转语音系统中的手动注释需求并改善语音相关任务的处理效果。

<details>
  <summary>Details</summary>

**Motivation:** 减少文本转语音系统中手动注释的需求，同时解决语音领域内在变化带来的问题

**Method:** 利用大型语言模型生成合成短语断点注释，并将其与传统注释进行比较

**Result:** 发现基于大型语言模型的合成数据生成方法能够有效地缓解短语断点预测的数据挑战

**Conclusion:** 大型语言模型作为生成合成数据的方法在语音领域显示出潜力。

**Abstract:** Current approaches to phrase break prediction address crucial prosodic
aspects of text-to-speech systems but heavily rely on vast human annotations
from audio or text, incurring significant manual effort and cost. Inherent
variability in the speech domain, driven by phonetic factors, further
complicates acquiring consistent, high-quality data. Recently, large language
models (LLMs) have shown success in addressing data challenges in NLP by
generating tailored synthetic data while reducing manual annotation needs.
Motivated by this, we explore leveraging LLM to generate synthetic phrase break
annotations, addressing the challenges of both manual annotation and
speech-related tasks by comparing with traditional annotations and assessing
effectiveness across multiple languages. Our findings suggest that LLM-based
synthetic data generation effectively mitigates data challenges in phrase break
prediction and highlights the potential of LLMs as a viable solution for the
speech domain.

</details>


### [12] [Privacy-Preserving Synthetic Review Generation with Diverse Writing Styles Using LLMs](https://arxiv.org/abs/2507.18055)
*Tevin Atwal,Chan Nam Tieu,Yefeng Yuan,Zhan Shi,Yuhong Liu,Liang Cheng*

Main category: cs.CL

> 本文针对由大规模语言模型生成的合成文本数据，提出了一套量化评估其多样性和隐私风险的指标，并通过实验揭示了这些模型生成多样化且保护隐私的合成数据的局限性，最终提出了一种基于提示的方法来提高合成评论的多样性同时保护评论者的隐私。

<details>
  <summary>Details</summary>

**Motivation:** 随着大规模语言模型生成的合成数据在数据驱动的应用中越来越受欢迎，其多样性和隐私风险尚未被充分探索。本文旨在通过专门的评估指标来量化合成文本数据的这些方面。

**Method:** 本文提出了一整套指标来评估合成数据集的多样性（包括语言表达、情感和用户视角）和隐私风险（包括重新识别风险和风格异常）。

**Result:** 实验结果显示，目前最先进的大规模语言模型生成的合成数据存在多样性和隐私保护方面的显著局限性。

**Conclusion:** 基于实验结果，本文提出了一种基于提示的方法以提高合成评论的多样性，同时确保用户的隐私。

**Abstract:** The increasing use of synthetic data generated by Large Language Models
(LLMs) presents both opportunities and challenges in data-driven applications.
While synthetic data provides a cost-effective, scalable alternative to
real-world data to facilitate model training, its diversity and privacy risks
remain underexplored. Focusing on text-based synthetic data, we propose a
comprehensive set of metrics to quantitatively assess the diversity (i.e.,
linguistic expression, sentiment, and user perspective), and privacy (i.e.,
re-identification risk and stylistic outliers) of synthetic datasets generated
by several state-of-the-art LLMs. Experiment results reveal significant
limitations in LLMs' capabilities in generating diverse and privacy-preserving
synthetic data. Guided by the evaluation results, a prompt-based approach is
proposed to enhance the diversity of synthetic reviews while preserving
reviewer privacy.

</details>


### [13] [TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios](https://arxiv.org/abs/2507.18061)
*Zehan Li,Hongjie Chen,Yuxin Zhang,Jing Zhou,Xuening Wang,Hang Lv,Mengjie Du,Yaodong Song,Jie Lian,Jian Kang,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.CL

> 本文提出了TELEVAl，一种专为评估中文环境下SLM对话能力而设计的动态基准。通过三个维度评估模型表现：显性语义、副语言和隐性语义、系统能力。实验表明现有模型仍需改进。

<details>
  <summary>Details</summary>

**Motivation:** 大多数现有的基准测试主要是评估SLM是否能执行类似于大型语言模型处理的任务，常与用户在现实世界中自然交互的方式不一致。

**Method:** 提出TELEVAl，这是一个动态基准测试，旨在评估SLM在现实中文交互场景中的有效性。TELEVAl定义了三个评估维度：显性语义、副语言和隐性语义、系统能力。它采用与现实世界使用一致的对话格式，并分别评估文本和音频输出。重点是模型能够从用户言语中提取隐含线索并适当回应的能力，无需额外指令。

**Result:** 实验表明，尽管近期有进展，现有的SLM在自然对话任务上仍有很大的改进空间。

**Conclusion:** 希望TELEVAl可以作为一个以用户为中心的评估框架，直接反映用户体验，有助于开发出更强大、面向对话的SLM。

**Abstract:** Spoken language models (SLMs) have seen rapid progress in recent years, along
with the development of numerous benchmarks for evaluating their performance.
However, most existing benchmarks primarily focus on evaluating whether SLMs
can perform complex tasks comparable to those tackled by large language models
(LLMs), often failing to align with how users naturally interact in real-world
conversational scenarios. In this paper, we propose TELEVAL, a dynamic
benchmark specifically designed to evaluate SLMs' effectiveness as
conversational agents in realistic Chinese interactive settings. TELEVAL
defines three evaluation dimensions: Explicit Semantics, Paralinguistic and
Implicit Semantics, and System Abilities. It adopts a dialogue format
consistent with real-world usage and evaluates text and audio outputs
separately. TELEVAL particularly focuses on the model's ability to extract
implicit cues from user speech and respond appropriately without additional
instructions. Our experiments demonstrate that despite recent progress,
existing SLMs still have considerable room for improvement in natural
conversational tasks. We hope that TELEVAL can serve as a user-centered
evaluation framework that directly reflects the user experience and contributes
to the development of more capable dialogue-oriented SLMs.

</details>


### [14] [Hybrid and Unitary Fine-Tuning of Large Language Models: Methods and Benchmarking under Resource Constraints](https://arxiv.org/abs/2507.18076)
*Haomin Qi,Zihan Dai,Chengbo Huang*

Main category: cs.CL

> A hybrid PEFT method is introduced that combines BOFT and LoRA-GA techniques, and adds uRNN principles to enhance gradient stability for efficient large language model fine-tuning with lower resource use.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the computational bottleneck of fine-tuning large language models, which includes high scale and memory demands. The aim is to find an efficient fine-tuning method that can reduce resource consumption while maintaining or improving performance quality.

**Method:** The paper introduces a hybrid strategy that dynamically integrates BOFT's orthogonal stability with LoRA-GA's gradient-aligned rapid convergence. It also adapts uRNN principles to transformer-based LLMs for enhanced gradient stability.

**Result:** The hybrid method achieves superior convergence efficiency and generalization across diverse tasks with a reduction of up to 2.1 times in training time and 50 percent in memory usage compared to full fine-tuning while maintaining high accuracy.

**Conclusion:** The hybrid method outperforms individual PEFT baselines and approaches full fine-tuning accuracy with significant reductions in training time and memory usage. It is considered a practical and scalable fine-tuning solution for LLMs deployed under resource constraints.

**Abstract:** Fine-tuning large language models (LLMs) remains a computational bottleneck
due to their scale and memory demands. This paper presents a comprehensive
evaluation of parameter-efficient fine-tuning (PEFT) techniques, including
LoRA, BOFT, LoRA-GA, and uRNN, and introduces a novel hybrid strategy that
dynamically integrates BOFT's orthogonal stability with LoRA-GA's
gradient-aligned rapid convergence. By computing per-layer adaptive updates
guided by gradient norms, the hybrid method achieves superior convergence
efficiency and generalization across diverse tasks. We also explore, for the
first time, the adaptation of unitary RNN (uRNN) principles to
transformer-based LLMs, enhancing gradient stability through structured unitary
constraints. Empirical evaluations on four benchmarks -- GLUE, GSM8K, MT-Bench,
and HumanEval -- using models ranging from 7B to 405B parameters demonstrate
that our hybrid method consistently outperforms individual PEFT baselines,
approaching full fine-tuning accuracy while reducing resource consumption by up
to 2.1 times in training time and 50 percent in memory usage. These findings
establish the hybrid approach as a practical and scalable fine-tuning solution
for real-world deployment of LLMs under resource constraints.

</details>


### [15] [A New Pair of GloVes](https://arxiv.org/abs/2507.18103)
*Riley Carlson,John Bauer,Christopher D. Manning*

Main category: cs.CL

> 本报告介绍了新的2024年版GloVe模型，它使用了更新的数据集训练，并且在文档化和模型性能上有所提升，特别是在处理当前内容相关的词汇任务上表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 由于2014年版的GloVe模型虽然被广泛使用，但语言和世界一直在变化，新的用法可能从中受益。并且2014年的模型没有详细记录所用的数据版本和预处理步骤，本研究对此进行了补充。

**Method:** 本研究使用了Wikipedia、Gigaword以及Dolma的一部分数据集来训练两组词嵌入模型，并通过词汇对比、直接测试和命名实体识别（NER）任务对这些新模型进行了评估。

**Result:** 评估结果显示，2024年版的词向量模型包含了新的文化及语言相关的词汇，并且在结构任务如类比和相似度测试中表现良好，尤其在非西方新闻数据集的NER任务上表现优于之前的数据集。

**Conclusion:** 2024年版的GloVe模型不仅更好地捕捉了语言的变化，而且通过详尽的文档化，让模型的使用更加透明和可靠。

**Abstract:** This report documents, describes, and evaluates new 2024 English GloVe
(Global Vectors for Word Representation) models. While the original GloVe
models built in 2014 have been widely used and found useful, languages and the
world continue to evolve and we thought that current usage could benefit from
updated models. Moreover, the 2014 models were not carefully documented as to
the exact data versions and preprocessing that were used, and we rectify this
by documenting these new models. We trained two sets of word embeddings using
Wikipedia, Gigaword, and a subset of Dolma. Evaluation through vocabulary
comparison, direct testing, and NER tasks shows that the 2024 vectors
incorporate new culturally and linguistically relevant words, perform
comparably on structural tasks like analogy and similarity, and demonstrate
improved performance on recent, temporally dependent NER datasets such as
non-Western newswire data.

</details>


### [16] [GOAT-SLM: A Spoken Language Model with Paralinguistic and Speaker Characteristic Awareness](https://arxiv.org/abs/2507.18119)
*Hongjie Chen,Zehan Li,Yaodong Song,Wenming Deng,Yitong Yao,Yuxin Zhang,Hang Lv,Xuechao Zhu,Jian Kang,Jie Lian,Jie Li,Chao Wang,Shuangyong Song,Yongxiang Li,Zhongjiang He*

Main category: cs.CL

> GOAT-SLM是一个具备伴随语言和说话人特征意识的新型语音语言模型，采用双模式头部架构和分阶段训练策略，以提升语言理解和语音生成的表达性与适应性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大部分模型仅将语音视为传递语言内容的载体，忽视了人类语音中嵌入的丰富伴随语言和说话人特征线索。为了克服这一局限性，提出了GOAT-SLM，以扩展语音语言建模的范围，超出文本语义的范畴。

**Method:** GOAT-SLM采用双模式头部架构，将语言建模与声学实现解耦，从而实现稳健的语言理解和表达性、适应性的语音生成。此外，还提出了一种分阶段的训练策略，通过大规模语音-文本语料库逐渐对齐语言、伴随语言和说话人特征信息。

**Result:** 实验结果表明，GOAT-SLM在TELEVAL多维评估基准上实现了平衡出色的性能，涵盖了语义和非语义任务，并在处理情感、方言变异和与年龄相关的交互方面优于现有的开源模型。

**Conclusion:** 这项工作强调了建模超越语言内容的重要性，并推进了更自然、更具适应性和社交意识的语音语言系统的发展。

**Abstract:** Recent advances in end-to-end spoken language models (SLMs) have
significantly improved the ability of AI systems to engage in natural spoken
interactions. However, most existing models treat speech merely as a vehicle
for linguistic content, often overlooking the rich paralinguistic and speaker
characteristic cues embedded in human speech, such as dialect, age, emotion,
and non-speech vocalizations. In this work, we introduce GOAT-SLM, a novel
spoken language model with paralinguistic and speaker characteristic awareness,
designed to extend spoken language modeling beyond text semantics. GOAT-SLM
adopts a dual-modality head architecture that decouples linguistic modeling
from acoustic realization, enabling robust language understanding while
supporting expressive and adaptive speech generation. To enhance model
efficiency and versatility, we propose a modular, staged training strategy that
progressively aligns linguistic, paralinguistic, and speaker characteristic
information using large-scale speech-text corpora. Experimental results on
TELEVAL, a multi-dimensional evaluation benchmark, demonstrate that GOAT-SLM
achieves well-balanced performance across both semantic and non-semantic tasks,
and outperforms existing open-source models in handling emotion, dialectal
variation, and age-sensitive interactions. This work highlights the importance
of modeling beyond linguistic content and advances the development of more
natural, adaptive, and socially aware spoken language systems.

</details>


### [17] [MathOPEval: A Fine-grained Evaluation Benchmark for Visual Operations of MLLMs in Mathematical Reasoning](https://arxiv.org/abs/2507.18140)
*Xiaoyuan Li,Moxin Li,Wenjie Wang,Rui Men,Yichang Zhang,Fuli Feng,Dayiheng Liu,Junyang Lin*

Main category: cs.CL

> 研究提出了一种评估MLLM多模态数学推理能力的方法，专注于评估模型通过代码进行视觉操作的能力，结果表明现有模型在这方面落后于人类。

<details>
  <summary>Details</summary>

**Motivation:** 现有的评估主要集中在仅基于文本的推理输出上，忽视了MLLM通过代码执行精确视觉操作的能力。

**Method:** 使用代码作为中间表示来精确表达和操纵图像中的推理步骤。

**Result:** 实验结果表明，现有的模型在执行细粒度的视觉操作方面仍然远远落后于人类的表现。

**Conclusion:** 研究提出了一个框架，用于评估MLLM在多模态数学推理中基于代码的能力，指出了模型在执行细粒度视觉操作方面的不足。

**Abstract:** Recent progress in Multi-modal Large Language Models (MLLMs) has enabled
step-by-step multi-modal mathematical reasoning by performing visual operations
based on the textual instructions. A promising approach uses code as an
intermediate representation to precisely express and manipulate the images in
the reasoning steps. However, existing evaluations focus mainly on text-only
reasoning outputs, leaving the MLLM's ability to perform accurate visual
operations via code largely unexplored. This work takes a first step toward
addressing that gap by evaluating MLLM's code-based capabilities in multi-modal
mathematical reasoning.Specifically, our framework focuses on two key
evaluation aspects: (1) Multi-modal Code Generation (MCG) evaluates the model's
ability to accurately understand and construct visualizations from scratch. (2)
Multi-modal Code Editing (MCE) assesses the model's capacity for fine-grained
operations, which include three types: Deletion, Modification and Annotation.
To evaluate the above tasks, we incorporate a dataset that covers the five most
popular types of mathematical figures, including geometric diagrams, function
plots, and three types of statistical charts, to provide a comprehensive and
effective measurement of existing MLLMs. Our experimental evaluation involves
nine mainstream MLLMs, and the results reveal that existing models still lag
significantly behind human performance in performing fine-grained visual
operations.

</details>


### [18] [HIVMedQA: Benchmarking large language models for HIV medical decision support](https://arxiv.org/abs/2507.18143)
*Gonzalo Cardenal Antolin,Jacques Fellay,Bashkim Jaha,Roger Kouyos,Niko Beerenwinkel,Diane Duroux*

Main category: cs.CL

> 本研究通过对LLMs在HIV管理中的表现进行全面评估，提出了HIVMedQA基准测试，结果显示在特定临床情境中，某些专有模型表现更优。

<details>
  <summary>Details</summary>

**Motivation:** 研究目的是评估LLM在HIV管理中的当前能力，特别是在复杂性情境下的应用。考虑到HIV管理的复杂性、多种治疗选择、合并症和遵循挑战，研究希望能通过评估揭示LLM在临床应用中的优势和局限。

**Method:** 本研究设计了一个名为HIVMedQA的基准测试，用于评估在HIV护理中的开放式医学问题回答。研究使用了七个通用型和三个医学专业化的LLM，并通过提示工程技术来提升性能。评估框架结合了词法相似度和“LLM作为评判者”的方法，扩展了临床相关性的反映。

**Result:** 研究发现，Gemini 2.5 Pro在大多数维度上表现最佳。值得注意的是，排名前三位的模型中有两个是专有的。随着问题复杂性的增加，性能下降。专门调整用于医学的模型并不总是优于通用型模型，而模型规模更大的也不总是性能更好。此外，推理和理解能力相比于事实回想更具挑战性，并观察到了如最近认知偏见和现状偏见的认知偏差。

**Conclusion:** 研究强调了为了确保LLM的安全性和有效性整合到临床护理中，必须有目标地进行开发和评估。尽管LLM在HIV管理中有潜力成为一个有价值的支持工具，但在临床应用中仍需关注其准确性和潜在的风险。

**Abstract:** Large language models (LLMs) are emerging as valuable tools to support
clinicians in routine decision-making. HIV management is a compelling use case
due to its complexity, including diverse treatment options, comorbidities, and
adherence challenges. However, integrating LLMs into clinical practice raises
concerns about accuracy, potential harm, and clinician acceptance. Despite
their promise, AI applications in HIV care remain underexplored, and LLM
benchmarking studies are scarce. This study evaluates the current capabilities
of LLMs in HIV management, highlighting their strengths and limitations. We
introduce HIVMedQA, a benchmark designed to assess open-ended medical question
answering in HIV care. The dataset consists of curated, clinically relevant
questions developed with input from an infectious disease physician. We
evaluated seven general-purpose and three medically specialized LLMs, applying
prompt engineering to enhance performance. Our evaluation framework
incorporates both lexical similarity and an LLM-as-a-judge approach, extended
to better reflect clinical relevance. We assessed performance across key
dimensions: question comprehension, reasoning, knowledge recall, bias,
potential harm, and factual accuracy. Results show that Gemini 2.5 Pro
consistently outperformed other models across most dimensions. Notably, two of
the top three models were proprietary. Performance declined as question
complexity increased. Medically fine-tuned models did not always outperform
general-purpose ones, and larger model size was not a reliable predictor of
performance. Reasoning and comprehension were more challenging than factual
recall, and cognitive biases such as recency and status quo were observed.
These findings underscore the need for targeted development and evaluation to
ensure safe, effective LLM integration in clinical care.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [19] [Lumina-mGPT 2.0: Stand-Alone AutoRegressive Image Modeling](https://arxiv.org/abs/2507.17801)
*Yi Xin,Juncheng Yan,Qi Qin,Zhen Li,Dongyang Liu,Shicheng Li,Victor Shea-Jay Huang,Yupeng Zhou,Renrui Zhang,Le Zhuo,Tiancheng Han,Xiaoqing Sun,Siqi Luo,Mengmeng Wang,Bin Fu,Yuewen Cao,Hongsheng Li,Guangtao Zhai,Xiaohong Liu,Yu Qiao,Peng Gao*

Main category: cs.CV

> Lumina-mGPT 2.0 是一个独立的、仅解码的自回归模型，专门用于高质量图像生成及其他任务。该模型从零开始训练，具有无限制的架构设计和许可证自由。它在生成质量上与DALL-E 3和SANA等领先的扩散模型相当，同时保持了自回归建模灵活性和组成性。通过统一的标记方案，它能够处理包括主题驱动生成、图像编辑、可控合成和密集预测等任务。此外，增加高效的解码策略进一步提升质量和速度。它在标准的文本到图像基准测试上表现优秀，并在多任务能力上有出色表现。

<details>
  <summary>Details</summary>

**Motivation:** 推动图像生成和其他任务的高质量和灵活性，同时解决现有依赖于预训练组件或混合架构的方法的限制。Lumina-mGPT 2.0旨在提供一个不受约束的架构设计和许可证自由度，同时保持与顶级扩散模型相当的生成质量。

**Method:** Lumina-mGPT 2.0是一个自回归模型，使用统一的标记方案进行训练，可以从零开始，不依赖预训练组件或混构结构。该方法采用了高效的解码策略，如推理时尺度和投机性的雅克比采样，以提高质量和速度。

**Result:** Lumina-mGPT 2.0在标准的文本到图像基准测试和Graph200K基准上表现良好，不仅与扩散模型相匹敌，在某些情况下甚至超过了它们，证明了其作为统一多模式生成基础模型的潜力。

**Conclusion:** Lumina-mGPT 2.0是一个强大的、灵活的统一多模态生成基础模型，它展示了通过自回归模型实现高质量图像生成和执行多种任务的能力。通过开放训练细节、代码和模型，进一步推动了本领域的研究和应用。

**Abstract:** We present Lumina-mGPT 2.0, a stand-alone, decoder-only autoregressive model
that revisits and revitalizes the autoregressive paradigm for high-quality
image generation and beyond. Unlike existing approaches that rely on pretrained
components or hybrid architectures, Lumina-mGPT 2.0 is trained entirely from
scratch, enabling unrestricted architectural design and licensing freedom. It
achieves generation quality on par with state-of-the-art diffusion models such
as DALL-E 3 and SANA, while preserving the inherent flexibility and
compositionality of autoregressive modeling. Our unified tokenization scheme
allows the model to seamlessly handle a wide spectrum of tasks-including
subject-driven generation, image editing, controllable synthesis, and dense
prediction-within a single generative framework. To further boost usability, we
incorporate efficient decoding strategies like inference-time scaling and
speculative Jacobi sampling to improve quality and speed, respectively.
Extensive evaluations on standard text-to-image benchmarks (e.g., GenEval, DPG)
demonstrate that Lumina-mGPT 2.0 not only matches but in some cases surpasses
diffusion-based models. Moreover, we confirm its multi-task capabilities on the
Graph200K benchmark, with the native Lumina-mGPT 2.0 performing exceptionally
well. These results position Lumina-mGPT 2.0 as a strong, flexible foundation
model for unified multimodal generation. We have released our training details,
code, and models at https://github.com/Alpha-VLLM/Lumina-mGPT-2.0.

</details>


### [20] [SV3.3B: A Sports Video Understanding Model for Action Recognition](https://arxiv.org/abs/2507.17844)
*Sai Varun Kodathala,Yashwanth Reddy Vutukoori,Rakesh Vunnam*

Main category: cs.CV

> 提出了SV3.3B，一个轻量级的视频理解模型，用以解决传统自动体育视频分析中计算密集型模型和缺乏精细运动理解的问题。该模型在NSVA篮球数据集的子集上评估，展示了能够生成技术详细和分析丰富的体育描述的能力，优于较大的闭源模型如GPT-4o变种模型。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决自动化体育视频分析中模型计算量大、需服务器端处理以及缺乏对运动生物力学细微过渡的理解等问题。

**Method:** SV3.3B模型结合了新颖的时域运动差异采样和自监督学习，并采用DWT-VGG16-LDA机制提取关键帧，使用V-DWT-JEPA2编码器和LLM解码器进行预训练和针对体育动作描述生成的微调。

**Result:** 在NSVA篮球数据集的子集上进行评估，展示了比GPT-4o更高的性能，特别是在技术细节和动作复杂度方面有显著改善。

**Conclusion:** SV3.3B模型在生成技术详细和分析丰富的体育描述方面表现优越，优于较大的闭源模型，并且具有更低的计算需求。

**Abstract:** This paper addresses the challenge of automated sports video analysis, which
has traditionally been limited by computationally intensive models requiring
server-side processing and lacking fine-grained understanding of athletic
movements. Current approaches struggle to capture the nuanced biomechanical
transitions essential for meaningful sports analysis, often missing critical
phases like preparation, execution, and follow-through that occur within
seconds. To address these limitations, we introduce SV3.3B, a lightweight 3.3B
parameter video understanding model that combines novel temporal motion
difference sampling with self-supervised learning for efficient on-device
deployment. Our approach employs a DWT-VGG16-LDA based keyframe extraction
mechanism that intelligently identifies the 16 most representative frames from
sports sequences, followed by a V-DWT-JEPA2 encoder pretrained through
mask-denoising objectives and an LLM decoder fine-tuned for sports action
description generation. Evaluated on a subset of the NSVA basketball dataset,
SV3.3B achieves superior performance across both traditional text generation
metrics and sports-specific evaluation criteria, outperforming larger
closed-source models including GPT-4o variants while maintaining significantly
lower computational requirements. Our model demonstrates exceptional capability
in generating technically detailed and analytically rich sports descriptions,
achieving 29.2% improvement over GPT-4o in ground truth validation metrics,
with substantial improvements in information density, action complexity, and
measurement precision metrics essential for comprehensive athletic analysis.
Model Available at https://huggingface.co/sportsvision/SV3.3B.

</details>


### [21] [Detail++: Training-Free Detail Enhancer for Text-to-Image Diffusion Models](https://arxiv.org/abs/2507.17853)
*Lifeng Chen,Jiner Wang,Zihao Pan,Beier Zhu,Xiaofeng Yang,Chi Zhang*

Main category: cs.CV

> The paper proposes Detail++, a training-free framework for text-to-image generation that uses a Progressive Detail Injection (PDI) strategy to handle complex prompts with multiple subjects and distinct attributes.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the difficulty of current text-to-image generation models in handling complex prompts with multiple subjects and attributes.

**Method:** Detail++ decomposes complex prompts into a sequence of simplified sub-prompts, using a staged generation approach that first ensures global composition and then refines details, leveraging the layout-controlling capacity of self-attention and cross-attention mechanisms with a Centroid Alignment Loss for accurate attribute binding.

**Result:** The experiments on T2I-CompBench and a new style composition benchmark show that Detail++ outperforms existing methods, especially in scenarios with multiple objects and complex styles.

**Conclusion:** The paper concludes that the proposed Detail++ framework effectively improves the performance of text-to-image generation in complex prompt scenarios, demonstrating the potential of staged detail injection and attribute alignment mechanisms.

**Abstract:** Recent advances in text-to-image (T2I) generation have led to impressive
visual results. However, these models still face significant challenges when
handling complex prompt, particularly those involving multiple subjects with
distinct attributes. Inspired by the human drawing process, which first
outlines the composition and then incrementally adds details, we propose
Detail++, a training-free framework that introduces a novel Progressive Detail
Injection (PDI) strategy to address this limitation. Specifically, we decompose
a complex prompt into a sequence of simplified sub-prompts, guiding the
generation process in stages. This staged generation leverages the inherent
layout-controlling capacity of self-attention to first ensure global
composition, followed by precise refinement. To achieve accurate binding
between attributes and corresponding subjects, we exploit cross-attention
mechanisms and further introduce a Centroid Alignment Loss at test time to
reduce binding noise and enhance attribute consistency. Extensive experiments
on T2I-CompBench and a newly constructed style composition benchmark
demonstrate that Detail++ significantly outperforms existing methods,
particularly in scenarios involving multiple objects and complex stylistic
conditions.

</details>


### [22] [FishDet-M: A Unified Large-Scale Benchmark for Robust Fish Detection and CLIP-Guided Model Selection in Diverse Aquatic Visual Domains](https://arxiv.org/abs/2507.17859)
*Muayad Abujabal,Lyes Saad Saoud,Irfan Hussain*

Main category: cs.CV

> 本研究提出了FishDet-M，一个用于鱼类检测的最大统一数据集，并评估了不同模型的性能，同时引入了一种零样本的模型选择框架，提高了系统适应性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机在于现有的鱼类检测技术由于数据集零散、成像条件各异和评估协议不一致而难以实际部署。

**Method:** 我们提出了FishDet-M，这是一个用于鱼类检测的最大统一基准，包含13个公开数据集，涵盖了多种水生环境。所有的数据都采用COCO样式的标注，包括边界框和分割掩模，以实现一致性和规模化的跨域评估。我们系统地评估了28种现代目标检测模型，包括YOLOv8到YOLOv12系列、基于R-CNN的检测器和基于DETR的模型。

**Result:** 结果表明，通过FishDet-M训练的不同模型展现出各异的检测性能，并揭示了不同架构模型在精度和效率之间的权衡。通过引入一种基于CLIP的模型选择框架，利用视觉-语言对齐来动态识别最适合每个输入图像的检测器，我们实现了高效率的性能，且无需进行集成计算。

**Conclusion:** FishDet-M为复杂水下场景的对象检测提供了一个标准化和可复现的平台。所有的数据集、预训练模型和评估工具都已公开，促进了未来水下计算机视觉和智能海洋系统的研究。

**Abstract:** Accurate fish detection in underwater imagery is essential for ecological
monitoring, aquaculture automation, and robotic perception. However, practical
deployment remains limited by fragmented datasets, heterogeneous imaging
conditions, and inconsistent evaluation protocols. To address these gaps, we
present \textit{FishDet-M}, the largest unified benchmark for fish detection,
comprising 13 publicly available datasets spanning diverse aquatic environments
including marine, brackish, occluded, and aquarium scenes. All data are
harmonized using COCO-style annotations with both bounding boxes and
segmentation masks, enabling consistent and scalable cross-domain evaluation.
We systematically benchmark 28 contemporary object detection models, covering
the YOLOv8 to YOLOv12 series, R-CNN based detectors, and DETR based models.
Evaluations are conducted using standard metrics including mAP, mAP@50, and
mAP@75, along with scale-specific analyses (AP$_S$, AP$_M$, AP$_L$) and
inference profiling in terms of latency and parameter count. The results
highlight the varying detection performance across models trained on FishDet-M,
as well as the trade-off between accuracy and efficiency across models of
different architectures. To support adaptive deployment, we introduce a
CLIP-based model selection framework that leverages vision-language alignment
to dynamically identify the most semantically appropriate detector for each
input image. This zero-shot selection strategy achieves high performance
without requiring ensemble computation, offering a scalable solution for
real-time applications. FishDet-M establishes a standardized and reproducible
platform for evaluating object detection in complex aquatic scenes. All
datasets, pretrained models, and evaluation tools are publicly available to
facilitate future research in underwater computer vision and intelligent marine
systems.

</details>


### [23] [Towards Facilitated Fairness Assessment of AI-based Skin Lesion Classifiers Through GenAI-based Image Synthesis](https://arxiv.org/abs/2507.17860)
*Ko Watanabe. Stanislav Frolov. Adriano Lucieri. Andreas Dengel*

Main category: cs.CV

> 研究利用LightningDiT模型评估黑色素瘤分类器的公平性，发现合成数据在公平性评估中很有前景，但不同训练数据集下的模型会带来验证上的挑战。

<details>
  <summary>Details</summary>

**Motivation:** 该研究的主要动机是评估和提高应用于皮肤癌筛查中的AI系统的公平性，特别是考虑到潜在的未预见和固有的偏见。

**Method:** 本研究利用了最先进的生成式人工智能（GenAI）LightningDiT模型来评估公开的黑色素瘤分类器的公平性。

**Result:** 研究结果表明，使用高度逼真的合成数据进行公平性评估是一个有前景的方向。然而，当用于评估的黑色素瘤检测模型是基于与合成图像数据集不同的数据集训练时，验证公平性就变得困难。

**Conclusion:** 我们提出的方法为利用合成数据来衡量和增强医学成像GenAI系统的公平性提供了一个有价值的途径。

**Abstract:** Recent advancements in Deep Learning and its application on the edge hold
great potential for the revolution of routine screenings for skin cancers like
Melanoma. Along with the anticipated benefits of this technology, potential
dangers arise from unforseen and inherent biases. Thus, assessing and improving
the fairness of such systems is of utmost importance. A key challenge in
fairness assessment is to ensure that the evaluation dataset is sufficiently
representative of different Personal Identifiable Information (PII) (sex, age,
and race) and other minority groups. Against the backdrop of this challenge,
this study leverages the state-of-the-art Generative AI (GenAI) LightningDiT
model to assess the fairness of publicly available melanoma classifiers. The
results suggest that fairness assessment using highly realistic synthetic data
is a promising direction. Yet, our findings indicate that verifying fairness
becomes difficult when the melanoma-detection model used for evaluation is
trained on data that differ from the dataset underpinning the synthetic images.
Nonetheless, we propose that our approach offers a valuable new avenue for
employing synthetic data to gauge and enhance fairness in medical-imaging GenAI
systems.

</details>


### [24] [DiNAT-IR: Exploring Dilated Neighborhood Attention for High-Quality Image Restoration](https://arxiv.org/abs/2507.17892)
*Hanzhou Liu,Binghan Li,Chengkai Liu,Mi Lu*

Main category: cs.CV

> 本文提出DiNAT-IR，一种结合滑动窗口注意力与混合扩张因子的Transformer架构，实现了全局上下文与局部细节的平衡，适用于图像修复任务，表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于传统的基于通道的自注意力机制在处理高分辨率图像时面临计算成本过高的问题，本文旨在提出一种新的注意力机制来平衡全局上下文理解与局部细节精准度，以实现高效的图像复原效果。

**Method:** DiNAT-IR 采用通道感知模块结合局部注意力机制来集成全局上下文，这是一款针对图像恢复任务的Transformer架构。

**Result:** 提出的DiNAT-IR在多个基准数据集中取得了具有竞争力的结果。

**Conclusion:** 研究结果表明，结合局部注意力机制与全局上下文理解的DiNAT-IR是解决低层次视觉问题提供了一种高效且高质量的解决方案。

**Abstract:** Transformers, with their self-attention mechanisms for modeling long-range
dependencies, have become a dominant paradigm in image restoration tasks.
However, the high computational cost of self-attention limits scalability to
high-resolution images, making efficiency-quality trade-offs a key research
focus. To address this, Restormer employs channel-wise self-attention, which
computes attention across channels instead of spatial dimensions. While
effective, this approach may overlook localized artifacts that are crucial for
high-quality image restoration. To bridge this gap, we explore Dilated
Neighborhood Attention (DiNA) as a promising alternative, inspired by its
success in high-level vision tasks. DiNA balances global context and local
precision by integrating sliding-window attention with mixed dilation factors,
effectively expanding the receptive field without excessive overhead. However,
our preliminary experiments indicate that directly applying this global-local
design to the classic deblurring task hinders accurate visual restoration,
primarily due to the constrained global context understanding within local
attention. To address this, we introduce a channel-aware module that
complements local attention, effectively integrating global context without
sacrificing pixel-level precision. The proposed DiNAT-IR, a Transformer-based
architecture specifically designed for image restoration, achieves competitive
results across multiple benchmarks, offering a high-quality solution for
diverse low-level computer vision problems.

</details>


### [25] [AFRDA: Attentive Feature Refinement for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2507.17957)
*Md. Al-Masrur Khan,Durgakant Pushp,Lantao Liu*

Main category: cs.CV

> 提出了一种自适应特征细化(AFR)模块，以解决UDA-SS中的分割问题，它通过不确定驱动注意力平衡局部和全局信息，增强了细粒度结构和边界信息，从而提高分割性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的UDA-SS方法往往难以平衡细粒度局部细节和全局上下文信息，导致复杂区域的分割错误。

**Method:** AFR模块通过使用来自低分辨率logits的语义先验来细化高分辨率特征，从而增强分割准确性。AFR还结合了捕获细粒度结构和提供关键边界信息的高频分量，改善了物体描绘。此外，AFR通过不确定驱动注意力自适应地平衡局部和全局信息，减少了误分类。其轻量级设计允许无缝集成到基于HRDA的UDA方法中。

**Result:** 在GTA V-->Cityscapes和Synthia-->Cityscapes上，分割性能(mIoU)分别提高了1.05%和1.04%。

**Conclusion:** AFR模块改进了现有的UDA-SS方法的分割性能，达到了新的状态。

**Abstract:** In Unsupervised Domain Adaptive Semantic Segmentation (UDA-SS), a model is
trained on labeled source domain data (e.g., synthetic images) and adapted to
an unlabeled target domain (e.g., real-world images) without access to target
annotations. Existing UDA-SS methods often struggle to balance fine-grained
local details with global contextual information, leading to segmentation
errors in complex regions. To address this, we introduce the Adaptive Feature
Refinement (AFR) module, which enhances segmentation accuracy by refining
highresolution features using semantic priors from low-resolution logits. AFR
also integrates high-frequency components, which capture fine-grained
structures and provide crucial boundary information, improving object
delineation. Additionally, AFR adaptively balances local and global information
through uncertaintydriven attention, reducing misclassifications. Its
lightweight design allows seamless integration into HRDA-based UDA methods,
leading to state-of-the-art segmentation performance. Our approach improves
existing UDA-SS methods by 1.05% mIoU on GTA V --> Cityscapes and 1.04% mIoU on
Synthia-->Cityscapes. The implementation of our framework is available at:
https://github.com/Masrur02/AFRDA

</details>


### [26] [OPEN: A Benchmark Dataset and Baseline for Older Adult Patient Engagement Recognition in Virtual Rehabilitation Learning Environments](https://arxiv.org/abs/2507.17959)
*Ali Abedi,Sadaf Safa,Tracey J. F. Colella,Shehroz S. Khan*

Main category: cs.CV

> OPEN数据集支持AI驱动的老年人参与度识别，是一个包含11位老年人在六个星期内的虚拟学习会话产生的35小时数据的大型数据集。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的动机在于，现有针对老年人在虚拟和远程医疗学习环境中参与度的研究和数据集非常有限，并且现有方法往往忽视了参与度的背景相关性和跨会话的纵向性质。通过引入OPEN数据集，作者旨在为老年人的参与度建模和更广泛地参与度识别研究提供一个可扩展的基础。

**Method:** 此论文介绍了OPEN数据集，这是一个专为老年人在虚拟和远程医疗学习环境中参与度识别而设计的数据集。数据集通过在六周内每周对11位老年人进行虚拟小组学习会话来收集，生成了超过35小时的数据，是同类最大的数据集。为了保护隐私，未公开原始视频，而是提供了从视频中提取的面部、手部和身体关节标记，以及情感和行为特征。

**Result:** 使用多个机器学习和深度学习模型进行了训练，实现了最高81%的参与度识别准确率。

**Conclusion:** 该数据集对老年人群参与度的个性化模型提供了可扩展的基础，推动了更广泛的参与度识别研究。

**Abstract:** Engagement in virtual learning is essential for participant satisfaction,
performance, and adherence, particularly in online education and virtual
rehabilitation, where interactive communication plays a key role. Yet,
accurately measuring engagement in virtual group settings remains a challenge.
There is increasing interest in using artificial intelligence (AI) for
large-scale, real-world, automated engagement recognition. While engagement has
been widely studied in younger academic populations, research and datasets
focused on older adults in virtual and telehealth learning settings remain
limited. Existing methods often neglect contextual relevance and the
longitudinal nature of engagement across sessions. This paper introduces OPEN
(Older adult Patient ENgagement), a novel dataset supporting AI-driven
engagement recognition. It was collected from eleven older adults participating
in weekly virtual group learning sessions over six weeks as part of cardiac
rehabilitation, producing over 35 hours of data, making it the largest dataset
of its kind. To protect privacy, raw video is withheld; instead, the released
data include facial, hand, and body joint landmarks, along with affective and
behavioral features extracted from video. Annotations include binary engagement
states, affective and behavioral labels, and context-type indicators, such as
whether the instructor addressed the group or an individual. The dataset offers
versions with 5-, 10-, 30-second, and variable-length samples. To demonstrate
utility, multiple machine learning and deep learning models were trained,
achieving engagement recognition accuracy of up to 81 percent. OPEN provides a
scalable foundation for personalized engagement modeling in aging populations
and contributes to broader engagement recognition research.

</details>


### [27] [Bearded Dragon Activity Recognition Pipeline: An AI-Based Approach to Behavioural Monitoring](https://arxiv.org/abs/2507.17987)
*Arsen Yermukan,Pedro Machado,Feliciano Domingos,Isibor Kennedy Ihianle,Jordan J. Bird,Stefano S. K. Kaburu,Samantha J. Ward*

Main category: cs.CV

> 本研究开发了一个自动化的食火鸡龙行为分析系统，使用YOLO模型识别其行为。虽然在检测狩猎行为上存在一定挑战，但该系统提高了效率和数据准确度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的食火鸡龙行为监控是耗时且容易出错的。本项目引入了一种自动化系统以进行实时视频分析，用以提高监控效率和数据质量。

**Method:** 使用You Only Look Once (YOLO)对象检测模型对食火鸡龙（Pogona Viticeps）的两个关键行为：晒太阳和狩猎，进行了实时视频分析。训练了五个YOLO变体（v5, v7, v8, v11, v12）在一个包含600张食火鸡龙图像、500张加热灯图像和100张蟋蟀图像的自定义公开数据集上。检测出来的对象坐标通过帧提取，时间插值确保连续性，并使用规则逻辑分类特定行为。

**Result:** YOLOv8s模型因其在准确性和速度之间的优越平衡被选为最佳模型（mAP@0.5:0.95=0.855）。晒太阳行为检测的可靠性较好，而狩猎行为检测相对不那么准确，主要是因为蟋蟀检测的准确性较低（mAP@0.5=0.392）。

**Conclusion:** 该自动化系统为受控环境下的爬行动物行为监控提供了一种可扩展的解决方案，大大提高了研究效率和数据质量。

**Abstract:** Traditional monitoring of bearded dragon (Pogona Viticeps) behaviour is
time-consuming and prone to errors. This project introduces an automated system
for real-time video analysis, using You Only Look Once (YOLO) object detection
models to identify two key behaviours: basking and hunting. We trained five
YOLO variants (v5, v7, v8, v11, v12) on a custom, publicly available dataset of
1200 images, encompassing bearded dragons (600), heating lamps (500), and
crickets (100). YOLOv8s was selected as the optimal model due to its superior
balance of accuracy (mAP@0.5:0.95 = 0.855) and speed. The system processes
video footage by extracting per-frame object coordinates, applying temporal
interpolation for continuity, and using rule-based logic to classify specific
behaviours. Basking detection proved reliable. However, hunting detection was
less accurate, primarily due to weak cricket detection (mAP@0.5 = 0.392).
Future improvements will focus on enhancing cricket detection through expanded
datasets or specialised small-object detectors. This automated system offers a
scalable solution for monitoring reptile behaviour in controlled environments,
significantly improving research efficiency and data quality.

</details>


### [28] [AG-VPReID.VIR: Bridging Aerial and Ground Platforms for Video-based Visible-Infrared Person Re-ID](https://arxiv.org/abs/2507.17995)
*Huy Nguyen,Kien Nguyen,Akila Pemasiri,Akmal Jahan,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

> 提出AG-VPReID.VIR数据集和TCC-VPReID框架，解决空地跨视角和RGB-IR跨模态行人重识别挑战。

<details>
  <summary>Details</summary>

**Motivation:** 为解决地面红外系统在遮挡、覆盖范围有限和易受阻塞等问题，提出了AG-VPReID.VIR，这是一个首个空地跨模态视频行人重识别数据集。

**Method:** 介绍了一种名为TCC-VPReID的三流架构，旨在解决跨平台和跨模态行人重识别的联合挑战，通过风格鲁棒特征学习、基于记忆的跨视图适应和中间指导时间建模来缩小空域和模态差异。

**Result:** 通过实验展示了所提数据集和方法的有效性，证明方法在多种评估协议中性能优异。

**Conclusion:** 实验表明AG-VPReID.VIR数据集相较于现有数据集具独特挑战，TCC-VPReID框架在多种评估协议中显著提高性能。

**Abstract:** Person re-identification (Re-ID) across visible and infrared modalities is
crucial for 24-hour surveillance systems, but existing datasets primarily focus
on ground-level perspectives. While ground-based IR systems offer nighttime
capabilities, they suffer from occlusions, limited coverage, and vulnerability
to obstructions--problems that aerial perspectives uniquely solve. To address
these limitations, we introduce AG-VPReID.VIR, the first aerial-ground
cross-modality video-based person Re-ID dataset. This dataset captures 1,837
identities across 4,861 tracklets (124,855 frames) using both UAV-mounted and
fixed CCTV cameras in RGB and infrared modalities. AG-VPReID.VIR presents
unique challenges including cross-viewpoint variations, modality discrepancies,
and temporal dynamics. Additionally, we propose TCC-VPReID, a novel
three-stream architecture designed to address the joint challenges of
cross-platform and cross-modality person Re-ID. Our approach bridges the domain
gaps between aerial-ground perspectives and RGB-IR modalities, through
style-robust feature learning, memory-based cross-view adaptation, and
intermediary-guided temporal modeling. Experiments show that AG-VPReID.VIR
presents distinctive challenges compared to existing datasets, with our
TCC-VPReID framework achieving significant performance gains across multiple
evaluation protocols. Dataset and code are available at
https://github.com/agvpreid25/AG-VPReID.VIR.

</details>


### [29] [Exploring the interplay of label bias with subgroup size and separability: A case study in mammographic density classification](https://arxiv.org/abs/2507.17996)
*Emma A. M. Stanley,Raghav Mehta,Mélanie Roschewitz,Nils D. Forkert,Ben Glocker*

Main category: cs.CV

> 标签偏差影响医学影像中的特定子组，导致深度学习模型特征表示偏移和性能差异，强调了使用无偏标签在验证集中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 探讨系统标签偏差对特定子组在医学影像数据集中的影响，以研究其对医疗AI系统公正性的影响。

**Method:** 使用EMBED数据集训练用于二分类组织密度的深度学习模型，分析标签偏差对可分和非可分子组的影响。

**Result:** 本次研究探讨了标签偏差对医疗AI系统公正性的影响，特别是在医学影像数据集中，标签偏差影响特定子组的情况。研究使用EMBED数据集，分析了子组大小和可分性如何影响深度学习模型的学习特征和性能。研究结果显示，标签偏差导致模型学习特征表示显著偏移，这种偏移依赖于受影响子组的相对大小和可分性。使用无偏标签的验证集定义分类阈值时，可观察到子组性能的显著差异。例如，当标签偏差影响大多数可分子组时，该子组的真实阳性率从0.898下降到0.518。本研究为进一步理解标签偏差对医学影像AI中子组公平性的后果做出了重要贡献。

**Conclusion:** 标签偏差导致深度学习模型的学习特征表示偏移，偏移依赖于受影响子组的大小和可分性。使用无偏标签的验证集可以显著改善子组的分类性能。

**Abstract:** Systematic mislabelling affecting specific subgroups (i.e., label bias) in
medical imaging datasets represents an understudied issue concerning the
fairness of medical AI systems. In this work, we investigated how size and
separability of subgroups affected by label bias influence the learned features
and performance of a deep learning model. Therefore, we trained deep learning
models for binary tissue density classification using the EMory BrEast imaging
Dataset (EMBED), where label bias affected separable subgroups (based on
imaging manufacturer) or non-separable "pseudo-subgroups". We found that
simulated subgroup label bias led to prominent shifts in the learned feature
representations of the models. Importantly, these shifts within the feature
space were dependent on both the relative size and the separability of the
subgroup affected by label bias. We also observed notable differences in
subgroup performance depending on whether a validation set with clean labels
was used to define the classification threshold for the model. For instance,
with label bias affecting the majority separable subgroup, the true positive
rate for that subgroup fell from 0.898, when the validation set had clean
labels, to 0.518, when the validation set had biased labels. Our work
represents a key contribution toward understanding the consequences of label
bias on subgroup fairness in medical imaging AI.

</details>


### [30] [Registration beyond Points: General Affine Subspace Alignment via Geodesic Distance on Grassmann Manifold](https://arxiv.org/abs/2507.17998)
*Jaeho Shin,Hyeonjae Gil,Junwoo Jang,Maani Ghaffari,Ayoung Kim*

Main category: cs.CV

> 本文为解决现有的Affine Grassmannian方法在刚体变换下的距离不可显式优化问题，提出了一种新的、基于高维线性子空间基的优化代价函数，并证明其在配准问题中可找到全局最优解，已在多项计算机视觉任务中验证了其优越性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管Affine Grassmannian在表示线和平面之间的接近性方面具有理论上的精确性，但现有方法只能测量接近度而不能直接得到距离作为刚体变换的显式函数。这导致了流形上的可优化距离函数尚未得到充分开发，从而限制了在配准问题的应用。

**Method:** 本文提出了一种新的方法，通过严格的数学证明，用高维线性子空间的基作为代价函数的显式表示。该方法导出了两个Grassmann特征之间的可优化代价函数，该函数基于刚体变换（$\mathbf{R}$ 和 $\mathbf{t}$）。

**Result:** 通过实验验证，提出的最优代价函数及其向内点集最大化的BnB求解器扩展，已经在提高现有解决方案的收敛性或在各种计算机视觉任务中超越它们方面得到了证明。

**Conclusion:** 该研究克服了现有方法的局限，提出了一种新的基于转换基的优化代价函数，可以在任意仿射子空间的配准问题中应用。相比于基于向量参数的方法，新方法能够通过直接最小化测地距离找到全局最优解，且具有无表示歧义的特点。

**Abstract:** Affine Grassmannian has been favored for expressing proximity between lines
and planes due to its theoretical exactness in measuring distances among
features. Despite this advantage, the existing method can only measure the
proximity without yielding the distance as an explicit function of rigid body
transformation. Thus, an optimizable distance function on the manifold has
remained underdeveloped, stifling its application in registration problems.
This paper is the first to explicitly derive an optimizable cost function
between two Grassmannian features with respect to rigid body transformation
($\mathbf{R}$ and $\mathbf{t}$). Specifically, we present a rigorous
mathematical proof demonstrating that the bases of high-dimensional linear
subspaces can serve as an explicit representation of the cost. Finally, we
propose an optimizable cost function based on the transformed bases that can be
applied to the registration problem of any affine subspace. Compared to vector
parameter-based approaches, our method is able to find a globally optimal
solution by directly minimizing the geodesic distance which is agnostic to
representation ambiguity. The resulting cost function and its extension to the
inlier-set maximizing \ac{BnB} solver have been demonstrated to improve the
convergence of existing solutions or outperform them in various computer vision
tasks. The code is available on
https://github.com/joomeok/GrassmannRegistration.

</details>


### [31] [GRR-CoCa: Leveraging LLM Mechanisms in Multimodal Model Architectures](https://arxiv.org/abs/2507.18009)
*Jake R. Patock,Nicole Catherine Lewis,Kevin McCoy,Christina Gomez,Canling Chen,Lorenzo Luzi*

Main category: cs.CV

> 研究通过引入在LLMs中已证明有效的架构改进，开发了一种改进的SOTA对比式标题生成模型GRR-CoCa，并展示了其在预训练和微调任务中的显著性能提升。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型多模态模型在多个领域中表现良好，但其架构复杂度仍然落后于当代大型语言模型。为了应对这一挑战，该研究希望通过在多模态模型中引入LLMs中已验证有效的架构改进以进一步提高模型性能和泛化能力。

**Method:** 提出了一种改进的SOTA对比式标题生成模型GRR-CoCa。该模型在文本解码器和视觉Transformer (ViT) 编码器中引入了高斯误差门控线性单元、均方根归一化以及旋转位置编码，这些都是LLMs中表现优异但在CoCa中尚未采用的架构改进。

**Result:** GRR-CoCa相比Baseline CoCa（具有相同的修改后的文本解码器但使用原始ViT编码器）在预训练数据集和三个不同领域的微调数据集上显著提高了性能。预训练结果的改进包括对比损失减少27.25%，困惑度降低3.71%，以及CoCa损失减少7.15%。微调结果的改进平均为对比损失降低13.66%，困惑度降低5.18%，CoCa损失减少5.55%。

**Conclusion:** GRR-CoCa的修改架构不仅提高了性能，还增强了在视觉-语言领域中的泛化能力。

**Abstract:** State-of-the-art (SOTA) image and text generation models are multimodal
models that have many similarities to large language models (LLMs). Despite
achieving strong performances, leading foundational multimodal model
architectures frequently lag behind the architectural sophistication of
contemporary LLMs. We propose GRR-CoCa, an improved SOTA Contrastive Captioner
(CoCa) model that incorporates Gaussian error gated linear units, root mean
squared normalization, and rotary positional embedding into the textual
decoders and the vision transformer (ViT) encoder. Each architectural
modification has been shown to improve model performance in LLMs, but has yet
to be adopted in CoCa. We benchmarked GRR-CoCa against Baseline CoCa, a model
with the same modified textual decoders but with CoCa's original ViT encoder.
We used standard pretraining and fine-tuning workflows to benchmark the models
on contrastive and generative tasks. Our GRR-CoCa significantly outperformed
Baseline CoCa on the pretraining dataset and three diverse fine-tuning
datasets. Pretraining improvements were 27.25% in contrastive loss, 3.71% in
perplexity, and 7.15% in CoCa loss. The average fine-tuning improvements were
13.66% in contrastive loss, 5.18% in perplexity, and 5.55% in CoCa loss. We
show that GRR-CoCa's modified architecture improves performance and
generalization across vision-language domains.

</details>


### [32] [Celeb-DF++: A Large-scale Challenging Video DeepFake Benchmark for Generalizable Forensics](https://arxiv.org/abs/2507.18015)
*Yuezun Li,Delong Zhu,Xinjie Cui,Siwei Lyu*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** The rapid advancement of AI technologies has significantly increased the
diversity of DeepFake videos circulating online, posing a pressing challenge
for \textit{generalizable forensics}, \ie, detecting a wide range of unseen
DeepFake types using a single model. Addressing this challenge requires
datasets that are not only large-scale but also rich in forgery diversity.
However, most existing datasets, despite their scale, include only a limited
variety of forgery types, making them insufficient for developing generalizable
detection methods. Therefore, we build upon our earlier Celeb-DF dataset and
introduce {Celeb-DF++}, a new large-scale and challenging video DeepFake
benchmark dedicated to the generalizable forensics challenge. Celeb-DF++ covers
three commonly encountered forgery scenarios: Face-swap (FS), Face-reenactment
(FR), and Talking-face (TF). Each scenario contains a substantial number of
high-quality forged videos, generated using a total of 22 various recent
DeepFake methods. These methods differ in terms of architectures, generation
pipelines, and targeted facial regions, covering the most prevalent DeepFake
cases witnessed in the wild. We also introduce evaluation protocols for
measuring the generalizability of 24 recent detection methods, highlighting the
limitations of existing detection methods and the difficulty of our new
dataset.

</details>


### [33] [High-fidelity 3D Gaussian Inpainting: preserving multi-view consistency and photorealistic details](https://arxiv.org/abs/2507.18023)
*Jun Zhou,Dinghao Li,Nannan Li,Mingjie Wang*

Main category: cs.CV

> We propose a novel 3D Gaussian inpainting framework for reconstructing complete 3D scenes by leveraging sparse inpainted views.

<details>
  <summary>Details</summary>

**Motivation:** Inpainting 3D scenes is a challenging task due to the irregularity of 3D structures and the need for multi-view consistency, which our method addresses.

**Method:** Our framework incorporates an automatic Mask Refinement Process and region-wise Uncertainty-guided Optimization for inpainting 3D scenes, using sparse inpainted views and estimating the importance of each region across multi-view images.

**Result:** Comprehensive experiments show that our approach outperforms existing state-of-the-art methods in both visual quality and view consistency.

**Conclusion:** The proposed 3D Gaussian inpainting framework achieves superior performance in visual quality and multi-view consistency over existing methods.

**Abstract:** Recent advancements in multi-view 3D reconstruction and novel-view synthesis,
particularly through Neural Radiance Fields (NeRF) and 3D Gaussian Splatting
(3DGS), have greatly enhanced the fidelity and efficiency of 3D content
creation. However, inpainting 3D scenes remains a challenging task due to the
inherent irregularity of 3D structures and the critical need for maintaining
multi-view consistency. In this work, we propose a novel 3D Gaussian inpainting
framework that reconstructs complete 3D scenes by leveraging sparse inpainted
views. Our framework incorporates an automatic Mask Refinement Process and
region-wise Uncertainty-guided Optimization. Specifically, we refine the
inpainting mask using a series of operations, including Gaussian scene
filtering and back-projection, enabling more accurate localization of occluded
regions and realistic boundary restoration. Furthermore, our Uncertainty-guided
Fine-grained Optimization strategy, which estimates the importance of each
region across multi-view images during training, alleviates multi-view
inconsistencies and enhances the fidelity of fine details in the inpainted
results. Comprehensive experiments conducted on diverse datasets demonstrate
that our approach outperforms existing state-of-the-art methods in both visual
quality and view consistency.

</details>
