<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 11]
- [cs.CV](#cs.CV) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Multimodal Consistency-Guided Reference-Free Data Selection for ASR Accent Adaptation](https://arxiv.org/abs/2602.13263)
*Ligong Lei,Wenwen Lu,Xudong Pang,Zaokere Kadeer,Aishan Wumaier*

Main category: cs.CL

> A multimodal consistency-guided data selection approach for accent adaptation in ASR systems shows strong performance gains, even with fewer data points, surpassing other methods in different settings.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve ASR performance on accented speech by addressing the limitations of existing pseudo-label selection methods, which often focus on textual fluency and can lead to error amplification during fine-tuning.

**Method:** The paper introduces a multimodal consistency-guided, reference-free data selection pipeline for ASR accent adaptation. It involves a target-aware preselection step using submodular mutual information, generating multiple pseudo-transcriptions through perturbation-based decoding, and scoring hypotheses using speech-text alignment and predicted WER.

**Result:** In an in-domain setting, the method achieves a 10.91% WER with only ~1.5k selected utterances, compared to 10.45% with 30k supervised labels. In a cross-domain setting, it also avoids performance degradation and outperforms random sampling and recent baselines.

**Conclusion:** The proposed method demonstrates effective accent adaptation in ASR by utilizing multimodal consistency for reference-free data selection, achieving comparable performance to supervised learning and outperforming other baselines in cross-domain settings.

**Abstract:** Automatic speech recognition (ASR) systems often degrade on accented speech because acoustic-phonetic and prosodic shifts induce a mismatch to training data, making labeled accent adaptation costly. However, common pseudo-label selection heuristics are largely text-centric (e.g., perplexity (PPL) filtering) and can prefer fluent yet acoustically mismatched hypotheses, leading to error amplification when fine-tuning. To address this, we introduce a multimodal consistency-guided, reference-free data selection pipeline for ASR accent adaptation under a transductive, label-free protocol. The pipeline starts with a target-aware preselection step based on submodular mutual information to improve query relevance and reduce downstream computation. It then generates multiple pseudo-transcriptions per utterance via perturbation-based decoding and scores each hypothesis using two reference-free signals: speech--text alignment in a shared embedding space and predicted word error rate (WER). A simple percentile-based selection rule retains reliable pseudo-labels for fine-tuning while discarding noisy utterances. In an in-domain setting, selecting ~1.5k utterances from a 30k pool achieves 10.91% WER, close to 10.45% obtained using 30k supervised labels. In a cross-domain setting with a mismatched candidate pool, consistency-filtered subsets avoid the degradation caused by unfiltered pseudo-labels under strong accent shift, and matched-hour experiments on a stronger ASR backbone further confirm gains over random sampling and recent selection baselines.

</details>


### [2] [LLM-Powered Automatic Translation and Urgency in Crisis Scenarios](https://arxiv.org/abs/2602.13452)
*Belu Ticona,Antonis Anastasopoulos*

Main category: cs.CL

> 通过研究发现，最先进的语言模型（LLMs）和机器翻译系统在多语言危机通信中表现不稳定，尤其是在保持沟通紧迫性方面。这表明将这类技术部署到危机沟通中存在显著风险。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于评估LLMs在危机场景中的适用性，特别是在多语言沟通中的紧迫性保留，因为这种适用性尚未得到充分评估。危机场景对语言技术的要求很高，本研究旨在验证这类工具在高风险情境下的表现。

**Method:** 本研究使用多语言危机数据和一个新引入的、带有紧迫性标注的数据集（涵盖超32种语言）来评估最先进的语言模型（LLMs）和机器翻译系统在危机领域翻译中的表现，尤其关注紧迫性的保留情况。

**Result:** 研究结果表明，专用翻译模型和LLMs都表现出了显著的性能下降和不稳定。即使从语言上能翻译得当，也可能在感知紧迫性方面产生扭曲，而基于LLM的紧迫性分类在不同语言的提示和输入中差别很大。

**Conclusion:** 本研究强调采用通用语言技术在危机沟通中的潜在风险，并指出需要开发危机场景感知的评估框架。

**Abstract:** Large language models (LLMs) are increasingly proposed for crisis preparedness and response, particularly for multilingual communication. However, their suitability for high-stakes crisis contexts remains insufficiently evaluated. This work examines the performance of state-of-the-art LLMs and machine translation systems in crisis-domain translation, with a focus on preserving urgency, which is a critical property for effective crisis communication and triaging. Using multilingual crisis data and a newly introduced urgency-annotated dataset covering over 32 languages, we show that both dedicated translation models and LLMs exhibit substantial performance degradation and instability. Crucially, even linguistically adequate translations can distort perceived urgency, and LLM-based urgency classifications vary widely depending on the language of the prompt and input. These findings highlight significant risks in deploying general-purpose language technologies for crisis communication and underscore the need for crisis-aware evaluation frameworks.

</details>


### [3] [Using Machine Learning to Enhance the Detection of Obfuscated Abusive Words in Swahili: A Focus on Child Safety](https://arxiv.org/abs/2602.13455)
*Phyllis Nabangi,Abdul-Jalil Zakaria,Jema David Ndibwile*

Main category: cs.CL

> 本研究关注斯瓦希里语隐晦语言的识别问题，应用了多种机器学习模型，但受限于数据集的规模和不平衡性，其结果具有一定局限性。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于数字技术的发展增加了网络欺凌和在线虐待的可能性，尤其是针对儿童，本研究旨在解决斯瓦希里语这种低资源语言中隐晦语言的识别和预防问题。

**Method:** 本研究采用了包括支持向量机(SVM)、逻辑回归和决策树等机器学习模型，并通过严格的参数调优和SMOTE技术处理数据不平衡问题。

**Result:** 研究发现，尽管这些模型在高维文本数据中表现良好，但数据集的小规模和不平衡限制了研究结果的普遍适用性。多种评价指标如精度、召回率和F1分数进行了详细分析。

**Conclusion:** 本研究强调了为儿童提供更安全的在线环境的重要性，建议未来工作集中在增强数据的健固性、探索迁移学习以及整合多模态数据，以创造更加全面和文化敏感的检测机制。

**Abstract:** The rise of digital technology has dramatically increased the potential for cyberbullying and online abuse, necessitating enhanced measures for detection and prevention, especially among children. This study focuses on detecting abusive obfuscated language in Swahili, a low-resource language that poses unique challenges due to its limited linguistic resources and technological support. Swahili is chosen due to its popularity and being the most widely spoken language in Africa, with over 16 million native speakers and upwards of 100 million speakers in total, spanning regions in East Africa and some parts of the Middle East.
  We employed machine learning models including Support Vector Machines (SVM), Logistic Regression, and Decision Trees, optimized through rigorous parameter tuning and techniques like Synthetic Minority Over-sampling Technique (SMOTE) to handle data imbalance. Our analysis revealed that, while these models perform well in high-dimensional textual data, our dataset's small size and imbalance limit our findings' generalizability. Precision, recall, and F1 scores were thoroughly analyzed, highlighting the nuanced performance of each model in detecting obfuscated language.
  This research contributes to the broader discourse on ensuring safer online environments for children, advocating for expanded datasets and advanced machine-learning techniques to improve the effectiveness of cyberbullying detection systems. Future work will focus on enhancing data robustness, exploring transfer learning, and integrating multimodal data to create more comprehensive and culturally sensitive detection mechanisms.

</details>


### [4] [Language Model Memory and Memory Models for Language](https://arxiv.org/abs/2602.13466)
*Benjamin L. Badger*

Main category: cs.CL

> 研究发现语言模型的记忆能力较弱，而自编码器能更好地形成记忆。通过结合因果性和信息保留的目标函数，可以训练出形成和解码信息丰富的记忆的模型。

<details>
  <summary>Details</summary>

**Motivation:** 研究机器学习模型中隐藏层向量嵌入存储输入信息的能力，探讨模型记忆能力不足的原因，并寻求改进方法。

**Method:** 通过对比语言模型嵌入与自编码器嵌入来研究模型的记忆能力。自编码器被训练用于输入再生，从而形成几乎完美的记忆。

**Result:** 发现语言模型的嵌入通常包含少量输入信息，而用于输入再生的自编码器嵌入能形成几乎完美的记忆。

**Conclusion:** 单一的下一个词预测训练不适合精确记忆形成，需结合多种目标函数提高模型的记忆能力。

**Abstract:** The ability of machine learning models to store input information in hidden layer vector embeddings, analogous to the concept of `memory', is widely employed but not well characterized. We find that language model embeddings typically contain relatively little input information regardless of data and compute scale during training. In contrast, embeddings from autoencoders trained for input regeneration are capable of nearly perfect memory formation. The substitution of memory embeddings for token sequences leads to substantial computational efficiencies, motivating the introduction of a parallelizable encoder-decoder memory model architecture. Upon causal training these models contain information-poor embeddings incapable of arbitrary information access, but by combining causal and information retention objective functions they learn to form and decode information-rich memories. Training can be further streamlined by freezing a high fidelity encoder followed by a curriculum training approach where decoders first learn to process memories and then learn to additionally predict next tokens. We introduce the perspective that next token prediction training alone is poorly suited for accurate memory formation as the objective itself is non-invertible, motivating the use of combined objective functions for models where the entire input is not exposed.

</details>


### [5] [From Perceptions To Evidence: Detecting AI-Generated Content In Turkish News Media With A Fine-Tuned Bert Classifier](https://arxiv.org/abs/2602.13504)
*Ozancan Ozdemir*

Main category: cs.CL

> 这项研究首次通过微调模型，实证测量了在土耳其新闻媒体中AI生成内容的使用情况，达到了高度稳定的分类结果和高置信度预测。

<details>
  <summary>Details</summary>

**Motivation:** 针对大型语言模型在新闻工作流中的快速集成所引起的问题，特别是在土耳其新闻媒体中缺乏实证研究的背景下，该研究填补了空白。

**Method:** 通过在三个具有不同编辑倾向的主要土耳其新闻来源上标注的3,600篇文章数据集上微调了特定于土耳其的BERT模型（dbmdz/bert-base-turkish-cased），实现对AI重写内容的二元分类。

**Result:** 该模型在保留测试集上实现了0.9708的F1分数，并且两个类别上的精确度和召回率对称。在2023年至2026年间对3,500多篇未见过的文章进行后续部署表明，跨来源和时间稳定的分类模式，平均预测置信度超过0.96，估计被LLM重写或修改的新闻内容为2.5%。

**Conclusion:** 据我们所知，这是首次从数据驱动的角度对土耳其新闻媒体中AI使用情况进行实证测量，超越了记者自我报告的感知。

**Abstract:** The rapid integration of large language models into newsroom workflows has raised urgent questions about the prevalence of AI-generated content in online media. While computational studies have begun to quantify this phenomenon in English-language outlets, no empirical investigation exists for Turkish news media, where existing research remains limited to qualitative interviews with journalists or fake news detection. This study addresses that gap by fine-tuning a Turkish-specific BERT model (dbmdz/bert-base-turkish-cased) on a labeled dataset of 3,600 articles from three major Turkish outlets with distinct editorial orientations for binary classification of AI-rewritten content. The model achieves 0.9708 F1 score on the held-out test set with symmetric precision and recall across both classes. Subsequent deployment on over 3,500 unseen articles spanning between 2023 and 2026 reveals consistent cross-source and temporally stable classification patterns, with mean prediction confidence exceeding 0.96 and an estimated 2.5 percentage of examined news content rewritten or revised by LLMs on average. To the best of our knowledge, this is the first study to move beyond self-reported journalist perceptions toward empirical, data-driven measurement of AI usage in Turkish news media.

</details>


### [6] [Think Deep, Not Just Long: Measuring LLM Reasoning Effort via Deep-Thinking Tokens](https://arxiv.org/abs/2602.13517)
*Wei-Lin Chen,Liqian Peng,Tian Tan,Chao Zhao,Blake JianHang Chen,Ziqian Lin,Alec Go,Yu Meng*

Main category: cs.CL

> 研究发现深度思考令牌比例与生成准确性有强正相关性，并提出Think@n策略，这能有效提升性能并降低成本。

<details>
  <summary>Details</summary>

**Motivation:** 现有研究表明，单纯的生成长度并不总是与准确性正相关，反而可能标志着过度思考，导致性能下降。因此，需要一种更可靠的推理质量评估方法。

**Method:** 通过识别深度思考令牌（模型深层预测在收敛前显著修订的令牌）来量化推理时的努力。这种方法在四个数学和科学基准测试（AIME 24/25, HMMT 25, 和 GPQA-diamond）和多种推理聚焦模型（GPT-OSS, DeepSeek-R1, 和 Qwen3）上进行了验证，并展示了深度思考比例与准确性的强正相关性。

**Result:** 提出了Think@n策略，该策略优先考虑具有高深度思考比例的样本。实验表明，Think@n策略在匹配或超越标准自我一致性性能的同时，通过基于短前缀提前拒绝无前途的生成来显著减少推理成本。

**Conclusion:** 深度思考比例为衡量推理质量提供了一个更好的指标，Think@n策略基于此提升了性能并减少了成本。

**Abstract:** Large language models (LLMs) have demonstrated impressive reasoning capabilities by scaling test-time compute via long Chain-of-Thought (CoT). However, recent findings suggest that raw token counts are unreliable proxies for reasoning quality: increased generation length does not consistently correlate with accuracy and may instead signal "overthinking," leading to performance degradation. In this work, we quantify inference-time effort by identifying deep-thinking tokens -- tokens where internal predictions undergo significant revisions in deeper model layers prior to convergence. Across four challenging mathematical and scientific benchmarks (AIME 24/25, HMMT 25, and GPQA-diamond) and a diverse set of reasoning-focused models (GPT-OSS, DeepSeek-R1, and Qwen3), we show that deep-thinking ratio (the proportion of deep-thinking tokens in a generated sequence) exhibits a robust and consistently positive correlation with accuracy, substantially outperforming both length-based and confidence-based baselines. Leveraging this insight, we introduce Think@n, a test-time scaling strategy that prioritizes samples with high deep-thinking ratios. We demonstrate that Think@n matches or exceeds standard self-consistency performance while significantly reducing inference costs by enabling the early rejection of unpromising generations based on short prefixes.

</details>


### [7] [On Calibration of Large Language Models: From Response To Capability](https://arxiv.org/abs/2602.13540)
*Sin-Han Yang,Cheng-Kuang Wu,Chieh-Yen Lin,Yun-Nung Chen,Hung-yi Lee,Shao-Hua Sun*

Main category: cs.CL

> 本研究引入了能力校准，解决了传统响应级自信度估计与实际应用场景之间的不匹配问题。研究结果显示，能力校准可提升$pass@k$预测和推理预算分配的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型的广泛应用需要更准确的自信度估计以为实际应用提供可靠支持。传统的响应级自信度估计忽略了模型解码的随机性，无法真正反映模型的能力。本研究旨在解决这个问题，通过提出能力校准的概念来改善自信度估计。

**Method:** 本研究引入了能力校准的概念，旨在解决传统校准方法与实际应用场景之间的不匹配问题。能力校准侧重于模型在整体查询上的预期准确性，而非单一响应的准确性。研究通过理论和实证分析了能力校准与响应校准之间的区别，并评估了几种自信度评估方法。

**Result:** 实验表明，能力校准可明显提升模型在预测准确性排名前$k$位置（$pass@k$）时的成功率，并改善了模型的资源分配策略，这些结果为实际应用场景提供了重要的支持。

**Conclusion:** 研究结果表明，通过能力校准的自信度估计方法能够提升$pass@k$预测和预算分配的准确性，并为未来的多种应用奠定了基础。

**Abstract:** Large language models (LLMs) are widely deployed as general-purpose problem solvers, making accurate confidence estimation critical for reliable use. Prior work on LLM calibration largely focuses on response-level confidence, which estimates the correctness of a single generated output. However, this formulation is misaligned with many practical settings where the central question is how likely a model is to solve a query overall. We show that this mismatch results from the stochastic nature of modern LLM decoding, under which single-response correctness fails to reflect underlying model capability. To address this issue, we introduce capability calibration, which targets the model's expected accuracy on a query. We formally distinguish capability calibration from response calibration and show that the two differ both theoretically and empirically. We establish an empirical evaluation setup and study a range of confidence estimation methods. Our results demonstrate that capability-calibrated confidence improves pass@$k$ prediction and inference budget allocation, establishing a foundation with potential for diverse applications.

</details>


### [8] [Small Reward Models via Backward Inference](https://arxiv.org/abs/2602.13551)
*Yike Wang,Faeze Brahman,Shangbin Feng,Teng Xiao,Hannaneh Hajishirzi,Yulia Tsvetkov*

Main category: cs.CL

> 研究提出了一种名为FLIP的新方法，用于奖励模型的构建，这种方法无需参考和规则，相比当前的方法表现出了显著的进步，并且在多种测试中展现了优越性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于大型语言模型的判断范式依赖于大型模型的强大推理能力，而其他方法需要参考响应或显式的评分标准，这限制了灵活性和广泛适用性。本工作旨在提出一种更灵活和广泛的奖励模型方法。

**Method:** FLIP (FLipped Inference for Prompt reconstruction) 是一种无参考和无规则的奖励模型方法，它通过反向推理来重构指令，即将给定的响应最有可能产生的指令进行推断。指令和推断出的指令之间的相似性被用作奖励信号。

**Result:** 在四个领域中使用13个小语言模型的评估中，FLIP比基于语言模型的判断基线方法平均高出79.6%。FLIP也通过并行采样和GRPO训练在测试时间缩放下的外部评估中显著提高了下游性能。发现FLIP对更长的输出和常见的奖励作弊形式特别有效。

**Conclusion:** FLIP方法通过利用验证生成差距，在缩小规模的环境中实现了可靠的奖励建模，这是判断方法所难以实现的。

**Abstract:** Reward models (RMs) play a central role throughout the language model (LM) pipeline, particularly in non-verifiable domains. However, the dominant LLM-as-a-Judge paradigm relies on the strong reasoning capabilities of large models, while alternative approaches require reference responses or explicit rubrics, limiting flexibility and broader accessibility. In this work, we propose FLIP (FLipped Inference for Prompt reconstruction), a reference-free and rubric-free reward modeling approach that reformulates reward modeling through backward inference: inferring the instruction that would most plausibly produce a given response. The similarity between the inferred and the original instructions is then used as the reward signal. Evaluations across four domains using 13 small language models show that FLIP outperforms LLM-as-a-Judge baselines by an average of 79.6%. Moreover, FLIP substantially improves downstream performance in extrinsic evaluations under test-time scaling via parallel sampling and GRPO training. We further find that FLIP is particularly effective for longer outputs and robust to common forms of reward hacking. By explicitly exploiting the validation-generation gap, FLIP enables reliable reward modeling in downscaled regimes where judgment methods fail. Code available at https://github.com/yikee/FLIP.

</details>


### [9] [DistillLens: Symmetric Knowledge Distillation Through Logit Lens](https://arxiv.org/abs/2602.13567)
*Manish Dhakal,Uthman Jinadu,Anjila Budathoki,Rajshekhar Sunderraman,Yi Ding*

Main category: cs.CL

> 本文提出DistillLens框架，通过Logit Lens强制学生和教师模型中间思想过程的对称性对齐，实验结果显示其在压缩大型语言模型上优于标准KD方法。

<details>
  <summary>Details</summary>

**Motivation:** 标准知识蒸馏（KD）在优化最终输出时通常将教师模型中间层的思想过程视为黑箱，而特征转移方法忽略了丰富不确定性配置文件的需求。

**Method:** 本文提出了DistillLens框架，通过Logit Lens将中间隐藏状态投影到词汇空间，使用对称散度目标强制结构对齐，解决了现有方法忽略最终输出所需丰富不确定性配置文件的问题。

**Result:** 在GPT-2和Llama架构上的广泛实验表明，DistillLens优于标准KD和特征转移基线，在各种指令遵循基准上表现更佳。

**Conclusion:** 通过对中间思想过程的对称性对齐，DistillLens框架能更好地保留高熵信息通道，同时防止高估和低估，从而提升语言模型压缩效果。

**Abstract:** Standard Knowledge Distillation (KD) compresses Large Language Models (LLMs) by optimizing final outputs, yet it typically treats the teacher's intermediate layer's thought process as a black box. While feature-based distillation attempts to bridge this gap, existing methods (e.g., MSE and asymmetric KL divergence) ignore the rich uncertainty profiles required for the final output. In this paper, we introduce DistillLens, a framework that symmetrically aligns the evolving thought processes of student and teacher models. By projecting intermediate hidden states into the vocabulary space via the Logit Lens, we enforce structural alignment using a symmetric divergence objective. Our analysis proves that this constraint imposes a dual-sided penalty, preventing both overconfidence and underconfidence while preserving the high-entropy information conduits essential for final deduction. Extensive experiments on GPT-2 and Llama architectures demonstrate that DistillLens consistently outperforms standard KD and feature-transfer baselines on diverse instruction-following benchmarks. The code is available at https://github.com/manishdhakal/DistillLens.

</details>


### [10] [LLM-Confidence Reranker: A Training-Free Approach for Enhancing Retrieval-Augmented Generation Systems](https://arxiv.org/abs/2602.13571)
*Zhipeng Song,Xiangyu Kong,Xinrui Bao,Yizhi Zhou,Jiulong Jiao,Sitong Liu,Yuhang Zhou,Heng Qi*

Main category: cs.CL

> Proposes LCR, a training-free algorithm leveraging LLM confidence signals from MSCP to improve reranking in RAG systems, significantly enhancing document retrieval accuracy without increasing computational costs.

<details>
  <summary>Details</summary>

**Motivation:** To address the critical challenge of hallucinations in large language models and improve the effectiveness of retrieval-augmented generation systems without the need for specialized training or excessive computational resources.

**Method:** LLM-Confidence Reranker (LCR), a training-free algorithm enhancing reranking in RAG systems using Maximum Semantic Cluster Proportion (MSCP) confidence signals from pre-trained language models.

**Result:** LCR consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, validated on BEIR and TREC benchmarks.

**Conclusion:** LCR provides a robust, efficient, and broadly compatible approach to enhancing document retrieval accuracy in RAG systems, mitigating the risk of hallucinations in knowledge-intensive tasks.

**Abstract:** Large language models (LLMs) have revolutionized natural language processing, yet hallucinations in knowledge-intensive tasks remain a critical challenge. Retrieval-augmented generation (RAG) addresses this by integrating external knowledge, but its efficacy depends on accurate document retrieval and ranking. Although existing rerankers demonstrate effectiveness, they frequently necessitate specialized training, impose substantial computational expenses, and fail to fully exploit the semantic capabilities of LLMs, particularly their inherent confidence signals. We propose the LLM-Confidence Reranker (LCR), a training-free, plug-and-play algorithm that enhances reranking in RAG systems by leveraging black-box LLM confidence derived from Maximum Semantic Cluster Proportion (MSCP). LCR employs a two-stage process: confidence assessment via multinomial sampling and clustering, followed by binning and multi-level sorting based on query and document confidence thresholds. This approach prioritizes relevant documents while preserving original rankings for high-confidence queries, ensuring robustness. Evaluated on BEIR and TREC benchmarks with BM25 and Contriever retrievers, LCR--using only 7--9B-parameter pre-trained LLMs--consistently improves NDCG@5 by up to 20.6% across pre-trained LLM and fine-tuned Transformer rerankers, without degradation. Ablation studies validate the hypothesis that LLM confidence positively correlates with document relevance, elucidating LCR's mechanism. LCR offers computational efficiency, parallelism for scalability, and broad compatibility, mitigating hallucinations in applications like medical diagnosis.

</details>


### [11] [Elo-Evolve: A Co-evolutionary Framework for Language Model Alignment](https://arxiv.org/abs/2602.13575)
*Jing Zhao,Ting Zhen,Junwei bao,Hongfei Jiang,Yang song*

Main category: cs.CL

> Elo-Evolve 是一种新的共演化框架，用于改进大语言模型对齐方式，通过动态多代理竞争和自适应对手池来消除对 Bradley-Terry 模型的依赖并减少数据噪声。

<details>
  <summary>Details</summary>

**Motivation:** 当前的大语言模型对齐方法依赖将大量的人类偏好数据压缩成静态绝对奖赏函数，这导致数据匮乏、噪声敏感和训练不稳定问题。

**Method:** Elo-Evolve 通过从成对比赛的胜负结果中直接学习，并使用 Elo 式对手选择进行自动课程学习，从而消除 Bradley-Terry 模型依赖并提供温度控制下的采样。

**Result:** 实验表明，与绝对评分方法相比，Elo-Evolve 在噪声减少方面提高了 4.5 倍，此外在 Alpaca Eval 2.0 和 MT-Bench 数据集上验证了点数方法、静态成对训练和 Elo-Evolve 的性能等级区分明显。

**Conclusion:** Elo-Evolve 通过成对比较和动态对手选择，在提供优越样本复杂度和改善语言模型对齐效果方面显示出整体性的优势。

**Abstract:** Current alignment methods for Large Language Models (LLMs) rely on compressing vast amounts of human preference data into static, absolute reward functions, leading to data scarcity, noise sensitivity, and training instability. We introduce Elo-Evolve, a co-evolutionary framework that redefines alignment as dynamic multi-agent competition within an adaptive opponent pool. Our approach makes two key innovations: (1) eliminating Bradley-Terry model dependencies by learning directly from binary win/loss outcomes in pairwise competitions, and (2) implementing Elo-orchestrated opponent selection that provides automatic curriculum learning through temperature-controlled sampling. We ground our approach in PAC learning theory, demonstrating that pairwise comparison achieves superior sample complexity and empirically validate a 4.5x noise reduction compared to absolute scoring approaches. Experimentally, we train a Qwen2.5-7B model using our framework with opponents including Qwen2.5-14B, Qwen2.5-32B, and Qwen3-8B models. Results demonstrate a clear performance hierarchy: point-based methods < static pairwise training < Elo-Evolve across Alpaca Eval 2.0 and MT-Bench, validating the progressive benefits of pairwise comparison and dynamic opponent selection for LLM alignment.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [12] [Beyond Ground: Map-Free LiDAR Relocalization for UAVs](https://arxiv.org/abs/2602.13267)
*Hengyu Mu,Jianshi Wu,Yuxin Guo,XianLian Lin,Qingyong Hu,Chenglu Wen,Cheng Wang*

Main category: cs.CV

> This paper introduces MAILS, a new map-free LiDAR relocalization framework for UAVs which improves upon existing methods by enhancing robustness and precision in UAV-specific conditions, supported by a novel dataset for evaluation.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to develop a LiDAR relocalization method specifically tailored for UAVs, as existing methods primarily cater to autonomous driving and fail to maintain accuracy in UAV scenarios where there are irregular trajectories and varying altitudes.

**Method:** MAILS, a novel map-free LiDAR relocalization framework for UAVs, includes a Locality-Preserving Sliding Window Attention module for extracting locally discriminative geometric features, and a coordinate-independent feature initialization module along with a locally invariant positional encoding mechanism to enhance robustness under substantial yaw rotations and altitude variations.

**Result:** Extensive experiments show that the MAILS framework achieves high precision in localization, demonstrating superiority over current methods in UAV scenarios with irregular trajectories and varying altitudes.

**Conclusion:** The proposed MAILS framework significantly enhances the robustness and precision of LiDAR relocalization in UAVs, outperforming existing techniques by a considerable margin. Additionally, the creation of a new large-scale dataset for evaluating UAV relocalization under realistic conditions is highlighted.

**Abstract:** Localization is a fundamental capability in unmanned aerial vehicle (UAV) systems. Map-free LiDAR relocalization offers an effective solution for achieving high-precision positioning in environments with weak or unavailable GNSS signals. However, existing LiDAR relocalization methods are primarily tailored to autonomous driving, exhibiting significantly degraded accuracy in UAV scenarios. In this paper, we propose MAILS, a novel map-free LiDAR relocalization framework for UAVs. A Locality-Preserving Sliding Window Attention module is first introduced to extract locally discriminative geometric features from sparse point clouds. To handle substantial yaw rotations and altitude variations encountered during UAV flight, we then design a coordinate-independent feature initialization module and a locally invariant positional encoding mechanism, which together significantly enhance the robustness of feature extraction. Furthermore, existing LiDAR-based relocalization datasets fail to capture real-world UAV flight characteristics, such as irregular trajectories and varying altitudes. To address this gap, we construct a large-scale LiDAR localization dataset for UAVs, which comprises four scenes and various flight trajectories, designed to evaluate UAV relocalization performance under realistic conditions. Extensive experiments demonstrate that our method achieves satisfactory localization precision and consistently outperforms existing techniques by a significant margin. Our code and dataset will be released soon.

</details>


### [13] [Explanatory Interactive Machine Learning for Bias Mitigation in Visual Gender Classification](https://arxiv.org/abs/2602.13286)
*Nathanya Satriani,Djordje Slijepčević,Markus Schedl,Matthias Zeppelzauer*

Main category: cs.CV

> This study utilizes Explanatory Interactive Learning (XIL) to mitigate bias in visual classifiers, demonstrating its potential to improve model fairness and, notably, the CAIPI strategy's ability to enhance classification accuracy while reducing bias.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to investigate how XIL can be utilized to guide machine learning models towards focusing on relevant features and reduce biases, particularly in tasks like gender classification where data bias is a significant concern.

**Method:** Analyzing the content provided, the paper explores the use of Explanatory Interactive Learning (XIL) to reduce bias in visual classifiers, employing three strategies: CAIPI, RRR, and a novel hybrid approach. The evaluation uses GradCAM and BLA for comparison with segmentation masks.

**Result:** The results indicate that XIL strategies, especially CAIPI, successfully guide the models to concentrate on pertinent features and decrease bias, achieving a balance in misclassification rates between genders.

**Conclusion:** The paper concludes that XIL methods can enhance fairness in gender classifiers and, in some cases, even improve classification accuracy without significant performance degradation.

**Abstract:** Explanatory interactive learning (XIL) enables users to guide model training in machine learning (ML) by providing feedback on the model's explanations, thereby helping it to focus on features that are relevant to the prediction from the user's perspective. In this study, we explore the capability of this learning paradigm to mitigate bias and spurious correlations in visual classifiers, specifically in scenarios prone to data bias, such as gender classification. We investigate two methodologically different state-of-the-art XIL strategies, i.e., CAIPI and Right for the Right Reasons (RRR), as well as a novel hybrid approach that combines both strategies. The results are evaluated quantitatively by comparing segmentation masks with explanations generated using Gradient-weighted Class Activation Mapping (GradCAM) and Bounded Logit Attention (BLA). Experimental results demonstrate the effectiveness of these methods in (i) guiding ML models to focus on relevant image features, particularly when CAIPI is used, and (ii) reducing model bias (i.e., balancing the misclassification rates between male and female predictions). Our analysis further supports the potential of XIL methods to improve fairness in gender classifiers. Overall, the increased transparency and fairness obtained by XIL leads to slight performance decreases with an exception being CAIPI, which shows potential to even improve classification accuracy.

</details>


### [14] [COOPERTRIM: Adaptive Data Selection for Uncertainty-Aware Cooperative Perception](https://arxiv.org/abs/2602.13287)
*Shilpa Mukhopadhyay,Amit Roy-Chowdhury,Hang Qiu*

Main category: cs.CV

> 本文提出了COOPERTRIM框架，通过利用时间连续性和环境动态变化检测来适应性地选择和共享感知特征，实现了带宽的有效利用，同时保持与原有方法相比较高的精度，并展示了在实际环境中的适应性和灵活性。

<details>
  <summary>Details</summary>

**Motivation:** 解决感知合作中的带宽限制与丰富的传感器信息之间的矛盾，减少传输冗余，提升实际部署的可能性。

**Method:** COOPERTRIM框架使用了一种新的符合时间不确定性的指标和数据驱动的机制，根据环境的复杂程度动态调整共享量。

**Result:** 在语义分割和3D检测任务中，COOPERTRIM实现了高达80.28%的带宽减少；与其它选择策略相比，COOPERTRIM在保持较高交并比的同时减少了72%的带宽使用；结合压缩策略，可进一步将带宽使用减少至1.46%。

**Conclusion:** COOPERTRIM框架显示了灵活性，在不同环境动态变化下仍能有效工作，提供了向实际部署迈进的可能性。

**Abstract:** Cooperative perception enables autonomous agents to share encoded representations over wireless communication to enhance each other's live situational awareness. However, the tension between the limited communication bandwidth and the rich sensor information hinders its practical deployment. Recent studies have explored selection strategies that share only a subset of features per frame while striving to keep the performance on par. Nevertheless, the bandwidth requirement still stresses current wireless technologies. To fundamentally ease the tension, we take a proactive approach, exploiting the temporal continuity to identify features that capture environment dynamics, while avoiding repetitive and redundant transmission of static information. By incorporating temporal awareness, agents are empowered to dynamically adapt the sharing quantity according to environment complexity. We instantiate this intuition into an adaptive selection framework, COOPERTRIM, which introduces a novel conformal temporal uncertainty metric to gauge feature relevance, and a data-driven mechanism to dynamically determine the sharing quantity. To evaluate COOPERTRIM, we take semantic segmentation and 3D detection as example tasks. Across multiple open-source cooperative segmentation and detection models, COOPERTRIM achieves up to 80.28% and 72.52% bandwidth reduction respectively while maintaining a comparable accuracy. Relative to other selection strategies, COOPERTRIM also improves IoU by as much as 45.54% with up to 72% less bandwidth. Combined with compression strategies, COOPERTRIM can further reduce bandwidth usage to as low as 1.46% without compromising IoU performance. Qualitative results show COOPERTRIM gracefully adapts to environmental dynamics, localization error, and communication latency, demonstrating flexibility and paving the way for real-world deployment.

</details>


### [15] [Evaluating the Impact of Post-Training Quantization on Reliable VQA with Multimodal LLMs](https://arxiv.org/abs/2602.13289)
*Paul Jonas Kurz,Tobias Jan Wieczorek,Mohamed A. Abdelsalam,Rahaf Aljundi,Marcus Rohrbach*

Main category: cs.CV

> 研究了后训练量化对多模态大语言模型在视觉问答任务中准确性和可靠性的影响，并提出了一种选择器置信度估算器来提升量化模型的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 解决多模态大语言模型在部署时面临的可靠性问题和模型压缩的需求。

**Method:** 通过在不同比特宽度下使用无数据与有数据量化方法对两个多模态模型进行压缩，并且引入选择器置信度估算器来应对量化引起的可靠性下降。

**Result:** 后训练量化降低了准确性和可靠性，但有数据量化方法缓解了这种影响。选择器显著提升了可靠性。结合int4 MBQ与选择器在降低约75%内存需求的同时实现了较好的效率和可靠性平衡。

**Conclusion:** 首次系统地研究了量化与多模态模型可靠性之间的联系。

**Abstract:** Multimodal Large Language Models (MLLM) are increasingly deployed in domains where both reliability and efficiency are critical. However, current models remain overconfident, producing highly certain but incorrect answers. At the same time, their large size limits deployment on edge devices, necessitating compression. We study the intersection of these two challenges by analyzing how Post-Training Quantization (PTQ) compression affects both accuracy and reliability in Visual Question Answering (VQA). We evaluate two MLLMs, Qwen2-VL-7B and Idefics3-8B, quantized with data-free (HQQ) and data-aware (MBQ) methods across multiple bit widths. To counteract the reduction in reliability caused by quantization, we adapt the Selector confidence estimator for quantized multimodal settings and test its robustness across various quantization levels and out-of-distribution (OOD) scenarios. We find that PTQ degrades both accuracy and reliability. Data-aware methods soften the effect thereof. The Selector substantially mitigates the reliability impact. The combination of int4 MBQ and the Selector achieves the best efficiency-reliability trade-off, closing in on uncompressed performance at approx. 75% less memory demand. Overall, we present the first systematic study linking quantization and reliability in multimodal settings.

</details>


### [16] [NutVLM: A Self-Adaptive Defense Framework against Full-Dimension Attacks for Vision Language Models in Autonomous Driving](https://arxiv.org/abs/2602.13293)
*Xiaoxu Peng,Dong Zhou,Jianwen Zhang,Guanghui Sun,Anh Tu Ngo,Anupam Chattopadhyay*

Main category: cs.CV

> NutVLM, a self-adaptive defense framework for Vision Language Models, ensures robustness against adversarial attacks like localized physical patches and global perturbations while maintaining performance on clean data.

<details>
  <summary>Details</summary>

**Motivation:** The motivation stems from the fact that VLM's are susceptible to adversarial attacks, which compromises their effectiveness in autonomous driving (AD) tasks. Current defense strategies often fail to ensure robustness without sacrificing the model's performance on clean data. The introduction of NutVLM is intended to address this issue comprehensively.

**Method:** Vision Language Models (VLMs) are made more resilient to adversarial attacks through NutVLM, a self-adaptive defense framework. NutNet++ acts as a front-line defense mechanism; it distinguishes between benign samples, local patches, and global perturbations. To address localized threats, a simple grayscale masking approach is enough to clear the threat, whereas global perturbations are countered through Expert-guided Adversarial Prompt Tuning (EAPT). EAPT creates corrective driving prompts, alleviating the need for retraining the entire model.

**Result:** The results of the NutVLM framework show a 4.89% improvement in overall metrics, such as accuracy, language score, and GPT score, on the Dolphins benchmark. This indicates the efficacy of the defense mechanism in enhancing the security of VLMs without degrading their performance on clean samples.

**Conclusion:** NutVLM offers a promising and scalable approach to securing VLMs against adversarial attacks in autonomous driving scenarios, balancing robustness and performance efficiency.

**Abstract:** Vision Language Models (VLMs) have advanced perception in autonomous driving (AD), but they remain vulnerable to adversarial threats. These risks range from localized physical patches to imperceptible global perturbations. Existing defense methods for VLMs remain limited and often fail to reconcile robustness with clean-sample performance. To bridge these gaps, we propose NutVLM, a comprehensive self-adaptive defense framework designed to secure the entire perception-decision lifecycle. Specifically, we first employ NutNet++ as a sentinel, which is a unified detection-purification mechanism. It identifies benign samples, local patches, and global perturbations through three-way classification. Subsequently, localized threats are purified via efficient grayscale masking, while global perturbations trigger Expert-guided Adversarial Prompt Tuning (EAPT). Instead of the costly parameter updates of full-model fine-tuning, EAPT generates "corrective driving prompts" via gradient-based latent optimization and discrete projection. These prompts refocus the VLM's attention without requiring exhaustive full-model retraining. Evaluated on the Dolphins benchmark, our NutVLM yields a 4.89% improvement in overall metrics (e.g., Accuracy, Language Score, and GPT Score). These results validate NutVLM as a scalable security solution for intelligent transportation. Our code is available at https://github.com/PXX/NutVLM.

</details>


### [17] [VisPhyWorld: Probing Physical Reasoning via Code-Driven Video Reconstruction](https://arxiv.org/abs/2602.13294)
*Jiarong Liang,Max Ku,Ka-Hei Hui,Ping Nie,Wenhu Chen*

Main category: cs.CV

> 通过引入一种新的评估框架VisPhyWorld和评估协议VisPhyBench，研究发现虽然最先进的MLLMs在理解语义场景方面表现优秀，但在物理动态模拟方面仍存在不足。

<details>
  <summary>Details</summary>

**Motivation:** 评估多模态大语言模型（MLLMs）是否真的能够推理物理动态仍然具有挑战性，因为大多数现有的基准依赖于识别式的协议，这些协议可不要求形成显式的、可测试的物理假设。

**Method:** 提出了一种名为VisPhyWorld的执行框架，该框架通过要求模型根据视觉观察生成可执行的模拟代码来评估物理推理。此框架将物理推理与渲染分离。

**Result:** 该研究的基准上生成的有效重建视频比例为97.7%。实验表明，虽然最先进的MLLMs在语义场景理解方面表现出色，但它们在准确推断物理参数和模拟一致的物理动态方面仍存在问题。

**Conclusion:** 实验显示，尽管最先进的MLLMs在语义场景理解方面表现出色，但它们在准确推断物理参数和模拟一致的物理动态方面却表现不佳。

**Abstract:** Evaluating whether Multimodal Large Language Models (MLLMs) genuinely reason about physical dynamics remains challenging. Most existing benchmarks rely on recognition-style protocols such as Visual Question Answering (VQA) and Violation of Expectation (VoE), which can often be answered without committing to an explicit, testable physical hypothesis. We propose VisPhyWorld, an execution-based framework that evaluates physical reasoning by requiring models to generate executable simulator code from visual observations. By producing runnable code, the inferred world representation is directly inspectable, editable, and falsifiable. This separates physical reasoning from rendering. Building on this framework, we introduce VisPhyBench, comprising 209 evaluation scenes derived from 108 physical templates and a systematic protocol that evaluates how well models reconstruct appearance and reproduce physically plausible motion. Our pipeline produces valid reconstructed videos in 97.7% on the benchmark. Experiments show that while state-of-the-art MLLMs achieve strong semantic scene understanding, they struggle to accurately infer physical parameters and to simulate consistent physical dynamics.

</details>


### [18] [MFN Decomposition and Related Metrics for High-Resolution Range Profiles Generative Models](https://arxiv.org/abs/2602.13296)
*Edwyn Brient,Santiago Velasco-Forero,Rami Kassab*

Main category: cs.CV

> The paper focuses on decomposing HRRP data into mask, features, and noise components and proposes two evaluation metrics based on physical interpretation, demonstrating their discriminative ability on a challenging task with an expensive dataset.

<details>
  <summary>Details</summary>

**Motivation:** The paper is motivated by the need to evaluate HRRP data generated by models effectively and the challenge of using black-box classification models for evaluation.

**Method:** The method used in the paper involves decomposing HRRP data into three components and formulating two metrics based on the physical properties of HRRP.

**Result:** The paper demonstrates that the proposed metrics are effective in evaluating generated HRRP data and are more revealing than black-box classification models.

**Conclusion:** The conclusion is that the proposed evaluation metrics based on decomposing HRRP data into components can be more effective and provide a deeper understanding of the generated data compared to current methods reliant on black-box classifiers.

**Abstract:** High-resolution range profile (HRRP ) data are in vogue in radar automatic target recognition (RATR). With the interest in classifying models using HRRP, filling gaps in datasets using generative models has recently received promising contributions. Evaluating generated data is a challenging topic, even for explicit data like face images. However, the evaluation methods used in the state-ofthe-art of HRRP generation rely on classification models. Such models, called ''black-box'', do not allow either explainability on generated data or multi-level evaluation. This work focuses on decomposing HRRP data into three components: the mask, the features, and the noise. Using this decomposition, we propose two metrics based on the physical interpretation of those data. We take profit from an expensive dataset to evaluate our metrics on a challenging task and demonstrate the discriminative ability of those.

</details>


### [19] [Conditional Generative Models for High-Resolution Range Profiles: Capturing Geometry-Driven Trends in a Large-Scale Maritime Dataset](https://arxiv.org/abs/2602.13297)
*Edwyn Brient,Santiago Velasco-Forero,Rami Kassab*

Main category: cs.CV

> 研究通过条件生成模型在大型海事数据库上分析高分辨率距离轮廓（HRRP）的合成，成功重现了真实数据的几何趋势，显示了获取几何对稳健HRRP生成的重要作用。

<details>
  <summary>Details</summary>

**Motivation:** 高分辨率距离轮廓（HRRP）对于雷达自动目标识别具有快速机载处理的优势，但其对获取条件的高敏感度限制了其在操作场景中的鲁棒性。通过条件HRRP生成可以缓解这一问题，但之前的研究受限于小且高度专业化的数据集。

**Method:** 研究集中在高分辨率距离轮廓（HRRP）的合成上，特别是在一个大型海事数据库上进行分析，该数据库代表了沿海监视的变化性。通过条件生成模型，研究对船只尺寸和期望的方面角度进行训练，以生成合成签名。

**Result:** 研究表明，生成模型在条件变量上的训练可以产生符合真实数据中观察到的视线几何趋势的合成签名。

**Conclusion:** 这些结果强调了获取几何对于稳健HRRP生成的核心作用。

**Abstract:** High-resolution range profiles (HRRPs) enable fast onboard processing for radar automatic target recognition, but their strong sensitivity to acquisition conditions limits robustness across operational scenarios. Conditional HRRP generation can mitigate this issue, yet prior studies are constrained by small, highly specific datasets. We study HRRP synthesis on a largescale maritime database representative of coastal surveillance variability. Our analysis indicates that the fundamental scenario drivers are geometric: ship dimensions and the desired aspect angle. Conditioning on these variables, we train generative models and show that the synthesized signatures reproduce the expected line-of-sight geometric trend observed in real data. These results highlight the central role of acquisition geometry for robust HRRP generation.

</details>
