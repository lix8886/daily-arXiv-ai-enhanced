{"id": "2507.13357", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2507.13357", "abs": "https://arxiv.org/abs/2507.13357", "authors": ["Atharva Bhargude", "Ishan Gonehal", "Chandler Haney", "Dave Yoon", "Kevin Zhu", "Aaron Sandoval", "Sean O'Brien", "Kaustubh Vinnakota"], "title": "Adaptive Linguistic Prompting (ALP) Enhances Phishing Webpage Detection in Multimodal Large Language Models", "comment": "Published at ACL 2025 SRW, 9 pages, 3 figures", "summary": "Phishing attacks represent a significant cybersecurity threat, necessitating\nadaptive detection techniques. This study explores few-shot Adaptive Linguistic\nPrompting (ALP) in detecting phishing webpages through the multimodal\ncapabilities of state-of-the-art large language models (LLMs) such as GPT-4o\nand Gemini 1.5 Pro. ALP is a structured semantic reasoning method that guides\nLLMs to analyze textual deception by breaking down linguistic patterns,\ndetecting urgency cues, and identifying manipulative diction commonly found in\nphishing content. By integrating textual, visual, and URL-based analysis, we\npropose a unified model capable of identifying sophisticated phishing attempts.\nOur experiments demonstrate that ALP significantly enhances phishing detection\naccuracy by guiding LLMs through structured reasoning and contextual analysis.\nThe findings highlight the potential of ALP-integrated multimodal LLMs to\nadvance phishing detection frameworks, achieving an F1-score of 0.93,\nsurpassing traditional approaches. These results establish a foundation for\nmore robust, interpretable, and adaptive linguistic-based phishing detection\nsystems using LLMs.", "AI": {"tldr": "本研究探讨了通过自适应语言提示（ALP）方法，利用大型语言模型（如GPT-4o和Gemini 1.5 Pro）多模态能力检测网络钓鱼网页的技术，展示了显著提高检测准确率的潜力。", "motivation": "网络钓鱼攻击是重大网络安全威胁，需要适应性的检测技术。研究表明ALP方法能够提高网络钓鱼检测准确率。", "method": "通过结构化语义推理方法ALP，指导大型语言模型分析文本欺骗，寻找语言模式、紧急提示以及操纵性措辞，并整合文本、视觉和URL分析，构建统一的检测模型。", "result": "实验结果显示，ALP方法能够引导大型语言模型通过结构化推理和上下文分析提高钓鱼检测准确性，得到F1评分为0.93，超越传统方法。", "conclusion": "研究证明了ALP融合多模态大型语言模型对改进钓鱼检测框架的有效性，为更强大、可解释和自适应的语言基础钓鱼检测系统奠定了基础。"}}
{"id": "2507.13380", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13380", "abs": "https://arxiv.org/abs/2507.13380", "authors": ["Keito Inoshita", "Rushia Harada"], "title": "Persona-Based Synthetic Data Generation Using Multi-Stage Conditioning with Large Language Models for Emotion Recognition", "comment": null, "summary": "In the field of emotion recognition, the development of high-performance\nmodels remains a challenge due to the scarcity of high-quality, diverse\nemotional datasets. Emotional expressions are inherently subjective, shaped by\nindividual personality traits, socio-cultural backgrounds, and contextual\nfactors, making large-scale, generalizable data collection both ethically and\npractically difficult. To address this issue, we introduce PersonaGen, a novel\nframework for generating emotionally rich text using a Large Language Model\n(LLM) through multi-stage persona-based conditioning. PersonaGen constructs\nlayered virtual personas by combining demographic attributes, socio-cultural\nbackgrounds, and detailed situational contexts, which are then used to guide\nemotion expression generation. We conduct comprehensive evaluations of the\ngenerated synthetic data, assessing semantic diversity through clustering and\ndistributional metrics, human-likeness via LLM-based quality scoring, realism\nthrough comparison with real-world emotion corpora, and practical utility in\ndownstream emotion classification tasks. Experimental results show that\nPersonaGen significantly outperforms baseline methods in generating diverse,\ncoherent, and discriminative emotion expressions, demonstrating its potential\nas a robust alternative for augmenting or replacing real-world emotional\ndatasets.", "AI": {"tldr": "提出了一种新的情感表达生成框架PersonaGen，用于解决高质量情感数据集稀少的问题，并展示出其优于现有方法的性能。", "motivation": "由于高质量、多样化的情感数据集稀缺，导致情感识别领域高性能模型的开发具有挑战性。情感表达本质上是主观的，受到个体性格特征、社会文化背景和情境因素的影响，大规模通用数据收集既有伦理问题又有实际困难。为了应对这个问题，提出了PersonaGen框架。", "method": "PersonaGen，一种利用大型语言模型（LLM）通过多阶段基于角色的条件生成情感丰富文本的新框架。PersonaGen 通过结合人口统计属性、社会文化背景和详细情境背景构建分层的虚拟角色，用来指导情感表达生成。", "result": "实验结果显示，PersonaGen 在生成多样化、连贯且具有区分性的情感表达方面显著优于基线方法，展示出作为增强或替代现实世界情感数据集的潜力。", "conclusion": "PersonaGen 框架能够生成多样化的、连贯的、具有区分性的情感表达，证明了其作为增强或替代现实世界情感数据集的潜在能力。"}}
{"id": "2507.13381", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.13381", "abs": "https://arxiv.org/abs/2507.13381", "authors": ["Rafiq Kamel", "Filippo Guerranti", "Simon Geisler", "Stephan Günnemann"], "title": "SAFT: Structure-Aware Fine-Tuning of LLMs for AMR-to-Text Generation", "comment": "Accepted at the KDD2025 Workshop on Structured Knowledge for LLMs", "summary": "Large Language Models (LLMs) are increasingly applied to tasks involving\nstructured inputs such as graphs. Abstract Meaning Representations (AMRs),\nwhich encode rich semantics as directed graphs, offer a rigorous testbed for\nevaluating LLMs on text generation from such structures. Yet, current methods\noften arbitrarily linearize AMRs, discarding key structural cues, or rely on\narchitectures incompatible with standard LLMs. We introduce SAFT, a\nstructure-aware fine-tuning approach that injects graph topology into\npretrained LLMs without architectural changes. We compute direction-sensitive\npositional encodings from the magnetic Laplacian of transformed AMRs and\nproject them into the embedding space of the LLM. While possibly applicable to\nany graph-structured inputs, we focus on AMR-to-text generation as a\nrepresentative and challenging benchmark. SAFT sets a new state-of-the-art on\nAMR 3.0 with a 3.5 BLEU improvement over baselines. Gains scale with graph\ncomplexity, highlighting the value of structure-aware representations in\nenhancing LLM performance. SAFT offers a general and effective pathway for\nbridging structured data and language models.", "AI": {"tldr": "介绍了一种结构敏感的微调方法SAFT，将图形拓扑注入到预训练的LLM中，从而在AMR文本生成任务上实现了新的最佳业绩，显著提升了LLM在处理复杂结构输入时的性能。", "motivation": "当前方法在处理AMR时，要么任意地线性化AMR，丢弃关键的结构线索，要么依赖于与标准LLM不兼容的架构。因此，需要一种方法能在保留图形结构信息的同时，与标准LLM兼容。", "method": "SAFT方法通过计算从变换后的AMR的磁场拉普拉斯矩阵的方向敏感的位置编码，并将它们投影到LLM的嵌入空间中，从而将图形结构注入到预训练的LLM中，而无需对架构进行任何更改。", "result": "SAFT在AMR 3.0上的性能优于基线模型，BLEU值提升了3.5。研究表明，结构敏感表示法在提升LLM处理复杂结构输入的性能上的有效性。", "conclusion": "SAFT提供了一种通用而有效的方法，用于将结构化数据与语言模型结合，能够在不改变模型架构的情况下显著提升LLM处理复杂结构数据的能力。"}}
{"id": "2507.13382", "categories": ["cs.CL", "cs.LG", "05-05C12"], "pdf": "https://arxiv.org/pdf/2507.13382", "abs": "https://arxiv.org/abs/2507.13382", "authors": ["Chandrashekar Muniyappa", "Sirisha Velampalli"], "title": "Context-Based Fake News Detection using Graph Based Approach: ACOVID-19 Use-case", "comment": "CSAIDE '25: Proceedings of the 2025 4th International Conference on\n  Cyber Security, Artificial Intelligence and the Digital Economy", "summary": "In today\\'s digital world, fake news is spreading with immense speed. Its a\nsignificant concern to address. In this work, we addressed that challenge using\nnovel graph based approach. We took dataset from Kaggle that contains real and\nfake news articles. To test our approach we incorporated recent covid-19\nrelated news articles that contains both genuine and fake news that are\nrelevant to this problem. This further enhances the dataset as well instead of\nrelying completely on the original dataset. We propose a contextual graph-based\napproach to detect fake news articles. We need to convert news articles into\nappropriate schema, so we leverage Natural Language Processing (NLP) techniques\nto transform news articles into contextual graph structures. We then apply the\nMinimum Description Length (MDL)-based Graph-Based Anomaly Detection (GBAD)\nalgorithm for graph mining. Graph-based methods are particularly effective for\nhandling rich contextual data, as they enable the discovery of complex patterns\nthat traditional query-based or statistical techniques might overlook. Our\nproposed approach identifies normative patterns within the dataset and\nsubsequently uncovers anomalous patterns that deviate from these established\nnorms.", "AI": {"tldr": "The paper introduces a graph-based approach using NLP techniques and the MDL-based GBAD algorithm for anomaly detection to identify fake news articles, enhancing the dataset with recent COVID-19 related news for better results.", "motivation": "The rapid spread of fake news in the digital world necessitates effective detection methods. The authors aim to improve upon traditional techniques by utilizing graph-based anomaly detection on both existing and more recent contextual datasets.", "method": "The authors employ a contextual graph-based approach where NLP techniques are used to convert news articles into graph structures. They then use the MDL-based GBAD algorithm for identifying anomalous patterns which correspond to fake news.", "result": "The method is tested on a dataset enhanced with recent COVID-19 news, allowing for a more contemporary and relevant analysis compared to relying solely on the original dataset.", "conclusion": "Graph-based methods, enhanced with NLP and GBAD, are effective in detecting fake news by identifying complex patterns and anomalies missed by traditional approaches."}}
{"id": "2507.13359", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.13359", "abs": "https://arxiv.org/abs/2507.13359", "authors": ["Yang Zhou", "Junjie Li", "CongYang Ou", "Dawei Yan", "Haokui Zhang", "Xizhe Xue"], "title": "Open-Vocabulary Object Detection in UAV Imagery: A Review and Future Perspectives", "comment": "27 pages, 5 figures", "summary": "Due to its extensive applications, aerial image object detection has long\nbeen a hot topic in computer vision. In recent years, advancements in Unmanned\nAerial Vehicles (UAV) technology have further propelled this field to new\nheights, giving rise to a broader range of application requirements. However,\ntraditional UAV aerial object detection methods primarily focus on detecting\npredefined categories, which significantly limits their applicability. The\nadvent of cross-modal text-image alignment (e.g., CLIP) has overcome this\nlimitation, enabling open-vocabulary object detection (OVOD), which can\nidentify previously unseen objects through natural language descriptions. This\nbreakthrough significantly enhances the intelligence and autonomy of UAVs in\naerial scene understanding. This paper presents a comprehensive survey of OVOD\nin the context of UAV aerial scenes. We begin by aligning the core principles\nof OVOD with the unique characteristics of UAV vision, setting the stage for a\nspecialized discussion. Building on this foundation, we construct a systematic\ntaxonomy that categorizes existing OVOD methods for aerial imagery and provides\na comprehensive overview of the relevant datasets. This structured review\nenables us to critically dissect the key challenges and open problems at the\nintersection of these fields. Finally, based on this analysis, we outline\npromising future research directions and application prospects. This survey\naims to provide a clear road map and a valuable reference for both newcomers\nand seasoned researchers, fostering innovation in this rapidly evolving domain.\nWe keep tracing related works at\nhttps://github.com/zhouyang2002/OVOD-in-UVA-imagery", "AI": {"tldr": "本文综述了在无人机视角下开放式词汇物体检测（OVOD）的技术进展，通过构建系统分类法介绍了现有的OVOD方法及相关数据集，并探讨了领域内的挑战和未来研究方向。", "motivation": "传统的无人机物体检测方法受限于预定义的类别，难以满足更广泛的检测需求。跨模态文本-图像对齐技术（如CLIP）使得开放式词汇物体检测成为可能，显著提高了无人机图像理解的智能性和自主性。", "method": "通过对开放式词汇物体检测(OVOD)与无人机视觉特性的结合进行概述，构建系统分类法，详细介绍现有方法及其数据集。", "result": "本文构建了详细的OVOD方法分类体系，概述了相关数据集，并指出了研究中的挑战及问题。", "conclusion": "综上所述，本文提出了未来研究的方向和应用前景，为领域内的研究人员提供了清晰的研究路线图。"}}
{"id": "2507.13390", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.13390", "abs": "https://arxiv.org/abs/2507.13390", "authors": ["Kundeshwar Pundalik", "Piyush Sawarkar", "Nihar Sahoo", "Abhishek Shinde", "Prateek Chanda", "Vedant Goswami", "Ajay Nagpal", "Atul Singh", "Viraj Thakur", "Vijay Dewane", "Aamod Thakur", "Bhargav Patel", "Smita Gautam", "Bhagwan Panditi", "Shyam Pawar", "Madhav Kotcha", "Suraj Racha", "Saral Sureka", "Pankaj Singh", "Rishi Bal", "Rohit Saluja", "Ganesh Ramakrishnan"], "title": "PARAM-1 BharatGen 2.9B Model", "comment": null, "summary": "Large Language Models (LLMs) have emerged as powerful general-purpose\nreasoning systems, yet their development remains dominated by English-centric\ndata, architectures, and optimization paradigms. This exclusionary design\nresults in structural under-representation of linguistically diverse regions\nsuch as India, where over 20 official languages and 100+ dialects coexist\nalongside phenomena like code-switching and diglossia. We introduce PARAM-1, a\n2.9B parameter decoder-only, text-only language model trained from scratch with\nan explicit architectural and linguistic focus on Indian diversity. PARAM-1 is\ntrained on a bilingual dataset consisting of only Hindi and English,\nconstructed with a strong focus on fact-rich, high-quality content. It is\nguided by three core principles: equitable representation of Indic languages\nthrough a 25% corpus allocation; tokenization fairness via a SentencePiece\ntokenizer adapted to Indian morphological structures; and culturally aligned\nevaluation benchmarks across IndicQA, code-mixed reasoning, and\nsocio-linguistic robustness tasks. By embedding diversity at the pretraining\nlevel-rather than deferring it to post-hoc alignment-PARAM-1 offers a\ndesign-first blueprint for equitable foundation modeling. Our results\ndemonstrate that it serves as both a competent general-purpose model and a\nrobust baseline for India-centric applications.", "AI": {"tldr": "PARAM-1模型通过双语训练和文化相关的设计原则，确保了印度语言的多样性和公平性表示，在印度语言背景下展现出了强大的泛用能力和特化任务支持能力。", "motivation": "大规模语言模型虽然作为强有力的通用推理系统，但其发展仍然以英语为主导，因此针对印度这样语言和文化多样性丰富的地区存在显著的结构性不足。本研究目的在于通过引入PARAM-1模型，提供一个将多样性在中国预训练阶段即加以重视的设计蓝图。", "method": "PARAM-1是一种具有29亿参数的解码器式，纯文本语言模型，专门针对印度的语言多样性进行构建和优化。该模型使用包含印地语和英语的双语数据集进行训练，重点在于含有丰富事实且高质量的内容。模型设计遵循三项基本原则：通过语料库分配保证印度语系的公正表示（25%的语料库分配给印度语言）；根据印度语系的形态结构调整SentencePiece分词器以确保分词公平性；通过涵盖包括印第安QA、混合语言推理和语言社会学稳健性任务的评估基准来保持文化相关性。", "result": "实验结果表明，PARAM-1不仅是一个够用的通用模型，也为印度本土应用提供了一个稳健的基准。", "conclusion": "PARAM-1证明了在模型设计初期就考虑语言多样性的设计理念，可以有效提升语言模型在处理具有文化和社会语言学特征任务中的性能，为构建公平性基础模型提供了范例。"}}
{"id": "2507.13360", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2507.13360", "abs": "https://arxiv.org/abs/2507.13360", "authors": ["Le-Anh Tran", "Chung Nguyen Tran", "Ngoc-Luu Nguyen", "Nhan Cach Dang", "Jordi Carrabina", "David Castells-Rufas", "Minh Son Nguyen"], "title": "Low-Light Enhancement via Encoder-Decoder Network with Illumination Guidance", "comment": "6 pages, 3 figures, ICCCE 2025", "summary": "This paper introduces a novel deep learning framework for low-light image\nenhancement, named the Encoder-Decoder Network with Illumination Guidance\n(EDNIG). Building upon the U-Net architecture, EDNIG integrates an illumination\nmap, derived from Bright Channel Prior (BCP), as a guidance input. This\nillumination guidance helps the network focus on underexposed regions,\neffectively steering the enhancement process. To further improve the model's\nrepresentational power, a Spatial Pyramid Pooling (SPP) module is incorporated\nto extract multi-scale contextual features, enabling better handling of diverse\nlighting conditions. Additionally, the Swish activation function is employed to\nensure smoother gradient propagation during training. EDNIG is optimized within\na Generative Adversarial Network (GAN) framework using a composite loss\nfunction that combines adversarial loss, pixel-wise mean squared error (MSE),\nand perceptual loss. Experimental results show that EDNIG achieves competitive\nperformance compared to state-of-the-art methods in quantitative metrics and\nvisual quality, while maintaining lower model complexity, demonstrating its\nsuitability for real-world applications. The source code for this work is\navailable at https://github.com/tranleanh/ednig.", "AI": {"tldr": "The paper presents EDNIG, a deep learning framework for enhancing low-light images through the use of an illumination map and various architectural enhancements, achieving competitive results with lower model complexity.", "motivation": "To introduce a novel deep learning framework, EDNIG, for low-light image enhancement that effectively handles underexposed regions and maintains lower model complexity for real-world applications.", "method": "Building upon the U-Net architecture, EDNIG integrates an illumination map derived from Bright Channel Prior (BCP) as a guidance input to focus on underexposed regions. A Spatial Pyramid Pooling (SPP) module is incorporated to extract multi-scale contextual features, and the Swish activation function is used for smoother gradient propagation during training. The model is optimized within a Generative Adversarial Network (GAN) framework using a composite loss function that combines adversarial loss, pixel-wise mean squared error (MSE), and perceptual loss.", "result": "Experimental results show that EDNIG achieves competitive performance compared to state-of-the-art methods in both quantitative metrics and visual quality.", "conclusion": "EDNIG demonstrates both lower model complexity and competitive performance, making it suitable for real-world low-light image enhancement applications."}}
{"id": "2507.13392", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13392", "abs": "https://arxiv.org/abs/2507.13392", "authors": ["Emil Häglund", "Johanna Björklund"], "title": "TopicImpact: Improving Customer Feedback Analysis with Opinion Units for Topic Modeling and Star-Rating Prediction", "comment": null, "summary": "We improve the extraction of insights from customer reviews by restructuring\nthe topic modelling pipeline to operate on opinion units - distinct statements\nthat include relevant text excerpts and associated sentiment scores. Prior work\nhas demonstrated that such units can be reliably extracted using large language\nmodels. The result is a heightened performance of the subsequent topic\nmodeling, leading to coherent and interpretable topics while also capturing the\nsentiment associated with each topic. By correlating the topics and sentiments\nwith business metrics, such as star ratings, we can gain insights on how\nspecific customer concerns impact business outcomes. We present our system's\nimplementation, use cases, and advantages over other topic modeling and\nclassification solutions. We also evaluate its effectiveness in creating\ncoherent topics and assess methods for integrating topic and sentiment\nmodalities for accurate star-rating prediction.", "AI": {"tldr": "通过重新构建主题建模管道以利用意见单元（包括相关文本摘录和情感分数的独立声明）来提高从客户评论中提取洞察的能力，从而实现更好地关联主题情感与业务指标，以了解特定客户关注如何影响业务成果.", "motivation": "改进从客户评论中提取见解的能力，通过在意见单元上进行主题建模，使得提取的标签和情感相关更为有效。以此为基础，企业可以获得关键的商业指标洞见。", "method": "使用大型语言模型可靠提取意见单元，改进主题建模管道。通过关联主题和情感与商业指标，评估系统的效能及预测星评级的方法。", "result": "实现更加连贯和可解释的主题，同时捕捉与每个主题相关的情感，从而提高主题分类和情感分析的综合性能。", "conclusion": "此系统在创建连贯主题方面有效，对于整合主题和情感模态进行准确的星评级预测也具有优势。相较于其他主题建模和分类方案，具有显著改进。"}}
{"id": "2507.13361", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13361", "abs": "https://arxiv.org/abs/2507.13361", "authors": ["Shmuel Berman", "Jia Deng"], "title": "VLMs have Tunnel Vision: Evaluating Nonlocal Visual Reasoning in Leading VLMs", "comment": null, "summary": "Visual Language Models (VLMs) excel at complex visual tasks such as VQA and\nchart understanding, yet recent work suggests they struggle with simple\nperceptual tests. We present an evaluation that tests vision-language models'\ncapacity for nonlocal visual reasoning -- reasoning that requires chaining\nevidence collected from multiple, possibly distant, regions of an image. We\nisolate three distinct forms of non-local vision: comparative perception, which\ndemands holding two images in working memory and comparing them; saccadic\nsearch, which requires making discrete, evidence-driven jumps to locate\nsuccessive targets; and smooth visual search, which involves searching smoothly\nalong a continuous contour. Flagship models (e.g., Gemini 2.5 Pro, Claude\nVision 3.7, GPT-o4-mini), even those that perform well on prior\nprimitive-vision benchmarks, fail these tests and barely exceed random accuracy\non two variants of our tasks that are trivial for humans. Our structured\nevaluation suite allows us to test if VLMs can perform similar visual\nalgorithms to humans. Our findings show that despite gains in raw visual\nacuity, current models lack core visual reasoning capabilities.", "AI": {"tldr": "研究通过评估视觉语言模型在非局部视觉推理任务中的表现，发现它们尽管在某些复杂任务中有出色表现，但在核心视觉推理能力上仍不如人类。", "motivation": "尽管视觉语言模型在复杂任务中表现出色，但研究发现它们在简单的感知测试中表现不佳。该研究旨在探讨这些模型是否具备类似于人类的视觉算法能力。", "method": "该研究设计了一套评估体系，测试视觉语言模型在非局部视觉推理任务中的能力，特别是比较感知、跳跃搜索和平滑视觉搜索三方面。", "result": "即使是那些在原始视觉基准测试中表现良好的旗舰模型，也在研究设计的测试中失败，且在某些任务中表现仅略高于随机水平。", "conclusion": "研究结果显示，尽管模型在视觉敏锐度上有所进步，但在核心视觉推理能力上仍显不足。"}}
{"id": "2507.13395", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2507.13395", "abs": "https://arxiv.org/abs/2507.13395", "authors": ["Xuanqi Gao", "Weipeng Jiang", "Juan Zhai", "Shiqing Ma", "Siyi Xie", "Xinyang Yin", "Chao Shen"], "title": "Mitigating Stylistic Biases of Machine Translation Systems via Monolingual Corpora Only", "comment": null, "summary": "The advent of neural machine translation (NMT) has revolutionized\ncross-lingual communication, yet preserving stylistic nuances remains a\nsignificant challenge. While existing approaches often require parallel corpora\nfor style preservation, we introduce Babel, a novel framework that enhances\nstylistic fidelity in NMT using only monolingual corpora. Babel employs two key\ncomponents: (1) a style detector based on contextual embeddings that identifies\nstylistic disparities between source and target texts, and (2) a\ndiffusion-based style applicator that rectifies stylistic inconsistencies while\nmaintaining semantic integrity. Our framework integrates with existing NMT\nsystems as a post-processing module, enabling style-aware translation without\nrequiring architectural modifications or parallel stylistic data. Extensive\nexperiments on five diverse domains (law, literature, scientific writing,\nmedicine, and educational content) demonstrate Babel's effectiveness: it\nidentifies stylistic inconsistencies with 88.21% precision and improves\nstylistic preservation by 150% while maintaining a high semantic similarity\nscore of 0.92. Human evaluation confirms that translations refined by Babel\nbetter preserve source text style while maintaining fluency and adequacy.", "AI": {"tldr": "Babel是一种新框架，旨在通过使用单语语料库来解决神经机器翻译中保留风格一致性的问题。", "motivation": "现有的机器翻译方法往往需要平行语料库来保持风格一致，而Babel框架则希望通过仅使用单语语料库的方法，来提高不同语言间沟通的风格保真度。", "method": "Babel框架利用两个关键组件来解决机器翻译中的风格保持问题：一是基于上下文嵌入的风格检测器，用于识别源文本和目标文本之间的风格差异；二是基于扩散的方法，用于修正这些风格不一致而保持语义一致性。该框架作为现有NMT系统的后处理模块运行，无需对架构进行修改或使用平行样式的数据。", "result": "在五种不同领域（法学、文学、科学写作、医学、教育内容）的广泛实验中，Babel框架被证明是有效的，如它以88.21%的精度识别了风格不一致，并提高了150%的风格保存，同时保持0.92的高语义相似度评分。人类评估亦证实，经过Babel调整后的翻译更好地保持了原始文本的风格，同时保持流畅性和准确性。", "conclusion": "实验结果和人类评估证明了Babel在五种不同领域中具有提高神经机器翻译风格一致性的有效性。这是在不依赖平行语料库的情况下，通过仅使用单语语料库实现了风格保持的显著进步。"}}
