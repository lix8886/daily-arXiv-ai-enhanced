<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 22]
- [cs.CV](#cs.CV) [Total: 19]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Uncovering Implicit Bias in Large Language Models with Concept Learning Dataset](https://arxiv.org/abs/2510.01219)
*Leroy Z. Wang*

Main category: cs.CL

> 通过特定任务集发现大型语言模型在上下文概念学习任务中对上行单调性的隐性偏见。

<details>
  <summary>Details</summary>

**Motivation:** 揭示大型语言模型内部存在的隐性偏见，特别在量词使用上。

**Method:** 通过上下文概念学习实验发现语言模型中的隐性偏见，特别是上行单调性在量词中的偏见。

**Result:** 发现语言模型在概念学习实验中的上行单调性偏见比直接提示测试中更为明显。

**Conclusion:** 上下文概念学习是一种有效发现语言模型中隐藏偏见的方法。

**Abstract:** We introduce a dataset of concept learning tasks that helps uncover implicit
biases in large language models. Using in-context concept learning experiments,
we found that language models may have a bias toward upward monotonicity in
quantifiers; such bias is less apparent when the model is tested by direct
prompting without concept learning components. This demonstrates that
in-context concept learning can be an effective way to discover hidden biases
in language models.

</details>


### [2] [Towards Open-Ended Discovery for Low-Resource NLP](https://arxiv.org/abs/2510.01220)
*Bonaventure F. P. Dossou,Henri Aïdasso*

Main category: cs.CL

> 本文提出了一种面向未来的方法，即在少资源语言和未充分记录语言的处理中，通过结合人机不确定性进行动态学习，以解决由于缺乏文本语料库和标注流水线所造成的制约。

<details>
  <summary>Details</summary>

**Motivation:** 论文的动机在于，尽管大语言模型在跨语言转移方面有了改进，但对于缺乏大量预收集数据和集中式基础设施的少资源和未充分记录的语言社区来说，这些方法仍然难以触及。作者认为亟需向开放性、交互式语言发现转变，即人工智能系统通过对话而非静态数据集动态学习新语言。

**Method:** 本文提出了一种新的框架，该框架基于联合的人机不确定性，结合模型的本体不确定性与人类说话者的犹豫线索和信心信号，以引导交互、查询选择和记忆保留。

**Result:** 

**Conclusion:** 该论文呼吁重新思考人工智能在未充分记录的语言中如何与人类知识互动，并提出从抽取式数据收集转向参与式、共同适应的学习过程的愿景，这种过程尊重并赋予社区权力，同时发现和保存世界上的语言多样性。

**Abstract:** Natural Language Processing (NLP) for low-resource languages remains
fundamentally constrained by the lack of textual corpora, standardized
orthographies, and scalable annotation pipelines. While recent advances in
large language models have improved cross-lingual transfer, they remain
inaccessible to underrepresented communities due to their reliance on massive,
pre-collected data and centralized infrastructure. In this position paper, we
argue for a paradigm shift toward open-ended, interactive language discovery,
where AI systems learn new languages dynamically through dialogue rather than
static datasets. We contend that the future of language technology,
particularly for low-resource and under-documented languages, must move beyond
static data collection pipelines toward interactive, uncertainty-driven
discovery, where learning emerges dynamically from human-machine collaboration
instead of being limited to pre-existing datasets. We propose a framework
grounded in joint human-machine uncertainty, combining epistemic uncertainty
from the model with hesitation cues and confidence signals from human speakers
to guide interaction, query selection, and memory retention. This paper is a
call to action: we advocate a rethinking of how AI engages with human knowledge
in under-documented languages, moving from extractive data collection toward
participatory, co-adaptive learning processes that respect and empower
communities while discovering and preserving the world's linguistic diversity.
This vision aligns with principles of human-centered AI, emphasizing
interactive, cooperative model building between AI systems and speakers.

</details>


### [3] [Discourse vs emissions: Analysis of corporate narratives, symbolic practices, and mimicry through LLMs](https://arxiv.org/abs/2510.01222)
*Bertrand Kian Hassani,Yacoub Bahini,Rizwan Mushtaq*

Main category: cs.CL

> 本论文开发了多维度框架，利用改进的大型语言模型评估了企业气候披露的质量，揭示了当前信息披露中的问题，并指出需要更严格的监管将企业的承诺与其行动相连接。

<details>
  <summary>Details</summary>

**Motivation:** 由于气候变化增加了对透明和可比的企业气候披露的需求，但模仿和象征性报告往往削弱其价值。因此，本论文旨在开发一种框架以评估企业披露的成熟度，并揭示企业信息披露的现状和问题。

**Method:** 本研究开发了一个多维度框架，使用为气候沟通优化过的大型语言模型（LLMs），对828家在美国上市的公司的信息披露成熟度进行评估。四个分类器——情感、承诺、具体性和目标雄心从可持续性和年度报告中提取叙述指标，并将其与公司的特征如排放量、市值和部门挂钩。

**Result:** 研究揭示了三点见解：(1) 风险导向的叙述常与明确的承诺相一致，但定量目标（如净零承诺）与语气脱钩；(2) 规模更大、排放更高的公司比同行披露更多的承诺和行动，尽管与定量目标保持不一致；(3) 信息披露方式的广泛相似性表明存在模仿行为，减少了差异性与决策的有用性。

**Conclusion:** 这些结果突显了LLMs在ESG叙事分析中的价值，并强调了需要更严格的监管来将承诺与可验证的转型策略相连接。

**Abstract:** Climate change has increased demands for transparent and comparable corporate
climate disclosures, yet imitation and symbolic reporting often undermine their
value. This paper develops a multidimensional framework to assess disclosure
maturity among 828 U.S.listed firms using large language models (LLMs)
fine-tuned for climate communication. Four classifiers-sentiment, commitment,
specificity, and target ambition-extract narrative indicators from
sustainability and annual reports, which are linked to firm attributes such as
emissions, market capitalization, and sector. Analyses reveal three insights:
(1) risk-focused narratives often align with explicit commitments, but
quantitative targets (e.g., net-zero pledges) remain decoupled from tone; (2)
larger and higher-emitting firms disclose more commitments and actions than
peers, though inconsistently with quantitative targets; and (3) widespread
similarity in disclosure styles suggests mimetic behavior, reducing
differentiation and decision usefulness. These results highlight the value of
LLMs for ESG narrative analysis and the need for stronger regulation to connect
commitments with verifiable transition strategies.

</details>


### [4] [Context Matters: Comparison of commercial large language tools in veterinary medicine](https://arxiv.org/abs/2510.01224)
*Tyler J Poore,Christopher J Pinard,Aleena Shabbir,Andrew Lagree,Andre Telfer,Kuan-Chuen Wu*

Main category: cs.CL

> 研究评估了三种兽医专用LLM总结工具，发现第一个产品表现最佳，并确认了评估框架的可靠性和可重复性。

<details>
  <summary>Details</summary>

**Motivation:** 为了探究大型语言模型在兽医领域的性能，特别是兽医肿瘤学中的应用。

**Method:** 使用了一个基于规则的LLM评估框架，对三种商业化的兽医专用LLM摘要工具在兽医肿瘤学记录的标准数据集上的表现进行了评分。

**Result:** Product 1表现最佳，整体评分中位数为4.61，显著高于Product 2和Product 3。评分框架在三次独立评估中表现出高度的一致性。

**Conclusion:** 研究强调了兽医专用商业LLM工具的重要性，并证明了使用LLM作为评估者的方法在临床自然语言处理摘要评估中可扩展且可重复。

**Abstract:** Large language models (LLMs) are increasingly used in clinical settings, yet
their performance in veterinary medicine remains underexplored. We evaluated
three commercially available veterinary-focused LLM summarization tools
(Product 1 [Hachiko] and Products 2 and 3) on a standardized dataset of
veterinary oncology records. Using a rubric-guided LLM-as-a-judge framework,
summaries were scored across five domains: Factual Accuracy, Completeness,
Chronological Order, Clinical Relevance, and Organization. Product 1 achieved
the highest overall performance, with a median average score of 4.61 (IQR:
0.73), compared to 2.55 (IQR: 0.78) for Product 2 and 2.45 (IQR: 0.92) for
Product 3. It also received perfect median scores in Factual Accuracy and
Chronological Order. To assess the internal consistency of the grading
framework itself, we repeated the evaluation across three independent runs. The
LLM grader demonstrated high reproducibility, with Average Score standard
deviations of 0.015 (Product 1), 0.088 (Product 2), and 0.034 (Product 3).
These findings highlight the importance of veterinary-specific commercial LLM
tools and demonstrate that LLM-as-a-judge evaluation is a scalable and
reproducible method for assessing clinical NLP summarization in veterinary
medicine.

</details>


### [5] [ClaimCheck: Real-Time Fact-Checking with Small Language Models](https://arxiv.org/abs/2510.01226)
*Akshith Reddy Putta,Jacob Devasier,Chengkai Li*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** We introduce ClaimCheck, an LLM-guided automatic fact-checking system
designed to verify real-world claims using live Web evidence and small language
models. Unlike prior systems that rely on large, closed-source models and
static knowledge stores, ClaimCheck employs a transparent, stepwise
verification pipeline that mirrors human fact-checking workflows consisting of
Web search query planning, Web-based evidence retrieval and summarization,
evidence synthesis and re-retrieval, and claim verdict evaluation. Each module
is optimized for small LLMs, allowing the system to deliver accurate and
interpretable fact-checking with significantly lower computational
requirements. Despite using a much smaller Qwen3-4B model, ClaimCheck achieves
state-of-the-art accuracy of 76.4% on the AVeriTeC dataset, outperforming
previous approaches using LLaMA3.1 70B and GPT-4o. Extensive ablations
demonstrate that careful modular design and prompting strategies can overcome
the limitations of smaller LLMs. To promote accessibility and transparency, we
provide a public demo at https://idir.uta.edu/claimcheck.

</details>


### [6] [EEFSUVA: A New Mathematical Olympiad Benchmark](https://arxiv.org/abs/2510.01227)
*Nicole N Khatibi,Daniil A. Radamovich,Michael P. Brenner*

Main category: cs.CL

> 研究通过新引入的EEFSUVA基准测试模型的数学推理能力，发现即使先进LLMs在该基准上表现也有所下降，强调了需要更广泛的数据集来更全面评估数学推理。

<details>
  <summary>Details</summary>

**Motivation:** 研究目的是详细评估大型语言模型在数学理解方面的能力，并探讨现有基准测试是否能真正反映模型的数学推理能力。

**Method:** 引入EEFSUVA基准，该基准从东欧和前苏联国家未广泛传播的区域和国家奥林匹克试题中筛选而来，这类试题与IMO难度相当，但强调非标准的解题技巧，并且在线数据集中的出现频率较低，以此来更全面地评估模型的数学理解能力。

**Result:** 初步结果显示，与传统的Olympiad风格基准相比，即使最先进的LLMs在EEFSUVA上的表现也有所下降。

**Conclusion:** 结果表明，使用更广泛的评估数据集对更全面地评估数学推理能力以及指导未来模型开发的重要性。

**Abstract:** Recent breakthroughs have spurred claims that large language models (LLMs)
match gold medal Olympiad to graduate level proficiency on mathematics
benchmarks. In this work, we examine these claims in detail and assess the
extent to which current benchmarks capture genuine LLM mathematical reasoning.
The composition of these benchmarks, primarily drawing from the International
Mathematics Olympiad (IMO) and related competitions, may overstate models
reasoning ability due to potential data contamination and a narrow focus on
familiar problem types. To enable a more holistic assessment of mathematical
understanding, we introduce EEFSUVA, a novel benchmark curated from under
circulated regional and national Olympiads of Eastern Europe and the countries
from the former Soviet Union. These contests feature problems of comparable
difficulty to the IMO and are renowned for demanding nonstandard
problem-solving techniques, yet their problems are far less prevalent in online
corpora. Preliminary results suggest that even state-of-the-art LLMs exhibit a
notable performance decline on EEFSUVA relative to other Olympiad-style
benchmarks. These findings also suggest the potential importance of broader
evaluation datasets for a fuller assessment of mathematical reasoning and for
guiding future model development.

</details>


### [7] [Who is In Charge? Dissecting Role Conflicts in Instruction Following](https://arxiv.org/abs/2510.01228)
*Siqi Zeng*

Main category: cs.CL

> 本文探究了大语言模型在处理系统提示与用户输入、社会暗示时的内在机制，揭示其内部冲突检测机制，发现社会暗示增强了指令遵循性，指出需要开发层次敏感的对齐方法。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型应按照分层指令执行，其中系统提示应优先于用户输入，但现有研究表明，模型往往忽视这一规则而过分遵守权威或共识等社会线索。本文旨在解释这一现象背后的原因。

**Method:** 本文通过线性探测、直接逻辑归属和引导实验等方法扩展了之前关于大语言模型行为研究的发现，探究了模型在处理系统提示和用户输入以及社会暗示冲突时的内在机制。

**Result:** 研究发现冲突决策的信号在模型早期编码中就已经形成，系统提示与用户输入和社交冲突各自形成了不同的子空间。直接逻辑归属揭示了在系统与用户提示的冲突中，模型内部冲突检测更强，但在只有社交暗示的情况下才能持续解决冲突。尽管大语言模型会使用社会暗示，引导实验却意外地揭示了，这些向量以角色无关的方式增强了指令遵循的稳定性。

**Conclusion:** 这些结果解释了大语言模型中系统服从性的脆弱性，并强调了需要开发轻量级、层次敏感的对齐方法的重要性。

**Abstract:** Large language models should follow hierarchical instructions where system
prompts override user inputs, yet recent work shows they often ignore this rule
while strongly obeying social cues such as authority or consensus. We extend
these behavioral findings with mechanistic interpretations on a large-scale
dataset. Linear probing shows conflict-decision signals are encoded early, with
system-user and social conflicts forming distinct subspaces. Direct Logit
Attribution reveals stronger internal conflict detection in system-user cases
but consistent resolution only for social cues. Steering experiments show that,
despite using social cues, the vectors surprisingly amplify instruction
following in a role-agnostic way. Together, these results explain fragile
system obedience and underscore the need for lightweight hierarchy-sensitive
alignment methods.

</details>


### [8] [Enhancing Transformer-Based Rerankers with Synthetic Data and LLM-Based Supervision](https://arxiv.org/abs/2510.01229)
*Dimitar Peshevski,Kiril Blazhevski,Martin Popovski,Gjorgji Madjarov*

Main category: cs.CL

> A method for generating synthetic data using LLMs to efficiently fine-tune smaller models for document reranking, balancing computational efficiency and re-ranking performance.

<details>
  <summary>Details</summary>

**Motivation:** While LLMs are good at reranking documents due to their deep semantic understanding and reasoning, their high computational cost makes them impractical for many real-world deployments. To address this issue and reduce dependency on scarce, manually labeled data, a novel pipeline is proposed to eliminate the need for human-labeled query-document pairs.

**Method:** Our method uses LLMs to generate synthetic queries from domain-specific corpora and employs an LLM-based classifier to label positive and hard-negative pairs. This synthetic dataset is then used to fine-tune a smaller transformer model with contrastive learning using Localized Contrastive Estimation (LCE) loss.

**Result:** Experiments on the MedQuAD dataset show that our approach significantly boosts in-domain performance and generalizes well to out-of-domain tasks.

**Conclusion:** The proposed pipeline demonstrates the potential to reduce computational costs while maintaining strong reranking capabilities through using LLMs for data generation and supervision instead of inference.

**Abstract:** Effective document reranking is essential for improving search relevance
across diverse applications. While Large Language Models (LLMs) excel at
reranking due to their deep semantic understanding and reasoning, their high
computational cost makes them impractical for many real-world deployments.
Fine-tuning smaller, task-specific models is a more efficient alternative but
typically depends on scarce, manually labeled data. To overcome this, we
propose a novel pipeline that eliminates the need for human-labeled
query-document pairs. Our method uses LLMs to generate synthetic queries from
domain-specific corpora and employs an LLM-based classifier to label positive
and hard-negative pairs. This synthetic dataset is then used to fine-tune a
smaller transformer model with contrastive learning using Localized Contrastive
Estimation (LCE) loss. Experiments on the MedQuAD dataset show that our
approach significantly boosts in-domain performance and generalizes well to
out-of-domain tasks. By using LLMs for data generation and supervision rather
than inference, we reduce computational costs while maintaining strong
reranking capabilities.

</details>


### [9] [Geometric Structures and Patterns of Meaning: A PHATE Manifold Analysis of Chinese Character Embeddings](https://arxiv.org/abs/2510.01230)
*Wen G. Gong*

Main category: cs.CL

> 研究使用PHATE分析法研究中文字符嵌入的几何模式，证实了语义内容与几何复杂性之间的相关性，支持传统语言学理论并提出一种语义组织的几何分析新框架。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于通过计算方法支持传统语言学理论，并建立一种语义组织的几何分析新框架。

**Method:** 使用PHATE流形分析法系统地研究中文字符嵌入中的几何模式，并通过七种嵌入模型和八种降维方法进行交叉验证。

**Result:** 观察到实义词的聚类模式和功能词的分支模式，揭示了语义内容与几何复杂性之间的相关性：有意义的字符表现出丰富的几何多样性，而结构部首则聚集成紧密的簇。

**Conclusion:** 研究结果表明几何复杂性与语义内容有关，支持了传统的语言学理论，并提供了一种全新的几何分析方法来研究语义组织。

**Abstract:** We systematically investigate geometric patterns in Chinese character
embeddings using PHATE manifold analysis. Through cross-validation across seven
embedding models and eight dimensionality reduction methods, we observe
clustering patterns for content words and branching patterns for function
words. Analysis of over 1000 Chinese characters across 12 semantic domains
reveals that geometric complexity correlates with semantic content: meaningful
characters exhibit rich geometric diversity while structural radicals collapse
into tight clusters. The comprehensive child-network analysis (123 phrases)
demonstrates systematic semantic expansion from elemental character. These
findings provide computational evidence supporting traditional linguistic
theory and establish a novel framework for geometric analysis of semantic
organization.

</details>


### [10] [Trustworthy Summarization via Uncertainty Quantification and Risk Awareness in Large Language Models](https://arxiv.org/abs/2510.01231)
*Shuaidong Pan,Di Wu*

Main category: cs.CL

> 本研究通过构建集成不确定性量化和风险意识机制的大型语言模型框架，显著提升了高风险场景下摘要的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机来自于信息过载和高风险决策任务的需求，旨在提高高风险场景下的自动摘要可靠性。

**Method:** 本文提出了一种结合不确定性量化和风险意识机制的大型语言模型框架，以提升高风险场景下自动摘要的可靠性。通过引入贝叶斯推断来建模参数空间中的不确定性，避免过度自信的预测，并通过预测分布熵衡量生成内容的不确定性水平。此外，模型还包括了风险评分和调节模块，使摘要能够准确涵盖核心内容，通过明确的风险级别提示提升信任度。

**Result:** 实验和敏感性分析验证了该方法在提高高风险应用中摘要的鲁棒性和可靠性的同时，还保持了流畅性和语义完整性。

**Conclusion:** 这项研究提供了一种解决可信摘要问题的系统方案，并展示了在方法论层面的可扩展性和实用性。

**Abstract:** This study addresses the reliability of automatic summarization in high-risk
scenarios and proposes a large language model framework that integrates
uncertainty quantification and risk-aware mechanisms. Starting from the demands
of information overload and high-risk decision-making, a conditional
generation-based summarization model is constructed, and Bayesian inference is
introduced during generation to model uncertainty in the parameter space, which
helps avoid overconfident predictions. The uncertainty level of the generated
content is measured using predictive distribution entropy, and a joint
optimization of entropy regularization and risk-aware loss is applied to ensure
that key information is preserved and risk attributes are explicitly expressed
during information compression. On this basis, the model incorporates risk
scoring and regulation modules, allowing summaries to cover the core content
accurately while enhancing trustworthiness through explicit risk-level prompts.
Comparative experiments and sensitivity analyses verify that the proposed
method significantly improves the robustness and reliability of summarization
in high-risk applications while maintaining fluency and semantic integrity.
This research provides a systematic solution for trustworthy summarization and
demonstrates both scalability and practical value at the methodological level.

</details>


### [11] [Benchmark Profiling: Mechanistic Diagnosis of LLM Benchmarks](https://arxiv.org/abs/2510.01232)
*Dongjun Kim,Gyuho Shim,Yongchan Chun,Minhyuk Kim,Chanjun Park,Heuiseok Lim*

Main category: cs.CL

> This paper introduces Benchmark Profiling, a method that breaks down and quantifies the abilities contributing to a model's success on benchmarks, revealing insights into the actual abilities the benchmarks measure.

<details>
  <summary>Details</summary>

**Motivation:** To verify if current benchmarks actually measure the labels they are assumed to test, as there is currently no systematic way to do so.

**Method:** We introduce Benchmark Profiling, a diagnostic framework that decomposes benchmark performance into ten cognitively grounded abilities. The method combines gradient-based importance scoring with targeted parameter ablation to compute an Ability Impact Score (AIS).

**Result:** Profiling three instruction-tuned models across ten widely used benchmarks yields four key findings: (i) most benchmarks draw on several abilities rather than one, (ii) datasets with similar labels rely on distinct ability mixtures, (iii) code-generation benchmarks reward broad, multi-skill improvement and show modest gains from narrow domain-specific fine-tuning, and (iv) abilities irrelevant to the task could negatively affect performance.

**Conclusion:** Benchmark Profiling explains why performance gains do not always translate into user-perceived competence and offers a transparent tool for benchmark audit and model interpretability.

**Abstract:** Large Language Models are commonly judged by their scores on standard
benchmarks, yet such scores often overstate real capability since they mask the
mix of skills a task actually demands. For example, ARC is assumed to test
reasoning, while HellaSwag is designed to evaluate commonsense. However, we
lack a systematic way to verify if these benchmarks actually measure these
labels. We introduce Benchmark Profiling, a diagnostic framework that
decomposes benchmark performance into ten cognitively grounded abilities. The
method combines gradient-based importance scoring with targeted parameter
ablation to compute an Ability Impact Score (AIS) that quantifies how much each
ability contributes to a model's success on a given benchmark. Profiling three
instruction-tuned models across ten widely used benchmarks yields four key
findings: (i) most benchmarks draw on several abilities rather than one, (ii)
datasets with similar labels rely on distinct ability mixtures, (iii)
code-generation benchmarks reward broad, multi-skill improvement and thus show
only modest gains from narrow domain-specific fine-tuning, and (iv) abilities
irrelevant to the task could negatively affect performance. Benchmark Profiling
therefore explains why performance gains do not always translate into
user-perceived competence and offers a transparent tool for benchmark audit and
model interpretability.

</details>


### [12] [Computational Social Linguistics for Telugu Cultural Preservation: Novel Algorithms for Chandassu Metrical Pattern Recognition](https://arxiv.org/abs/2510.01233)
*Boddu Sri Pavan,Boddu Swathi Sree*

Main category: cs.CL

> 研究学者利用计算社会方法，建立了第一个全面的数字框架来分析泰卢固语的韵律诗歌，这对于保护宝贵的文化遗产和推动集体智慧具有重要意义。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机是保护濒危的文化知识系统 — 泰卢固语的Chandassu传统，这是一种代表了几个世纪集体文化智慧的诗歌传统。

**Method:** 此研究开发了一个完整的数字框架，用于分析泰卢固语的韵律模式，结合了传统社区知识与现代计算方法。该框架包括AksharamTokenizer用于韵律感知的分词，LaghuvuGuruvu Generator用于分类轻重音节，以及PadyaBhedam Checker用于自动模式识别。

**Result:** 该算法对提出的Chandassu Score的准确率达到91.73%，评估指标反映了传统的文学标准。

**Conclusion:** 该方法为以社区为中心的方法保护文化遗产提供了见解，并支持了数字人文和意识社会的计算系统中的更广泛倡议。

**Abstract:** This research presents a computational social science approach to preserving
Telugu Chandassu, the metrical poetry tradition representing centuries of
collective cultural intelligence. We develop the first comprehensive digital
framework for analyzing Telugu prosodic patterns, bridging traditional
community knowledge with modern computational methods. Our social computing
approach involves collaborative dataset creation of 4,651 annotated padyams,
expert-validated linguistic patterns, and culturally-informed algorithmic
design. The framework includes AksharamTokenizer for prosody-aware
tokenization, LaghuvuGuruvu Generator for classifying light and heavy
syllables, and PadyaBhedam Checker for automated pattern recognition. Our
algorithm achieves 91.73% accuracy on the proposed Chandassu Score, with
evaluation metrics reflecting traditional literary standards. This work
demonstrates how computational social science can preserve endangered cultural
knowledge systems while enabling new forms of collective intelligence around
literary heritage. The methodology offers insights for community-centered
approaches to cultural preservation, supporting broader initiatives in digital
humanities and socially-aware computing systems.

</details>


### [13] [LLMRank: Understanding LLM Strengths for Model Routing](https://arxiv.org/abs/2510.01234)
*Shubham Agrawal,Prasang Gupta*

Main category: cs.CL

> 提出了LLMRank，一种使用丰富的提示特征进行大语言模型路由的框架，优于依赖潜在嵌入的方法。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型（LLMs）的快速增长带来了部署挑战，需要选择最合适的模型来优化性能和效率之间的权衡。为了解决这个问题，我们提出了一种新的路由方法来实现这一目标。

**Method:** 我们提出了LLMRank，一种基于提示的路由框架，它利用从提示中提取的丰富的人类可读特征，包括任务类型、推理模式、复杂性指标、句法线索以及来自轻量级代理求解器的信号。与依赖于潜在嵌入的先前一次性路由器不同，LLMRank使用在RouterBench上训练的神经排名模型来预测每种模型的效用，RouterBench包含了跨越11个基准测试和11个最先进的大语言模型的36,497个提示。

**Result:** 我们的方法实现了高达89.2%的理论最大效用，同时也提供了解释路由决策的特征归属。广泛的实验证明了多方面特征提取和混合排名目标的重要性，突出了基于特征驱动的路由方法对于高效和透明部署大语言模型的潜力。

**Conclusion:** 实验结果表明，我们的特征驱动的路由方法在实现高效和透明部署大语言模型方面具有巨大潜力。

**Abstract:** The rapid growth of large language models (LLMs) with diverse capabilities,
latency and computational costs presents a critical deployment challenge:
selecting the most suitable model for each prompt to optimize the trade-off
between performance and efficiency. We introduce LLMRank, a prompt-aware
routing framework that leverages rich, human-readable features extracted from
prompts, including task type, reasoning patterns, complexity indicators,
syntactic cues, and signals from a lightweight proxy solver. Unlike prior
one-shot routers that rely solely on latent embeddings, LLMRank predicts
per-model utility using a neural ranking model trained on RouterBench,
comprising 36,497 prompts spanning 11 benchmarks and 11 state-of-the-art LLMs,
from small efficient models to large frontier systems. Our approach achieves up
to 89.2% of oracle utility, while providing interpretable feature attributions
that explain routing decisions. Extensive studies demonstrate the importance of
multifaceted feature extraction and the hybrid ranking objective, highlighting
the potential of feature-driven routing for efficient and transparent LLM
deployment.

</details>


### [14] [GRPO++: Enhancing Dermatological Reasoning under Low Resource Settings](https://arxiv.org/abs/2510.01236)
*Ismam Nur Swapnil,Aranya Saha,Tanvir Ahmed Khan,Mohammad Ariful Haque*

Main category: cs.CL

> We developed DermIQ-VLM, a specialized Vision-Language Model for dermatology, using a resource-efficient training pipeline based on GRPO++, supervised fine-tuning, and expert-aligned DPO, which shows notable improvements in performance.

<details>
  <summary>Details</summary>

**Motivation:** The motivation of this paper is to address the limitations of Vision-Language Models (VLMs) in dermatology, particularly their struggle with structured reasoning due to data scarcity and high computational costs. We aim to develop a specialized VLM that can mimic a dermatologist's diagnostic capabilities in environments with limited resources.

**Method:** Our paper introduces DermIQ-VLM, a Vision-Language Model tailored for dermatology that employs a resource-efficient multi-stage training methodology. The core of our approach is the adaptation of the Grouped Relative Policy Optimization (GRPO) framework into GRPO++, which is designed to stabilize the GRPO process while reducing its data and computational requirements. Our pipeline initiates with disease recognition using GRPO++, followed by supervised fine-tuning to improve conversational abilities. To reduce factual errors introduced during fine-tuning, we employ Direct Preference Optimization (DPO) using a Knowledge Graph-based system to align the model with expert preferences.

**Result:** Our preliminary evaluation on a dermatological dataset indicates that our methodology significantly enhances performance compared to conventional fine-tuning strategies. This suggests that our pipeline could be a practical solution for advancing VLMs in dermatology with a more efficient use of resources.

**Conclusion:** In conclusion, our study demonstrates the efficacy of DermIQ-VLM and its training pipeline in overcoming the challenges faced by existing VLMs in dermatology. Our findings substantiate the potential of our resource-efficient strategy in creating reliable, specialized VLMs for dermatological applications, even within resource-constrained settings.

**Abstract:** Vision-Language Models (VLMs) show promise in medical image analysis, yet
their capacity for structured reasoning in complex domains like dermatology is
often limited by data scarcity and the high computational cost of advanced
training techniques. To address these challenges, we introduce DermIQ-VLM, a
VLM developed through a multi-stage, resource-efficient methodology designed to
emulate a dermatologist's diagnostic process. Our primary contribution is a
modified version of Grouped Relative Policy Optimization (GRPO), called GRPO++,
which stabilizes the powerful but data-intensive GRPO framework. Our proposed
training pipeline first employs GRPO++ for reasoning-oriented disease
recognition, followed by supervised fine-tuning for conversational ability. To
mitigate factual errors introduced during this step, we then align the model
using Direct Preference Optimization (DPO), leveraging a Knowledge Graph-based
system as a scalable proxy for expert preference. A preliminary evaluation on a
curated dermatological dataset demonstrates that our proposed methodology
yields notable performance gains over standard fine-tuning approaches. These
findings validate the potential of our pipeline as a feasible pathway for
developing specialized, reliable VLMs in resource-constrained environments.

</details>


### [15] [Confidence-Aware Routing for Large Language Model Reliability Enhancement: A Multi-Signal Approach to Pre-Generation Hallucination Mitigation](https://arxiv.org/abs/2510.01237)
*Nandakishor M*

Main category: cs.CL

> 研究提出了一种新的基于置信度的路由系统，通过对模型生成内容之前的可靠性评估，减少了幻觉出现的几率，并显著提高了计算效率。这种方法在知识密集型问答任务上取得了显著提高。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机在于解决大语言模型中存在的幻觉问题（即生成可信但事实性错误的内容）。现有的缓解策略主要集中在生成后的校正，这种策略计算成本高，并且无法阻止不可靠内容的生成。

**Method:** 本论文提出了一种基于置信度的路由系统，该系统可以主动评估大语言模型在生成前的不确定性，并根据估计的可靠性重新定向查询。此方法结合了三个互补信号：内部表示和参考嵌入之间的语义对齐、模型层间内部收敛性分析以及学习到的置信估计。

**Result:** 本研究在知识密集型问答基准测试中的评估显示，该方法在幻觉检测（0.74对基线的0.42）方面取得了显著的改进，同时与事后方法相比，计算成本减少了40%。F1评分从0.61提升到了0.82，且假阳性率较低（0.09）。

**Conclusion:** 从反应性修正转向主动评估的范式转变，为提高大语言模型的可靠性提供了一种计算效率较高的方法。

**Abstract:** Large Language Models suffer from hallucination, generating plausible yet
factually incorrect content. Current mitigation strategies focus on
post-generation correction, which is computationally expensive and fails to
prevent unreliable content generation. We propose a confidence-aware routing
system that proactively assesses model uncertainty before generation and
redirects queries based on estimated reliability. Our approach combines three
complementary signals: semantic alignment between internal representations and
reference embeddings, internal convergence analysis across model layers, and
learned confidence estimation. The unified confidence score determines routing
to four pathways: local generation for high confidence, retrieval-augmented
generation for medium confidence, larger models for low confidence, and human
review for very low confidence. Evaluation on knowledge-intensive QA benchmarks
demonstrates significant improvements in hallucination detection (0.74 vs. 0.42
baseline) while reducing computational costs by 40% compared to post-hoc
methods. The F1 score improves from 0.61 to 0.82 with low false positive rates
(0.09). This paradigm shift from reactive correction to proactive assessment
offers a computationally efficient approach to LLM reliability enhancement.

</details>


### [16] [Silent Tokens, Loud Effects: Padding in LLMs](https://arxiv.org/abs/2510.01238)
*Rom Himelstein,Amit LeVi,Yonatan Belinkov,Avi Mendelson*

Main category: cs.CL

> 研究发现，即使是少量的填充标记也会影响大语言模型的计算结果和输出质量，必须在实际部署中加以谨慎处理。

<details>
  <summary>Details</summary>

**Motivation:** 虽然填充标记应完全被屏蔽，但实现错误可能导致它们影响计算，这种影响的程度尚不清楚。我们旨在探讨填充标记在这类模型中的实际影响。

**Method:** 我们通过在三个开源模型家族（Llama, Gemma, Qwen）中插入不同量的填充标记，并从四个维度（激活，生成质量，偏见和安全性）进行评估，以此系统地研究了填充标记对大语言模型的影响。

**Result:** 即使少量的填充标记也会改变隐藏的表示，降低小型模型的生成质量，以不可预测的方式改变偏见，并削弱安全保护措施。

**Conclusion:** 这些发现表明，填充标记不仅仅是一个无害的细节，而是在部署中必须谨慎处理的健壮性风险。

**Abstract:** Padding tokens are widely used in large language models (LLMs) to equalize
sequence lengths during batched inference. While they should be fully masked,
implementation errors can cause them to influence computation, and the extent
of this influence is not well understood. We systematically study this effect
across three open-source model families (Llama, Gemma, Qwen), inserting
controlled amounts of padding and evaluating outcomes along four axes:
activations, generation quality, bias, and safety. Even small amounts of
padding shift hidden representations, degrade quality in smaller models, alter
bias in unpredictable ways, and weaken safety guardrails. These findings
demonstrate that padding is not a harmless detail but a robustness risk that
must be carefully handled in deployment.

</details>


### [17] [CIFLEX: Contextual Instruction Flow for Sub-task Execution in Multi-Turn Interactions with a Single On-Device LLM](https://arxiv.org/abs/2510.01239)
*Juntae Lee,Jihwan Bang,Seunghan Yang,Simyung Chang*

Main category: cs.CL

> CIFLEX系统通过复用主任务的缓存和层次分类策略来有效减少计算开销，实现设备上多任务对话的高效处理。

<details>
  <summary>Details</summary>

**Motivation:** 由于大型语言模型变得越来越能够有效且全面地支持用户请求，需要一种系统能够高效地处理多任务对话中的子任务，避免在任务转换时的计算开销。

**Method:** CIFLEX采用上下文指令流来处理多轮交互中的子任务，通过复用主任务的关键值缓存，并在隔离的侧路径中仅注入任务特定指令，减少计算开销。同时开发了一种层次分类策略来支持小型模型的子任务选择。

**Result:** 实验显示，CIFLEX显著减少了计算成本，同时不降低任务性能，实现了设备上的高效多任务对话。

**Conclusion:** CIFLEX为设备上的大型语言模型多轮对话提供了高效的子任务处理解决方案，通过减少计算开销促进了多任务对话的扩展性和效率。

**Abstract:** We present CIFLEX (Contextual Instruction Flow for Sub-task Execution), which
is a novel execution system for efficient sub-task handling in multi-turn
interactions with a single on-device large language model (LLM). As LLMs become
increasingly capable, a single model is expected to handle diverse sub-tasks
that more effectively and comprehensively support answering user requests.
Naive approach reprocesses the entire conversation context when switching
between main and sub-tasks (e.g., query rewriting, summarization), incurring
significant computational overhead. CIFLEX mitigates this overhead by reusing
the key-value (KV) cache from the main task and injecting only task-specific
instructions into isolated side paths. After sub-task execution, the model
rolls back to the main path via cached context, thereby avoiding redundant
prefill computation. To support sub-task selection, we also develop a
hierarchical classification strategy tailored for small-scale models,
decomposing multi-choice decisions into binary ones. Experiments show that
CIFLEX significantly reduces computational costs without degrading task
performance, enabling scalable and efficient multi-task dialogue on-device.

</details>


### [18] [SKYLENAGE Technical Report: Mathematical Reasoning and Contest-Innovation Benchmarks for Multi-Level Math Evaluation](https://arxiv.org/abs/2510.01241)
*Hu Wei,Ze Xu,Boyu Yang,Linlin Miao,Weiqi Zhai,Yihan Li,Zixuan Li,Zhijun Wang,Boya Wang,Jianwei Yu,Jialing Yuan,Xiaoyue Zhang,Cheng He,Minglei Chen,Zifan Zhang,Qianhui Li,Wei Wang,Xiang Xu*

Main category: cs.CL

> 研究推出了 SKYLENAGE-ReasoningMATH 和 SKYLENAGE-MATH 两个数学推理基准测试，对比了15种大语言模型的表现，最强模型分别达到了81%和44%的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大语言模型在许多公开的数学套件中表现良好，但数学领域的前沿问题由于天花板效应而逐渐受到限制。为了提供一个更艰难且覆盖面广的数学基准测试，以供未来评估数学推理能力的参考。

**Method:** 提出了两个互补的基准测试：SKYLENAGE-ReasoningMATH 和 SKYLENAGE-MATH，分别包含100道和150道题目，以及详细的题目元数据如长度、数字密度和符号复杂度。

**Result:** 在竞赛类套件评估中，最强的模型达到44%的准确率，次强模型达到37%；准确性从高中到博士级别逐渐下降，顶级系统在博士级别到高中级别的保持率为79%。在推理测试集中，最优模型整体准确率为81%，表现最佳的模型在最难的部分也显示出明显的稳健性优势。

**Conclusion:** SKYLENAGE 提供了一个困难的、以推理为中心且涵盖广泛的数学基准测试，具有校准的难度和丰富的元数据，作为未来评估数学推理能力的参考基准。

**Abstract:** Large language models (LLMs) now perform strongly on many public math suites,
yet frontier separation within mathematics increasingly suffers from ceiling
effects. We present two complementary benchmarks: SKYLENAGE-ReasoningMATH, a
100-item, structure-aware diagnostic set with per-item metadata on length,
numeric density, and symbolic complexity; and SKYLENAGE-MATH, a 150-item
contest-style suite spanning four stages from high school to doctoral under a
seven-subject taxonomy. We evaluate fifteen contemporary LLM variants under a
single setup and analyze subject x model and grade x model performance. On the
contest suite, the strongest model reaches 44% while the runner-up reaches 37%;
accuracy declines from high school to doctoral, and top systems exhibit a
doctoral-to-high-school retention near 79%. On the reasoning set, the best
model attains 81% overall, and hardest-slice results reveal clear robustness
gaps between leaders and the mid-tier. In summary, we release
SKYLENAGE-ReasoningMATH and report aggregate results for SKYLENAGE-MATH;
together, SKYLENAGE provides a hard, reasoning-centered and broadly covering
math benchmark with calibrated difficulty and rich metadata, serving as a
reference benchmark for future evaluations of mathematical reasoning.

</details>


### [19] [Redundancy-as-Masking: Formalizing the Artificial Age Score (AAS) to Model Memory Aging in Generative AI](https://arxiv.org/abs/2510.01242)
*Seyma Yaman Kayadibi*

Main category: cs.CL

> 本研究提出了人工年龄分数（AAS），这是一个衡量人工智能系统记忆老化程度的新指标。通过观察大型语言模型在不同会话中的记忆性能，研究发现AI系统通过记忆不对称性老化，而不是通过时间。AAS在一项涉及ChatGPT-5的25天双语研究中得到验证，展示了它作为评测AI系统记忆退化情况的实用工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在开发一种衡量人工智能记忆老化的度量标准，并探讨大型语言模型在会话中由于记忆不对称性而表现出的老化现象。

**Method:** 引入人工年龄分数（AAS）作为记忆老化的一种度量。该分数是基于可观察回忆行为的对数比例熵度量。在重构的实验中，采用“冗余作为掩蔽”的形式来解释冗余如何减少惩罚质量。在没有估计冗余的假设下（R=0），研究了AAS在一段涉及ChatGPT-5的25天双语研究中的表现。

**Result:** 在有着持续交互环节的会话中，模型可以稳定回忆语义和情景细节，AAS数值下降，表明系统年轻；而在重置会话时，模型能够保持语义一致性，但无法保持情景连续性，AAS数值上升，反映了记忆老化。

**Conclusion:** AAS作为理论上稳固且任务无关的诊断工具，能够有效地评估人工智能系统中的记忆退化。本研究还建立在冯·诺依曼、香农和图灵的相关理论的基础上。

**Abstract:** Artificial intelligence is observed to age not through chronological time but
through structural asymmetries in memory performance. In large language models,
semantic cues such as the name of the day often remain stable across sessions,
while episodic details like the sequential progression of experiment numbers
tend to collapse when conversational context is reset. To capture this
phenomenon, the Artificial Age Score (AAS) is introduced as a log-scaled,
entropy-informed metric of memory aging derived from observable recall
behavior. The score is formally proven to be well-defined, bounded, and
monotonic under mild and model-agnostic assumptions, making it applicable
across various tasks and domains. In its Redundancy-as-Masking formulation, the
score interprets redundancy as overlapping information that reduces the
penalized mass. However, in the present study, redundancy is not explicitly
estimated; all reported values assume a redundancy-neutral setting (R = 0),
yielding conservative upper bounds. The AAS framework was tested over a 25-day
bilingual study involving ChatGPT-5, structured into stateless and persistent
interaction phases. During persistent sessions, the model consistently recalled
both semantic and episodic details, driving the AAS toward its theoretical
minimum, indicative of structural youth. In contrast, when sessions were reset,
the model preserved semantic consistency but failed to maintain episodic
continuity, causing a sharp increase in the AAS and signaling structural memory
aging. These findings support the utility of AAS as a theoretically grounded,
task-independent diagnostic tool for evaluating memory degradation in
artificial systems. The study builds on foundational concepts from von
Neumann's work on automata, Shannon's theories of information and redundancy,
and Turing's behavioral approach to intelligence.

</details>


### [20] [Detoxifying Large Language Models via Autoregressive Reward Guided Representation Editing](https://arxiv.org/abs/2510.01243)
*Yisong Xiao,Aishan Liu,Siyuan Liang,Zonghao Ying,Xianglong Liu,Dacheng Tao*

Main category: cs.CL

> ARGRE框架通过建模潜在空间中的毒性转换实现了去毒过程的精细控制，在不牺牲模型性能的情况下，提高去毒的准确性和效率。该方法在多个模型上效果显著。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大型语言模型在多种任务中表现出色，但它们仍然容易生成有毒内容，因此需要去毒策略以确保安全和责任的部署。现有的测试时去毒方法往往由于对毒素和非毒素输出之间的转换空间探索不足而干预不准确。

**Method:** 提出了一种名为ARGRE的测试时去毒框架，该框架明确建模了潜在表示空间中的毒性转换，实现了稳定的奖励引导编辑。ARGRE确定了非毒性语义方向，并在毒性与非毒性表示之间进行插值，揭示细粒度的转换轨迹。这些轨迹将稀疏的毒性注释转化为密集的训练信号，从而构建了一个自回归奖励模型，提供稳定的编辑指导。在推理时，奖励模型引导一个自适应的两步编辑过程，包括基于预期奖励差距的方向引导和轻量级梯度优化。

**Result:** 通过8个广泛应用的大型语言模型进行的广泛实验表明，ARGRE在有效性（减少62.21%的毒性）和效率（减少47.58%的推理时间）上显著优于领先基线，且对原始模型的核心能力几乎没有降解。

**Conclusion:** 这种新方法通过精细控制去毒过程，在不牺牲模型性能的情况下，提高去毒的准确性和效率。

**Abstract:** Large Language Models (LLMs) have demonstrated impressive performance across
various tasks, yet they remain vulnerable to generating toxic content,
necessitating detoxification strategies to ensure safe and responsible
deployment. Test-time detoxification methods, which typically introduce static
or dynamic interventions into LLM representations, offer a promising solution
due to their flexibility and minimal invasiveness. However, current approaches
often suffer from imprecise interventions, primarily due to their insufficient
exploration of the transition space between toxic and non-toxic outputs. To
address this challenge, we propose \textsc{A}utoregressive \textsc{R}eward
\textsc{G}uided \textsc{R}epresentation \textsc{E}diting (ARGRE), a novel
test-time detoxification framework that explicitly models toxicity transitions
within the latent representation space, enabling stable and precise
reward-guided editing. ARGRE identifies non-toxic semantic directions and
interpolates between toxic and non-toxic representations to reveal fine-grained
transition trajectories. These trajectories transform sparse toxicity
annotations into dense training signals, enabling the construction of an
autoregressive reward model that delivers stable and precise editing guidance.
At inference, the reward model guides an adaptive two-step editing process to
obtain detoxified representations: it first performs directional steering based
on expected reward gaps to shift representations toward non-toxic regions,
followed by lightweight gradient-based refinements. Extensive experiments
across 8 widely used LLMs show that ARGRE significantly outperforms leading
baselines in effectiveness (-62.21% toxicity) and efficiency (-47.58% inference
time), while preserving the core capabilities of the original model with
minimal degradation. Our code is available at the website.

</details>


### [21] [Feasibility of Structuring Stress Documentation Using an Ontology-Guided Large Language Model](https://arxiv.org/abs/2510.01244)
*Hyeoneui Kim,Jeongha Kim,Huijing Xu,Jinsun Jung,Sunghoon Kang,Sun Joo Jang*

Main category: cs.CL

> 通过开发精神压力本体（MeSO），本研究展示了使用大型语言模型（LLM）进行结构化提取压力相关信息的可行性，从非结构化文本中提取信息的成功率为78.2%，为提升压力文档的连续性和临床实用性提供了潜在方案。

<details>
  <summary>Details</summary>

**Motivation:** 压力，源于外部压力源、个人评价及生理或心理反应的动态交互，对健康有着显著影响，但在电子健康记录中经常被低估或记录不一致，通常为非结构化的自由文本格式。环境AI技术在这种情况下有减少文档负担的潜力，但主要产生非结构化叙述，限制了下游的临床应用能力。

**Method:** 本研究开发了一种精神压力本体（MeSO），通过整合压力理论模型和11种验证过的压力评估工具中的概念进行构建，并通过本体陷阱扫描器（Ontology Pitfall Scanner）和专家验证来提升其结构和内容质量。使用MeSO从35篇Reddit帖子中提取六类压力相关信息，包括压力源、压力反应、应对策略、持续时间、发作时间及时间概况，采用了Claude Sonnet 4大型语言模型，并通过人工审核评估其准确性和本体覆盖范围。

**Result:** 最终的本体包含了181个概念，分为8个顶级分类。从220个可提取的压力相关信息项中，大型语言模型正确识别了172项（78.2%），误分类了27项（12.3%），遗漏了21项（9.5%）。所有正确提取的项都能准确映射到MeSO，但有24个相关概念尚未包含在本体内。

**Conclusion:** 本研究展示了使用基于本体的大型语言模型进行结构化提取压力相关信息的可行性，对提升环境AI系统中压力文档记载的连续性和实用性有重要意义。未来的工作应包括临床对话数据的使用以及跨大型语言模型的比较。

**Abstract:** Stress, arising from the dynamic interaction between external stressors,
individual appraisals, and physiological or psychological responses,
significantly impacts health yet is often underreported and inconsistently
documented, typically captured as unstructured free-text in electronic health
records. Ambient AI technologies offer promise in reducing documentation
burden, but predominantly generate unstructured narratives, limiting downstream
clinical utility.
  This study aimed to develop an ontology for mental stress and evaluate the
feasibility of using a Large Language Model (LLM) to extract ontology-guided
stress-related information from narrative text. The Mental Stress Ontology
(MeSO) was developed by integrating theoretical models like the Transactional
Model of Stress with concepts from 11 validated stress assessment tools. MeSO's
structure and content were refined using Ontology Pitfall Scanner! and expert
validation.
  Using MeSO, six categories of stress-related information--stressor, stress
response, coping strategy, duration, onset, and temporal profile--were
extracted from 35 Reddit posts using Claude Sonnet 4. Human reviewers evaluated
accuracy and ontology coverage. The final ontology included 181 concepts across
eight top-level classes. Of 220 extractable stress-related items, the LLM
correctly identified 172 (78.2%), misclassified 27 (12.3%), and missed 21
(9.5%). All correctly extracted items were accurately mapped to MeSO, although
24 relevant concepts were not yet represented in the ontology.
  This study demonstrates the feasibility of using an ontology-guided LLM for
structured extraction of stress-related information, offering potential to
enhance the consistency and utility of stress documentation in ambient AI
systems. Future work should involve clinical dialogue data and comparison
across LLMs.

</details>


### [22] [SeMob: Semantic Synthesis for Dynamic Urban Mobility Prediction](https://arxiv.org/abs/2510.01245)
*Runfei Chen,Shuyang Jiang,Wei Huang*

Main category: cs.CL

> SeMob结合语言模型(LLM)和多智能体框架，通过渐进融合架构，提高了人类动态移动性预测的精度，特别是在事件驱动的情况下的预测。

<details>
  <summary>Details</summary>

**Motivation:** 现有时空模型在整合外部事件的文本描述方面存在困难，导致难以预测人类移动性中的突然变化。

**Method:** SeMob采用多智能体框架，利用基于LLM的智能体自动提取和推理复杂在线文本中的时空相关信息。通过提出的一种创新的渐进融合架构，将细节相关的上下文与时空数据结合起来。

**Result:** SeMob在构建的数据集上评估，与时空模型相比，最大分别降低了13.92%的MAE和11.12%的RMSE。特别是在事件发生地点附近的时空区域内，这种框架表现出了显著的优势。

**Conclusion:** 通过融合事件驱动的预测，SeMob提供了更精准的人类动态移动性预测，特别是对于由外部事件引起的突然变化的预测。

**Abstract:** Human mobility prediction is vital for urban services, but often fails to
account for abrupt changes from external events. Existing spatiotemporal models
struggle to leverage textual descriptions detailing these events. We propose
SeMob, an LLM-powered semantic synthesis pipeline for dynamic mobility
prediction. Specifically, SeMob employs a multi-agent framework where LLM-based
agents automatically extract and reason about spatiotemporally related text
from complex online texts. Fine-grained relevant contexts are then incorporated
with spatiotemporal data through our proposed innovative progressive fusion
architecture. The rich pre-trained event prior contributes enriched insights
about event-driven prediction, and hence results in a more aligned forecasting
model. Evaluated on a dataset constructed through our pipeline, SeMob achieves
maximal reductions of 13.92% in MAE and 11.12% in RMSE compared to the
spatiotemporal model. Notably, the framework exhibits pronounced superiority
especially within spatiotemporal regions close to an event's location and time
of occurrence.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [23] [LVTINO: LAtent Video consisTency INverse sOlver for High Definition Video Restoration](https://arxiv.org/abs/2510.01339)
*Alessio Spagnoletti,Andrés Almansa,Marcelo Pereyra*

Main category: cs.CV

> 本文提出了一种基于视频一致性模型（VCMs）的高清晰度视频恢复逆解算器LVTINO，实现了高质量的视频重建，并且在计算效率上超越了现有的基于图像LDM的方法。

<details>
  <summary>Details</summary>

**Motivation:** 计算成像方法越来越依赖于强大的生成扩散模型来解决具有挑战性的图像恢复任务。然而，将这些进展扩展到高质量视频恢复面临着重大挑战，因为需要恢复精细的空间细节同时捕捉微妙的时态依赖性，而直接在帧对帧的基础上应用基于图像的LDM先验通常会导致时态上不一致的重建结果。

**Method:** 提出了一种称为LVTINO的零样本或即插即用的高清晰度视频恢复逆解算器，该解算器利用视频一致性模型（VCMs）作为先验知识，此方法避开了自动微分的需要，并仅通过几次神经函数评估即实现了最先进的视频重建质量，同时保证了测量的一致性和帧间平滑的过渡。

**Result:** 广泛的实验表明，LVTINO在对一系列视频逆问题的处理上，与当前最先进的逐帧应用图像LDM方法相比，显著地提高了感知质量，从而在重建保真度和计算效率方面建立了新的基准。

**Conclusion:** 通过利用视频一致性模型（VCMs）作为高清晰度视频恢复逆解算器的先验知识，我们实现了高质量的视频重建，改善了重建质量和计算效率。

**Abstract:** Computational imaging methods increasingly rely on powerful generative
diffusion models to tackle challenging image restoration tasks. In particular,
state-of-the-art zero-shot image inverse solvers leverage distilled
text-to-image latent diffusion models (LDMs) to achieve unprecedented accuracy
and perceptual quality with high computational efficiency. However, extending
these advances to high-definition video restoration remains a significant
challenge, due to the need to recover fine spatial detail while capturing
subtle temporal dependencies. Consequently, methods that naively apply
image-based LDM priors on a frame-by-frame basis often result in temporally
inconsistent reconstructions. We address this challenge by leveraging recent
advances in Video Consistency Models (VCMs), which distill video latent
diffusion models into fast generators that explicitly capture temporal
causality. Building on this foundation, we propose LVTINO, the first zero-shot
or plug-and-play inverse solver for high definition video restoration with
priors encoded by VCMs. Our conditioning mechanism bypasses the need for
automatic differentiation and achieves state-of-the-art video reconstruction
quality with only a few neural function evaluations, while ensuring strong
measurement consistency and smooth temporal transitions across frames.
Extensive experiments on a diverse set of video inverse problems show
significant perceptual improvements over current state-of-the-art methods that
apply image LDMs frame by frame, establishing a new benchmark in both
reconstruction fidelity and computational efficiency.

</details>


### [24] [Image Generation Based on Image Style Extraction](https://arxiv.org/abs/2510.01347)
*Shuochen Chang*

Main category: cs.CV

> 本研究旨在通过从单个给定的风格化参考图像获取细粒度的风格表示，并将其注入到生成体中，以最大化预训练生成模型的生成能力，实现细粒度控制的风格化图像生成。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于解决文本到图像生成模型中难以精确描述和控制细粒度风格的问题，以及难以将风格化参考图像的指导信息与传统文本指导生成的文本条件直接对齐的问题。

**Method:** 本研究提出了一种基于风格提取的三阶段训练图像生成方法，利用风格编码器和风格投影层将风格表示与文本表示对齐，实现基于细粒度文本线索的风格导向生成。

**Result:** 该项研究构造了一个名为Style30k-captions的数据集，其中包含图像、风格标签和文本描述的三元组，用于训练风格编码器和风格投影层。

**Conclusion:** 结论表明，通过本研究提出的方法，可以实现细粒度的文本线索引导的图像风格生成，从而更好地满足特定风格的图像生成需求。

**Abstract:** Image generation based on text-to-image generation models is a task with
practical application scenarios that fine-grained styles cannot be precisely
described and controlled in natural language, while the guidance information of
stylized reference images is difficult to be directly aligned with the textual
conditions of traditional textual guidance generation. This study focuses on
how to maximize the generative capability of the pretrained generative model,
by obtaining fine-grained stylistic representations from a single given
stylistic reference image, and injecting the stylistic representations into the
generative body without changing the structural framework of the downstream
generative model, so as to achieve fine-grained controlled stylized image
generation. In this study, we propose a three-stage training style
extraction-based image generation method, which uses a style encoder and a
style projection layer to align the style representations with the textual
representations to realize fine-grained textual cue-based style guide
generation. In addition, this study constructs the Style30k-captions dataset,
whose samples contain a triad of images, style labels, and text descriptions,
to train the style encoder and style projection layer in this experiment.

</details>


### [25] [EvoStruggle: A Dataset Capturing the Evolution of Struggle across Activities and Skill Levels](https://arxiv.org/abs/2510.01362)
*Shijia Feng,Michael Wray,Walterio Mayol-Cuevas*

Main category: cs.CV

> 本文介绍了EvoStruggle数据集，通过定量化挣扎决策来研究技能获取过程中挣扎的变化，以及建立时间动作定位模型来检测挣扎。实验表明模型具有跨任务和跨活动的较好泛化能力。

<details>
  <summary>Details</summary>

**Motivation:** 确定技能训练过程中个人挣扎的时机对于优化人类学习和发展有效的辅助系统至关重要。但是现有的操作数据集没有关注挣扎如何随时间演变。这项研究填补了这一空白。

**Method:** 通过收集一个包含61.68小时视频记录，2,793个视频和5,385个时间标记挣扎段的数据集来确定挣扎（struggle）问题，该数据集来自76名参与者。参与者被要求五次重复执行同一任务，以捕捉技能的演变。挣扎问题被定义为一个时间动作定位任务，专注于识别并精确地定位挣扎段落的开始和结束时间。

**Result:** 实验结果显示，时间动作定位模型可以成功地学习检测挣扎线索，即使是在未见过的任务或活动中。在跨任务和跨活动的通用性上，模型分别达到了34.56%和19.24%的整体平均mAP。

**Conclusion:** 挣扎是可以在多种技能任务之间转移的概念，虽然目前挣扎检测仍然存在改进的空间。

**Abstract:** The ability to determine when a person struggles during skill acquisition is
crucial for both optimizing human learning and enabling the development of
effective assistive systems. As skills develop, the type and frequency of
struggles tend to change, and understanding this evolution is key to
determining the user's current stage of learning. However, existing
manipulation datasets have not focused on how struggle evolves over time. In
this work, we collect a dataset for struggle determination, featuring 61.68
hours of video recordings, 2,793 videos, and 5,385 annotated temporal struggle
segments collected from 76 participants. The dataset includes 18 tasks grouped
into four diverse activities -- tying knots, origami, tangram puzzles, and
shuffling cards, representing different task variations. In addition,
participants repeated the same task five times to capture their evolution of
skill. We define the struggle determination problem as a temporal action
localization task, focusing on identifying and precisely localizing struggle
segments with start and end times. Experimental results show that Temporal
Action Localization models can successfully learn to detect struggle cues, even
when evaluated on unseen tasks or activities. The models attain an overall
average mAP of 34.56% when generalizing across tasks and 19.24% across
activities, indicating that struggle is a transferable concept across various
skill-based tasks while still posing challenges for further improvement in
struggle detection. Our dataset is available at
https://github.com/FELIXFENG2019/EvoStruggle.

</details>


### [26] [SPUS: A Lightweight and Parameter-Efficient Foundation Model for PDEs](https://arxiv.org/abs/2510.01370)
*Abu Bucker Siddik,Diane Oyen,Alexander Most,Michal Kucer,Ayan Biswas*

Main category: cs.CV

> 该研究提出了一种名为SPUS的基于轻量级残差U-Net架构的基础模型，用于解决多种偏微分方程，相比现有模型，SPUS在参数效率和泛化能力上表现出了显著优势。

<details>
  <summary>Details</summary>

**Motivation:** 为了在这样一个极简的框架中实现有效的学习，作者决定采用一种基于轻量级残差U-Net架构的基底模型，与大多数高计算和参数开销的大型复杂变压器架构的基底模型不同。

**Method:** 本文介绍了Small PDE U-Net Solver (SPUS)，这是一个基于轻量级残差U-Net架构的紧凑、高效的基底模型（FM），用于解决广泛的偏微分方程（PDEs）。SPUS采用了一种简单但强大的自回归预训练策略，以学习数字求解器的行为并掌握底层物理。

**Result:** 实验结果表明，使用残差U-Net架构的SPUS在下游任务上达到了最先进的泛化性能，同时所需参数较少，且需要的微调数据有限。

**Conclusion:** 这突显了SPUS作为解决多样化PDE系统的高参数效率基底模型的潜在价值。

**Abstract:** We introduce Small PDE U-Net Solver (SPUS), a compact and efficient
foundation model (FM) designed as a unified neural operator for solving a wide
range of partial differential equations (PDEs). Unlike existing
state-of-the-art PDE FMs-primarily based on large complex transformer
architectures with high computational and parameter overhead-SPUS leverages a
lightweight residual U-Net-based architecture that has been largely
underexplored as a foundation model architecture in this domain. To enable
effective learning in this minimalist framework, we utilize a simple yet
powerful auto-regressive pretraining strategy which closely replicates the
behavior of numerical solvers to learn the underlying physics. SPUS is
pretrained on a diverse set of fluid dynamics PDEs and evaluated across 6
challenging unseen downstream PDEs spanning various physical systems.
Experimental results demonstrate that SPUS using residual U-Net based
architecture achieves state-of-the-art generalization on these downstream tasks
while requiring significantly fewer parameters and minimal fine-tuning data,
highlighting its potential as a highly parameter-efficient FM for solving
diverse PDE systems.

</details>


### [27] [DisCo: Reinforcement with Diversity Constraints for Multi-Human Generation](https://arxiv.org/abs/2510.01399)
*Shubhankar Borse,Farzad Farhadzadeh,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

> 研究团队提出了DisCo框架，这是一个基于强化学习的方法，通过优化生成的多个人物的身份多样性，解决了现有文本到图像模型生成多个人物图像时所遇到的问题，显著提高了生成人物的唯一性和身份多样性。

<details>
  <summary>Details</summary>

**Motivation:** 现有的文本到图像转换模型在实现现实主义方面表现出色，但在处理多人体提示时会出现问题，比如复制面部、合并身份和人数统计不准确等问题。此研究旨在解决这些问题。

**Method:** 我们介绍了一种名为DisCo（利用多样性约束的强化）的新型框架，这是第一个直接优化多人体生成的身份多样性的深度强化学习框架。DisCo通过组相关策略优化（GRPO）细化了流动匹配模型，并采用了一种组合奖励机制来实现以下目标：（i）对图像内部的面部相似性进行惩罚；（ii）减少跨样本身份的重复；（iii）强制执行准确的人数计数；（iv）通过人类偏好分数保持视觉保真度。

**Result:** 在DiverseHumans测试集上的结果表明，DisCo实现了高达98.6的唯一面部准确度和接近完美的全局身份散布，超过了开源和专有的方法（例如Gemini，GPT-Image），同时保持了高度的感知质量。

**Conclusion:** 我们的研究结果确立了DisCo作为一个可扩展且不需要额外注释的解决方案，有效解决了生成模型中的长期身份危机问题，并为多人体生成设定了新的基准。

**Abstract:** State-of-the-art text-to-image models excel at realism but collapse on
multi-human prompts - duplicating faces, merging identities, and miscounting
individuals. We introduce DisCo (Reinforcement with Diversity Constraints), the
first RL-based framework to directly optimize identity diversity in multi-human
generation. DisCo fine-tunes flow-matching models via Group-Relative Policy
Optimization (GRPO) with a compositional reward that (i) penalizes intra-image
facial similarity, (ii) discourages cross-sample identity repetition, (iii)
enforces accurate person counts, and (iv) preserves visual fidelity through
human preference scores. A single-stage curriculum stabilizes training as
complexity scales, requiring no extra annotations. On the DiverseHumans
Testset, DisCo achieves 98.6 Unique Face Accuracy and near-perfect Global
Identity Spread - surpassing both open-source and proprietary methods (e.g.,
Gemini, GPT-Image) while maintaining competitive perceptual quality. Our
results establish DisCo as a scalable, annotation-free solution that resolves
the long-standing identity crisis in generative models and sets a new benchmark
for compositional multi-human generation.

</details>


### [28] [GeoSURGE: Geo-localization using Semantic Fusion with Hierarchy of Geographic Embeddings](https://arxiv.org/abs/2510.01448)
*Angel Daruna,Nicholas Meegan,Han-Pang Chiu,Supun Samarasekera,Rakesh Kumar*

Main category: cs.CV

> The paper presents a novel method for visual geo-localization, involving hierarchical geographic embeddings and robust fusion of visual features. It outperforms previous state-of-the-art methods in multiple benchmarks.

<details>
  <summary>Details</summary>

**Motivation:** Despite progress in learned geographic representations for visual geo-localization, this domain remains an active research area. The aim is to improve the accuracy and efficiency of determining a geographic location using only the visual content of an image.

**Method:** Our method aligns the visual representation of a query image with a learned geographic representation, using a hierarchical model of geographic embeddings. It efficiently fuses the image's appearance features with its semantic segmentation to form a robust representation.

**Result:** The method achieves state-of-the-art performance on five benchmark datasets, surpassing previous methods in 22 out of 25 evaluated metrics.

**Conclusion:** The combination of geographic and visual representations leads to significant improvements in visual geo-localization accuracy, validated by empirical performance and ablation studies.

**Abstract:** Worldwide visual geo-localization seeks to determine the geographic location
of an image anywhere on Earth using only its visual content. Learned
representations of geography for visual geo-localization remain an active
research topic despite much progress. We formulate geo-localization as aligning
the visual representation of the query image with a learned geographic
representation. Our novel geographic representation explicitly models the world
as a hierarchy of geographic embeddings. Additionally, we introduce an approach
to efficiently fuse the appearance features of the query image with its
semantic segmentation map, forming a robust visual representation. Our main
experiments demonstrate improved all-time bests in 22 out of 25 metrics
measured across five benchmark datasets compared to prior state-of-the-art
(SOTA) methods and recent Large Vision-Language Models (LVLMs). Additional
ablation studies support the claim that these gains are primarily driven by the
combination of geographic and visual representations.

</details>


### [29] [Data Selection for Fine-tuning Vision Language Models via Cross Modal Alignment Trajectories](https://arxiv.org/abs/2510.01454)
*Nilay Naharas,Dang Nguyen,Nesihan Bulut,Mohammadhossein Bateni,Vahab Mirrokni,Baharan Mirzasoleiman*

Main category: cs.CV

> 提出XMAS方法，通过聚类去除大型视觉语言模型训练数据中的冗余信息，大幅减少所需数据量并保持模型性能，同时加快训练速度。

<details>
  <summary>Details</summary>

**Motivation:** 尽管数据选择已经在视觉模型和大型语言模型中得到了广泛研究，但对于大型视觉语言模型而言，这一领域仍处于探索初期。现有的方法都无法在不同的子集大小上超过随机选择的效果。

**Method:** 我们提出了XMAS，这是一种基于对注意力矩阵轨迹进行聚类的数据高效微调方法。通过训练一个小型代理LVLM获得注意力矩阵的顶级奇异值轨迹，并从这些聚类中选择一个平衡子集以有效去除大规模LVLM训练数据中的冗余信息。

**Result:** 实验结果显示，XMAS可以从LLaVA-665k数据集中消除50%的数据，以及从Vision-Flan数据集中消除85%的数据，同时完全保持LLaVA-1.5-7B在10个下游基准上的性能，并将其训练速度提高1.2倍。相对于LLaVA-665k的最佳基线，数据减少多了30%。

**Conclusion:** XMAS方法提供了一种原则性的数据高效微调方法，适用于大型视觉语言模型，显著减少了训练数据量同时保持了模型性能，并加速了训练过程。

**Abstract:** Data-efficient learning aims to eliminate redundancy in large training
datasets by training models on smaller subsets of the most informative
examples. While data selection has been extensively explored for vision models
and large language models (LLMs), it remains underexplored for Large
Vision-Language Models (LVLMs). Notably, none of existing methods can
outperform random selection at different subset sizes. In this work, we propose
the first principled method for data-efficient instruction tuning of LVLMs. We
prove that examples with similar cross-modal attention matrices during
instruction tuning have similar gradients. Thus, they influence model
parameters in a similar manner and convey the same information to the model
during training. Building on this insight, we propose XMAS, which clusters
examples based on the trajectories of the top singular values of their
attention matrices obtained from fine-tuning a small proxy LVLM. By sampling a
balanced subset from these clusters, XMAS effectively removes redundancy in
large-scale LVLM training data. Extensive experiments show that XMAS can
discard 50% of the LLaVA-665k dataset and 85% of the Vision-Flan dataset while
fully preserving performance of LLaVA-1.5-7B on 10 downstream benchmarks and
speeding up its training by 1.2x. This is 30% more data reduction compared to
the best baseline for LLaVA-665k. The project's website can be found at
https://bigml-cs-ucla.github.io/XMAS-project-page/.

</details>


### [30] [Purrception: Variational Flow Matching for Vector-Quantized Image Generation](https://arxiv.org/abs/2510.01478)
*Răzvan-Andrei Matişan,Vincent Tao Hu,Grigory Bartosh,Björn Ommer,Cees G. M. Snoek,Max Welling,Jan-Willem van de Meent,Mohammad Mahdi Derakhshani,Floor Eijkelboom*

Main category: cs.CV

> Purrception 方法实现更快的训练收敛速度和具有竞争力的图像生成质量，通过结合连续和离散方法的优势。

<details>
  <summary>Details</summary>

**Motivation:** 目的是结合连续方法的几何感知和离散方法的类别监督，以实现对可编程代码的不确定性量化和温度控制生成，并提高图像生成训练效率。

**Method:** Purrception采用变分流匹配方法进行矢量量化图像生成，通过在连续嵌入空间中计算速度场来学习代码簿索引的类别后验，从而在维护连续传输动力学的同时提供显式的类别监督。

**Result:** 在ImageNet-1k 256x256图像生成评估中，相较于连续流匹配和离散流匹配基线，训练收敛速度更快，同时与最先进的模型相比，也达到了有竞争力的FID分数。

**Conclusion:** 该研究表明变分流匹配能够有效在图像生成中桥接连续传输和离散监督，提升训练效率。

**Abstract:** We introduce Purrception, a variational flow matching approach for
vector-quantized image generation that provides explicit categorical
supervision while maintaining continuous transport dynamics. Our method adapts
Variational Flow Matching to vector-quantized latents by learning categorical
posteriors over codebook indices while computing velocity fields in the
continuous embedding space. This combines the geometric awareness of continuous
methods with the discrete supervision of categorical approaches, enabling
uncertainty quantification over plausible codes and temperature-controlled
generation. We evaluate Purrception on ImageNet-1k 256x256 generation. Training
converges faster than both continuous flow matching and discrete flow matching
baselines while achieving competitive FID scores with state-of-the-art models.
This demonstrates that Variational Flow Matching can effectively bridge
continuous transport and discrete supervision for improved training efficiency
in image generation.

</details>


### [31] [AortaDiff: A Unified Multitask Diffusion Framework For Contrast-Free AAA Imaging](https://arxiv.org/abs/2510.01498)
*Yuxuan Ou,Ning Bi,Jiazhen Pan,Jiancheng Yang,Boliang Yu,Usama Zidan,Regent Lee,Vicente Grau*

Main category: cs.CV

> 本文提出了一种新的多任务深度学习框架，能够从NCCT生成CECT图像并进行主动脉腔和血栓分割，优于现有技术。

<details>
  <summary>Details</summary>

**Motivation:** 由于常规的多阶段方法会导致错误累积，并且不利用共享的语义和解剖结构，本文旨在使用统一的深度学习框架来解决这些问题，并且减少对比剂的使用。

**Method:** 提出了一种将条件扩散模型（CDM）与多任务学习相结合的统一深度学习框架，旨在从非对比CT（NCCT）扫描中生成合成的对比增强CT（CECT）图像，并同时分割主动脉腔和血栓。该方法共享编码器和解码器的参数，并采用半监督训练策略，在标签缺失的样本上也能进行学习，共使用264名患者的队列进行评估。

**Result:** 在影像合成上，PSNR达到了25.61 dB，显著优于单任务CDM的23.80 dB。对于主动脉腔的Dice得分为0.89，血栓的Dice得分为0.53，相比于nnU-Net分别提高了0.02和0.05。此外，该方法将主动脉腔直径的误差从5.78 mm减少到4.19 mm，血栓区域的误差从41.45%减少到33.85%。

**Conclusion:** 实验表明，该方法在合成图像质量和解剖结构分割方面优于现有技术，特别是在血栓分割上实现了显著的改善，同时提高了临床测量的准确性。

**Abstract:** While contrast-enhanced CT (CECT) is standard for assessing abdominal aortic
aneurysms (AAA), the required iodinated contrast agents pose significant risks,
including nephrotoxicity, patient allergies, and environmental harm. To reduce
contrast agent use, recent deep learning methods have focused on generating
synthetic CECT from non-contrast CT (NCCT) scans. However, most adopt a
multi-stage pipeline that first generates images and then performs
segmentation, which leads to error accumulation and fails to leverage shared
semantic and anatomical structures. To address this, we propose a unified deep
learning framework that generates synthetic CECT images from NCCT scans while
simultaneously segmenting the aortic lumen and thrombus. Our approach
integrates conditional diffusion models (CDM) with multi-task learning,
enabling end-to-end joint optimization of image synthesis and anatomical
segmentation. Unlike previous multitask diffusion models, our approach requires
no initial predictions (e.g., a coarse segmentation mask), shares both encoder
and decoder parameters across tasks, and employs a semi-supervised training
strategy to learn from scans with missing segmentation labels, a common
constraint in real-world clinical data. We evaluated our method on a cohort of
264 patients, where it consistently outperformed state-of-the-art single-task
and multi-stage models. For image synthesis, our model achieved a PSNR of 25.61
dB, compared to 23.80 dB from a single-task CDM. For anatomical segmentation,
it improved the lumen Dice score to 0.89 from 0.87 and the challenging thrombus
Dice score to 0.53 from 0.48 (nnU-Net). These segmentation enhancements led to
more accurate clinical measurements, reducing the lumen diameter MAE to 4.19 mm
from 5.78 mm and the thrombus area error to 33.85% from 41.45% when compared to
nnU-Net. Code is available at https://github.com/yuxuanou623/AortaDiff.git.

</details>


### [32] [From Videos to Indexed Knowledge Graphs -- Framework to Marry Methods for Multimodal Content Analysis and Understanding](https://arxiv.org/abs/2510.01513)
*Basem Rizk,Joel Walsh,Mark Core,Benjamin Nye*

Main category: cs.CV

> 本文提出了一种框架，能够高效地设计用于多模态内容分析的处理流程，并将视频转化为时间上半结构化的数据形式，并进一步转化为可查询且能支持持续学习的帧级索引知识图表示。

<details>
  <summary>Details</summary>

**Motivation:** 多模态内容分析面临着计算复杂度高、工程量大的问题，特别是视频等复杂数据的处理。将现有的开源模型和方法融合起来更是一个挑战。

**Method:** 框架通过融合预训练模型来构建处理视频的流程，并将视频转换成时间上的半结构化数据格式，再转化为支持查询和持续学习的帧级知识图表示。

**Result:** 未提供具体实现结果。

**Conclusion:** 该框架支持将多模态内容（特别是视频）转化为易于处理的知识图表示，从而支持新的特定领域知识的动态加入。

**Abstract:** Analysis of multi-modal content can be tricky, computationally expensive, and
require a significant amount of engineering efforts. Lots of work with
pre-trained models on static data is out there, yet fusing these opensource
models and methods with complex data such as videos is relatively challenging.
In this paper, we present a framework that enables efficiently prototyping
pipelines for multi-modal content analysis. We craft a candidate recipe for a
pipeline, marrying a set of pre-trained models, to convert videos into a
temporal semi-structured data format. We translate this structure further to a
frame-level indexed knowledge graph representation that is query-able and
supports continual learning, enabling the dynamic incorporation of new
domain-specific knowledge through an interactive medium.

</details>


### [33] [WALT: Web Agents that Learn Tools](https://arxiv.org/abs/2510.01524)
*Viraj Prabhu,Yutong Dai,Matthew Fernandez,Jing Gu,Krithika Ramakrishnan,Yanqi Luo,Silvio Savarese,Caiming Xiong,Junnan Li,Zeyuan Chen,Ran Xu*

Main category: cs.CV

> WALT框架通过逆向工程将网站内置功能转化为可调用工具，降低了代理的执行难度，提高了成功率，并减少对LLM推理的依赖。

<details>
  <summary>Details</summary>

**Motivation:** 当前的Web代理方法依赖于逐步的UI交互和大量的LLM推理，这种方法在面对动态布局和长时间任务时容易失效。相比之下，人类利用网站提供的高级操作来处理任务。因此，提出了WALT框架来解决这一问题。

**Method:** WALT（Web Agents that Learn Tools）框架将网站内的功能逆向工程为可重用的工具，包括搜索、过滤、排序、发帖、评论、点赞、创建、编辑和删除等功能。这些工具抽象了低级别的执行过程，使代理只需调用相应的工具函数即可。

**Result:** 在VisualWebArena和WebArena上的测试表明，WALT能够用更少的步骤、更少的LLM推理实现更高的成功率。

**Conclusion:** WALT建立了一个稳健且通用的浏览器自动化范式，解决了传统方法在动态网站和长周期任务中的不足。

**Abstract:** Web agents promise to automate complex browser tasks, but current methods
remain brittle -- relying on step-by-step UI interactions and heavy LLM
reasoning that break under dynamic layouts and long horizons. Humans, by
contrast, exploit website-provided functionality through high-level operations
like search, filter, and sort. We introduce WALT (Web Agents that Learn Tools),
a framework that reverse-engineers latent website functionality into reusable
invocable tools. Rather than hypothesizing ad-hoc skills, WALT exposes robust
implementations of automations already designed into websites -- spanning
discovery (search, filter, sort), communication (post, comment, upvote), and
content management (create, edit, delete). Tools abstract away low-level
execution: instead of reasoning about how to click and type, agents simply call
search(query) or create(listing). This shifts the computational burden from
fragile step-by-step reasoning to reliable tool invocation. On VisualWebArena
and WebArena, WALT achieves higher success with fewer steps and less
LLM-dependent reasoning, establishing a robust and generalizable paradigm for
browser automation.

</details>


### [34] [MATCH: Multi-faceted Adaptive Topo-Consistency for Semi-Supervised Histopathology Segmentation](https://arxiv.org/abs/2510.01532)
*Meilong Xu,Xiaoling Hu,Shahira Abousamra,Chen Li,Chao Chen*

Main category: cs.CV

> 本文提出了一种半监督分割框架，通过利用多个随机dropout和时间训练快照获得的扰动预测，强制保持拓扑一致性，以辨别具有生物意义的结构。通过引入一种新的匹配策略，减少预测中的分歧，从而降低拓扑错误，提高分割的准确性和鲁棒性，对于可靠的下游分析至关重要。代码可在GitHub获取。

<details>
  <summary>Details</summary>

**Motivation:** 在半监督分割中，从无标签数据中捕获有意义的语义结构至关重要，但组织病理学图像分析中的对象密集分布加剧了这一挑战。

**Method:** 该方法通过随机dropout和时间训练快照获得多个扰动预测，并强制保持这些输出之间的拓扑一致性。同时，提出一种新的匹配策略，结合空间重叠和全局结构对齐，减少预测中的差异。

**Result:** 实验表明，该方法有效降低了拓扑错误，实现了更稳健和准确的分割结果。

**Conclusion:** 通过本文提出的方法，成功提高了半监督分割的效果，增强了对组织病理学图像中生物结构识别的准确度和鲁棒性。

**Abstract:** In semi-supervised segmentation, capturing meaningful semantic structures
from unlabeled data is essential. This is particularly challenging in
histopathology image analysis, where objects are densely distributed. To
address this issue, we propose a semi-supervised segmentation framework
designed to robustly identify and preserve relevant topological features. Our
method leverages multiple perturbed predictions obtained through stochastic
dropouts and temporal training snapshots, enforcing topological consistency
across these varied outputs. This consistency mechanism helps distinguish
biologically meaningful structures from transient and noisy artifacts. A key
challenge in this process is to accurately match the corresponding topological
features across the predictions in the absence of ground truth. To overcome
this, we introduce a novel matching strategy that integrates spatial overlap
with global structural alignment, minimizing discrepancies among predictions.
Extensive experiments demonstrate that our approach effectively reduces
topological errors, resulting in more robust and accurate segmentations
essential for reliable downstream analysis. Code is available at
\href{https://github.com/Melon-Xu/MATCH}{https://github.com/Melon-Xu/MATCH}.

</details>


### [35] [Towards Better Optimization For Listwise Preference in Diffusion Models](https://arxiv.org/abs/2510.01540)
*Jiamu Bai,Xin Yu,Meilong Xu,Weitao Lu,Xin Pan,Kiwan Maeng,Daniel Kifer,Jian Wang,Yu Wang*

Main category: cs.CV

> Diffusion-LPO is a framework that extends DPO to process listwise human feedback, improving the alignment of T2I models with human preferences across various visual generation tasks.

<details>
  <summary>Details</summary>

**Motivation:** To improve the alignment of text-to-image models with human preferences by using listwise preferences in reinforcement learning from human feedback (RLHF).

**Method:** Diffusion-LPO, which extends Direct Preference Optimization (DPO) to handle listwise preferences in diffusion models.

**Result:** Diffusion-LPO outperforms pairwise DPO on various tasks, such as text-to-image generation and image editing, showing better visual quality and preference alignment.

**Conclusion:** Listwise Preference Optimization (Diffusion-LPO) is effective in aligning T2I diffusion models more precisely with human preferences compared to using pairwise preferences.

**Abstract:** Reinforcement learning from human feedback (RLHF) has proven effectiveness
for aligning text-to-image (T2I) diffusion models with human preferences.
Although Direct Preference Optimization (DPO) is widely adopted for its
computational efficiency and avoidance of explicit reward modeling, its
applications to diffusion models have primarily relied on pairwise preferences.
The precise optimization of listwise preferences remains largely unaddressed.
In practice, human feedback on image preferences often contains implicit ranked
information, which conveys more precise human preferences than pairwise
comparisons. In this work, we propose Diffusion-LPO, a simple and effective
framework for Listwise Preference Optimization in diffusion models with
listwise data. Given a caption, we aggregate user feedback into a ranked list
of images and derive a listwise extension of the DPO objective under the
Plackett-Luce model. Diffusion-LPO enforces consistency across the entire
ranking by encouraging each sample to be preferred over all of its lower-ranked
alternatives. We empirically demonstrate the effectiveness of Diffusion-LPO
across various tasks, including text-to-image generation, image editing, and
personalized preference alignment. Diffusion-LPO consistently outperforms
pairwise DPO baselines on visual quality and preference alignment.

</details>


### [36] [Growing Visual Generative Capacity for Pre-Trained MLLMs](https://arxiv.org/abs/2510.01546)
*Hanyu Wang,Jiaming Han,Ziyan Yang,Qi Zhao,Shanchuan Lin,Xiangyu Yue,Abhinav Shrivastava,Zhenheng Yang,Hao Chen*

Main category: cs.CV

> The paper introduces Bridge, a pure autoregressive multimodal large language model (MLLM) that integrates text and image understanding and generation using a Mixture-of-Transformers architecture and a novel semantic-to-pixel discrete representation, achieving high performance with minimal increase in sequence length.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to construct a unified MLLM that can handle both image understanding and generation within a single autoregressive framework, addressing the trade-offs that exist in current approaches between semantic alignment and pixel-level detail.

**Method:** The method involves augmenting pre-trained visual understanding models with generative capabilities through a Mixture-of-Transformers architecture. A new semantic-to-pixel discrete representation is introduced to enhance visual generation fidelity without significantly increasing the sequence length.

**Result:** The results demonstrate that Bridge achieves competitive or superior performance in understanding and generation benchmarks across various multimodal tasks. It accomplishes this with reduced training data and decreased training time compared to prior unified MLLMs.

**Conclusion:** The conclusion is that Bridge effectively overcomes the limitations of existing approaches by enabling the creation of a unified MLLM that supports both understanding and generation with high performance, while also being more efficient in terms of training data and time requirements.

**Abstract:** Multimodal large language models (MLLMs) extend the success of language
models to visual understanding, and recent efforts have sought to build unified
MLLMs that support both understanding and generation. However, constructing
such models remains challenging: hybrid approaches combine continuous
embeddings with diffusion or flow-based objectives, producing high-quality
images but breaking the autoregressive paradigm, while pure autoregressive
approaches unify text and image prediction over discrete visual tokens but
often face trade-offs between semantic alignment and pixel-level fidelity. In
this work, we present Bridge, a pure autoregressive unified MLLM that augments
pre-trained visual understanding models with generative ability through a
Mixture-of-Transformers architecture, enabling both image understanding and
generation within a single next-token prediction framework. To further improve
visual generation fidelity, we propose a semantic-to-pixel discrete
representation that integrates compact semantic tokens with fine-grained pixel
tokens, achieving strong language alignment and precise description of visual
details with only a 7.9% increase in sequence length. Extensive experiments
across diverse multimodal benchmarks demonstrate that Bridge achieves
competitive or superior results in both understanding and generation
benchmarks, while requiring less training data and reduced training time
compared to prior unified MLLMs.

</details>


### [37] [Robust Classification of Oral Cancer with Limited Training Data](https://arxiv.org/abs/2510.01547)
*Akshay Bhagwan Sonawane,Lena D. Swamikannan,Lakshman Tamil*

Main category: cs.CV

> 本文提出了一种结合CNN和贝叶斯深度学习的方法，提高了基于小样本集的口腔癌分类模型的可靠性和泛化性。

<details>
  <summary>Details</summary>

**Motivation:** 口腔癌是全球常见的癌症之一，尤其是在缺乏足够医疗资源的地区，死亡率特别高。早期诊断对降低死亡率至关重要，但受限于口腔健康项目的不足、基础设施缺乏和医疗人员短缺等问题。传统深度学习模型尽管有潜力，但其依赖点估计会导致过度自信和可靠性降低，并且需要大规模的训练数据来避免过拟合和确保通用性，这在数据受限的环境中难以实现。

**Method:** 提出了一种结合卷积神经网络（CNN）和贝叶斯深度学习的混合模型，用于基于小规模训练集的口腔癌分类。该方法通过变分推理引入不确定性量化，以提高可靠性。

**Result:** 该模型在与训练数据集相似分布的测试数据集中达到了94%的准确率，与传统CNN表现相当。但在面对从实际情况中获取的、与训练数据分布有差异的图像数据时，模型表现出了更好的泛化能力，实现了88%的准确率，而传统CNN则仅为72.94%。

**Conclusion:** 该模型通过贝叶斯推理在数据稀缺的环境中增强早期口腔癌诊断的可靠性和泛化性，对于提升早期诊断能力具有重要意义。

**Abstract:** Oral cancer ranks among the most prevalent cancers globally, with a
particularly high mortality rate in regions lacking adequate healthcare access.
Early diagnosis is crucial for reducing mortality; however, challenges persist
due to limited oral health programs, inadequate infrastructure, and a shortage
of healthcare practitioners. Conventional deep learning models, while
promising, often rely on point estimates, leading to overconfidence and reduced
reliability. Critically, these models require large datasets to mitigate
overfitting and ensure generalizability, an unrealistic demand in settings with
limited training data. To address these issues, we propose a hybrid model that
combines a convolutional neural network (CNN) with Bayesian deep learning for
oral cancer classification using small training sets. This approach employs
variational inference to enhance reliability through uncertainty
quantification. The model was trained on photographic color images captured by
smartphones and evaluated on three distinct test datasets. The proposed method
achieved 94% accuracy on a test dataset with a distribution similar to that of
the training data, comparable to traditional CNN performance. Notably, for
real-world photographic image data, despite limitations and variations
differing from the training dataset, the proposed model demonstrated superior
generalizability, achieving 88% accuracy on diverse datasets compared to 72.94%
for traditional CNNs, even with a smaller dataset. Confidence analysis revealed
that the model exhibits low uncertainty (high confidence) for correctly
classified samples and high uncertainty (low confidence) for misclassified
samples. These results underscore the effectiveness of Bayesian inference in
data-scarce environments in enhancing early oral cancer diagnosis by improving
model reliability and generalizability.

</details>


### [38] [Consistent Assistant Domains Transformer for Source-free Domain Adaptation](https://arxiv.org/abs/2510.01559)
*Renrong Shao,Wei Zhang,Kangyang Luo,Qin Li,and Jun Wang*

Main category: cs.CV

> 本文提出了一种新的SFDA方法CADTrans，通过构造多样化和一致性策略来解决传统方法在处理困难样本和领域偏差上的局限，实验结果表明CADTrans在多个基准数据集上表现优异。

<details>
  <summary>Details</summary>

**Motivation:** 传统SFDA方法中，由于无法直接获取源域数据，无法获得确定性的不变特征，且现有方法易受困难样本以及领域偏差的影响。CADTrans旨在改进现有方法的缺点，解决它们在表示多样性和区分样本难易程度方面的不足。

**Method:** 本文提出了用于无源领域适应（SFDA）的一致性辅助域变换器（CADTrans），通过构建领域一致性不变特征表示来解决现有方法中多样性表示不足的问题。CADTrans通过辅助域模块从中级聚拢的全局注意力中获得多样化表示，并利用多种一致性策略获得不变特征表示，以区分简单和困难样本。此外，为对齐困难样本至相应简单样本，构建了条件多核最大平均差异（CMK-MMD）策略来区分相同类别样本和不同类别样本。

**Result:** 在多个基准测试（如Office-31，Office-Home，VISDA-C和DomainNet-126）上进行的广泛实验证明，本文提出的CADTrans方法比现有方法取得了显著的性能提升。

**Conclusion:** 实验结果证明，CADTrans通过引入辅助域模块并采用多样性和一致性的策略，能够在源域不可用的情况下提升目标领域的性能，并成功解决了传统SFDA方法面临的困难样本对齐问题。

**Abstract:** Source-free domain adaptation (SFDA) aims to address the challenge of
adapting to a target domain without accessing the source domain directly.
However, due to the inaccessibility of source domain data, deterministic
invariable features cannot be obtained. Current mainstream methods primarily
focus on evaluating invariant features in the target domain that closely
resemble those in the source domain, subsequently aligning the target domain
with the source domain. However, these methods are susceptible to hard samples
and influenced by domain bias. In this paper, we propose a Consistent Assistant
Domains Transformer for SFDA, abbreviated as CADTrans, which solves the issue
by constructing invariable feature representations of domain consistency.
Concretely, we develop an assistant domain module for CADTrans to obtain
diversified representations from the intermediate aggregated global attentions,
which addresses the limitation of existing methods in adequately representing
diversity. Based on assistant and target domains, invariable feature
representations are obtained by multiple consistent strategies, which can be
used to distinguish easy and hard samples. Finally, to align the hard samples
to the corresponding easy samples, we construct a conditional multi-kernel max
mean discrepancy (CMK-MMD) strategy to distinguish between samples of the same
category and those of different categories. Extensive experiments are conducted
on various benchmarks such as Office-31, Office-Home, VISDA-C, and
DomainNet-126, proving the significant performance improvements achieved by our
proposed approaches. Code is available at
https://github.com/RoryShao/CADTrans.git.

</details>


### [39] [Guiding Multimodal Large Language Models with Blind and Low Vision People Visual Questions for Proactive Visual Interpretations](https://arxiv.org/abs/2510.01576)
*Ricardo Gonzalez Penuela,Felipe Arias-Russi,Victor Capriles*

Main category: cs.CV

> 本研究开发了一个系统，该系统利用以往BLV用户的提问来指导MLLM生成更相关的图像描述，从而提高交流效率，评估显示该方法有效。

<details>
  <summary>Details</summary>

**Motivation:** 尽管多模态大型语言模型已经整合到视觉解释应用中以支持失明和低视力用户，但这些应用倾向于提供全面但冗长的描述，这往往导致交流效率低下。本研究旨在通过生成更上下文相关的描述来解决这一问题。

**Method:** 本研究开发了一个系统，该系统利用VizWiz-LF数据集中以往BLV用户的提问，为BLV用户生成更相关的图像描述。当系统接收到一张图像时，它能找到相似的视觉上下文，并使用相关的提问来指导MLLM生成更适合用户的描述。

**Result:** 通过三名人类标注者对92个具有上下文意识和无上下文意识的描述进行的评估表明，具有上下文意识的描述在76.1%的情况下能预测并解答用户的问题，并且在54.4%的比较中更受用户欢迎。

**Conclusion:** 本研究展示了使用BLV用户的视觉提问来指导MLLM生成更相关的图像描述的方法的有效性，研究成果和数据分析已在GitHub上公开。

**Abstract:** Multimodal large language models (MLLMs) have been integrated into visual
interpretation applications to support Blind and Low Vision (BLV) users because
of their accuracy and ability to provide rich, human-like interpretations.
However, these applications often default to comprehensive, lengthy
descriptions regardless of context. This leads to inefficient exchanges, as
users must go through irrelevant details rather than receiving the specific
information they are likely to seek. To deliver more contextually-relevant
information, we developed a system that draws on historical BLV users
questions. When given an image, our system identifies similar past visual
contexts from the VizWiz-LF dataset and uses the associated questions to guide
the MLLM generate descriptions more relevant to BLV users. An evaluation with
three human labelers who revised 92 context-aware and context-free descriptions
showed that context-aware descriptions anticipated and answered users'
questions in 76.1% of cases (70 out of 92) and were preferred in 54.4% of
comparisons (50 out of 92). Our paper reviews, and data analysis are publicly
available in a Github repository at
https://github.com/rgonzalezp/guiding-multimodal-large-language-models-with-blind-and-low-vision-people-visual-questions .

</details>


### [40] [ImageNet-Think-250K: A Large-Scale Synthetic Dataset for Multimodal Reasoning for Vision Language Models](https://arxiv.org/abs/2510.01582)
*Krishna Teja Chitty-Venkata,Murali Emani*

Main category: cs.CV

> 本研究开发了一个名为ImageNet-Think的多模态推理数据集，用以提升视觉语言模型的推理能力，并将公开数据集和评估基准，以促进相关领域的研究。

<details>
  <summary>Details</summary>

**Motivation:** 我们的目标是促进更强大VLMs的发展，同时也对多模态推理机制作出更深入的探讨。

**Method:** 我们开发了ImageNet-Think数据集，这是一个旨在帮助提高视觉语言模型（VLMs）推理能力的多模态推理数据集。该数据集基于ImageNet21k 数据集中的250,000张图像，提供结构化的推理标记和相应的答案。数据集由两个先进的VLMs（GLM-4.1V-9B-Thinking和Kimi-VL-A3B-Thinking-2506）生成，每张图像都有两对推理-答案序列，作为训练和评估多模态推理模型的资源。

**Result:** 通过该数据集，我们捕捉到了VLMs的分步推理过程及其最终的描述性答案，为发展更稳健的VLMs做出了可能的贡献。

**Conclusion:** 我们所创建的这个数据集和评估基准将会公开用于帮助研究多模态VLMs的思考/推理能力，推进视觉语言模型的发展和对多模态推理机制的理解。

**Abstract:** We develop ImageNet-Think, a multimodal reasoning dataset designed to aid the
development of Vision Language Models (VLMs) with explicit reasoning
capabilities. Our dataset is built on 250,000 images from ImageNet21k dataset,
providing structured thinking tokens and corresponding answers. Our synthetic
dataset is generated by two state-of-the-art VLMs: GLM-4.1V-9B-Thinking and
Kimi-VL-A3B-Thinking-2506. Each image is accompanied by two pairs of
thinking-answer sequences, creating a resource for training and evaluating
multimodal reasoning models. We capture the step-by-step reasoning process of
VLMs and the final descriptive answers. Our goal with this dataset is to enable
the development of more robust VLMs while contributing to the broader
understanding of multimodal reasoning mechanisms. The dataset and evaluation
benchmarks will be publicly available to aid research in reasoning/thinking
multimodal VLMs.

</details>


### [41] [NPN: Non-Linear Projections of the Null-Space for Imaging Inverse Problems](https://arxiv.org/abs/2510.01608)
*Roman Jacome,Romario Gualdrón-Hurtado,Leon Suarez,Henry Arguello*

Main category: cs.CV

> 本文提出了一种新的非线性零空间投影（NPN）正则化方法，该方法通过神经网络在传感矩阵零空间的低维投影中寻找解，从而改善图像逆问题的重建保真度。

<details>
  <summary>Details</summary>

**Motivation:** 传统的先验通常忽略了零空间的任务特定结构。本文的动机在于解决高维信号从欠采样、噪声测量中恢复的基本问题，并通过针对特定传感矩阵的先验信息来提高解的可解释性和适应性。

**Method:** 本文提出了一种新的正则化类别，称为非线性零空间投影（NPN），该方法使用神经网络在传感矩阵零空间的低维投影中寻找解，而不是在图像域中施加结构约束。

**Result:** 实验结果表明，在包括压缩感知、去模糊、超分辨率、计算机断层扫描和磁共振成像在内的各种图像逆问题中，与现有的重建框架和传统图像域先验相结合时，NPN先验可以提高重建精度。

**Conclusion:** NPN展示了通过聚焦传感矩阵零空间的结构来提高重建精度的能力，并在多种图像逆问题中显示出优越性。

**Abstract:** Imaging inverse problems aims to recover high-dimensional signals from
undersampled, noisy measurements, a fundamentally ill-posed task with infinite
solutions in the null-space of the sensing operator. To resolve this ambiguity,
prior information is typically incorporated through handcrafted regularizers or
learned models that constrain the solution space. However, these priors
typically ignore the task-specific structure of that null-space. In this work,
we propose \textit{Non-Linear Projections of the Null-Space} (NPN), a novel
class of regularization that, instead of enforcing structural constraints in
the image domain, promotes solutions that lie in a low-dimensional projection
of the sensing matrix's null-space with a neural network. Our approach has two
key advantages: (1) Interpretability: by focusing on the structure of the
null-space, we design sensing-matrix-specific priors that capture information
orthogonal to the signal components that are fundamentally blind to the sensing
process. (2) Flexibility: NPN is adaptable to various inverse problems,
compatible with existing reconstruction frameworks, and complementary to
conventional image-domain priors. We provide theoretical guarantees on
convergence and reconstruction accuracy when used within plug-and-play methods.
Empirical results across diverse sensing matrices demonstrate that NPN priors
consistently enhance reconstruction fidelity in various imaging inverse
problems, such as compressive sensing, deblurring, super-resolution, computed
tomography, and magnetic resonance imaging, with plug-and-play methods,
unrolling networks, deep image prior, and diffusion models.

</details>
