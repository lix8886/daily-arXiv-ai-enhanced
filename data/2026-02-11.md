<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 8]
- [cs.CV](#cs.CV) [Total: 5]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Overview of PAN 2026: Voight-Kampff Generative AI Detection, Text Watermarking, Multi-Author Writing Style Analysis, Generative Plagiarism Detection, and Reasoning Trajectory Detection](https://arxiv.org/abs/2602.09147)
*Janek Bevendorff,Maik Fröbe,André Greiner-Petter,Andreas Jakoby,Maximilian Mayerl,Preslav Nakov,Henry Plutz,Martin Potthast,Benno Stein,Minh Ngoc Ta,Yuxia Wang,Eva Zangerle*

Main category: cs.CL

> PAN研讨会计划通过五个任务来促进计算风格学和文本取证领域的发展，包括生成式AI检测、文本水印、多作者写作风格分析、生成式抄袭检测和推理路径检测。

<details>
  <summary>Details</summary>

**Motivation:** PAN研讨会的目的是推动计算风格学和文本取证的发展，通过举办具有挑战性的任务促进该领域的发展和进步。

**Method:** 该论文的目标是通过客观和可重复的评估来推进计算风格学和文本取证。具体工作包括检测生成式AI文本、文本水印技术、多作者写作风格分析、生成式抄袭检测和推理路径检测五个任务。

**Result:** 虽然摘要中没有直接给出实验结果，但是计划通过TIRA实验平台接收软件提交，这将促进该领域的研究进展。

**Conclusion:** 通过组织这些任务，研讨会旨在推动相关技术的发展，尤其是针对生成式AI内容的检测和分析。

**Abstract:** The goal of the PAN workshop is to advance computational stylometry and text forensics via objective and reproducible evaluation. In 2026, we run the following five tasks: (1) Voight-Kampff Generative AI Detection, particularly in mixed and obfuscated authorship scenarios, (2) Text Watermarking, a new task that aims to find new and benchmark the robustness of existing text watermarking schemes, (3) Multi-author Writing Style Analysis, a continued task that aims to find positions of authorship change, (4) Generative Plagiarism Detection, a continued task that targets source retrieval and text alignment between generated text and source documents, and (5) Reasoning Trajectory Detection, a new task that deals with source detection and safety detection of LLM-generated or human-written reasoning trajectories. As in previous years, PAN invites software submissions as easy-to-reproduce Docker containers for most of the tasks. Since PAN 2012, more than 1,100 submissions have been made this way via the TIRA experimentation platform.

</details>


### [2] [Measuring Inclusion in Interaction: Inclusion Analytics for Human-AI Collaborative Learning](https://arxiv.org/abs/2602.09269)
*Jaeyoon Choi,Nia Nixon*

Main category: cs.CL

> 该论文提出了一种基于对话的框架——包容性分析，用于在协作问题解决过程中动态地评估包容性。

<details>
  <summary>Details</summary>

**Motivation:** 当前评估人工智能和教育中的包容性、公平性和可及性的方法有限，未能捕捉协作问题解决过程中的即时互动细节。

**Method:** 论文定义了参与公平性、情感氛围和学术公平性三个维度来衡量包容性，并展示了使用可扩展的互动水平度量使得这些构造在分析中可见的方法。

**Result:** 通过模拟对话和人类与AI团队实验的实证数据，展示包容性分析框架如何揭示参与模式、关系动态和观点采纳的模式。

**Conclusion:** 该研究首次展示了在人机协作学习环境中采取过程定向方法测量包容性的可能性。

**Abstract:** Inclusion, equity, and access are widely valued in AI and education, yet are often assessed through coarse sample descriptors or post-hoc self-reports that miss how inclusion is shaped moment by moment in collaborative problem solving (CPS). In this proof-of-concept paper, we introduce inclusion analytics, a discourse-based framework for examining inclusion as a dynamic, interactional process in CPS. We conceptualize inclusion along three complementary dimensions -- participation equity, affective climate, and epistemic equity -- and demonstrate how these constructs can be made analytically visible using scalable, interaction-level measures. Using both simulated conversations and empirical data from human-AI teaming experiments, we illustrate how inclusion analytics can surface patterns of participation, relational dynamics, and idea uptake that remain invisible to aggregate or post-hoc evaluations. This work represents an initial step toward process-oriented approaches to measuring inclusion in human-AI collaborative learning environments.

</details>


### [3] [Effective Reasoning Chains Reduce Intrinsic Dimensionality](https://arxiv.org/abs/2602.09276)
*Archiki Prasad,Mandar Joshi,Kenton Lee,Mohit Bansal,Peter Shaw*

Main category: cs.CL

> 本研究通过内在维度这一度量工具，确认有效的推理策略能够更好地压缩任务所需参数，且这种策略对语言模型在各种数据上的泛化性能有着正面的影响。

<details>
  <summary>Details</summary>

**Motivation:** 虽然链式推理在复杂的推理任务上改善了语言模型的表现，但对于具体机制的理解仍然不足。作者希望通过引入内在维度这一量化指标来更好地分析推理过程及策略对模型泛化能力的影响。

**Method:** 通过固定模型架构并改变任务描述来评估不同推理策略，使用内在维度作为量化推理链有效性的一种度量。内在维度衡量了达到特定任务给定准确度阈值所需要的最少模型维度数量。

**Result:** 研究发现，有效的推理策略能够降低任务的内在维度，并且这种内在维度在GSM8K数据集上的4B和1B参数模型中均显示出良好的泛化性能，无论是对于分布内还是分布外的数据。

**Conclusion:** 此研究提供了一个新颖的量化指标——内在维度，用于分析推理过程，表明有效的推理链通过更好的压缩任务来使用更少的参数，从而促进学习。

**Abstract:** Chain-of-thought (CoT) reasoning and its variants have substantially improved the performance of language models on complex reasoning tasks, yet the precise mechanisms by which different strategies facilitate generalization remain poorly understood. While current explanations often point to increased test-time computation or structural guidance, establishing a consistent, quantifiable link between these factors and generalization remains challenging. In this work, we identify intrinsic dimensionality as a quantitative measure for characterizing the effectiveness of reasoning chains. Intrinsic dimensionality quantifies the minimum number of model dimensions needed to reach a given accuracy threshold on a given task. By keeping the model architecture fixed and varying the task formulation through different reasoning strategies, we demonstrate that effective reasoning strategies consistently reduce the intrinsic dimensionality of the task. Validating this on GSM8K with Gemma-3 1B and 4B, we observe a strong inverse correlation between the intrinsic dimensionality of a reasoning strategy and its generalization performance on both in-distribution and out-of-distribution data. Our findings suggest that effective reasoning chains facilitate learning by better compressing the task using fewer parameters, offering a new quantitative metric for analyzing reasoning processes.

</details>


### [4] [Don't Shoot The Breeze: Topic Continuity Model Using Nonlinear Naive Bayes With Attention](https://arxiv.org/abs/2602.09312)
*Shu-Ting Pi,Pradeep Bagavan,Yejia Li,Disha,Qun Liu*

Main category: cs.CL

> 本文提出了一种话题连续性模型，用于评估聊天机器人回复是否与初始对话主题一致，该模型使用Naive Bayes方法和注意力机制，可以处理任意长度的对话，并在长而复杂的对话中表现出色，为LLM的负责任使用提供了机会。

<details>
  <summary>Details</summary>

**Motivation:** 解决聊天机器人在不同商业场景中保持话题连续性的挑战，提升用户体验并优化计算资源使用。

**Method:** 基于自然语言理解模型，通过Naive Bayes方法转化为可量化的形式，并引入注意力机制和对数非线性来增强模型捕捉话题连续性能力。

**Result:** 实验显示，该模型在处理长而复杂对话方面显著优于传统方法，表现出色。

**Conclusion:** 该模型提出了处理话题连续性的一种新颖方法，尤其适用于长对话，为提升大型语言模型的使用体验提供了路径。

**Abstract:** Utilizing Large Language Models (LLM) as chatbots in diverse business scenarios often presents the challenge of maintaining topic continuity. Abrupt shifts in topics can lead to poor user experiences and inefficient utilization of computational resources. In this paper, we present a topic continuity model aimed at assessing whether a response aligns with the initial conversation topic. Our model is built upon the expansion of the corresponding natural language understanding (NLU) model into quantifiable terms using a Naive Bayes approach. Subsequently, we have introduced an attention mechanism and logarithmic nonlinearity to enhance its capability to capture topic continuity. This approach allows us to convert the NLU model into an interpretable analytical formula. In contrast to many NLU models constrained by token limits, our proposed model can seamlessly handle conversations of any length with linear time complexity. Furthermore, the attention mechanism significantly improves the model's ability to identify topic continuity in complex conversations. According to our experiments, our model consistently outperforms traditional methods, particularly in handling lengthy and intricate conversations. This unique capability offers us an opportunity to ensure the responsible and interpretable use of LLMs.

</details>


### [5] [Beyond Uniform Credit: Causal Credit Assignment for Policy Optimization](https://arxiv.org/abs/2602.09331)
*Mykola Khandoga,Rui Yuan,Vinay Kumar Sankarapu*

Main category: cs.CL

> Counterfactual importance weighting in policy gradient methods for language models improves reasoning tasks by adjusting token importance directly from the policy model's own probability shifts.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the limitation of uniform credit assignment in policy gradient methods, which does not differentiate critical from filler tokens during reasoning tasks.

**Method:** Policy gradient methods for language model reasoning use uniform credit for all tokens. The proposed method introduces counterfactual importance weighting to adjust credit based on the impact of tokens on answer probability.

**Result:** Experiments show consistent improvements over uniform baselines and faster convergence to equivalent accuracy on the GSM8K dataset.

**Conclusion:** The findings support the use of counterfactual importance weighting as foundational for future research in enhancing language model reasoning, though they remain a basis for further investigation.

**Abstract:** Policy gradient methods for language model reasoning, such as GRPO and DAPO, assign uniform credit to all generated tokens - the filler phrase "Let me think" receives the same gradient update as the critical calculation "23 + 45 = 68." We propose counterfactual importance weighting: mask reasoning spans, measure the drop in answer probability, and upweight tokens accordingly during policy gradient updates. Our method requires no auxiliary models or external annotation, instead importance is estimated directly from the policy model's own probability shifts. Experiments on GSM8K across three models spanning the Qwen and Llama families demonstrate consistent improvements over uniform baselines and faster convergence to equivalent accuracy. Inverting the importance signal hurts performance, confirming we capture genuine causal structure rather than noise. Analysis shows the method correctly prioritizes calculation steps over scaffolding text. We view these findings as establishing counterfactual importance weighting as a foundation for further research rather than a complete solution.

</details>


### [6] [FM SO.P: A Progressive Task Mixture Framework with Automatic Evaluation for Cross-Domain SOP Understanding](https://arxiv.org/abs/2602.09336)
*Siyuan Huang,Ziyu Wang,Chao Pan,Han Zhao*

Main category: cs.CL

> 我们提出了一种新的方法FM SO.P，通过逐步任务混合和自适应多代理评估系统，有效地解决了语言模型在理解企业标准操作程序(SOPs)和跨领域泛化方面的问题。

<details>
  <summary>Details</summary>

**Motivation:** 现有的语言模型在理解企业标准操作程序(SOPs)方面存在困难，并且无法很好地进行跨领域泛化。

**Method:** 我们提出了FM SO.P，通过两个创新点解决上述挑战：1) 引入逐步任务混合（progressive task mixtures），分阶段构建三项任务类型的能力：概念辨析、行动序列理解和情境感知图推理。2) 提出一个自适应多代理评估系统，包含三个代理，能够自动生成评分标准，分层测试集和评分标准，适应不同领域的约束条件。

**Result:** 在包含七个领域的SOPBench基准测试中，FM SO.P使用32B参数的模型实现了48.3%的通过率，而开源的7B参数模型实现了34.3%的通过率，与Qwen-2.5-72B-Instruct基线模型的34.4%的通过率相匹配，而我们的模型参数量少了10倍。

**Conclusion:** FM SO.P在企业标准操作程序理解和跨领域泛化方面取得了显著成果，显示了模型的高效性和优越性。

**Abstract:** Standard Operating Procedures (SOPs) are critical for enterprise operations, yet existing language models struggle with SOP understanding and cross-domain generalization. Current methods fail because joint training cannot differentiate between reasoning capabilities that SOP requires: terminology precision, sequential ordering, and constraint reasoning. We propose FM SO.P, solving these challenges through two novelties. First, we introduce progressive task mixtures that build capabilities by stages across three task types with cumulative data: concept disambiguation for terminology precision, action sequence understanding for procedural correctness, and scenario-aware graph reasoning for conditional logic. Second, we propose an automatic multi-agent evaluation system consisting of three agents that adaptively generate rubrics, stratified test sets, and rubric scoring, adapting to domains (e.g., temporal constraints for DMV, regulatory compliance for banking). Evaluated on SOPBench across seven domains (Bank, DMV, Healthcare, Market, University, Library, Hotel), FM SO.P achieves 48.3\% pass rate with our 32B model and 34.3\% with our opensource 7B model, matching Qwen-2.5-72B-Instruct baseline (34.4\%) with 10x fewer parameters.

</details>


### [7] [Understanding Risk and Dependency in AI Chatbot Use from User Discourse](https://arxiv.org/abs/2602.09339)
*Jianfeng Zhu,Karin G. Coifman,Ruoming Jin*

Main category: cs.CL

> 通过对Reddit社区的帖子进行大规模计算主题分析，识别出AI相关的心理风险经验维度。

<details>
  <summary>Details</summary>

**Motivation:** 由于对AI使用相关的心理风险如何出现、如何被体验以及如何被用户监管的经验性理解仍然有限，因此对这些内容进行研究。

**Method:** 采用多代理LLM辅助主题分析法，基于Braun和Clarke的反思框架，对从2023年至2025年期间收集的两个Reddit社区(r/AIDangers和r/ChatbotAddiction)的帖子进行了大规模计算主题分析。

**Result:** 识别出了14个常见的主题类别，并将其综合为五个高层次的经验维度。通过应用基于BERT的情感分类器对情感模式进行了进一步表征和分类。发现自我调节困难最为普遍，恐惧则集中在关于自主性、控制和技术风险的担忧上。

**Conclusion:** 这些结果为未来的人工智能安全研究、评估和负责任的治理奠定了基础。

**Abstract:** Generative AI systems are increasingly embedded in everyday life, yet empirical understanding of how psychological risk associated with AI use emerges, is experienced, and is regulated by users remains limited. We present a large-scale computational thematic analysis of posts collected between 2023 and 2025 from two Reddit communities, r/AIDangers and r/ChatbotAddiction, explicitly focused on AI-related harm and distress. Using a multi-agent, LLM-assisted thematic analysis grounded in Braun and Clarke's reflexive framework, we identify 14 recurring thematic categories and synthesize them into five higher-order experiential dimensions. To further characterize affective patterns, we apply emotion labeling using a BERT-based classifier and visualize emotional profiles across dimensions. Our findings reveal five empirically derived experiential dimensions of AI-related psychological risk grounded in real-world user discourse, with self-regulation difficulties emerging as the most prevalent and fear concentrated in concerns related to autonomy, control, and technical risk. These results provide early empirical evidence from lived user experience of how AI safety is perceived and emotionally experienced outside laboratory or speculative contexts, offering a foundation for future AI safety research, evaluation, and responsible governance.

</details>


### [8] [Digital Linguistic Bias in Spanish: Evidence from Lexical Variation in LLMs](https://arxiv.org/abs/2602.09346)
*Yoshifumi Kawasaki*

Main category: cs.CL

> 研究考察了大型语言模型（LLMs）捕捉西班牙语地理词汇变体的程度，发现除数据量外，其他因素也影响了模型对不同地区的方言表示。

<details>
  <summary>Details</summary>

**Motivation:** 研究目的是考察大型语言模型在捕捉存在显著地区差异的西班牙语地理词汇变体方面的表现，并探究除数据量外，哪些因素影响了LLMs中的方言表示。

**Method:** 采用大规模专家整理的西班牙语词汇变体数据库，利用问卷形式的问题（是或否问题和多项选择问题）来探究大型语言模型（LLMs）对西班牙语地理词汇变体的捕捉程度。评估涵盖了21个西班牙语国家的900多个词汇项，并在国家和方言区层面进行评估。

**Result:** 结果表明，LLMs在识别与西班牙、赤道几内亚、墨西哥及中美洲和拉普拉塔河流域有关的词汇变体方面更为准确，而智利方言对模型来说尤其难以区分。

**Conclusion:** 这项工作通过大规模详细的评估为理解LLMs中的方言知识提供了实证，并为西班牙语的数字语言偏见讨论提供了新的证据。

**Abstract:** This study examines the extent to which Large Language Models (LLMs) capture geographic lexical variation in Spanish, a language that exhibits substantial regional variation. Treating LLMs as virtual informants, we probe their dialectal knowledge using two survey-style question formats: Yes-No questions and multiple-choice questions. To this end, we exploited a large-scale, expert-curated database of Spanish lexical variation. Our evaluation covers more than 900 lexical items across 21 Spanish-speaking countries and is conducted at both the country and dialectal area levels. Across both evaluation formats, the results reveal systematic differences in how LLMs represent Spanish language varieties. Lexical variation associated with Spain, Equatorial Guinea, Mexico & Central America, and the La Plata River is recognized more accurately by the models, while the Chilean variety proves particularly difficult for the models to distinguish. Importantly, differences in the volume of country-level digital resources do not account for these performance patterns, suggesting that factors beyond data quantity shape dialectal representation in LLMs. By providing a fine-grained, large-scale evaluation of geographic lexical variation, this work advances empirical understanding of dialectal knowledge in LLMs and contributes new evidence to discussions of Digital Linguistic Bias in Spanish.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [9] [UI-Venus-1.5 Technical Report](https://arxiv.org/abs/2602.09082)
*Veuns-Team,:,Changlong Gao,Zhangxuan Gu,Yulin Liu,Xinyu Qiu,Shuheng Shen,Yue Wen,Tianyu Xia,Zhenyu Xu,Zhengwen Zeng,Beitong Zhou,Xingran Zhou,Weizhi Chen,Sunhao Dai,Jingya Dou,Yichen Gong,Yuan Guo,Zhenlin Guo,Feng Li,Qian Li,Jinzhen Lin,Yuqi Zhou,Linchao Zhu,Liang Chen,Zhenyu Guo,Changhua Meng,Weiqiang Wang*

Main category: cs.CV

> UI-Venus-1.5是一个统一的，端到端的GUI代理，适用于强大的现实世界应用，通过三种关键技术进步，它在多个基准测试中达到了新的行业领先水平，并展示了在中文移动应用中的强大导航能力。

<details>
  <summary>Details</summary>

**Motivation:** 尽管GUI代理在自动化数字环境互动中有巨大潜力，但在追求广泛通用性和一致强势任务表现方面仍有挑战。UI-Venus-1.5旨在解决这一问题，提供一个更健壮的解决方案。

**Method:** UI-Venus-1.5采用三种技术进步来达到其目标：1) 中期训练阶段，使用跨30+数据集的100亿tokens来建立基础的GUI语义；2) 在线增强学习，通过完整的轨迹回放对齐学习目标，以适应长期、动态的大规模环境导航；3) 通过模型融合，将领域特定模型（如基础模型、网络、移动）合并成一个统一的GUI代理。

**Result:** UI-Venus-1.5在ScreenSpot-Pro, VenusBench-GD, 和AndroidWorld等基准测试中达到了新的行业领先性能，明显优于之前的强大基线。此外，该模型在各种中文移动应用中展现出了强大的导航能力，能有效地执行用户指令。

**Conclusion:** 研究结果表明，通过引入新的训练技术和模型融合方法，UI-Venus-1.5能够超越现有的性能标准，在多样化的中文移动应用环境中成功执行导航任务，这展示了其在真实场景中的强大功能。

**Abstract:** GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus

</details>


### [10] [Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling](https://arxiv.org/abs/2602.09084)
*Ruijie Ye,Jiayi Zhang,Zhuoxin Liu,Zihao Zhu,Siyuan Yang,Li Li,Tianfu Fu,Franck Dernoncourt,Yue Zhao,Jiacheng Zhu,Ryan Rossi,Wenhao Chai,Zhengzhong Tu*

Main category: cs.CV

> 论文提出 Agent Banana，解决基于指令的图像编辑在专业工作流中的问题，包括过度编辑、多回合编辑下的对象忠实度问题和分辨率不匹配。

<details>
  <summary>Details</summary>

**Motivation:** 研究基于指令的图像编辑在专业工作流中的应用，并解决三大挑战：编辑者通常过度编辑，超出了用户的意图；现有模型大多是一次性操作，而多回合编辑可能会改变对象的忠实度；以及评估分辨率与真实工作流的分辨率不一致的问题。

**Method:** Agent Banana 是一个分层式的代理规划执行框架，用于高保真、对象感知的审慎编辑。它引入了两种关键机制：1) Context Folding：将长交互历史压缩成结构化的记忆，以实现稳定的长时段控制；2) 图像图层分解：执行局部图层编辑，保留非目标区域，同时支持原生分辨率输出。

**Result:** 通过 HDD-Bench 基准测试，Agent Banana 在多个回合的一致性和背景保真度上表现最佳（例如 IC 0.871，SSIM-OM 0.84，LPIPS-OM 0.12），同时在指令跟随方面具有竞争力，并且在标准单回合编辑基准上也表现出色。

**Conclusion:** 该工作有望推进可靠的、专业的代理图像编辑，并将其融入实际工作流。

**Abstract:** We study instruction-based image editing under professional workflows and identify three persistent challenges: (i) editors often over-edit, modifying content beyond the user's intent; (ii) existing models are largely single-turn, while multi-turn edits can alter object faithfulness; and (iii) evaluation at around 1K resolution is misaligned with real workflows that often operate on ultra high-definition images (e.g., 4K). We propose Agent Banana, a hierarchical agentic planner-executor framework for high-fidelity, object-aware, deliberative editing. Agent Banana introduces two key mechanisms: (1) Context Folding, which compresses long interaction histories into structured memory for stable long-horizon control; and (2) Image Layer Decomposition, which performs localized layer-based edits to preserve non-target regions while enabling native-resolution outputs. To support rigorous evaluation, we build HDD-Bench, a high-definition, dialogue-based benchmark featuring verifiable stepwise targets and native 4K images (11.8M pixels) for diagnosing long-horizon failures. On HDD-Bench, Agent Banana achieves the best multi-turn consistency and background fidelity (e.g., IC 0.871, SSIM-OM 0.84, LPIPS-OM 0.12) while remaining competitive on instruction following, and also attains strong performance on standard single-turn editing benchmarks. We hope this work advances reliable, professional-grade agentic image editing and its integration into real workflows.

</details>


### [11] [SemanticMoments: Training-Free Motion Similarity via Third Moment Features](https://arxiv.org/abs/2602.09146)
*Saar Huberman,Kfir Goldberg,Or Patashnik,Sagie Benaim,Ron Mokady*

Main category: cs.CV

> 本文提出SemanticMoments方法，通过计算预训练语义模型特征上的时间统计量来理解以运动为中心的视频，优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有视频检索方法过于依赖于静态外观和场景上下文，而非运动动态。传统的基于运动的方法如光学流缺乏语义基础。为了展示这种偏倚并解决它，作者提出了SemanticMoments方法。

**Method:** SemanticMoments方法计算预训练的语义模型特征上的时间统计量，特别是高阶时刻。

**Result:** SemanticMoments在SimMotion基准测试中表现优于现有的RGB、流量和文本监督方法。

**Conclusion:** 研究表明，在语义特征空间中的时间统计为以运动为中心的视频理解提供了可扩展和感知基础。

**Abstract:** Retrieving videos based on semantic motion is a fundamental, yet unsolved, problem. Existing video representation approaches overly rely on static appearance and scene context rather than motion dynamics, a bias inherited from their training data and objectives. Conversely, traditional motion-centric inputs like optical flow lack the semantic grounding needed to understand high-level motion. To demonstrate this inherent bias, we introduce the SimMotion benchmarks, combining controlled synthetic data with a new human-annotated real-world dataset. We show that existing models perform poorly on these benchmarks, often failing to disentangle motion from appearance. To address this gap, we propose SemanticMoments, a simple, training-free method that computes temporal statistics (specifically, higher-order moments) over features from pre-trained semantic models. Across our benchmarks, SemanticMoments consistently outperforms existing RGB, flow, and text-supervised methods. This demonstrates that temporal statistics in a semantic feature space provide a scalable and perceptually grounded foundation for motion-centric video understanding.

</details>


### [12] [A Hybrid Deterministic Framework for Named Entity Extraction in Broadcast News Video](https://arxiv.org/abs/2602.09154)
*Andrea Filiberto Lucas,Dylan Seychell*

Main category: cs.CV

> A framework for extracting personal names from news videos is proposed, emphasizing transparency and reliability. It achieves robust performance and provides traceable, auditable extraction, suitable for journalistic purposes.

<details>
  <summary>Details</summary>

**Motivation:** The increasing volume of video-based news content has created a need for automatic, transparent methods to extract on-screen information. Manual indexing is impractical due to variability in graphics, typography, and platform designs. Additionally, 59% of respondents found difficulty reading names in fast-paced broadcasts, underlining the practical importance of the work.

**Method:** The paper introduces a comprehensive framework for automatically detecting and extracting personal names from broadcast and social-media-native news videos. It consists of an interpretable, modular extraction pipeline and a curated, balanced corpus of annotated frames that reflects the diversity of contemporary news graphics.

**Result:** The method achieves 95.8% mAP@0.5 for graphical element localization, with precision at 79.9% and recall at 74.4%. While it performs slightly worse in raw accuracy (F1: 77.08%) than generative systems (F1: 84.18%), it offers greater transparency and auditability, avoiding hallucination and providing full traceability.

**Conclusion:** The proposed pipeline delivers a methodologically rigorous and interpretable baseline for hybrid multimodal information extraction in modern news media. It meets the need for transparent and reliable methods to extract on-screen information from the growing volume of video-based news content.

**Abstract:** The growing volume of video-based news content has heightened the need for transparent and reliable methods to extract on-screen information. Yet the variability of graphical layouts, typographic conventions, and platform-specific design patterns renders manual indexing impractical. This work presents a comprehensive framework for automatically detecting and extracting personal names from broadcast and social-media-native news videos. It introduces a curated and balanced corpus of annotated frames capturing the diversity of contemporary news graphics and proposes an interpretable, modular extraction pipeline designed to operate under deterministic and auditable conditions.
  The pipeline is evaluated against a contrasting class of generative multimodal methods, revealing a clear trade-off between deterministic auditability and stochastic inference. The underlying detector achieves 95.8% mAP@0.5, demonstrating operationally robust performance for graphical element localisation. While generative systems achieve marginally higher raw accuracy (F1: 84.18% vs 77.08%), they lack the transparent data lineage required for journalistic and analytical contexts. The proposed pipeline delivers balanced precision (79.9%) and recall (74.4%), avoids hallucination, and provides full traceability across each processing stage. Complementary user findings indicate that 59% of respondents report difficulty reading on-screen names in fast-paced broadcasts, underscoring the practical relevance of the task. The results establish a methodologically rigorous and interpretable baseline for hybrid multimodal information extraction in modern news media.

</details>


### [13] [Decoding Future Risk: Deep Learning Analysis of Tubular Adenoma Whole-Slide Images](https://arxiv.org/abs/2602.09155)
*Ahmed Rahu,Brian Shula,Brandon Combs,Aqsa Sultana,Surendra P. Singh,Vijayan K. Asari,Derrick Forchetti*

Main category: cs.CV

> 使用卷积神经网络(CNN)分析低级别管状腺瘤的全幻灯片图像（WSIs），以预测患者未来发生结直肠癌的风险。

<details>
  <summary>Details</summary>

**Motivation:** 尽管采取了预防措施，低级别腺瘤患者仍有可能发展成结直肠癌（CRC）。通过数字病理学和机器学习的发展，希望能够客观全面地分析WSIs，以识别出具有较高风险的患者。

**Method:** 利用卷积神经网络(CNN)机器学习算法对低级别管状腺瘤的全幻灯片图像(WIIs)中的细微组织学特征进行识别和分析。

**Result:** 尚无具体结果数据。

**Conclusion:** 研究旨在通过使用CNN机器学习技术对WSIs进行深入分析，以精准判断哪些低级别腺瘤患者未来有更高的CRC风险，从而为个体化的监测和预防性治疗策略提供科学依据。

**Abstract:** Colorectal cancer (CRC) remains a significant cause of cancer-related mortality, despite the widespread implementation of prophylactic initiatives aimed at detecting and removing precancerous polyps. Although screening effectively reduces incidence, a notable portion of patients initially diagnosed with low-grade adenomatous polyps will still develop CRC later in life, even without the presence of known high-risk syndromes. Identifying which low-risk patients are at higher risk of progression is a critical unmet need for tailored surveillance and preventative therapeutic strategies. Traditional histological assessment of adenomas, while fundamental, may not fully capture subtle architectural or cytological features indicative of malignant potential. Advancements in digital pathology and machine learning provide an opportunity to analyze whole-slide images (WSIs) comprehensively and objectively. This study investigates whether machine learning algorithms, specifically convolutional neural networks (CNNs), can detect subtle histological features in WSIs of low-grade tubular adenomas that are predictive of a patient's long-term risk of developing colorectal cancer.

</details>
