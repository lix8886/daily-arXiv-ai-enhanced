<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 5]
- [cs.CV](#cs.CV) [Total: 8]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [TabReX : Tabular Referenceless eXplainable Evaluation](https://arxiv.org/abs/2512.15907)
*Tejas Anvekar,Juhna Park,Aparna Garimella,Vivek Gupta*

Main category: cs.CL

> TabReX 是一种无参考的基于属性的框架，通过将源文本和生成的表格转换为知识图谱并进行匹配，评估了大型语言模型生成的表格的质量，提供了结构和事实准确性的量度，并且对于更难的扰动稳定。

<details>
  <summary>Details</summary>

**Motivation:** 评估大型语言模型生成的表格的质量仍然是一个挑战：现有的指标要么将表格扁平化为文本，忽略结构，要么依赖于固定参考，限制了泛化能力。

**Method:** 我们提出了一种无参考、基于属性的框架TabReX，用于通过基于图的推理来评估表格生成。TabReX 将源文本和生成的表格转换为规范化的知识图谱，通过一个由大语言模型引导的匹配过程进行对齐，并计算可以解释的、具有评分准则意识的分数，以量化结构和事实的准确性。

**Result:** 实验结果表明，TabReX 与专家排名的相关性最高，能在更难的扰动下保持稳定，并使模型与提示的细粒度分析成为可能。

**Conclusion:** TabReX 建立了一个新的评估生成系统的可信和可解释性的范例。

**Abstract:** Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. TabReX converts both source text and generated tables into canonical knowledge graphs, aligns them through an LLM-guided matching process, and computes interpretable, rubric-aware scores that quantify structural and factual fidelity. The resulting metric provides controllable trade-offs between sensitivity and specificity, yielding human-aligned judgments and cell-level error traces. To systematically asses metric robustness, we introduce TabReX-Bench, a large-scale benchmark spanning six domains and twelve planner-driven perturbation types across three difficulty tiers. Empirical results show that TabReX achieves the highest correlation with expert rankings, remains stable under harder perturbations, and enables fine-grained model-vs-prompt analysis establishing a new paradigm for trustworthy, explainable evaluation of structured generation systems.

</details>


### [2] [Social Story Frames: Contextual Reasoning about Narrative Intent and Reception](https://arxiv.org/abs/2512.15925)
*Joel Mire,Maria Antoniak,Steven R. Wilson,Zexin Ma,Achyutarama R. Ganti,Andrew Piper,Maarten Sap*

Main category: cs.CL

> 介绍了SocialStoryFrames，一种形式化方法，用于提取读者对于故事的反应，开发了两个验证模型，并应用于社交媒体数据集，用以研究故事讲述的多样性和实践。

<details>
  <summary>Details</summary>

**Motivation:** 现有的读者反应的计算模型有限，无法进行细致的分析。为了弥补这一差距，引入了SocialStoryFrames。

**Method:** 提出了一种新的形式化方法，称为SocialStoryFrames，用于提取读者反应的可能推论。开发了两个模型SSF-Generator和SSF-Classifier，分别通过人类调查和专家标注进行验证。

**Result:** 通过将这些模型应用于SSFCorpus，一个由6140篇来自不同背景的社交媒体故事组成的精选数据集，剖析了故事叙述意图的频率和相互依赖性，并对比了不同社区之间的叙述实践。

**Conclusion:** 通过将详细的、基于上下文的建模与读者反应的通用分类法联系起来，SocialStoryFrames开辟了对在线社区中故事讲述的新研究。

**Abstract:** Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader response, such as perceived author intent, explanatory and predictive reasoning, affective responses, and value judgments, using conversational context and a taxonomy grounded in narrative theory, linguistic pragmatics, and psychology. We develop two models, SSF-Generator and SSF-Classifier, validated through human surveys (N=382 participants) and expert annotations, respectively. We conduct pilot analyses to showcase the utility of the formalism for studying storytelling at scale. Specifically, applying our models to SSF-Corpus, a curated dataset of 6,140 social media stories from diverse contexts, we characterize the frequency and interdependence of storytelling intents, and we compare and contrast narrative practices (and their diversity) across communities. By linking fine-grained, context-sensitive modeling with a generic taxonomy of reader responses, SocialStoryFrames enable new research into storytelling in online communities.

</details>


### [3] [BRAID: Bounded Reasoning for Autonomous Inference and Decisions](https://arxiv.org/abs/2512.15959)
*Armağan Amcalar,Eyup Cinar*

Main category: cs.CL

> 研究发现，使用BRAID框架的结构化提示可以显著提高大型语言模型的推理准确性和成本效益。

<details>
  <summary>Details</summary>

**Motivation:** 研究大型语言模型（LLMs）在性能、成本和令牌使用之间的非线性关系，通过有结构的提示方法来提高模型的推理效率和成本效益。

**Method:** 使用BRAID（有界的推理框架）在不同层级的GPT模型上进行结构化提示的定量研究，通过Mermaid基础指令图来实现模型的结构性推理，而不是通过无界的自然语言令牌扩展。

**Result:** 研究表明，结构化的机器可读提示显著提高了生产系统中代理的推理准确性和成本效益。

**Conclusion:** BRAID被确立为优化自主代理系统推理效率的有效且可扩展技术。

**Abstract:** Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.

</details>


### [4] [Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms](https://arxiv.org/abs/2512.16034)
*Kieran Henderson,Kian Omoomi,Vasudha Varadarajan,Allison Lahnala,Charles Welch*

Main category: cs.CL

> 研究分析了不同类型自我披露信息在预测评判者对社会规范评价中的影响，发现人口统计信息比态度、关系和经验更重要，理论导向的方法优于自动生成的群集，并且需要较少的相关评论就能达到效果，评判者的自我披露信息种类越多样化，预测效果越好。

<details>
  <summary>Details</summary>

**Motivation:** 探索不同类型个人信息披露在预测评判者标签中的影响，因为以往个人信息数量有限，对哪种类型的信息最有帮助尚无深入了解。

**Method:** 对自我披露句子进行分类，并利用它们建立评判者模型预测社会规范的判断。通过多个消融实验和分析来检验不同信息类型对预测注解模式的影响。

**Result:** 发现人口统计信息比态度、关系和经验具有更大的影响力，基于理论的方法比自动生成的群集更加有效，预测需要的相关评论数量较少，评判者自我披露信息种类越多样化，预测性能越好。

**Conclusion:** 对于预测评判者标签而言，人口统计信息特别重要，少量的相关评论就足够预测，而广泛地收集多样的自我披露信息可以增强模型的预测性能。

**Abstract:** Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind of information is most informative for predicting annotator labels. In this work, we categorize self-disclosure sentences and use them to build annotator models for predicting judgments of social norms. We perform several ablations and analyses to examine the impact of the type of information on our ability to predict annotation patterns. We find that demographics are more impactful than attitudes, relationships, and experiences. Generally, theory-based approaches worked better than automatic clusters. Contrary to previous work, only a small number of related comments are needed. Lastly, having a more diverse sample of annotator self-disclosures leads to the best performance.

</details>


### [5] [Are We on the Right Way to Assessing LLM-as-a-Judge?](https://arxiv.org/abs/2512.16041)
*Yuanning Feng,Sinan Wang,Zhengxiang Cheng,Yao Wan,Dongping Chen*

Main category: cs.CL

> 本文提出了Sage评估套件，用于评估LLM-as-a-Judge的质量，强调了其稳定性和与现有基准的高度相关性，并指出现有的先进LLM在评判角色上的不一致现象，提出了深度推理和小组评判可提高评判一致性。

<details>
  <summary>Details</summary>

**Motivation:** 现有LLM-as-a-Judge评估基准主要依赖人工标注的地面实况，这引入了人类偏见，影响评估的可靠性并限制了可扩展性。

**Method:** 本文提出了一种名为Sage的新评估套件，用于评估LLM-as-a-Judge的质量，无需任何人工标注。Sage引入了理性选择理论中的两种新视角来衡量LLM-as-a-Judge：局部自洽性和全局逻辑一致性。

**Result:** 实验显示，Sage的稳定性与LLMBar和RewardBench2等监督基准高度相关，表明Sage作为LLM-as-a-Judge评估套件的可靠性。发现顶级LLM在评分和成对设置中表现出显著的可靠性问题。同时指出人类评判也有相当的不一致性。

**Conclusion:** Sage展示了它作为LLM-as-a-Judge评估套件的可靠性，并揭示了当前最佳LLM在评判角色上的限制。通过深度推理和小组评判，性能可得到提升。人类评判同样存在不一致性。

**Abstract:** LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [6] [Two-Step Data Augmentation for Masked Face Detection and Recognition: Turning Fake Masks to Real](https://arxiv.org/abs/2512.15774)
*Yan Yang,George Bebis,Mircea Nicolescu*

Main category: cs.CV

> 提出了一个结合规则变换和GAN的两步数据增强框架，以生成高质量的戴口罩脸样本，增强了现有方法并提出了未来的改进方向。

<details>
  <summary>Details</summary>

**Motivation:** 数据稀缺性和分布偏移对于口罩脸的检测和识别是一个巨大挑战。因此，需要一种有效的数据增强方法来生成高质量的戴口罩脸样本。

**Method:** 我们提出了一种两步生成数据增强框架，该框架结合了基于规则的口罩变换与无配对的图像到图像转换（使用GAN），从而能够在纯粹的合成变换之外生成真实的戴口罩脸照片样本。

**Result:** 相比于单独使用基于规则的变换，我们提出的方法在定性上一直有改进，并且补充了现有的类似IAMGAN的基于GAN的戴口罩脸生成方法。此外，我们引入了非口罩保存损失和随机噪声注入来稳定训练并增强样本多样性。

**Conclusion:** 实验证明了所提出组件的有效性，并指向了未来在面向脸识别任务的数据集中增强的改进方向。

**Abstract:** Data scarcity and distribution shift pose major challenges for masked face detection and recognition. We propose a two-step generative data augmentation framework that combines rule-based mask warping with unpaired image-to-image translation using GANs, enabling the generation of realistic masked-face samples beyond purely synthetic transformations. Compared to rule-based warping alone, the proposed approach yields consistent qualitative improvements and complements existing GAN-based masked face generation methods such as IAMGAN. We introduce a non-mask preservation loss and stochastic noise injection to stabilize training and enhance sample diversity. Experimental observations highlight the effectiveness of the proposed components and suggest directions for future improvements in data-centric augmentation for face recognition tasks.

</details>


### [7] [Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models](https://arxiv.org/abs/2512.15885)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Pier Luigi Dovesi,Shaghayegh Roohi,Mark Granroth-Wilding,Rita Cucchiara*

Main category: cs.CV

> JARVIS framework leverages I-JEPA for self-supervised visual enhancement in MLLMs, addressing the limitations of learning purely from language-supervision, and shows consistent performance improvement on vision tasks.

<details>
  <summary>Details</summary>

**Motivation:** The proficiency of MLLMs in visual reasoning tasks is limited due to their reliance on subjective textual descriptions and the imbalance between multimodal instruction tuning and text-only pre-training.

**Method:** JARVIS, a JEPA-inspired framework, integrates I-JEPA learning into the vision-language alignment pipeline to improve visual reasoning in MLLMs without solely relying on language supervision.

**Result:** Extensive experiments on standard MLLM benchmarks demonstrate that JARVIS enhances performance on vision-centric benchmarks across various LLM families, without compromising multimodal reasoning abilities.

**Conclusion:** JARVIS successfully addresses the challenges MLLMs face in visual reasoning tasks by focusing on self-supervised visual enhancement, leading to performance gains on vision-centric benchmarks.

**Abstract:** Multimodal Large Language Models (MLLMs) have recently demonstrated impressive capabilities in connecting vision and language, yet their proficiency in fundamental visual reasoning tasks remains limited. This limitation can be attributed to the fact that MLLMs learn visual understanding primarily from textual descriptions, which constitute a subjective and inherently incomplete supervisory signal. Furthermore, the modest scale of multimodal instruction tuning compared to massive text-only pre-training leads MLLMs to overfit language priors while overlooking visual details. To address these issues, we introduce JARVIS, a JEPA-inspired framework for self-supervised visual enhancement in MLLMs. Specifically, we integrate the I-JEPA learning paradigm into the standard vision-language alignment pipeline of MLLMs training. Our approach leverages frozen vision foundation models as context and target encoders, while training the predictor, implemented as the early layers of an LLM, to learn structural and semantic regularities from images without relying exclusively on language supervision. Extensive experiments on standard MLLM benchmarks show that JARVIS consistently improves performance on vision-centric benchmarks across different LLM families, without degrading multimodal reasoning abilities. Our source code is publicly available at: https://github.com/aimagelab/JARVIS.

</details>


### [8] [City Navigation in the Wild: Exploring Emergent Navigation from Web-Scale Knowledge in MLLMs](https://arxiv.org/abs/2512.15933)
*Dwip Dalal,Utkarsh Mishra,Narendra Ahuja,Nebojsa Jojic*

Main category: cs.CV

> 研究介绍了CityNav基准测试，用于评估MLLMs在复杂现实环境中的导航能力，并提出了VoP方法以显著提高导航成功率。

<details>
  <summary>Details</summary>

**Motivation:** 当前的评估基准主要集中在语言或依赖模拟环境，很少探索对知识密集型推理的要求。本研究旨在填补MLLMs在解决复杂现实世界任务的能力评估上的空白，特别是评估在知识密集型环境中的导航能力。

**Method:** 本研究提出了Sparsely Grounded Visual Navigation任务，旨在评估MLLMs在知识密集型现实环境中的顺序决策能力。具体实现通过CityNav基准测试，该测试涵盖了四个全球不同城市，评估未经过环境注释和架构修改的MLLMs的城市导航能力。代理必须仅依赖视觉输入和内部多模态推理，完成超过50个决策点的顺序导航，并自主地通过解释城市特定线索和识别地标来实现定位。

**Result:** 通过广泛的评估显示，目前最先进的MLLMs和标准推理技术显著地在具有挑战性的环境中表现不佳。研究提出了一种新的改进方法，称为Path Verbalization (VoP)，通过显式地探究从MLLMs获取的认知地图（关键地标和朝向目的地的方向）来增强导航成功率。

**Conclusion:** 研究证明了CityNav基准测试的有效性，并提出方法Verbalization of Path（VoP），显着提升了基于模型的导航成功率，并强调了未来研究在适用于复杂现实场景的MLLMs和评估流程改进上仍有很大的发展空间。

**Abstract:** Leveraging multimodal large language models (MLLMs) to develop embodied agents offers significant promise for addressing complex real-world tasks. However, current evaluation benchmarks remain predominantly language-centric or heavily reliant on simulated environments, rarely probing the nuanced, knowledge-intensive reasoning essential for practical, real-world scenarios. To bridge this critical gap, we introduce the task of Sparsely Grounded Visual Navigation, explicitly designed to evaluate the sequential decision-making abilities of MLLMs in challenging, knowledge-intensive real-world environments. We operationalize this task with CityNav, a comprehensive benchmark encompassing four diverse global cities, specifically constructed to assess raw MLLM-driven agents in city navigation. Agents are required to rely solely on visual inputs and internal multimodal reasoning to sequentially navigate 50+ decision points without additional environmental annotations or specialized architectural modifications. Crucially, agents must autonomously achieve localization through interpreting city-specific cues and recognizing landmarks, perform spatial reasoning, and strategically plan and execute routes to their destinations. Through extensive evaluations, we demonstrate that current state-of-the-art MLLMs and standard reasoning techniques (e.g., Chain-of-Thought, Reflection) significantly underperform in this challenging setting. To address this, we propose Verbalization of Path (VoP), which explicitly grounds the agent's internal reasoning by probing an explicit cognitive map (key landmarks and directions toward the destination) from the MLLMs, substantially enhancing navigation success. Project Webpage: https://dwipddalal.github.io/AgentNav/

</details>


### [9] [R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space](https://arxiv.org/abs/2512.15940)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.CV

> 本文介绍了R4框架，一个无需训练的4D时空检索增强推理框架，提升了视觉语言模型的多模态记忆能力，并通过实验证明其在动态环境中执行推理任务时的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 受人类感知和在四维空间中推理的启发，提出了一种无需训练的4D时空推理增强框架R4，以提升视觉语言模型的上下文依赖推理能力。

**Method:** R4框架通过将对象级别的语义描述锚定在度量空间和时间中，持续构建4D知识数据库，从而为视觉语言模型提供结构化的终身记忆。

**Result:** 实验结果表明，R4在基于环境的任务理解和导航基准测试中，在时空信息检索和推理方面明显优于基线方法。

**Conclusion:** R4提出了一个全新的4D推理范式，展示了在动态环境中进行事件性和协作推理而不必经过训练的能力。

**Abstract:** Humans perceive and reason about their surroundings in four dimensions by building persistent, structured internal representations that encode semantic meaning, spatial layout, and temporal dynamics. These multimodal memories enable them to recall past events, infer unobserved states, and integrate new information into context-dependent reasoning. Inspired by this capability, we introduce R4, a training-free framework for retrieval-augmented reasoning in 4D spatio-temporal space that equips vision-language models (VLMs) with structured, lifelong memory. R4 continuously constructs a 4D knowledge database by anchoring object-level semantic descriptions in metric space and time, yielding a persistent world model that can be shared across agents. At inference, natural language queries are decomposed into semantic, spatial, and temporal keys to retrieve relevant observations, which are integrated into the VLM's reasoning. Unlike classical retrieval-augmented generation methods, retrieval in R4 operates directly in 4D space, enabling episodic and collaborative reasoning without training. Experiments on embodied question answering and navigation benchmarks demonstrate that R4 substantially improves retrieval and reasoning over spatio-temporal information compared to baselines, advancing a new paradigm for embodied 4D reasoning in dynamic environments.

</details>


### [10] [The Perceptual Observatory Characterizing Robustness and Grounding in MLLMs](https://arxiv.org/abs/2512.15949)
*Tejas Anvekar,Fenil Bardoliya,Pavan K. Turaga,Chitta Baral,Vivek Gupta*

Main category: cs.CV

> 文章描述了一个新的框架，称为感知观测台，用于评估多模态大型语言模型的视觉理解能力，超越了简单任务准确性的评估。

<details>
  <summary>Details</summary>

**Motivation:** 现有的评估方法过于关注任务结果的准确性，而忽视了模型的鲁棒性、归因保真度和在受控扰动下的推理能力。此框架致力于解决这些问题，提供模型如何在扰动下保持感知和关系结构的见解。

**Method:** 介绍了一个框架——感知观测台（The Perceptual Observatory），用于描述多模态大型语言模型（MLLMs）在不同垂直领域的表现。这些垂直领域包括：(i) 简单视觉任务，如面部匹配和文本视觉理解能力；(ii) 从局部到全局的理解，涵盖图像匹配、格点指向游戏和属性定位，测试通用的视觉模型。每个垂直领域都通过基于像素的增强和基于扩散的风格化错觉进行系统性扰动，验证模型在扰动下的性能。

**Result:** 尚未提供具体结果，但框架旨在提供多模态大型语言模型在不同视觉任务下的表现洞察。

**Conclusion:** 感知观测台框架将以一种原则性的方式提供当前和未来模型在保持感知和关系结构方面的优缺点分析基础。

**Abstract:** Recent advances in multimodal large language models (MLLMs) have yielded increasingly powerful models, yet their perceptual capacities remain poorly characterized. In practice, most model families scale language component while reusing nearly identical vision encoders (e.g., Qwen2.5-VL 3B/7B/72B), which raises pivotal concerns about whether progress reflects genuine visual grounding or reliance on internet-scale textual world knowledge. Existing evaluation methods emphasize end-task accuracy, overlooking robustness, attribution fidelity, and reasoning under controlled perturbations. We present The Perceptual Observatory, a framework that characterizes MLLMs across verticals like: (i) simple vision tasks, such as face matching and text-in-vision comprehension capabilities; (ii) local-to-global understanding, encompassing image matching, grid pointing game, and attribute localization, which tests general visual grounding. Each vertical is instantiated with ground-truth datasets of faces and words, systematically perturbed through pixel-based augmentations and diffusion-based stylized illusions. The Perceptual Observatory moves beyond leaderboard accuracy to yield insights into how MLLMs preserve perceptual grounding and relational structure under perturbations, providing a principled foundation for analyzing strengths and weaknesses of current and future models.

</details>


### [11] [Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models](https://arxiv.org/abs/2512.15957)
*Utsav Panchal,Yuchen Liu,Luigi Palmieri,Ilche Georgievski,Marco Aiello*

Main category: cs.CV

> 提出CAMP-VLM模型，整合视觉语言模型和场景图信息，用于预测多人行为，并在预测准确性上表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 准确定预测移动机器人在有人类活动环境中的人类行为至关重要，而现有研究主要集中在从自我中心视角预测单个人的行为。为了理解多个从第三人称视角观察到的人类行为，提出了新的框架。

**Method:** CAMP-VLM：一種基於視覺語言模型（VLM）的框架，整合了來自視覺輸入的上下文特徵和來自場景圖的空間感知，以增強對人類-場景交互的預測能力。

**Result:** 通过有监督微调（SFT）和直接偏好优化（DPO），CAMP-VLM在预测准确性上优于最佳基线模型高达66.9%。

**Conclusion:** CAMP-VLM框架在多个人类行为预测方面表现优异，特别是在从观察者的视角进行预测时。

**Abstract:** Accurately predicting human behaviors is crucial for mobile robots operating in human-populated environments. While prior research primarily focuses on predicting actions in single-human scenarios from an egocentric view, several robotic applications require understanding multiple human behaviors from a third-person perspective. To this end, we present CAMP-VLM (Context-Aware Multi-human behavior Prediction): a Vision Language Model (VLM)-based framework that incorporates contextual features from visual input and spatial awareness from scene graphs to enhance prediction of humans-scene interactions. Due to the lack of suitable datasets for multi-human behavior prediction from an observer view, we perform fine-tuning of CAMP-VLM with synthetic human behavior data generated by a photorealistic simulator, and evaluate the resulting models on both synthetic and real-world sequences to assess their generalization capabilities. Leveraging Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), CAMP-VLM outperforms the best-performing baseline by up to 66.9% in prediction accuracy.

</details>


### [12] [From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection](https://arxiv.org/abs/2512.15971)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

> 我们改进了两种基于VLM的对象检测器以适应多光谱输入，并通过实验验证了其在少样本及全监督设置下的优越性能。

<details>
  <summary>Details</summary>

**Motivation:** 多光谱物体检测对于自动驾驶和监控等安全敏感应用至关重要。然而，多光谱数据注释的稀缺性限制了深度检测器的训练。因此，我们受到视觉语言模型近期成功的启发，探索其在少样本多光谱物体检测中的潜力。

**Method:** 通过调整基于视觉语言模型(Vision-Language Models, VLM)的两类检测器Grounding DINO和YOLO-World，使其能够处理多光谱输入，并提出了一种有效整合文本、视觉和热图像模态的机制。

**Result:** 在FLIR和M3FD两个流行的多光谱图像基准测试中，试验结果表明基于VLM的检测器在少样本场景中表现优异，显著优于使用类似数据训练的专业多光谱模型。

**Conclusion:** 大型VLM中学习到的语义先验能够有效迁移到未见过的光谱模态，这对于实现数据高效的多光谱感知提供了强有力的方法。

**Abstract:** Multispectral object detection is critical for safety-sensitive applications such as autonomous driving and surveillance, where robust perception under diverse illumination conditions is essential. However, the limited availability of annotated multispectral data severely restricts the training of deep detectors. In such data-scarce scenarios, textual class information can serve as a valuable source of semantic supervision. Motivated by the recent success of Vision-Language Models (VLMs) in computer vision, we explore their potential for few-shot multispectral object detection. Specifically, we adapt two representative VLM-based detectors, Grounding DINO and YOLO-World, to handle multispectral inputs and propose an effective mechanism to integrate text, visual and thermal modalities. Through extensive experiments on two popular multispectral image benchmarks, FLIR and M3FD, we demonstrate that VLM-based detectors not only excel in few-shot regimes, significantly outperforming specialized multispectral models trained with comparable data, but also achieve competitive or superior results under fully supervised settings. Our findings reveal that the semantic priors learned by large-scale VLMs effectively transfer to unseen spectral modalities, ofFering a powerful pathway toward data-efficient multispectral perception.

</details>


### [13] [Are vision-language models ready to zero-shot replace supervised classification models in agriculture?](https://arxiv.org/abs/2512.15977)
*Earl Ranario,Mason J. Earles*

Main category: cs.CV

> 通过对多种视觉-语言模型的性能测试，发现它们在农业决策支持中的表现不一，尤其在没有明确提示的情况下表现较差，不适合作为独立的农业诊断系统，但可以作为辅助工具。

<details>
  <summary>Details</summary>

**Motivation:** 研究视觉-语言模型（VLMs）在农业决策支持领域的可靠性，其中VLMs被越来越多地提出作为视觉识别任务的通用解决方案。

**Method:** 通过对AgML集合中的27个农业分类数据集进行基准测试，涵盖了植物病害、害虫和损伤以及植物和杂草种类识别等领域。测试了多种开源和闭源的视觉-语言模型（VLMs）的性能，并与监督任务特定基线（YOLO11）的准确性进行了比较。

**Result:** 实验结果显示，零样本VLMs的性能明显低于监督任务特定基线(YOLO11)，在多选提示下，表现最好的VLM (Gemini-3 Pro)达到了约62%的平均准确率；而开放式提示的准确率通常低于25%。开源模型Qwen-VL-72B表现最佳，接近闭源模型的表现。不同类型任务中，植物和杂草种类分类比害虫和损伤识别要容易。

**Conclusion:** 当前的现成VLMs还不适合作为独立的农业诊断系统，但是当与受限接口、明确的标签本体和领域感知评估策略结合使用时，可以作为辅助组件。

**Abstract:** Vision-language models (VLMs) are increasingly proposed as general-purpose solutions for visual recognition tasks, yet their reliability for agricultural decision support remains poorly understood. We benchmark a diverse set of open-source and closed-source VLMs on 27 agricultural classification datasets from the AgML collection, spanning 162 classes across plant disease, pest and damage, and plant and weed species identification. Across all tasks, zero-shot VLMs substantially underperform a supervised task-specific baseline (YOLO11), which consistently achieves markedly higher accuracy than any foundation model. Under multiple-choice prompting, the best-performing VLM (Gemini-3 Pro) reaches approximately 62% average accuracy, while open-ended prompting yields much lower performance, with raw accuracies typically below 25%. Applying LLM-based semantic judging increases open-ended accuracy (for example, from 21% to 30% for top models) and alters model rankings, demonstrating that evaluation methodology meaningfully affects reported conclusions. Among open-source models, Qwen-VL-72B performs best, approaching closed-source performance under constrained prompting but still trailing top proprietary systems. Task-level analysis shows that plant and weed species classification is consistently easier than pest and damage identification, which remains the most challenging category across models. Overall, these results indicate that current off-the-shelf VLMs are not yet suitable as standalone agricultural diagnostic systems, but can function as assistive components when paired with constrained interfaces, explicit label ontologies, and domain-aware evaluation strategies.

</details>
