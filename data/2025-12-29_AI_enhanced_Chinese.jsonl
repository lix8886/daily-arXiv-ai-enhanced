{"id": "2512.21402", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.21402", "abs": "https://arxiv.org/abs/2512.21402", "authors": ["Arnav Gupta", "Gurekas Singh Sahney", "Hardik Rathi", "Abhishek Chandwani", "Ishaan Gupta", "Pratik Narang", "Dhruv Kumar"], "title": "Understanding Virality: A Rubric based Vision-Language Model Framework for Short-Form Edutainment Evaluation", "comment": "Under Review", "summary": "Evaluating short-form video content requires moving beyond surface-level quality metrics toward human-aligned, multimodal reasoning. While existing frameworks like VideoScore-2 assess visual and semantic fidelity, they do not capture how specific audiovisual attributes drive real audience engagement. In this work, we propose a data-driven evaluation framework that uses Vision-Language Models (VLMs) to extract unsupervised audiovisual features, clusters them into interpretable factors, and trains a regression-based evaluator to predict engagement on short-form edutainment videos. Our curated YouTube Shorts dataset enables systematic analysis of how VLM-derived features relate to human engagement behavior. Experiments show strong correlations between predicted and actual engagement, demonstrating that our lightweight, feature-based evaluator provides interpretable and scalable assessments compared to traditional metrics (e.g., SSIM, FID). By grounding evaluation in both multimodal feature importance and human-centered engagement signals, our approach advances toward robust and explainable video understanding.", "AI": {"tldr": "本研究提出了一种使用视觉语言模型提取视听特征并预测短视频观众参与度的数据驱动评估框架。实验显示其预测的参与度与实际参与度有强相关性，优于传统方法。", "motivation": "现有的框架如VideoScore-2在评估视觉和语义保真度方面已经很完善，但未能捕捉到特定的视听属性如何驱动实际的观众参与度。因此，有必要利用一种新的方法来评估短视频内容，使之更加贴近人类的参与行为。", "method": "通过利用视觉语言模型（VLMs）提取无监督的视听特征，并将这些特征聚类为可解释的因素，随后使用这些因素训练一个回归评估器来预测短视频的观众参与度。", "result": "该研究提出了一种基于数据的评估框架，利用视觉语言模型（VLMs）提取无监督的视听特征，将这些特征聚类为可解释的因素，然后训练一个回归评估器来预测短视频的观众参与度。实验表明，预测的参与度与实际参与度之间存在强相关性。因此，该轻量级、基于特征的评估器提供了与传统指标相比更具解释性和可扩展性的评估方法。", "conclusion": "该研究提出的方法能够更加贴近人类行为，提供解释性和可扩展性的视频内容评估方法。"}}
{"id": "2512.21414", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21414", "abs": "https://arxiv.org/abs/2512.21414", "authors": ["Christina Liu", "Alan Q. Wang", "Joy Hsu", "Jiajun Wu", "Ehsan Adeli"], "title": "A Tool Bottleneck Framework for Clinically-Informed and Interpretable Medical Image Understanding", "comment": null, "summary": "Recent tool-use frameworks powered by vision-language models (VLMs) improve image understanding by grounding model predictions with specialized tools. Broadly, these frameworks leverage VLMs and a pre-specified toolbox to decompose the prediction task into multiple tool calls (often deep learning models) which are composed to make a prediction. The dominant approach to composing tools is using text, via function calls embedded in VLM-generated code or natural language. However, these methods often perform poorly on medical image understanding, where salient information is encoded as spatially-localized features that are difficult to compose or fuse via text alone. To address this, we propose a tool-use framework for medical image understanding called the Tool Bottleneck Framework (TBF), which composes VLM-selected tools using a learned Tool Bottleneck Model (TBM). For a given image and task, TBF leverages an off-the-shelf medical VLM to select tools from a toolbox that each extract clinically-relevant features. Instead of text-based composition, these tools are composed by the TBM, which computes and fuses the tool outputs using a neural network before outputting the final prediction. We propose a simple and effective strategy for TBMs to make predictions with any arbitrary VLM tool selection. Overall, our framework not only improves tool-use in medical imaging contexts, but also yields more interpretable, clinically-grounded predictors. We evaluate TBF on tasks in histopathology and dermatology and find that these advantages enable our framework to perform on par with or better than deep learning-based classifiers, VLMs, and state-of-the-art tool-use frameworks, with particular gains in data-limited regimes. Our code is available at https://github.com/christinaliu2020/tool-bottleneck-framework.", "AI": {"tldr": "研究提出了一种新的工具使用框架TBF，通过TBM来组合工具，提升了医学图像理解的效果，并且使得预测结果更具解释性和临床相关性。", "motivation": "现有的工具使用框架在医学图像理解上表现不佳，因为医学图像中显著的信息是空间局部特征，这些特征很难通过纯文本组合。", "method": "提出了名为工具瓶颈框架（TBF）的框架，用于解决医学图像理解中的问题。通过使用一个学习到的工具瓶颈模型（TBM），这个框架可以将VLM选中的工具输出计算和融合，从而克服单纯基于文本的工具组合的局限性。", "result": "实验在病理学和皮肤病学任务上的评估显示，TBF与深度学习分类器、VLMs和最先进的工具使用框架相比，在数据有限的情况下表现出显著优势。", "conclusion": "TBF提高了医学图像分析中的工具使用效率，并生成了更具解释性和临床相关性的预测模型。"}}
{"id": "2512.21434", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21434", "abs": "https://arxiv.org/abs/2512.21434", "authors": ["Nairouz Mrabah", "Mohamed Bouguessa", "Sihem Sami"], "title": "Scalable Deep Subspace Clustering Network", "comment": "Published at the 2025 IEEE 12th International Conference on Data Science and Advanced Analytics (DSAA)", "summary": "Subspace clustering methods face inherent scalability limits due to the $O(n^3)$ cost (with $n$ denoting the number of data samples) of constructing full $n\\times n$ affinities and performing spectral decomposition. While deep learning-based approaches improve feature extraction, they maintain this computational bottleneck through exhaustive pairwise similarity computations. We propose SDSNet (Scalable Deep Subspace Network), a deep subspace clustering framework that achieves $\\mathcal{O}(n)$ complexity through (1) landmark-based approximation, avoiding full affinity matrices, (2) joint optimization of auto-encoder reconstruction with self-expression objectives, and (3) direct spectral clustering on factorized representations. The framework combines convolutional auto-encoders with subspace-preserving constraints. Experimental results demonstrate that SDSNet achieves comparable clustering quality to state-of-the-art methods with significantly improved computational efficiency.", "AI": {"tldr": "SDSNet提出了一种新的子空间聚类框架，其通过基于地标点的近似避免完整亲和矩阵构建，实现O(n)复杂度，同时保持高质量的聚类结果。", "motivation": "传统的子空间聚类方法由于构建完整的n×n亲和矩阵和进行谱分解的O(n^3)成本，存在固有的可扩展性限制。虽然基于深度学习的方法改善了特征提取，但在通过详尽的成对相似性计算时仍保持这一计算瓶颈。SDSNet旨在解决这些可扩展性问题。", "method": "SDSNet (Scalable Deep Subspace Network)采用基于地标点的近似方法避免构建完整的亲和矩阵，同时联合优化自动编码器重构与自表达目标，并直接在因子化表示上进行谱聚类，结合卷积自动编码器与子空间保持约束。", "result": "实验结果表明，SDSNet在聚类质量上与最先进的方法相当，同时具有显著提高的计算效率。", "conclusion": "SDSNet提供了一种通过深度学习实现子空间聚类的新方法，其在保持高聚类质量的同时显著降低了计算成本。"}}
{"id": "2512.21452", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21452", "abs": "https://arxiv.org/abs/2512.21452", "authors": ["Haotian Lv", "Yuhui Zhang", "Jiangbo Dai", "Hanli Wu", "Jiaji Wang", "Dawei Wang"], "title": "Intelligent recognition of GPR road hidden defect images based on feature fusion and attention mechanism", "comment": "Accepted for publication in *IEEE Transactions on Geoscience and Remote Sensing*", "summary": "Ground Penetrating Radar (GPR) has emerged as a pivotal tool for non-destructive evaluation of subsurface road defects. However, conventional GPR image interpretation remains heavily reliant on subjective expertise, introducing inefficiencies and inaccuracies. This study introduces a comprehensive framework to address these limitations: (1) A DCGAN-based data augmentation strategy synthesizes high-fidelity GPR images to mitigate data scarcity while preserving defect morphology under complex backgrounds; (2) A novel Multi-modal Chain and Global Attention Network (MCGA-Net) is proposed, integrating Multi-modal Chain Feature Fusion (MCFF) for hierarchical multi-scale defect representation and Global Attention Mechanism (GAM) for context-aware feature enhancement; (3) MS COCO transfer learning fine-tunes the backbone network, accelerating convergence and improving generalization. Ablation and comparison experiments validate the framework's efficacy. MCGA-Net achieves Precision (92.8%), Recall (92.5%), and mAP@50 (95.9%). In the detection of Gaussian noise, weak signals and small targets, MCGA-Net maintains robustness and outperforms other models. This work establishes a new paradigm for automated GPR-based defect detection, balancing computational efficiency with high accuracy in complex subsurface environments.", "AI": {"tldr": "该研究提出了一种基于DCGAN数据增强、MCGA-Net网络和MS COCO迁移学习的综合框架，提升了基于GPR的路基缺陷检测的效率和准确性。", "motivation": "传统的GPR图像解释严重依赖主观专业知识，这导致了效率低下和不准确的问题，该研究旨在解决这些问题，提高缺陷检测的自动化水平。", "method": "研究设计了一种基于DCGAN的数据增强策略、提出了MCGA-Net网络，并使用MS COCO进行迁移学习。MCGA-Net结合MCFF和GAM技术，提升了多模态特征的表示和全局特征增强的能力。", "result": "通过钝化实验和对比实验证实了该框架的有效性，MCGA-Net在精度、召回率和mAP@50上均达到了高水平，并且在高斯噪声、弱信号和小目标检测上展现了较强的鲁棒性。", "conclusion": "本研究提供了一种新的GPR基缺陷检测框架，实现了计算效率与高精度在复杂地下环境中的平衡。"}}
{"id": "2512.21422", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21422", "abs": "https://arxiv.org/abs/2512.21422", "authors": ["Nathan Stringham", "Fateme Hashemi Chaleshtori", "Xinyuan Yan", "Zhichao Xu", "Bei Wang", "Ana Marasović"], "title": "Teaching People LLM's Errors and Getting it Right", "comment": null, "summary": "People use large language models (LLMs) when they should not. This is partly because they see LLMs compose poems and answer intricate questions, so they understandably, but incorrectly, assume LLMs won't stumble on basic tasks like simple arithmetic. Prior work has tried to address this by clustering instance embeddings into regions where an LLM is likely to fail and automatically describing patterns in these regions. The found failure patterns are taught to users to mitigate their overreliance. Yet, this approach has not fully succeeded. In this analysis paper, we aim to understand why.\n  We first examine whether the negative result stems from the absence of failure patterns. We group instances in two datasets by their meta-labels and evaluate an LLM's predictions on these groups. We then define criteria to flag groups that are sizable and where the LLM is error-prone, and find meta-label groups that meet these criteria. Their meta-labels are the LLM's failure patterns that could be taught to users, so they do exist. We next test whether prompting and embedding-based approaches can surface these known failures. Without this, users cannot be taught about them to reduce their overreliance. We find mixed results across methods, which could explain the negative result. Finally, we revisit the final metric that measures teaching effectiveness. We propose to assess a user's ability to effectively use the given failure patterns to anticipate when an LLM is error-prone. A user study shows a positive effect from teaching with this metric, unlike the human-AI team accuracy. Our findings show that teaching failure patterns could be a viable approach to mitigating overreliance, but success depends on better automated failure-discovery methods and using metrics like ours.", "AI": {"tldr": "研究分析了为何用户过度依赖LLM以及如何通过识别和教学失败模式来解决这个问题。发现自动识别失败模式的方法和评估标准的优化是关键。", "motivation": "本研究旨在理解为何先前的方法未能完全成功地减少用户对LLM的过度依赖，并探索教学失败模式是否是一个有潜力的方法。", "method": "本研究首先通过元标签对两个数据集中的实例进行分组，以评估LLM在这些组中的预测性能，并确定哪些组是较大且容易出错的，从而识别出潜在的失败模式。接着，研究测试了提示和基于嵌入的方法是否能识别这些已知的失败模式。最后，通过用户研究重新评估了教学效果，提出了一个新的度量标准，评估用户利用失败模式预测LLM易出错场景的能力。", "result": "研究发现，LLM确实存在可识别的失败模式，并且在提示和基于嵌入的方法中得到了部分有效的结果。同时，新的教学效果度量标准显示出积极的影响，而相较于团队准确性测量，这展示出教学方法的有效性。", "conclusion": "教学失败模式可以是减轻用户对LLM过度依赖的一项有效措施，但成功的关键在于改进自动发现失败的方法以及采用新的度量标准评估教学效果。"}}
{"id": "2512.21459", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21459", "abs": "https://arxiv.org/abs/2512.21459", "authors": ["Xiao Jin", "Liang Diao", "Qixin Xiao", "Yifan Hu", "Ziqi Zhang", "Yuchen Liu", "Haisong Gu"], "title": "CCAD: Compressed Global Feature Conditioned Anomaly Detection", "comment": "18 pages, 9 figures", "summary": "Anomaly detection holds considerable industrial significance, especially in scenarios with limited anomalous data. Currently, reconstruction-based and unsupervised representation-based approaches are the primary focus. However, unsupervised representation-based methods struggle to extract robust features under domain shift, whereas reconstruction-based methods often suffer from low training efficiency and performance degradation due to insufficient constraints. To address these challenges, we propose a novel method named Compressed Global Feature Conditioned Anomaly Detection (CCAD). CCAD synergizes the strengths of both paradigms by adapting global features as a new modality condition for the reconstruction model. Furthermore, we design an adaptive compression mechanism to enhance both generalization and training efficiency. Extensive experiments demonstrate that CCAD consistently outperforms state-of-the-art methods in terms of AUC while achieving faster convergence. In addition, we contribute a reorganized and re-annotated version of the DAGM 2007 dataset with new annotations to further validate our method's effectiveness. The code for reproducing main results is available at https://github.com/chloeqxq/CCAD.", "AI": {"tldr": "The paper introduces CCAD, a new anomaly detection method that improves upon existing approaches by integrating global features and an adaptive compression mechanism, leading to better performance and faster convergence.", "motivation": "The motivation arises from the challenges faced by current anomaly detection methods, where unsupervised representation-based methods fail to extract robust features under domain shift, and reconstruction-based methods suffer from low training efficiency and performance degradation due to limited constraints.", "method": "The paper proposes a novel method named Compressed Global Feature Conditioned Anomaly Detection (CCAD). This method combines the strengths of reconstruction-based and unsupervised representation-based approaches by using global features as a new modality to condition the reconstruction model. Additionally, an adaptive compression mechanism is designed to improve generalization and training efficiency.", "result": "Experiments show that CCAD consistently outperforms state-of-the-art methods in AUC score and achieves faster convergence.", "conclusion": "The paper concludes with the effectiveness of CCAD in anomaly detection, supported by experiments that demonstrate superior performance and efficiency, and contributions include a re-organized and re-annotated DAGM 2007 dataset for further validation."}}
{"id": "2512.21439", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.21439", "abs": "https://arxiv.org/abs/2512.21439", "authors": ["Geoffroy Morlat", "Marceau Nahon", "Augustin Chartouny", "Raja Chatila", "Ismael T. Freire", "Mehdi Khamassi"], "title": "Morality is Contextual: Learning Interpretable Moral Contexts from Human Data with Probabilistic Clustering and Large Language Models", "comment": "11 pages, 5 figures, +24 pages of Appendix", "summary": "Moral actions are judged not only by their outcomes but by the context in which they occur. We present COMETH (Contextual Organization of Moral Evaluation from Textual Human inputs), a framework that integrates a probabilistic context learner with LLM-based semantic abstraction and human moral evaluations to model how context shapes the acceptability of ambiguous actions. We curate an empirically grounded dataset of 300 scenarios across six core actions (violating Do not kill, Do not deceive, and Do not break the law) and collect ternary judgments (Blame/Neutral/Support) from N=101 participants. A preprocessing pipeline standardizes actions via an LLM filter and MiniLM embeddings with K-means, producing robust, reproducible core-action clusters. COMETH then learns action-specific moral contexts by clustering scenarios online from human judgment distributions using principled divergence criteria. To generalize and explain predictions, a Generalization module extracts concise, non-evaluative binary contextual features and learns feature weights in a transparent likelihood-based model. Empirically, COMETH roughly doubles alignment with majority human judgments relative to end-to-end LLM prompting (approx. 60% vs. approx. 30% on average), while revealing which contextual features drive its predictions. The contributions are: (i) an empirically grounded moral-context dataset, (ii) a reproducible pipeline combining human judgments with model-based context learning and LLM semantics, and (iii) an interpretable alternative to end-to-end LLMs for context-sensitive moral prediction and explanation.", "AI": {"tldr": "COMETH框架整合了概率性上下文学习器和基于LLM的语义抽象，通过学习真实世界道德行为上下文以解释行为的道德评价。实验表明COMETH较传统LLM模型在预测上更加准确和解释性强。", "motivation": "研究动机在于探索行为判定不仅仅依赖于行为结果，其发生的上下文环境同样起着关键作用。COMETH框架旨在模拟和解释这种复杂的行为判定过程。", "method": "COMETH框架结合概率性上下文学习器、基于LLM的语义抽象和人类道德评价来建模上下文如何影响模糊行为的可接受性。通过K-means聚类和MiniLM嵌入处理数据集中的600个行为。此外，COMETH通过人类判断分布对场景进行在线聚类，从而学习特定行为的道德上下文，并通过提取二元上下文特征和学习特征权重来解释预测。", "result": "COMETH在与大多数人类判断一致上有所提升，相较于直接使用LLM提示模型，其平均一致率大约为60%，而LLM模型的平均水平大约为30%。", "conclusion": "该研究提供了以实证为基础的道德上下文数据集，结合人类判断与模型驱动的上下文学习，以及LLM语义处理的可重复处理流程。并提出了一种透明且易于解释的方案，用以处理上下文敏感的道德预测。"}}
{"id": "2512.21472", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.21472", "abs": "https://arxiv.org/abs/2512.21472", "authors": ["Kumar Abhishek", "Jeremy Kawahara", "Ghassan Hamarneh"], "title": "IMA++: ISIC Archive Multi-Annotator Dermoscopic Skin Lesion Segmentation Dataset", "comment": "11 pages, 7 figures", "summary": "Multi-annotator medical image segmentation is an important research problem, but requires annotated datasets that are expensive to collect. Dermoscopic skin lesion imaging allows human experts and AI systems to observe morphological structures otherwise not discernable from regular clinical photographs. However, currently there are no large-scale publicly available multi-annotator skin lesion segmentation (SLS) datasets with annotator-labels for dermoscopic skin lesion imaging. We introduce ISIC MultiAnnot++, a large public multi-annotator skin lesion segmentation dataset for images from the ISIC Archive. The final dataset contains 17,684 segmentation masks spanning 14,967 dermoscopic images, where 2,394 dermoscopic images have 2-5 segmentations per image, making it the largest publicly available SLS dataset. Further, metadata about the segmentation, including the annotators' skill level and segmentation tool, is included, enabling research on topics such as annotator-specific preference modeling for segmentation and annotator metadata analysis. We provide an analysis on the characteristics of this dataset, curated data partitions, and consensus segmentation masks.", "AI": {"tldr": "本文介绍了一个大型的公共皮肤病变分割数据集--ISIC MultiAnnot++，包含了17,684个分割掩模和14,967个皮肤镜影像，并包括了标注者的技术水平等元数据，以促进特定标注者偏好建模和元数据分析的研究。", "motivation": "由于多标注者医学影像分割是一个重要的研究问题，但需要昂贵的标注数据集，因此本文旨在解决没有大型公开多标注者皮肤病变分割数据集的问题。", "method": "本文介绍了ISIC MultiAnnot++，一个大型公开的多标注者皮肤病变分割数据集，包含了来自ISIC Archive的17,684个分割掩模和14,967个皮肤镜影像，其中2,394个影像有2-5个分割标注。", "result": "本文提供了对数据集特性的分析，整理好的数据分区和共识分割掩模，为研究者提供了宝贵的资源。", "conclusion": "ISIC MultiAnnot++数据集的创建克服了皮肤病变分割领域缺乏大型标注数据集的难题，促进了该领域的发展。"}}
{"id": "2512.21494", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21494", "abs": "https://arxiv.org/abs/2512.21494", "authors": ["Soichiro Murakami", "Hidetaka Kamigaito", "Hiroya Takamura", "Manabu Okumura"], "title": "Oogiri-Master: Benchmarking Humor Understanding via Oogiri", "comment": null, "summary": "Humor is a salient testbed for human-like creative thinking in large language models (LLMs). We study humor using the Japanese creative response game Oogiri, in which participants produce witty responses to a given prompt, and ask the following research question: What makes such responses funny to humans? Previous work has offered only limited reliable means to answer this question. Existing datasets contain few candidate responses per prompt, expose popularity signals during ratings, and lack objective and comparable metrics for funniness. Thus, we introduce Oogiri-Master and Oogiri-Corpus, which are a benchmark and dataset designed to enable rigorous evaluation of humor understanding in LLMs. Each prompt is paired with approximately 100 diverse candidate responses, and funniness is rated independently by approximately 100 human judges without access to others' ratings, reducing popularity bias and enabling robust aggregation. Using Oogiri-Corpus, we conduct a quantitative analysis of the linguistic factors associated with funniness, such as text length, ambiguity, and incongruity resolution, and derive objective metrics for predicting human judgments. Subsequently, we benchmark a range of LLMs and human baselines in Oogiri-Master, demonstrating that state-of-the-art models approach human performance and that insight-augmented prompting improves the model performance. Our results provide a principled basis for evaluating and advancing humor understanding in LLMs.", "AI": {"tldr": "本研究通过设计Oogiri-Master基准测试和Oogiri-Corpus数据集，量化分析了影响趣味性的语言因素，使得评价和提高大型语言模型（LLMs）的幽默理解能力变得有理有据。", "motivation": "研究幽默对于检验大型语言模型（LLMs）的类人创造性思维具有重要意义。先前的研究无法提供有效的方法来回答“是什么使得回答给人类带来幽默感”的问题。", "method": "该研究设计了一个基准测试Oogiri-Master和数据集Oogiri-Corpus来评估大型语言模型（LLMs）理解和生成幽默的能力。每个提示都与大约100个不同的候选回应配对，并由大约100位人类评定者独立评定趣味性，无需查看其他人的评分，减少了流行度偏差，使聚合更为稳健。", "result": "研究通过Oogiri-Corpus进行了关于与趣味性相关联的语言因素的定量分析，例如文本长度、歧义和不协调解决方式，从而得出预测人类判断的客观标准。此外，在Oogiri-Master基准测试中，展示了最先进的模型接近人类表现，洞察力增强的提示可以提高模型性能。", "conclusion": "研究提供了一种评价和改进大型语言模型幽默理解能力的原则依据。"}}
{"id": "2512.21476", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.21476", "abs": "https://arxiv.org/abs/2512.21476", "authors": ["Suncheng Xiang", "Xiaoyang Wang", "Junjie Jiang", "Hejia Wang", "Dahong Qian"], "title": "GPF-Net: Gated Progressive Fusion Learning for Polyp Re-Identification", "comment": "Work in progress", "summary": "Colonoscopic Polyp Re-Identification aims to match the same polyp from a large gallery with images from different views taken using different cameras, which plays an important role in the prevention and treatment of colorectal cancer in computer-aided diagnosis. However, the coarse resolution of high-level features of a specific polyp often leads to inferior results for small objects where detailed information is important. To address this challenge, we propose a novel architecture, named Gated Progressive Fusion network, to selectively fuse features from multiple levels using gates in a fully connected way for polyp ReID. On the basis of it, a gated progressive fusion strategy is introduced to achieve layer-wise refinement of semantic information through multi-level feature interactions. Experiments on standard benchmarks show the benefits of the multimodal setting over state-of-the-art unimodal ReID models, especially when combined with the specialized multimodal fusion strategy.", "AI": {"tldr": "本文提出一种名为Gated Progressive Fusion网络的新架构，用于解决结肠镜息肉再识别挑战，实验显示该方法在高分辨率的小目标识别上优于现有技术。", "motivation": "为了改善结肠镜息肉再识别的效果，特别是在需要详细信息的小目标识别上，研究人员提出了新的解决方案。", "method": "研究中提出了一种新的网络结构（Gated Progressive Fusion网络），通过多层级特征的全连接式融合来提高息肉再识别的准确性。引入了一个分层式的语义信息细化策略，通过多层次特征交互来实现这一目标。", "result": "该研究通过设计一种名为Gated Progressive Fusion网络的新架构，解决了结肠镜息肉再识别中高分辨率特征不足的问题。实验结果表明，这种多模态设置相较于最先进的单模态再识别模型具有优势。", "conclusion": "实验结果表明，结合特定的多模态融合策略，该方法在标准基准上的表现优于现有的单模态再识别模型。"}}
{"id": "2512.21567", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.21567", "abs": "https://arxiv.org/abs/2512.21567", "authors": ["Changzhi Sun", "Xiangyu Chen", "Jixiang Luo", "Dell Zhang", "Xuelong Li"], "title": "Beyond Heuristics: A Decision-Theoretic Framework for Agent Memory Management", "comment": null, "summary": "External memory is a key component of modern large language model (LLM) systems, enabling long-term interaction and personalization. Despite its importance, memory management is still largely driven by hand-designed heuristics, offering little insight into the long-term and uncertain consequences of memory decisions. In practice, choices about what to read or write shape future retrieval and downstream behavior in ways that are difficult to anticipate. We argue that memory management should be viewed as a sequential decision-making problem under uncertainty, where the utility of memory is delayed and dependent on future interactions. To this end, we propose DAM (Decision-theoretic Agent Memory), a decision-theoretic framework that decomposes memory management into immediate information access and hierarchical storage maintenance. Within this architecture, candidate operations are evaluated via value functions and uncertainty estimators, enabling an aggregate policy to arbitrate decisions based on estimated long-term utility and risk. Our contribution is not a new algorithm, but a principled reframing that clarifies the limitations of heuristic approaches and provides a foundation for future research on uncertainty-aware memory systems.", "AI": {"tldr": "提出了DAM框架重新定义记忆管理为在不确定性下的决策问题，通过价值函数和不确定性估计器评估操作，以考虑长期效用和风险。这是一个原理性的重新定义，旨在澄清启发式方法的局限性，并为未来关于不确定性感知的记忆系统的研究打下基础。", "motivation": "记忆管理通常是通过手工设计的启发式方法进行，这提供了很少关于记忆决策长期和不确定后果的见解。作者认为记忆管理应被视为一个在不确定性下的顺序决策问题，记忆的效用是延迟的，并依赖于未来的交互。", "method": "提出了一种名为DAM（决策论代理记忆）的决策理论框架，将记忆管理分解为即时信息访问和分层存储维护。在这个框架中，候选操作通过价值函数和不确定性估计器进行评估，从而允许一个汇总策略根据估计的长期效用和风险来仲裁决策。", "result": "该论文没有具体提及一种新的算法，而是一个关于记忆管理的新视角。这项工作的贡献在于提供了一个关于记忆管理的原理性重新定义，为未来研究指明方向。", "conclusion": "这篇文章提出了一种新的决策论框架，用于理解和操作语言模型中的外存记忆。该框架为理解和解决记忆管理中的不确定性和长期后果提供了基础。它不是一种新的算法，而是一种概念上的重新定义，开创了未来研究的新方向。"}}
