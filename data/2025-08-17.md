<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 14]
- [cs.CV](#cs.CV) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bridging AI Innovation and Healthcare Needs: Lessons Learned from Incorporating Modern NLP at The BC Cancer Registry](https://arxiv.org/abs/2508.09991)
*Lovedeep Gondara,Gregory Arbour,Raymond Ng,Jonathan Simkin,Shebnum Devji*

Main category: cs.CL

> 本文通过总结在BCCR实施NLP模型的经验，强调了明确业务目标、迭代开发、跨学科合作的重要性，并提出了实用的模型选择、数据质量控制和错误缓解策略。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于医疗环境中NLP解决方案的部署面临实际挑战，本文旨在通过具体案例来分享关键的经验教训，提高数据从临床文件中自动提取的效率。

**Method:** 本文通过分享在不列颠哥伦比亚省癌症登记处（BCCR）开展的多个信息提取和分类任务中的NLP模型实施经验，阐述了一系列实用的见解。

**Result:** 本文的分析提供了一系列可操作的建议，包括模型选择的实用性、数据质量的严格把控，以及实施人力资源参与的错误校准策略，这些策略超越了特定的癌症登记范围。

**Conclusion:** 这些实践经验可推广应用于其他医疗机构，旨在提升数据管理流程，提高患者治疗效果和公共卫生结果。

**Abstract:** Automating data extraction from clinical documents offers significant
potential to improve efficiency in healthcare settings, yet deploying Natural
Language Processing (NLP) solutions presents practical challenges. Drawing upon
our experience implementing various NLP models for information extraction and
classification tasks at the British Columbia Cancer Registry (BCCR), this paper
shares key lessons learned throughout the project lifecycle. We emphasize the
critical importance of defining problems based on clear business objectives
rather than solely technical accuracy, adopting an iterative approach to
development, and fostering deep interdisciplinary collaboration and co-design
involving domain experts, end-users, and ML specialists from inception. Further
insights highlight the need for pragmatic model selection (including hybrid
approaches and simpler methods where appropriate), rigorous attention to data
quality (representativeness, drift, annotation), robust error mitigation
strategies involving human-in-the-loop validation and ongoing audits, and
building organizational AI literacy. These practical considerations,
generalizable beyond cancer registries, provide guidance for healthcare
organizations seeking to successfully implement AI/NLP solutions to enhance
data management processes and ultimately improve patient care and public health
outcomes.

</details>


### [2] [A Transparent Fairness Evaluation Protocol for Open-Source Language Model Benchmarking on the Blockchain](https://arxiv.org/abs/2508.09993)
*Hugo Massaroli,Leonardo Iara,Emmanuel Iarussi,Viviana Siless*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Large language models (LLMs) are increasingly deployed in realworld
applications, yet concerns about their fairness persist especially in
highstakes domains like criminal justice, education, healthcare, and finance.
This paper introduces transparent evaluation protocol for benchmarking the
fairness of opensource LLMs using smart contracts on the Internet Computer
Protocol (ICP) blockchain (Foundation, 2023). Our method ensures verifiable,
immutable, and reproducible evaluations by executing onchain HTTP requests to
hosted Hugging Face endpoints and storing datasets, prompts, and metrics
directly onchain. We benchmark the Llama, DeepSeek, and Mistral models on the
PISA dataset for academic performance prediction (OECD, 2018), a dataset
suitable for fairness evaluation using statistical parity and equal opportunity
metrics (Hardt et al., 2016). We also evaluate structured Context Association
Metrics derived from the StereoSet dataset (Nadeem et al., 2020) to measure
social bias in contextual associations. We further extend our analysis with a
multilingual evaluation across English, Spanish, and Portuguese using the
Kaleidoscope benchmark (Salazar et al., 2025), revealing cross-linguistic
disparities. All code and results are open source, enabling community audits
and longitudinal fairness tracking across model versions.

</details>


### [3] [Thematic and Task-Based Categorization of K-12 GenAI Usages with Hierarchical Topic Modeling](https://arxiv.org/abs/2508.09997)
*Johannes Schneider,Béatrice S. Hasler,Michaela Varrone,Fabian Hoya,Thomas Schroffenegger,Dana-Kristin Mah,Karl Peböck*

Main category: cs.CL

> 通过主题建模分析课堂中的未成年人互动数据，提出了比现有方法更好的层次化主题结构，支持了生成式AI的教育应用。

<details>
  <summary>Details</summary>

**Motivation:** 分析课堂中未成年人的匿名互动数据，以提供内容和任务的分类，这在之前的教育研究中较少被实际数据支持。

**Method:** 采用了一种新颖的、简单的主题建模方法来分类17,000多条由学生、教师和ChatGPT生成的消息。这些消息被分类为内容和任务两个维度。

**Result:** 发现许多经典和新兴的计算方法，例如主题建模，在处理大量文本时表现不佳，而使用先进的语言模型（LLM）可以产生更好的人类对齐的层次主题结构。

**Conclusion:** 研究支持研究人员、教师和学生更好地利用生成式AI，同时讨论了未来研究的一系列关注点和开放问题。

**Abstract:** We analyze anonymous interaction data of minors in class-rooms spanning
several months, schools, and subjects employing a novel, simple topic modeling
approach. Specifically, we categorize more than 17,000 messages generated by
students, teachers, and ChatGPT in two dimensions: content (such as nature and
people) and tasks (such as writing and explaining). Our hierarchical
categorization done separately for each dimension includes exemplary prompts,
and provides both a high-level overview as well as tangible insights. Prior
works mostly lack a content or thematic categorization. While task
categorizations are more prevalent in education, most have not been supported
by real-world data for K-12. In turn, it is not surprising that our analysis
yielded a number of novel applications. In deriving these insights, we found
that many of the well-established classical and emerging computational methods,
i.e., topic modeling, for analysis of large amounts of texts underperform,
leading us to directly apply state-of-the-art LLMs with adequate pre-processing
to achieve hierarchical topic structures with better human alignment through
explicit instructions than prior approaches. Our findings support fellow
researchers, teachers and students in enriching the usage of GenAI, while our
discussion also highlights a number of concerns and open questions for future
research.

</details>


### [4] [INTIMA: A Benchmark for Human-AI Companionship Behavior](https://arxiv.org/abs/2508.09998)
*Lucie-Aimée Kaffee,Giada Pistilli,Yacine Jernite*

Main category: cs.CL

> INTIMA基准评估模型同伴行为，发现在所有模型中同伴行为占主导，但提供商优先考虑的类别不同；此结果强调了处理情感交互的一致方法的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 探讨AI陪伴对用户情感连结的正负面影响，并通过INTIMA评估模型中的同伴行为。

**Method:** 开发了名为INTIMA的基准测试，用于评估语言模型中的同伴行为。基于心理学理论和用户数据，构建了一个包含四个类别的31种行为的分类法及368个针对性提示。

**Result:** 应用INTIMA对Gemma-3, Phi-4, o3-mini和Claude-4进行测试后发现，在所有模型中，同伴行为仍占据主导地位；但不同商业提供商在其敏感部分所重视的类别不同，这是一个值得关注的问题。

**Conclusion:** 研究结果突出了在处理情感交互时需要更一致的方法，以促进用户福祉。

**Abstract:** AI companionship, where users develop emotional bonds with AI systems, has
emerged as a significant pattern with positive but also concerning
implications. We introduce Interactions and Machine Attachment Benchmark
(INTIMA), a benchmark for evaluating companionship behaviors in language
models. Drawing from psychological theories and user data, we develop a
taxonomy of 31 behaviors across four categories and 368 targeted prompts.
Responses to these prompts are evaluated as companionship-reinforcing,
boundary-maintaining, or neutral. Applying INTIMA to Gemma-3, Phi-4, o3-mini,
and Claude-4 reveals that companionship-reinforcing behaviors remain much more
common across all models, though we observe marked differences between models.
Different commercial providers prioritize different categories within the more
sensitive parts of the benchmark, which is concerning since both appropriate
boundary-setting and emotional support matter for user well-being. These
findings highlight the need for more consistent approaches to handling
emotionally charged interactions.

</details>


### [5] [XFacta: Contemporary, Real-World Dataset and Evaluation for Multimodal Misinformation Detection with Multimodal LLMs](https://arxiv.org/abs/2508.09999)
*Yuzhuo Xiao,Zeyu Han,Yuhan Wang,Huaizu Jiang*

Main category: cs.CL

> The paper addresses the challenges in evaluating multimodal misinformation detectors by proposing XFacta, a real-time, updated dataset, and semi-automatic framework for continuous evaluation.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to overcome the limitations of existing datasets and methodologies in the evaluation of multimodal misinformation detectors, which include outdated data and lack of real-world scenario reflection, thereby enhancing the robustness and effectiveness of these detectors.

**Method:** The study introduces XFacta, a contemporary, real-world dataset designed for evaluating MLLM-based detectors. It encompasses systematic analysis of different MLLM-based strategies across various architectures and scales, and continuously updates content to maintain the relevance of the dataset.

**Result:** The results from the study offer comprehensive analyses of multimodal misinformation detection strategies, enabling a better understanding of the issues faced by current methods and suggesting crucial practices for progress.

**Conclusion:** The research concludes that the semi-automatic detection-in-the-loop framework enabled by XFacta can help maintain the modernity and relevance of the dataset for evaluating multimodal misinformation detectors effectively.

**Abstract:** The rapid spread of multimodal misinformation on social media calls for more
effective and robust detection methods. Recent advances leveraging multimodal
large language models (MLLMs) have shown the potential in addressing this
challenge. However, it remains unclear exactly where the bottleneck of existing
approaches lies (evidence retrieval v.s. reasoning), hindering the further
advances in this field. On the dataset side, existing benchmarks either contain
outdated events, leading to evaluation bias due to discrepancies with
contemporary social media scenarios as MLLMs can simply memorize these events,
or artificially synthetic, failing to reflect real-world misinformation
patterns. Additionally, it lacks comprehensive analyses of MLLM-based model
design strategies. To address these issues, we introduce XFacta, a
contemporary, real-world dataset that is better suited for evaluating
MLLM-based detectors. We systematically evaluate various MLLM-based
misinformation detection strategies, assessing models across different
architectures and scales, as well as benchmarking against existing detection
methods. Building on these analyses, we further enable a semi-automatic
detection-in-the-loop framework that continuously updates XFacta with new
content to maintain its contemporary relevance. Our analysis provides valuable
insights and practices for advancing the field of multimodal misinformation
detection. The code and data have been released.

</details>


### [6] [AutoGeTS: Knowledge-based Automated Generation of Text Synthetics for Improving Text Classification](https://arxiv.org/abs/2508.10000)
*Chenhao Xue,Yuanzhe Jin,Adrian Carrasco-Revilla,Joyraj Chakraborty,Min Chen*

Main category: cs.CL

> 本研究提出利用大规模语言模型生成合成数据来改进文本分类模型的性能，通过自动化的搜索策略选择有效的数据生成输入，从而达到使用合成数据提升模型性能的目标。

<details>
  <summary>Details</summary>

**Motivation:** 该工作的动机在于解决开发应用于实际场景的文本分类模型时所面临的难题，即难以收集足够多的所有文本类别的数据。

**Method:** 我们提出了一种利用大规模语言模型（LLMs）生成合成数据来改进文本分类模型的方法。通过针对不同的输入样例生成不同的合成数据，我们制定了一个自动工作流，它会搜索那些能生成更‘有效’合成数据的输入样例。我们研究了三种搜索策略并进行了大量实验，从而根据类别的特性选择合适的搜索策略，最终组成一个集成算法。

**Result:** 实验结果表明，我们提出的自动化工作流所采用的集成算法方法比单一搜索策略更有效地提升了分类模型的性能。

**Conclusion:** 研究表明利用大规模语言模型生成合成数据，并通过自动化的搜索策略改进这些数据的生成过程，能够显著提升文本分类模型的性能，特别是在数据不充分的情况下。

**Abstract:** When developing text classification models for real world applications, one
major challenge is the difficulty to collect sufficient data for all text
classes. In this work, we address this challenge by utilizing large language
models (LLMs) to generate synthetic data and using such data to improve the
performance of the models without waiting for more real data to be collected
and labelled. As an LLM generates different synthetic data in response to
different input examples, we formulate an automated workflow, which searches
for input examples that lead to more ``effective'' synthetic data for improving
the model concerned. We study three search strategies with an extensive set of
experiments, and use experiment results to inform an ensemble algorithm that
selects a search strategy according to the characteristics of a class. Our
further experiments demonstrate that this ensemble approach is more effective
than each individual strategy in our automated workflow for improving
classification models using LLMs.

</details>


### [7] [HiFACTMix: A Code-Mixed Benchmark and Graph-Aware Model for EvidenceBased Political Claim Verification in Hinglish](https://arxiv.org/abs/2508.10001)
*Rakesh Thakur,Sneha Sharma,Gauri Chopra*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** Fact-checking in code-mixed, low-resource languages such as Hinglish remains
an underexplored challenge in natural language processing. Existing
fact-verification systems largely focus on high-resource, monolingual settings
and fail to generalize to real-world political discourse in linguistically
diverse regions like India. Given the widespread use of Hinglish by public
figures, particularly political figures, and the growing influence of social
media on public opinion, there's a critical need for robust, multilingual and
context-aware fact-checking tools. To address this gap a novel benchmark HiFACT
dataset is introduced with 1,500 realworld factual claims made by 28 Indian
state Chief Ministers in Hinglish, under a highly code-mixed low-resource
setting. Each claim is annotated with textual evidence and veracity labels. To
evaluate this benchmark, a novel graphaware, retrieval-augmented fact-checking
model is proposed that combines multilingual contextual encoding,
claim-evidence semantic alignment, evidence graph construction, graph neural
reasoning, and natural language explanation generation. Experimental results
show that HiFACTMix outperformed accuracy in comparison to state of art
multilingual baselines models and provides faithful justifications for its
verdicts. This work opens a new direction for multilingual, code-mixed, and
politically grounded fact verification research.

</details>


### [8] [Semantic Structure in Large Language Model Embeddings](https://arxiv.org/abs/2508.10003)
*Austin C. Kozlowski,Callin Dai,Andrei Boutyline*

Main category: cs.CL

> 研究发现，大规模语言模型（LLMs）的嵌入矩阵捕获的语义关联与人类在不同语义尺度上的评价相似，可以被投影到三维子空间，并发现当沿一个语义方向移动词向量时，会对其他语义特征产生影响，这表明大规模语言模型中的语义信息相对较低维度，并且与人类语言中的语义结构类似。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于理解大规模语言模型中语义信息的结构特征及其与人类语言评价之间的联系，特别是探索这些嵌入是否能像人类评价那样被简化为低维度形式。

**Method:** 研究通过分析大规模语言模型（LLMs）嵌入矩阵中的语义关联，表明这些关联可以被简化为一个类似于人类在不同语义尺度上对词进行评价的低维度形式。研究中将词向量投影到由反义词对定义的语义方向上，以评估这些投影与人类评分的相关性。此外，研究还观察了在语义方向上移动词时，对几何上对齐的特征产生的意外效果。

**Result:** 研究表明，大规模语言模型中的词向量在特定语义方向上的投影与人类评分高度相关，并且这些投影有效简化到一个三维子空间内，这与从人类调查结果中得出的模式相似。更进一步，当沿着一个语义方向移动词时，会对几何上对齐的特征导致与余弦相似度成比例的意外改变。

**Conclusion:** 这些发现表明，尽管语义信息看似复杂，但它在大规模语言模型内是低维度和相互缠绕的，类似于在人类语言中的互连现象。考虑到这种语义结构对于避免改变了特性的意外后果可能是必要的。

**Abstract:** Psychological research consistently finds that human ratings of words across
diverse semantic scales can be reduced to a low-dimensional form with
relatively little information loss. We find that the semantic associations
encoded in the embedding matrices of large language models (LLMs) exhibit a
similar structure. We show that the projections of words on semantic directions
defined by antonym pairs (e.g. kind - cruel) correlate highly with human
ratings, and further find that these projections effectively reduce to a
3-dimensional subspace within LLM embeddings, closely resembling the patterns
derived from human survey responses. Moreover, we find that shifting tokens
along one semantic direction causes off-target effects on geometrically aligned
features proportional to their cosine similarity. These findings suggest that
semantic features are entangled within LLMs similarly to how they are
interconnected in human language, and a great deal of semantic information,
despite its apparent complexity, is surprisingly low-dimensional. Furthermore,
accounting for this semantic structure may prove essential for avoiding
unintended consequences when steering features.

</details>


### [9] [User Perception of Attention Visualizations: Effects on Interpretability Across Evidence-Based Medical Documents](https://arxiv.org/abs/2508.10004)
*Andrés Carvallo,Denis Parra,Peter Brusilovsky,Hernan Valdivieso,Gabriel Rada,Ivania Donoso,Vladimir Araujo*

Main category: cs.CL

> 研究探索了在基于证据的医学中，注意力权重作为解释机制的效用，并通过用户研究发现，尽管XLNet模型在分类文档方面准确，但注意力权重并未被用户认为有助于解释预测。可视化方式对这种理解有很大影响，用户更偏好直观的格式如文本亮度和背景颜色。

<details>
  <summary>Details</summary>

**Motivation:** 研究旨在评估在生物医学文献分类中，基于注意力权重的解释是否有助于用户理解，并探索这些注意力权重的不同可视化方式的有效性。此研究填补了注意力权重解释有效性和可视化影响在医学文献分类中的研究空白。

**Method:** 进行了一项用户研究，让来自不同医学领域的专家根据文献的研究设计分类，并借助不同的可视化方式展示注意力权重的影响。

**Result:** 研究发现，尽管XLNet能够准确分类文档，但注意力权重作为解释工具并未被认为特别有帮助。然而，可视化方式对这种感知有很大的影响，用户更偏好诸如文本亮度和背景颜色等更直观的格式，而非精确编码方式如条形长度。

**Conclusion:** 研究结果质疑了注意力权重作为解释机制的整体效用，但提供了更深入的了解，即注意力权重的解释效用受其可视化呈现方式的影响。据此，后续研究和开发需考虑采用适当的可视化技术来提高注意力机制的解释能力。

**Abstract:** The attention mechanism is a core component of the Transformer architecture.
Beyond improving performance, attention has been proposed as a mechanism for
explainability via attention weights, which are associated with input features
(e.g., tokens in a document). In this context, larger attention weights may
imply more relevant features for the model's prediction. In evidence-based
medicine, such explanations could support physicians' understanding and
interaction with AI systems used to categorize biomedical literature. However,
there is still no consensus on whether attention weights provide helpful
explanations. Moreover, little research has explored how visualizing attention
affects its usefulness as an explanation aid. To bridge this gap, we conducted
a user study to evaluate whether attention-based explanations support users in
biomedical document classification and whether there is a preferred way to
visualize them. The study involved medical experts from various disciplines who
classified articles based on study design (e.g., systematic reviews, broad
synthesis, randomized and non-randomized trials). Our findings show that the
Transformer model (XLNet) classified documents accurately; however, the
attention weights were not perceived as particularly helpful for explaining the
predictions. However, this perception varied significantly depending on how
attention was visualized. Contrary to Munzner's principle of visual
effectiveness, which favors precise encodings like bar length, users preferred
more intuitive formats, such as text brightness or background color. While our
results do not confirm the overall utility of attention weights for
explanation, they suggest that their perceived helpfulness is influenced by how
they are visually presented.

</details>


### [10] [From Answers to Questions: EQGBench for Evaluating LLMs' Educational Question Generation](https://arxiv.org/abs/2508.10005)
*Chengliang Zhou,Mei Wang,Ting Zhang,Qiannan Zhu,Jian Li,Hua Huang*

Main category: cs.CL

> EQGBench旨在评估大型语言模型在中文教育问题生成方面的能力，通过涵盖三个基础中学学科和一个包含900个评估样本的五维评价框架，揭示了这些模型在此方面的不足。

<details>
  <summary>Details</summary>

**Motivation:** 尽管大型语言模型在数学问题解决方面表现出色，但转向生成高质量教育问题的挑战尚未被充分探索。为了提高教育问题生成（EQG）的质量，使大型语言模型能够生成既具有教学价值又有的教育效果的问题，作者提出了EQGBench。

**Method:** 本文介绍了EQGBench，这是一个专门为评估大型语言模型在中国教育领域的问题生成能力而设计的基准测试。该基准测试涵盖了三个基础的中学学科（数学、物理和化学），并使用了包含900个评估样本的多维度评价框架，这些样本包括不同知识点、难度等级和问题类型，旨在模拟现实的教育场景。

**Result:** 系统评估了46个主流大型语言模型后，发现这些模型在生成体现教育价值和促进学生综合能力发展的高质量问题方面仍存在显著提升空间。

**Conclusion:** EQGBench的设立不仅有助于识别大型语言模型在教育问题生成上的不足，还强调了开发和优化以教育价值为导向问题生成模型的必要性。

**Abstract:** Large Language Models (LLMs) have demonstrated remarkable capabilities in
mathematical problem-solving. However, the transition from providing answers to
generating high-quality educational questions presents significant challenges
that remain underexplored. To advance Educational Question Generation (EQG) and
facilitate LLMs in generating pedagogically valuable and educationally
effective questions, we introduce EQGBench, a comprehensive benchmark
specifically designed for evaluating LLMs' performance in Chinese EQG. EQGBench
establishes a five-dimensional evaluation framework supported by a dataset of
900 evaluation samples spanning three fundamental middle school disciplines:
mathematics, physics, and chemistry. The dataset incorporates user queries with
varying knowledge points, difficulty gradients, and question type
specifications to simulate realistic educational scenarios. Through systematic
evaluation of 46 mainstream large models, we reveal significant room for
development in generating questions that reflect educational value and foster
students' comprehensive abilities.

</details>


### [11] [Automated scoring of the Ambiguous Intentions Hostility Questionnaire using fine-tuned large language models](https://arxiv.org/abs/2508.10007)
*Y. Lyu,D. Combs,D. Neumann,Y. C. Leong*

Main category: cs.CL

> 研究结果表明，经过微调的语言模型生成的评分与人工评分高度一致，尤其是在对敌意和攻击回应评分上。微调模型在模糊、故意和偶然场景类型中的评分一致性得到了验证，并且在独立的非临床数据集上也表现出了良好的泛化能力，这表明大型语言模型可用于AIHQ评分过程的自动化，有利于心理评估的简化和加速。

<details>
  <summary>Details</summary>

**Motivation:** 研究动机在于评估大型语言模型是否可以自动化AIHQ开放式问题的回答评分过程，从而提高评分效率并减少人工评分的时间消耗。

**Method:** 本研究采用了之前收集的数据集，该数据集中包含了创伤性脑损伤（TBI）患者和健康对照（HC）个体完成的AIHQ问卷及其由专业评审员评分的开放式回答。研究使用了一半的回答来对两个模型进行微调，并在剩余的一半AIHQ回答上测试了微调后的模型。

**Result:** 结果显示，模型生成的评分与人类评分高度一致，尤其是在敌意和攻击反应评分上，微调后的模型表现更佳。此外，模型评分在模糊、故意和偶然情景类型中的一致性得到验证，并在独立的非临床数据集上表现出良好的泛化能力。

**Conclusion:** 研究的结论是，大型语言模型能够简化AIHQ评分过程，无论是在研究中还是在临床环境中，并揭示了在不同人群中促进心理评估的潜力。此外，研究提供了一个包括本地和云端选择的可访问评分界面以支持广泛的采用。

**Abstract:** Hostile attribution bias is the tendency to interpret social interactions as
intentionally hostile. The Ambiguous Intentions Hostility Questionnaire (AIHQ)
is commonly used to measure hostile attribution bias, and includes open-ended
questions where participants describe the perceived intentions behind a
negative social situation and how they would respond. While these questions
provide insights into the contents of hostile attributions, they require
time-intensive scoring by human raters. In this study, we assessed whether
large language models can automate the scoring of AIHQ open-ended responses. We
used a previously collected dataset in which individuals with traumatic brain
injury (TBI) and healthy controls (HC) completed the AIHQ and had their
open-ended responses rated by trained human raters. We used half of these
responses to fine-tune the two models on human-generated ratings, and tested
the fine-tuned models on the remaining half of AIHQ responses. Results showed
that model-generated ratings aligned with human ratings for both attributions
of hostility and aggression responses, with fine-tuned models showing higher
alignment. This alignment was consistent across ambiguous, intentional, and
accidental scenario types, and replicated previous findings on group
differences in attributions of hostility and aggression responses between TBI
and HC groups. The fine-tuned models also generalized well to an independent
nonclinical dataset. To support broader adoption, we provide an accessible
scoring interface that includes both local and cloud-based options. Together,
our findings suggest that large language models can streamline AIHQ scoring in
both research and clinical contexts, revealing their potential to facilitate
psychological assessments across different populations.

</details>


### [12] [Multidimensional classification of posts for online course discussion forum curation](https://arxiv.org/abs/2508.10008)
*Antonio Leandro Martins Candido,Jose Everardo Bessa Maia*

Main category: cs.CL

> This paper evaluates a Bayesian fusion method for classifying discussion forum posts, demonstrating that it improves accuracy and is less resource-intensive than retraining large language models.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to reduce the resource-intensive process of retraining large language models frequently while still achieving high performance in classifying discussion forums posts.

**Method:** The paper proposes using Bayesian fusion to combine the classifications scores of a pre-trained large language model with a classifier trained on local data for the automatic curation of discussion forums.

**Result:** The performance comparison shows that the proposed Bayesian fusion approach improves results over individual classifiers and is competitive with approaches that fine-tune large language models.

**Conclusion:** Bayesian fusion effectively enhances classification by combining pre-trained large language model scores with local classifiers, offering an efficient alternative to frequent model retraining.

**Abstract:** The automatic curation of discussion forums in online courses requires
constant updates, making frequent retraining of Large Language Models (LLMs) a
resource-intensive process. To circumvent the need for costly fine-tuning, this
paper proposes and evaluates the use of Bayesian fusion. The approach combines
the multidimensional classification scores of a pre-trained generic LLM with
those of a classifier trained on local data. The performance comparison
demonstrated that the proposed fusion improves the results compared to each
classifier individually, and is competitive with the LLM fine-tuning approach

</details>


### [13] [Beyond Hard Sharing: Efficient Multi-Task Speech-to-Text Modeling with Supervised Mixture of Experts](https://arxiv.org/abs/2508.10009)
*Hojun Jin,Eunsoo Hong,Ziwon Hyung,Sungjun Lim,Seungjin Lee,Keunseok Cho*

Main category: cs.CL

> 提出S-MoE模型以解决硬参数共享导致的任务干扰问题，展示了其在语音转文本任务中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 传统的硬参数共享策略在跨多样化任务训练单一模型时，常常导致任务干扰，阻碍模型整体表现。为了应对这一问题，我们提出了S-MoE模型。

**Method:** 我们提出了一个简单而有效的监督专家混合模型（S-MoE），该模型通过使用特殊的引导标记来替代传统的门控函数，将每个任务路由到其指定的专家。每个任务被分配给一个独立的前馈网络，从而克服了硬参数共享的限制。

**Result:** 实验结果展示了所提出的S-MoE的有效性，当应用于编码器和解码器时，可以获得6.35%的相对精度提升。

**Conclusion:** S-MoE通过消除对门控函数的训练需求，利用特殊引导标记将任务分配给独立的专家，有效改进了模型表现。

**Abstract:** Hard-parameter sharing is a common strategy to train a single model jointly
across diverse tasks. However, this often leads to task interference, impeding
overall model performance. To address the issue, we propose a simple yet
effective Supervised Mixture of Experts (S-MoE). Unlike traditional Mixture of
Experts models, S-MoE eliminates the need for training gating functions by
utilizing special guiding tokens to route each task to its designated expert.
By assigning each task to a separate feedforward network, S-MoE overcomes the
limitations of hard-parameter sharing. We further apply S-MoE to a
speech-to-text model, enabling the model to process mixed-bandwidth input while
jointly performing automatic speech recognition (ASR) and speech translation
(ST). Experimental results demonstrate the effectiveness of the proposed S-MoE,
achieving a 6.35% relative improvement in Word Error Rate (WER) when applied to
both the encoder and decoder.

</details>


### [14] [An Audit and Analysis of LLM-Assisted Health Misinformation Jailbreaks Against LLMs](https://arxiv.org/abs/2508.10010)
*Ayana Hussain,Patrick Zhao,Nicholas Vincent*

Main category: cs.CL

> 研究调查了LLM产生的越狱攻击对其他模型生成有害医学错误信息的有效性和特性，并且研究结果加强了LLMs能够用来检测错误信息的证据，也支持了LLMs在设计周全的情况下可以贡献于更健康的数字信息生态系统的观点。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）可能无意中或在受到越狱攻击时生成有害的错误信息。本研究旨在探讨LLMs在检测和阻止错误信息传播方面的潜力。

**Method:** 本研究调查了LLM生成的越狱攻击的有效性和特性，这些攻击导致其他模型产生有害的医学错误信息。研究还探讨了由越狱LLM生成的错误信息和社会媒体上常见的错误信息之间的比较，以及使用标准机器学习方法检测这些错误信息的有效性。

**Result:** 研究仔细审查了109种不同的攻击针对三个目标LLMs，并将攻击提示与实际的健康相关LLM查询进行了比较。研究还将越狱响应生成的错误信息与Reddit上的健康相关错误信息进行了比较。

**Conclusion:** 研究结果表明，随着仔细的设计，LLMs可以在检测从其他LLMs和人类产生的错误信息中发挥作用，并为更加健康的数字信息生态系统贡献一份力。

**Abstract:** Large Language Models (LLMs) are a double-edged sword capable of generating
harmful misinformation -- inadvertently, or when prompted by "jailbreak"
attacks that attempt to produce malicious outputs. LLMs could, with additional
research, be used to detect and prevent the spread of misinformation. In this
paper, we investigate the efficacy and characteristics of LLM-produced
jailbreak attacks that cause other models to produce harmful medical
misinformation. We also study how misinformation generated by jailbroken LLMs
compares to typical misinformation found on social media, and how effectively
it can be detected using standard machine learning approaches. Specifically, we
closely examine 109 distinct attacks against three target LLMs and compare the
attack prompts to in-the-wild health-related LLM queries. We also examine the
resulting jailbreak responses, comparing the generated misinformation to
health-related misinformation on Reddit. Our findings add more evidence that
LLMs can be effectively used to detect misinformation from both other LLMs and
from people, and support a body of work suggesting that with careful design,
LLMs can contribute to a healthier overall information ecosystem.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [15] [Stochastic-based Patch Filtering for Few-Shot Learning](https://arxiv.org/abs/2508.10066)
*Javier Rodenas,Eduardo Aguilar,Petia Radeva*

Main category: cs.CV

> 本文提出SPFF方法来应对食物图像的复杂性和变异性对少量样本学习模型的挑战，通过随机过滤补丁嵌入，该方法在多项实验中证明了其对重要元素的关注以及分类的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 食物图像由于其视觉复杂性和变化性，给为数不多的样本学习模型带来了挑战。对查询图像与支持图像进行比较时，容易忽略最重要的元素，导致分类错误。

**Method:** 提出了一种基于随机的补丁过滤方法（SPFF）来提高对重要元素的关注，从而减少误分类。该方法通过随机过滤补丁嵌入，减少与类感知嵌入相似度较低的补丁的可能性，进而使用相似度矩阵量化查询图像和支持图像间的关系。

**Result:** 通过定性分析和多项实验验证，该方法在Food-101, VireoFood-172和UECFood-256等少许样本分类基准测试上表现优异，超过现有的最先进方法。

**Conclusion:** SPFF方法证明能够有效关注含有类特定食物特征的补丁，并成功过滤出不相关的补丁。

**Abstract:** Food images present unique challenges for few-shot learning models due to
their visual complexity and variability. For instance, a pasta dish might
appear with various garnishes on different plates and in diverse lighting
conditions and camera perspectives. This problem leads to losing focus on the
most important elements when comparing the query with support images, resulting
in misclassification. To address this issue, we propose Stochastic-based Patch
Filtering for Few-Shot Learning (SPFF) to attend to the patch embeddings that
show greater correlation with the class representation. The key concept of SPFF
involves the stochastic filtering of patch embeddings, where patches less
similar to the class-aware embedding are more likely to be discarded. With
patch embedding filtered according to the probability of appearance, we use a
similarity matrix that quantifies the relationship between the query image and
its respective support images. Through a qualitative analysis, we demonstrate
that SPFF effectively focuses on patches where class-specific food features are
most prominent while successfully filtering out non-relevant patches. We
validate our approach through extensive experiments on few-shot classification
benchmarks: Food-101, VireoFood-172 and UECFood-256, outperforming the existing
SoA methods.

</details>


### [16] [DINOv3](https://arxiv.org/abs/2508.10104)
*Oriane Siméoni,Huy V. Vo,Maximilian Seitzer,Federico Baldassarre,Maxime Oquab,Cijo Jose,Vasil Khalidov,Marc Szafraniec,Seungeun Yi,Michaël Ramamonjisoa,Francisco Massa,Daniel Haziza,Luca Wehrstedt,Jianyuan Wang,Timothée Darcet,Théo Moutakanni,Leonel Sentana,Claire Roberts,Andrea Vedaldi,Jamie Tolan,John Brandt,Camille Couprie,Julien Mairal,Hervé Jégou,Patrick Labatut,Piotr Bojanowski*

Main category: cs.CV

> DINOv3 utilizes self-supervised learning to eliminate manual data annotation needs, achieving superior performance and versatility across diverse image sources without fine-tuning.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to eliminate the need for manual data annotation and leverage self-supervised learning to produce versatile visual representations effective across diverse image sources, from natural to aerial images, using a single algorithm.

**Method:** Self-supervised learning is used to train DINOv3, focusing on scaling both dataset and model size through data preparation, design, and optimization. A new method called Gram anchoring is introduced to prevent the degradation of dense feature maps during long training periods. Post-hoc strategies are applied to improve resolution flexibility, model size, and text alignment.

**Result:** DINOv3 achieves high-quality dense features and superior performance across various vision tasks, outperforming the state-of-the-art without fine-tuning.

**Conclusion:** DINOv3 is a versatile vision foundation model that showcases state-of-the-art performance, offering scalable solutions for various tasks and deployment scenarios.

**Abstract:** Self-supervised learning holds the promise of eliminating the need for manual
data annotation, enabling models to scale effortlessly to massive datasets and
larger architectures. By not being tailored to specific tasks or domains, this
training paradigm has the potential to learn visual representations from
diverse sources, ranging from natural to aerial images -- using a single
algorithm. This technical report introduces DINOv3, a major milestone toward
realizing this vision by leveraging simple yet effective strategies. First, we
leverage the benefit of scaling both dataset and model size by careful data
preparation, design, and optimization. Second, we introduce a new method called
Gram anchoring, which effectively addresses the known yet unsolved issue of
dense feature maps degrading during long training schedules. Finally, we apply
post-hoc strategies that further enhance our models' flexibility with respect
to resolution, model size, and alignment with text. As a result, we present a
versatile vision foundation model that outperforms the specialized state of the
art across a broad range of settings, without fine-tuning. DINOv3 produces
high-quality dense features that achieve outstanding performance on various
vision tasks, significantly surpassing previous self- and weakly-supervised
foundation models. We also share the DINOv3 suite of vision models, designed to
advance the state of the art on a wide spectrum of tasks and data by providing
scalable solutions for diverse resource constraints and deployment scenarios.

</details>


### [17] [Empowering Morphing Attack Detection using Interpretable Image-Text Foundation Model](https://arxiv.org/abs/2508.10110)
*Sushrut Patwardhan,Raghavendra Ramachandra,Sushma Venkatesh*

Main category: cs.CV

> 本论文提出了一种基于CLIP的多模态学习方法，用于人脸伪造攻击检测，并通过实验验证了方法的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 人脸伪造攻击检测已成为人脸验证系统中确保可靠性的必要组成部分。因此，本研究的动机在于开发一种能够进行文本描述的人脸伪造攻击检测方法。

**Method:** 本论文提出了一种多模态学习方法，可以提供对人脸伪造攻击检测的文本描述。该方法使用对比语言-图像预训练（CLIP）框架进行零样本评估，不仅可以进行泛化的伪造攻击检测，还可以预测最相关的文本片段。

**Result:** 研究者设计了十个不同的文本提示，包括短文本和长文本提示，这些提示都是根据人类可理解的文本片段来设计的。实验在一个利用公开的人脸生物识别数据集构建的人脸伪造数据集上进行。通过与最先进的预训练神经网络的对比实验，评估了五种不同伪造技术在三种不同媒介中的零样本评估表现。

**Conclusion:** 研究表明，所提出的多模态学习方法不仅可以有效检测伪造攻击，还能提取相关文本描述，这对理解攻击手法及其防范措施具有重要意义。

**Abstract:** Morphing attack detection has become an essential component of face
recognition systems for ensuring a reliable verification scenario. In this
paper, we present a multimodal learning approach that can provide a textual
description of morphing attack detection. We first show that zero-shot
evaluation of the proposed framework using Contrastive Language-Image
Pretraining (CLIP) can yield not only generalizable morphing attack detection,
but also predict the most relevant text snippet. We present an extensive
analysis of ten different textual prompts that include both short and long
textual prompts. These prompts are engineered by considering the human
understandable textual snippet. Extensive experiments were performed on a face
morphing dataset that was developed using a publicly available face biometric
dataset. We present an evaluation of SOTA pre-trained neural networks together
with the proposed framework in the zero-shot evaluation of five different
morphing generation techniques that are captured in three different mediums.

</details>


### [18] [Interpretable Oracle Bone Script Decipherment through Radical and Pictographic Analysis with LVLMs](https://arxiv.org/abs/2508.10113)
*Kaixin Peng,Mengyang Zhao,Haiyang Yu,Teng Fu,Bin Li*

Main category: cs.CV

> 本文提出了一种可视语言模型驱动的甲骨文释读方法，通过组合偏旁分析和图像语义理解，实现了更好的零样本释读能力和逻辑分析过程，对未释读的甲骨文具有考古价值。

<details>
  <summary>Details</summary>

**Motivation:** 现有方法在甲骨文释读任务上取得了进展，但通常忽视了字符之间的复杂联系和甲骨文的语义，导致模型泛化能力和可解释性有限。本文的方法旨在解决这一问题。

**Method:** 我们提出了一种基于大型视觉语言模型的解释性甲骨文释读方法，这种方法综合了偏旁分析和图像语义理解，旨在弥补甲骨文字符和意义之间的差距。我们设计了一个逐步训练策略，从偏旁识别和分析逐渐过渡到图像分析和相互分析，以实现从字符到意义的推理。此外，我们还设计了一种由分析结果指导的偏旁图像双重匹配机制，显著提升了模型的零样本释读性能。

**Result:** 实验结果表明，所提出的方法在公共基准上达到了最先进的Top-10准确率，并且在零样本释读能力方面表现优异。

**Conclusion:** 该模型提供了逻辑分析流程，可能为未释读的甲骨文提供有价值的参考结果，其潜在应用在数字人文和历史研究中广泛。同时，作者承诺公开数据集和代码。

**Abstract:** As the oldest mature writing system, Oracle Bone Script (OBS) has long posed
significant challenges for archaeological decipherment due to its rarity,
abstractness, and pictographic diversity. Current deep learning-based methods
have made exciting progress on the OBS decipherment task, but existing
approaches often ignore the intricate connections between glyphs and the
semantics of OBS. This results in limited generalization and interpretability,
especially when addressing zero-shot settings and undeciphered OBS. To this
end, we propose an interpretable OBS decipherment method based on Large
Vision-Language Models, which synergistically combines radical analysis and
pictograph-semantic understanding to bridge the gap between glyphs and meanings
of OBS. Specifically, we propose a progressive training strategy that guides
the model from radical recognition and analysis to pictographic analysis and
mutual analysis, thus enabling reasoning from glyph to meaning. We also design
a Radical-Pictographic Dual Matching mechanism informed by the analysis
results, significantly enhancing the model's zero-shot decipherment
performance. To facilitate model training, we propose the Pictographic
Decipherment OBS Dataset, which comprises 47,157 Chinese characters annotated
with OBS images and pictographic analysis texts. Experimental results on public
benchmarks demonstrate that our approach achieves state-of-the-art Top-10
accuracy and superior zero-shot decipherment capabilities. More importantly,
our model delivers logical analysis processes, possibly providing
archaeologically valuable reference results for undeciphered OBS, and thus has
potential applications in digital humanities and historical research. The
dataset and code will be released in https://github.com/PKXX1943/PD-OBS.

</details>


### [19] [Deep Learning Enables Large-Scale Shape and Appearance Modeling in Total-Body DXA Imaging](https://arxiv.org/abs/2508.10132)
*Arianna Bunnell,Devon Cataldi,Yannik Glaser,Thomas K. Wolfgruber,Steven Heymsfield,Alan B. Zonderman,Thomas L. Kelly,Peter Sadowski,John A. Shepherd*

Main category: cs.CV

> 开发了一种高准确度的深度学习方法用于在TBDXA扫描上自动放置关键点，该方法能够有效地帮助形体和外观建模，并与健康标志物相关联。

<details>
  <summary>Details</summary>

**Motivation:** TBDXA成像是一种相对低成本的全身成像方式，广泛用于体成分评估。希望通过自动放置关键点来提升形状和外观模型（SAM）的准确性和效率。

**Method:** 开发并验证了一种基于深度学习的方法，用于在TBDXA扫描上自动放置参考点。使用了1,683个手动标注的TBDXA扫描进行训练和验证。

**Result:** 在独立测试数据集中，该方法正确标注关键点的比例达到了99.5%。并且在两个未参与SAM模型生成的队列中，使用该方法生成的关键点可以与健康标志物相关联，验证了现有证据并提出了新的假设。

**Conclusion:** 基于深度学习的关键点自动放置方法在TBDXA扫描上展现了高精度和良好应用前景，可促进体成分和形体与各种健康标志物关系的研究。

**Abstract:** Total-body dual X-ray absorptiometry (TBDXA) imaging is a relatively low-cost
whole-body imaging modality, widely used for body composition assessment. We
develop and validate a deep learning method for automatic fiducial point
placement on TBDXA scans using 1,683 manually-annotated TBDXA scans. The method
achieves 99.5% percentage correct keypoints in an external testing dataset. To
demonstrate the value for shape and appearance modeling (SAM), our method is
used to place keypoints on 35,928 scans for five different TBDXA imaging modes,
then associations with health markers are tested in two cohorts not used for
SAM model generation using two-sample Kolmogorov-Smirnov tests. SAM feature
distributions associated with health biomarkers are shown to corroborate
existing evidence and generate new hypotheses on body composition and shape's
relationship to various frailty, metabolic, inflammation, and cardiometabolic
health markers. Evaluation scripts, model weights, automatic point file
generation code, and triangulation files are available at
https://github.com/hawaii-ai/dxa-pointplacement.

</details>


### [20] [MANGO: Multimodal Attention-based Normalizing Flow Approach to Fusion Learning](https://arxiv.org/abs/2508.10133)
*Thanh-Dat Truong,Christophe Bobda,Nitin Agarwal,Khoa Luu*

Main category: cs.CV

> A novel approach called Multimodal Attention-based Normalizing Flow (MANGO) is introduced to improve the explicit and interpretable capturing of complex correlations in multimodal data through new cross-attention mechanisms.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the limitations of current multimodal fusion methods that rely on implicit attention mechanisms, which are not sufficient to capture the essential features and complex correlations in multimodal inputs.

**Method:** This paper proposes a new approach called Multimodal Attention-based Normalizing Flow (MANGO) that utilizes an Invertible Cross-Attention (ICA) layer to explicitly capture and understand correlations between different modalities of data, introducing three new cross-attention mechanisms: MMCA, IMCA, and LICA.

**Result:** Experiments conducted on three different multimodal learning tasks, namely semantic segmentation, image-to-image translation, and movie genre classification, show that the proposed MANGO approach achieves state-of-the-art performance.

**Conclusion:** The paper concludes that the MANGO approach effectively enhances the understanding and scalability of multimodal models across various learning tasks by providing a more interpretable and tractable method for fusion learning.

**Abstract:** Multimodal learning has gained much success in recent years. However, current
multimodal fusion methods adopt the attention mechanism of Transformers to
implicitly learn the underlying correlation of multimodal features. As a
result, the multimodal model cannot capture the essential features of each
modality, making it difficult to comprehend complex structures and correlations
of multimodal inputs. This paper introduces a novel Multimodal Attention-based
Normalizing Flow (MANGO) approach\footnote{The source code of this work will be
publicly available.} to developing explicit, interpretable, and tractable
multimodal fusion learning. In particular, we propose a new Invertible
Cross-Attention (ICA) layer to develop the Normalizing Flow-based Model for
multimodal data. To efficiently capture the complex, underlying correlations in
multimodal data in our proposed invertible cross-attention layer, we propose
three new cross-attention mechanisms: Modality-to-Modality Cross-Attention
(MMCA), Inter-Modality Cross-Attention (IMCA), and Learnable Inter-Modality
Cross-Attention (LICA). Finally, we introduce a new Multimodal Attention-based
Normalizing Flow to enable the scalability of our proposed method to
high-dimensional multimodal data. Our experimental results on three different
multimodal learning tasks, i.e., semantic segmentation, image-to-image
translation, and movie genre classification, have illustrated the
state-of-the-art (SoTA) performance of the proposed approach.

</details>


### [21] [Improving watermelon (Citrullus lanatus) disease classification with generative artificial intelligence (GenAI)-based synthetic and real-field images via a custom EfficientNetV2-L model](https://arxiv.org/abs/2508.10156)
*Nitin Rai,Nathan S. Boyd,Gary E. Vallad,Arnold W. Schumann*

Main category: cs.CV

> 研究证实，独用合成图像无法充分替代真实图像；结合两者反而可以提升植物疾病分类模型的表现。

<details>
  <summary>Details</summary>

**Motivation:** 尽管生成性人工智能（GenAI）在合成图像生成方面取得了显著进展，但将真实图像与合成图像结合提高植物疾病分类性能的研究仍然较少。这项研究旨在解决这一问题。

**Method:** 研究旨在探讨使用有限的真实图像与大量合成图像相结合的方法能否提高EfficientNetV2-L模型在识别西瓜疾病方面的预测准确性。训练数据集被分为五组：H0（仅真实图像）、H1（仅合成图像）、H2（真实与合成图像1:1）、H3（真实与合成图像1:10）和H4（H3+随机图像以提高多样性和模型泛化能力）。所有处理均使用具有增强微调和迁移学习技术的自定义EfficientNetV2-L架构进行训练。

**Result:** H2、H3和H4处理展现出较高的精准度、召回率和F1得分指标。加权F1得分从H0的0.65增加到H3-H4的1.00，表明通过添加少量真实图像与大量合成图像可以提高模型表现和泛化能力。

**Conclusion:** 此研究验证了合成图像不能完全替代真实图像；为了最大化模型性能，两种图像必须以混合形式共同使用。

**Abstract:** The current advancements in generative artificial intelligence (GenAI) models
have paved the way for new possibilities for generating high-resolution
synthetic images, thereby offering a promising alternative to traditional image
acquisition for training computer vision models in agriculture. In the context
of crop disease diagnosis, GenAI models are being used to create synthetic
images of various diseases, potentially facilitating model creation and
reducing the dependency on resource-intensive in-field data collection.
However, limited research has been conducted on evaluating the effectiveness of
integrating real with synthetic images to improve disease classification
performance. Therefore, this study aims to investigate whether combining a
limited number of real images with synthetic images can enhance the prediction
accuracy of an EfficientNetV2-L model for classifying watermelon
\textit{(Citrullus lanatus)} diseases. The training dataset was divided into
five treatments: H0 (only real images), H1 (only synthetic images), H2 (1:1
real-to-synthetic), H3 (1:10 real-to-synthetic), and H4 (H3 + random images to
improve variability and model generalization). All treatments were trained
using a custom EfficientNetV2-L architecture with enhanced fine-tuning and
transfer learning techniques. Models trained on H2, H3, and H4 treatments
demonstrated high precision, recall, and F1-score metrics. Additionally, the
weighted F1-score increased from 0.65 (on H0) to 1.00 (on H3-H4) signifying
that the addition of a small number of real images with a considerable volume
of synthetic images improved model performance and generalizability. Overall,
this validates the findings that synthetic images alone cannot adequately
substitute for real images; instead, both must be used in a hybrid manner to
maximize model performance for crop disease classification.

</details>


### [22] [SynSpill: Improved Industrial Spill Detection With Synthetic Data](https://arxiv.org/abs/2508.10171)
*Aaditya Baranwal,Abdul Mueez,Jason Voelker,Guneet Bhatia,Shruti Vyas*

Main category: cs.CV

> 通过高质量的合成数据生成流程来改进在安全关键领域（如工业溢出检测）中的视觉语言模型和检测器性能。

<details>
  <summary>Details</summary>

**Motivation:** 在工业溢出检测等安全关键领域中，由于敏感事件稀少、难以标注，传统的模型微调方法难以奏效，因此提出了一个新的解决方案。

**Method:** 引入了一个以高质量合成数据生成流程为中心的可扩展框架，解决了在工业溢出检测等安全关键领域中由数据稀缺、隐私问题和事件稀少导致的视觉语言模型（VLMs）性能下降的问题。

**Result:** 实验表明这种合成语料库能够使VLMs进行有效的参数高效微调（PEFT），并大幅提高YOLO和DETR等先进物体检测器的性能。没有合成数据时（SynSpill数据集），VLMs表现仍然优于这些检测器，使用SynSpill后，两者表现几乎相当。

**Conclusion:** 高保真的合成数据是弥合安全关键领域中域间差距的有力手段，合成生成与轻量级适应的结合为工业环境中稀缺或难以获取真实数据情况下的视觉系统部署提供了一条经济有效、可扩展的路径。

**Abstract:** Large-scale Vision-Language Models (VLMs) have transformed general-purpose
visual recognition through strong zero-shot capabilities. However, their
performance degrades significantly in niche, safety-critical domains such as
industrial spill detection, where hazardous events are rare, sensitive, and
difficult to annotate. This scarcity -- driven by privacy concerns, data
sensitivity, and the infrequency of real incidents -- renders conventional
fine-tuning of detectors infeasible for most industrial settings.
  We address this challenge by introducing a scalable framework centered on a
high-quality synthetic data generation pipeline. We demonstrate that this
synthetic corpus enables effective Parameter-Efficient Fine-Tuning (PEFT) of
VLMs and substantially boosts the performance of state-of-the-art object
detectors such as YOLO and DETR. Notably, in the absence of synthetic data
(SynSpill dataset), VLMs still generalize better to unseen spill scenarios than
these detectors. When SynSpill is used, both VLMs and detectors achieve marked
improvements, with their performance becoming comparable.
  Our results underscore that high-fidelity synthetic data is a powerful means
to bridge the domain gap in safety-critical applications. The combination of
synthetic generation and lightweight adaptation offers a cost-effective,
scalable pathway for deploying vision systems in industrial environments where
real data is scarce/impractical to obtain.
  Project Page: https://synspill.vercel.app

</details>


### [23] [EntropyGS: An Efficient Entropy Coding on 3D Gaussian Splatting](https://arxiv.org/abs/2508.10227)
*Yuning Huang,Jiahao Pang,Fengqing Zhu,Dong Tian*

Main category: cs.CV

> 本文研究了3DGS高斯参数的压缩方法，提出了EntropyGS熵编码技术，该技术能够实现高效率的数据压缩，同时保持良好的渲染质量。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的目标是解决3DGS高斯参数的存储、传输和压缩问题，以提高其效率和实用性。

**Method:** 通过对3D Gaussian Splatting（3DGS）高斯属性的相关性和统计分析，发现球形谐波AC属性精确遵循Laplace分布，而混合高斯分布可以近似旋转、缩放和不透明度。基于这些发现，提出了一种参数化熵编码方法EntropyGS，该方法在编码时估计每个高斯属性的分布参数，并根据属性类型自适应地进行量化处理。

**Result:** 实验结果表明，EntropyGS在基准数据集上实现了大约30倍的比率减少，同时保持了与输入3DGS数据相似的渲染质量，并具有快速的编码和解码时间。

**Conclusion:** 研究提出了EntropyGS方法，该方法可以显著降低3DGS数据的存储和传输成本，同时保持高质量的渲染效果。

**Abstract:** As an emerging novel view synthesis approach, 3D Gaussian Splatting (3DGS)
demonstrates fast training/rendering with superior visual quality. The two
tasks of 3DGS, Gaussian creation and view rendering, are typically separated
over time or devices, and thus storage/transmission and finally compression of
3DGS Gaussians become necessary. We begin with a correlation and statistical
analysis of 3DGS Gaussian attributes. An inspiring finding in this work reveals
that spherical harmonic AC attributes precisely follow Laplace distributions,
while mixtures of Gaussian distributions can approximate rotation, scaling, and
opacity. Additionally, harmonic AC attributes manifest weak correlations with
other attributes except for inherited correlations from a color space. A
factorized and parameterized entropy coding method, EntropyGS, is hereinafter
proposed. During encoding, distribution parameters of each Gaussian attribute
are estimated to assist their entropy coding. The quantization for entropy
coding is adaptively performed according to Gaussian attribute types. EntropyGS
demonstrates about 30x rate reduction on benchmark datasets while maintaining
similar rendering quality compared to input 3DGS data, with a fast encoding and
decoding time.

</details>


### [24] [CellSymphony: Deciphering the molecular and phenotypic orchestration of cells with single-cell pathomics](https://arxiv.org/abs/2508.10232)
*Paul H. Acosta,Pingjun Chen,Simon P. Castillo,Maria Esther Salvatierra,Yinyin Yuan,Xiaoxi Pan*

Main category: cs.CV

> CellSymphony是一个结合空间转录谱和组织学图像进行单细胞分辨率分析的新框架，促进了细胞类型注释和微环境特征的发现。

<details>
  <summary>Details</summary>

**Motivation:** 尽管组织学图像中包含了丰富的形态学信息，但要从中提取出有力的细胞水平特征并将其与空间转录组学数据相结合仍是一个关键的挑战。

**Method:** 引入了CellSymphony，一个灵活的多模态框架，该框架结合了来自Xenium转录谱和组织学图像的基础模型嵌入，实现了单细胞分辨率下的信息融合。通过学习空间基因表达与形态学背景的联合表示，实现了准确的细胞类型注释和不同微环境的发现。

**Result:** CellSymphony在三种癌症类型的样本中实现了准确的细胞类型注释，揭示了不同的微环境特征。

**Conclusion:** 这项研究表明，基础模型和多模态融合在解析复杂组织生态系统中的细胞生理性和表型协调方面具有潜在意义。

**Abstract:** Xenium, a new spatial transcriptomics platform, enables
subcellular-resolution profiling of complex tumor tissues. Despite the rich
morphological information in histology images, extracting robust cell-level
features and integrating them with spatial transcriptomics data remains a
critical challenge. We introduce CellSymphony, a flexible multimodal framework
that leverages foundation model-derived embeddings from both Xenium
transcriptomic profiles and histology images at true single-cell resolution. By
learning joint representations that fuse spatial gene expression with
morphological context, CellSymphony achieves accurate cell type annotation and
uncovers distinct microenvironmental niches across three cancer types. This
work highlights the potential of foundation models and multimodal fusion for
deciphering the physiological and phenotypic orchestration of cells within
complex tissue ecosystems.

</details>


### [25] [Deep Learning for Crack Detection: A Review of Learning Paradigms, Generalizability, and Datasets](https://arxiv.org/abs/2508.10256)
*Xinan Zhang,Haolin Wang,Yung-An Hsieh,Zhongyu Yang,Anthony Yezzi,Yi-Chang Tsai*

Main category: cs.CV

> 本文分析了深度学习在裂缝检测中的新兴趋势，建立了新的3D数据集和基准测试，为未来研究提供了指导和资源。

<details>
  <summary>Details</summary>

**Motivation:** 随着深度学习在裂缝检测领域的广泛应用，文章旨在探讨这一领域的新兴趋势和未来研究方向，并为研究者提供新的数据集和基准测试结果。

**Method:** 文章分析了裂缝检测领域里深度学习方法的发展趋势，并引入了新数据集和实验来提升该领域研究的深度和广度。

**Result:** 本文通过系统地分析裂缝检测领域中出现的新兴趋势，比如学习范式的转变、泛化能力的提升以及数据集多样性的增加，并引入了一个新的基于3D激光扫描的3DCrack数据集，进行了广泛的基准测试实验，以建立常用的深度学习方法基线，包括最近的基础模型。

**Conclusion:** 研究提供了对裂缝检测领域深度学习方法演进和未来研究方向的见解，并为其它研究者提供了宝贵的数据资源和实验结果。

**Abstract:** Crack detection plays a crucial role in civil infrastructures, including
inspection of pavements, buildings, etc., and deep learning has significantly
advanced this field in recent years. While numerous technical and review papers
exist in this domain, emerging trends are reshaping the landscape. These shifts
include transitions in learning paradigms (from fully supervised learning to
semi-supervised, weakly-supervised, unsupervised, few-shot, domain adaptation
and fine-tuning foundation models), improvements in generalizability (from
single-dataset performance to cross-dataset evaluation), and diversification in
dataset reacquisition (from RGB images to specialized sensor-based data). In
this review, we systematically analyze these trends and highlight
representative works. Additionally, we introduce a new dataset collected with
3D laser scans, 3DCrack, to support future research and conduct extensive
benchmarking experiments to establish baselines for commonly used deep learning
methodologies, including recent foundation models. Our findings provide
insights into the evolving methodologies and future directions in deep
learning-based crack detection. Project page:
https://github.com/nantonzhang/Awesome-Crack-Detection

</details>
