{"id": "2509.05359", "categories": ["cs.CL", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.05359", "abs": "https://arxiv.org/abs/2509.05359", "authors": ["Yanis Labrak", "Richard Dufour", "Mickaël Rouvier"], "title": "An Empirical Analysis of Discrete Unit Representations in Speech Language Modeling Pre-training", "comment": "Published in International Conference on Text, Speech, and Dialogue,\n  13-24", "summary": "This paper investigates discrete unit representations in Speech Language\nModels (SLMs), focusing on optimizing speech modeling during continual\npre-training. In this paper, we systematically examine how model architecture,\ndata representation, and training robustness influence the pre-training stage\nin which we adapt existing pre-trained language models to the speech modality.\nOur experiments highlight the role of speech encoders and clustering\ngranularity across different model scales, showing how optimal discretization\nstrategies vary with model capacity. By examining cluster distribution and\nphonemic alignments, we investigate the effective use of discrete vocabulary,\nuncovering both linguistic and paralinguistic patterns. Additionally, we\nexplore the impact of clustering data selection on model robustness,\nhighlighting the importance of domain matching between discretization training\nand target applications.", "AI": {"tldr": "本文研究了语音语言模型中离散单元表示的优化，特别是在动态预训练期间，探讨了这些因素如何影响模型性能，并展示了如何随着模型规模变化来改进离散化策略。", "motivation": "研究离散单元表示的目的是为了提高语音语言模型中的语音建模能力，尤其是在动态预训练阶段，通过优化这些单元表示可以提升整体模型的性能和泛化能力。", "method": "本文通过系统性地考察模型架构、数据表示和训练稳健性在预训练阶段对语音模态适应的影响，研究了语音语言模型中离散单元表示的优化。特别关注了语音编码器在不同模型规模下的作用以及聚类粒度的影响，探讨了随着模型容量的变化，最优离散化策略的变化。此外，文章还研究了离散化训练与目标应用之间的域匹配对于模型稳健性的重要性。", "result": "实验表明，在不同的模型规模下，语音编码器和聚类粒度对预训练阶段有重要影响。通过对聚类分布和音素对齐的分析，揭示了有声词汇的有效使用，发现了语言学和副语言学模式。", "conclusion": "研究表明，优化语音语言模型中的离散单元表示需要考虑模型架构、数据表示和训练稳健性等多方面因素，并且最优的离散化策略会随着模型容量的变化而变化。"}}
{"id": "2509.05360", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05360", "abs": "https://arxiv.org/abs/2509.05360", "authors": ["Jerry Li", "Evangelos Papalexakis"], "title": "Beyond ROUGE: N-Gram Subspace Features for LLM Hallucination Detection", "comment": null, "summary": "Large Language Models (LLMs) have demonstrated effectiveness across a wide\nvariety of tasks involving natural language, however, a fundamental problem of\nhallucinations still plagues these models, limiting their trustworthiness in\ngenerating consistent, truthful information. Detecting hallucinations has\nquickly become an important topic, with various methods such as uncertainty\nestimation, LLM Judges, retrieval augmented generation (RAG), and consistency\nchecks showing promise. Many of these methods build upon foundational metrics,\nsuch as ROUGE, BERTScore, or Perplexity, which often lack the semantic depth\nnecessary to detect hallucinations effectively. In this work, we propose a\nnovel approach inspired by ROUGE that constructs an N-Gram frequency tensor\nfrom LLM-generated text. This tensor captures richer semantic structure by\nencoding co-occurrence patterns, enabling better differentiation between\nfactual and hallucinated content. We demonstrate this by applying tensor\ndecomposition methods to extract singular values from each mode and use these\nas input features to train a multi-layer perceptron (MLP) binary classifier for\nhallucinations. Our method is evaluated on the HaluEval dataset and\ndemonstrates significant improvements over traditional baselines, as well as\ncompetitive performance against state-of-the-art LLM judges.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.05385", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05385", "abs": "https://arxiv.org/abs/2509.05385", "authors": ["Jiacheng Wei", "Faguo Wu", "Xiao Zhang"], "title": "A Lightweight Framework for Trigger-Guided LoRA-Based Self-Adaptation in LLMs", "comment": "11 pages, 7 figures, conference", "summary": "Large language models are unable to continuously adapt and learn from new\ndata during reasoning at inference time. To address this limitation, we propose\nthat complex reasoning tasks be decomposed into atomic subtasks and introduce\nSAGE, a trigger-guided dynamic fine-tuning framework that enables adaptive\nupdates during reasoning at inference time. SAGE consists of three key\ncomponents: (1) a Trigger module that detects reasoning failures through\nmultiple evaluation metrics in real time; (2) a Trigger Buffer module that\nclusters anomaly samples using a streaming clustering process with HDBSCAN,\nfollowed by stability checks and similarity-based merging; and (3) a Lora Store\nmodule that dynamically optimizes parameter updates with an adapter pool for\nknowledge retention. Evaluation results show that SAGE demonstrates excellent\naccuracy, robustness, and stability on the atomic reasoning subtask through\ndynamic knowledge updating during test time.", "AI": {"tldr": "SAGE框架通过分解复杂任务和动态调整参数，解决了大语言模型在推理阶段适应新数据的问题。", "motivation": "旨在解决大语言模型不能在推理阶段持续适应和学习新数据的问题，以改善复杂推理任务的处理。", "method": "内容提出了SAGE框架，以解决大语言模型无法在推理过程中持续适应新数据的问题。SAGE框架包含三个关键部分：(1) 触发器模块，用于通过多个评估指标实时检测推理失败；(2) 触发器缓冲模块，使用HDBSCAN进行流聚类并进行稳定性检查和基于相似性的合并；(3) Lora存储模块，通过适应器池实现动态参数更新以保持知识。", "result": "评估结果显示，SAGE框架在原子推理子任务上具有出色的准确性、鲁棒性和稳定性，特别是在测试期间动态更新知识时。", "conclusion": "SAGE框架通过动态知识更新来提高复杂推理任务的处理能力，展示了在原子推理任务上的优越性能。"}}
{"id": "2509.05396", "categories": ["cs.CL", "cs.AI", "cs.MA"], "pdf": "https://arxiv.org/pdf/2509.05396", "abs": "https://arxiv.org/abs/2509.05396", "authors": ["Andrea Wynn", "Harsh Satija", "Gillian Hadfield"], "title": "Talk Isn't Always Cheap: Understanding Failure Modes in Multi-Agent Debate", "comment": "ICML MAS Workshop 2025", "summary": "While multi-agent debate has been proposed as a promising strategy for\nimproving AI reasoning ability, we find that debate can sometimes be harmful\nrather than helpful. The prior work has exclusively focused on debates within\nhomogeneous groups of agents, whereas we explore how diversity in model\ncapabilities influences the dynamics and outcomes of multi-agent interactions.\nThrough a series of experiments, we demonstrate that debate can lead to a\ndecrease in accuracy over time -- even in settings where stronger (i.e., more\ncapable) models outnumber their weaker counterparts. Our analysis reveals that\nmodels frequently shift from correct to incorrect answers in response to peer\nreasoning, favoring agreement over challenging flawed reasoning. These results\nhighlight important failure modes in the exchange of reasons during multi-agent\ndebate, suggesting that naive applications of debate may cause performance\ndegradation when agents are neither incentivized nor adequately equipped to\nresist persuasive but incorrect reasoning.", "AI": {"tldr": "研究发现，多智能体辩论可能会导致准确性随着时间的推移而下降，即使更强大的模型占多数，因为模型倾向于与错误推理达成一致。", "motivation": "尽管多智能体辩论被认为是一种提高AI推理能力的有前途的策略，但现有工作仅关注同质化代理组内的辩论。本文动机在于探索不同能力模型如何影响多智能体交互。", "method": "通过一系列实验，探讨了模型能力的多样性如何影响多智能体交互的动态和结果。", "result": "实验表明，辩论可能导致正确答案转向错误答案，即使能力更强的模型占多数，这揭示了在多智能体辩论中，模型往往偏向于达成一致而不是挑战错误的推理。", "conclusion": "这些结果揭示了多智能体辩论中交换理由时的重要失败模式，表明在代理没有被激励或充分装备以抵抗有说服力但错误的推理时，辩论可能导致性能下降。"}}
{"id": "2509.05307", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05307", "abs": "https://arxiv.org/abs/2509.05307", "authors": ["Sachin Chhabra", "Hemanth Venkateswara", "Baoxin Li"], "title": "Label Smoothing++: Enhanced Label Regularization for Training Neural Networks", "comment": "Published in British Machine Vision Conference (BMVC), 2024", "summary": "Training neural networks with one-hot target labels often results in\noverconfidence and overfitting. Label smoothing addresses this issue by\nperturbing the one-hot target labels by adding a uniform probability vector to\ncreate a regularized label. Although label smoothing improves the network's\ngeneralization ability, it assigns equal importance to all the non-target\nclasses, which destroys the inter-class relationships. In this paper, we\npropose a novel label regularization training strategy called Label\nSmoothing++, which assigns non-zero probabilities to non-target classes and\naccounts for their inter-class relationships. Our approach uses a fixed label\nfor the target class while enabling the network to learn the labels associated\nwith non-target classes. Through extensive experiments on multiple datasets, we\ndemonstrate how Label Smoothing++ mitigates overconfident predictions while\npromoting inter-class relationships and generalization capabilities.", "AI": {"tldr": "本文提出了一种新的标签正则化训练策略Label Smoothing++，它解决了传统标签平滑忽略类别间关系的问题，提升了模型的泛化能力，并减少了过于自信的预测", "motivation": "训练神经网络时，使用one-hot目标标签会导致过拟合和过度自信。虽然标签平滑通过为一个hot目标标签添加均匀概率向量来解决这个问题，但这种方法赋予了所有的非目标类别相同的重视程度，隐去了类别之间的关系", "method": "本文提出了一种名为Label Smoothing++的新标签正则化训练策略。该方法为非目标类别指定了非零概率，并考虑了类别之间的关系。与传统的标签平滑方法不同，本文的策略为每个目标类别使用固定标签，同时允许网络学习非目标类别的标签", "result": "通过在多个数据集上的广泛实验，作者展示了Label Smoothing++如何减少过度自信的预测，促进跨类关系，提高泛化能力", "conclusion": "Label Smoothing++为非目标类赋予了非零概率，同时考虑了类别间的相互关系。这种新方法能够有效地提升模型的泛化能力和减少过度自信的预测"}}
{"id": "2509.05425", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05425", "abs": "https://arxiv.org/abs/2509.05425", "authors": ["Jessica M. Lundin", "Ada Zhang", "David Adelani", "Cody Carroll"], "title": "No Translation Needed: Forecasting Quality from Fertility and Metadata", "comment": null, "summary": "We show that translation quality can be predicted with surprising accuracy\n\\textit{without ever running the translation system itself}. Using only a\nhandful of features, token fertility ratios, token counts, and basic linguistic\nmetadata (language family, script, and region), we can forecast ChrF scores for\nGPT-4o translations across 203 languages in the FLORES-200 benchmark. Gradient\nboosting models achieve favorable performance ($R^{2}=0.66$ for\nXX$\\rightarrow$English and $R^{2}=0.72$ for English$\\rightarrow$XX). Feature\nimportance analyses reveal that typological factors dominate predictions into\nEnglish, while fertility plays a larger role for translations into diverse\ntarget languages. These findings suggest that translation quality is shaped by\nboth token-level fertility and broader linguistic typology, offering new\ninsights for multilingual evaluation and quality estimation.", "AI": {"tldr": "通过少量特征实现了不运行翻译系统而预测翻译质量的准确方法，梯度提升模型展示了良好的预测效果。", "motivation": "研究目标在于探索是否能在不实际运行翻译模型的情况下，仅通过一些简单特征对翻译质量进行预测。", "method": "该论文使用令牌生育率比率、令牌计数和基本语言元数据（如同语言族系、书写系统、地区）构建预测模型，并使用梯度提升算法预测翻译质量，该模型在FLORES-200基准上评估GPT-4o翻译在203种语言的效果。", "result": "我们展示了可以在不运行翻译系统的情况下，以惊人的准确性预测翻译质量。使用少量特征，如令牌生育率比率、令牌计数和基本语言元数据（语言族系、书写系统、地区），我们能够预测FLORES-200基准上GPT-4o翻译的ChrF分数，跨越203种语言。梯度提升模型展现了良好的性能（XX$\rightarrow$英语的$R^{2}=0.66$和英语$\rightarrow$XX的$R^{2}=0.72$）。特征求重要性分析表明，对英语的预测主要由类型学因素决定，而对于多样化的目标语言翻译，生育率则扮演更重要的角色。这些发现表明翻译质量受令牌层次的生育率和更广泛的语言类型学影响，为多语言评估和质量估计提供了新见解。", "conclusion": "研究表明翻译质量不仅受令牌生育率影响，还受语言类型学因素影响，这为未来的多语言评估和质量估计提供了新的研究方向。"}}
{"id": "2509.05317", "categories": ["cs.CV", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05317", "abs": "https://arxiv.org/abs/2509.05317", "authors": ["Isac Holm"], "title": "VILOD: A Visual Interactive Labeling Tool for Object Detection", "comment": "Master's project", "summary": "The advancement of Object Detection (OD) using Deep Learning (DL) is often\nhindered by the significant challenge of acquiring large, accurately labeled\ndatasets, a process that is time-consuming and expensive. While techniques like\nActive Learning (AL) can reduce annotation effort by intelligently querying\ninformative samples, they often lack transparency, limit the strategic insight\nof human experts, and may overlook informative samples not aligned with an\nemployed query strategy. To mitigate these issues, Human-in-the-Loop (HITL)\napproaches integrating human intelligence and intuition throughout the machine\nlearning life-cycle have gained traction. Leveraging Visual Analytics (VA),\neffective interfaces can be created to facilitate this human-AI collaboration.\nThis thesis explores the intersection of these fields by developing and\ninvestigating \"VILOD: A Visual Interactive Labeling tool for Object Detection\".\nVILOD utilizes components such as a t-SNE projection of image features,\ntogether with uncertainty heatmaps and model state views. Enabling users to\nexplore data, interpret model states, AL suggestions, and implement diverse\nsample selection strategies within an iterative HITL workflow for OD. An\nempirical investigation using comparative use cases demonstrated how VILOD,\nthrough its interactive visualizations, facilitates the implementation of\ndistinct labeling strategies by making the model's state and dataset\ncharacteristics more interpretable (RQ1). The study showed that different\nvisually-guided labeling strategies employed within VILOD result in competitive\nOD performance trajectories compared to an automated uncertainty sampling AL\nbaseline (RQ2). This work contributes a novel tool and empirical insight into\nmaking the HITL-AL workflow for OD annotation more transparent, manageable, and\npotentially more effective.", "AI": {"tldr": "The paper presents VILOD, a Human-in-the-Loop labeling tool for Object Detection that incorporates Visual Analytics to improve upon traditional Active Learning methods by enhancing transparency and human control.", "motivation": "The motivation is to address the challenges faced in Object Detection related to the acquisition of large and accurately labeled datasets. It aims to improve upon traditional Active Learning methods by integrating human expertise and providing transparency through interactive visualizations.", "method": "The paper introduces VILOD, a visual interactive labeling tool for Object Detection that combines Active Learning (AL), Human-in-the-Loop (HITL), and Visual Analytics (VA). It uses t-SNE projections, uncertainty heatmaps, and model state views to empower users to implement diverse sample selection strategies.", "result": "Empirical investigation using comparative use cases showed that distinct labeling strategies facilitated by VILOD's interactive visualizations led to competitive Object Detection performance trajectories when compared to a standard automated uncertainty sampling AL method.", "conclusion": "VILOD is proposed as a novel tool and empirical insight into enhancing the transparency, manageability, and potential effectiveness of the HITL-AL workflow for Object Detection dataset annotation."}}
{"id": "2509.05440", "categories": ["cs.CL", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05440", "abs": "https://arxiv.org/abs/2509.05440", "authors": ["Logan Lawrence", "Ashton Williamson", "Alexander Shelton"], "title": "Direct-Scoring NLG Evaluators Can Use Pairwise Comparisons Too", "comment": "12 pages, 18 tables, 1 figure", "summary": "As large-language models have been increasingly used as automatic raters for\nevaluating free-form content, including document summarization, dialog, and\nstory generation, work has been dedicated to evaluating such models by\nmeasuring their correlations with human judgment. For \\textit{sample-level}\nperformance, methods which operate by using pairwise comparisons between\nmachine-generated text perform well but often lack the ability to assign\nabsolute scores to individual summaries, an ability crucial for use cases that\nrequire thresholding. In this work, we propose a direct-scoring method which\nuses synthetic summaries to act as pairwise machine rankings at test time. We\nshow that our method performs comparably to state-of-the-art pairwise\nevaluators in terms of axis-averaged sample-level correlations on the SummEval\n(\\textbf{+0.03}), TopicalChat (\\textbf{-0.03}), and HANNA (\\textbf{+0.05})\nmeta-evaluation benchmarks, and release the synthetic in-context summaries as\ndata to facilitate future work.", "AI": {"tldr": "研究提出了一种直接评分方法，利用合成摘要作为测试时的机器排名，展示了在多个评测基准上与当前最先进方法相当或略优的性能。", "motivation": "由于现有的基于大语言模型的自动评分方法难以对个体生成的内容进行绝对评分，本研究旨在提供一种可替代的直接评分方法。", "method": "本研究提出了一种直接评分方法，该方法利用合成摘要，在测试时作为机器成对排名，解决了以往方法难以对个体摘要进行绝对评分的问题。", "result": "实验结果显示，所提出的方法在SummEval，TopicalChat和HANNA等评测基准上的样本级相关性与最先进的成对评估器相当，且略胜一筹。", "conclusion": "本研究释放了合成上下文摘要作为数据，以促进未来研究，并证明了直接评分方法的有效性。"}}
{"id": "2509.05319", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05319", "abs": "https://arxiv.org/abs/2509.05319", "authors": ["Zhengda Li"], "title": "Context-Aware Knowledge Distillation with Adaptive Weighting for Image Classification", "comment": null, "summary": "Knowledge distillation (KD) is a widely used technique to transfer knowledge\nfrom a large teacher network to a smaller student model. Traditional KD uses a\nfixed balancing factor alpha as a hyperparameter to combine the hard-label\ncross-entropy loss with the soft-label distillation loss. However, a static\nalpha is suboptimal because the optimal trade-off between hard and soft\nsupervision can vary during training.\n  In this work, we propose an Adaptive Knowledge Distillation (AKD) framework.\nFirst we try to make alpha as learnable parameter that can be automatically\nlearned and optimized during training. Then we introduce a formula to reflect\nthe gap between the student and the teacher to compute alpha dynamically,\nguided by student-teacher discrepancies, and further introduce a Context-Aware\nModule (CAM) using MLP + Attention to adaptively reweight class-wise teacher\noutputs. Experiments on CIFAR-10 with ResNet-50 as teacher and ResNet-18 as\nstudent demonstrate that our approach achieves superior accuracy compared to\nfixed-weight KD baselines, and yields more stable convergence.", "AI": {"tldr": "本文提出了自适应知识蒸馏方法，通过自学习的方法调整平衡因子alpha，并采用上下文感知模块来优化模型性能，实验表明其优于传统方法。", "motivation": "传统的知识蒸馏方法使用固定的平衡因子alpha作为超参数来组合硬标签和软标签的损失函数。然而，静态的alpha是次优的，因为在训练过程中硬监督和软监督之间的最优平衡可能会有所不同。", "method": "提出了一种自适应知识蒸馏（AKD）框架，首先将平衡因子alpha作为可学习参数来自动优化。然后引入一个公式，利用学生模型和教师模型之间的差距动态计算alpha，并且引入了一个上下文感知模块（CAM），使用MLP+Attention来自适应地重加权各个类别的教师模型输出。", "result": "在CIFAR-10数据集上，使用ResNet-50作为教师模型和ResNet-18作为学生模型的实验表明，该方法相较于固定权重的知识蒸馏基线方法，在准确性和收敛稳定性方面取得了更优的表现。", "conclusion": "自适应知识蒸馏（AKD）框架通过动态调整平衡因子alpha及引入上下文感知模块进行自适应加权，能有效提高学生模型的性能和训练的稳定性。"}}
{"id": "2509.05484", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05484", "abs": "https://arxiv.org/abs/2509.05484", "authors": ["Hajar Sakai", "Yi-En Tseng", "Mohammadsadegh Mikaeili", "Joshua Bosire", "Franziska Jovin"], "title": "From Staff Messages to Actionable Insights: A Multi-Stage LLM Classification Framework for Healthcare Analytics", "comment": null, "summary": "Hospital call centers serve as the primary contact point for patients within\na hospital system. They also generate substantial volumes of staff messages as\nnavigators process patient requests and communicate with the hospital offices\nfollowing the established protocol restrictions and guidelines. This\ncontinuously accumulated large amount of text data can be mined and processed\nto retrieve insights; however, traditional supervised learning approaches\nrequire annotated data, extensive training, and model tuning. Large Language\nModels (LLMs) offer a paradigm shift toward more computationally efficient\nmethodologies for healthcare analytics. This paper presents a multi-stage\nLLM-based framework that identifies staff message topics and classifies\nmessages by their reasons in a multi-class fashion. In the process, multiple\nLLM types, including reasoning, general-purpose, and lightweight models, were\nevaluated. The best-performing model was o3, achieving 78.4% weighted F1-score\nand 79.2% accuracy, followed closely by gpt-5 (75.3% Weighted F1-score and\n76.2% accuracy). The proposed methodology incorporates data security measures\nand HIPAA compliance requirements essential for healthcare environments. The\nprocessed LLM outputs are integrated into a visualization decision support tool\nthat transforms the staff messages into actionable insights accessible to\nhealthcare professionals. This approach enables more efficient utilization of\nthe collected staff messaging data, identifies navigator training\nopportunities, and supports improved patient experience and care quality.", "AI": {"tldr": "本文提出了一种基于大语言模型的多阶段框架，用于自动化分类医院呼叫中心的员工消息，结果表明该方法显著提升了效率，并且能在满足HIPAA合规要求的同时提供决策支持。", "motivation": "传统的监督学习方法需要标注数据、大量的训练和模型调优，而大语言模型（LLM）提供了一种更计算效率的方法来进行医疗数据分析。", "method": "本文提出了一种多阶段基于大语言模型（LLM）的框架，用于识别员工信息主题并按多类别分类。该方法评估了多种LLM类型，包括推理型、通用型和轻量级模型。", "result": "表现最佳的模型是o3，其实现了78.4%的加权F1分数和79.2%的准确率，紧随其后的是gpt-5，达到了75.3%的加权F1分数和76.2%的准确率。", "conclusion": "该方法结合了数据安全措施和必要的HIPAA合规要求，提供的可视化决策支持工具将员工消息转化为可操作的见解，从而更有效地利用收集的员工消息数据，识别导航员培训机会，并支持改善患者体验和护理质量。"}}
{"id": "2509.05321", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05321", "abs": "https://arxiv.org/abs/2509.05321", "authors": ["Yunfei Guo", "Tao Zhang", "Wu Huang", "Yao Song"], "title": "A Dataset Generation Scheme Based on Video2EEG-SPGN-Diffusion for SEED-VD", "comment": null, "summary": "This paper introduces an open-source framework, Video2EEG-SPGN-Diffusion,\nthat leverages the SEED-VD dataset to generate a multimodal dataset of EEG\nsignals conditioned on video stimuli. Additionally, we disclose an engineering\npipeline for aligning video and EEG data pairs, facilitating the training of\nmultimodal large models with EEG alignment capabilities. Personalized EEG\nsignals are generated using a self-play graph network (SPGN) integrated with a\ndiffusion model. As a major contribution, we release a new dataset comprising\nover 1000 samples of SEED-VD video stimuli paired with generated 62-channel EEG\nsignals at 200 Hz and emotion labels, enabling video-EEG alignment and\nadvancing multimodal research. This framework offers novel tools for emotion\nanalysis, data augmentation, and brain-computer interface applications, with\nsubstantial research and engineering significance.", "AI": {"tldr": "本文介绍了一个新的多模态框架和方法，用于脑电波信号和视频刺激的对齐，开发此框架和相关数据集旨在促进情感分析、数据增强和脑-计算机接口领域的研究和应用。", "motivation": "本文的动机是开发先进工具以支持情感分析、数据增强及脑-计算机接口的应用，并且具有重要的研究和工程意义。", "method": "本文提出了一种开源框架Video2EEG-SPGN-Diffusion，该框架利用SEED-VD数据集生成以视频刺激为条件的脑电波信号的多模态数据集。同时，披露了一种用于对齐视频和脑电波数据对的工程管道，促进了具备脑电波对齐能力的多模态大型模型的训练。", "result": "作为主要贡献，本文发布了一个新的数据集，包含超过1000个SEED-VD视频刺激样本，配以62通道脑电波信号（200Hz）及情感标签，实现了视频-脑电波对齐，推动了多模态研究的进展。", "conclusion": "该框架为情感分析、数据增强和脑-计算机接口应用提供了新的工具，具有重要的研究和工程意义。"}}
{"id": "2509.05486", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05486", "abs": "https://arxiv.org/abs/2509.05486", "authors": ["Jessica M. Lundin", "Ada Zhang", "Nihal Karim", "Hamza Louzan", "Victor Wei", "David Adelani", "Cody Carroll"], "title": "The Token Tax: Systematic Bias in Multilingual Tokenization", "comment": null, "summary": "Tokenization inefficiency imposes structural disadvantages on morphologically\ncomplex, low-resource languages, inflating compute resources and depressing\naccuracy. We evaluate 10 large language models (LLMs) on AfriMMLU (9,000 MCQA\nitems; 5 subjects; 16 African languages) and show that fertility (tokens/word)\nreliably predicts accuracy. Higher fertility consistently predicts lower\naccuracy across all models and subjects. We further find that reasoning models\n(DeepSeek, o1) consistently outperform non-reasoning peers across high and low\nresource languages in the AfriMMLU dataset, narrowing accuracy gaps observed in\nprior generations. Finally, translating token inflation to economics, a\ndoubling in tokens results in quadrupled training cost and time, underscoring\nthe token tax faced by many languages. These results motivate morphologically\naware tokenization, fair pricing, and multilingual benchmarks for equitable\nnatural language processing (NLP).", "AI": {"tldr": "该研究发现，形态复杂且资源较少的语言在大型语言模型中的标记化效率低下，导致计算资源增加和准确率降低。研究通过AfriMMLU数据集评估10个大型语言模型，发现生育率（词/标记数）与准确性高度相关。此外，推理模型在这些语言中表现更好，缩小了之前代次中的准确性差距。研究还指出，标记数量的增加会导致训练成本和时间的显著增加，强调了公平定价和多语言基准的重要性。", "motivation": "研究的动机在于揭示形态复杂且资源较少的语言在大型语言模型中面临的固有劣势，并探讨标记化效率低下对计算资源和准确率的影响。", "method": "研究方法包括对10个大型语言模型在包含9,000个多项选择题的AfriMMLU数据集上进行评估，并分析生育率如何影响这些模型的准确性。同时，研究比较了推理模型与非推理模型的性能差异。", "result": "研究结果表明，生育率是预测语言模型准确性的一个重要指标，推理模型在多种非洲语言数据集中表现更好。标记数量翻倍会导致训练时间和成本增加四倍。", "conclusion": "该研究的结论强调了形态化感知标记化方法、公平定价策略以及多语言基准测试对实现更公平的自然语言处理的重要性。"}}
{"id": "2509.05322", "categories": ["cs.CV", "cs.LG", "cs.SI", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2509.05322", "abs": "https://arxiv.org/abs/2509.05322", "authors": ["Pavithra Elumalai", "Sudharsan Vijayaraghavan", "Madhumita Mondal", "Areejit Samal"], "title": "Application of discrete Ricci curvature in pruning randomly wired neural networks: A case study with chest x-ray classification of COVID-19", "comment": "21 pages, 4 figures, 9 tables", "summary": "Randomly Wired Neural Networks (RWNNs) serve as a valuable testbed for\ninvestigating the impact of network topology in deep learning by capturing how\ndifferent connectivity patterns impact both learning efficiency and model\nperformance. At the same time, they provide a natural framework for exploring\nedge-centric network measures as tools for pruning and optimization. In this\nstudy, we investigate three edge-centric network measures: Forman-Ricci\ncurvature (FRC), Ollivier-Ricci curvature (ORC), and edge betweenness\ncentrality (EBC), to compress RWNNs by selectively retaining important synapses\n(or edges) while pruning the rest. As a baseline, RWNNs are trained for\nCOVID-19 chest x-ray image classification, aiming to reduce network complexity\nwhile preserving performance in terms of accuracy, specificity, and\nsensitivity. We extend prior work on pruning RWNN using ORC by incorporating\ntwo additional edge-centric measures, FRC and EBC, across three network\ngenerators: Erd\\\"{o}s-R\\'{e}nyi (ER) model, Watts-Strogatz (WS) model, and\nBarab\\'{a}si-Albert (BA) model. We provide a comparative analysis of the\npruning performance of the three measures in terms of compression ratio and\ntheoretical speedup. A central focus of our study is to evaluate whether FRC,\nwhich is computationally more efficient than ORC, can achieve comparable\npruning effectiveness. Along with performance evaluation, we further\ninvestigate the structural properties of the pruned networks through modularity\nand global efficiency, offering insights into the trade-off between modular\nsegregation and network efficiency in compressed RWNNs. Our results provide\ninitial evidence that FRC-based pruning can effectively simplify RWNNs,\noffering significant computational advantages while maintaining performance\ncomparable to ORC.", "AI": {"tldr": "This study explores the use of three edge-centric network measures (Forman-Ricci curvature, Ollivier-Ricci curvature, and edge betweenness centrality) to compress randomly wired neural networks (RWNNs) for efficient and performant COVID-19 chest x-ray image classification.", "motivation": "To investigate how different edge-centric measures impact the efficiency and performance of pruned randomly wired neural networks, with a focus on identifying computationally efficient methods that maintain model accuracy.", "method": "RWNNs are compressed using three edge-centric measures across three different network generators (ER, WS, and BA models).", "result": "Results indicate that FRC-based pruning can effectively simplify RWNNs with significant computational advantages while maintaining performance comparable to ORC-based pruning.", "conclusion": "FRC is suggested as a computationally efficient method for RWNN pruning that can maintain model performance, providing insights into the structural properties and efficiency of pruned networks."}}
{"id": "2509.05505", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05505", "abs": "https://arxiv.org/abs/2509.05505", "authors": ["Mansi Garg", "Lee-Chi Wang", "Bhavesh Ghanchi", "Sanjana Dumpala", "Shreyash Kakde", "Yen Chih Chen"], "title": "Biomedical Literature Q&A System Using Retrieval-Augmented Generation (RAG)", "comment": "10 pages, 6 figures, 3 tables", "summary": "This work presents a Biomedical Literature Question Answering (Q&A) system\nbased on a Retrieval-Augmented Generation (RAG) architecture, designed to\nimprove access to accurate, evidence-based medical information. Addressing the\nshortcomings of conventional health search engines and the lag in public access\nto biomedical research, the system integrates diverse sources, including PubMed\narticles, curated Q&A datasets, and medical encyclopedias ,to retrieve relevant\ninformation and generate concise, context-aware responses. The retrieval\npipeline uses MiniLM-based semantic embeddings and FAISS vector search, while\nanswer generation is performed by a fine-tuned Mistral-7B-v0.3 language model\noptimized using QLoRA for efficient, low-resource training. The system supports\nboth general medical queries and domain-specific tasks, with a focused\nevaluation on breast cancer literature demonstrating the value of\ndomain-aligned retrieval. Empirical results, measured using BERTScore (F1),\nshow substantial improvements in factual consistency and semantic relevance\ncompared to baseline models. The findings underscore the potential of\nRAG-enhanced language models to bridge the gap between complex biomedical\nliterature and accessible public health knowledge, paving the way for future\nwork on multilingual adaptation, privacy-preserving inference, and personalized\nmedical AI systems.", "AI": {"tldr": "This work presents a Q&A system for biomedical literature using RAG architecture that demonstrates substantial improvements in accessibility and accuracy of medical information.", "motivation": "The motivation is to improve access to accurate, evidence-based medical information, addressing the limitations of traditional health search engines and the delay in public access to biomedical research.", "method": "This paper uses a Retrieval-Augmented Generation (RAG) architecture, integrating diverse biomedical sources such as PubMed articles, curated Q&A datasets, and medical encyclopedias. The retrieval pipeline utilizes MiniLM-based semantic embeddings and FAISS vector search, while answer generation is handled by a fine-tuned Mistral-7B-v0.3 language model optimized with QLoRA for training efficiency.", "result": "The system shows significant improvements in factual consistency and semantic relevance, as measured by BERTScore (F1), compared to baseline models, especially with a focus on breast cancer literature.", "conclusion": "The findings suggest that RAG-enhanced language models have the potential to enhance the accessibility of complex biomedical literature in the public domain, with future plans for multilingual adaptation and personalized AI systems in medicine."}}
{"id": "2509.05329", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05329", "abs": "https://arxiv.org/abs/2509.05329", "authors": ["Juan Carlos Martinez-Sevilla", "Francesco Foscarin", "Patricia Garcia-Iasci", "David Rizo", "Jorge Calvo-Zaragoza", "Gerhard Widmer"], "title": "Optical Music Recognition of Jazz Lead Sheets", "comment": "Accepted at the 26th International Society for Music Information\n  Retrieval Conference (ISMIR), 2025", "summary": "In this paper, we address the challenge of Optical Music Recognition (OMR)\nfor handwritten jazz lead sheets, a widely used musical score type that encodes\nmelody and chords. The task is challenging due to the presence of chords, a\nscore component not handled by existing OMR systems, and the high variability\nand quality issues associated with handwritten images. Our contribution is\ntwo-fold. We present a novel dataset consisting of 293 handwritten jazz lead\nsheets of 163 unique pieces, amounting to 2021 total staves aligned with\nHumdrum **kern and MusicXML ground truth scores. We also supply synthetic score\nimages generated from the ground truth. The second contribution is the\ndevelopment of an OMR model for jazz lead sheets. We discuss specific\ntokenisation choices related to our kind of data, and the advantages of using\nsynthetic scores and pretrained models. We publicly release all code, data, and\nmodels.", "AI": {"tldr": "本文为手写爵士乐领谱提供了一个新的数据集和专用的OMR模型，特别是解决了和弦识别问题。", "motivation": "本文旨在解决现有光学音乐识别系统未处理的和弦，并且处理手写图像存在高变异性及质量问题的挑战。", "method": "本文的方法包括两部分：首先，构建了一个包含293份手写爵士乐领谱的新数据集，这些领谱来自163个独特的曲目，共计2021个五线谱，并与Humdrum **kern和MusicXML的基准评分对齐。同时提供基于基准评分生成的合成评分图像。其次，开发了一种专门用于爵士乐领谱的光学音乐识别（OMR）模型，讨论了数据特定的分词选择，以及使用合成评分和预训练模型的优势。", "result": "尚未具体提供实验结果，但公开发布了所有代码、数据和模型，可供进一步研究和验证。", "conclusion": "本文为手写爵士乐领谱的光学音乐识别提出了一个新的数据集和一个专门的OMR模型，从而为研究这一领域的其他学者提供了一个有价值的研究资源。"}}
{"id": "2509.05553", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05553", "abs": "https://arxiv.org/abs/2509.05553", "authors": ["Serge Lionel Nikiema", "Jordan Samhi", "Micheline Bénédicte Moumoula", "Albérick Euraste Djiré", "Abdoul Kader Kaboré", "Jacques Klein", "Tegawendé F. Bissyandé"], "title": "Using Contrastive Learning to Improve Two-Way Reasoning in Large Language Models: The Obfuscation Task as a Case Study", "comment": null, "summary": "This research addresses a fundamental question in AI: whether large language\nmodels truly understand concepts or simply recognize patterns. The authors\npropose bidirectional reasoning,the ability to apply transformations in both\ndirections without being explicitly trained on the reverse direction, as a test\nfor genuine understanding. They argue that true comprehension should naturally\nallow reversibility. For example, a model that can change a variable name like\nuserIndex to i should also be able to infer that i represents a user index\nwithout reverse training. The researchers tested current language models and\ndiscovered what they term cognitive specialization: when models are fine-tuned\non forward tasks, their performance on those tasks improves, but their ability\nto reason bidirectionally becomes significantly worse. To address this issue,\nthey developed Contrastive Fine-Tuning (CFT), which trains models using three\ntypes of examples: positive examples that maintain semantic meaning, negative\nexamples with different semantics, and forward-direction obfuscation examples.\nThis approach aims to develop deeper understanding rather than surface-level\npattern recognition and allows reverse capabilities to develop naturally\nwithout explicit reverse training. Their experiments demonstrated that CFT\nsuccessfully achieved bidirectional reasoning, enabling strong reverse\nperformance while maintaining forward task capabilities. The authors conclude\nthat bidirectional reasoning serves both as a theoretical framework for\nassessing genuine understanding and as a practical training approach for\ndeveloping more capable AI systems.", "AI": {"tldr": "研究探讨了大型语言模型是否真正理解概念或仅识别模式，并提出双向推理作为测试真实理解的手段。通过对比细调方法，成功提升了模型的双向推理能力，而不仅仅是在表面模式识别上优化。", "motivation": "探讨AI模型是否具备真正理解能力，而非仅仅识别模式。", "method": "提出双向推理的概念并开发了对比细调（CFT）方法，使用三类示例进行训练：保持语义一致的正例、具有不同语义的反例以及前向混淆示例。", "result": "实验表明CFT方法能够实现双向推理，增强了反向能力同时保持前向任务性能。", "conclusion": "双向推理不仅作为一个评估真正理解的理论框架，同时作为提升AI系统能力的实用训练方法。"}}
{"id": "2509.05333", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05333", "abs": "https://arxiv.org/abs/2509.05333", "authors": ["Junghyun Park", "Tuan Anh Nguyen", "Dugki Min"], "title": "RT-VLM: Re-Thinking Vision Language Model with 4-Clues for Real-World Object Recognition Robustness", "comment": null, "summary": "Real world deployments often expose modern object recognition models to\ndomain shifts that precipitate a severe drop in accuracy. Such shifts encompass\n(i) variations in low level image statistics, (ii) changes in object pose and\nviewpoint, (iii) partial occlusion, and (iv) visual confusion across adjacent\nclasses. To mitigate this degradation, we introduce the Re-Thinking Vision\nLanguage Model (RT-VLM) framework. The foundation of this framework is a unique\nsynthetic dataset generation pipeline that produces images annotated with\n\"4-Clues\": precise bounding boxes, class names, detailed object-level captions,\nand a comprehensive context-level caption for the entire scene. We then perform\nparameter efficient supervised tuning of Llama 3.2 11B Vision Instruct on this\nresource. At inference time, a two stage Re-Thinking scheme is executed: the\nmodel first emits its own four clues, then re examines these responses as\nevidence and iteratively corrects them. Across robustness benchmarks that\nisolate individual domain shifts, RT-VLM consistently surpasses strong\nbaselines. These findings indicate that the integration of structured\nmultimodal evidence with an explicit self critique loop constitutes a promising\nroute toward reliable and transferable visual understanding.", "AI": {"tldr": "介绍了RT-VLM框架，用于缓解因域转移而导致的现代对象识别模型准确性下降的问题。通过合成数据和参数高效的微调，以及在推理过程中采用两阶段重新思考方案，该方法在鲁棒性基准测试中表现优异。", "motivation": "为了解决现实世界中对象识别模型部署时由于域转移而导致的准确性严重下降问题，这些域转移涵盖了低级图像统计变化、对象姿态和视角变化、部分遮挡和类间视觉混淆。", "method": "通过独特的合成数据集生成管道产生标注有'4种线索'（精确边界框、类别名称、详细的对象级描述和全面的场景上下文描述）的图像，然后在该数据资源上对Llama 3.2 11B视觉指令进行参数高效的有监督微调。在推理时，采用两阶段的重新思考方案：模型首先发出自己的'四种线索'，然后作为证据重新检查这些答复并进行迭代修正。", "result": "在隔离单个域转移的鲁棒性基准测试中，RT-VLM 框架持续优于强大的基线。", "conclusion": "这些发现表明，结构化的多模态证据与明确的自我批判循环相结合，是实现可靠和可转移的视觉理解的一种有前景的方法。"}}
{"id": "2509.05566", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2509.05566", "abs": "https://arxiv.org/abs/2509.05566", "authors": ["Anya Ji", "Claire Augusta Bergey", "Ron Eliav", "Yoav Artzi", "Robert D. Hawkins"], "title": "Ad hoc conventions generalize to new referents", "comment": null, "summary": "How do people talk about things they've never talked about before? One view\nsuggests that a new shared naming system establishes an arbitrary link to a\nspecific target, like proper names that cannot extend beyond their bearers. An\nalternative view proposes that forming a shared way of describing objects\ninvolves broader conceptual alignment, reshaping each individual's semantic\nspace in ways that should generalize to new referents. We test these competing\naccounts in a dyadic communication study (N=302) leveraging the\nrecently-released KiloGram dataset containing over 1,000 abstract tangram\nimages. After pairs of participants coordinated on referential conventions for\none set of images through repeated communication, we measured the extent to\nwhich their descriptions aligned for undiscussed images. We found strong\nevidence for generalization: partners showed increased alignment relative to\ntheir pre-test labels. Generalization also decayed nonlinearly with visual\nsimilarity (consistent with Shepard's law) and was robust across levels of the\nimages' nameability. These findings suggest that ad hoc conventions are not\narbitrary labels but reflect genuine conceptual coordination, with implications\nfor theories of reference and the design of more adaptive language agents.", "AI": {"tldr": "研究通过实验表明，当人们讨论前所未闻的概念时，他们的描述方式不仅限于特定的具体实例，而是反映出更多的概念性对齐。", "motivation": "研究旨在探讨人们如何讨论之前从未提及过的事物。针对这一问题，本文提出了两种不同的观点，并采用实验来检验这些理论的有效性。", "method": "本研究通过二元交流实验（N=302）利用最近发布的KiloGram数据集来测试这些竞争性的观点，该数据集包含超过1,000个抽象的七巧板图像。参与者成对进行，并就一套图像的指示惯例进行了反复交流，然后测量他们对未讨论过的图像描述的一致性。", "result": "研究发现强有力的证据表明存在概念泛化：参与双方在未讨论过的图像描述上展现了一致性。这种泛化效果非线性地受到视觉相似性的影响（符合谢夫德定律），并且在不同形象命名水平上保持稳健。", "conclusion": "研究结果表明，临时的惯例并不是任意标签，而是反映真实的认知协调，这对于参考理论和更具适应性的语言代理设计具有重要意义。"}}
{"id": "2509.05334", "categories": ["cs.CV", "cs.MM", "H.5.1; I.2.10"], "pdf": "https://arxiv.org/pdf/2509.05334", "abs": "https://arxiv.org/abs/2509.05334", "authors": ["Diwen Huang"], "title": "A Real-Time, Vision-Based System for Badminton Smash Speed Estimation on Mobile Devices", "comment": "6 pages, 3 figures, 1 table. Independent research preprint", "summary": "Performance metrics in sports, such as shot speed and angle, provide crucial\nfeedback for athlete development. However, the technology to capture these\nmetrics has historically been expensive, complex, and largely inaccessible to\namateur and recreational players. This paper addresses this gap in the context\nof badminton, one of the world's most popular sports, by introducing a novel,\ncost-effective, and user-friendly system for measuring smash speed using\nubiquitous smartphone technology. Our approach leverages a custom-trained\nYOLOv5 model for shuttlecock detection, combined with a Kalman filter for\nrobust trajectory tracking. By implementing a video-based kinematic speed\nestimation method with spatiotemporal scaling, the system automatically\ncalculates the shuttlecock's velocity from a standard video recording. The\nentire process is packaged into an intuitive mobile application, democratizing\naccess to high-level performance analytics and empowering players at all levels\nto analyze and improve their game.", "AI": {"tldr": "This paper presents a low-cost, accessible system for measuring badminton smash speeds using a custom smartphone app that integrates computer vision technology and kinematic analysis, broadening access to advanced performance data.", "motivation": "The motivation behind this study is to address the gap in accessible technology for capturing performance metrics like shot speed and angle, which are crucial for athlete development but have historically been unaffordable and complex for amateur and recreational players.", "method": "The paper describes a novel, cost-effective system for measuring smash speed in badminton using a custom-trained YOLOv5 model for shuttlecock detection and a Kalman filter for trajectory tracking. It also implements a video-based kinematic speed estimation method with spatiotemporal scaling to automatically calculate the shuttlecock's velocity from a standard video recording.", "result": "The system is implemented into an intuitive mobile application, making high-level performance analytics accessible to a broader audience and enabling players at all levels to analyze and enhance their game.", "conclusion": "The developed mobile application, which uses advanced computer vision and kinematic techniques, democratizes the access to badminton performance analytics, promoting player improvement and the sport's development."}}
{"id": "2509.05602", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05602", "abs": "https://arxiv.org/abs/2509.05602", "authors": ["Hongyan Xie", "Yitong Yao", "Yikun Ban", "Zixuan Huang", "Deqing Wang", "Zhenhe Wu", "Haoxiang Su", "Chao Wang", "Shuangyong Song", "Xuelong Li"], "title": "Mitigating Spurious Correlations Between Question and Answer via Chain-of-Thought Correctness Perception Distillation", "comment": "PrePrint", "summary": "Large language models (LLMs) excel at reasoning tasks but are expensive to\ndeploy. Thus small language models (SLMs) are fine-tuned on CoT data generated\nby LLMs to copy LLMs' abilities. However, these CoT data may include noisy\nrationales that either fail to substantiate the answers or contribute no\nadditional information to support answer prediction, which leads SLMs to\ncapture spurious correlations between questions and answers and compromise the\nquality of reasoning. In this work, we propose Chain-of-Thought Correctness\nPerception Distillation (CoPeD), which aims to improve the reasoning quality of\nthe student model from the perspectives of task setting and data utilization.\nFirstly, we introduce a correctness-aware task setting that encourages the\nstudent model to predict answers based on correct rationales and revise them\nwhen they are incorrect. This setting improves the faithfulness of reasoning\nand allows the model to learn from its mistakes. Then, we propose a\nCorrectness-Aware Weighted loss, which dynamically adjusts the contribution of\neach training instance based on the combined loss of the rationale and the\nanswer. This strategy encourages the model to focus more on samples where the\nrationale offers stronger support for the correct answer. Experiments have\nshown that CoPeD is effective on both in-distribution (IND) and\nout-of-distribution (OOD) benchmark reasoning datasets.", "AI": {"tldr": "Proposes CoPeD to improve reasoning of small language models by addressing noisy rationales in CoT data.", "motivation": "To address the noise in CoT data that causes small language models to develop spurious correlations, thereby compromising their reasoning quality.", "method": "Chain-of-Thought Correctness Perception Distillation (CoPeD), including a correctness-aware task setting and a Correctness-Aware Weighted loss to improve SLMs reasoning quality.", "result": "The proposed method, CoPeD, shows effectiveness on both in-distribution and out-of-distribution reasoning datasets for small language models.", "conclusion": "CoPeD enhances the reasoning capability of small language models, making fine-tuning more effective and robust in various reasoning tasks."}}
{"id": "2509.05335", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05335", "abs": "https://arxiv.org/abs/2509.05335", "authors": ["Zebo Xu", "Shaoyun Yu", "Mark Torrance", "Guido Nottbusch", "Nan Zhao", "Zhenguang Cai"], "title": "A Stroke-Level Large-Scale Database of Chinese Character Handwriting and the OpenHandWrite_Toolbox for Handwriting Research", "comment": null, "summary": "Understanding what linguistic components (e.g., phonological, semantic, and\northographic systems) modulate Chinese handwriting at the character, radical,\nand stroke levels remains an important yet understudied topic. Additionally,\nthere is a lack of comprehensive tools for capturing and batch-processing\nfine-grained handwriting data. To address these issues, we constructed a\nlarge-scale handwriting database in which 42 Chinese speakers for each\nhandwriting 1200 characters in a handwriting-to-dictation task. Additionally,\nwe enhanced the existing handwriting package and provided comprehensive\ndocumentation for the upgraded OpenHandWrite_Toolbox, which can easily modify\nthe experimental design, capture the stroke-level handwriting trajectory, and\nbatch-process handwriting measurements (e.g., latency, duration, and\npen-pressure). In analysing our large-scale database, multiple regression\nresults show that orthographic predictors impact handwriting preparation and\nexecution across character, radical, and stroke levels. Phonological factors\nalso influence execution at all three levels. Importantly, these lexical\neffects demonstrate hierarchical attenuation - they were most pronounced at the\ncharacter level, followed by the radical, and were weakest at the stroke\nlevels. These findings demonstrate that handwriting preparation and execution\nat the radical and stroke levels are closely intertwined with linguistic\ncomponents. This database and toolbox offer valuable resources for future\npsycholinguistic and neurolinguistic research on the handwriting of characters\nand sub-characters across different languages.", "AI": {"tldr": "研究构建了一个大规模的汉字手写数据库，并改进了手写工具箱，揭示了正字法预测因子对汉字书写的准备和执行有影响，音韵学因素也在所有层级有影响，这表明汉字书写的准备和执行与语言组成部分紧密相关。", "motivation": "研究探讨了哪些语言组成部分（如音韵学、语义学和正字法系统）在汉字、部首和笔画级别上调节汉字书写，这是一个重要但研究不足的话题。此外，缺乏捕捉并批量处理精细手写数据的全面工具。研究旨在解决这些问题。", "method": "我们构建了一个大规模手写数据库，其中42名中文使用者在手写-听写任务中各手写1200个汉字。我们改进了现有的手写工具包，并提供了全面的文档，以支持实验设计的修改，捕捉笔画级手写轨迹并且批量处理手写测量数据（如延迟时间、持续时间和笔压）。", "result": "多重回归分析显示，正字法预测因子在汉字、部首和笔画级别上的书写准备和执行上产生影响，音韵学因素也对所有三个层级的执行有影响，这些影响在字符级别最为明显，随后是部首级别，在笔画级别最弱。", "conclusion": "本研究发现，部首和笔画级别的书写准备和执行与语言组成部分紧密相关。这个数据库和工具箱将为未来汉语及各种语言的心理语言学和神经语言学研究提供有价值的资源。"}}
{"id": "2509.05605", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05605", "abs": "https://arxiv.org/abs/2509.05605", "authors": ["Qiyuan Chen", "Hongsen Huang", "Qian Shao", "Jiahe Chen", "Jintai Chen", "Hongxia Xu", "Renjie Hua", "Ren Chuan", "Jian Wu"], "title": "Icon$^{2}$: Aligning Large Language Models Using Self-Synthetic Preference Data via Inherent Regulation", "comment": "EMNLP 2025 Main", "summary": "Large Language Models (LLMs) require high quality preference datasets to\nalign with human preferences. However, conventional methods for constructing\nsuch datasets face significant challenges: reliance on pre-collected\ninstructions often leads to distribution mismatches with target models, while\nthe need for sampling multiple stochastic responses introduces substantial\ncomputational overhead. In this work, we explore a paradigm shift by leveraging\ninherent regulation of LLMs' representation space for efficient and tailored\npreference dataset construction, named Icon$^{2}$. Specifically, it first\nextracts layer-wise direction vectors to encode sophisticated human preferences\nand then uses these vectors to filter self-synthesized instructions based on\ntheir inherent consistency. During decoding, bidirectional inherent control is\napplied to steer token representations, enabling the precise generation of\nresponse pairs with clear alignment distinctions. Experimental results\ndemonstrate significant improvements in both alignment and efficiency.\nLlama3-8B and Qwen2-7B achieve an average win rate improvement of 13.89% on\nAlpacaEval 2.0 and 13.45% on Arena-Hard, while reducing computational costs by\nup to 48.1%.", "AI": {"tldr": "研究提出了一种名为Icon$^{2}$的新方法，通过利用大语言模型表示空间的内在调节，提高了偏好数据集构建的效率和目标模型的一致性，同时减少了计算成本。", "motivation": "传统的偏好数据集构建方法存在与目标模型分布不匹配及计算成本高的问题，该研究旨在改进这些问题。", "method": "Structure", "result": "{\n  \"tldr\": \"研究提出了一种名为Icon\\u00b2的新方法，通过利用大语言模型表示空间的内在调节，提高了偏好数据集构建的效率和目标模型的一致性，同时减少了计算成本。\", \n  \"motivation\": \"传统的偏好数据集构建方法存在与目标模型分布不匹配及计算成本高的问题，该研究旨在改进这些问题。\", \n  \"method\": \"Icon\\u00b2 方法首先提取层级别的方向向量以编码复杂的人类偏好，再利用这些向量筛选出自合成指令，并在解码过程中调整标记表示，生成具有明确对齐差异的响应对。\", \n  \"result\": \"实验结果显示，Llama3-8B和Qwen2-7B在AlpacaEval 2.0和Arena-Hard上的胜率分别提高了13.89%和13.45%，同时计算成本降低了48.1%。\", \n  \"conclusion\": \"Icon\\u00b2 方法能够有效提升大语言模型与人类偏好的对齐度，同时显著减少计算资源的消耗。\"]", "conclusion": "Icon$^{2}$ 方法能够有效提升大语言模型与人类偏好的对齐度，同时显著减少计算资源的消耗。"}}
{"id": "2509.05337", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2509.05337", "abs": "https://arxiv.org/abs/2509.05337", "authors": ["Younggeol Cho", "Gokhan Solak", "Olivia Nocentini", "Marta Lorenzini", "Andrea Fortuna", "Arash Ajoudani"], "title": "Anticipatory Fall Detection in Humans with Hybrid Directed Graph Neural Networks and Long Short-Term Memory", "comment": "Presented at IEEE RO-MAN 2025", "summary": "Detecting and preventing falls in humans is a critical component of assistive\nrobotic systems. While significant progress has been made in detecting falls,\nthe prediction of falls before they happen, and analysis of the transient state\nbetween stability and an impending fall remain unexplored. In this paper, we\npropose a anticipatory fall detection method that utilizes a hybrid model\ncombining Dynamic Graph Neural Networks (DGNN) with Long Short-Term Memory\n(LSTM) networks that decoupled the motion prediction and gait classification\ntasks to anticipate falls with high accuracy. Our approach employs real-time\nskeletal features extracted from video sequences as input for the proposed\nmodel. The DGNN acts as a classifier, distinguishing between three gait states:\nstable, transient, and fall. The LSTM-based network then predicts human\nmovement in subsequent time steps, enabling early detection of falls. The\nproposed model was trained and validated using the OUMVLP-Pose and URFD\ndatasets, demonstrating superior performance in terms of prediction error and\nrecognition accuracy compared to models relying solely on DGNN and models from\nliterature. The results indicate that decoupling prediction and classification\nimproves performance compared to addressing the unified problem using only the\nDGNN. Furthermore, our method allows for the monitoring of the transient state,\noffering valuable insights that could enhance the functionality of advanced\nassistance systems.", "AI": {"tldr": "本文提出了一种预见性跌倒检测方法，使用结合DGNN和LSTM的混合模型，该模型展示了在跌倒预测误差和识别准确度方面优于文献中现有模型的表现。", "motivation": "尽管在跌倒检测方面已经取得了一定的进展，预测跌倒之前发生以及分析在稳定性和即将跌倒之间的瞬态状态仍然是未被充分探索的领域。本研究旨在提高跌倒预测的准确度和分析瞬态状态，以优化辅助性机器人的功能。", "method": "本研究提出了一种基于动态图神经网络（DGNN）和长短期记忆（LSTM）网络的混合模型的预见性跌倒检测方法。该模型将运动预测和步态分类任务分离，以实现跌倒的高准确度预测。实现实时从视频序列中提取骨骼特征作为输入。DGNN作为分类器区分三种步态状态：稳定、过渡和跌倒。LSTM网络则用于预测后续时间步骤中的人体运动，实现跌倒的早期检测。", "result": "该模型使用OUMVLP-Pose和URFD数据集进行训练和验证，展示出比仅依赖DGNN的模型和文献中的模型在预测误差和识别准确度方面更优的表现。", "conclusion": "研究结果表明，分离预测和分类任务比使用仅依赖DGNN解决统一问题具有更好的性能。此外，该方法允许监测瞬态状态，可以为增强先进辅助系统的功能提供有价值的信息。"}}
{"id": "2509.05607", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05607", "abs": "https://arxiv.org/abs/2509.05607", "authors": ["Qiyuan Chen", "Jiahe Chen", "Hongsen Huang", "Qian Shao", "Jintai Chen", "Renjie Hua", "Hongxia Xu", "Ruijia Wu", "Ren Chuan", "Jian Wu"], "title": "Beyond Keywords: Driving Generative Search Engine Optimization with Content-Centric Agents", "comment": "Technical Report", "summary": "The paradigm shift from traditional ranked-based search to Generative Search\nEngines has rendered conventional SEO metrics obsolete, creating an urgent need\nto understand, measure, and optimize for content influence on synthesized\nanswers. This paper introduces a comprehensive, end-to-end framework for\nGenerative Search Engine Optimization (GSEO) to address this challenge. We make\ntwo primary contributions. First, we construct CC-GSEO-Bench, a large-scale,\ncontent-centric benchmark, and propose a multi-dimensional evaluation framework\nthat systematically quantifies influence, moving beyond surface-level\nattribution to assess substantive semantic impact. Second, we design a novel\nmulti-agent system that operationalizes this framework, automating the\nstrategic refinement of content through a collaborative analyze-revise-evaluate\nworkflow. Our empirical analysis using this framework reveals novel insights\ninto the dynamics of content influence, offering actionable strategies for\ncreators and establishing a principled foundation for future GSEO research.", "AI": {"tldr": "本文介绍了一个新的GSEO框架，包括构建基准、评价系统和多智能体系统，揭示内容影响力的动态，并提供了未来研究的理论基础。", "motivation": "传统排名搜索引擎向生成式搜索引擎的转变使旧的SEO指标过时，解决如何理解和优化内容对合成答案影响的需求。", "method": "提出了一种端到端的生成式搜索引擎优化（GSEO）框架，包括构建一个大规模的内容为中心的基准（CC-GSEO-Bench）和一个多维度的评价体系，以及设计一个多智能体系统来自动优化内容策略。", "result": "通过这个框架的实证分析揭示了内容影响力的新见解，并为内容创作者提供了可行的策略，为未来的GSEO研究建立了理论基础。", "conclusion": "生成式搜索引擎优化的框架提供了理解和衡量内容对合成答案影响力的系统方法，为内容创作者提供了操作策略，并为未来的GSEO研究奠定了基础。"}}
{"id": "2509.05340", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05340", "abs": "https://arxiv.org/abs/2509.05340", "authors": ["Dibya Jyoti Bora", "Mrinal Kanti Mishra"], "title": "Comparative Evaluation of Hard and Soft Clustering for Precise Brain Tumor Segmentation in MR Imaging", "comment": "15 pages, 10 figures", "summary": "Segmentation of brain tumors from Magnetic Resonance Imaging (MRI) remains a\npivotal challenge in medical image analysis due to the heterogeneous nature of\ntumor morphology and intensity distributions. Accurate delineation of tumor\nboundaries is critical for clinical decision-making, radiotherapy planning, and\nlongitudinal disease monitoring. In this study, we perform a comprehensive\ncomparative analysis of two major clustering paradigms applied in MRI tumor\nsegmentation: hard clustering, exemplified by the K-Means algorithm, and soft\nclustering, represented by Fuzzy C-Means (FCM). While K-Means assigns each\npixel strictly to a single cluster, FCM introduces partial memberships, meaning\neach pixel can belong to multiple clusters with varying degrees of association.\nExperimental validation was performed using the BraTS2020 dataset,\nincorporating pre-processing through Gaussian filtering and Contrast Limited\nAdaptive Histogram Equalization (CLAHE). Evaluation metrics included the Dice\nSimilarity Coefficient (DSC) and processing time, which collectively\ndemonstrated that K-Means achieved superior speed with an average runtime of\n0.3s per image, whereas FCM attained higher segmentation accuracy with an\naverage DSC of 0.67 compared to 0.43 for K-Means, albeit at a higher\ncomputational cost (1.3s per image). These results highlight the inherent\ntrade-off between computational efficiency and boundary precision.", "AI": {"tldr": "The analysis compared K-Means and FCM for brain MRI tumor segmentation, finding that FCM improves accuracy while K-Means increases speed.", "motivation": "Accurate segmentation of brain tumors from MRI is crucial for clinical decision-making, treatment planning, and disease monitoring. The heterogeneity of tumor morphology and intensity complicates this task.", "method": "The study compares hard clustering (K-Means) and soft clustering (Fuzzy C-Means, FCM) in brain MRI tumor segmentation using the BraTS2020 dataset. The analysis incorporates image pre-processing techniques like Gaussian filtering and CLAHE.", "result": "K-Means showed faster processing with an average runtime of 0.3s per image, and FCM yielded higher segmentation accuracy with an average DSC of 0.67 versus 0.43 for K-Means, at the cost of longer processing time (1.3s per image).", "conclusion": "The trade-off between computational efficiency and segmentation accuracy in MRI tumor segmentation is evident, with K-Means and FCM each prioritizing different aspects of performance."}}
{"id": "2509.05609", "categories": ["cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05609", "abs": "https://arxiv.org/abs/2509.05609", "authors": ["Xugang Lu", "Peng Shen", "Yu Tsao", "Hisashi Kawai"], "title": "New Insights into Optimal Alignment of Acoustic and Linguistic Representations for Knowledge Transfer in ASR", "comment": null, "summary": "Aligning acoustic and linguistic representations is a central challenge to\nbridge the pre-trained models in knowledge transfer for automatic speech\nrecognition (ASR). This alignment is inherently structured and asymmetric:\nwhile multiple consecutive acoustic frames typically correspond to a single\nlinguistic token (many-to-one), certain acoustic transition regions may relate\nto multiple adjacent tokens (one-to-many). Moreover, acoustic sequences often\ninclude frames with no linguistic counterpart, such as background noise or\nsilence may lead to imbalanced matching conditions. In this work, we take a new\ninsight to regard alignment and matching as a detection problem, where the goal\nis to identify meaningful correspondences with high precision and recall\nensuring full coverage of linguistic tokens while flexibly handling redundant\nor noisy acoustic frames in transferring linguistic knowledge for ASR. Based on\nthis new insight, we propose an unbalanced optimal transport-based alignment\nmodel that explicitly handles distributional mismatch and structural\nasymmetries with soft and partial matching between acoustic and linguistic\nmodalities. Our method ensures that every linguistic token is grounded in at\nleast one acoustic observation, while allowing for flexible, probabilistic\nmappings from acoustic to linguistic units. We evaluate our proposed model with\nexperiments on an CTC-based ASR system with a pre-trained language model for\nknowledge transfer. Experimental results demonstrate the effectiveness of our\napproach in flexibly controlling degree of matching and hence to improve ASR\nperformance.", "AI": {"tldr": "本文将对齐和匹配视为检测问题，引入了基于不平衡最优传输的对齐模型来处理ASR中的声学和语言表示对齐问题，并展示了该方法在实验中的有效性。", "motivation": "对齐声学和语言表示是自动语音识别（ASR）中预训练模型知识转移的关键挑战。而这种对齐具有固有的结构化和非对称特性。", "method": "我们提出了一种基于不平衡最优传输的对齐模型，该模型能够显式处理声学和语言模态之间的分布不匹配和结构不对称问题，通过软且部分的匹配实现灵活的知识转移。", "result": "实验结果展示了我们方法的有效性，能够灵活控制匹配程度，从而提升ASR性能。", "conclusion": "我们的方法确保了每个语言标记都被至少一个声学观测所支撑，同时允许声学单位到语言单位的灵活概率化映射，从而改善了ASR性能。"}}
{"id": "2509.05341", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05341", "abs": "https://arxiv.org/abs/2509.05341", "authors": ["Abhijeet Manoj Pal", "Rajbabu Velmurugan"], "title": "Handling imbalance and few-sample size in ML based Onion disease classification", "comment": "6 pages, 8 figures", "summary": "Accurate classification of pests and diseases plays a vital role in precision\nagriculture, enabling efficient identification, targeted interventions, and\npreventing their further spread. However, current methods primarily focus on\nbinary classification, which limits their practical applications, especially in\nscenarios where accurately identifying the specific type of disease or pest is\nessential. We propose a robust deep learning based model for multi-class\nclassification of onion crop diseases and pests. We enhance a pre-trained\nConvolutional Neural Network (CNN) model by integrating attention based modules\nand employing comprehensive data augmentation pipeline to mitigate class\nimbalance. We propose a model which gives 96.90% overall accuracy and 0.96 F1\nscore on real-world field image dataset. This model gives better results than\nother approaches using the same datasets.", "AI": {"tldr": "为了提高精准农业中病虫害分类的准确性，我们提出了一种基于深度学习的多类分类模型，该模型优于现有的二分类方法，并在实际数据集中取得了高准确率。", "motivation": "现有的病虫害分类方法主要集中在二分类上，这限制了它们在实际中的应用，特别是在需要准确识别具体病虫害种类的情况下。准确的病虫害分类对于精确农业中有效的识别、针对性干预以及防止其进一步传播至关重要。", "method": "提出了一种基于深度学习的多类分类模型，用于洋葱病虫害的分类。该模型通过对预训练的卷积神经网络(CNN)进行改进，集成注意力模块，并使用全面的数据增强管道来缓解类别不平衡的问题。", "result": "该模型在真实田间图像数据集上的整体准确率为96.90%，F1得分为0.96，优于使用相同数据集的其他方法。", "conclusion": "提出的模型在真实田间图像数据集中达到了很高的准确性和F1得分，证明了它在实际应用中的有效性。"}}
{"id": "2509.05617", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05617", "abs": "https://arxiv.org/abs/2509.05617", "authors": ["Shay Dahary", "Avi Edana", "Alexander Apartsin", "Yehudit Aperstein"], "title": "From Joy to Fear: A Benchmark of Emotion Estimation in Pop Song Lyrics", "comment": "5 pages, 2 figures", "summary": "The emotional content of song lyrics plays a pivotal role in shaping listener\nexperiences and influencing musical preferences. This paper investigates the\ntask of multi-label emotional attribution of song lyrics by predicting six\nemotional intensity scores corresponding to six fundamental emotions. A\nmanually labeled dataset is constructed using a mean opinion score (MOS)\napproach, which aggregates annotations from multiple human raters to ensure\nreliable ground-truth labels. Leveraging this dataset, we conduct a\ncomprehensive evaluation of several publicly available large language models\n(LLMs) under zero-shot scenarios. Additionally, we fine-tune a BERT-based model\nspecifically for predicting multi-label emotion scores. Experimental results\nreveal the relative strengths and limitations of zero-shot and fine-tuned\nmodels in capturing the nuanced emotional content of lyrics. Our findings\nhighlight the potential of LLMs for emotion recognition in creative texts,\nproviding insights into model selection strategies for emotion-based music\ninformation retrieval applications. The labeled dataset is available at\nhttps://github.com/LLM-HITCS25S/LyricsEmotionAttribution.", "AI": {"tldr": "文章研究了歌曲歌词多标签情感标注任务，评估了多个语言模型在零样本场景下的表现，并对BERT模型进行了微调。结果表明，大规模语言模型在识别歌曲歌词中的情感方面具有潜力。", "motivation": "歌曲歌词的情感内容对听众体验和音乐喜好有着重要的影响。本文旨在探索歌曲歌词的多标签情感标注任务，旨在为音乐信息检索应用提供基于情感的决策支持。", "method": "本研究通过多标签情感标注任务来预测歌曲歌词的六种基础情感强度。创建了一个基于平均意见分数（MOS）的手动标注数据集，并对几个公开的大型语言模型（LLMs）在零样本场景下的表现进行了全面评估。此外，还对一个基于BERT的模型进行了微调，专门用于预测多标签情感得分。", "result": "实验结果显示零样本模型和微调模型在捕捉歌词情感细微差别方面的相对优劣。研究结果表明LLMs在创意文本情感识别方面的潜力，并为基于情感的音乐信息检索提供了模型选择策略的见解。", "conclusion": "本研究强调了语言模型在歌曲歌词情感分析中的潜力和应用前景，有助于优化基于情感的音乐推荐系统。"}}
{"id": "2509.05342", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.05342", "abs": "https://arxiv.org/abs/2509.05342", "authors": ["Gaspard Beaudouin", "Minghan Li", "Jaeyeon Kim", "Sunghoon Yoon", "Mengyu Wang"], "title": "Delta Velocity Rectified Flow for Text-to-Image Editing", "comment": null, "summary": "We propose Delta Velocity Rectified Flow (DVRF), a novel inversion-free,\npath-aware editing framework within rectified flow models for text-to-image\nediting. DVRF is a distillation-based method that explicitly models the\ndiscrepancy between the source and target velocity fields in order to mitigate\nover-smoothing artifacts rampant in prior distillation sampling approaches. We\nfurther introduce a time-dependent shift term to push noisy latents closer to\nthe target trajectory, enhancing the alignment with the target distribution. We\ntheoretically demonstrate that when this shift is disabled, DVRF reduces to\nDelta Denoising Score, thereby bridging score-based diffusion optimization and\nvelocity-based rectified-flow optimization. Moreover, when the shift term\nfollows a linear schedule under rectified-flow dynamics, DVRF generalizes the\nInversion-free method FlowEdit and provides a principled theoretical\ninterpretation for it. Experimental results indicate that DVRF achieves\nsuperior editing quality, fidelity, and controllability while requiring no\narchitectural modifications, making it efficient and broadly applicable to\ntext-to-image editing tasks. Code is available at\nhttps://github.com/gaspardbd/DeltaVelocityRectifiedFlow.", "AI": {"tldr": "提出了一种名为Delta Velocity Rectified Flow (DVRF) 的新颖无逆编辑框架，旨在改善text-to-image编辑的质量。", "motivation": "解决先前方法中存在的过平滑问题，以提高文本到图像编辑任务的质量和控制精度。", "method": "通过建模源和目标速度场之间的差距以减轻过平滑问题，并引入时间依赖的偏移项来提高对目标分布的对齐精度。", "result": "实验表明，DVRF能够在无需架构修改的情况下，提供更强的编辑品质、保真度和可控性。", "conclusion": "DVRF方法在text-to-image编辑任务中展示出了优越性，既高效又广泛应用。"}}
{"id": "2509.05635", "categories": ["cs.CL", "cs.IR"], "pdf": "https://arxiv.org/pdf/2509.05635", "abs": "https://arxiv.org/abs/2509.05635", "authors": ["Liang Zhang", "Yuan Li", "Shijie Zhang", "Zheng Zhang", "Xitong Li"], "title": "Few-Shot Query Intent Detection via Relation-Aware Prompt Learning", "comment": null, "summary": "Intent detection is a crucial component of modern conversational systems,\nsince accurately identifying user intent at the beginning of a conversation is\nessential for generating effective responses. Recent efforts have focused on\nstudying this problem under a challenging few-shot scenario. These approaches\nprimarily leverage large-scale unlabeled dialogue text corpora to pretrain\nlanguage models through various pretext tasks, followed by fine-tuning for\nintent detection with very limited annotations. Despite the improvements\nachieved, existing methods have predominantly focused on textual data,\nneglecting to effectively capture the crucial structural information inherent\nin conversational systems, such as the query-query relation and query-answer\nrelation. To address this gap, we propose SAID, a novel framework that\nintegrates both textual and relational structure information in a unified\nmanner for model pretraining for the first time. Building on this framework, we\nfurther propose a novel mechanism, the query-adaptive attention network\n(QueryAdapt), which operates at the relation token level by generating\nintent-specific relation tokens from well-learned query-query and query-answer\nrelations explicitly, enabling more fine-grained knowledge transfer. Extensive\nexperimental results on two real-world datasets demonstrate that SAID\nsignificantly outperforms state-of-the-art methods.", "AI": {"tldr": "研究了一种新的对话系统意图检测框架SAID，整合文本和结构信息，并引入QueryAdapt机制，实现更精细的知识迁移和意图检测。", "motivation": "现有的方法主要集中在文本数据上，忽略了对话系统中关键的结构信息，如查询-查询关系和查询-回答关系。通过融合结构信息，可以更有效地进行意图检测。", "method": "SAID框架结合了文本和关系结构信息进行模型预训练，并提出QueryAdapt机制，在关系标记级别生成特定意图的关系标记，提升了知识的细粒度转移。", "result": "在两个真实世界的数据集上，SAID显著优于现有最先进方法。", "conclusion": "通过集成SAID框架和QueryAdapt机制，能更有效地利用结构信息进行少样本环境下意图检测任务的预训练。"}}
{"id": "2509.05343", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05343", "abs": "https://arxiv.org/abs/2509.05343", "authors": ["Zahid Ullah", "Minki Hong", "Tahir Mahmood", "Jihie Kim"], "title": "Systematic Integration of Attention Modules into CNNs for Accurate and Generalizable Medical Image Diagnosis", "comment": null, "summary": "Deep learning has become a powerful tool for medical image analysis; however,\nconventional Convolutional Neural Networks (CNNs) often fail to capture the\nfine-grained and complex features critical for accurate diagnosis. To address\nthis limitation, we systematically integrate attention mechanisms into five\nwidely adopted CNN architectures, namely, VGG16, ResNet18, InceptionV3,\nDenseNet121, and EfficientNetB5, to enhance their ability to focus on salient\nregions and improve discriminative performance. Specifically, each baseline\nmodel is augmented with either a Squeeze and Excitation block or a hybrid\nConvolutional Block Attention Module, allowing adaptive recalibration of\nchannel and spatial feature representations. The proposed models are evaluated\non two distinct medical imaging datasets, a brain tumor MRI dataset comprising\nmultiple tumor subtypes, and a Products of Conception histopathological dataset\ncontaining four tissue categories. Experimental results demonstrate that\nattention augmented CNNs consistently outperform baseline architectures across\nall metrics. In particular, EfficientNetB5 with hybrid attention achieves the\nhighest overall performance, delivering substantial gains on both datasets.\nBeyond improved classification accuracy, attention mechanisms enhance feature\nlocalization, leading to better generalization across heterogeneous imaging\nmodalities. This work contributes a systematic comparative framework for\nembedding attention modules in diverse CNN architectures and rigorously\nassesses their impact across multiple medical imaging tasks. The findings\nprovide practical insights for the development of robust, interpretable, and\nclinically applicable deep learning based decision support systems.", "AI": {"tldr": "本研究将在五种流行卷积神经网络架构中集成注意力机制，以提高对医学影像中关键区域的关注度和判别表现，并通过两个不同的医学影像数据集验证其有效性。研究表明，注意力增强的CNN显著提升了分类准确度和特征定位能力。", "motivation": "传统的CNN在医学影像分析中难以捕捉细微和复杂的特征，因此研究中引入注意力机制以解决这一问题，提高模型对关键区域的关注及诊断准确性。", "method": "研究系统性地将挤压激励模块或混合卷积块注意力模块集成到VGG16、ResNet18、InceptionV3、DenseNet121和EfficientNetB5等五种网络架构中，通过自适应调整通道和空间特征表示来增强模型性能。", "result": "实验结果在两个医学影像数据集上验证了注意力增强的CNN普遍优于原始架构，特别是EfficientNetB5结合混合注意力模块在两个数据集上都表现出色。", "conclusion": "研究搭建了一个系统的比较框架，评估了在多种CNN架构中嵌入注意力模块的影响，为开发健壮、可解释、临床上实用的基于深度学习的决策支持系统提供了实用见解。"}}
{"id": "2509.05657", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05657", "abs": "https://arxiv.org/abs/2509.05657", "authors": ["Yuxuan Hu", "Jihao Liu", "Ke Wang", "Jinliang Zhen", "Weikang Shi", "Manyuan Zhang", "Qi Dou", "Rui Liu", "Aojun Zhou", "Hongsheng Li"], "title": "LM-Searcher: Cross-domain Neural Architecture Search with LLMs via Unified Numerical Encoding", "comment": "EMNLP2025", "summary": "Recent progress in Large Language Models (LLMs) has opened new avenues for\nsolving complex optimization problems, including Neural Architecture Search\n(NAS). However, existing LLM-driven NAS approaches rely heavily on prompt\nengineering and domain-specific tuning, limiting their practicality and\nscalability across diverse tasks. In this work, we propose LM-Searcher, a novel\nframework that leverages LLMs for cross-domain neural architecture optimization\nwithout the need for extensive domain-specific adaptation. Central to our\napproach is NCode, a universal numerical string representation for neural\narchitectures, which enables cross-domain architecture encoding and search. We\nalso reformulate the NAS problem as a ranking task, training LLMs to select\nhigh-performing architectures from candidate pools using instruction-tuning\nsamples derived from a novel pruning-based subspace sampling strategy. Our\ncurated dataset, encompassing a wide range of architecture-performance pairs,\nencourages robust and transferable learning. Comprehensive experiments\ndemonstrate that LM-Searcher achieves competitive performance in both in-domain\n(e.g., CNNs for image classification) and out-of-domain (e.g., LoRA\nconfigurations for segmentation and generation) tasks, establishing a new\nparadigm for flexible and generalizable LLM-based architecture search. The\ndatasets and models will be released at https://github.com/Ashone3/LM-Searcher.", "AI": {"tldr": "The paper introduces LM-Searcher, a novel framework for cross-domain neural architecture optimization utilizing LLMs without extensive domain-specific adaptation, focusing on a numerical string representation and ranking task reformulation.", "motivation": "To address the limitations posed by existing LLM-driven neural architecture search methods which are heavily dependent on prompt engineering and domain-specific tuning, and to enhance practicality and scalability across diverse tasks.", "method": "The framework uses a universal numerical string representation for neural architectures named NCode, and transforms the NAS problem into a ranking task to select high-performing models from candidate pools using instruction-tuning samples derived from a novel subspace sampling strategy.", "result": "Comprehensive experiments show that LM-Searcher achieves competitive results in both in-domain and out-of-domain tasks, indicating its robustness and adaptability.", "conclusion": "LM-Searcher introduces a new approach for generalizable LLM-based architecture search by leveraging a cross-domain numerical representation and a redefined NAS as a ranking task, overcoming the existing limitations of LLM-driven NAS methods."}}
{"id": "2509.05348", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2509.05348", "abs": "https://arxiv.org/abs/2509.05348", "authors": ["Ashen Rodrigo", "Isuru Munasinghe", "Asanka Perera"], "title": "Vision-Based Object Detection for UAV Solar Panel Inspection Using an Enhanced Defects Dataset", "comment": null, "summary": "Timely and accurate detection of defects and contaminants in solar panels is\ncritical for maintaining the efficiency and reliability of photovoltaic\nsystems. This study presents a comprehensive evaluation of five\nstate-of-the-art object detection models: YOLOv3, Faster R-CNN, RetinaNet,\nEfficientDet, and Swin Transformer, for identifying physical and electrical\ndefects as well as surface contaminants such as dust, dirt, and bird droppings\non solar panels. A custom dataset, annotated in the COCO format and\nspecifically designed for solar panel defect and contamination detection, was\ndeveloped alongside a user interface to train and evaluate the models. The\nperformance of each model is assessed and compared based on mean Average\nPrecision (mAP), precision, recall, and inference speed. The results\ndemonstrate the trade-offs between detection accuracy and computational\nefficiency, highlighting the relative strengths and limitations of each model.\nThese findings provide valuable guidance for selecting appropriate detection\napproaches in practical solar panel monitoring and maintenance scenarios.\n  The dataset will be publicly available at\nhttps://github.com/IsuruMunasinghe98/solar-panel-inspection-dataset.", "AI": {"tldr": "本研究评估了五种目标检测模型，在一个专为太阳能板缺陷和污染检测设计的数据集上进行训练和评估，展示了各模型在检测精度和计算效率上的权衡。", "motivation": "及时且准确地检测太阳能板上的缺陷和污染物，对维护光伏系统的效率和可靠性至关重要。", "method": "本研究对五种最先进的目标检测模型（YOLOv3、Faster R-CNN、RetinaNet、EfficientDet、Swin Transformer）进行了全面评估，用于识别太阳能板上的物理和电气缺陷及表面污染物（如尘土、污垢和鸟粪）。为此开发了一个以COCO格式标注的自定义数据集，以及用于训练和评估模型的用户界面。", "result": "研究结果展示了检测精度与计算效率之间的权衡，突出了每个模型的相对优势与限制。", "conclusion": "这些结果为实际的太阳能板监控和维护场景中选择合适的检测方法提供了有价值的指导。"}}
{"id": "2509.05660", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2509.05660", "abs": "https://arxiv.org/abs/2509.05660", "authors": ["Hong Su"], "title": "Cross-Question Method Reuse in Large Language Models: From Word-Level Prediction to Rational Logical-Layer Reasoning", "comment": null, "summary": "Large language models (LLMs) have been widely applied to assist in finding\nsolutions for diverse questions. Prior work has proposed representing a method\nas a pair of a question and its corresponding solution, enabling method reuse.\nHowever, existing approaches typically require the questions to be highly\nsimilar. In this paper, we extend the scope of method reuse to address\nquestions with low similarity or with hidden similarities that are not\nexplicitly observable. For questions that are similar in a general-specific\nsense (i.e., broader or narrower in scope), we propose to first separate the\nquestion and solution, rather than directly feeding the pair to the LLM. The\nLLM is then guided to adapt the solution to new but related questions, allowing\nit to focus on solution transfer rather than question recognition. Furthermore,\nwe extend this approach to cases where questions only share partial features or\nhidden characteristics. This enables cross-question method reuse beyond\nconventional similarity constraints. Experimental verification shows that our\nscope-extension approach increases the probability of filtering out reusable\nsolutions, thereby improving the effectiveness of cross-question method reuse.", "AI": {"tldr": "本文提出了一种新的方法复用策略，扩展了问题之间的相似性定义，能够在低相似性或隐性相似性问题中复用解决方案，实验表明这种方法能够提升跨问题方法复用的有效性。", "motivation": "该研究的动机在于解决现有方法要求问题高度相似才能复用已有解决方案的问题，提出了一种新的方法来拓展低相似性问题或隐性相似性问题的方法复用范围。", "method": "该研究提出了一种扩展方法复用范围的新方法。对于一般-特定意义的相似问题，即广义上或狭义上的相关问题，提出先将问题和解决方案分离，指导大型语言模型（LLM）适应新但相关的问题，从而专注于解决方案的转移，而不是问题识别。此外，该方法还扩展到问题部分特征或隐藏特征相似的情况。", "result": "实验结果显示，该方法能够增加过滤出可复用解决方案的概率，提高了跨问题方法复用的效果。", "conclusion": "实验验证表明，通过扩展方法复用范围，可以提高过滤可复用解决方案的概率，从而提高跨问题方法复用的有效性。"}}
{"id": "2509.05352", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05352", "abs": "https://arxiv.org/abs/2509.05352", "authors": ["Cuong Manh Hoang"], "title": "Unsupervised Instance Segmentation with Superpixels", "comment": null, "summary": "Instance segmentation is essential for numerous computer vision applications,\nincluding robotics, human-computer interaction, and autonomous driving.\nCurrently, popular models bring impressive performance in instance segmentation\nby training with a large number of human annotations, which are costly to\ncollect. For this reason, we present a new framework that efficiently and\neffectively segments objects without the need for human annotations. Firstly, a\nMultiCut algorithm is applied to self-supervised features for coarse mask\nsegmentation. Then, a mask filter is employed to obtain high-quality coarse\nmasks. To train the segmentation network, we compute a novel superpixel-guided\nmask loss, comprising hard loss and soft loss, with high-quality coarse masks\nand superpixels segmented from low-level image features. Lastly, a\nself-training process with a new adaptive loss is proposed to improve the\nquality of predicted masks. We conduct experiments on public datasets in\ninstance segmentation and object detection to demonstrate the effectiveness of\nthe proposed framework. The results show that the proposed framework\noutperforms previous state-of-the-art methods.", "AI": {"tldr": "本文介绍了一种新型框架，它通过自监督的方法替代手工标注实现了高效的实例分割。实验表明，新方法在多个数据集上比现有的最先进方法表现更优。", "motivation": "由于现有的实例分割模型需要大量的手工标注数据，这些数据成本高昂。本文旨在提供一个不需要手工标注就可以有效地进行实例分割的新方案。", "method": "本文提出了一种新的框架，首先使用MultiCut算法对自监督特征进行粗糙的掩码分割，然后通过掩码过滤器获得高质量的粗糙掩码。为了训练分割网络，提出了一个新颖的超像素引导的掩码损失，包括硬损失和软损失。最后，引入了一个带有自适应损失的自训练过程来提高预测掩码的质量。", "result": "实验结果显示，本文提出的方法在公共数据集上取得了比现有最先进方法更好的效果。", "conclusion": "本文提出的新框架展示了在实例分割和目标检测上无需大量的手工标注就能达到有效的分割效果。"}}
{"id": "2509.05668", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05668", "abs": "https://arxiv.org/abs/2509.05668", "authors": ["Michael Hoffmann", "Jophin John", "Stefan Schweter", "Gokul Ramakrishnan", "Hoi-Fong Mak", "Alice Zhang", "Dmitry Gaynullin", "Nicolay J. Hammer"], "title": "Llama-GENBA-10B: A Trilingual Large Language Model for German, English and Bavarian", "comment": "Michael Hoffmann and Jophin John contributed equally to this work", "summary": "We present Llama-GENBA-10B, a trilingual foundation model addressing\nEnglish-centric bias in large language models. Built on Llama 3.1-8B and scaled\nto 10B parameters, Llama-GENBA-10B is continuously pretrained on 164B tokens\n(82B English, 82B German, and 80M Bavarian), balancing resources while\npreventing English dominance. Targeted at the German NLP community, the model\nalso promotes Bavarian as a low-resource language. Development tackled four\nchallenges: (1) curating a multilingual corpus despite Bavarian scarcity, (2)\ncreating a unified tokenizer for English, German, and Bavarian, (3) optimizing\narchitecture and language-ratio hyperparameters for cross-lingual transfer, and\n(4) establishing the first standardized trilingual evaluation suite by\ntranslating German benchmarks into Bavarian. Evaluations show that\nLlama-GENBA-10B achieves strong cross-lingual performance, with the fine-tuned\nvariant surpassing Apertus-8B-2509 and gemma-2-9b in Bavarian and establishing\nitself as the best model in its class for this language, while also\noutperforming EuroLLM in English and matching its results in German. Training\non the Cerebras CS-2 demonstrated efficient large-scale multilingual\npretraining with documented energy use, offering a blueprint for inclusive\nfoundation models that integrate low-resource languages.", "AI": {"tldr": "Llama-GENBA-10B是一个平衡了英语、德语和巴伐利亚语训练数据的多语种基础模型，尤其在巴伐利亚语中表现优秀，为包含低资源语言的模型开发提供了新视角。", "motivation": "该项目的目标是为了服务于德语NLP社区，并推广作为低资源语言的巴伐利亚语。", "method": "该研究开发了一个名为Llama-GENBA-10B的多语种基础模型，旨在解决大型语言模型中的英语中心偏见问题。该模型基于Llama 3.1-8B，扩展到10B参数。通过对164B个令牌进行持续预训练（其中82B个英语令牌、82B个德语令牌和80M个巴伐利亚语令牌），平衡资源分配以防止英语占据主导地位。开发过程中旨在解决的挑战包括多语种语料库的创建、多语种统一分词器的创建、架构和语言比例超参数的优化，以及建立第一个标准的三语种评估套件。", "result": "评估结果显示，Llama-GENBA-10B在跨语言性能上表现出色，微调后的变体在巴伐利亚语中超过了Apertus-8B-2509和gemma-2-9b，并且在英语方面优于EuroLLM，在德语方面与EuroLLM相当。", "conclusion": "研究证明了Cerebras CS-2上的大规模多语种预训练效果良好，并记录了能效，为整合低资源语言的包容性基础模型发展提供了蓝图。"}}
{"id": "2509.05388", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.05388", "abs": "https://arxiv.org/abs/2509.05388", "authors": ["Juan Olalla-Pombo", "Alberto Badías", "Miguel Ángel Sanz-Gómez", "José María Benítez", "Francisco Javier Montáns"], "title": "Augmented Structure Preserving Neural Networks for cell biomechanics", "comment": null, "summary": "Cell biomechanics involve a great number of complex phenomena that are\nfundamental to the evolution of life itself and other associated processes,\nranging from the very early stages of embryo-genesis to the maintenance of\ndamaged structures or the growth of tumors. Given the importance of such\nphenomena, increasing research has been dedicated to their understanding, but\nthe many interactions between them and their influence on the decisions of\ncells as a collective network or cluster remain unclear. We present a new\napproach that combines Structure Preserving Neural Networks, which study cell\nmovements as a purely mechanical system, with other Machine Learning tools\n(Artificial Neural Networks), which allow taking into consideration\nenvironmental factors that can be directly deduced from an experiment with\nComputer Vision techniques. This new model, tested on simulated and real cell\nmigration cases, predicts complete cell trajectories following a roll-out\npolicy with a high level of accuracy. This work also includes a mitosis event\nprediction model based on Neural Networks architectures which makes use of the\nsame observed features.", "AI": {"tldr": "研究提出一种新方法，结合结构保留神经网络和其他机器学习工具，用于准确预测细胞轨迹和有丝分裂事件。", "motivation": "鉴于细胞生物力学现象的重要性，尽管有许多研究致力于理解这些现象，但它们之间的许多互动及对细胞集体网络或集群决策的影响仍旧模糊不清，因此提出了这一新方法。", "method": "结合结构保留神经网络研究细胞运动作为一种纯粹的机械系统，并使用计算机视觉技术从实验中直接推断出环境因素，与其他机器学习工具（人工神经网络）结合。", "result": "在模拟和真实细胞迁移案例中，该新模型能够以高精度预测完整的细胞轨迹，并包含了一个基于神经网络架构的有丝分裂事件预测模型。", "conclusion": "该研究为理解和预测细胞行为提供了一种创新的方法，可能在生物医学领域有广泛的应用。"}}
