<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 23]
- [cs.CV](#cs.CV) [Total: 26]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Collaborative and Proactive Management of Task-Oriented Conversations](https://arxiv.org/abs/2510.05110)
*Arezoo Saedi,Afsaneh Fatemi,Mohammad Ali Nematbakhsh,Sophie Rosset,Anne Vilnat*

Main category: cs.CL

> 论文提出了一个基于信息系统的方法来规划任务导向的对话，利用预定义插槽模型用户偏好的方法，通过数据库查询顺序传递相应实体。实验显示这种方法在MultiWOZ数据集上取得最优的表现。

<details>
  <summary>Details</summary>

**Motivation:** 该论文指出当前大多数任务导向型对话系统依赖大型语言模型，但忽视了基于目标的规划。因此，论文希望创建一个包含建设性中间信息的规划对话管理模型。

**Method:** 该论文建立了一个基于信息状态方法的对话管理模型来处理任务导向型对话。初始阶段，定义了用户偏好的插槽和文本部分信息。通过分析中间信息，识别关键情况并创建相应信息组件。这些组件的各种配置生成有限信息状态。随后，创建对话步骤以指示在这些信息状态之间的移动及需执行的过程。最后，构建更新策略。该模型利用大型语言模型的上下文学习能力实现，通过预定义插槽创建数据库查询并按照文本部分指示检索实体的顺序，这使得能按一致性顺序传递所有相关实体给偏好。

**Result:** 该模型在MultiWOZ数据集上的测试对话取得了最大的信息完整性和成功性，并且相比于之前的方法有了改进。

**Conclusion:** 论文的结论是其提出的模型利用了大型语言模型的上下文学习优势，并通过特定的数据库查询优化了实体传递，提高了任务导向对话系统的性能。

**Abstract:** Task oriented dialogue systems (TOD) complete particular tasks based on user
preferences across natural language interactions. Considering the impressive
performance of large language models (LLMs) in natural language processing
(NLP) tasks, most of the latest TODs are centered on LLMs. While proactive
planning is crucial for task completion, many existing TODs overlook effective
goal-aware planning. This paper creates a model for managing task-oriented
conversations, conceptualized centered on the information state approach to
dialogue management. The created model incorporated constructive intermediate
information in planning. Initially, predefined slots and text part
informational components are created to model user preferences. Investigating
intermediate information, critical circumstances are identified. Informational
components corresponding to these circumstances are created. Possible
configurations for these informational components lead to limited information
states. Then, dialogue moves, which indicate movement between these information
states and the procedures that must be performed in the movements, are created.
Eventually, the update strategy is constructed. The created model is
implemented leveraging in-context learning of LLMs. In this model, database
queries are created centered on indicated predefined slots and the order of
retrieved entities is indicated centered on text part. This mechanism enables
passing the whole corresponding entities to the preferences in the order of
congruency. Evaluations exploiting the complete test conversations of MultiWOZ,
with no more than a domain in a conversation, illustrate maximal inform and
success, and improvement compared with previous methods.

</details>


### [2] [Trainable Reference-Based Evaluation Metric for Identifying Quality of English-Gujarati Machine Translation System](https://arxiv.org/abs/2510.05113)
*Nisheeth Joshi,Pragya Katyayan,Palak Arora*

Main category: cs.CL

> 本文提出了一种基于监督学习的针对古吉拉特语机器翻译的评价指标，该指标在实验中表现出优于其他现有指标的能力。

<details>
  <summary>Details</summary>

**Motivation:** 由于实验表明适用于英语和其他欧洲语言的评价方法在印度语言上表现不佳，因此本文旨在开发针对古吉拉特语的机器翻译评价指标。

**Method:** 本文介绍了基于监督学习的参考文本机器翻译评价指标，该指标专门用于古吉拉特语。研究中训练了两个版本的评价指标，每个版本使用25个特征进行训练。其中一个模型使用6个隐藏层并在500个周期内进行训练，另一个模型使用10个隐藏层并在500个周期内进行训练。

**Result:** 通过收集7个机器翻译系统的1000个输出，并与一个人类参考翻译进行比较，测试了该评价指标的性能。结果显示，开发的评价指标比现有一些指标更能产生更好的人类相关性。

**Conclusion:** 研究表明，基于监督学习的参考文本机器翻译评价指标对于古吉拉特语可以产生较高的人类相关的评价结果。

**Abstract:** Machine Translation (MT) Evaluation is an integral part of the MT development
life cycle. Without analyzing the outputs of MT engines, it is impossible to
evaluate the performance of an MT system. Through experiments, it has been
identified that what works for English and other European languages does not
work well with Indian languages. Thus, In this paper, we have introduced a
reference-based MT evaluation metric for Gujarati which is based on supervised
learning. We have trained two versions of the metric which uses 25 features for
training. Among the two models, one model is trained using 6 hidden layers with
500 epochs while the other model is trained using 10 hidden layers with 500
epochs. To test the performance of the metric, we collected 1000 MT outputs of
seven MT systems. These MT engine outputs were compared with 1 human reference
translation. While comparing the developed metrics with other available
metrics, it was found that the metrics produced better human correlations.

</details>


### [3] [Hallucination is Inevitable for LLMs with the Open World Assumption](https://arxiv.org/abs/2510.05116)
*Bowen Xu*

Main category: cs.CL

> 论文将语言模型产生的不准确或虚构输出（即'幻觉'）重新定义为一种泛化问题的表现形式，并提出了在开放世界假设下，幻觉是不可避免的，建议将其视为不应仅从工程缺陷角度处理的结构特征。

<details>
  <summary>Details</summary>

**Motivation:** 探讨在追求通用人工智能的背景下，如何更全面地理解语言模型中的幻觉问题，而非单纯将其视为需要最小化的缺陷。

**Method:** 通过将幻觉问题与封闭世界和开放世界的假设条件相关联，分类幻觉的不同情况，区分哪些幻觉可能纠正，哪些在开放世界条件下似乎是不可避免的。

**Result:** 论文提出了将幻觉定义为泛化问题的传统假设之外的观点，并且建议应将幻觉视为一种应兼容于人类智能的结构特征。

**Conclusion:** 在开放世界条件下，幻觉是不可避免的，因此不应仅从工程缺陷的角度来对待幻觉，而应看作是一个结构特征，以期与人类智能相兼容。

**Abstract:** Large Language Models (LLMs) exhibit impressive linguistic competence but
also produce inaccurate or fabricated outputs, often called ``hallucinations''.
Engineering approaches usually regard hallucination as a defect to be
minimized, while formal analyses have argued for its theoretical inevitability.
Yet both perspectives remain incomplete when considering the conditions
required for artificial general intelligence (AGI). This paper reframes
``hallucination'' as a manifestation of the generalization problem. Under the
Closed World assumption, where training and test distributions are consistent,
hallucinations may be mitigated. Under the Open World assumption, however,
where the environment is unbounded, hallucinations become inevitable. This
paper further develops a classification of hallucination, distinguishing cases
that may be corrected from those that appear unavoidable under open-world
conditions. On this basis, it suggests that ``hallucination'' should be
approached not merely as an engineering defect but as a structural feature to
be tolerated and made compatible with human intelligence.

</details>


### [4] [Towards Structured Knowledge: Advancing Triple Extraction from Regional Trade Agreements using Large Language Models](https://arxiv.org/abs/2510.05121)
*Durgesh Nandini,Rebekka Koch,Mirco Schoenfeld*

Main category: cs.CL

> 研究使用Llama 3.1模型从自然语言的贸易协定文本中提取经济贸易信息三元组，应用了零样本、单样本和少样本技术，评估了其在经济应用中的有效性。

<details>
  <summary>Details</summary>

**Motivation:** 研究的动机在于探索大型语言模型在经济领域抽取结构化知识的有效性，尤其是从自然语言的贸易协定文本中创建经济贸易知识图谱的潜力。

**Method:** 研究使用Llama 3.1模型，应用零样本、单样本和少样本提示技术，处理无结构的区域贸易协定文本，提取相关信息三元组。通过对正反例的考虑，进行定量和定性评估。

**Result:** 该研究旨在探索大型语言模型(LLMs)在经济领域的应用中抽取结构化知识的有效性，尤其是从自然语言的贸易协定文本中提取经济贸易知识图谱。研究中，使用了Llama 3.1模型处理无结构的区域贸易协定文本，抽取贸易相关信息三元组。研究讨论了零样本、单样本和少样本提示技术的性能，同时考虑了正反例的影响，并基于定量和定性指标进行了评估。研究强调了语言模型在经济应用中的重要性。

**Conclusion:** 研究强调了语言模型在经济应用中的重要性，并讨论了抽取贸易相关信息三元组的挑战和未来可能的研究方向。

**Abstract:** This study investigates the effectiveness of Large Language Models (LLMs) for
the extraction of structured knowledge in the form of Subject-Predicate-Object
triples. We apply the setup for the domain of Economics application. The
findings can be applied to a wide range of scenarios, including the creation of
economic trade knowledge graphs from natural language legal trade agreement
texts. As a use case, we apply the model to regional trade agreement texts to
extract trade-related information triples. In particular, we explore the
zero-shot, one-shot and few-shot prompting techniques, incorporating positive
and negative examples, and evaluate their performance based on quantitative and
qualitative metrics. Specifically, we used Llama 3.1 model to process the
unstructured regional trade agreement texts and extract triples. We discuss key
insights, challenges, and potential future directions, emphasizing the
significance of language models in economic applications.

</details>


### [5] [CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support Conversation](https://arxiv.org/abs/2510.05122)
*Jie Zhu,Yuanchen Zhou,Shuo Jiang,Junhui Li,Lifan Guo,Feng Chen,Chi Zhang,Fang Kong*

Main category: cs.CL

> 提出CARE框架，旨在加强情感支持对话中的逻辑连贯性和支持性，改善认知推理过程，而不需要依赖大规模合成数据。

<details>
  <summary>Details</summary>

**Motivation:** 尽管最近的研究主要集中在数据增强和合成语料库的构建上，但它们往往忽视了构成有效情感支持背后更深层次的认知推理过程。

**Method:** 通过CARE框架，利用原始的情感支持对话训练集指导模型生成逻辑连贯和支持性的响应，以增强认知推理过程。在此基础上，使用强化学习进一步优化和加强推理过程。

**Result:** 实验结果表明，CARE大大提高了响应的逻辑合理性和支持性质量，推动了同理心、认知上更强大的和类似人类的情感支持系统的发展。

**Conclusion:** CARE框架证明了通过利用原始情感支持对话训练集并结合强化学习可以显著提升情感支持系统的逻辑连贯性和支持性质量。

**Abstract:** Emotional Support Conversation (ESC) plays a vital role in alleviating
psychological stress and providing emotional value through dialogue. While
recent studies have largely focused on data augmentation and synthetic corpus
construction, they often overlook the deeper cognitive reasoning processes that
underpin effective emotional support. To address this gap, we propose
\textbf{CARE}, a novel framework that strengthens reasoning in ESC without
relying on large-scale synthetic data. CARE leverages the original ESC training
set to guide models in generating logically coherent and supportive responses,
thereby explicitly enhancing cognitive reasoning. Building on this foundation,
we further employ reinforcement learning to refine and reinforce the reasoning
process. Experimental results demonstrate that CARE significantly improves both
the logical soundness and supportive quality of responses, advancing the
development of empathetic, cognitively robust, and human-like emotional support
systems.

</details>


### [6] [MADS: Multi-Agent Dialogue Simulation for Diverse Persuasion Data Generation](https://arxiv.org/abs/2510.05124)
*Mingjin Li,Yu Liu,Huayi Liu,Xiang Ye,Chao Jiang,Hongguang Zhang*

Main category: cs.CL

> MADS, a scalable framework for generating persuasive multi-turn dialogues through agent self-play, effectively simulates diverse user personas and employs task-oriented persuasion strategies, leading to significant improvements in organic traffic conversion in real-world marketing scenarios.

<details>
  <summary>Details</summary>

**Motivation:** To address the challenges in generating training data without human annotation and to improve the persuasive capacity of small LLMs.

**Method:** MADS uses three agents to simulate dialogues: User Agents for diverse persona-driven behaviors, a Dialog Agent for persuasion strategies, and an Optimization Agent for refining dialogue outcomes.

**Result:** In a real-world marketing scenario, MADS improved the organic traffic conversion rate by 22.4%, showing clear business value.

**Conclusion:** The MADS framework is effective in enhancing the persuasive capacity of small LLMs, demonstrating potential for significant business benefits without the need for extensive human annotation.

**Abstract:** We propose MADS (Multi-Agent Dialogue Simulation), a scalable framework for
generating persuasive multi-turn dialogues via agent self-play. MADS employs
three coordinated agents: User Agents simulating diverse persona-driven
behaviors, a Dialog Agent executing task-oriented persuasion strategies and an
Optimization Agent evaluating and refining dialogue outcomes. We further
validate its effectiveness through users' Chain-of-Attitude (CoA) modeling and
dedicated LLMs' persuasion assessment. This approach enables low-cost
generation of training data without human annotation, addressing key industry
challenges such as lack of user data, cold-start evaluation difficulties, and
prompt inefficiency. Applied to a real-world marketing scenario, MADS
significantly improved the persuasion capacity of small LLMs, increasing the
organic traffic conversion rate by 22.4\% (from 1.83\% to 2.24\%) ,
demonstrating clear business value.

</details>


### [7] [Catalog-Native LLM: Speaking Item-ID Dialect with Less Entanglement for Recommendation](https://arxiv.org/abs/2510.05125)
*Reza Shirkavand,Xiaokai Wei,Chen Wang,Zheng Hui,Heng Huang,Michelle Gong*

Main category: cs.CL

> 本论文提出了IDIOMoE模型，通过结合协作过滤与大型语言模型的优势，解决了推荐系统中自然语言处理和协作信号解释的挑战，实验证明模型表现优异。

<details>
  <summary>Details</summary>

**Motivation:** 面对用户日益增长的自然语言查询和解释透明度的需求，本论文动机在于整合协作过滤和大型语言模型的优势，以提供更好的推荐体验和服务。

**Method:** 本论文采用了Mixture-of-Experts (MoE)方法，将项目的交互历史视为一种特殊的语言表达形式，用单独的文本专家和项目专家处理，通过令牌类型门控机制避免了不同模态处理的冲突。

**Result:** 本论文通过引入Item-ID + Oral-language Mixture-of-Experts Language Model (IDIOMoE)，来整合协作过滤和大型语言模型的优势，旨在解决现代推荐系统中用户期望自然语言查询和透明解释的需求。IDIOMoE将项目交互历史视为语言空间中的原生方言，使协作信号能以自然语言的形式被理解。通过将预训练LLM每个块的前馈网络分割成单独的文本专家和项目专家，并结合令牌类型门控，方法避免了文本和目录模式之间的破坏性干扰。实验结果显示，IDIOMoE在公开和专有数据集上均表现出强大的推荐性能，同时保持了预训练模型的文本理解能力。

**Conclusion:** 本论文证明了IDIOMoE模型能有效整合协作过滤和大型语言模型的优势，提高推荐系统的性能，同时满足用户对自然语言查询和透明解释的期望。

**Abstract:** While collaborative filtering delivers predictive accuracy and efficiency,
and Large Language Models (LLMs) enable expressive and generalizable reasoning,
modern recommendation systems must bring these strengths together. Growing user
expectations, such as natural-language queries and transparent explanations,
further highlight the need for a unified approach. However, doing so is
nontrivial. Collaborative signals are often token-efficient but semantically
opaque, while LLMs are semantically rich but struggle to model implicit user
preferences when trained only on textual inputs. This paper introduces Item-ID
+ Oral-language Mixture-of-Experts Language Model (IDIOMoE), which treats item
interaction histories as a native dialect within the language space, enabling
collaborative signals to be understood in the same way as natural language. By
splitting the Feed Forward Network of each block of a pretrained LLM into a
separate text expert and an item expert with token-type gating, our method
avoids destructive interference between text and catalog modalities. IDIOMoE
demonstrates strong recommendation performance across both public and
proprietary datasets, while preserving the text understanding of the pretrained
model.

</details>


### [8] [Improving Metacognition and Uncertainty Communication in Language Models](https://arxiv.org/abs/2510.05126)
*Mark Steyvers,Catarina Belem,Padhraic Smyth*

Main category: cs.CL

> 研究通过监督微调改进 LLMs 传达不确定性的能力，提高校准和区分度，多任务微调产生更广泛收益，但改进具有任务特定性。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型（LLMs）在决策情境中得到越来越广泛的应用，但是当模型以不表达低置信度的方式呈现答案时，用户可能不知道地根据错误的答案采取行动。尽管先前研究表明 LLM 维持内部不确定性的信号，但是它们明确的置信度表达通常是不准确的，不能很好地区分正确和错误的答案。因此，对 LLMs 的改进方法进行了研究，以增强模型传达不确定性并评估改进是否泛化。

**Method:** 通过在涵盖一般知识、数学和开放性 trivia 的数据集上对两种类型的大型语言模型 (LLMs) 进行监督微调，探讨是否可以提高模型传达不确定性的能力，并评估这些改进是否能在不同任务和领域之间泛化。研究包括两个元认知任务：(1) 单个问题信心估计，模型为其答案分配一个数值的信心；(2) 一对信心比较，模型选择两个答案中哪个更可能正确。

**Result:** 微调提高了校准（陈述的信心与准确性之间的校准）和区分度（正确与不正确的响应的信心更高）在域内和跨域中的表现，同时准确度保持不变。但是，改进具有任务特定性：在单个问题校准训练上没有转移到成对比较中，反之亦然。相比之下，两项元认知形式的多任务微调产生了更广泛的收益，在域外评估中产生了更低的校准误差和更强的区分度。

**Conclusion:** 研究表明，尽管 LLMs 中不确定性传达是可训练和可泛化的，但不同的元认知技能并不会自然地相互加强，必须通过多任务训练来一起开发。

**Abstract:** Large language models (LLMs) are increasingly used in decision-making
contexts, but when they present answers without signaling low confidence, users
may unknowingly act on erroneous outputs. While prior work shows that LLMs
maintain internal uncertainty signals, their explicit verbalized confidence is
typically miscalibrated and poorly discriminates between correct and incorrect
answers. Across two types of LLMs, we investigate whether supervised finetuning
can improve models' ability to communicate uncertainty and whether such
improvements generalize across tasks and domains. We finetune the LLMs on
datasets spanning general knowledge, mathematics, and open-ended trivia, and
evaluate two metacognitive tasks: (1) single-question confidence estimation,
where the model assigns a numeric certainty to its answer, and (2) pairwise
confidence comparison, where the model selects which of two answers it is more
likely to have correct. We assess generalization to unseen domains, including
medical and legal reasoning. Results show that finetuning improves calibration
(alignment between stated confidence and accuracy) and discrimination (higher
confidence for correct vs. incorrect responses) within and across domains,
while leaving accuracy unchanged. However, improvements are task-specific:
training on single-question calibration does not transfer to pairwise
comparison, and vice versa. In contrast, multitask finetuning on both forms of
metacognition yields broader gains, producing lower calibration error and
stronger discrimination in out-of-domain evaluations. These results show that
while uncertainty communication in LLMs is trainable and generalizable,
different metacognitive skills do not naturally reinforce one another and must
be developed together through multitask training.

</details>


### [9] [Advancing Automated Spatio-Semantic Analysis in Picture Description Using Language Models](https://arxiv.org/abs/2510.05128)
*Si-Ioi Ng,Pranav S. Ambadi,Kimberly D. Mueller,Julie Liss,Visar Berisha*

Main category: cs.CL

> A BERT-based pipeline for automated CIU extraction and ordering outperforms dictionary-based methods in assessing cognitive-linguistic impairments via picture description analysis.

<details>
  <summary>Details</summary>

**Motivation:** To address the limitations of existing methods that overlook the visual narrative path in cognitive-linguistic impairment assessment, the paper aims to offer an automated system for CIU extraction and ordering.

**Method:** Content uses a BERT-based pipeline fine-tuned with binary cross-entropy and pairwise ranking loss for automated CIU extraction and ordering from picture descriptions, specifically the Cookie Theft picture.

**Result:** The method achieves high precision and recall in CIU detection, low sequence error rates, and shows strong correlations with ground truth, performing comparably to manual annotations in group difference assessments.

**Conclusion:** The study demonstrates the effectiveness of the proposed pipeline in characterizing visual narrative paths for cognitive impairment assessment. The tool is made publicly available.

**Abstract:** Current methods for automated assessment of cognitive-linguistic impairment
via picture description often neglect the visual narrative path - the sequence
and locations of elements a speaker described in the picture. Analyses of
spatio-semantic features capture this path using content information units
(CIUs), but manual tagging or dictionary-based mapping is labor-intensive. This
study proposes a BERT-based pipeline, fine tuned with binary cross-entropy and
pairwise ranking loss, for automated CIU extraction and ordering from the
Cookie Theft picture description. Evaluated by 5-fold cross-validation, it
achieves 93% median precision, 96% median recall in CIU detection, and 24%
sequence error rates. The proposed method extracts features that exhibit strong
Pearson correlations with ground truth, surpassing the dictionary-based
baseline in external validation. These features also perform comparably to
those derived from manual annotations in evaluating group differences via
ANCOVA. The pipeline is shown to effectively characterize visual narrative
paths for cognitive impairment assessment, with the implementation and models
open-sourced to public.

</details>


### [10] [Automated Alignment of Math Items to Content Standards in Large-Scale Assessments Using Language Models](https://arxiv.org/abs/2510.05129)
*Qingshu Xu,Hong Jiao,Tianyi Zhou,Ming Li,Nan Zhang,Sydney Peters,Yanbin Fu*

Main category: cs.CL

> 研究使用多种语言模型和经典机器学习模型评估自动对齐项目与内容标准的效果，发现DeBERTa-v3-base和RoBERTa-large在领域和技能对齐上表现最佳。

<details>
  <summary>Details</summary>

**Motivation:** 准确地对齐项目与内容标准对于大规模评估中的有效得分解释至关重要。

**Method:** 本研究评估了三种自动对齐项目与内容标准的方法：1）提取嵌入并训练多种经典监督机器学习模型，并进一步研究了降维对模型性能的影响；2）对八个BERT模型及其变体进行微调以实现领域和技能对齐；3）探索基于多数投票和堆叠的集成学习方法。

**Result:** 研究结果显示，对于领域对齐，DeBERTa-v3-base模型取得了最高的加权平均F1分数为0.950；而对于技能对齐，RoBERTa-large模型获得了最高的F1分数为0.869。集成模型表现不如最佳的语言模型，而降维虽然提升了基于嵌入的线性分类器性能，但其表现仍然落后于语言模型。

**Conclusion:** 这项研究展示了不同方法在自动化项目与内容标准对齐的应用。

**Abstract:** Accurate alignment of items to content standards is critical for valid score
interpretation in large-scale assessments. This study evaluates three automated
paradigms for aligning items with four domain and nineteen skill labels. First,
we extracted embeddings and trained multiple classical supervised machine
learning models, and further investigated the impact of dimensionality
reduction on model performance. Second, we fine-tuned eight BERT model and its
variants for both domain and skill alignment. Third, we explored ensemble
learning with majority voting and stacking with multiple meta-models. The
DeBERTa-v3-base achieved the highest weighted-average F1 score of 0.950 for
domain alignment while the RoBERTa-large yielded the highest F1 score of 0.869
for skill alignment. Ensemble models did not surpass the best-performing
language models. Dimension reduction enhanced linear classifiers based on
embeddings but did not perform better than language models. This study
demonstrated different methods in automated item alignment to content
standards.}

</details>


### [11] [Submodular Context Partitioning and Compression for In-Context Learning-short paper](https://arxiv.org/abs/2510.05130)
*Shaoyi Zheng,Canyu Zhang,Tianyi Zhou,Shengjie Wang*

Main category: cs.CL

> The paper addresses inefficiencies in in-context learning for large language models by proposing Sub-CP, a framework that enhances performance through diverse and coherent block partitioning strategies.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve in-context learning (ICL) for large language models (LLMs) by addressing the limitations of existing methods related to input complexity and block partitioning.

**Method:** Sub-CP is a block-aware context selection framework that uses submodular objectives to control block diversity, allowing for a flexible range of selection strategies from globally diverse to locally coherent.

**Result:** Extensive experiments on various tasks and datasets show that Sub-CP consistently improves performance across different model scales.

**Conclusion:** Sub-CP effectively addresses the performance issues associated with information redundancy and under-representation caused by different partition strategies in existing in-context learning methods.

**Abstract:** In-context learning (ICL) enables efficient few-shot learning in large
language models (LLMs) without training, but suffers from the quadratic input
complexity of transformers, limiting the maximum number of exemplars. While
various efficient ICL approaches partition the context into blocks to process
(e.g., ensembling, compression, cross-attention), they often ignore the
information redundancy or under-representation caused by different partition
strategies, leading to suboptimal performance. To tackle this problem, we
propose Sub-CP, a block-aware context selection framework that leverages
submodular objectives to control block diversity. Sub-CP supports a flexible
spectrum of selection strategies, allowing each block to range from globally
diverse to locally coherent. This allows fine-grained control over semantic
structure while enabling precomputation. Extensive experiments across diverse
tasks on multiple datasets show that Sub-CP consistently improves performance
across model scales.

</details>


### [12] [Rationale-Augmented Retrieval with Constrained LLM Re-Ranking for Task Discovery](https://arxiv.org/abs/2510.05131)
*Bowen Wei*

Main category: cs.CL

> 提出了一种混合语义搜索系统，以解决Head Start项目中新手员工面临的任务搜索难题，该系统通过结合多种技术，提高了搜索的准确性、可信度和经济效益。

<details>
  <summary>Details</summary>

**Motivation:** 解决了Head Start项目中新手或轮岗员工在平台上寻找适当任务模块时，因领域特定术语和系统命名法导致的搜索困难。

**Method:** 提出了一种实用的混合语义搜索系统，该系统通过轻量级的容错词汇检索、基于嵌入向量的相似度以及受限的大语言模型（LLM）重排序进行协同工作。

**Result:** 详细框架包括所需资源、分阶段实施策略、具体的里程碑、使用精编测试用例的离线评估协议（如Hit@K, Precision@K, Recall@K, MRR）以及包含查询成功率、零结果率和驻留时间代理的在线测量方法。

**Conclusion:** 该方法利用现有的任务库和知识库基础设施，确保了可信度，具有适应术语变化的可进化性，并通过智能缓存、短名单生成和优雅降级机制实现了经济效益。

**Abstract:** Head Start programs utilizing GoEngage face significant challenges when new
or rotating staff attempt to locate appropriate Tasks (modules) on the platform
homepage. These difficulties arise from domain-specific jargon (e.g., IFPA,
DRDP), system-specific nomenclature (e.g., Application Pool), and the inherent
limitations of lexical search in handling typos and varied word ordering. We
propose a pragmatic hybrid semantic search system that synergistically combines
lightweight typo-tolerant lexical retrieval, embedding-based vector similarity,
and constrained large language model (LLM) re-ranking. Our approach leverages
the organization's existing Task Repository and Knowledge Base infrastructure
while ensuring trustworthiness through low false-positive rates, evolvability
to accommodate terminological changes, and economic efficiency via intelligent
caching, shortlist generation, and graceful degradation mechanisms. We provide
a comprehensive framework detailing required resources, a phased implementation
strategy with concrete milestones, an offline evaluation protocol utilizing
curated test cases (Hit@K, Precision@K, Recall@K, MRR), and an online
measurement methodology incorporating query success metrics, zero-result rates,
and dwell-time proxies.

</details>


### [13] [Training Large Language Models To Reason In Parallel With Global Forking Tokens](https://arxiv.org/abs/2510.05132)
*Sheng Jia,Xiao Wang,Shiva Prasad Kasiviswanathan*

Main category: cs.CL

> 论文提出了一种新的微调方法（SSFT），通过集合形式的全局损失和二分匹配技术，有效地提高了在生成多样化且准确的推理路径上的性能。

<details>
  <summary>Details</summary>

**Motivation:** 动机是解决在处理具有挑战性问题时，现有方法在促进多样性的同时降低了准确性的困境。特别是在采样树的深处，触发多样化且正确推理路径的分支标记通常难以被及时发现。

**Method:** 采用了集合形式的全局损失(Supervised Fine-Tuning, SFT)的方法，通过自我监督的二分匹配，解决挑战性问题中的多种可能推理路径的生成问题。这种方法称为集合监督微调(Set Supervised Fine-Tuning, SSFT)。

**Result:** 实验结果表明，与传统的SFT方法相比，SSFT方法在多种推理基准测试下的Pass@1和Cons@k指标上都有显著的提升。

**Conclusion:** 结论表明，SSFT相较于传统的SFT方法能够更好地在保持推理路径多样性的同时提高预测准确性，实现了性能上的提升。

**Abstract:** Although LLMs have demonstrated improved performance by scaling parallel
test-time compute, doing so relies on generating reasoning paths that are both
diverse and accurate. For challenging problems, the forking tokens that trigger
diverse yet correct reasoning modes are typically deep in the sampling tree.
Consequently, common strategies to encourage diversity, such as temperature
scaling, encounter a worsened trade-off between diversity and accuracy.
Motivated by this challenge, we treat parallel reasoning as a
set-of-next-token-prediction problem, and incorporate a set-based global loss
into Supervised Fine-Tuning (SFT) using self-supervised bipartite matching
between our global forking tokens and unique reasoning traces. We observe that,
while naive fine-tuning with multiple reasoning traces collapses these unique
reasoning modes, our proposed method, Set Supervised Fine-Tuning (SSFT),
preserves these modes and produces emergent global forking tokens. Experiments
on multiple reasoning benchmarks show that our SSFT consistently outperforms
SFT under both Pass@1 and Cons@k metrics.

</details>


### [14] [Characterizing Model Behavior Under Synthetic Data Training: An Empirical Study Across Scales and Mixing Ratios](https://arxiv.org/abs/2510.05133)
*Y. Du,G. Wu,G. Tang,W. Wang,Q. Fan*

Main category: cs.CL

> 研究通过一系列实验探讨了合成数据比例对语言模型的影响，发现模型在一定比例的合成数据下表现稳定，但过高的合成数据比例会加速性能下降，研究为合成数据应用提供了指导。

<details>
  <summary>Details</summary>

**Motivation:** 尽管之前的工作展示了在保持较高外部数据比例的情况下合成数据的成功应用，但是关于合成数据比例如何影响模型行为的系统性理解仍然不足，尤其是在不同规模下的影响。

**Method:** 本研究使用Pythia模型套件（参数从410M至12B）在五个多样化的任务上进行实验，评估模型在1至3次训练过程中，随着合成数据比例（0%-50%）的变化，模型性能、校准度和输出特征的变化情况。

**Result:** 研究发现：模型在合成数据比例不超过20%时性能保持稳定，但超过30%后性能急剧下降；大型模型（6.9B-12B参数）比小型模型（410M-1.4B参数）更能抵抗合成数据的影响；校准度的下降先于准确性损失，可作为早期预警信号；任务的特性很重要，推理任务在合成数据训练下比检索任务更快衰减。

**Conclusion:** 当前最佳实践，如STaR和Self-Instruct系统维持超过80%的外部数据，在我们的实验确认的安全范围内运作良好。根据模型规模和任务要求提供实际的合成数据预算指导。

**Abstract:** Synthetic data generated by large language models has become integral to
modern NLP training pipelines, from bootstrapping reasoning capabilities to
augmenting instruction-following datasets. While recent work demonstrates
successful applications maintaining high external data ratios, systematic
understanding of how synthetic data proportion affects model behavior across
different scales remains limited. This paper presents a controlled empirical
study examining model performance, calibration, and output characteristics when
trained on varying synthetic-to-external data ratios. Using the Pythia model
suite (410M-12B parameters) across five diverse tasks, we evaluate models after
one to three training iterations with synthetic data proportions ranging from
0-50\%. Our key findings include: models maintain stable performance with up to
20\% synthetic data, but degradation accelerates beyond 30\%; larger models
(6.9B-12B) show greater robustness to synthetic data than smaller models
(410M-1.4B); calibration degradation precedes accuracy loss, providing an early
warning signal; and task characteristics matter, with reasoning tasks degrading
faster than retrieval tasks under synthetic data training. Importantly, we find
that current best practices, such as those employed in STaR and Self-Instruct
systems that maintain greater than 80\% external data, operate well within safe
regimes identified by our experiments. We provide practical guidance for
practitioners on synthetic data budgets based on model scale and task
requirements, alongside detailed comparison with concurrent work including
Shumailov et al.'s model collapse findings.

</details>


### [15] [Curiosity-Driven LLM-as-a-judge for Personalized Creative Judgment](https://arxiv.org/abs/2510.05135)
*Vanya Bannihatti Kumar,Divyanshu Goyal,Akhil Eppa,Neel Bhandari*

Main category: cs.CL

> 我们提出了一种好奇心驱动的LLM评估创意写作的方法，该方法比监督微调的方法在个性化评估创意判断方面表现更好。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现代大型语言模型在客观任务上表现出色，但它们在评估创造力等主观任务上面临挑战。我们希望通过个性化的方法来提高模型在评估创意写作方面的表现。

**Method:** 我们提出了一种新颖的好奇心驱动的LLM作为评判者，用于个性化评估每个人的创意写作判断。我们使用Chakrabarty et al. (2024)提出的Torrance创造力思维测试(TTCW)基准进行实验，该基准包含由专家人类根据原创性等主观维度标注的故事。

**Result:** 实验结果显示，我们的方法相较于基线监督微调方法，在各种评估指标（Pearson相关性、Cohen's kappa和F1值）上均有提升，特别是对于主观评估，当不同标注者意见不一致时，这种方法尤为有用。

**Conclusion:** 这一研究证明了好奇心驱动的LLM在主观、个性化的创意写作评估任务上的有效性，对促进AI在创造力评估领域的应用具有潜力。

**Abstract:** Modern large language models (LLMs) excel at objective tasks such as
evaluating mathematical reasoning and factual accuracy, yet they falter when
faced with the nuanced, subjective nature of assessing creativity. In this
work, we propose a novel curiosity-driven LLM-as-a-judge for evaluating
creative writing which is personlized to each individual's creative judgments.
We use the Torrance Test of Creative Thinking(TTCW) benchmark introduced in
Chakrabarty et al. (2024), which has stories annotated by expert humans across
various subjective dimensions like Originality, to test our hypothesis. We show
that our method enables models across various sizes, to learn the nuanced
creative judgments of different individuals, by showing improvements over
baseline supervised finetuning(SFT) method across various evaluation metrics
like Pearson correlation, Cohen's and F1 values. Our method is especially
useful in subjective evaluations where not all the annotators agree with each
other.

</details>


### [16] [Linguistic Characteristics of AI-Generated Text: A Survey](https://arxiv.org/abs/2510.05136)
*Luka Terčon,Kaja Dobrovoljc*

Main category: cs.CL

> 本文综述了AI生成文本的语言特征研究，总结了现存趋势，强调了需要进行更广泛的跨语言和跨模型调查以及对提示敏感性的研究。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于AI生成文本在教育、医疗和科学研究等领域的广泛应用，研究其语言特征变得越来越重要，尤其是在语料库语言学、计算语言学和自然语言处理等领域。这种广泛存在的AI生成文本需要一个更系统的总结和理解。

**Method:** 本文通过多个维度分类现有研究工作，并总结目前研究的趋势。维度包括语言描述的层次、模型类型、分析的体裁、分析的语言和提示方法。

**Result:** 现有的研究发现，AI生成的文本更倾向于使用正式、非个人化的风格，特征是名词、限定词和介词的增加使用，而形容词和副词的使用较少。同时，AI生成文本的词汇多样性较低，词汇量较少且重复性较高。

**Conclusion:** 研究显示，大多数研究集中于英语数据和GPT模型系列生成的文本，需要更多的跨语言和跨模型的研究。此外，很少有研究探讨提示敏感性的问题，未来的研究应考虑使用多种提示词进行文本生成。

**Abstract:** Large language models (LLMs) are solidifying their position in the modern
world as effective tools for the automatic generation of text. Their use is
quickly becoming commonplace in fields such as education, healthcare, and
scientific research. There is a growing need to study the linguistic features
present in AI-generated text, as the increasing presence of such texts has
profound implications in various disciplines such as corpus linguistics,
computational linguistics, and natural language processing. Many observations
have already been made, however a broader synthesis of the findings made so far
is required to provide a better understanding of the topic. The present survey
paper aims to provide such a synthesis of extant research. We categorize the
existing works along several dimensions, including the levels of linguistic
description, the models included, the genres analyzed, the languages analyzed,
and the approach to prompting. Additionally, the same scheme is used to present
the findings made so far and expose the current trends followed by researchers.
Among the most-often reported findings is the observation that AI-generated
text is more likely to contain a more formal and impersonal style, signaled by
the increased presence of nouns, determiners, and adpositions and the lower
reliance on adjectives and adverbs. AI-generated text is also more likely to
feature a lower lexical diversity, a smaller vocabulary size, and repetitive
text. Current research, however, remains heavily concentrated on English data
and mostly on text generated by the GPT model family, highlighting the need for
broader cross-linguistic and cross-model investigation. In most cases authors
also fail to address the issue of prompt sensitivity, leaving much room for
future studies that employ multiple prompt wordings in the text generation
phase.

</details>


### [17] [Demystifying deep search: a holistic evaluation with hint-free multi-hop questions and factorised metrics](https://arxiv.org/abs/2510.05137)
*Maojia Song,Renhang Liu,Xinyu Wang,Yong Jiang,Pengjun Xie,Fei Huang,Soujanya Poria,Jingren Zhou*

Main category: cs.CL

> 提出了WebDetective基准测试框架，以解决RAG系统和网络代理在多跳搜索任务中所面临的提示泄露和单一评估的问题，通过对25种先进模型的评估发现了知识利用和适当拒绝方面的系统性弱点，并通过EvidenceLoop工作流程来改进这些系统的搜索和推理能力。

<details>
  <summary>Details</summary>

**Motivation:** 当前评估实践中存在两个主要问题：提示泄露推理路径，以及通过单一通过率进行评估导致的行为多样性被忽视。这导致了评估的不准确和系统能力发展受限，因此需要一个更为全面和多样化的评估框架来推进自主推理系统的开发。

**Method:** 通过开发名为WebDetective的基准测试和EvidenceLoop的代理工作流程来解决当前RAG系统和网络代理在多跳深度搜索任务中的两个主要限制：问题文本中的推理路径泄露和评估方法的单一化。WebDetective包含无提示的多跳问题及一个受控的维基百科沙盒，确保模型行为的全面可追溯性，并提供了一个将搜索充分性、知识利用和拒绝行为分开的全面评估框架。EvidenceLoop则专注于解决这些挑战，通过包含验证循环和系统证据跟踪来提升搜索和综合能力。

**Result:** 通过WebDetective对25个先进模型的评估揭示了系统在知识利用和适当拒绝行为上的系统性弱点，暴露了当前系统执行给定推理路径能力较强，但发现推理路径的能力较弱的问题。

**Conclusion:** WebDetective的诊断框架可以引导具体的技术改进，被视为开发真正自主推理系统的重要工具，而不是仅仅跟随模式的代理。EvidenceLoop展现出改善搜索和综合能力的潜力。

**Abstract:** RAG (Retrieval-Augmented Generation) systems and web agents are increasingly
evaluated on multi-hop deep search tasks, yet current practice suffers from two
major limitations. First, most benchmarks leak the reasoning path in the
question text, allowing models to follow surface cues rather than discover
reasoning chains autonomously. Second, evaluation is typically reduced to a
single pass rate, which collapses diverse behaviours into one score and
obscures whether failures stem from inadequate search, poor knowledge use, or
inappropriate refusal. To address these issues, we present WebDetective, a
benchmark of hint-free multi-hop questions paired with a controlled Wikipedia
sandbox that ensures full traceability of model actions, and a holistic
evaluation framework that separates search sufficiency, knowledge utilisation,
and refusal behaviour. Our evaluation of 25 state-of-the-art models reveals
systematic weaknesses across all architectures: models struggle with knowledge
utilisation despite having sufficient evidence and demonstrate near-absent
appropriate refusal when evidence is lacking. These patterns expose a
fundamental gap: today's systems excel at executing given reasoning paths but
fail when required to discover them. We develop an agentic workflow,
EvidenceLoop, that explicitly targets the challenges our benchmark identifies,
incorporating verification loops and systematic evidence tracking that improve
both search and synthesis capabilities. This baseline demonstrates that
WebDetective's diagnostic framework can guide concrete architectural
improvements, establishing our benchmark as a critical tool for developing
genuinely autonomous reasoning systems rather than pattern-following agents.

</details>


### [18] [LiRA: A Multi-Agent Framework for Reliable and Readable Literature Review Generation](https://arxiv.org/abs/2510.05138)
*Gregory Hok Tjoan Go,Khang Ly,Anders Søgaard,Amin Tabatabaei,Maarten de Rijke,Xinyi Chen*

Main category: cs.CL

> 研究团队开发了LiRA系统，以提高系统性文献综述的可靠性和可操作性，特别是在写作质量和引用质量方面表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 由于科学出版物的快速增长，难以维持文献综述的全面性和时效性。之前的很多工作主要集中在自动化检索和筛选上，但文献综述的写作阶段，尤其是在可读性和事实准确性方面，探讨较少。

**Method:** 提出了一种多代理协作工作流LiRA，用于模拟人类文献综述过程，包括内容设计、子部分写作、编辑和审阅等专有代理的协作。

**Result:** LiRA在SciReviewGen和一个专有的ScienceDirect数据集上的评估结果表明，其在写作和引用质量方面超过了现有的基准（如AutoSurvey和MASS-Survey），并且在与人类写作的相似性方面保持了竞争力。

**Conclusion:** 研究结果凸显了代理大语言模型工作流在提升自动化科学写作可靠性与可用性方面的潜力，即使在没有特定领域调优的情况下也是如此。

**Abstract:** The rapid growth of scientific publications has made it increasingly
difficult to keep literature reviews comprehensive and up-to-date. Though prior
work has focused on automating retrieval and screening, the writing phase of
systematic reviews remains largely under-explored, especially with regard to
readability and factual accuracy. To address this, we present LiRA (Literature
Review Agents), a multi-agent collaborative workflow which emulates the human
literature review process. LiRA utilizes specialized agents for content
outlining, subsection writing, editing, and reviewing, producing cohesive and
comprehensive review articles. Evaluated on SciReviewGen and a proprietary
ScienceDirect dataset, LiRA outperforms current baselines such as AutoSurvey
and MASS-Survey in writing and citation quality, while maintaining competitive
similarity to human-written reviews. We further evaluate LiRA in real-world
scenarios using document retrieval and assess its robustness to reviewer model
variation. Our findings highlight the potential of agentic LLM workflows, even
without domain-specific tuning, to improve the reliability and usability of
automated scientific writing.

</details>


### [19] [NLD-LLM: A systematic framework for evaluating small language transformer models on natural language description](https://arxiv.org/abs/2510.05139)
*Hamed Jelodar,Mohammad Meymani,Parisa Hamedi,Tochukwu Emmanuel Nwankwo,Samita Bai,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.CL

> 本文提出NLD-LLM框架，用于评估语言模型生成源代码描述的能力，强调提示工程在提高模型性能方面的重要性。

<details>
  <summary>Details</summary>

**Motivation:** NLD是一项NLP任务，需要模型从自然语言输入生成结构化和有意义的输出。本研究旨在系统评估语言模型在生成源代码描述方面的性能。

**Method:** 提出了NLD-LLM，一个系统性的NLP框架，用于评估语言模型生成准确且简洁的源代码描述的能力。框架包含多种Transformer模型，并采用全面的提示设计策略，包括标准格式、清晰的任务指南和NLD提示。此外，还采用了迭代改进过程以提高输出质量并评估模型的适应性。

**Result:** 分析表明，提示工程显著影响模型的有效性，适当的设计可以使得较小的模型在性能上与较大的模型相当。

**Conclusion:** 研究展示了在NLD任务中，通过精心设计的提示策略，可以提高模型输出的质量，甚至让较小的模型在性能上表现出色。

**Abstract:** Natural Language Description (NLD) is a Natural Language Processing (NLP)
task that requires models to generate structured and meaningful outputs from
natural language inputs. In this work, we propose NLD-LLM, a systematic NLP
framework to evaluate the performance of language models to generate accurate
and concise source code descriptions. This framework incorporates a diverse set
of transformer models, including Qwen, DeepSeek, Phi, LLaMA, and Mistral,
spanning various sizes, architectures, and training approaches. Central to
NLD-LLM is a comprehensive prompt design strategy that includes standardized
formatting, clear task guidance, and NLD prompting, ensuring fair and
consistent evaluation. Additionally, we apply an iterative refinement process
to improve output's quality and assess the model's adaptability. Using semantic
and structural metrics, our analysis demonstrates that prompt engineering
significantly impacts the effectiveness of the model such that smaller models
often performing competitively when supported by well-crafted prompts.

</details>


### [20] [To model human linguistic prediction, make LLMs less superhuman](https://arxiv.org/abs/2510.05141)
*Byung-Doh Oh,Tal Linzen*

Main category: cs.CL

> 文章分析了大型语言模型（LLMs）比人类更优秀地预测下一个词的能力如何影响其作为人类语言预测认知模型的有效性，并提出需要开发具有人类般记忆能力的语言模型。

<details>
  <summary>Details</summary>

**Motivation:** 探讨大型语言模型在预测人类阅读行为上的不足，发现模型过度强于人类的语言预测能力导致不能准确预测人类处理语言时的难度，并提出解决这一问题的可能方向。

**Method:** 通过分析大型语言模型（LLMs）与人类语言理解的对比，文章探究了LLMs作为人类语言预测认知模型的潜力和局限性。作者认为，LLMs的'超人类'特性主要归因于它们比人类具有更强的事实和训练实例长期记忆，以及更好的文本中先前词汇的短期记忆能力。

**Result:** 发现LLMs的预测能力远超人类，导致它们无法准确预测人类阅读行为，反而预测出较低的阅读处理难度。

**Conclusion:** 需要创建具有人类般记忆能力的语言模型，并指出当前的人类数据不足以衡量进展，建议进行进一步的人类实验以填补这一空白。

**Abstract:** When people listen to or read a sentence, they actively make predictions
about upcoming words: words that are less predictable are generally read more
slowly than predictable ones. The success of large language models (LLMs),
which, like humans, make predictions about upcoming words, has motivated
exploring the use of these models as cognitive models of human linguistic
prediction. Surprisingly, in the last few years, as language models have become
better at predicting the next word, their ability to predict human reading
behavior has declined. This is because LLMs are able to predict upcoming words
much better than people can, leading them to predict lower processing
difficulty in reading than observed in human experiments; in other words,
mainstream LLMs are 'superhuman' as models of language comprehension. In this
position paper, we argue that LLMs' superhumanness is primarily driven by two
factors: compared to humans, LLMs have much stronger long-term memory for facts
and training examples, and they have much better short-term memory for previous
words in the text. We advocate for creating models that have human-like
long-term and short-term memory, and outline some possible directions for
achieving this goal. Finally, we argue that currently available human data is
insufficient to measure progress towards this goal, and outline human
experiments that can address this gap.

</details>


### [21] [Reliable End-to-End Material Information Extraction from the Literature with Source-Tracked Multi-Stage Large Language Models](https://arxiv.org/abs/2510.05142)
*Xin Wang,Anshu Raj,Matthew Luebbe,Haiming Wen,Shuozhi Xu,Kun Lu*

Main category: cs.CL

> 研究提出了一种多阶段信息提取管道，利用大型语言模型从实验报告的材料中精确提取多种特性，具备高精确率和可靠性的特征提取能力，并且能高效地从文献中挖掘数据，为机器学习和材料信息学提供了可靠的数据库。

<details>
  <summary>Details</summary>

**Motivation:** 数据驱动的材料发现需要大规模的实验数据集，但大多数信息仍然被困在非结构化的文献中。现有的提取工作往往只关注有限的特性，并没有解决复合-加工-微观结构-性能关系的综合问题，这对理解材料行为至关重要，因而对建立综合数据库构成了挑战。

**Method:** 我们提出了一种多阶段信息提取管道，由大型语言模型驱动，能够从实验报告的材料中独占捕获47个特性，这些特性涵盖了组成、处理、微观结构和属性。该管道通过迭代提取和源跟踪来提高准确性和可靠性。

**Result:** 在特征级别（独立属性）和元组级别（互依特性）的评估中，获得了接近0.96的F1分数。与没有源跟踪的单次抽取相比，我们方法在微观结构类别的F1分数提高了10.0%（特征级别）和13.7%（元组级别），并且在100篇关于含沉淀物的多元主元素合金的文章中，遗漏的材料从49个减少到13个（错漏率从12.4%降低到3.3%）。

**Conclusion:** 此管道支持大型文献信息的可扩展且高效的挖掘，产生了高精度、遗漏少且无错误正例的数据库。这些数据库为机器学习和材料信息学提供了可靠的输入，同时模块化设计适用于多种材料类别，实现了综合材料信息提取。

**Abstract:** Data-driven materials discovery requires large-scale experimental datasets,
yet most of the information remains trapped in unstructured literature.
Existing extraction efforts often focus on a limited set of features and have
not addressed the integrated composition-processing-microstructure-property
relationships essential for understanding materials behavior, thereby posing
challenges for building comprehensive databases. To address this gap, we
propose a multi-stage information extraction pipeline powered by large language
models, which captures 47 features spanning composition, processing,
microstructure, and properties exclusively from experimentally reported
materials. The pipeline integrates iterative extraction with source tracking to
enhance both accuracy and reliability. Evaluations at the feature level
(independent attributes) and tuple level (interdependent features) yielded F1
scores around 0.96. Compared with single-pass extraction without source
tracking, our approach improved F1 scores of microstructure category by 10.0%
(feature level) and 13.7% (tuple level), and reduced missed materials from 49
to 13 out of 396 materials in 100 articles on precipitate-containing
multi-principal element alloys (miss rate reduced from 12.4% to 3.3%). The
pipeline enables scalable and efficient literature mining, producing databases
with high precision, minimal omissions, and zero false positives. These
datasets provide trustworthy inputs for machine learning and materials
informatics, while the modular design generalizes to diverse material classes,
enabling comprehensive materials information extraction.

</details>


### [22] [SynCED-EnDe 2025: A Synthetic and Curated English - German Dataset for Critical Error Detection in Machine Translation](https://arxiv.org/abs/2510.05144)
*Muskaan Chopra,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CL

> 本文介绍了SynCED-EnDe数据集，解决了现有数据集的局限性，并通过实验验证了其在错误检测方面的优异性能。

<details>
  <summary>Details</summary>

**Motivation:** 动机在于现有的WMT21数据集在规模、标签平衡性、领域覆盖率和时效性上存在不足，新的数据集旨在解决这些问题并推进机器翻译的安全应用。

**Method:** 该研究提出了SynCED-EnDe，一个新的英语-德语翻译错误检测数据集，包含1000个黄金标签和8000个银标签的句子对，并引入了具体的错误子类、结构触发标志和细粒度辅助判断。

**Result:** 基准实验显示，通过XLM-R和其他相关编码器，新数据集在错误检测方面比WMT21数据集表现更好。

**Conclusion:** SynCED-EnDe数据集旨在作为社区资源，推进机器翻译在信息检索和对话助手中的安全部署，特别是在可穿戴AI设备等新环境中的应用。

**Abstract:** Critical Error Detection (CED) in machine translation aims to determine
whether a translation is safe to use or contains unacceptable deviations in
meaning. While the WMT21 English-German CED dataset provided the first
benchmark, it is limited in scale, label balance, domain coverage, and temporal
freshness. We present SynCED-EnDe, a new resource consisting of 1,000
gold-labeled and 8,000 silver-labeled sentence pairs, balanced 50/50 between
error and non-error cases. SynCED-EnDe draws from diverse 2024-2025 sources
(StackExchange, GOV.UK) and introduces explicit error subclasses, structured
trigger flags, and fine-grained auxiliary judgments (obviousness, severity,
localization complexity, contextual dependency, adequacy deviation). These
enrichments enable systematic analyses of error risk and intricacy beyond
binary detection. The dataset is permanently hosted on GitHub and Hugging Face,
accompanied by documentation, annotation guidelines, and baseline scripts.
Benchmark experiments with XLM-R and related encoders show substantial
performance gains over WMT21 due to balanced labels and refined annotations. We
envision SynCED-EnDe as a community resource to advance safe deployment of MT
in information retrieval and conversational assistants, particularly in
emerging contexts such as wearable AI devices.

</details>


### [23] [Every Step Counts: Decoding Trajectories as Authorship Fingerprints of dLLMs](https://arxiv.org/abs/2510.05148)
*Qi Li,Runpeng Yu,Haiquan Lu,Xinchao Wang*

Main category: cs.CL

> 研究开发了 Directed Decoding Map (DDM) 以解决离散扩散大语言模型 (dLLMs) 在不同模型或同一模型不同检查点之间的归因问题，并提出 Gaussian-Trajectory Attribution (GTA) 方法来有效利用提取出的结构信息。

<details>
  <summary>Details</summary>

**Motivation:** 离散扩散大语言模型 (dLLMs) 由于其解码机制的独特性，能够提升模型在代码生成和数学任务上的性能。然而，在模型归属评价任务中，dLLMs 解码结果多样性的挑战显而易见，研究动机在于找到一种方式来有效提取和利用解码轨迹中的信息，以区分不同的模型实例。

**Method:** 研究首先提出 DDM 来捕捉解码步骤间的结构性关系，然后使用 GTA 在各个解码位置上为每个目标模型拟合一个单元格高斯分布，并将轨迹的似然性作为归因得分。

**Result:** 实验结果验证了所提方法的有效性，在多种设置下都获得了很好的表现。

**Conclusion:** 本文提出的 DDM 和 GTA 方法，有效解决了dLLM在归因任务上的挑战，通过捕捉和利用解码过程中的结构信息，提升了不同模型实例间的归因准确性。

**Abstract:** Discrete Diffusion Large Language Models (dLLMs) have recently emerged as a
competitive paradigm for non-autoregressive language modeling. Their
distinctive decoding mechanism enables faster inference speed and strong
performance in code generation and mathematical tasks. In this work, we show
that the decoding mechanism of dLLMs not only enhances model utility but also
can be used as a powerful tool for model attribution. A key challenge in this
problem lies in the diversity of attribution scenarios, including
distinguishing between different models as well as between different
checkpoints or backups of the same model. To ensure broad applicability, we
identify two fundamental problems: what information to extract from the
decoding trajectory, and how to utilize it effectively. We first observe that
relying directly on per-step model confidence yields poor performance. This is
mainly due to the bidirectional decoding nature of dLLMs: each newly decoded
token influences the confidence of other decoded tokens, making model
confidence highly redundant and washing out structural signal regarding
decoding order or dependencies. To overcome this, we propose a novel
information extraction scheme called the Directed Decoding Map (DDM), which
captures structural relationships between decoding steps and better reveals
model-specific behaviors. Furthermore, to make full use of the extracted
structural information during attribution, we propose Gaussian-Trajectory
Attribution (GTA), where we fit a cell-wise Gaussian distribution at each
decoding position for each target model, and define the likelihood of a
trajectory as the attribution score: if a trajectory exhibits higher
log-likelihood under the distribution of a specific model, it is more likely to
have been generated by that model. Extensive experiments under different
settings validate the utility of our methods.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [24] [Attention-Enhanced Prototypical Learning for Few-Shot Infrastructure Defect Segmentation](https://arxiv.org/abs/2510.05266)
*Christina Thrainer,Md Meftahul Ferdaus,Mahdi Abdelguerfi,Christian Guetl,Steven Sloan,Kendall N. Niles,Ken Pathak*

Main category: cs.CV

> 我们的研究通过改进的特征金字塔网络（E-FPN）和原型学习框架解决了基础设施检测中的少样本语义分割难题，特别是在涵洞和下水道缺陷类别上，表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 当前深度学习框架虽然表现良好，但仍需大量标注数据，且在利用少量数据学习新的缺陷类别方面存在问题。我们的工作针对基础设施检测应用中的少样本语义分割问题，特别是在标记训练样本稀缺且昂贵的情况下。

**Method:** 我们的Enhanced Feature Pyramid Network (E-FPN)框架使用原型学习方法进行涵洞和下水道缺陷类别的少样本语义分割。该方法的主要贡献包括：1) 使用InceptionSepConv块和深度可分离卷积的自适应E-FPN编码器进行高效的多尺度特征提取；2) 使用带掩码平均池化的原型学习，从少量支持样本创建强大的原型；3) 通过全局自注意力、局部自注意力和交叉注意力实现注意力特征表示。

**Result:** 该方法在具有挑战性的基础设施检测数据集上的实验显示了优秀的少样本性能，最佳配置下（8路5样本训练），在2类分类测试中的F1得分为82.55%，mIoU达到72.26%，特别是在自注意力方法中性能有显著改善。

**Conclusion:** 我们的框架解决了基础设施检测系统中快速响应新类型缺陷的需求，特别是在新的训练数据有限的情况下，有助于制定更有效和具有成本效益的关键基础设施维护方案。

**Abstract:** Few-shot semantic segmentation is vital for deep learning-based
infrastructure inspection applications, where labeled training examples are
scarce and expensive. Although existing deep learning frameworks perform well,
the need for extensive labeled datasets and the inability to learn new defect
categories with little data are problematic. We present our Enhanced Feature
Pyramid Network (E-FPN) framework for few-shot semantic segmentation of culvert
and sewer defect categories using a prototypical learning framework. Our
approach has three main contributions: (1) adaptive E-FPN encoder using
InceptionSepConv blocks and depth-wise separable convolutions for efficient
multi-scale feature extraction; (2) prototypical learning with masked average
pooling for powerful prototype generation from small support examples; and (3)
attention-based feature representation through global self-attention, local
self-attention and cross-attention. Comprehensive experimentation on
challenging infrastructure inspection datasets illustrates that the method
achieves excellent few-shot performance, with the best configuration being
8-way 5-shot training configuration at 82.55% F1-score and 72.26% mIoU in 2-way
classification testing. The self-attention method had the most significant
performance improvements, providing 2.57% F1-score and 2.9% mIoU gain over
baselines. Our framework addresses the critical need to rapidly respond to new
defect types in infrastructure inspection systems with limited new training
data that lead to more efficient and economical maintenance plans for critical
infrastructure systems.

</details>


### [25] [SkinMap: Weighted Full-Body Skin Segmentation for Robust Remote Photoplethysmography](https://arxiv.org/abs/2510.05296)
*Zahra Maleki,Amirhossein Akbari,Amirhossein Binesh,Babak Khalaj*

Main category: cs.CV

> 本文提出了一种改进的rPPG方法，通过新的皮肤分割技术来提高准确性，特别是在运动和不同肤色的情况下。

<details>
  <summary>Details</summary>

**Motivation:** 传统的rPPG技术易受到光线和运动的影响。为了提高其准确性，特别是提高其在无监督管道中的表现，本文旨在改善皮肤区域的选择。

**Method:** 提出了一种新的皮肤分割技术，该技术优先考虑皮肤区域以提高提取信号的质量。该方法可以检测全身的皮肤区域，更抗运动干扰，并去除可能引起干扰的区域如嘴巴、眼睛和头发。

**Result:** 实验结果表明，本模型能够在嘈杂条件下如说话和头部旋转时捕获心跳，并保持预测的心率和实际心率之间的平均绝对误差，而其他方法在此类条件下则表现不佳。此外，该模型还能高精度地检测各种肤色。

**Conclusion:** 该技术展示了在种种挑战条件下也能保持高精度，预示着其在实际应用中的巨大潜力。

**Abstract:** Remote photoplethysmography (rPPG) is an innovative method for monitoring
heart rate and vital signs by using a simple camera to record a person, as long
as any part of their skin is visible. This low-cost, contactless approach helps
in remote patient monitoring, emotion analysis, smart vehicle utilization, and
more. Over the years, various techniques have been proposed to improve the
accuracy of this technology, especially given its sensitivity to lighting and
movement. In the unsupervised pipeline, it is necessary to first select skin
regions from the video to extract the rPPG signal from the skin color changes.
We introduce a novel skin segmentation technique that prioritizes skin regions
to enhance the quality of the extracted signal. It can detect areas of skin all
over the body, making it more resistant to movement, while removing areas such
as the mouth, eyes, and hair that may cause interference. Our model is
evaluated on publicly available datasets, and we also present a new dataset,
called SYNC-rPPG, to better represent real-world conditions. The results
indicate that our model demonstrates a prior ability to capture heartbeats in
challenging conditions, such as talking and head rotation, and maintain the
mean absolute error (MAE) between predicted and actual heart rates, while other
methods fail to do so. In addition, we demonstrate high accuracy in detecting a
diverse range of skin tones, making this technique a promising option for
real-world applications.

</details>


### [26] [DeepAf: One-Shot Spatiospectral Auto-Focus Model for Digital Pathology](https://arxiv.org/abs/2510.05315)
*Yousef Yeganeh,Maximilian Frantzen,Michael Lee,Kun-Hsing Yu,Nassir Navab,Azade Farshad*

Main category: cs.CV

> This paper presents DeepAf, a novel auto-focus framework for transforming conventional microscopes into efficient slide scanners, achieving high accuracy and rapid focusing with low input requirements.

<details>
  <summary>Details</summary>

**Motivation:** High costs and accessibility challenges of Whole Slide Imaging (WSI) scanners and limitations of existing low-cost alternatives motivated the development of a more accessible and efficient solution for digital pathology.

**Method:** We introduce DeepAf, a novel auto-focus framework that uses a hybrid architecture to combine spatial and spectral features for predicting focus distance in a single-shot. This system transforms conventional microscopes into efficient slide scanners.

**Result:** The system reduces focusing time by 80% compared to stack-based methods, achieving focus accuracy of 0.18 μm on the same-lab samples. In a clinical study of 536 brain tissue samples, the system achieves 0.90 AUC in cancer classification at 4x magnification, surpassing typical performance at higher magnification. DeepAf exhibits robust cross-lab generalization.

**Conclusion:** DeepAf provides a comprehensive design that offers accessible, real-time, and accurate digital pathology solutions, especially in settings with limited resources, while maintaining diagnostic accuracy.

**Abstract:** While Whole Slide Imaging (WSI) scanners remain the gold standard for
digitizing pathology samples, their high cost limits accessibility in many
healthcare settings. Other low-cost solutions also face critical limitations:
automated microscopes struggle with consistent focus across varying tissue
morphology, traditional auto-focus methods require time-consuming focal stacks,
and existing deep-learning approaches either need multiple input images or lack
generalization capability across tissue types and staining protocols. We
introduce a novel automated microscopic system powered by DeepAf, a novel
auto-focus framework that uniquely combines spatial and spectral features
through a hybrid architecture for single-shot focus prediction. The proposed
network automatically regresses the distance to the optimal focal point using
the extracted spatiospectral features and adjusts the control parameters for
optimal image outcomes. Our system transforms conventional microscopes into
efficient slide scanners, reducing focusing time by 80% compared to stack-based
methods while achieving focus accuracy of 0.18 {\mu}m on the same-lab samples,
matching the performance of dual-image methods (0.19 {\mu}m) with half the
input requirements. DeepAf demonstrates robust cross-lab generalization with
only 0.72% false focus predictions and 90% of predictions within the depth of
field. Through an extensive clinical study of 536 brain tissue samples, our
system achieves 0.90 AUC in cancer classification at 4x magnification, a
significant achievement at lower magnification than typical 20x WSI scans. This
results in a comprehensive hardware-software design enabling accessible,
real-time digital pathology in resource-constrained settings while maintaining
diagnostic accuracy.

</details>


### [27] [Fine-Tuned CNN-Based Approach for Multi-Class Mango Leaf Disease Detection](https://arxiv.org/abs/2510.05326)
*Jalal Ahmmed,Faruk Ahmed,Rashedul Hasan Shohan,Md. Mahabub Rana,Mahdi Hasan*

Main category: cs.CV

> 本研究评估了几种预训练的卷积神经网络用于芒果叶病害多类别识别的效能，DenseNet201表现最佳。研究强调了迁移学习和微调策略在精准可靠的智能农业应用中的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 芒果是南亚重要的水果作物，但其种植常受叶病害影响，这严重影响了产量和质量。因此，本研究旨在开发一种基于深度学习的多类别叶病害识别方法，以提高芒果的生产效率和产品质量。

**Method:** 该研究使用了五种预训练的卷积神经网络（DenseNet201, InceptionV3, ResNet152V2, SeResNet152, 和 Xception）来识别八类芒果叶病害。通过迁移学习和微调策略对这些模型进行评估，使用了包括准确率、精确率、召回率、F1分数和混淆矩阵在内的标准评估指标。

**Result:** DenseNet201在所有测试的模型中表现最佳，准确率达到99.33%，特别是对于Cutting Weevil和Bacterial Canker的识别非常出色。ResNet152V2和SeResNet152也表现良好，相比之下，InceptionV3和Xception在一些视觉上相似的病害类别如Sooty Mould和Powdery Mildew上的表现较差。

**Conclusion:** 研究结果表明，通过迁移学习和微调策略训练的深度学习模型能够有效用于多类芒果叶病害的精准识别，这对智能农业应用具有重要意义。

**Abstract:** Mango is an important fruit crop in South Asia, but its cultivation is
frequently hampered by leaf diseases that greatly impact yield and quality.
This research examines the performance of five pre-trained convolutional neural
networks, DenseNet201, InceptionV3, ResNet152V2, SeResNet152, and Xception, for
multi-class identification of mango leaf diseases across eight classes using a
transfer learning strategy with fine-tuning. The models were assessed through
standard evaluation metrics, such as accuracy, precision, recall, F1-score, and
confusion matrices. Among the architectures tested, DenseNet201 delivered the
best results, achieving 99.33% accuracy with consistently strong metrics for
individual classes, particularly excelling in identifying Cutting Weevil and
Bacterial Canker. Moreover, ResNet152V2 and SeResNet152 provided strong
outcomes, whereas InceptionV3 and Xception exhibited lower performance in
visually similar categories like Sooty Mould and Powdery Mildew. The training
and validation plots demonstrated stable convergence for the highest-performing
models. The capability of fine-tuned transfer learning models, for precise and
dependable multi-class mango leaf disease detection in intelligent agricultural
applications.

</details>


### [28] [Mitigating Diffusion Model Hallucinations with Dynamic Guidance](https://arxiv.org/abs/2510.05356)
*Kostas Triaridis,Alexandros Graikos,Aggelina Chatziagapi,Grigorios G. Chrysos,Dimitris Samaras*

Main category: cs.CV

> 本文提出了动态引导方法来减少扩散模型生成中的幻觉现象，同时保证语义多样性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管扩散模型的演示效果令人印象深刻，但它们通常会产生结构不一致的样本，这些样本超出了真实数据分布的支持范围。这些幻觉往往归因于数据分布模式之间的过度平滑。然而，语义插值通常是可取的，并且可以导致生成多样性。

**Method:** 通过引入动态引导(Dynamic Guidance)，该方法选择性地仅沿预知会产生伪影的方向锐化得分函数，从而减少幻觉的产生，同时保持有效的语义变异。

**Result:** 动态引导显著减少了受控和自然图像数据集上的幻觉，明显优于基线方法。

**Conclusion:** 这是首个在生成阶段而非通过事后过滤来解决幻觉问题的方法。

**Abstract:** Diffusion models, despite their impressive demos, often produce hallucinatory
samples with structural inconsistencies that lie outside of the support of the
true data distribution. Such hallucinations can be attributed to excessive
smoothing between modes of the data distribution. However, semantic
interpolations are often desirable and can lead to generation diversity, thus
we believe a more nuanced solution is required. In this work, we introduce
Dynamic Guidance, which tackles this issue. Dynamic Guidance mitigates
hallucinations by selectively sharpening the score function only along the
pre-determined directions known to cause artifacts, while preserving valid
semantic variations. To our knowledge, this is the first approach that
addresses hallucinations at generation time rather than through post-hoc
filtering. Dynamic Guidance substantially reduces hallucinations on both
controlled and natural image datasets, significantly outperforming baselines.

</details>


### [29] [LightCache: Memory-Efficient, Training-Free Acceleration for Video Generation](https://arxiv.org/abs/2510.05367)
*Yang Xiao,Gen Li,Kaiyuan Deng,Yushu Wu,Zheng Zhan,Yanzhi Wang,Xiaolong Ma,Bo Hui*

Main category: cs.CV

> This paper proposes three strategies for reducing memory consumption in the denoising and decoding stages of diffusion model inference, leading to faster inference speed and lower memory usage without significantly degrading quality.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the issue of substantial memory surges in the denoising and decoding stages of diffusion model inference, which are often observed in cache-based acceleration methods.

**Method:** In this paper, the authors decompose the inference process into encoding, denoising, and decoding stages. They analyze the characteristics of these stages and propose three strategies for reducing memory consumption: Asynchronous Cache Swapping, Feature chunk, and Slicing latents to decode.

**Result:** The proposed approach achieves faster inference speed and lower memory usage, with quality degradation remaining within an acceptable range.

**Conclusion:** The paper concludes that the strategies proposed for stage-specific acceleration can effectively reduce memory consumption while maintaining a balance between speed and quality.

**Abstract:** Training-free acceleration has emerged as an advanced research area in video
generation based on diffusion models. The redundancy of latents in diffusion
model inference provides a natural entry point for acceleration. In this paper,
we decompose the inference process into the encoding, denoising, and decoding
stages, and observe that cache-based acceleration methods often lead to
substantial memory surges in the latter two stages. To address this problem, we
analyze the characteristics of inference across different stages and propose
stage-specific strategies for reducing memory consumption: 1) Asynchronous
Cache Swapping. 2) Feature chunk. 3) Slicing latents to decode. At the same
time, we ensure that the time overhead introduced by these three strategies
remains lower than the acceleration gains themselves. Compared with the
baseline, our approach achieves faster inference speed and lower memory usage,
while maintaining quality degradation within an acceptable range. The Code is
available at https://github.com/NKUShaw/LightCache .

</details>


### [30] [See the past: Time-Reversed Scene Reconstruction from Thermal Traces Using Visual Language Models](https://arxiv.org/abs/2510.05408)
*Kebin Contreras,Luis Toscano-Palomino,Mauro Dalla Mura,Jorge Bacca*

Main category: cs.CV

> 研究提出了一种利用视觉语言模型和受限扩散过程结合RGB和热图像来恢复几秒前场景状态的方法，实现了时间反转成像的可行性。

<details>
  <summary>Details</summary>

**Motivation:** 这项工作旨在通过当前的观测恢复过去的场景状态，特别是在取证和场景分析中有潜在应用价值。通过结合RGB和热成像信息，该研究提供了一种新的方法来推断超过普通RGB相机能力的近期事件。

**Method:** 该研究提出了一种结合视觉语言模型（VLMs）和受限扩散过程的时间反转重建框架，其中一个VLM生成场景描述，另一个引导图像重建，以确保语义和结构的一致性。

**Result:** 该方法在三个受控场景中进行了评估，展示了重建最多120秒之前可信过去的帧的可行性。

**Conclusion:** 这项研究提供了一个从热痕迹中实现时间反转成像的第一步。

**Abstract:** Recovering the past from present observations is an intriguing challenge with
potential applications in forensics and scene analysis. Thermal imaging,
operating in the infrared range, provides access to otherwise invisible
information. Since humans are typically warmer (37 C -98.6 F) than their
surroundings, interactions such as sitting, touching, or leaning leave residual
heat traces. These fading imprints serve as passive temporal codes, allowing
for the inference of recent events that exceed the capabilities of RGB cameras.
This work proposes a time-reversed reconstruction framework that uses paired
RGB and thermal images to recover scene states from a few seconds earlier. The
proposed approach couples Visual-Language Models (VLMs) with a constrained
diffusion process, where one VLM generates scene descriptions and another
guides image reconstruction, ensuring semantic and structural consistency. The
method is evaluated in three controlled scenarios, demonstrating the
feasibility of reconstructing plausible past frames up to 120 seconds earlier,
providing a first step toward time-reversed imaging from thermal traces.

</details>


### [31] [Personalizing Retrieval using Joint Embeddings or "the Return of Fluffy"](https://arxiv.org/abs/2510.05411)
*Bruno Korbar,Andrew Zisserman*

Main category: cs.CV

> 提出了一种新的方法，使用映射网络将图像对象实例信息转换成文本标记，结合自然语言查询进行更好的图像检索。

<details>
  <summary>Details</summary>

**Motivation:** 本文的目标是能够使用结合图像对象实例信息和对该对象所做之事或所在之处的自然文本描述的复合查询来检索图像。

**Method:** 我们设计了一个映射网络，可以将局部图像嵌入（对象实例）“翻译”为文本标记，使该标记与自然语言查询相结合，适用于CLIP风格的文本编码和图像检索。通过一个简单的训练步骤，为每个对象实例生成该文本标记。

**Result:** 我们的方法显示，在两个旨在评估个性化检索的基准测试中，使用可训练的映射网络（称为pi-map）与冻结的CLIP文本和图像编码器的结合，优于当前最先进的方法。

**Conclusion:** 通过设计的pi-map映射网络，实现了使用复合查询进行图像检索，该网络与已有CLIP模型中的文本和图像编码器结合，展示了在个性化检索任务中的优势。

**Abstract:** The goal of this paper is to be able to retrieve images using a compound
query that combines object instance information from an image, with a natural
text description of what that object is doing or where it is. For example, to
retrieve an image of "Fluffy the unicorn (specified by an image) on someone's
head". To achieve this we design a mapping network that can "translate" from a
local image embedding (of the object instance) to a text token, such that the
combination of the token and a natural language query is suitable for CLIP
style text encoding, and image retrieval. Generating a text token in this
manner involves a simple training procedure, that only needs to be performed
once for each object instance. We show that our approach of using a trainable
mapping network, termed pi-map, together with frozen CLIP text and image
encoders, improves the state of the art on two benchmarks designed to assess
personalized retrieval.

</details>


### [32] [ArchitectHead: Continuous Level of Detail Control for 3D Gaussian Head Avatars](https://arxiv.org/abs/2510.05488)
*Peizhi Yan,Rabab Ward,Qiang Tang,Shan Du*

Main category: cs.CV

> 本文提出了一个可以使3D高斯点头像模型支持连续可控LOD效果的框架ArchitectHead，实验验证了该框架在高LOD时的高性能和在低LOD时的效率提升。

<details>
  <summary>Details</summary>

**Motivation:** 尽管现有的3D高斯喷涂（3DGS）能够实时渲染逼真的3D人物头像，但它们通常需要数万个固定数量的3D高斯点，无法灵活调整细节层次。由于实际应用中需要在渲染效率与视觉质量之间找到平衡点，故本文目的在于使头像模型支持连续控制LOD的能力。

**Method:** 本文提出了一种名为ArchitectHead的框架，该框架可以在2D UV特征空间中参数化3D高斯点，并通过一个多级可学习特征图组成的UV特征场来编码这些高斯点的潜在特征。接着，通过一个轻量级的神经网络解码器将这些潜在特征转换为用于渲染的3D高斯属性。通过动态地在不同的分辨率下重新采样特征图，ArchitectHead可以实现对细节层次（LOD）的连续可控调整，且无需重新训练。

**Result:** 实验结果显示，ArchitectHead在最高LOD的自我重现和跨身份重新演绎任务中达到了最先进的质量水平，并在较低的LOD下保持接近最先进的性能。

**Conclusion:** 总的来说，通过ArchitectHead框架，可以高效连续地控制LOD，且在最低LOD下仅使用6.2%的高斯点，同时只中度降低质量，渲染速度几乎翻倍。

**Abstract:** 3D Gaussian Splatting (3DGS) has enabled photorealistic and real-time
rendering of 3D head avatars. Existing 3DGS-based avatars typically rely on
tens of thousands of 3D Gaussian points (Gaussians), with the number of
Gaussians fixed after training. However, many practical applications require
adjustable levels of detail (LOD) to balance rendering efficiency and visual
quality. In this work, we propose "ArchitectHead", the first framework for
creating 3D Gaussian head avatars that support continuous control over LOD. Our
key idea is to parameterize the Gaussians in a 2D UV feature space and propose
a UV feature field composed of multi-level learnable feature maps to encode
their latent features. A lightweight neural network-based decoder then
transforms these latent features into 3D Gaussian attributes for rendering.
ArchitectHead controls the number of Gaussians by dynamically resampling
feature maps from the UV feature field at the desired resolutions. This method
enables efficient and continuous control of LOD without retraining.
Experimental results show that ArchitectHead achieves state-of-the-art (SOTA)
quality in self and cross-identity reenactment tasks at the highest LOD, while
maintaining near SOTA performance at lower LODs. At the lowest LOD, our method
uses only 6.2\% of the Gaussians while the quality degrades moderately (L1 Loss
+7.9\%, PSNR --0.97\%, SSIM --0.6\%, LPIPS Loss +24.1\%), and the rendering
speed nearly doubles.

</details>


### [33] [Human Action Recognition from Point Clouds over Time](https://arxiv.org/abs/2510.05506)
*James Dickens*

Main category: cs.CV

> A new approach for 3D action recognition from point cloud data is introduced, involving segmentation, tracking, and a novel backbone with sparse convolutions. The method shows strong performance on the NTU RGB-D 120 dataset.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to leverage dense 3D data from depth sensors and Lidar for action recognition, offering an alternative to traditional methods like skeletal and video-based approaches.

**Method:** This paper proposes a new method for 3D action recognition from point cloud data, which includes segmenting human point clouds, tracking over time, body part segmentation, and using a novel backbone combining point-based techniques with sparse convolutions on voxel-mapped sequences.

**Result:** The method was tested on the NTU RGB-D 120 dataset and shown to be competitive with current skeletal action recognition methods, achieving 89.3% accuracy when combining sensor-based and estimated depth data.

**Conclusion:** The paper concludes that the new 3D action recognition method is effective, achieving high accuracy and outperforming previous point cloud-based methods with the incorporation of multiple auxiliary features.

**Abstract:** Recent research into human action recognition (HAR) has focused predominantly
on skeletal action recognition and video-based methods. With the increasing
availability of consumer-grade depth sensors and Lidar instruments, there is a
growing opportunity to leverage dense 3D data for action recognition, to
develop a third way. This paper presents a novel approach for recognizing
actions from 3D videos by introducing a pipeline that segments human point
clouds from the background of a scene, tracks individuals over time, and
performs body part segmentation. The method supports point clouds from both
depth sensors and monocular depth estimation. At the core of the proposed HAR
framework is a novel backbone for 3D action recognition, which combines
point-based techniques with sparse convolutional networks applied to
voxel-mapped point cloud sequences. Experiments incorporate auxiliary point
features including surface normals, color, infrared intensity, and body part
parsing labels, to enhance recognition accuracy. Evaluation on the NTU RGB- D
120 dataset demonstrates that the method is competitive with existing skeletal
action recognition algorithms. Moreover, combining both sensor-based and
estimated depth inputs in an ensemble setup, this approach achieves 89.3%
accuracy when different human subjects are considered for training and testing,
outperforming previous point cloud action recognition methods.

</details>


### [34] [Be Tangential to Manifold: Discovering Riemannian Metric for Diffusion Models](https://arxiv.org/abs/2510.05509)
*Shinnosuke Saito,Takashi Matsubara*

Main category: cs.CV

> 该论文针对扩散模型缺乏显式低维度潜在空间的问题，提出了一种在噪声空间中的黎曼度量方式，提升了扩散模型在插值任务中的表现，使之能够生成更加自然和忠实过渡的图像。

<details>
  <summary>Details</summary>

**Motivation:** 该论文的研究动机是解决扩散模型缺乏显式的低维度潜在空间参数化数据流形的缺点。而现有的扩散模型插值方法通常通过高密度区域的路径，这种方法不一定是沿着数据流形的，会导致感知上的不自然过渡。通过拥抱扩散模型所学习的数据流形，该研究旨在通过新的方法改善插值过渡。

**Method:** 该论文的方法是提出了一种新颖的黎曼度量方式，在噪声空间中应用该度量方式能促使测地线保持在或者平行于已学习的数据流形上。该方法是受到最近发现的分数函数的雅可比矩阵能捕捉局部数据流形的切空间的启发。

**Result:** 该论文的实验结果表明，他们提出的黎曼度量在噪声空间中生成的图像插值过渡比现有的基于密度的方法和简单的基线方法更加自然和准确。

**Conclusion:** 该论文得出结论，他们所提出的在噪声空间中的黎曼度量方法能够使得扩散模型更好地捕捉到数据流形的信息，并在图像插值任务中产生更加自然和忠实的过渡。

**Abstract:** Diffusion models are powerful deep generative models (DGMs) that generate
high-fidelity, diverse content. However, unlike classical DGMs, they lack an
explicit, tractable low-dimensional latent space that parameterizes the data
manifold. This absence limits manifold-aware analysis and operations, such as
interpolation and editing. Existing interpolation methods for diffusion models
typically follow paths through high-density regions, which are not necessarily
aligned with the data manifold and can yield perceptually unnatural
transitions. To exploit the data manifold learned by diffusion models, we
propose a novel Riemannian metric on the noise space, inspired by recent
findings that the Jacobian of the score function captures the tangent spaces to
the local data manifold. This metric encourages geodesics in the noise space to
stay within or run parallel to the learned data manifold. Experiments on image
interpolation show that our metric produces perceptually more natural and
faithful transitions than existing density-based and naive baselines.

</details>


### [35] [Teamwork: Collaborative Diffusion with Low-rank Coordination and Adaptation](https://arxiv.org/abs/2510.05532)
*Sam Sartor,Pieter Peers*

Main category: cs.CV

> 本论文主要提出了Teamwork，一种灵活和高效的解决方案，它可以通过协调和适应多个基础扩散模型实例来扩展通道数量，用于多种图像处理任务，支持队友的动态（去）激活。

<details>
  <summary>Details</summary>

**Motivation:** 大型预训练扩散模型可以提供用于许多图形应用的强大先验。然而，对于生成性应用（如神经渲染和逆方法，例如SVBRDF估计和内在图像分解）来说，需要额外的输入或输出通道。当前的通道扩展解决方案往往是针对具体应用的，这些解决方案可能难以适应不同的扩散模型或新任务。因此，研究动机在于提出一个灵活且高效的统一解决方案来解决这些问题。

**Method:** 本研究引入了Teamwork：一种灵活且高效的统一解决方案，用于同时增加输入和输出通道数量，并针对新任务调整预训练扩散模型。Teamwork通过协调和适应多个基础扩散模型实例（即队友）实现通道扩展，而不改变预训练扩散模型的架构。研究采用了低秩适应（LoRA）的新型变体来解决适应和不同队友之间的协调问题。此外，Teamwork支持队友的动态（去）激活。

**Result:** 本研究通过多个生成和逆图形任务（如图像修复、单图像SVBRDF估计、内在图像分解、神经着色和内在图像合成）来证明了Teamwork的灵活性和高效率。

**Conclusion:** 实验结果显示，Teamwork在多种生成和逆图形任务（如图像修复、单图像SVBRDF估计、内在图像分解、神经着色和内在图像合成）上展示了其灵活性和高效率。

**Abstract:** Large pretrained diffusion models can provide strong priors beneficial for
many graphics applications. However, generative applications such as neural
rendering and inverse methods such as SVBRDF estimation and intrinsic image
decomposition require additional input or output channels. Current solutions
for channel expansion are often application specific and these solutions can be
difficult to adapt to different diffusion models or new tasks. This paper
introduces Teamwork: a flexible and efficient unified solution for jointly
increasing the number of input and output channels as well as adapting a
pretrained diffusion model to new tasks. Teamwork achieves channel expansion
without altering the pretrained diffusion model architecture by coordinating
and adapting multiple instances of the base diffusion model (\ie, teammates).
We employ a novel variation of Low Rank-Adaptation (LoRA) to jointly address
both adaptation and coordination between the different teammates. Furthermore
Teamwork supports dynamic (de)activation of teammates. We demonstrate the
flexibility and efficiency of Teamwork on a variety of generative and inverse
graphics tasks such as inpainting, single image SVBRDF estimation, intrinsic
decomposition, neural shading, and intrinsic image synthesis.

</details>


### [36] [Seeing the Big Picture: Evaluating Multimodal LLMs' Ability to Interpret and Grade Handwritten Student Work](https://arxiv.org/abs/2510.05538)
*Owen Henkel,Bill Roberts,Doug Jaffe,Laurence Holt*

Main category: cs.CV

> 研究探讨了多模态大型语言模型在评估手写数学作业和插图方面的表现。模型在评估算术题答案上有接近人类的准确率，但在直接受换单纯插图进行评估时遇到困难。辅助人类描述插图后，模型表现有所提升。

<details>
  <summary>Details</summary>

**Motivation:** 随着多模态大型语言模型（MLLMs）的最新进展，研究它们在评估、分析并提供学生手写作业反馈方面的潜力变得十分重要。特别是在小学和初中数学教育中，这种能力尤为有益，因为看到学生问题的解答步骤可以提供有价值的洞察，尽管这需要大量的时间来批改。

**Method:** 研究通过两个实验探讨了多模态大型语言模型（MLLMs）在评估和分析手写学生作业方面的应用。实验A分析了来自加纳中学生解决算术题的288份手写答案。实验B评估了来自美国小学生的150份数学插图，这些插图作为题目的答案，并且需要复杂的视觉解释和教学判断来分析评价。研究尝试将MLLMs的视觉能力与其教学能力分开，通过直接评估学生插图以及用详细的人类描述辅助MLLMs评估。

**Result:** 实验A中模型在判断算术题的答案上的准确率为95%，但仍存在一些人类教育者很少会犯的错误。实验B中，直接分析插图时模型的准确率较低，为0.20，当辅助人类描述后，准确率显著提高到0.47，与人与人之间的评分水平相当。

**Conclusion:** 研究结果表明，MLLMs在解释算术作业方面做得相对较好，但在识别和评估学生数学插图方面仍有挑战。

**Abstract:** Recent advances in multimodal large language models (MLLMs) raise the
question of their potential for grading, analyzing, and offering feedback on
handwritten student classwork. This capability would be particularly beneficial
in elementary and middle-school mathematics education, where most work remains
handwritten, because seeing students' full working of a problem provides
valuable insights into their learning processes, but is extremely
time-consuming to grade. We present two experiments investigating MLLM
performance on handwritten student mathematics classwork. Experiment A examines
288 handwritten responses from Ghanaian middle school students solving
arithmetic problems with objective answers. In this context, models achieved
near-human accuracy (95%, k = 0.90) but exhibited occasional errors that human
educators would be unlikely to make. Experiment B evaluates 150 mathematical
illustrations from American elementary students, where the drawings are the
answer to the question. These tasks lack single objective answers and require
sophisticated visual interpretation as well as pedagogical judgment in order to
analyze and evaluate them. We attempted to separate MLLMs' visual capabilities
from their pedagogical abilities by first asking them to grade the student
illustrations directly, and then by augmenting the image with a detailed human
description of the illustration. We found that when the models had to analyze
the student illustrations directly, they struggled, achieving only k = 0.20
with ground truth scores, but when given human descriptions, their agreement
levels improved dramatically to k = 0.47, which was in line with human-to-human
agreement levels. This gap suggests MLLMs can "see" and interpret arithmetic
work relatively well, but still struggle to "see" student mathematical
illustrations.

</details>


### [37] [Midway Network: Learning Representations for Recognition and Motion from Latent Dynamics](https://arxiv.org/abs/2510.05558)
*Christopher Hoang,Mengye Ren*

Main category: cs.CV

> Midway Network 是一种新的自我监督学习架构，首次仅通过自然视频学习对象识别和运动理解的强大视觉表示，通过扩展潜在动态建模到这个领域实现这一目标，它在语义分割和光流任务中表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自我监督学习方法已经表明它们可以从无标签数据中学习，但主要集中在获取丰富的识别或运动表示，而不是两者兼备。因此，Midway Network 的目标是仅通过自然视频，同时学习强大的对象识别和运动理解视觉表示。

**Method:** 通过扩展潜在动态建模到这个领域，Midway Network 采用了中间的自顶向下路径推断视频帧之间的运动潜变量，并使用密集的前向预测目标和分层结构来处理自然视频中的复杂多目标场景。

**Result:** 研究结果表明，Midway Network 在两个大型自然视频数据集上预先训练之后，在语义分割和光流任务中相对于先前的自我监督学习方法表现出强大的性能。

**Conclusion:** Midway Network 的学习动态能够通过一种基于前向特征扰动的新分析方法捕捉高层次的对应关系。

**Abstract:** Object recognition and motion understanding are key components of perception
that complement each other. While self-supervised learning methods have shown
promise in their ability to learn from unlabeled data, they have primarily
focused on obtaining rich representations for either recognition or motion
rather than both in tandem. On the other hand, latent dynamics modeling has
been used in decision making to learn latent representations of observations
and their transformations over time for control and planning tasks. In this
work, we present Midway Network, a new self-supervised learning architecture
that is the first to learn strong visual representations for both object
recognition and motion understanding solely from natural videos, by extending
latent dynamics modeling to this domain. Midway Network leverages a midway
top-down path to infer motion latents between video frames, as well as a dense
forward prediction objective and hierarchical structure to tackle the complex,
multi-object scenes of natural videos. We demonstrate that after pretraining on
two large-scale natural video datasets, Midway Network achieves strong
performance on both semantic segmentation and optical flow tasks relative to
prior self-supervised learning methods. We also show that Midway Network's
learned dynamics can capture high-level correspondence via a novel analysis
method based on forward feature perturbation.

</details>


### [38] [HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video](https://arxiv.org/abs/2510.05560)
*Hongchi Xia,Chih-Hao Lin,Hao-Yu Hsu,Quentin Leboutet,Katelyn Gao,Michael Paulitsch,Benjamin Ummenhofer,Shenlong Wang*

Main category: cs.CV

> HoloScene是一种新型的交互式3D重建框架，它通过优化目标函数来实现几何、物理和渲染的高效重建，适用于多种应用场合。

<details>
  <summary>Details</summary>

**Motivation:** 当前的3D重建和场景理解方法在几何完整性、对象交互性、物理合理性等多个方面通常存在不足。为了解决这些问题，提出了HoloScene。

**Method:** HoloScene采用了一种基于能量优化的方法来进行3D重建，该方法将观察数据、物理约束和生成性先验集成到一个统一的目标函数中，通过结合基于采样的探索和基于梯度的细化来高效地进行优化。

**Result:** 实验结果表明，在多个基准数据集上的评估显示了HoloScene的优越性能，同时在互动游戏和实时数字孪生操作中的应用也展示了其广泛适用性和有效性。

**Conclusion:** HoloScene可以创建出几何完整精准、物理稳定、视点变化下渲染逼真的数字孪生，体现了该框架对于复杂重建问题的处理能力。

**Abstract:** Digitizing the physical world into accurate simulation-ready virtual
environments offers significant opportunities in a variety of fields such as
augmented and virtual reality, gaming, and robotics. However, current 3D
reconstruction and scene-understanding methods commonly fall short in one or
more critical aspects, such as geometry completeness, object interactivity,
physical plausibility, photorealistic rendering, or realistic physical
properties for reliable dynamic simulation. To address these limitations, we
introduce HoloScene, a novel interactive 3D reconstruction framework that
simultaneously achieves these requirements. HoloScene leverages a comprehensive
interactive scene-graph representation, encoding object geometry, appearance,
and physical properties alongside hierarchical and inter-object relationships.
Reconstruction is formulated as an energy-based optimization problem,
integrating observational data, physical constraints, and generative priors
into a unified, coherent objective. Optimization is efficiently performed via a
hybrid approach combining sampling-based exploration with gradient-based
refinement. The resulting digital twins exhibit complete and precise geometry,
physical stability, and realistic rendering from novel viewpoints. Evaluations
conducted on multiple benchmark datasets demonstrate superior performance,
while practical use-cases in interactive gaming and real-time digital-twin
manipulation illustrate HoloScene's broad applicability and effectiveness.
Project page: https://xiahongchi.github.io/HoloScene.

</details>


### [39] [CalibCLIP: Contextual Calibration of Dominant Semantics for Text-Driven Image Retrieval](https://arxiv.org/abs/2510.05586)
*Bin Kang,Bin Chen,Junjie Wang,Yulin Li,Junzhi Zhao,Zhuotao Tian*

Main category: cs.CV

> 本文提出了一种无需训练的CalibCLIP方法，通过对比视觉增强器（CVE）和辨别性概念校准器（DCC）解决了视觉语言模型（VLMs）中少数低贡献Token过度捕获全局语义的问题，实验表明该方法在不同图像检索任务中的基准测试上表现优异。

<details>
  <summary>Details</summary>

**Motivation:** 现有视觉语言模型（VLMs）由于结构限制，少数低贡献Token过度影响全局语义，主导信息聚合过程，抑制文本驱动图像检索任务中的辨别性特征。

**Method:** 针对现有视觉语言模型（VLMs）中少数低贡献Token过度捕获全局语义的问题，本文提出了CalibCLIP，一种无需训练的校准方法。具体来说，在视觉空间中，提出了对比视觉增强器（CVE），将视觉特征分解为目标区域和低信息区域，识别出主导Token，并动态抑制其表达。在文本空间中，引入了辨别性概念校准器（DCC），旨在区分文本查询中的通用概念和辨别性概念，削弱通用概念的挑战，强化辨别性概念的表达，从而增强相似样本间的差异化。

**Result:** 实验结果证明，CalibCLIP在七个跨三种图像检索任务的基准测试中均表现出一致的改进效果。

**Conclusion:** 代码已开源，证明了CalibCLIP的有效性。

**Abstract:** Existing Visual Language Models (VLMs) suffer structural limitations where a
few low contribution tokens may excessively capture global semantics,
dominating the information aggregation process and suppressing the
discriminative features in text-driven image retrieval tasks. To address this,
we introduce \textbf{CalibCLIP}, a training-free method designed to calibrate
the suppressive effect of dominant tokens. Specifically, in the visual space,
we propose the Contrastive Visual Enhancer (CVE), which decouples visual
features into target and low information regions. Subsequently, it identifies
dominant tokens and dynamically suppresses their representations.In the textual
space, we introduce the Discriminative Concept Calibrator (DCC), which aims to
differentiate between general and discriminative concepts within the text
query. By mitigating the challenges posed by generic concepts and improving the
representations of discriminative concepts, DCC strengthens the differentiation
among similar samples. Finally, extensive experiments demonstrate consistent
improvements across seven benchmarks spanning three image retrieval tasks,
underscoring the effectiveness of CalibCLIP. Code is available at:
https://github.com/kangbin98/CalibCLIP

</details>


### [40] [Improving Chain-of-Thought Efficiency for Autoregressive Image Generation](https://arxiv.org/abs/2510.05593)
*Zeqi Gu,Markos Georgopoulos,Xiaoliang Dai,Marjan Ghazvininejad,Chu Wang,Felix Juefei-Xu,Kunpeng Li,Yujun Shi,Zecheng He,Zijian He,Jiawei Zhou,Abe Davis,Jialiang Wang*

Main category: cs.CV

> The paper introduces ShortCoTI, an optimization framework that reduces unnecessary redundancy in image generation, thus improving computational efficiency without compromising image quality.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to address the issue of visual overthinking, which introduces unnecessary redundancy, increases computational costs, and can introduce details that contradict the original prompt in image generation.

**Method:** ShortCoTI is introduced as a lightweight optimization framework that encourages more concise chain-of-thought (CoT) sequences while preserving output image quality in autoregressive multimodal large language models used for image generation.

**Result:** Incorporating ShortCoTI into a reinforcement learning paradigm reduces prompt reasoning length by 54% while maintaining or slightly improving quality metrics across multiple benchmarks (T2I-CompBench, GenEval).

**Conclusion:** ShortCoTI improves computational efficiency without compromising the fidelity or visual appeal of generated images by eliminating verbose explanations and repetitive refinements in reasoning prompts.

**Abstract:** Autoregressive multimodal large language models have recently gained
popularity for image generation, driven by advances in foundation models. To
enhance alignment and detail, newer approaches employ chain-of-thought (CoT)
reasoning, expanding user inputs into elaborated prompts prior to image
synthesis. However, this strategy can introduce unnecessary redundancy -- a
phenomenon we call visual overthinking -- which increases computational costs
and can introduce details that contradict the original prompt. In this work, we
explore how to generate more concise CoT sequences for more efficient image
generation. We introduce ShortCoTI, a lightweight optimization framework that
encourages more concise CoT while preserving output image quality. ShortCoTI
rewards more concise prompts with an adaptive function that scales according to
an estimated difficulty for each task. Incorporating this reward into a
reinforcement learning paradigm reduces prompt reasoning length by 54% while
maintaining or slightly improving quality metrics across multiple benchmarks
(T2I-CompBench, GenEval). Qualitative analysis shows that our method eliminates
verbose explanations and repetitive refinements, producing reasoning prompts
that are both concise and semantically rich. As a result, ShortCoTI improves
computational efficiency without compromising the fidelity or visual appeal of
generated images.

</details>


### [41] [HOI-R1: Exploring the Potential of Multimodal Large Language Models for Human-Object Interaction Detection](https://arxiv.org/abs/2510.05609)
*Junwen Chen,Peilin Xiong,Keiji Yanai*

Main category: cs.CV

> 本文提出HOI-R1方法，基于强化学习无需额外检测模块解决了HOI检测任务，在HICO-DET数据集上达到了基线方法两倍的准确率。

<details>
  <summary>Details</summary>

**Motivation:** 当前HOI检测方法高度依赖VLMs的知识，但在将这些知识与目标检测模块的HOI实例表示连接的训练策略和模型架构方面颇为复杂。同时，多语种语言模型在HOI检测任务中的固有的推理能力还未得到充分探索。因此，本文旨在利用强化学习方法训练MLLMs来探索解决HOI任务的新方法。

**Method:** 本文提出了一种新的方法HOI-R1，首次探索了语言模型在HOI检测任务上的潜力，无需额外的检测模块。通过引入HOI推理过程和HOI检测奖励函数，该方法仅使用文本解决了HOI检测的问题。

**Result:** 实验结果表明，HOI-R1在HICO-DET数据集上达到了基线方法两倍的准确率，并具有很好的泛化能力。

**Conclusion:** HOI-R1展示了一种新的方法，可以直接通过文本处理解决HOI检测任务，且无需复杂的模块连接，显示出巨大的潜力和发展空间。

**Abstract:** Recent Human-object interaction detection (HOID) methods highly require prior
knowledge from VLMs to enhance the interaction recognition capabilities. The
training strategies and model architectures for connecting the knowledge from
VLMs to the HOI instance representations from the object detector are
challenging, and the whole framework is complex for further development or
application. On the other hand, the inherent reasoning abilities of MLLMs on
human-object interaction detection are under-explored. Inspired by the recent
success of training MLLMs with reinforcement learning (RL) methods, we propose
HOI-R1 and first explore the potential of the language model on the HOID task
without any additional detection modules. We introduce an HOI reasoning process
and HOID reward functions to solve the HOID task by pure text. The results on
the HICO-DET dataset show that HOI-R1 achieves 2x the accuracy of the baseline
with great generalization ability. The source code is available at
https://github.com/cjw2021/HOI-R1.

</details>


### [42] [Efficient Conditional Generation on Scale-based Visual Autoregressive Models](https://arxiv.org/abs/2510.05610)
*Jiaqi Liu,Tao Huang,Chang Xu*

Main category: cs.CV

> 提出了一种能够在不显著增加训练成本的前提下，实现复杂图像生成控制的高效控制模型（ECM），相较现有基线方法，实现了更高的训练和推理效率。

<details>
  <summary>Details</summary>

**Motivation:** 针对现有自回归（AR）模型在复杂的空间条件生成中需要精细调整预训练模型，导致高昂的训练成本的问题，提出了新型框架来优化训练效率和生成控制。

**Method:** 提出了一种称为高效控制模型（ECM）的即插即用框架。该框架具有一个轻量级的控制模块，通过分布式架构引入控制信号。这种架构包括上下文感知注意力层，利用实时生成的标记微调条件特征，并设计了一个共享门控前馈网络（FFN），旨在最大化其有限容量的利用率，并确保连贯的控制特征学习。此外，为了优先学习早期控制序列，提出了一种以早期为中心的采样策略，减少了每次迭代的训练标记数量，而推理过程中的温度计划则补偿了后期标记训练不足的问题。

**Result:** 实验验证了在尺度基AR模型上，方法能够在降低训练标记数量的同时，实现高保真度和多样化的图像生成控制，优于现有基线方法，并显著提高了训练和推理效率。

**Conclusion:** 该研究展示了一种可行的方法，通过优化的控制模块和策略，在控制空间条件生成上的训练效率和效果方面，自回归模型有望与扩散模型相媲美，同时减少了计算成本、提升了控制能力。

**Abstract:** Recent advances in autoregressive (AR) models have demonstrated their
potential to rival diffusion models in image synthesis. However, for complex
spatially-conditioned generation, current AR approaches rely on fine-tuning the
pre-trained model, leading to significant training costs. In this paper, we
propose the Efficient Control Model (ECM), a plug-and-play framework featuring
a lightweight control module that introduces control signals via a distributed
architecture. This architecture consists of context-aware attention layers that
refine conditional features using real-time generated tokens, and a shared
gated feed-forward network (FFN) designed to maximize the utilization of its
limited capacity and ensure coherent control feature learning. Furthermore,
recognizing the critical role of early-stage generation in determining semantic
structure, we introduce an early-centric sampling strategy that prioritizes
learning early control sequences. This approach reduces computational cost by
lowering the number of training tokens per iteration, while a complementary
temperature scheduling during inference compensates for the resulting
insufficient training of late-stage tokens. Extensive experiments on
scale-based AR models validate that our method achieves high-fidelity and
diverse control over image generation, surpassing existing baselines while
significantly improving both training and inference efficiency.

</details>


### [43] [PointNSP: Autoregressive 3D Point Cloud Generation with Next-Scale Level-of-Detail Prediction](https://arxiv.org/abs/2510.05613)
*Ziqiao Meng,Qichao Wang,Zhiyang Dou,Zixing Song,Zhipeng Zhou,Irwin King,Peilin Zhao*

Main category: cs.CV

> PointNSP解决了自回归点云生成中的顺序偏见问题，通过一种从粗到细的生成方法，在多尺度下实现了高质量的点云生成，达到新的技术高峰。

<details>
  <summary>Details</summary>

**Motivation:** 自回归点云生成方法由于强加了固有的人造顺序，与无序的点集不符，导致在生成质量上长期落后于扩散方法。这种顺序偏见强调了短程连续性，但削弱了模型捕捉长程依赖的能力，影响全局结构属性的生成。

**Method:** 提出了PointNSP框架，这是一个从粗到细的生成模型，它在低分辨率下保持全局形状结构，并通过下一尺度预测逐步在更高尺度上细化精细几何。这个多尺度分解使得自回归目标与点集的排列不变性相一致，同时避免了固定顺序的脆弱性。

**Result:** 实验表明，PointNSP在ShapeNet数据集上首次建立自回归范式的生成质量最新水准。它在参数、训练和推断效率上超过了强大的扩散基准模型。此外，在生成8,192个点的密集点云时，PointNSP的优势更为显著。

**Conclusion:** 通过提出PointNSP，改进了自回归模型生成点云的质量，使其首次达到了某一领域的最先进水平，同时还在效率方面超过了某些扩散模型。

**Abstract:** Autoregressive point cloud generation has long lagged behind diffusion-based
approaches in quality. The performance gap stems from the fact that
autoregressive models impose an artificial ordering on inherently unordered
point sets, forcing shape generation to proceed as a sequence of local
predictions. This sequential bias emphasizes short-range continuity but
undermines the model's capacity to capture long-range dependencies, hindering
its ability to enforce global structural properties such as symmetry,
consistent topology, and large-scale geometric regularities. Inspired by the
level-of-detail (LOD) principle in shape modeling, we propose PointNSP, a
coarse-to-fine generative framework that preserves global shape structure at
low resolutions and progressively refines fine-grained geometry at higher
scales through a next-scale prediction paradigm. This multi-scale factorization
aligns the autoregressive objective with the permutation-invariant nature of
point sets, enabling rich intra-scale interactions while avoiding brittle fixed
orderings. Experiments on ShapeNet show that PointNSP establishes
state-of-the-art (SOTA) generation quality for the first time within the
autoregressive paradigm. In addition, it surpasses strong diffusion-based
baselines in parameter, training, and inference efficiency. Finally, in dense
generation with 8,192 points, PointNSP's advantages become even more
pronounced, underscoring its scalability potential.

</details>


### [44] [TFM Dataset: A Novel Multi-task Dataset and Integrated Pipeline for Automated Tear Film Break-Up Segmentation](https://arxiv.org/abs/2510.05615)
*Guangrong Wan,Jun liu,Tang tang,Lianghao Shi,Wenjun Luo,TingTing Xu*

Main category: cs.CV

> 本文提出TFM数据集和TF-Net模型，用于泪膜破裂的自动分析，进一步实现了一整套自动化分析流程TF-Collab，以提升干眼症诊断的准确性和效率。

<details>
  <summary>Details</summary>

**Motivation:** 针对自动泪膜破裂分析的困难，由于缺乏注释数据集和综合解决方案，文章旨在开发一种新的数据集和模型来提高诊断干眼综合征的效率和准确性。

**Method:** 本文介绍了TFM数据集，这是首个用于多任务泪膜分析的综合数据集。基于该数据集，作者提出了TF-Net，一个高效的基础分割模型，它通过改进特征金字塔网络来平衡准确性与计算效率。此外，还设计了TF-Collab，一个结合所有三项任务的实时集成管道，进一步自动化分析流程。

**Result:** 基准性能评估显示，TF-Net在TFM分割子集上相对于多种最先进的医学图像分割模型具备竞争优势。实验结果证明了TF-Net和TF-Collab的有效性，成功自动化泪膜分析流程。

**Conclusion:** 实验结果证明所提出的TF-Net和TF-Collab的有效性，为眼表诊断未来的研究奠定了基础。

**Abstract:** Tear film break-up (TFBU) analysis is critical for diagnosing dry eye
syndrome, but automated TFBU segmentation remains challenging due to the lack
of annotated datasets and integrated solutions. This paper introduces the Tear
Film Multi-task (TFM) Dataset, the first comprehensive dataset for multi-task
tear film analysis, comprising 15 high-resolution videos (totaling 6,247
frames) annotated with three vision tasks: frame-level classification ('clear',
'closed', 'broken', 'blur'), Placido Ring detection, and pixel-wise TFBU area
segmentation. Leveraging this dataset, we first propose TF-Net, a novel and
efficient baseline segmentation model. TF-Net incorporates a MobileOne-mini
backbone with re-parameterization techniques and an enhanced feature pyramid
network to achieve a favorable balance between accuracy and computational
efficiency for real-time clinical applications. We further establish benchmark
performance on the TFM segmentation subset by comparing TF-Net against several
state-of-the-art medical image segmentation models. Furthermore, we design
TF-Collab, a novel integrated real-time pipeline that synergistically leverages
models trained on all three tasks of the TFM dataset. By sequentially
orchestrating frame classification for BUT determination, pupil region
localization for input standardization, and TFBU segmentation, TF-Collab fully
automates the analysis. Experimental results demonstrate the effectiveness of
the proposed TF-Net and TF-Collab, providing a foundation for future research
in ocular surface diagnostics. Our code and the TFM datasets are available at
https://github.com/glory-wan/TF-Net

</details>


### [45] [InstaGeo: Compute-Efficient Geospatial Machine Learning from Data to Deployment](https://arxiv.org/abs/2510.05617)
*Ibrahim Salihu Yusuf,Iffanice Houndayi,Rym Oualha,Mohamed Aziz Cherif,Kobby Panford-Quainoo,Arnu Pretorius*

Main category: cs.CV

> The paper presents InstaGeo, an open-source, end-to-end framework that overcomes limitations in deploying geospatial foundation models by integrating automated data curation, model distillation, and seamless deployment.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind the paper is to address the challenges of automated geospatial data pipelines and the large size of fine-tuned models, which limit the deployment of geospatial foundation models (GFMs) for humanitarian and environmental applications.

**Method:** The paper introduces InstaGeo, an end-to-end framework that integrates automated data curation, task-specific model distillation, and seamless deployment. It transforms raw satellite imagery into model-ready datasets and produces compact models with minimal accuracy loss, suitable for real-time Earth observation.

**Result:** The distilled models in InstaGeo are up to 8x smaller than standard fine-tuned counterparts, reducing FLOPs and CO2 emissions. Reproduced datasets for flood mapping, crop segmentation, and desert locust prediction show only marginal drops in accuracy. A new crop segmentation dataset achieves a state-of-the-art mIoU of 60.65%.

**Conclusion:** InstaGeo transforms research-grade GFMs into practical, low-carbon tools by unifying data preparation, model compression, and deployment. The approach shifts geospatial AI toward innovation driven by data quality and application needs, enabling the processing from raw data to model deployment in just one working day.

**Abstract:** Open-access multispectral imagery from missions like Landsat 8-9 and
Sentinel-2 has fueled the development of geospatial foundation models (GFMs)
for humanitarian and environmental applications. Yet, their deployment remains
limited by (i) the absence of automated geospatial data pipelines and (ii) the
large size of fine-tuned models. Existing GFMs lack workflows for processing
raw satellite imagery, and downstream adaptations often retain the full
complexity of the original encoder.
  We present InstaGeo, an open-source, end-to-end framework that addresses
these challenges by integrating: (1) automated data curation to transform raw
imagery into model-ready datasets; (2) task-specific model distillation to
derive compact, compute-efficient models; and (3) seamless deployment as
interactive web-map applications. Using InstaGeo, we reproduced datasets from
three published studies and trained models with marginal mIoU differences of
-0.73 pp for flood mapping, -0.20 pp for crop segmentation, and +1.79 pp for
desert locust prediction. The distilled models are up to 8x smaller than
standard fine-tuned counterparts, reducing FLOPs and CO2 emissions with minimal
accuracy loss.
  Leveraging InstaGeo's streamlined data pipeline, we also curated a larger
crop segmentation dataset, achieving a state-of-the-art mIoU of 60.65%, a 12 pp
improvement over prior baselines. Moreover, InstaGeo enables users to progress
from raw data to model deployment within a single working day.
  By unifying data preparation, model compression, and deployment, InstaGeo
transforms research-grade GFMs into practical, low-carbon tools for real-time,
large-scale Earth observation. This approach shifts geospatial AI toward data
quality and application-driven innovation. Source code, datasets, and model
checkpoints are available at:
https://github.com/instadeepai/InstaGeo-E2E-Geospatial-ML.git

</details>


### [46] [Beyond Spectral Peaks: Interpreting the Cues Behind Synthetic Image Detection](https://arxiv.org/abs/2510.05633)
*Sara Mandelli,Diego Vila-Portela,David Vázquez-Padín,Paolo Bestagini,Fernando Pérez-González*

Main category: cs.CV

> 本文研究了图像检测器是否依赖频谱峰值，并发现大多数检测器并不依赖频谱峰值，从而提出了一个简单线性检测器作为基线，以提高可解释性。

<details>
  <summary>Details</summary>

**Motivation:** 目前最先进的检测器通常作为黑箱使用，不清楚它们是否真正依赖这些峰值。这限制了它们的可解释性和信任度。为了应对这一问题，我们进行了系统性的研究。

**Method:** 我们提出了一种策略来从图像中移除频谱峰值，并分析了这一操作对多个检测器的影响。此外，我们引入了一种仅依赖频率峰值的简单线性检测器，作为完全可解释的基线，不受深度学习混淆的影响。

**Result:** 我们的研究结果显示，大多数检测器并非从根本上依赖于频谱峰值，这挑战了该领域的广泛假设，并为开发更加透明和可靠的取证工具铺平了道路。

**Conclusion:** 我们的研究挑战了检测器依赖频谱峰值的假设，并提出了一种新的检测器，这对于开发更透明和可信赖的图像检测工具具有重要意义。

**Abstract:** Over the years, the forensics community has proposed several deep
learning-based detectors to mitigate the risks of generative AI. Recently,
frequency-domain artifacts (particularly periodic peaks in the magnitude
spectrum), have received significant attention, as they have been often
considered a strong indicator of synthetic image generation. However,
state-of-the-art detectors are typically used as black-boxes, and it still
remains unclear whether they truly rely on these peaks. This limits their
interpretability and trust. In this work, we conduct a systematic study to
address this question. We propose a strategy to remove spectral peaks from
images and analyze the impact of this operation on several detectors. In
addition, we introduce a simple linear detector that relies exclusively on
frequency peaks, providing a fully interpretable baseline free from the
confounding influence of deep learning. Our findings reveal that most detectors
are not fundamentally dependent on spectral peaks, challenging a widespread
assumption in the field and paving the way for more transparent and reliable
forensic tools.

</details>


### [47] [Combined Hyperbolic and Euclidean Soft Triple Loss Beyond the Single Space Deep Metric Learning](https://arxiv.org/abs/2510.05643)
*Shozo Saeki,Minoru Kawahara,Hirohisa Aman*

Main category: cs.CV

> 本文提出 CHEST 损失，以改进基于代理的损失在双曲空间中的应用，提升深度度量学习的性能，导致在四个基准数据集上表现优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 研发 CHEST 损失的原因在于弥补基于代理的损失在双曲空间应用上的空白，并改进大规模数据集的度量学习，以减少训练复杂度。

**Method:** CHEST loss 结合了双曲空间和欧式空间的基于代理的损失以及基于双曲层次聚类的正则化损失，旨在改善深度度量学习的准确性与学习稳定性。

**Result:** 在四个基准数据集上的评估中，CHEST 损失达到了新的最先进性能。

**Conclusion:** 结合双曲和欧式空间的 CHEST 损失能够有效提高深度度量学习的准确性和学习稳定性。

**Abstract:** Deep metric learning (DML) aims to learn a neural network mapping data to an
embedding space, which can represent semantic similarity between data points.
Hyperbolic space is attractive for DML since it can represent richer
structures, such as tree structures. DML in hyperbolic space is based on
pair-based loss or unsupervised regularization loss. On the other hand,
supervised proxy-based losses in hyperbolic space have not been reported yet
due to some issues in applying proxy-based losses in a hyperbolic space.
However, proxy-based losses are attractive for large-scale datasets since they
have less training complexity. To address these, this paper proposes the
Combined Hyperbolic and Euclidean Soft Triple (CHEST) loss. CHEST loss is
composed of the proxy-based losses in hyperbolic and Euclidean spaces and the
regularization loss based on hyperbolic hierarchical clustering. We find that
the combination of hyperbolic and Euclidean spaces improves DML accuracy and
learning stability for both spaces. Finally, we evaluate the CHEST loss on four
benchmark datasets, achieving a new state-of-the-art performance.

</details>


### [48] [Ocular-Induced Abnormal Head Posture: Diagnosis and Missing Data Imputation](https://arxiv.org/abs/2510.05649)
*Saja Al-Dabet,Sherzod Turaev,Nazar Zaki,Arif O. Khan,Luai Eldweik*

Main category: cs.CV

> 文章提出了两种深度学习框架来改善AHP的自动化诊断和处理数据缺失问题，实验结果表现出色，证实了其临床应用价值。

<details>
  <summary>Details</summary>

**Motivation:** 眼部引起的异常头部姿势（AHP）是眼球偏斜等眼部不正位状况的一种代偿机制，通过早期诊断最小化疾病严重性和相关并发症如面部不对称。然而，当前的临床评估仍然主要是主观的，不完整的医疗记录使得评估更加复杂。

**Method:** 提出了两个互补的深度学习框架：AHP-CADNet（用于自动化诊断的多级注意力融合框架）和基于课程学习的数据补全框架（用于减少数据缺失的影响）

**Result:** 在PoseGaze-AHP数据集上的评估显示了强大的诊断性能。AHP-CADNet在分类任务中取得了96.9-99.0%的准确率，并且对于连续变量的预测误差较低，MAE范围在0.103到0.199之间，R2值超过0.93。补全框架在所有临床变量中保持了93.46-99.78%的准确性，引入临床变量依赖模型带来了显著改进（p < 0.001）。

**Conclusion:** 这些研究结果证实了这两个框架在临床环境中自动诊断和数据缺失恢复方面的有效性。

**Abstract:** Ocular-induced abnormal head posture (AHP) is a compensatory mechanism that
arises from ocular misalignment conditions, such as strabismus, enabling
patients to reduce diplopia and preserve binocular vision. Early diagnosis
minimizes morbidity and secondary complications such as facial asymmetry;
however, current clinical assessments remain largely subjective and are further
complicated by incomplete medical records. This study addresses both challenges
through two complementary deep learning frameworks. First, AHP-CADNet is a
multi-level attention fusion framework for automated diagnosis that integrates
ocular landmarks, head pose features, and structured clinical attributes to
generate interpretable predictions. Second, a curriculum learning-based
imputation framework is designed to mitigate missing data by progressively
leveraging structured variables and unstructured clinical notes to enhance
diagnostic robustness under realistic data conditions. Evaluation on the
PoseGaze-AHP dataset demonstrates robust diagnostic performance. AHP-CADNet
achieves 96.9-99.0 percent accuracy across classification tasks and low
prediction errors for continuous variables, with MAE ranging from 0.103 to
0.199 and R2 exceeding 0.93. The imputation framework maintains high accuracy
across all clinical variables (93.46-99.78 percent with PubMedBERT), with
clinical dependency modeling yielding significant improvements (p < 0.001).
These findings confirm the effectiveness of both frameworks for automated
diagnosis and recovery from missing data in clinical settings.

</details>


### [49] [EduVerse: A User-Defined Multi-Agent Simulation Space for Education Scenario](https://arxiv.org/abs/2510.05650)
*Yiping Ma,Shiyu Hu,Buyuan Zhu,Yipei Wang,Yaxuan Kang,Shiqing Liu,Kang Hao Cheong*

Main category: cs.CV

> EduVerse is a novel AI tool for simulating educational environments by integrating human and AI agents in realistic classroom settings, offering capabilities for studying cognitive, social, and evolutionary dynamics in education.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind EduVerse is to address the core challenge in educational AI of reproducing the complexity of real classrooms, including cognitive development, group interaction, and long-term evolution, which existing methods often fail to capture comprehensively.

**Method:** EduVerse, a user-defined multi-agent simulation space, is built on a layered CIE (Cognition-Interaction-Evolution) architecture, enabling the simulation of open-ended cognition, dynamic social interaction, affective factors, and multi-session development in a classroom environment. With a human-in-the-loop interface, real users can participate in the simulation and interact with AI agents.

**Result:** EduVerse was validated in middle-school Chinese classes, demonstrating pedagogical realism with simulated IRF rates closely matching those of real classrooms, group interaction and role differentiation consistent with real classrooms, and positive transition rate R+ increases reflective of longitudinal student development.

**Conclusion:** EduVerse offers a scalable platform for educational AI that balances realism, reproducibility, and interpretability, allowing for a more comprehensive study of classroom dynamics and fostering cross-disciplinary research through open-sourcing.

**Abstract:** Reproducing cognitive development, group interaction, and long-term evolution
in virtual classrooms remains a core challenge for educational AI, as real
classrooms integrate open-ended cognition, dynamic social interaction,
affective factors, and multi-session development rarely captured together.
Existing approaches mostly focus on short-term or single-agent settings,
limiting systematic study of classroom complexity and cross-task reuse. We
present EduVerse, the first user-defined multi-agent simulation space that
supports environment, agent, and session customization. A distinctive
human-in-the-loop interface further allows real users to join the space. Built
on a layered CIE (Cognition-Interaction-Evolution) architecture, EduVerse
ensures individual consistency, authentic interaction, and longitudinal
adaptation in cognition, emotion, and behavior-reproducing realistic classroom
dynamics with seamless human-agent integration. We validate EduVerse in
middle-school Chinese classes across three text genres, environments, and
multiple sessions. Results show: (1) Instructional alignment: simulated IRF
rates (0.28-0.64) closely match real classrooms (0.37-0.49), indicating
pedagogical realism; (2) Group interaction and role differentiation: network
density (0.27-0.40) with about one-third of peer links realized, while
human-agent tasks indicate a balance between individual variability and
instructional stability; (3) Cross-session evolution: the positive transition
rate R+ increase by 11.7% on average, capturing longitudinal shifts in
behavior, emotion, and cognition and revealing structured learning
trajectories. Overall, EduVerse balances realism, reproducibility, and
interpretability, providing a scalable platform for educational AI. The system
will be open-sourced to foster cross-disciplinary research.

</details>
