<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 14]
- [cs.CV](#cs.CV) [Total: 11]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [Bilingual Word Level Language Identification for Omotic Languages](https://arxiv.org/abs/2509.07998)
*Mesay Gemeda Yigezu,Girma Yohannis Bade,Atnafu Lambebo Tonja,Olga Kolesnikova,Grigori Sidorov,Alexander Gelbukh*

Main category: cs.CL

> 本研究解决了埃塞俄比亚南部Wolaita和Gofa语言的双语语言识别问题，通过使用BERT结合LSTM的方法在测试集中获得了0.72的F1分数，可用于解决社交媒体中的不良问题，并为进一步研究提供基础。

<details>
  <summary>Details</summary>

**Motivation:** 解决在埃塞俄比亚南部使用的Wolaita和Gofa语言中存在的词汇相似性和差异性所带来的语言识别挑战。

**Method:** 采用了基于BERT的预训练语言模型和LSTM方法的组合。

**Result:** 在测试集上获得了0.72的F1分数。

**Conclusion:** 有助于解决社交媒体中的不良问题，并为这一领域的进一步研究奠定基础。

**Abstract:** Language identification is the task of determining the languages for a given
text. In many real world scenarios, text may contain more than one language,
particularly in multilingual communities. Bilingual Language Identification
(BLID) is the task of identifying and distinguishing between two languages in a
given text. This paper presents BLID for languages spoken in the southern part
of Ethiopia, namely Wolaita and Gofa. The presence of words similarities and
differences between the two languages makes the language identification task
challenging. To overcome this challenge, we employed various experiments on
various approaches. Then, the combination of the BERT based pretrained language
model and LSTM approach performed better, with an F1 score of 0.72 on the test
set. As a result, the work will be effective in tackling unwanted social media
issues and providing a foundation for further research in this area.

</details>


### [2] [AntiDote: Bi-level Adversarial Training for Tamper-Resistant LLMs](https://arxiv.org/abs/2509.08000)
*Debdeep Sanyal,Manodeep Ray,Murari Mandal*

Main category: cs.CL

> 本文提出了AntiDote方法，通过对抗训练来增强大语言模型的安全性，使其更难以被篡改，且性能下降不超过0.5%。

<details>
  <summary>Details</summary>

**Motivation:** 当前的安全措施在保护LLM的一般能力的同时抵抗完全接触到模型权重和架构的坚定对手方面存在困难，这些对手可以通过全参数微调来消除现有防护。为解决这个问题，我们提出了AntiDote。

**Method:** 我们提出了AntiDote，这是一种双向优化程序，用于训练LLM以对抗此类篡改。AntiDote包含一个辅助对手超网络，该网络学习生成基于防守模型内部激活的恶意低秩适配(LoRA)权重。防守LLM则通过一种目标训练法以消除这些对抗权重增加的影响，使其保持安全对齐。

**Result:** 我们用52种红队攻击，包括越狱提示、潜在空间操纵和直接权重空间攻击进行了验证。与篡改抵抗和遗忘基线相比，AntiDote在对抗攻击中表现出高达27.4%的韧性。

**Conclusion:** 我们的研究提供了一种实用且计算效率高的方法，用于构建安全成为更加固有且有韧性的属性的公开权重模型。

**Abstract:** The release of open-weight large language models (LLMs) creates a tension
between advancing accessible research and preventing misuse, such as malicious
fine-tuning to elicit harmful content. Current safety measures struggle to
preserve the general capabilities of the LLM while resisting a determined
adversary with full access to the model's weights and architecture, who can use
full-parameter fine-tuning to erase existing safeguards. To address this, we
introduce AntiDote, a bi-level optimization procedure for training LLMs to be
resistant to such tampering. AntiDote involves an auxiliary adversary
hypernetwork that learns to generate malicious Low-Rank Adaptation (LoRA)
weights conditioned on the defender model's internal activations. The defender
LLM is then trained with an objective to nullify the effect of these
adversarial weight additions, forcing it to maintain its safety alignment. We
validate this approach against a diverse suite of 52 red-teaming attacks,
including jailbreak prompting, latent space manipulation, and direct
weight-space attacks. AntiDote is upto 27.4\% more robust against adversarial
attacks compared to both tamper-resistance and unlearning baselines. Crucially,
this robustness is achieved with a minimal trade-off in utility, incurring a
performance degradation of upto less than 0.5\% across capability benchmarks
including MMLU, HellaSwag, and GSM8K. Our work offers a practical and compute
efficient methodology for building open-weight models where safety is a more
integral and resilient property.

</details>


### [3] [MVPBench: A Benchmark and Fine-Tuning Framework for Aligning Large Language Models with Diverse Human Values](https://arxiv.org/abs/2509.08022)
*Yao Liang,Dongcheng Zhao,Feifei Zhao,Guobin Shen,Yuwei Wang,Dongqi Liang,Yi Zeng*

Main category: cs.CL

> MVPBench是一个新的基准测试，用于评估LLMs的价值观对齐情况，覆盖75个国家。研究发现，不同地区的LLMs的价值观对齐存在显著差异，但轻量级微调方法可以显著提高其性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试经常忽视文化和人口统计学的多样性，导致对价值对齐在全球范围内如何推广的理解有限。因此研究的动机是克服这一局限，全面评估LLMs的全球价值观对齐。

**Method:** 该研究介绍了MVPBench，这是一个系统评估大型语言模型（LLMs）在多维度人类价值观偏好上对齐情况的新基准，涵盖75个国家。MVPBench 包含24,020个高质量实例，标注了细粒度的价值标签、个性化问题和丰富的人口统计学元数据。

**Result:** 通过MVPBench，该研究深入分析了几种最先进的LLMs，揭示了地理和人口统计学背景下对齐性能之间存在显著差异。此外，研究还展示了轻量级微调方法可以显著提高价值对齐，在领域内和领域外均表现出优越性。

**Conclusion:** 研究结果强调了人口敏感的价值观对齐评价的必要性，并为构建具有文化适应性和价值观敏感性的LLMs提供了实际行动建议。MVPBench为未来关于全球价值观对齐、个性化价值建模和公平人工智能发展的研究奠定了实际基础。

**Abstract:** The alignment of large language models (LLMs) with human values is critical
for their safe and effective deployment across diverse user populations.
However, existing benchmarks often neglect cultural and demographic diversity,
leading to limited understanding of how value alignment generalizes globally.
In this work, we introduce MVPBench, a novel benchmark that systematically
evaluates LLMs' alignment with multi-dimensional human value preferences across
75 countries. MVPBench contains 24,020 high-quality instances annotated with
fine-grained value labels, personalized questions, and rich demographic
metadata, making it the most comprehensive resource of its kind to date. Using
MVPBench, we conduct an in-depth analysis of several state-of-the-art LLMs,
revealing substantial disparities in alignment performance across geographic
and demographic lines. We further demonstrate that lightweight fine-tuning
methods, such as Low-Rank Adaptation (LoRA) and Direct Preference Optimization
(DPO), can significantly enhance value alignment in both in-domain and
out-of-domain settings. Our findings underscore the necessity for
population-aware alignment evaluation and provide actionable insights for
building culturally adaptive and value-sensitive LLMs. MVPBench serves as a
practical foundation for future research on global alignment, personalized
value modeling, and equitable AI development.

</details>


### [4] [NOWJ@COLIEE 2025: A Multi-stage Framework Integrating Embedding Models and Large Language Models for Legal Retrieval and Entailment](https://arxiv.org/abs/2509.08025)
*Hoang-Trung Nguyen,Tan-Minh Nguyen,Xuan-Bach Le,Tuan-Kiet Le,Khanh-Huyen Nguyen,Ha-Thanh Nguyen,Thi-Hai-Yen Vuong,Le-Minh Nguyen*

Main category: cs.CL

> 本文介绍了NOWJ小组在2025年COLIEE大赛中的表现，专注于法律案例蕴含任务上的两个阶段的检索系统，该系统结合词汇-语义过滤与上下文语言模型分析，以0.3195的F1评分在任务2中获胜。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机在于强调在COLIEE 2025比赛中，NOWJ小组在所有五个任务中的参与情况，重点展示了法律案例蕴含任务上的进展。

**Method:** 我们的方法涵盖了法律案例蕴含任务（任务2），并在五个任务中使用了综合方法系统地整合了预排名模型（如BM25、BERT、monoT5）、基于嵌入的语义表示（如BGE-m3、LLM2Vec）和先进的大语言模型（如Qwen-2、QwQ-32B、DeepSeek-V3）来进行摘要、相关性评分和上下文再排序。

**Result:** 在任务2中，我们的两阶段检索系统结合了词汇-语义过滤和上下文化语言模型分析，以0.3195的F1评分获得了第一名。在其他任务上，如法律案例检索、成文法检索、法律文本蕴含和法律判决预测中，我们通过精心设计的集成模型和提示性推理策略展示了强大的性能。

**Conclusion:** 我们的发现强调了将传统信息检索技术与当代生成模型相结合的混合模型在法律信息处理中的潜力，为未来的发展提供了有价值的参考。

**Abstract:** This paper presents the methodologies and results of the NOWJ team's
participation across all five tasks at the COLIEE 2025 competition, emphasizing
advancements in the Legal Case Entailment task (Task 2). Our comprehensive
approach systematically integrates pre-ranking models (BM25, BERT, monoT5),
embedding-based semantic representations (BGE-m3, LLM2Vec), and advanced Large
Language Models (Qwen-2, QwQ-32B, DeepSeek-V3) for summarization, relevance
scoring, and contextual re-ranking. Specifically, in Task 2, our two-stage
retrieval system combined lexical-semantic filtering with contextualized LLM
analysis, achieving first place with an F1 score of 0.3195. Additionally, in
other tasks--including Legal Case Retrieval, Statute Law Retrieval, Legal
Textual Entailment, and Legal Judgment Prediction--we demonstrated robust
performance through carefully engineered ensembles and effective prompt-based
reasoning strategies. Our findings highlight the potential of hybrid models
integrating traditional IR techniques with contemporary generative models,
providing a valuable reference for future advancements in legal information
processing.

</details>


### [5] [SciGPT: A Large Language Model for Scientific Literature Understanding and Knowledge Discovery](https://arxiv.org/abs/2509.08032)
*Fengyu She,Nan Wang,Hongfei Wu,Ziyi Wan,Jingmian Wang,Chang Wang*

Main category: cs.CL

> SciGPT是一种专门针对科学文献理解的领域适应型基础模型，通过采用一系列创新技术来改进科学文献处理能力和降低资源消耗。

<details>
  <summary>Details</summary>

**Motivation:** 随着科学研究文献的指数级增长，研究人员难以高效地进行知识综合。虽然通用大型语言模型在文本处理中显示出潜力，但在捕获科学领域的细微差别和处理复杂科学任务方面存在不足。

**Method:** SciGPT采用了基于Qwen3架构的三项关键技术：低代价领域蒸馏、稀疏专家混合注意机制以及知识感知适应。

**Result:** 实验结果显示，SciGPT在ScienceBench基准测试中的核心科学任务上超过GPT-4o，包括序列标注、生成和推理。

**Conclusion:** SciGPT展示了其在支持AI增强的科学发现方面的潜力，特别是在未见过的科学任务中表现出色。

**Abstract:** Scientific literature is growing exponentially, creating a critical
bottleneck for researchers to efficiently synthesize knowledge. While
general-purpose Large Language Models (LLMs) show potential in text processing,
they often fail to capture scientific domain-specific nuances (e.g., technical
jargon, methodological rigor) and struggle with complex scientific tasks,
limiting their utility for interdisciplinary research. To address these gaps,
this paper presents SciGPT, a domain-adapted foundation model for scientific
literature understanding and ScienceBench, an open source benchmark tailored to
evaluate scientific LLMs.
  Built on the Qwen3 architecture, SciGPT incorporates three key innovations:
(1) low-cost domain distillation via a two-stage pipeline to balance
performance and efficiency; (2) a Sparse Mixture-of-Experts (SMoE) attention
mechanism that cuts memory consumption by 55\% for 32,000-token long-document
reasoning; and (3) knowledge-aware adaptation integrating domain ontologies to
bridge interdisciplinary knowledge gaps.
  Experimental results on ScienceBench show that SciGPT outperforms GPT-4o in
core scientific tasks including sequence labeling, generation, and inference.
It also exhibits strong robustness in unseen scientific tasks, validating its
potential to facilitate AI-augmented scientific discovery.

</details>


### [6] [No for Some, Yes for Others: Persona Prompts and Other Sources of False Refusal in Language Models](https://arxiv.org/abs/2509.08075)
*Flor Miriam Plaza-del-Arco,Paul Röttger,Nino Scherrer,Emanuele Borgonovo,Elmar Plischke,Dirk Hovy*

Main category: cs.CL

> 研究通过基于蒙特卡洛的方法，探究了社会人口学角色对大型语言模型错误拒绝率的影响，发现角色的影响可能被夸大，并且这种影响可能受到模型能力和任务类型的显著影响。

<details>
  <summary>Details</summary>

**Motivation:** 大型语言模型(LLMs)在我们的日常生活中越来越普及且趋向个性化。然而，LLMs的个性化可能导致一些意外的副作用，尤其在特定角色提示下可能会产生对用户请求的错误拒绝。为了更全面地了解问题的严重程度，本研究试图量化解决这一问题。

**Method:** 本研究提出了一种基于蒙特卡洛的方法，以高效地量化问题的影响。该方法测试了15个基于性别、种族、宗教和残疾的社会人口学角色，16种不同的模型，以及三种任务（自然语言推理、礼貌性和攻击性分类），并采用了九种不同的提示重述以控制其他因素的影响。

**Result:** 研究表明，随着模型能力的提升，角色对拒信率的影响逐渐减小。然而，某些社会人口学角色会导致一些模型的错误拒绝率增加，表明在对齐策略或安全机制中可能存在潜在偏见。同时，模型选择和任务类型对错误拒绝的影响显著，尤其是涉及到敏感内容的任务。

**Conclusion:** 研究结论表明，社会人口学角色对大型语言模型错误拒绝率的影响可能被过度估计，实际上可能与其他因素有关。这为未来模型的开发和应用提供了重要见解，尤其是在处理敏感信息时。

**Abstract:** Large language models (LLMs) are increasingly integrated into our daily lives
and personalized. However, LLM personalization might also increase unintended
side effects. Recent work suggests that persona prompting can lead models to
falsely refuse user requests. However, no work has fully quantified the extent
of this issue. To address this gap, we measure the impact of 15
sociodemographic personas (based on gender, race, religion, and disability) on
false refusal. To control for other factors, we also test 16 different models,
3 tasks (Natural Language Inference, politeness, and offensiveness
classification), and nine prompt paraphrases. We propose a Monte Carlo-based
method to quantify this issue in a sample-efficient manner. Our results show
that as models become more capable, personas impact the refusal rate less and
less. Certain sociodemographic personas increase false refusal in some models,
which suggests underlying biases in the alignment strategies or safety
mechanisms. However, we find that the model choice and task significantly
influence false refusals, especially in sensitive content tasks. Our findings
suggest that persona effects have been overestimated, and might be due to other
factors.

</details>


### [7] [Culturally transmitted color categories in LLMs reflect a learning bias toward efficient compression](https://arxiv.org/abs/2509.08093)
*Nathaniel Imel,Noga Zaslavsky*

Main category: cs.CL

> 研究发现，大型语言模型（LLMs）能够类比人类语义系统，生成感知基础较强的语义系统，与驱动跨人类语言语义效率的基本原理相同。

<details>
  <summary>Details</summary>

**Motivation:** 已有证据表明，人类语言中的语义分类系统能够通过信息瓶颈（IB）复杂度-准确性原则实现接近最优的压缩。LLMs并未针对此目标训练，因此本文探讨LLMs是否能演化出与人类相似的高效语义系统。

**Method:** 通过在大型语言模型（LLMs）上重现两项关于颜色命名的人类行为研究来探讨LLMs是否能类似人类一样优化语义系统。具体使用了Gemini 2.0-flash和Llama 3.3-70B-Instruct模型，首先是英语颜色命名研究，其次通过迭代上下文语言学习来模拟假的颜色命名系统在LLMs中的文化演变。

**Result:** 研究结果显示，Gemini模型在英语颜色命名上与英语母语者高度一致，并获得较高的IB效率得分；而Llama模型虽然也表现高效，但复杂度较低。迭代上下文学习表明，LLMs能够像人类一样重构随机系统，趋向更高的IB效率和与世界语言模式的更高一致性。

**Conclusion:** 这些发现证明了LLMs能够根据感知基础的人类语义系统演化，这与驱动跨人类语言语义效率的基本原理相似。

**Abstract:** Converging evidence suggests that systems of semantic categories across human
languages achieve near-optimal compression via the Information Bottleneck (IB)
complexity-accuracy principle. Large language models (LLMs) are not trained for
this objective, which raises the question: are LLMs capable of evolving
efficient human-like semantic systems? To address this question, we focus on
the domain of color as a key testbed of cognitive theories of categorization
and replicate with LLMs (Gemini 2.0-flash and Llama 3.3-70B-Instruct) two
influential human behavioral studies. First, we conduct an English color-naming
study, showing that Gemini aligns well with the naming patterns of native
English speakers and achieves a significantly high IB-efficiency score, while
Llama exhibits an efficient but lower complexity system compared to English.
Second, to test whether LLMs simply mimic patterns in their training data or
actually exhibit a human-like inductive bias toward IB-efficiency, we simulate
cultural evolution of pseudo color-naming systems in LLMs via iterated
in-context language learning. We find that akin to humans, LLMs iteratively
restructure initially random systems towards greater IB-efficiency and
increased alignment with patterns observed across the world's languages. These
findings demonstrate that LLMs are capable of evolving perceptually grounded,
human-like semantic systems, driven by the same fundamental principle that
governs semantic efficiency across human languages.

</details>


### [8] [MERLIN: Multi-Stage Curriculum Alignment for Multilingual Encoder and LLM Fusion](https://arxiv.org/abs/2509.08105)
*Kosei Uemura,David Guzmán,Quang Phuoc Nguyen,Jesujoba Oluwadara Alabi,En-shiun Annie Lee,David Ifeoluwa Adelani*

Main category: cs.CL

> 研究介绍MERLIN模型，用以提升低资源语言中的推理准确性，超越现有模型。

<details>
  <summary>Details</summary>

**Motivation:** 虽然大型语言模型在英语方面表现出色，但在许多低资源语言中的复杂推理任务上仍然存在问题。现有的编码器加解码器方法如LangBridge和MindMerger在中高资源语言上提高了准确性，但在低资源语言上仍有很大差距。

**Method:** MERLIN采用两阶段模型堆叠框架，结合课程学习策略，从通用的双语文本逐步过渡到特定任务的数据，并仅微调一小部分DoRA权重。

**Result:** MERLIN，一种两阶段模型堆叠框架，采用从通用双语文本到任务特定数据的课程学习策略，并仅调整少量DoRA权重，显著提升了低资源语言中的推理准确性。在AfriMGSM基准测试中，MERLIN将精确匹配准确率提高了12.9个百分点，超过了MindMerger和GPT-4o-mini。此外，MERLIN还在MGSM和MSVAMP上分别提高了0.9和2.8个百分点，展示了其在低资源和高资源设置中的有效性。

**Conclusion:** MERLIN模型在处理低资源语言的复杂推理任务上表现出色，其独特的课程学习策略和模型参数高效调整机制是主要贡献。

**Abstract:** Large language models excel in English but still struggle with complex
reasoning in many low-resource languages (LRLs). Existing encoder-plus-decoder
methods such as LangBridge and MindMerger raise accuracy on mid and
high-resource languages, yet they leave a large gap on LRLs. We present MERLIN,
a two-stage model-stacking framework that applies a curriculum learning
strategy -- from general bilingual bitext to task-specific data -- and adapts
only a small set of DoRA weights. On the AfriMGSM benchmark MERLIN improves
exact-match accuracy by +12.9 pp over MindMerger and outperforms GPT-4o-mini.
It also yields consistent gains on MGSM and MSVAMP (+0.9 and +2.8 pp),
demonstrating effectiveness across both low and high-resource settings.

</details>


### [9] [Bias after Prompting: Persistent Discrimination in Large Language Models](https://arxiv.org/abs/2509.08146)
*Nivedha Sivakumar,Natalie Mackraz,Samira Khorshidi,Krishna Patel,Barry-John Theobald,Luca Zappella,Nicholas Apostoloff*

Main category: cs.CL

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** A dangerous assumption that can be made from prior work on the bias transfer
hypothesis (BTH) is that biases do not transfer from pre-trained large language
models (LLMs) to adapted models. We invalidate this assumption by studying the
BTH in causal models under prompt adaptations, as prompting is an extremely
popular and accessible adaptation strategy used in real-world applications. In
contrast to prior work, we find that biases can transfer through prompting and
that popular prompt-based mitigation methods do not consistently prevent biases
from transferring. Specifically, the correlation between intrinsic biases and
those after prompt adaptation remain moderate to strong across demographics and
tasks -- for example, gender (rho >= 0.94) in co-reference resolution, and age
(rho >= 0.98) and religion (rho >= 0.69) in question answering. Further, we
find that biases remain strongly correlated when varying few-shot composition
parameters, such as sample size, stereotypical content, occupational
distribution and representational balance (rho >= 0.90). We evaluate several
prompt-based debiasing strategies and find that different approaches have
distinct strengths, but none consistently reduce bias transfer across models,
tasks or demographics. These results demonstrate that correcting bias, and
potentially improving reasoning ability, in intrinsic models may prevent
propagation of biases to downstream tasks.

</details>


### [10] [Verbalized Algorithms](https://arxiv.org/abs/2509.08150)
*Supriya Lall,Christian Farrell,Hari Pathanjaly,Marko Pavic,Sarvesh Chezhian,Masataro Asai*

Main category: cs.CL

> 文章提出了利用经典算法的'verbalized algorithms' (VAs) 新范式，通过将任务分解为简单操作，并仅限LLMs处理这些简单任务来提高任务处理效率，特别是对于排序和聚类任务。

<details>
  <summary>Details</summary>

**Motivation:** 由于一次查询大语言模型（LLMs）并希望得到正确的推理任务答案的方法存在局限性，因此提出了VAs这一概念。希望通过利用经典算法的理论理解，可以更有效地解决推理任务。

**Method:** 提出了一种称为'verbalized algorithms' (VAs) 的新范式，该范式利用经典算法，将任务分解为简单的自然语言字符串操作，并仅限LLMs处理这些简单任务。例如，在对自然语言字符串进行排序时，'verbalized sorting' 把LLMs作为二元比较预言机使用在一个已知和分析过的排序算法中，如bitonic排序网络。

**Result:** 在排序和聚类任务中展示了这种新方法的有效性。

**Conclusion:** 通过利用经典算法的VAs方法，可以更有效地解决自然语言处理任务，特别是在排序和聚类任务中。

**Abstract:** Instead of querying LLMs in a one-shot manner and hoping to get the right
answer for a reasoning task, we propose a paradigm we call \emph{verbalized
algorithms} (VAs), which leverage classical algorithms with established
theoretical understanding. VAs decompose a task into simple elementary
operations on natural language strings that they should be able to answer
reliably, and limit the scope of LLMs to only those simple tasks. For example,
for sorting a series of natural language strings, \emph{verbalized sorting}
uses an LLM as a binary comparison oracle in a known and well-analyzed sorting
algorithm (e.g., bitonic sorting network). We demonstrate the effectiveness of
this approach on sorting and clustering tasks.

</details>


### [11] [Balancing Quality and Variation: Spam Filtering Distorts Data Label Distributions](https://arxiv.org/abs/2509.08217)
*Eve Fleisig,Matthias Orlikowski,Philipp Cimiano,Dan Klein*

Main category: cs.CL

> Evaluating annotator filtering heuristics reveals conservative settings are optimal for preserving label diversity and filtering spam in subjective tasks.

<details>
  <summary>Details</summary>

**Motivation:** The goal is to balance the preservation of data label variation, indicative of diverse opinions, while filtering out spam or low-quality responses in machine learning datasets.

**Method:** We empirically evaluate a range of heuristics for annotator filtering to maintain variation in subjective tasks, assessing their impact on label diversity and accuracy.

**Result:** Conservative settings for annotator removal (<5%) are found to best maintain the balance, as stricter methods introduce more error relative to the true average label and misidentify variation rather than actual spam.

**Conclusion:** Existing spam filtering methods often assume variability in responses indicates spam, which is inaccurate; methods should account for label diversity to correctly identify and remove spam.

**Abstract:** For machine learning datasets to accurately represent diverse opinions in a
population, they must preserve variation in data labels while filtering out
spam or low-quality responses. How can we balance annotator reliability and
representation? We empirically evaluate how a range of heuristics for annotator
filtering affect the preservation of variation on subjective tasks. We find
that these methods, designed for contexts in which variation from a single
ground-truth label is considered noise, often remove annotators who disagree
instead of spam annotators, introducing suboptimal tradeoffs between accuracy
and label diversity. We find that conservative settings for annotator removal
(<5%) are best, after which all tested methods increase the mean absolute error
from the true average label. We analyze performance on synthetic spam to
observe that these methods often assume spam annotators are less random than
real spammers tend to be: most spammers are distributionally indistinguishable
from real annotators, and the minority that are distinguishable tend to give
fixed answers, not random ones. Thus, tasks requiring the preservation of
variation reverse the intuition of existing spam filtering methods: spammers
tend to be less random than non-spammers, so metrics that assume variation is
spam fare worse. These results highlight the need for spam removal methods that
account for label diversity.

</details>


### [12] [Towards Knowledge-Aware Document Systems: Modeling Semantic Coverage Relations via Answerability Detection](https://arxiv.org/abs/2509.08304)
*Yehudit Aperstein,Alon Gottlib,Gal Benita,Alexander Apartsin*

Main category: cs.CL

> 提出一种新的语义覆盖率关系（SCR）建模框架，使用问答方法评估文本间信息关系。

<details>
  <summary>Details</summary>

**Motivation:** 理解不同格式文档间的信息共享方式对于信息检索、摘要和内容对齐等任务至关重要。

**Method:** 采用基于问答(QA)的方法，通过文档之间共享问题的答案能力来衡量语义覆盖。

**Result:** 判别模型显著优于生成模型，其中RoBERTa-base模型准确率最高达61.4%，随机森林模型宏观F1得分最佳为52.9%。

**Conclusion:** 研究表明QA方法能有效评估风格不同的文本间的语义相关性，揭示了当前模型在表层相似性之外推理信息的能力。

**Abstract:** Understanding how information is shared across documents, regardless of the
format in which it is expressed, is critical for tasks such as information
retrieval, summarization, and content alignment. In this work, we introduce a
novel framework for modelling Semantic Coverage Relations (SCR), which
classifies document pairs based on how their informational content aligns. We
define three core relation types: equivalence, where both texts convey the same
information using different textual forms or styles; inclusion, where one
document fully contains the information of another and adds more; and semantic
overlap, where each document presents partially overlapping content. To capture
these relations, we adopt a question answering (QA)-based approach, using the
answerability of shared questions across documents as an indicator of semantic
coverage. We construct a synthetic dataset derived from the SQuAD corpus by
paraphrasing source passages and selectively omitting information, enabling
precise control over content overlap. This dataset allows us to benchmark
generative language models and train transformer-based classifiers for SCR
prediction. Our findings demonstrate that discriminative models significantly
outperform generative approaches, with the RoBERTa-base model achieving the
highest accuracy of 61.4% and the Random Forest-based model showing the best
balance with a macro-F1 score of 52.9%. The results show that QA provides an
effective lens for assessing semantic relations across stylistically diverse
texts, offering insights into the capacity of current models to reason about
information beyond surface similarity. The dataset and code developed in this
study are publicly available to support reproducibility.

</details>


### [13] [Toward Subtrait-Level Model Explainability in Automated Writing Evaluation](https://arxiv.org/abs/2509.08345)
*Alejandro Andrade-Lotero,Lee Becker,Joshua Southerland,Scott Hellman*

Main category: cs.CL

> The paper explores the use of generative language models in providing transparent and explainable subtrait scoring for automated writing assessments.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind the research is to enhance the transparency of automated writing scores through the assessment of subtraits.

**Method:** The paper uses generative language models to prototype explainability and subtrait scoring in automated writing assessment.

**Result:** The study shows a modest correlation between human subtrait and trait scores, as well as between automated and human subtrait scores.

**Conclusion:** The approach is useful for providing greater transparency and understanding of automated writing scores to educators and students.

**Abstract:** Subtrait (latent-trait components) assessment presents a promising path
toward enhancing transparency of automated writing scores. We prototype
explainability and subtrait scoring with generative language models and show
modest correlation between human subtrait and trait scores, and between
automated and human subtrait scores. Our approach provides details to demystify
scores for educators and students.

</details>


### [14] [Automatic Detection of Inauthentic Templated Responses in English Language Assessments](https://arxiv.org/abs/2509.08355)
*Yashad Samant,Lee Becker,Scott Hellman,Bradley Behan,Sarah Hughes,Joshua Southerland*

Main category: cs.CL

> 研究介绍了一个自动化检测模板化不真实回答的任务（AuDITR），并强调需定期更新模型。

<details>
  <summary>Details</summary>

**Motivation:** 低技能测试者可能通过使用模板化的素材来欺骗自动评分系统，因此这项研究旨在解决这一问题，并强调在实际应用中定期更新模型的重要性。

**Method:** 本研究介绍了一种基于机器学习的方法，用于检测高利害英语语言测评中的模板化不真实回答。

**Result:** 建立了基于机器学习的方法，并证明了在实际应用中定期更新模型的重要性。

**Conclusion:** 本研究的结果表明，采用机器学习方法能够有效地检测英语语言测评中的模板化回答，并且定期更新模型对于保持检测系统的有效性至关重要。

**Abstract:** In high-stakes English Language Assessments, low-skill test takers may employ
memorized materials called ``templates'' on essay questions to ``game'' or fool
the automated scoring system. In this study, we introduce the automated
detection of inauthentic, templated responses (AuDITR) task, describe a machine
learning-based approach to this task and illustrate the importance of regularly
updating these models in production.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [15] [3D and 4D World Modeling: A Survey](https://arxiv.org/abs/2509.07996)
*Lingdong Kong,Wesley Yang,Jianbiao Mei,Youquan Liu,Ao Liang,Dekai Zhu,Dongyue Lu,Wei Yin,Xiaotao Hu,Mingkai Jia,Junyuan Deng,Kaiwen Zhang,Yang Wu,Tianyi Yan,Shenyuan Gao,Song Wang,Linfeng Li,Liang Pan,Yong Liu,Jianke Zhu,Wei Tsang Ooi,Steven C. H. Hoi,Ziwei Liu*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** World modeling has become a cornerstone in AI research, enabling agents to
understand, represent, and predict the dynamic environments they inhabit. While
prior work largely emphasizes generative methods for 2D image and video data,
they overlook the rapidly growing body of work that leverages native 3D and 4D
representations such as RGB-D imagery, occupancy grids, and LiDAR point clouds
for large-scale scene modeling. At the same time, the absence of a standardized
definition and taxonomy for ``world models'' has led to fragmented and
sometimes inconsistent claims in the literature. This survey addresses these
gaps by presenting the first comprehensive review explicitly dedicated to 3D
and 4D world modeling and generation. We establish precise definitions,
introduce a structured taxonomy spanning video-based (VideoGen),
occupancy-based (OccGen), and LiDAR-based (LiDARGen) approaches, and
systematically summarize datasets and evaluation metrics tailored to 3D/4D
settings. We further discuss practical applications, identify open challenges,
and highlight promising research directions, aiming to provide a coherent and
foundational reference for advancing the field. A systematic summary of
existing literature is available at https://github.com/worldbench/survey

</details>


### [16] [An Explainable Deep Neural Network with Frequency-Aware Channel and Spatial Refinement for Flood Prediction in Sustainable Cities](https://arxiv.org/abs/2509.08003)
*Shahid Shafi Dar,Bharat Kaurav,Arnav Jain,Chandravardhan Singh Raghaw,Mohammad Zia Ur Rehman,Nagendra Kumar*

Main category: cs.CV

> 本文提出了XFloodNet框架，解决城市洪水分类中的挑战，采用了层级交叉模态门控注意力机制、异构卷积自适应多尺度注意模块以及级联卷积变压器特征优化技术，基于三个基准数据集测试，取得优异的分类结果，超越现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 传统洪水检测方法依赖单一数据类型和静态规则系统，无法捕捉洪水事件的动态非线性关系，现有注意力机制和集成学习方法在层级细化、跨模态特征整合以及适应噪声或非结构化环境的能力上具有局限性，导致洪水分类性能不佳。

**Method:** XFloodNet框架包含三个创新组件：1) 层级交叉模态门控注意力机制，2) 异构卷积自适应多尺度注意模块，3) 级联卷积变压器特征优化技术，共同提高了洪水相关的特征提取与分类能力。

**Result:** 研究在三个基准数据集上进行了验证，分别是Chennai Floods, Rhine18 Floods, 和Harz17 Floods数据集，XFloodNet分别获得了F1-scores为93.33%，82.24%，和88.60%的结果，超越了现有的方法。

**Conclusion:** XFloodNet框架基于先进的深度学习技术，表现出了在城市洪水分类中优异的性能，为解决复杂的洪水检测问题提供了新的手段，取得了显著超出现有方法的性能结果。

**Abstract:** In an era of escalating climate change, urban flooding has emerged as a
critical challenge for sustainable cities, threatening lives, infrastructure,
and ecosystems. Traditional flood detection methods are constrained by their
reliance on unimodal data and static rule-based systems, which fail to capture
the dynamic, non-linear relationships inherent in flood events. Furthermore,
existing attention mechanisms and ensemble learning approaches exhibit
limitations in hierarchical refinement, cross-modal feature integration, and
adaptability to noisy or unstructured environments, resulting in suboptimal
flood classification performance. To address these challenges, we present
XFloodNet, a novel framework that redefines urban flood classification through
advanced deep-learning techniques. XFloodNet integrates three novel components:
(1) a Hierarchical Cross-Modal Gated Attention mechanism that dynamically
aligns visual and textual features, enabling precise multi-granularity
interactions and resolving contextual ambiguities; (2) a Heterogeneous
Convolutional Adaptive Multi-Scale Attention module, which leverages
frequency-enhanced channel attention and frequency-modulated spatial attention
to extract and prioritize discriminative flood-related features across spectral
and spatial domains; and (3) a Cascading Convolutional Transformer Feature
Refinement technique that harmonizes hierarchical features through adaptive
scaling and cascading operations, ensuring robust and noise-resistant flood
detection. We evaluate our proposed method on three benchmark datasets, such as
Chennai Floods, Rhine18 Floods, and Harz17 Floods, XFloodNet achieves
state-of-the-art F1-scores of 93.33%, 82.24%, and 88.60%, respectively,
surpassing existing methods by significant margins.

</details>


### [17] [Video Parallel Scaling: Aggregating Diverse Frame Subsets for VideoLLMs](https://arxiv.org/abs/2509.08016)
*Hyungjin Chung,Hyelin Nam,Jiyeon Kim,Hyojun Go,Byeongjun Park,Junho Kim,Joonseok Lee,Seongsu Ha,Byung-Hoon Kim*

Main category: cs.CV

> 提出了Video Parallel Scaling (VPS) 方法，通过并行处理不同帧子集，提高视频大语言模型的感知带宽，从而改善性能而不增加训练成本。实验表明VPS在不同模型架构和规模上均能显著提升性能。

<details>
  <summary>Details</summary>

**Motivation:** 增加输入帧数以捕捉细粒度时间细节会带来计算成本过高和长上下文长度下的性能下降问题。目的是解决视频大语言模型的时间推理能力瓶颈，提高其性能。

**Method:** VPS通过多个并行的推理流，每个流处理视频帧的不同非重叠子集，然后聚合这些流的输出概率，从而整合比单次传递更多的视觉信息，理论上证明了这种方法能够改善性能，而无需额外训练。

**Result:** 在2B-32B规模的不同模型架构上进行的实验显示，VPS在Video-MME和EventHallusion等基准上表现出色，性能显著提升。此外，VPS相比于其他并行方法（如自洽性）扩展性更佳，且与其解码策略互补。

**Conclusion:** VPS证明了通过整合多个并行流的视觉证据，可以提高视频LLM的感知带宽和时间推理能力，而不增加计算成本或者改变模型架构。它提供了一个高效且鲁棒的框架来提升视频LLM的性能。

**Abstract:** Video Large Language Models (VideoLLMs) face a critical bottleneck:
increasing the number of input frames to capture fine-grained temporal detail
leads to prohibitive computational costs and performance degradation from long
context lengths. We introduce Video Parallel Scaling (VPS), an inference-time
method that expands a model's perceptual bandwidth without increasing its
context window. VPS operates by running multiple parallel inference streams,
each processing a unique, disjoint subset of the video's frames. By aggregating
the output probabilities from these complementary streams, VPS integrates a
richer set of visual information than is possible with a single pass. We
theoretically show that this approach effectively contracts the Chinchilla
scaling law by leveraging uncorrelated visual evidence, thereby improving
performance without additional training. Extensive experiments across various
model architectures and scales (2B-32B) on benchmarks such as Video-MME and
EventHallusion demonstrate that VPS consistently and significantly improves
performance. It scales more favorably than other parallel alternatives (e.g.
Self-consistency) and is complementary to other decoding strategies, offering a
memory-efficient and robust framework for enhancing the temporal reasoning
capabilities of VideoLLMs.

</details>


### [18] [Two Stage Context Learning with Large Language Models for Multimodal Stance Detection on Climate Change](https://arxiv.org/abs/2509.08024)
*Lata Pangtey,Omkar Kabde,Shahid Shafi Dar,Nagendra Kumar*

Main category: cs.CV

> This paper proposes a multimodal stance detection framework that integrates text and visual elements using a hierarchical fusion method, with successful performance on the MultiClimate dataset.

<details>
  <summary>Details</summary>

**Motivation:** The motivation stems from the need for advanced multimodal methods to analyze social media content that combines text and visual elements. Most existing approaches only focus on textual data, which limits their ability to understand complex social media interactions.

**Method:** Our method involves a hierarchical fusion approach that integrates textual data processed by a Large Language Model with visual data interpreted by a domain-aware image caption generator. These modalities are then jointly modeled using a specialized transformer module to perform stance detection.

**Result:** The proposed framework was evaluated on the MultiClimate dataset and achieved an accuracy of 76.2%, precision of 76.3%, recall of 76.2%, and an F1-score of 76.2%, outperforming state-of-the-art methods.

**Conclusion:** The study concludes that the proposed multimodal stance detection framework is effective in capturing interactions between texts and images, and it significantly outperforms existing methods in classifying stance in multimodal social media content.

**Abstract:** With the rapid proliferation of information across digital platforms, stance
detection has emerged as a pivotal challenge in social media analysis. While
most of the existing approaches focus solely on textual data, real-world social
media content increasingly combines text with visual elements creating a need
for advanced multimodal methods. To address this gap, we propose a multimodal
stance detection framework that integrates textual and visual information
through a hierarchical fusion approach. Our method first employs a Large
Language Model to retrieve stance-relevant summaries from source text, while a
domain-aware image caption generator interprets visual content in the context
of the target topic. These modalities are then jointly modeled along with the
reply text, through a specialized transformer module that captures interactions
between the texts and images. The proposed modality fusion framework integrates
diverse modalities to facilitate robust stance classification. We evaluate our
approach on the MultiClimate dataset, a benchmark for climate change-related
stance detection containing aligned video frames and transcripts. We achieve
accuracy of 76.2%, precision of 76.3%, recall of 76.2% and F1-score of 76.2%,
respectively, outperforming existing state-of-the-art approaches.

</details>


### [19] [Two-Stage Swarm Intelligence Ensemble Deep Transfer Learning (SI-EDTL) for Vehicle Detection Using Unmanned Aerial Vehicles](https://arxiv.org/abs/2509.08026)
*Zeinab Ghasemi Darehnaei,Mohammad Shokouhifar,Hossein Yazdanjouei,S. M. J. Rastegar Fatemi*

Main category: cs.CV

> SI-EDTL模型通过结合多种预训练的Faster R-CNN模型和迁移分类器，并利用鲸鱼优化算法进行超参数优化，实现了无人机图像中多类型车辆的高效检测。

<details>
  <summary>Details</summary>

**Motivation:** 动机是提出一种新的模型来提高检测无人机图像中多类型车辆的性能，特别是在精度、精确性和召回率方面。

**Method:** 该方法包括使用多种预训练模型和分类器形成集成学习器集，使用鲸鱼优化算法优化超参数，并利用加权平均进行聚合分类。

**Result:** 该论文介绍了SI-EDTL模型，这是一种用于检测无人机图像中多车辆的两阶段群智能集成深度迁移学习模型。SI-EDTL结合了三个预训练的Faster R-CNN特征提取器模型（InceptionV3、ResNet50、GoogLeNet）与五个迁移分类器（KNN、SVM、MLP、C4.5、朴素贝叶斯），形成15种不同的基本学习器。通过加权平均聚合来分类车辆类型为轿车、货车、卡车、公交车或背景。使用鲸鱼优化算法对超参数进行优化，以平衡精度、精确性和召回率。在MATLAB R2020b中实现，并采用并行处理，SI-EDTL在AU-AIR无人机数据集上表现出优于现有方法的性能。

**Conclusion:** 结论是SI-EDTL在AU-AIR无人机数据集上超过了现有的检测方法，展示了其在检测无人机图像中的多类型车辆方面的优越性能。

**Abstract:** This paper introduces SI-EDTL, a two-stage swarm intelligence ensemble deep
transfer learning model for detecting multiple vehicles in UAV images. It
combines three pre-trained Faster R-CNN feature extractor models (InceptionV3,
ResNet50, GoogLeNet) with five transfer classifiers (KNN, SVM, MLP, C4.5,
Na\"ive Bayes), resulting in 15 different base learners. These are aggregated
via weighted averaging to classify regions as Car, Van, Truck, Bus, or
background. Hyperparameters are optimized with the whale optimization algorithm
to balance accuracy, precision, and recall. Implemented in MATLAB R2020b with
parallel processing, SI-EDTL outperforms existing methods on the AU-AIR UAV
dataset.

</details>


### [20] [MCTED: A Machine-Learning-Ready Dataset for Digital Elevation Model Generation From Mars Imagery](https://arxiv.org/abs/2509.08027)
*Rafał Osadnik,Pablo Gómez,Eleni Bohacek,Rickbir Bahia*

Main category: cs.CV

> Error

<details>
  <summary>Details</summary>

**Motivation:** Error

**Method:** Error

**Result:** Error

**Conclusion:** Error

**Abstract:** This work presents a new dataset for the Martian digital elevation model
prediction task, ready for machine learning applications called MCTED. The
dataset has been generated using a comprehensive pipeline designed to process
high-resolution Mars orthoimage and DEM pairs from Day et al., yielding a
dataset consisting of 80,898 data samples. The source images are data gathered
by the Mars Reconnaissance Orbiter using the CTX instrument, providing a very
diverse and comprehensive coverage of the Martian surface. Given the complexity
of the processing pipelines used in large-scale DEMs, there are often artefacts
and missing data points in the original data, for which we developed tools to
solve or mitigate their impact. We divide the processed samples into training
and validation splits, ensuring samples in both splits cover no mutual areas to
avoid data leakage. Every sample in the dataset is represented by the optical
image patch, DEM patch, and two mask patches, indicating values that were
originally missing or were altered by us. This allows future users of the
dataset to handle altered elevation regions as they please. We provide
statistical insights of the generated dataset, including the spatial
distribution of samples, the distributions of elevation values, slopes and
more. Finally, we train a small U-Net architecture on the MCTED dataset and
compare its performance to a monocular depth estimation foundation model,
DepthAnythingV2, on the task of elevation prediction. We find that even a very
small architecture trained on this dataset specifically, beats a zero-shot
performance of a depth estimation foundation model like DepthAnythingV2. We
make the dataset and code used for its generation completely open source in
public repositories.

</details>


### [21] [APML: Adaptive Probabilistic Matching Loss for Robust 3D Point Cloud Reconstruction](https://arxiv.org/abs/2509.08104)
*Sasan Sharifipour,Constantino Álvarez Casado,Mohammad Sabokrou,Miguel Bordallo López*

Main category: cs.CV

> 本文提出了自适应概率匹配损失（APML），解决了现有点云预测任务中的密度不均和非可微操作问题，提升了模型性能。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服现有损失函数在点云预测任务中点云密度不均和非可微操作的问题，提出了APML。

**Method:** 我们提出了自适应概率匹配损失（APML），这是一种全微分的一对一匹配近似方法，利用Sinkhorn迭代和基于成对距离的温度缩放相似性矩阵。我们通过解析计算温度来保证最小分配概率，从而消除手动调整的需求。

**Result:** APML损失函数在ShapeNet基准测试上和从WiFi CSI测量生成3D人体点云的时空Transformer模型上，达到了更快的收敛速度、更优秀的空间分布，特别是在低密度区域，而且在没有额外超参数搜索的情况下取得了更好的或相当的定量性能。

**Conclusion:** APML不仅在运行时间上与Chamfer距离函数相近，还避免了非可微操作，展示出了强大的性能并且在实际应用中更加简便。

**Abstract:** Training deep learning models for point cloud prediction tasks such as shape
completion and generation depends critically on loss functions that measure
discrepancies between predicted and ground-truth point sets. Commonly used
functions such as Chamfer Distance (CD), HyperCD, and InfoCD rely on
nearest-neighbor assignments, which often induce many-to-one correspondences,
leading to point congestion in dense regions and poor coverage in sparse
regions. These losses also involve non-differentiable operations due to index
selection, which may affect gradient-based optimization. Earth Mover Distance
(EMD) enforces one-to-one correspondences and captures structural similarity
more effectively, but its cubic computational complexity limits its practical
use. We propose the Adaptive Probabilistic Matching Loss (APML), a fully
differentiable approximation of one-to-one matching that leverages Sinkhorn
iterations on a temperature-scaled similarity matrix derived from pairwise
distances. We analytically compute the temperature to guarantee a minimum
assignment probability, eliminating manual tuning. APML achieves near-quadratic
runtime, comparable to Chamfer-based losses, and avoids non-differentiable
operations. When integrated into state-of-the-art architectures (PoinTr, PCN,
FoldingNet) on ShapeNet benchmarks and on a spatiotemporal Transformer (CSI2PC)
that generates 3D human point clouds from WiFi CSI measurements, APM loss
yields faster convergence, superior spatial distribution, especially in
low-density regions, and improved or on-par quantitative performance without
additional hyperparameter search. The code is available at:
https://github.com/apm-loss/apml.

</details>


### [22] [Lightweight Deep Unfolding Networks with Enhanced Robustness for Infrared Small Target Detection](https://arxiv.org/abs/2509.08205)
*Jingjing Liu,Yinchao Han,Xianchao Xiu,Jianhua Zhang,Wanquan Liu*

Main category: cs.CV

> 本文提出了一种基于RPCA的超轻量框架L-RPCANet，旨在解决ISTD的挑战，通过构建分层瓶颈结构和嵌入降噪模块等方法实现了出色的性能和鲁棒性。

<details>
  <summary>Details</summary>

**Motivation:** 虽然深度展开网络（DUNs）在红外小目标检测（ISTD）中展示了令人鼓舞的性能，但现有方法在参数轻量化和噪声鲁棒性方面仍面临重大挑战。

**Method:** 本文提出了一种基于鲁棒主成分分析（RPCA）的超轻量框架，称为L-RPCANet。通过构建分层瓶颈结构，减少了特征提取的通道数，提高了网络参数的轻量化。此外，嵌入了一个降噪模块以增强对复杂噪声的鲁棒性，并利用挤压激励网络（SENet）作为通道注意力机制，以关注通道间不同特征的变化程度，从而实现了在保持轻量化和鲁棒性的同时获得出色性能。

**Result:** 在ISTD数据集上的广泛实验验证了所提出方法相对于最新方法（包括RPCANet，DRPCANet和RPCANet++）的优越性。

**Conclusion:** 代码可在https://github.com/xianchaoxiu/L-RPCANet获取。

**Abstract:** Infrared small target detection (ISTD) is one of the key techniques in image
processing. Although deep unfolding networks (DUNs) have demonstrated promising
performance in ISTD due to their model interpretability and data adaptability,
existing methods still face significant challenges in parameter lightweightness
and noise robustness. In this regard, we propose a highly lightweight framework
based on robust principal component analysis (RPCA) called L-RPCANet.
Technically, a hierarchical bottleneck structure is constructed to reduce and
increase the channel dimension in the single-channel input infrared image to
achieve channel-wise feature refinement, with bottleneck layers designed in
each module to extract features. This reduces the number of channels in feature
extraction and improves the lightweightness of network parameters. Furthermore,
a noise reduction module is embedded to enhance the robustness against complex
noise. In addition, squeeze-and-excitation networks (SENets) are leveraged as a
channel attention mechanism to focus on the varying importance of different
features across channels, thereby achieving excellent performance while
maintaining both lightweightness and robustness. Extensive experiments on the
ISTD datasets validate the superiority of our proposed method compared with
state-of-the-art methods covering RPCANet, DRPCANet, and RPCANet++. The code
will be available at https://github.com/xianchaoxiu/L-RPCANet.

</details>


### [23] [Sparse Transformer for Ultra-sparse Sampled Video Compressive Sensing](https://arxiv.org/abs/2509.08228)
*Miao Cao,Siming Zheng,Lishun Wang,Ziyang Chen,David Brady,Xin Yuan*

Main category: cs.CV

> 本文提出了一种新的采样策略Ultra-Sparse Sampling (USS) 和一种新的稀疏Transformer模型BSTFormer，用于提高视频压缩成像(Video SCI)在高帧率、高分辨率摄像中的应用，该策略和模型都显著优于现有的方法。

<details>
  <summary>Details</summary>

**Motivation:** 由于当前视频压缩成像(Video SCI)的处理模型基于随机采样(RS)，数据处理能耗高，不适用于未来像素级高帧率摄像，因此本文提出了一种新的采样策略——USS策略，来减少功耗并提高视频SCI的有效性。

**Method:** 提出了一种名为Ultra-Sparse Sampling (USS) 的策略，其中在每个空间位置上，只有一个子帧设为1，所有其他子帧设为0。我们建立了一个基于数字微镜设备（DMD）的编码系统来验证USS策略的有效性，并提出了一种名为BSTFormer的方法，利用局部块注意力机制、全局稀疏注意力机制和全局时间注意力机制来利用USS测量的稀疏性。

**Result:** 实验结果表明，该方法在模拟数据和真实数据上都显著优于所有先前的最先进算法。此外，USS策略相较于RS策略具有更高的动态范围。

**Conclusion:** USS策略在实现视频SCI系统时是可选的，其固定曝光时间使得USS策略在片上实现上具有优势。

**Abstract:** Digital cameras consume ~0.1 microjoule per pixel to capture and encode
video, resulting in a power usage of ~20W for a 4K sensor operating at 30 fps.
Imagining gigapixel cameras operating at 100-1000 fps, the current processing
model is unsustainable. To address this, physical layer compressive measurement
has been proposed to reduce power consumption per pixel by 10-100X. Video
Snapshot Compressive Imaging (SCI) introduces high frequency modulation in the
optical sensor layer to increase effective frame rate. A commonly used sampling
strategy of video SCI is Random Sampling (RS) where each mask element value is
randomly set to be 0 or 1. Similarly, image inpainting (I2P) has demonstrated
that images can be recovered from a fraction of the image pixels. Inspired by
I2P, we propose Ultra-Sparse Sampling (USS) regime, where at each spatial
location, only one sub-frame is set to 1 and all others are set to 0. We then
build a Digital Micro-mirror Device (DMD) encoding system to verify the
effectiveness of our USS strategy. Ideally, we can decompose the USS
measurement into sub-measurements for which we can utilize I2P algorithms to
recover high-speed frames. However, due to the mismatch between the DMD and
CCD, the USS measurement cannot be perfectly decomposed. To this end, we
propose BSTFormer, a sparse TransFormer that utilizes local Block attention,
global Sparse attention, and global Temporal attention to exploit the sparsity
of the USS measurement. Extensive results on both simulated and real-world data
show that our method significantly outperforms all previous state-of-the-art
algorithms. Additionally, an essential advantage of the USS strategy is its
higher dynamic range than that of the RS strategy. Finally, from the
application perspective, the USS strategy is a good choice to implement a
complete video SCI system on chip due to its fixed exposure time.

</details>


### [24] [GTA-Crime: A Synthetic Dataset and Generation Framework for Fatal Violence Detection with Adversarial Snippet-Level Domain Adaptation](https://arxiv.org/abs/2509.08232)
*Seongho Kim,Sejong Ryu,Hyoukjun You,Je Hyeong Hong*

Main category: cs.CV

> 本文提出GTA-Crime数据集和一种片段级领域适应策略来提升致命暴力事件在监控视频中的检测准确性。

<details>
  <summary>Details</summary>

**Motivation:** 本研究的动机在于解决诸如枪击和刺伤等致命事件在监控视频中的检测难题，这些事件由于其罕见性和数据收集的道德问题使得检测变得困难。

**Method:** 本文提出了GTA-Crime，这是一个利用Grand Theft Auto 5制作的致命事件异常视频数据集及其生成框架，并提出了一种基于Wasserstein对抗训练的片段级领域适应策略来解决合成视频与现实世界视频特征之间的差异。

**Result:** 实验结果表明，结合GTA-Crime数据集和提出的领域适应策略可以提高现实世界中致命暴力行为的检测准确率。

**Conclusion:** 实验结果证明了该数据集的有效性，同时表明将GTA-Crime与领域适应策略结合能够显著提高现实中致命暴力事件的检测精度。

**Abstract:** Recent advancements in video anomaly detection (VAD) have enabled
identification of various criminal activities in surveillance videos, but
detecting fatal incidents such as shootings and stabbings remains difficult due
to their rarity and ethical issues in data collection. Recognizing this
limitation, we introduce GTA-Crime, a fatal video anomaly dataset and
generation framework using Grand Theft Auto 5 (GTA5). Our dataset contains
fatal situations such as shootings and stabbings, captured from CCTV multiview
perspectives under diverse conditions including action types, weather, time of
day, and viewpoints. To address the rarity of such scenarios, we also release a
framework for generating these types of videos. Additionally, we propose a
snippet-level domain adaptation strategy using Wasserstein adversarial training
to bridge the gap between synthetic GTA-Crime features and real-world features
like UCF-Crime. Experimental results validate our GTA-Crime dataset and
demonstrate that incorporating GTA-Crime with our domain adaptation strategy
consistently enhances real world fatal violence detection accuracy. Our dataset
and the data generation framework are publicly available at
https://github.com/ta-ho/GTA-Crime.

</details>


### [25] [RepViT-CXR: A Channel Replication Strategy for Vision Transformers in Chest X-ray Tuberculosis and Pneumonia Classification](https://arxiv.org/abs/2509.08234)
*Faisal Ahmed*

Main category: cs.CV

> 研发了一个名为RepViT-CXR的技术，用于将单通道的胸部X光图像调整为适合Vision Transformers (ViTs) 处理的三通道输入格式，并在多个数据集上超越了当前最佳模型。

<details>
  <summary>Details</summary>

**Motivation:** 解决现有的Vision Transformers (ViTs) 预训练模型无法直接处理单通道的胸部X光图像的问题，提高肺部疾病检测的准确性。

**Method:** 提出了RepViT-CXR，采用通道复制策略，通过复用单通道的胸部X光图像来生成符合ViTs输入需求的三通道图像，最大限度地减少信息损失。

**Result:** 在TB-CXR、Pediatric Pneumonia、Shenzhen TB三个基准数据集上，RepViT-CXR的表现优于之前最佳的方法，包括Topo-CXR、DCNN、VGG16等。

**Conclusion:** RepViT-CXR通过简单的通道复制策略，展示了在灰度医学图像分析上的优异表现，尤其是在结核病和肺炎的检测上，有助于临床筛查系统的实际部署。

**Abstract:** Chest X-ray (CXR) imaging remains one of the most widely used diagnostic
tools for detecting pulmonary diseases such as tuberculosis (TB) and pneumonia.
Recent advances in deep learning, particularly Vision Transformers (ViTs), have
shown strong potential for automated medical image analysis. However, most ViT
architectures are pretrained on natural images and require three-channel
inputs, while CXR scans are inherently grayscale. To address this gap, we
propose RepViT-CXR, a channel replication strategy that adapts single-channel
CXR images into a ViT-compatible format without introducing additional
information loss. We evaluate RepViT-CXR on three benchmark datasets. On the
TB-CXR dataset,our method achieved an accuracy of 99.9% and an AUC of 99.9%,
surpassing prior state-of-the-art methods such as Topo-CXR (99.3% accuracy,
99.8% AUC). For the Pediatric Pneumonia dataset, RepViT-CXR obtained 99.0%
accuracy, with 99.2% recall, 99.3% precision, and an AUC of 99.0%,
outperforming strong baselines including DCNN and VGG16. On the Shenzhen TB
dataset, our approach achieved 91.1% accuracy and an AUC of 91.2%, marking a
performance improvement over previously reported CNN-based methods. These
results demonstrate that a simple yet effective channel replication strategy
allows ViTs to fully leverage their representational power on grayscale medical
imaging tasks. RepViT-CXR establishes a new state of the art for TB and
pneumonia detection from chest X-rays, showing strong potential for deployment
in real-world clinical screening systems.

</details>
