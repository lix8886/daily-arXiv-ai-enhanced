<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 13]
- [cs.CV](#cs.CV) [Total: 17]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [MTEB-NL and E5-NL: Embedding Benchmark and Models for Dutch](https://arxiv.org/abs/2509.12340)
*Nikolay Banar,Ehsan Lotfi,Jens Van Nooten,Cristina Arhiliuc,Marija Kliocaite,Walter Daelemans*

Main category: cs.CL

> 为解决荷兰语在多语言资源中的代表性不足问题，我们推出了MTEB-NL，一个新训练数据集以及一系列高效的E5-NL模型。

<details>
  <summary>Details</summary>

**Motivation:** 荷兰语在发布的多语言资源中代表性不足，我们希望通过引入新的评估和生成资源来解决这一问题。

**Method:** 我们介绍了Massive Text Embedding Benchmark for Dutch (MTEB-NL)，它包含了现有的荷兰语数据集和新创建的数据集，涵盖了广泛的任务。此外，我们提供了一个训练数据集，该数据集基于现有的荷兰语检索数据集，并通过大型语言模型生成的合成数据来扩展任务覆盖范围。最后，我们发布了紧凑且高效的E5-NL模型系列，并通过Hugging Face Hub和MTEB包公开我们的资源。

**Result:** 我们发布了一系列的E5-NL模型，这些模型在多个任务上表现出色。

**Conclusion:** 我们的研究有助于填补荷兰语嵌入式资源的空白，并鼓励进一步开发荷兰语嵌入式模型。

**Abstract:** Recently, embedding resources, including models, benchmarks, and datasets,
have been widely released to support a variety of languages. However, the Dutch
language remains underrepresented, typically comprising only a small fraction
of the published multilingual resources. To address this gap and encourage the
further development of Dutch embeddings, we introduce new resources for their
evaluation and generation. First, we introduce the Massive Text Embedding
Benchmark for Dutch (MTEB-NL), which includes both existing Dutch datasets and
newly created ones, covering a wide range of tasks. Second, we provide a
training dataset compiled from available Dutch retrieval datasets, complemented
with synthetic data generated by large language models to expand task coverage
beyond retrieval. Finally, we release a series of E5-NL models compact yet
efficient embedding models that demonstrate strong performance across multiple
tasks. We make our resources publicly available through the Hugging Face Hub
and the MTEB package.

</details>


### [2] [MORABLES: A Benchmark for Assessing Abstract Moral Reasoning in LLMs with Fables](https://arxiv.org/abs/2509.12371)
*Matteo Marcuzzo,Alessandro Zangari,Andrea Albarelli,Jose Camacho-Collados,Mohammad Taher Pilehvar*

Main category: cs.CL

> The paper introduces MORABLES, a benchmark designed to assess large language models' capabilities in moral inference through complex reasoning and inference, highlighting the models' susceptibility to adversarial manipulation and reliance on superficial patterns.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to evaluate large language models' deeper comprehension skills, particularly in moral reasoning, beyond standard benchmarks that primarily test reading comprehension.

**Method:** The method involves creating multiple-choice questions from fables and short stories, introducing adversarial variants to challenge the models' robustness, and collecting human-verified answers for comparison.

**Result:** Larger models outperform smaller ones but exhibit significant vulnerabilities and often self-contradict when tested on moral choice questions, suggesting that their performance does not imply true reasoning ability.

**Conclusion:** The conclusion is that while larger models perform better on the MORABLES benchmark, their results are driven by scale rather than improved reasoning capabilities, and they struggle with adversarial manipulation.

**Abstract:** As LLMs excel on standard reading comprehension benchmarks, attention is
shifting toward evaluating their capacity for complex abstract reasoning and
inference. Literature-based benchmarks, with their rich narrative and moral
depth, provide a compelling framework for evaluating such deeper comprehension
skills. Here, we present MORABLES, a human-verified benchmark built from fables
and short stories drawn from historical literature. The main task is structured
as multiple-choice questions targeting moral inference, with carefully crafted
distractors that challenge models to go beyond shallow, extractive question
answering. To further stress-test model robustness, we introduce adversarial
variants designed to surface LLM vulnerabilities and shortcuts due to issues
such as data contamination. Our findings show that, while larger models
outperform smaller ones, they remain susceptible to adversarial manipulation
and often rely on superficial patterns rather than true moral reasoning. This
brittleness results in significant self-contradiction, with the best models
refuting their own answers in roughly 20% of cases depending on the framing of
the moral choice. Interestingly, reasoning-enhanced models fail to bridge this
gap, suggesting that scale - not reasoning ability - is the primary driver of
performance.

</details>


### [3] [LLM-as-a-Judge: Rapid Evaluation of Legal Document Recommendation for Retrieval-Augmented Generation](https://arxiv.org/abs/2509.12382)
*Anu Pradhan,Alexandra Ortan,Apurv Verma,Madhavan Seshadri*

Main category: cs.CL

> The paper investigates using LLMs as judges in AI evaluation, proposing more robust statistical methods for more reliable evaluations in legal applications.

<details>
  <summary>Details</summary>

**Motivation:** The main motivation behind this research is the inadequacy of current evaluation methods for Generative AI in specialized domains like legal research, where the quality of recommendations is critical.

**Method:** This paper explores the use of Large Language Models (LLM) as judges for evaluating Retrieval-Augmented Generation systems in legal contexts, addressing the limitations of traditional evaluation metrics. It discusses the importance of inter-rater reliability and statistical soundness in such evaluations.

**Result:** The study identifies Gwet's AC2 and rank correlation coefficients as more robust for judge selection than traditional agreement metrics like Krippendorff's alpha. It also recommends the use of the Wilcoxon Signed-Rank Test with Benjamini-Hochberg corrections for comparing systems statistically.

**Conclusion:** The findings propose a scalable, cost-effective, and statistically principled evaluation framework that automates the evaluation process for legal applications, thereby improving efficiency and maintaining high standards of recommendation quality.

**Abstract:** The evaluation bottleneck in recommendation systems has become particularly
acute with the rise of Generative AI, where traditional metrics fall short of
capturing nuanced quality dimensions that matter in specialized domains like
legal research. Can we trust Large Language Models to serve as reliable judges
of their own kind? This paper investigates LLM-as-a-Judge as a principled
approach to evaluating Retrieval-Augmented Generation systems in legal
contexts, where the stakes of recommendation quality are exceptionally high.
  We tackle two fundamental questions that determine practical viability: which
inter-rater reliability metrics best capture the alignment between LLM and
human assessments, and how do we conduct statistically sound comparisons
between competing systems? Through systematic experimentation, we discover that
traditional agreement metrics like Krippendorff's alpha can be misleading in
the skewed distributions typical of AI system evaluations. Instead, Gwet's AC2
and rank correlation coefficients emerge as more robust indicators for judge
selection, while the Wilcoxon Signed-Rank Test with Benjamini-Hochberg
corrections provides the statistical rigor needed for reliable system
comparisons.
  Our findings suggest a path toward scalable, cost-effective evaluation that
maintains the precision demanded by legal applications, transforming what was
once a human-intensive bottleneck into an automated, yet statistically
principled, evaluation framework.

</details>


### [4] [SENTRA: Selected-Next-Token Transformer for LLM Text Detection](https://arxiv.org/abs/2509.12385)
*Mitchell Plyler,Yilun Zhang,Alexander Tuzhilin,Saoud Khalifah,Sen Tian*

Main category: cs.CL

> 本文介绍了一种名为SEnTRA的新方法，用于检测未声明为LLM生成的文本。该方法基于Transformer编码器，经实验验证，在跨领域检测上优于现有方法。

<details>
  <summary>Details</summary>

**Motivation:** 随着LLM能力的提升和应用的广泛，其被滥用的可能性也在增加。本文旨在解决未明确声明的LLM生成文本的检测问题，尤其是在跨领域场景下。

**Method:** 本文提出了一种新的、通用的、基于监督学习的LLM文本检测器SEnTRA。SEnTRA基于Transformer编码器，利用选择的下一个token概率序列，并通过在大量未标记数据上的对比预训练来提升性能。

**Result:** 实验在跨越24个文本领域的三个流行公开数据集上进行，结果表明SEnTRA作为一种通用分类器，在跨领域设置下显著超越了流行的基线模型。

**Conclusion:** SEnTRA能有效地检测未声明的LLM生成文本，并展示了其在不同类型文本数据上的通用性和优越性。

**Abstract:** LLMs are becoming increasingly capable and widespread. Consequently, the
potential and reality of their misuse is also growing. In this work, we address
the problem of detecting LLM-generated text that is not explicitly declared as
such. We present a novel, general-purpose, and supervised LLM text detector,
SElected-Next-Token tRAnsformer (SENTRA). SENTRA is a Transformer-based encoder
leveraging selected-next-token-probability sequences and utilizing contrastive
pre-training on large amounts of unlabeled data. Our experiments on three
popular public datasets across 24 domains of text demonstrate SENTRA is a
general-purpose classifier that significantly outperforms popular baselines in
the out-of-domain setting.

</details>


### [5] [MORQA: Benchmarking Evaluation Metrics for Medical Open-Ended Question Answering](https://arxiv.org/abs/2509.12405)
*Wen-wai Yim,Asma Ben Abacha,Zixuan Yu,Robert Doerning,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

> 本文介绍了MORQA，一个专门为医疗领域设计的多语言基准测试，旨在评估自然语言生成系统的输出质量。研究发现，大语言模型在评价与专家判断的一致性上优于传统指标，强调了符合人类标准的评估方法的重要性。

<details>
  <summary>Details</summary>

**Motivation:** 自然语言生成（NLG）系统在医疗领域的评估面临独特的挑战，主要是因为对准确性和领域专业知识的要求极高。传统的自动评估指标，在区分高质量输出时常常无法满足要求，尤其是在医疗问答任务中，由于答案的开放性使得多份有效回答可能并存。

**Method:** 本文介绍了MORQA（Medical Open-Response QA），一个新设计的多语言基准测试，用于评估自然语言生成（NLG）评估指标在三个医疗视觉和文本问答数据集上的有效性，这些数据集包含英语和中文。与其他资源不同，这些数据集包括由医疗专家编写的不同数量的黄金标准答案，以及三个英语和中文子集的专家人工评分。

**Result:** 本文对传统指标和大语言模型（LLM）评估者（如GPT-4和Gemini）进行了基准测试，结果表明，基于LLM的方法在与专家评价关联方面显著优于传统指标。

**Conclusion:** 研究结果提供了第一个全面的多语言定性研究，揭示了医疗领域NLG评估中需要符合人类标准的评估方法。所有数据集和标注都将公开发布以支持未来的研究。

**Abstract:** Evaluating natural language generation (NLG) systems in the medical domain
presents unique challenges due to the critical demands for accuracy, relevance,
and domain-specific expertise. Traditional automatic evaluation metrics, such
as BLEU, ROUGE, and BERTScore, often fall short in distinguishing between
high-quality outputs, especially given the open-ended nature of medical
question answering (QA) tasks where multiple valid responses may exist. In this
work, we introduce MORQA (Medical Open-Response QA), a new multilingual
benchmark designed to assess the effectiveness of NLG evaluation metrics across
three medical visual and text-based QA datasets in English and Chinese. Unlike
prior resources, our datasets feature 2-4+ gold-standard answers authored by
medical professionals, along with expert human ratings for three English and
Chinese subsets. We benchmark both traditional metrics and large language model
(LLM)-based evaluators, such as GPT-4 and Gemini, finding that LLM-based
approaches significantly outperform traditional metrics in correlating with
expert judgments. We further analyze factors driving this improvement,
including LLMs' sensitivity to semantic nuances and robustness to variability
among reference answers. Our results provide the first comprehensive,
multilingual qualitative study of NLG evaluation in the medical domain,
highlighting the need for human-aligned evaluation methods. All datasets and
annotations will be publicly released to support future research.

</details>


### [6] [MedFact: Benchmarking the Fact-Checking Capabilities of Large Language Models on Chinese Medical Texts](https://arxiv.org/abs/2509.12440)
*Jiayi He,Yangmin Huang,Qianyun Du,Xiangying Zhou,Zhiyang He,Jiaxue Hu,Xiaodong Tao,Lixian Lai*

Main category: cs.CL

> 本文介绍了MedFact，一个新的中文医疗事实核查基准测试，用于评估大语言模型在医疗领域的事实可靠性，并揭示了即使顶级模型在错误定位上也难以达到人类水平，并且存在过度批评正确信息的现象。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试往往局限于狭窄的数据领域，无法捕捉到实际医疗信息的复杂性。为了弥补这一关键差距，本文提出了MedFact，一个针对中文医疗事实核查的新且具有挑战性的基准测试。

**Method:** MedFact由2116个专家注释的实例组成，这些实例来自多样化的实际文本，横跨13个医疗专科、8种细粒度错误类型、4种写作风格和多个难度级别。其构造采用混合的AI-human框架，专家反馈迭代地精炼AI驱动的多标准筛选过程。

**Result:** 对20个领先大语言模型的综合评估表明，模型通常能判断文本中是否包含错误，但在准确定位错误方面仍然面临较大挑战，顶级模型的表现也未达到人类专家的水平。另外，还发现模型存在过度批评正确信息的现象。

**Conclusion:** 通过强调在医疗应用中部署大语言模型所面临的这些关键挑战，MedFact提供了一个强大的资源，以推动更可靠和医学意识更强的模型的发展。

**Abstract:** The increasing deployment of Large Language Models (LLMs) in healthcare
necessitates a rigorous evaluation of their factual reliability. However,
existing benchmarks are often limited by narrow domains of data, failing to
capture the complexity of real-world medical information. To address this
critical gap, we introduce MedFact, a new and challenging benchmark for Chinese
medical fact-checking. MedFact comprises 2,116 expert-annotated instances
curated from diverse real-world texts, spanning 13 medical specialties, 8
fine-grained error types, 4 writing styles, and multiple difficulty levels. Its
construction employs a hybrid AI-human framework where iterative expert
feedback refines an AI-driven, multi-criteria filtering process, ensuring both
high data quality and difficulty. We conduct a comprehensive evaluation of 20
leading LLMs, benchmarking their performance on veracity classification and
error localization against a human expert baseline. Our results reveal that
while models can often determine if a text contains an error, precisely
localizing it remains a substantial challenge, with even top-performing models
falling short of human performance. Furthermore, our analysis uncovers a
frequent ``over-criticism'' phenomenon, a tendency for models to misidentify
correct information as erroneous, which is exacerbated by advanced reasoning
techniques such as multi-agent collaboration and inference-time scaling. By
highlighting these critical challenges for deploying LLMs in medical
applications, MedFact provides a robust resource to drive the development of
more factually reliable and medically aware models.

</details>


### [7] [Topic Coverage-based Demonstration Retrieval for In-Context Learning](https://arxiv.org/abs/2509.12451)
*Wonbin Kweon,SeongKu Kang,Runchu Tian,Pengcheng Jiang,Jiawei Han,Hwanjo Yu*

Main category: cs.CL

> The paper introduces TopicK, a method for in-context learning that retrieves demonstrations by focusing on topic-level knowledge required for a given input, significantly improving on previous techniques.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve upon prior methods that retrieve demonstrations based solely on embedding similarity or generation probability, which often lead to irrelevant or redundant examples. This is crucial for effective in-context learning by ensuring comprehensive coverage of topic-level knowledge relevant to both the test input and the model.

**Method:** TopicK, a topic coverage-based retrieval framework, is proposed. This framework estimates the topics required by the input and assesses the model's knowledge on those topics, iteratively selecting demonstrations that introduce previously uncovered required topics where the model exhibits low topical knowledge.

**Result:** The effectiveness of TopicK is validated through extensive experiments across various datasets and both open- and closed-source LLMs.

**Conclusion:** TopicK demonstrates improved demonstration retrieval for in-context learning by focusing on required topic-level knowledge, leading to better performance across tested models and datasets.

**Abstract:** The effectiveness of in-context learning relies heavily on selecting
demonstrations that provide all the necessary information for a given test
input. To achieve this, it is crucial to identify and cover fine-grained
knowledge requirements. However, prior methods often retrieve demonstrations
based solely on embedding similarity or generation probability, resulting in
irrelevant or redundant examples. In this paper, we propose TopicK, a topic
coverage-based retrieval framework that selects demonstrations to
comprehensively cover topic-level knowledge relevant to both the test input and
the model. Specifically, TopicK estimates the topics required by the input and
assesses the model's knowledge on those topics. TopicK then iteratively selects
demonstrations that introduce previously uncovered required topics, in which
the model exhibits low topical knowledge. We validate the effectiveness of
TopicK through extensive experiments across various datasets and both open- and
closed-source LLMs. Our source code is available at
https://github.com/WonbinKweon/TopicK_EMNLP2025.

</details>


### [8] [Does Language Model Understand Language?](https://arxiv.org/abs/2509.12459)
*Suvojit Acharjee,Utathya Aich,Asfak Ali*

Main category: cs.CL

> 本研究评估了最先进的语言模型在英语和孟加拉语细节复杂语言现象理解上的能力，引入了新的评估指南和HCE准确性指标，并发现Compound-Beta是最稳定的模型，其在跨语言表现上具有与人类判断高度一致的特点。

<details>
  <summary>Details</summary>

**Motivation:** 尽管自然语言生成和理解方面取得了进展，但语言模型在处理诸如时态、否定、语态和语气等细微语言现象方面仍存在困难，这些现象对于有效的沟通至关重要。本研究的动机在于，为了在教育技术中部署语言模型（例如辅导系统、自动评分和翻译应用），需要严格评估这些模型与人类语言理解的一致性，特别是在联合国可持续发展目标4（SDG 4）所强调的语言清晰度方面。

**Method:** 本文介绍了一个新的评估认知推理系统环境的指南，使用了一个名为LUCID的数据集来评估最先进的语言模型在处理细节复杂的语言现象（如时态、否定、语态变化）方面的表现。评估使用的标准包括皮尔森相关系数、斯皮尔曼等级相关系数、平均绝对误差以及一个新的语料库启发度准确性（HCE准确性）指标，该指标反映模型判断在接近人类打分平均值一个标准差范围内的频率。

**Result:** 研究结果强调Compound-Beta为性能最均衡的模型，它在各类语言条件下展示了高相关性和低MAE。特别地，该模型在英语中表现出最高的皮尔森相关系数，并在混合语言数据上表现出稳定的性能，表明其在跨语言情况中与人类判断高度一致。

**Conclusion:** 研究结论表明，Compound-Beta在英语和混合语言环境下表现出最高相关性和最低平均绝对误差，显示出与人类判断的高度一致性，尤其是在跨语言场景中。这表明Compound-Beta是解决教育技术领域语言理解挑战的一种前景广阔的语言模型。

**Abstract:** Despite advances in natural language generation and understanding, LM still
struggle with fine grained linguistic phenomena such as tense, negation, voice,
and modality which are the elements central to effective human communication.
In the context of the United Nations SDG 4, where linguistic clarity is
critical, the deployment of LMs in educational technologies demands careful
scrutiny. As LMs are increasingly powering applications like tutoring systems,
automated grading, and translation, their alignment with human linguistic
interpretation becomes essential for effective learning. In this study, we
conduct a evaluation of SOTA language models across these challenging contexts
in both English and Bengali. To ensure a structured assessment, we introduce a
new Route for Evaluation of Cognitive Inference in Systematic Environments
guidelines. Our proposed LUCID dataset, composed of carefully crafted sentence
pairs in English and Bengali, specifically challenges these models on critical
aspects of language comprehension, including negation, tense, voice variations.
We assess the performance of SOTA models including MISTRAL-SABA-24B,
LLaMA-4-Scout-17B, LLaMA-3.3-70B, Gemma2-9B, and Compound-Beta using standard
metrics like Pearson correlation, Spearman correlation, and Mean Absolute
Error, as well as novel, linguistically inspired metric the HCE accuracy. The
HCE accuracy measures how often model predictions fall within one standard
deviation of the mean human rating, thus capturing human like tolerance for
variability in language interpretation. Our findings highlight Compound-Beta as
the most balanced model, consistently achieving high correlations and low MAEs
across diverse language conditions. It records the highest Pearson correlation
in English and demonstrates robust performance on mixed-language data,
indicating a strong alignment with human judgments in cross lingual scenarios.

</details>


### [9] [Audited Reasoning Refinement: Fine-Tuning Language Models via LLM-Guided Step-Wise Evaluation and Correction](https://arxiv.org/abs/2509.12476)
*Sumanta Bhattacharyya,Sara Riaz,Pedram Rooshenas*

Main category: cs.CL

> 我们提出了Reason-Refine-then-Align (R2tA) 的方法，通过精炼大型语言模型（LLMs）产生的推理痕迹，形成高质量的数据集并进行两阶段的校正，以训练在数据稀缺领域中具有推理能力的小型模型，解决其在特定任务中的挑战，使得能够生成更加准确和一致的推理输出。

<details>
  <summary>Details</summary>

**Motivation:** 直接的人类监督或高质量标签稀缺时，训练特定任务的小型推理模型是具有挑战性的。大型语言模型（LLMs）具备推理能力，产生丰富的中间推理痕迹，可以系统地精炼为有效的监督信号。为此我们提出了一种基于精炼模型推理以作为训练任务特定推理模型的监督信号的方法。

**Method:** 我们提出了一种名为Reason-Refine-then-Align (R2tA) 的方法，首先从一个开源基础模型中生成特定任务的初始推理和响应，然后通过修正幻觉和不一致性来精炼这些推理，从而形成一个高质量的数据集。接着，进行两阶段的对齐，首先是监督微调（SFT），然后是直接偏好优化（DPO），以调整模型的中间推理与经过人工验证的概念偏好相符，最后以这个对齐后的推理为条件进行输出。

**Result:** 我们使用R2tA进行了一个案例研究，将其应用于数据库系统设计中评估扩展实体关系图（EERDs），这是一个结构上较为复杂的任务，而单纯使用提示的方法往往会错过或产生错误。实验结果表明，R2tA提供了一种实用且成本有效的路径，可以在数据稀缺领域内实现大规模的LLM适应，能够创造出可重复使用的AI工具，适用于教育等众多领域。

**Conclusion:** R2tA为数据稀缺领域的LLM适应提供了一种实际可行、成本效益高的解决方案，特别是对于复杂任务，如数据库系统的设计评估，R2tA能够训练出任务特定的高质量推理模型，并且可以生成教育、科研等领域的可复用AI工具。

**Abstract:** Training a task-specific small reasoning model is challenging when direct
human supervision or high-quality labels are scarce. However, LLMs with
reasoning capabilities produce abundant intermediate reasoning traces that can
be systematically refined to create effective supervision signals. We propose
Reason-Refine-then-Align (R2tA), which turns refined model rationales into
supervision for training task-specific reasoning models. Our method generates
initial reasoning and responses from an open-source base model on task-specific
inputs, then refines these traces, fixing hallucinations and inconsistencies,
to form a high-fidelity dataset. We perform a two-stage alignment, supervised
fine-tuning (SFT), followed by direct preference optimization (DPO) to
calibrate the model's intermediate reasoning with human-validated conceptual
preferences and then condition the final output on that aligned reasoning. As a
case study, we apply R2tA to evaluate extended entity relationship diagrams
(EERDs) in database system design, a structurally complex task where
prompt-only methods miss or hallucinate errors. We curated a dataset of 600
EERD variants (train/test split of 450/150, respectively) with induced mistakes
spanning 11 categories. Empirical evaluation suggests R2tA provides a
practical, cost-effective path to scalable LLM adaptation in data-scarce
domains, enabling reproducible AI tools for education and beyond.

</details>


### [10] [FunAudio-ASR Technical Report](https://arxiv.org/abs/2509.12508)
*Keyu An,Yanni Chen,Chong Deng,Changfeng Gao,Zhifu Gao,Bo Gong,Xiangang Li,Yabin Li,Xiang Lv,Yunjie Ji,Yiheng Jiang,Bin Ma,Haoneng Luo,Chongjia Ni,Zexu Pan,Yiping Peng,Zhendong Peng,Peiyao Wang,Hao Wang,Wen Wang,Wupeng Wang,Biao Tian,Zhentao Tan,Nan Yang,Bin Yuan,Jieping Ye,Jixing Yu,Qinglin Zhang,Kun Zou,Han Zhao,Shengkui Zhao,Jingren Zhou*

Main category: cs.CL

> FunAudio-ASR是结合大规模数据、模型集成和强化学习的先进自动语音识别系统，针对实际应用需求进行优化，能够在复杂和多样的语音识别场景中实现最先进性能。实验结果显示其在真实场景中的表现优秀。

<details>
  <summary>Details</summary>

**Motivation:** 自动语音识别（ASR）尽管受益于数据和模型规模的扩展以及与大型语言模型的集成取得了显著进步，但大型语言模型存在幻觉问题，这在实际应用中会显著降低用户体验。本论文旨在通过FunAudio-ASR解决这些问题。

**Method:** 本文介绍了一个名为FunAudio-ASR的大型LLM（Large Language Model）为基础的自动语音识别（ASR）系统。该系统综合了大规模数据、大型模型容量、与大型语言模型的深度集成以及强化学习，以实现各种复杂语音识别场景中的最先进性能。

**Result:** 实验结果表明，尽管许多基于LLM的ASR系统在开源基准上的性能较强，但在实际工业评估集上的表现却不如预期。而由于以生产为导向的优化，FunAudio-ASR在实际应用场景的数据集上达到了最先进性能，并展示了其实用和鲁棒的表现。

**Conclusion:** 论文结论是FunAudio-ASR通过对流媒体能力、噪声鲁棒性、代码切换、关键词定制等的优化，不仅提升了解决方案的实际应用效果，还展示了在实际设定中的有效性和鲁棒性。

**Abstract:** In recent years, automatic speech recognition (ASR) has witnessed
transformative advancements driven by three complementary paradigms: data
scaling, model size scaling, and deep integration with large language models
(LLMs). However, LLMs are prone to hallucination, which can significantly
degrade user experience in real-world ASR applications. In this paper, we
present FunAudio-ASR, a large-scale, LLM-based ASR system that synergistically
combines massive data, large model capacity, LLM integration, and reinforcement
learning to achieve state-of-the-art performance across diverse and complex
speech recognition scenarios. Moreover, FunAudio-ASR is specifically optimized
for practical deployment, with enhancements in streaming capability, noise
robustness, code-switching, hotword customization, and satisfying other
real-world application requirements. Experimental results show that while most
LLM-based ASR systems achieve strong performance on open-source benchmarks,
they often underperform on real industry evaluation sets. Thanks to
production-oriented optimizations, FunAudio-ASR achieves SOTA performance on
real application datasets, demonstrating its effectiveness and robustness in
practical settings.

</details>


### [11] [A comparison of pipelines for the translation of a low resource language based on transformers](https://arxiv.org/abs/2509.12514)
*Chiara Bonfanti,Michele Colombino,Giulia Coucourde,Faeze Memari,Stefano Pinardi,Rosa Meo*

Main category: cs.CL

> A study comparing three different pipelines for creating machine translation models for Bambara, a language with low resources. The simpler transformer-based pipeline achieves the best translation accuracy despite the complex methods used in other pipelines.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this paper is to investigate and compare different methodologies for developing a machine translator for Bambara, a language with low-resource availability. The study aims to find the most effective translation pipeline for such low-resource languages.

**Method:** This work involves three distinct pipelines for creating machine translators for Bambara. The first pipeline involves training a simple transformer model for French to Bambara translation. The second pipeline fine-tunes LLaMA3 instructor models using decoder-only architectures for similar translation tasks. The third pipeline utilizes language distillation with a student-teacher dual neural network approach to integrate Bambara into the pre-trained LaBSE model with BERT extension for generating translations.

**Result:** The results reveal that the first pipeline, despite its simplicity, achieves the highest translation accuracy with 10% BLEU and 21% chrF scores on the Bayelemagaba dataset. On the newly created Yiri dataset, it attains 33.81% BLEU and 41% chrF scores. Moreover, the instructor-based models perform better on individual datasets compared to aggregated datasets indicating a bias towards capturing dataset-specific nuances.

**Conclusion:** The conclusion drawn from the work shows that even a simpler method might outperform more sophisticated models when it comes to translation accuracy for low-resource languages like Bambara. It also underscores the potential of dataset-specific models over general ones.

**Abstract:** This work compares three pipelines for training transformer-based neural
networks to produce machine translators for Bambara, a Mand\`e language spoken
in Africa by about 14,188,850 people. The first pipeline trains a simple
transformer to translate sentences from French into Bambara. The second
fine-tunes LLaMA3 (3B-8B) instructor models using decoder-only architectures
for French-to-Bambara translation. Models from the first two pipelines were
trained with different hyperparameter combinations to improve BLEU and chrF
scores, evaluated on both test sentences and official Bambara benchmarks. The
third pipeline uses language distillation with a student-teacher dual neural
network to integrate Bambara into a pre-trained LaBSE model, which provides
language-agnostic embeddings. A BERT extension is then applied to LaBSE to
generate translations. All pipelines were tested on Dokotoro (medical) and
Bayelemagaba (mixed domains). Results show that the first pipeline, although
simpler, achieves the best translation accuracy (10% BLEU, 21% chrF on
Bayelemagaba), consistent with low-resource translation results. On the Yiri
dataset, created for this work, it achieves 33.81% BLEU and 41% chrF.
Instructor-based models perform better on single datasets than on aggregated
collections, suggesting they capture dataset-specific patterns more
effectively.

</details>


### [12] [MAGIC-Enhanced Keyword Prompting for Zero-Shot Audio Captioning with CLIP Models](https://arxiv.org/abs/2509.12591)
*Vijay Govindarajan,Pratik Patel,Sahil Tripathi,Md Azizul Hoque,Gautam Siddharth Kashyap*

Main category: cs.CL

> This paper introduces a zero-shot Automated Audio Captioning system that utilizes a pre-trained audio CLIP model and a Large Language Model (LLM) to generate accurate captions, significantly improving performance metrics when compared to previous methods.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this research is to tackle the challenges faced by Automated Audio Captioning (AAC) systems due to limited datasets by leveraging pre-trained models to achieve a zero-shot AAC system.

**Method:** Our approach involves using a pre-trained audio CLIP model to extract auditory features and generate a structured prompt, which guides a Large Language Model (LLM) in the process of generating captions. This method refines the selection of tokens through the audio CLIP model to ensure alignment with the audio content, differing from the traditional greedy decoding strategy.

**Result:** The research demonstrates a 35% improvement in the NLG mean score, rising from 4.7 to 7.3, when using the MAGIC search with the WavCaps model. It was observed that performance was heavily reliant on the audio-text matching model and keyword selection.

**Conclusion:** The effectiveness of the proposed zero-shot AAC system has been demonstrated, particularly when using a single keyword prompt, which suggests directions for future improvements in audio captioning technology.

**Abstract:** Automated Audio Captioning (AAC) generates captions for audio clips but faces
challenges due to limited datasets compared to image captioning. To overcome
this, we propose the zero-shot AAC system that leverages pre-trained models,
eliminating the need for extensive training. Our approach uses a pre-trained
audio CLIP model to extract auditory features and generate a structured prompt,
which guides a Large Language Model (LLM) in caption generation. Unlike
traditional greedy decoding, our method refines token selection through the
audio CLIP model, ensuring alignment with the audio content. Experimental
results demonstrate a 35% improvement in NLG mean score (from 4.7 to 7.3) using
MAGIC search with the WavCaps model. The performance is heavily influenced by
the audio-text matching model and keyword selection, with optimal results
achieved using a single keyword prompt, and a 50% performance drop when no
keyword list is used.

</details>


### [13] [EconProver: Towards More Economical Test-Time Scaling for Automated Theorem Proving](https://arxiv.org/abs/2509.12603)
*Mukai Li,Linfeng Song,Zhenwen Liang,Jiahao Xu,Shansan Gong,Qi Liu,Haitao Mi,Dong Yu*

Main category: cs.CL

> 本研究对比了不同推理策略在自动定理证明中的计算效率，提出了EconRL管道，结合动态链式思考切换机制和多样化的并行强化学习，大幅减少计算成本同时保持性能。实验表明EconProver在miniF2F和ProofNet数据集上，仅以12%的计算成本达到基线方法的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的大语言模型虽然通过测试时的时间扩展策略提升了自动定理证明性能，但也带来了大量的计算开销。当前的成本分析仅控制采样次数，忽略不同策略造成的成本差异。本研究旨在系统性地对比不同的推理策略，并提出减少计算成本的方法。

**Method:** 结构化论文分析方法用于提取关键信息

**Result:** 实验在两个数据集miniF2F和ProofNet上表明，EconProver相比于基线方法，在保持性能的同时，计算成本仅为其12%。

**Conclusion:** 本研究为部署轻量级自动定理证明模型提供了可行的见解，即在不牺牲性能的情况下减少计算成本。

**Abstract:** Large Language Models (LLMs) have recently advanced the field of Automated
Theorem Proving (ATP), attaining substantial performance gains through widely
adopted test-time scaling strategies, notably reflective Chain-of-Thought (CoT)
reasoning and increased sampling passes. However, they both introduce
significant computational overhead for inference. Moreover, existing cost
analyses typically regulate only the number of sampling passes, while
neglecting the substantial disparities in sampling costs introduced by
different scaling strategies. In this paper, we systematically compare the
efficiency of different test-time scaling strategies for ATP models and
demonstrate the inefficiency of the current state-of-the-art (SOTA) open-source
approaches. We then investigate approaches to significantly reduce token usage
and sample passes while maintaining the original performance. Specifically, we
propose two complementary methods that can be integrated into a unified EconRL
pipeline for amplified benefits: (1) a dynamic Chain-of-Thought (CoT) switching
mechanism designed to mitigate unnecessary token consumption, and (2) Diverse
parallel-scaled reinforcement learning (RL) with trainable prefixes to enhance
pass rates under constrained sampling passes. Experiments on miniF2F and
ProofNet demonstrate that our EconProver achieves comparable performance to
baseline methods with only 12% of the computational cost. This work provides
actionable insights for deploying lightweight ATP models without sacrificing
performance.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [14] [Artificial Intelligence in Breast Cancer Care: Transforming Preoperative Planning and Patient Education with 3D Reconstruction](https://arxiv.org/abs/2509.12242)
*Mustafa Khanbhai,Giulia Di Nardo,Jun Ma,Vivienne Freitas,Caterina Masino,Ali Dolatabadi,Zhaoxun "Lorenz" Liu,Wey Leong,Wagner H. Souza,Amin Madani*

Main category: cs.CV

> 本研究提出了一种新的机器学习方法U-Mamba，用于提高3D解剖结构重建算法在乳腺癌等应用中的泛化能力。实验表明该方法在不同解剖结构上的Dice相似性系数(DSC)值分别为0.97、0.96和0.82，并通过临床评估证明了其在手术计划和患者教育方面的价值。

<details>
  <summary>Details</summary>

**Motivation:** 传统的模型在泛化能力方面存在局限性，难以处理不同数据集中的解剖结构分割。本研究旨在提高算法的泛化能力，以改善3D解剖重建的精度，超越乳腺癌应用范围。

**Method:** 本研究对2018年1月至2023年6月的120份回顾性乳腺MRI进行处理，利用U-Mamba模型对T1加权和动态对比增强序列图像进行分割，并在ITK-SNAP软件中进行3D可视化。通过人工介入的方式进行模型优化，以提高其在不同影像场景中的泛化能力。

**Result:** 使用U-Mamba模型，在全器官、纤维腺体组织以及肿瘤分割上，DSC值分别为0.97（±0.013）、0.96（±0.024）和0.82（±0.12），显示了强大的性能。

**Conclusion:** 基于人工介入的机器学习方法成功使算法在不同患者数据集的3D重建和解剖分割上泛化，改进了临床前规划和手术导航，并提升了患者教育，更好地支持了共享决策和患者自主选择。

**Abstract:** Effective preoperative planning requires accurate algorithms for segmenting
anatomical structures across diverse datasets, but traditional models struggle
with generalization. This study presents a novel machine learning methodology
to improve algorithm generalization for 3D anatomical reconstruction beyond
breast cancer applications. We processed 120 retrospective breast MRIs (January
2018-June 2023) through three phases: anonymization and manual segmentation of
T1-weighted and dynamic contrast-enhanced sequences; co-registration and
segmentation of whole breast, fibroglandular tissue, and tumors; and 3D
visualization using ITK-SNAP. A human-in-the-loop approach refined
segmentations using U-Mamba, designed to generalize across imaging scenarios.
Dice similarity coefficient assessed overlap between automated segmentation and
ground truth. Clinical relevance was evaluated through clinician and patient
interviews. U-Mamba showed strong performance with DSC values of 0.97
($\pm$0.013) for whole organs, 0.96 ($\pm$0.024) for fibroglandular tissue, and
0.82 ($\pm$0.12) for tumors on T1-weighted images. The model generated accurate
3D reconstructions enabling visualization of complex anatomical features.
Clinician interviews indicated improved planning, intraoperative navigation,
and decision support. Integration of 3D visualization enhanced patient
education, communication, and understanding. This human-in-the-loop machine
learning approach successfully generalizes algorithms for 3D reconstruction and
anatomical segmentation across patient datasets, offering enhanced
visualization for clinicians, improved preoperative planning, and more
effective patient education, facilitating shared decision-making and empowering
informed patient choices across medical applications.

</details>


### [15] [RU-Net for Automatic Characterization of TRISO Fuel Cross Sections](https://arxiv.org/abs/2509.12244)
*Lu Cai,Fei Xu,Min Xian,Yalei Tang,Shoukun Sun,John Stempien*

Main category: cs.CV

> 研究使用卷积神经网络（CNN）自动分割TRISO颗粒微观横截面图像，减少了分析中的主观性和手动工作量，并提高了分割结果的客观性。RU-Net模型在IoU方面表现最佳。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于TRISO颗粒燃料在辐照过程中会出现芯块膨胀和缓冲层致密化等现象，传统的手工分析既耗时又具有主观性。为了减少这种主观性并加速数据分析的进程，研究引入了卷积神经网络进行自动分析。

**Method:** 生成了包含2000多张辐照TRISO层微观图像及其标注图像的大数据集，使用RU-Net以及三种现存架构（U-Net、ResNet和Attention U-Net）进行自动分割。RU-Net是在此次研究中开发的模型。

**Result:** 初步结果显示，基于RU-Net的模型在衡量两个区域重叠程度的IoU指标上表现最佳。

**Conclusion:** 通过使用CNN模型，加快了TRISO颗粒横截面图像的分析速度，明显减少了手工劳动并提高了分割结果的客观性。

**Abstract:** During irradiation, phenomena such as kernel swelling and buffer
densification may impact the performance of tristructural isotropic (TRISO)
particle fuel. Post-irradiation microscopy is often used to identify these
irradiation-induced morphologic changes. However, each fuel compact generally
contains thousands of TRISO particles. Manually performing the work to get
statistical information on these phenomena is cumbersome and subjective. To
reduce the subjectivity inherent in that process and to accelerate data
analysis, we used convolutional neural networks (CNNs) to automatically segment
cross-sectional images of microscopic TRISO layers. CNNs are a class of
machine-learning algorithms specifically designed for processing structured
grid data. They have gained popularity in recent years due to their remarkable
performance in various computer vision tasks, including image classification,
object detection, and image segmentation. In this research, we generated a
large irradiated TRISO layer dataset with more than 2,000 microscopic images of
cross-sectional TRISO particles and the corresponding annotated images. Based
on these annotated images, we used different CNNs to automatically segment
different TRISO layers. These CNNs include RU-Net (developed in this study), as
well as three existing architectures: U-Net, Residual Network (ResNet), and
Attention U-Net. The preliminary results show that the model based on RU-Net
performs best in terms of Intersection over Union (IoU). Using CNN models, we
can expedite the analysis of TRISO particle cross sections, significantly
reducing the manual labor involved and improving the objectivity of the
segmentation results.

</details>


### [16] [Modular, On-Site Solutions with Lightweight Anomaly Detection for Sustainable Nutrient Management in Agriculture](https://arxiv.org/abs/2509.12247)
*Abigail R. Cohen,Yuming Sun,Zhihao Qin,Harsh S. Muriki,Zihao Xiao,Yeonju Lee,Matthew Housley,Andrew F. Sharkey,Rhuanito S. Ferrarezi,Jing Li,Lu Gan,Yongsheng Chen*

Main category: cs.CV

> The paper proposes a flexible, tiered pipeline using multi-spectral imaging and machine/deep learning for efficient nutrient management in crop growth, balancing between energy efficiency and estimation accuracy.

<details>
  <summary>Details</summary>

**Motivation:** The motivation of the study is to improve nutrient management efficiency for crop growth and sustainable resource use, overcoming the limitations of current approaches which are either slow or too computationally intensive.

**Method:** This study uses a nutrient depletion experiment with three treatments (100%, 50%, and 25% fertilizer strength), and multispectral imaging (MSI). A hierarchical pipeline involving an autoencoder (AE) for early warning and two status estimation modules (vegetation index features with machine learning (Random Forest, RF) and raw whole-image deep learning (Vision Transformer, ViT)) are developed for anomaly detection and status estimation.

**Result:** The study concludes that the hierarchical pipeline provides high-efficiency anomaly detection (73% detection of T3 samples 9 days after transplanting) with lower energy consumption. The state estimation using ViT outperforms that using RF in assessing phosphorus and calcium but at a higher energy cost.

**Conclusion:** The findings suggest that the modular pipeline can contribute to edge diagnostics and sustainable agriculture practices, offering a balance between energy efficiency and detailed analysis capability.

**Abstract:** Efficient nutrient management is critical for crop growth and sustainable
resource consumption (e.g., nitrogen, energy). Current approaches require
lengthy analyses, preventing real-time optimization; similarly, imaging
facilitates rapid phenotyping but can be computationally intensive, preventing
deployment under resource constraints. This study proposes a flexible, tiered
pipeline for anomaly detection and status estimation (fresh weight, dry mass,
and tissue nutrients), including a comprehensive energy analysis of approaches
that span the efficiency-accuracy spectrum. Using a nutrient depletion
experiment with three treatments (T1-100%, T2-50%, and T3-25% fertilizer
strength) and multispectral imaging (MSI), we developed a hierarchical pipeline
using an autoencoder (AE) for early warning. Further, we compared two status
estimation modules of different complexity for more detailed analysis:
vegetation index (VI) features with machine learning (Random Forest, RF) and
raw whole-image deep learning (Vision Transformer, ViT). Results demonstrated
high-efficiency anomaly detection (73% net detection of T3 samples 9 days after
transplanting) at substantially lower energy than embodied energy in wasted
nitrogen. The state estimation modules show trade-offs, with ViT outperforming
RF on phosphorus and calcium estimation (R2 0.61 vs. 0.58, 0.48 vs. 0.35) at
higher energy cost. With our modular pipeline, this work opens opportunities
for edge diagnostics and practical opportunities for agricultural
sustainability.

</details>


### [17] [Humor in Pixels: Benchmarking Large Multimodal Models Understanding of Online Comics](https://arxiv.org/abs/2509.12248)
*Yuriel Ryan,Rui Yang Tan,Kenny Tsu Wei Choo,Roy Ka-Wei Lee*

Main category: cs.CV

> 研究引入了PixelHumor数据集，以评估LMMs在多模态幽默和叙事理解上的能力，实验显示现有LMMs性能仍有待提高。

<details>
  <summary>Details</summary>

**Motivation:** 理解幽默是社会智能的核心方面，但对LMMs来说仍然是一个重大挑战。该项目的目标是提供一个严格的框架来评估多模态情境和叙事推理，从而推动LMMs在自然、社交互动方面的发展。

**Method:** 通过引入PixelHumor，一个包含2,800个注释多面板漫画的数据集来评估大型多模态模型（LMMs）在解读多模态幽默和识别叙事序列方面的能力。

**Result:** 实验发现，最先进的LMMs在区分面板顺序方面仅达到61%的准确率，远低于人类的表现。这揭示了现有模型在集成视觉和文本线索以理解连贯叙事和幽默方面存在重大不足。

**Conclusion:** PixelHumor提供了一个评估LMMs多模态叙事和幽默理解能力的框架，通过识别现有LMMs的不足来推动模型的发展。

**Abstract:** Understanding humor is a core aspect of social intelligence, yet it remains a
significant challenge for Large Multimodal Models (LMMs). We introduce
PixelHumor, a benchmark dataset of 2,800 annotated multi-panel comics designed
to evaluate LMMs' ability to interpret multimodal humor and recognize narrative
sequences. Experiments with state-of-the-art LMMs reveal substantial gaps: for
instance, top models achieve only 61% accuracy in panel sequencing, far below
human performance. This underscores critical limitations in current models'
integration of visual and textual cues for coherent narrative and humor
understanding. By providing a rigorous framework for evaluating multimodal
contextual and narrative reasoning, PixelHumor aims to drive the development of
LMMs that better engage in natural, socially aware interactions.

</details>


### [18] [OnlineHOI: Towards Online Human-Object Interaction Generation and Perception](https://arxiv.org/abs/2509.12250)
*Yihong Ji,Yunze Liu,Yiyao Zhuo,Weijiang Yu,Fei Ma,Joshua Huang,Fei Yu*

Main category: cs.CV

> 针对HOI的线上生成和感知任务，提出并实现了OnlineHOI框架。

<details>
  <summary>Details</summary>

**Motivation:** 现有的人类-物体交互（HOI）方法主要适用于离线场景，而在现实世界中，信息仅限于当前时刻及历史数据，离线方法在线上环境中表现不佳。

**Method:** 引入了基于Mamba框架的OnlineHOI架构，该框架采用了记忆机制，能够高效整合历史信息。

**Result:** 在Core4D和OAKINK2在线生成任务以及线上HOI4D感知任务中，达到了最先进的结果。

**Conclusion:** OnlineHOI能在真实世界环境中更好地处理人类-物体交互数据流，表现出色。

**Abstract:** The perception and generation of Human-Object Interaction (HOI) are crucial
for fields such as robotics, AR/VR, and human behavior understanding. However,
current approaches model this task in an offline setting, where information at
each time step can be drawn from the entire interaction sequence. In contrast,
in real-world scenarios, the information available at each time step comes only
from the current moment and historical data, i.e., an online setting. We find
that offline methods perform poorly in an online context. Based on this
observation, we propose two new tasks: Online HOI Generation and Perception. To
address this task, we introduce the OnlineHOI framework, a network architecture
based on the Mamba framework that employs a memory mechanism. By leveraging
Mamba's powerful modeling capabilities for streaming data and the Memory
mechanism's efficient integration of historical information, we achieve
state-of-the-art results on the Core4D and OAKINK2 online generation tasks, as
well as the online HOI4D perception task.

</details>


### [19] [EfficientNet-Based Multi-Class Detection of Real, Deepfake, and Plastic Surgery Faces](https://arxiv.org/abs/2509.12258)
*Li Kun,Milena Radenkovic*

Main category: cs.CV

> 深度学习技术的进步带来诸多益处，但也引发社会风险，特别是深伪技术可能影响个人隐私、政界形象和国家安全。

<details>
  <summary>Details</summary>

**Motivation:** 探讨深度学习，特别是深伪技术在社会生活中的应用及其带来的利与弊。

**Method:** 分析论文内容，未提供具体方法论。

**Result:** 深伪技术可以产生难以区分的虚假图像和视频，可能影响面部识别系统的功能，带来社会风险。

**Conclusion:** 深伪技术的不当使用对社会产生了负面影响，包括误导用户，影响选举和破坏政治人物形象。

**Abstract:** Currently, deep learning has been utilised to tackle several difficulties in
our everyday lives. It not only exhibits progress in computer vision but also
constitutes the foundation for several revolutionary technologies. Nonetheless,
similar to all phenomena, the use of deep learning in diverse domains has
produced a multifaceted interaction of advantages and disadvantages for human
society. Deepfake technology has advanced, significantly impacting social life.
However, developments in this technology can affect privacy, the reputations of
prominent personalities, and national security via software development. It can
produce indistinguishable counterfeit photographs and films, potentially
impairing the functionality of facial recognition systems, so presenting a
significant risk.
  The improper application of deepfake technology produces several detrimental
effects on society. Face-swapping programs mislead users by altering persons'
appearances or expressions to fulfil particular aims or to appropriate personal
information. Deepfake technology permeates daily life through such techniques.
Certain individuals endeavour to sabotage election campaigns or subvert
prominent political figures by creating deceptive pictures to influence public
perception, causing significant harm to a nation's political and economic
structure.

</details>


### [20] [A Modern Look at Simplicity Bias in Image Classification Tasks](https://arxiv.org/abs/2509.12265)
*Xiaoguang Chang,Teng Wang,Changyin Sun*

Main category: cs.CV

> 本文研究了CLIP模型中简单性偏见（SB）与其在各种图像分类任务中的性能之间的关系。

<details>
  <summary>Details</summary>

**Motivation:** 当前的研究主要集中在简单模型或合成任务上，但对大型模型中简单性偏见（SB）的测量仍然具有挑战性，对SB在各种图像分类任务中的相关性知之甚少。

**Method:** 我们首先对用于表征小型模型的现有复杂性度量的潜在局限性进行了理论分析。为了解决这个问题，我们提出了一种频率感知度量，该度量能够捕捉更细粒度的简单性偏见（SB）差异。我们还验证了这种度量在受到最近两种SB调制方法影响的CLIP模型上比之前的度量更具有信息性和一致性。其次，我们研究了这些模型的SB与其在范围广泛的各种图像分类任务中的性能之间的关系，包括零样本设置和微调设置。

**Result:** 实验结果揭示了一系列行为。例如，更强的SB与在OOD泛化上的更好性能相关，而非在对抗鲁棒性方面。

**Conclusion:** 这些结果强调了将模型的归纳偏差与目标任务特性相一致的好处。

**Abstract:** The simplicity Bias (SB) of neural networks, i.e.\ their tendency to
represent simple functions, is a key factor in their generalization
capabilities. Recent studies show that an excessive SB may harm performance on
complex tasks, and the need for this bias varies across tasks. Many of these
studies focus on simple models or synthetic tasks. It remains challenging to
measure the SB in large models and little is known about the relevance of the
SB to various image classification tasks.
  In this paper, we investigate the relationship between the SB in CLIP models
and their performance across image classification tasks. First, we
theoretically analyze the potential limitation of existing measures of
complexity that have been used to characterize small models. To address this,
we propose a frequency-aware measure capturing finer-grained SB differences. We
validate this measure on CLIP models subjected to two recent SB-modulation
methods, demonstrating that it is more informative and consistent than previous
measures. Second, we examine the relation between the SB of those models and
their performance across a range of image classification tasks, including
zero-shot and fine-tuning settings. These experiments reveal a range of
behaviors. For example, a stronger SB correlates with a better performance on
OOD generalization than on adversarial robustness. These results highlight the
benefits of aligning a model's inductive biases with the characteristics of the
target task.

</details>


### [21] [GraphDerm: Fusing Imaging, Physical Scale, and Metadata in a Population-Graph Classifier for Dermoscopic Lesions](https://arxiv.org/abs/2509.12277)
*Mehdi Yousefzadeh,Parsa Esfahanian,Sara Rashidifar,Hossein Salahshoor Gavalan,Negar Sadat Rafiee Tabatabaee,Saeid Gorgin,Dara Rahmati,Maryam Daneshpazhooh*

Main category: cs.CV

> 本研究提出了一种集合图像、毫米尺度校准及患者元数据的皮肤镜分类框架GraphDerm，通过结合GNN来提高皮肤镜图像分类的准确性，结果显著优于仅使用图像信息的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基于AI的皮肤镜图像识别技术往往忽略了患者元数据（如年龄、性别、部位）以及对于几何分析所需的实际尺度。GraphDerm则融合了这些信息，试图提高皮肤镜图像分类的准确性。这是第一次在ISIC规模上应用GNN用于皮肤镜检查。

**Method:** GraphDerm，这是一种集合了成像、毫米级校准和患者元数据的多类皮肤镜分类的群体图框架。具体来说，研究团队整理了ISIC 2018/2019数据集，合成嵌入尺子的图像以及精确的掩模，使用U-Net（SE-ResNet-18）进行病灶和尺子的分割。通过轻量级的1D-CNN，从尺子掩模的两点相关性中回归像素每毫米。从病灶掩模中计算出真实规模的描述子（面积、周长、惯性半径）。节点特征采用EfficientNet-B3；边代表元数据/几何相似性（完全加权或阈值化）。通过谱图神经网络进行半监督节点分类；提出了一个基于图像的ANN作为基准模型。

**Result:** 尺子和病灶分割的Dice系数分别为0.904和0.908；尺度回归的平均绝对误差为1.5像素（RMSE为6.6）。图结构模型的AUC为0.9812；使用约25%边的阈值化变体保持AUC为0.9788（对仅基于图像的基准模型为0.9440）。每类的AUC大多在0.97至0.99之间。

**Conclusion:** 将校准尺度、病变几何形状和元数据统一到一个群体图中，在基于ISIC-2019的多类皮肤镜分类上比仅基于图像的方法取得了显著成效。稀疏图可以保持接近最优的精度，表明这种方法具有高效的部署潜力。

**Abstract:** Introduction. Dermoscopy aids melanoma triage, yet image-only AI often
ignores patient metadata (age, sex, site) and the physical scale needed for
geometric analysis. We present GraphDerm, a population-graph framework that
fuses imaging, millimeter-scale calibration, and metadata for multiclass
dermoscopic classification, to the best of our knowledge the first ISIC-scale
application of GNNs to dermoscopy. Methods. We curate ISIC 2018/2019,
synthesize ruler-embedded images with exact masks, and train U-Nets
(SE-ResNet-18) for lesion and ruler segmentation. Pixels-per-millimeter are
regressed from the ruler-mask two-point correlation via a lightweight 1D-CNN.
From lesion masks we compute real-scale descriptors (area, perimeter, radius of
gyration). Node features use EfficientNet-B3; edges encode metadata/geometry
similarity (fully weighted or thresholded). A spectral GNN performs
semi-supervised node classification; an image-only ANN is the baseline.
Results. Ruler and lesion segmentation reach Dice 0.904 and 0.908; scale
regression attains MAE 1.5 px (RMSE 6.6). The graph attains AUC 0.9812, with a
thresholded variant using about 25% of edges preserving AUC 0.9788 (vs. 0.9440
for the image-only baseline); per-class AUCs typically fall in the 0.97-0.99
range. Conclusion. Unifying calibrated scale, lesion geometry, and metadata in
a population graph yields substantial gains over image-only pipelines on
ISIC-2019. Sparser graphs retain near-optimal accuracy, suggesting efficient
deployment. Scale-aware, graph-based AI is a promising direction for
dermoscopic decision support; future work will refine learned edge semantics
and evaluate on broader curated benchmarks.

</details>


### [22] [PATIMT-Bench: A Multi-Scenario Benchmark for Position-Aware Text Image Machine Translation in Large Vision-Language Models](https://arxiv.org/abs/2509.12278)
*Wanru Zhuang,Wenbo Li,Zhibin Lan,Xu Han,Peng Li,Jinsong Su*

Main category: cs.CV

> 本文提出了位置感知文本图像翻译（PATIMT），通过构建PATIMTBench数据集和自适应OCR精炼管道，支持了更细粒度和布局保留的图像中文字翻译任务，LVLMs在任务上达到了最好效果。

<details>
  <summary>Details</summary>

**Motivation:** 传统的文本图像翻译研究主要集中在对图像中所有文本的翻译，忽视了边界框的提供及场景多样性的覆盖。而本研究进一步提出位置感知文本图像翻译，旨在提供细粒度和布局保留的翻译，具有重要的实用价值。

**Method:** 该研究提出了位置感知文本图像翻译（PATIMT），包括区域特定翻译和带定位线索的全图像翻译两个关键子任务。为了支持模型评估，构建了PATIMTBench数据集和自适应图像OCR精炼管道，后者可以根据不同场景自适应选择合适的OCR工具并优化图像中的文字识别结果。

**Result:** 通过对数据进行微调，紧凑的大视觉-语言模型（LVLMs）在两个子任务上都达到了最先进的性能。实验结果还表明了该研究训练数据的可扩展性和通用性。

**Conclusion:** 本研究提出的位置感知文本图像翻译及由此构建的数据集与方法为未来的文本图像翻译研究提供了重要参考，并展示了视觉-语言模型在这一任务上的潜力。

**Abstract:** Text Image Machine Translation (TIMT) aims to translate texts embedded within
an image into another language. Current TIMT studies primarily focus on
providing translations for all the text within an image, while neglecting to
provide bounding boxes and covering limited scenarios. In this work, we extend
traditional TIMT into position-aware TIMT (PATIMT), aiming to support
fine-grained and layoutpreserving translation, which holds great practical
value but remains largely unexplored. This task comprises two key sub-tasks:
regionspecific translation and full-image translation with grounding. To
support existing models on PATIMT and conduct fair evaluation, we construct the
PATIMT benchmark (PATIMTBench), which consists of 10 diverse real-world
scenarios. Specifically, we introduce an Adaptive Image OCR Refinement
Pipeline, which adaptively selects appropriate OCR tools based on scenario and
refines the results of text-rich images. To ensure evaluation reliability, we
further construct a test set, which contains 1,200 high-quality instances
manually annotated and reviewed by human experts. After fine-tuning on our
data, compact Large Vision-Language Models (LVLMs) achieve state-of-the-art
performance on both sub-tasks. Experimental results also highlight the
scalability and generalizability of our training data

</details>


### [23] [Domain Adaptive SAR Wake Detection: Leveraging Similarity Filtering and Memory Guidance](https://arxiv.org/abs/2509.12279)
*He Gao,Baoxiang Huang,Milena Radenkovic,Borui Li,Ge Chen*

Main category: cs.CV

> 提出一种新的方法SimMemDA，使用WakeGAN生成与SAR图像风格相近的伪图像，并结合实例级特征相似性过滤机制和特征-置信度记忆库来提高对SAR图像中船尾迹检测的准确性。

<details>
  <summary>Details</summary>

**Motivation:** 由于SAR图像具有的复杂成像机制，导致SAR图像中的尾迹特征经常显得抽象且噪点较多，给SAR图像中的尾迹特征注释带来挑战。光学图像提供更多的视觉线索，但因为领域迁移，光谱图像训练的模型在应用于SAR图像时表现出较差的性能。本文希望解决跨模态领域适应挑战，提高跨模态尾迹检测任务的准确性和鲁棒性。

**Method:** 提出名为SimMemDA的跨模态领域适应框架，该框架通过实例级特征相似性过滤和特征记忆引导来解决无监督领域自适应中的船尾迹检测问题。首先，采用WakeGAN对光学图像进行风格转换，生成与SAR图像风格相近的伪图像。其次，设计实例级特征相似性过滤机制，以识别并优先选择具有目标域类似分布的源域样本，从而减少负面迁移。同时，引入特征-置信度记忆库，结合K近邻置信度加权融合策略，动态校准目标域中的伪标签，提高伪标签的可靠性和稳定性。最后，通过区域混合训练进一步增强泛化能力，策略性地结合源域注释与校准后的目标伪标签。

**Result:** 实验结果表明所提SimMemDA方法能提高跨模态船尾迹检测任务的准确性和鲁棒性。

**Conclusion:** 实验证明，提出的SimMemDA方法能提高跨模态尾迹检测任务的准确性和鲁棒性，验证了其有效性和可行性。

**Abstract:** Synthetic Aperture Radar (SAR), with its all-weather and wide-area
observation capabilities, serves as a crucial tool for wake detection. However,
due to its complex imaging mechanism, wake features in SAR images often appear
abstract and noisy, posing challenges for accurate annotation. In contrast,
optical images provide more distinct visual cues, but models trained on optical
data suffer from performance degradation when applied to SAR images due to
domain shift. To address this cross-modal domain adaptation challenge, we
propose a Similarity-Guided and Memory-Guided Domain Adaptation (termed
SimMemDA) framework for unsupervised domain adaptive ship wake detection via
instance-level feature similarity filtering and feature memory guidance.
Specifically, to alleviate the visual discrepancy between optical and SAR
images, we first utilize WakeGAN to perform style transfer on optical images,
generating pseudo-images close to the SAR style. Then, instance-level feature
similarity filtering mechanism is designed to identify and prioritize source
samples with target-like distributions, minimizing negative transfer.
Meanwhile, a Feature-Confidence Memory Bank combined with a K-nearest neighbor
confidence-weighted fusion strategy is introduced to dynamically calibrate
pseudo-labels in the target domain, improving the reliability and stability of
pseudo-labels. Finally, the framework further enhances generalization through
region-mixed training, strategically combining source annotations with
calibrated target pseudo-labels. Experimental results demonstrate that the
proposed SimMemDA method can improve the accuracy and robustness of cross-modal
ship wake detection tasks, validating the effectiveness and feasibility of the
proposed method.

</details>


### [24] [Uncertainty-Aware Hourly Air Temperature Mapping at 2 km Resolution via Physics-Guided Deep Learning](https://arxiv.org/abs/2509.12329)
*Shengjie Kris Liu,Siqin Wang,Lu Zhang*

Main category: cs.CV

> 研究团队开发了Amplifier Air-Transformer方法，利用深度学习和物理引导模型，实现美国本土每小时2公里分辨率的气温数据生成，该方法能够通过神经网络重构地表温度并将之转化为精确的气温数据，同时提高了预测的可靠性。

<details>
  <summary>Details</summary>

**Motivation:** 尽管地面气象站提供连续监测数据，卫星能提供广泛的空间覆盖，但还没有任何一个单一的数据源能够以时空无缝的方式提供数据。因此，研究者提出了一种新的方法来填补这一空白。

**Method:** 提出了一种基于数据驱动和物理引导的深度学习方法来生成美国本土每小时2公里分辨率的气温数据。该方法，称为Amplifier Air-Transformer，首先通过神经网络重构被云层遮挡的GOES-16地表温度数据，该网络整合了年温度周期并引入线性项来提升ERA5温度值在更细尺度的精度。其次，通过另一个神经网络利用地表属性将重构的地表温度转化为气温。该方法还通过深度集成学习估计预测不确定性以提高可靠性。

**Result:** 该方法在基于777亿像素的地表温度数据和1.55亿个来自气象站的气温记录（2018-2024）的测试中，实现了每小时气温映射精度为1.93°C。

**Conclusion:** 该方法不仅简化了地表温度重构过程和气温预测，还可扩展到其他卫星数据源，以实现高时空分辨率的无缝气温监测。

**Abstract:** Near-surface air temperature is a key physical property of the Earth's
surface. Although weather stations offer continuous monitoring and satellites
provide broad spatial coverage, no single data source offers seamless data in a
spatiotemporal fashion. Here, we propose a data-driven, physics-guided deep
learning approach to generate hourly air temperature data at 2 km resolution
over the contiguous United States. The approach, called Amplifier
Air-Transformer, first reconstructs GOES-16 surface temperature data obscured
by clouds. It does so through a neural network encoded with the annual
temperature cycle, incorporating a linear term to amplify ERA5 temperature
values at finer scales and convolutional layers to capture spatiotemporal
variations. Then, another neural network transforms the reconstructed surface
temperature into air temperature by leveraging its latent relationship with key
Earth surface properties. The approach is further enhanced with predictive
uncertainty estimation through deep ensemble learning to improve reliability.
The proposed approach is built and tested on 77.7 billion surface temperature
pixels and 155 million air temperature records from weather stations across the
contiguous United States (2018-2024), achieving hourly air temperature mapping
accuracy of 1.93 C in station-based validation. The proposed approach
streamlines surface temperature reconstruction and air temperature prediction,
and it can be extended to other satellite sources for seamless air temperature
monitoring at high spatiotemporal resolution. The generated data of this study
can be downloaded at https://doi.org/10.5281/zenodo.15252812, and the project
webpage can be found at https://skrisliu.com/HourlyAirTemp2kmUSA/.

</details>


### [25] [DS@GT AnimalCLEF: Triplet Learning over ViT Manifolds with Nearest Neighbor Classification for Animal Re-identification](https://arxiv.org/abs/2509.12353)
*Anthony Miyaguchi,Chandrasekaran Maruthaiyannan,Charles R. Clark*

Main category: cs.CV

> 研究显示，度量学习的效果高度依赖于初始骨干嵌入的质量和领域特定性，特定模型的表现优于通用模型。

<details>
  <summary>Details</summary>

**Motivation:** 探索度量学习的有效性如何依赖于初始骨干嵌入的质量和领域特定性，特别是在动物再识别任务中。

**Method:** 对比了通用模型DINOv2和领域特定模型MegaDescriptor作为骨干模型的效果，使用带鲁棒阈值处理的K-最近邻分类器来识别个体或标记新个体。

**Result:** 对于领域特定模型MegaDescriptor，三重学习投影头提升了0.13点性能，而对于通用模型DINOv2，性能提升仅为0.03点。

**Conclusion:** 展示了调整通用特征以适应特定的有限数据再识别任务的局限性，并强调领域特定预训练的重要性。

**Abstract:** This paper details the DS@GT team's entry for the AnimalCLEF 2025
re-identification challenge. Our key finding is that the effectiveness of
post-hoc metric learning is highly contingent on the initial quality and
domain-specificity of the backbone embeddings. We compare a general-purpose
model (DINOv2) with a domain-specific model (MegaDescriptor) as a backbone. A
K-Nearest Neighbor classifier with robust thresholding then identifies known
individuals or flags new ones. While a triplet-learning projection head
improved the performance of the specialized MegaDescriptor model by 0.13
points, it yielded minimal gains (0.03) for the general-purpose DINOv2 on
averaged BAKS and BAUS. We demonstrate that the general-purpose manifold is
more difficult to reshape for fine-grained tasks, as evidenced by stagnant
validation loss and qualitative visualizations. This work highlights the
critical limitations of refining general-purpose features for specialized,
limited-data re-ID tasks and underscores the importance of domain-specific
pre-training. The implementation for this work is publicly available at
github.com/dsgt-arc/animalclef-2025.

</details>


### [26] [GhostNetV3-Small: A Tailored Architecture and Comparative Study of Distillation Strategies for Tiny Images](https://arxiv.org/abs/2509.12380)
*Florian Zager,Hamza A. A. Gardi*

Main category: cs.CV

> 论文探索了在资源受限的边缘设备上部署深度神经网络的方法，通过优化GhostNetV3的架构并对比多种知识蒸馏技术，发现架构优化比蒸馏更有助于提升性能。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络虽然在众多任务中取得显著成功，但由于计算需求高，不适合部署在资源受限的边缘设备上。论文希望通过压缩和适配模型，使得这些模型可以在这样的环境中更加有效地运行。

**Method:** 本论文研究了模型压缩和适配策略，旨在实现在资源受限的边缘设备上的高效推理。文章重点介绍了GhostNetV3这一适用于移动应用的先进架构，并提出了一种新的版本GhostNetV3-Small，该版本针对低分辨率输入进行了优化。
此外，论文还比较评估了几种知识蒸馏策略，包括传统的知识蒸馏、教师助手以及教师集策略。

**Result:** 实验结果显示，GhostNetV3-Small在CIFAR-10数据集上显著优于原版GhostNetV3，达到了93.94%的准确率。所有测试的知识蒸馏策略均未超过基线训练的表现。

**Conclusion:** 研究结果表明，在小规模图像分类任务上，架构适应比知识蒸馏更能提升性能，这强调了对有效模型设计及针对低分辨率域的高级知识蒸馏技术的需求。

**Abstract:** Deep neural networks have achieved remarkable success across a range of
tasks, however their computational demands often make them unsuitable for
deployment on resource-constrained edge devices. This paper explores strategies
for compressing and adapting models to enable efficient inference in such
environments. We focus on GhostNetV3, a state-of-the-art architecture for
mobile applications, and propose GhostNetV3-Small, a modified variant designed
to perform better on low-resolution inputs such as those in the CIFAR-10
dataset. In addition to architectural adaptation, we provide a comparative
evaluation of knowledge distillation techniques, including traditional
knowledge distillation, teacher assistants, and teacher ensembles. Experimental
results show that GhostNetV3-Small significantly outperforms the original
GhostNetV3 on CIFAR-10, achieving an accuracy of 93.94%. Contrary to
expectations, all examined distillation strategies led to reduced accuracy
compared to baseline training. These findings indicate that architectural
adaptation can be more impactful than distillation in small-scale image
classification tasks, highlighting the need for further research on effective
model design and advanced distillation techniques for low-resolution domains.

</details>


### [27] [From Orthomosaics to Raw UAV Imagery: Enhancing Palm Detection and Crown-Center Localization](https://arxiv.org/abs/2509.12400)
*Rongkun Zhu,Kangning Cui,Wei Tang,Rui-Feng Wang,Sarra Alqahtani,David Lutz,Fan Yang,Paul Fine,Jordan Karubian,Robert Plemmons,Jean-Michel Morel,Victor Pauca,Miles Silman*

Main category: cs.CV

> 研究发现原始无人机图像在部署相关场景中性能更优，而正射影像在跨领域泛化上具有优势，树冠中心注释的使用进一步提升了定位精度，为生态监测和保护管理提供了实际指导。

<details>
  <summary>Details</summary>

**Motivation:** 准确的树木个体定位对于生态监测和森林管理至关重要。虽然无人机生成的正射影像被广泛使用，但其拼接伪影和繁琐的预处理限制了其现场部署的适用性。

**Method:** 使用了最先进的检测器和关键点模型来比较原始无人机图像与正射影像在目标检测上的性能差异。

**Result:** 研究探讨了原始无人机图像在热带森林中对棕榈树检测及树冠中心定位的应用。研究解决了两个问题：原始图像与正射影像在目标检测性能上的差异，以及树冠中心注释对定位精度的提升程度。实验发现，原始图像在实际部署中表现更优，而正射影像在跨领域泛化能力上更有优势。树冠中心注释的加入进一步提升了定位精度，为生态学分析提供了精确的树木位置信息。

**Conclusion:** 这些发现在无人机为基础的生物多样性和保护监测中提供了实用的操作指导。

**Abstract:** Accurate mapping of individual trees is essential for ecological monitoring
and forest management. Orthomosaic imagery from unmanned aerial vehicles (UAVs)
is widely used, but stitching artifacts and heavy preprocessing limit its
suitability for field deployment. This study explores the use of raw UAV
imagery for palm detection and crown-center localization in tropical forests.
Two research questions are addressed: (1) how detection performance varies
across orthomosaic and raw imagery, including within-domain and cross-domain
transfer, and (2) to what extent crown-center annotations improve localization
accuracy beyond bounding-box centroids. Using state-of-the-art detectors and
keypoint models, we show that raw imagery yields superior performance in
deployment-relevant scenarios, while orthomosaics retain value for robust
cross-domain generalization. Incorporating crown-center annotations in training
further improves localization and provides precise tree positions for
downstream ecological analyses. These findings offer practical guidance for
UAV-based biodiversity and conservation monitoring.

</details>


### [28] [DYNAMO: Dependency-Aware Deep Learning Framework for Articulated Assembly Motion Prediction](https://arxiv.org/abs/2509.12430)
*Mayank Patel,Rahul Jain,Asim Unmesh,Karthik Ramani*

Main category: cs.CV

> 文章引入了MechBench，这是一个包含693个多样化合成齿轮装配的基准数据集，用于研究耦合运动。此外，提出了DYNAMO模型，用于从CAD点云中预测每个部件的运动轨迹。

<details>
  <summary>Details</summary>

**Motivation:** 理解和从静态几何图形中推断出连杆机械装配件的运动是3D感知和设计自动化中的一个核心挑战。尽管之前的工作主要针对日常连杆物体，但遇到像齿轮这样运动由几何耦合产生的机械装配件时，现有的方法很难基于几何信息推理出关系运动。

**Method:** 提出DYNAMO，这是一种依赖性感知的神经模型，可以从分割的CAD点云直接预测每个部件的SE(3)运动轨迹。

**Result:** 实验表明，DYNAMO在不同的齿轮配置中能达到准确且时间上一致的预测结果，优于其他基线方法。

**Conclusion:** MechBench和DYNAMO共同建立了一个新的系统框架，用于从数据中学习CAD装配件中的耦合机械运动。

**Abstract:** Understanding the motion of articulated mechanical assemblies from static
geometry remains a core challenge in 3D perception and design automation. Prior
work on everyday articulated objects such as doors and laptops typically
assumes simplified kinematic structures or relies on joint annotations.
However, in mechanical assemblies like gears, motion arises from geometric
coupling, through meshing teeth or aligned axes, making it difficult for
existing methods to reason about relational motion from geometry alone. To
address this gap, we introduce MechBench, a benchmark dataset of 693 diverse
synthetic gear assemblies with part-wise ground-truth motion trajectories.
MechBench provides a structured setting to study coupled motion, where part
dynamics are induced by contact and transmission rather than predefined joints.
Building on this, we propose DYNAMO, a dependency-aware neural model that
predicts per-part SE(3) motion trajectories directly from segmented CAD point
clouds. Experiments show that DYNAMO outperforms strong baselines, achieving
accurate and temporally consistent predictions across varied gear
configurations. Together, MechBench and DYNAMO establish a novel systematic
framework for data-driven learning of coupled mechanical motion in CAD
assemblies.

</details>


### [29] [Cott-ADNet: Lightweight Real-Time Cotton Boll and Flower Detection Under Field Conditions](https://arxiv.org/abs/2509.12442)
*Rui-Feng Wang,Mingrui Xu,Matthew C Bauer,Iago Beffart Schardong,Xiaowen Ma,Kangning Cui*

Main category: cs.CV

> 提出了Cott-ADNet以识别棉花苞和花朵，提高了空间表示和鲁棒性，适用于复杂田间条件。

<details>
  <summary>Details</summary>

**Motivation:** 改善棉花收获自动化、产量估计和育种研究，通过提高棉花苞和花朵识别的准确性。

**Method:** 基于YOLOv11n，增加NeLU增强全局注意力机制和扩张接收字段SPPF模块，以提高弱低对比特征捕捉和多尺度上下文建模。

**Result:** 在4,966张图像构成的数据集上实现了91.5%的精度、89.8%的召回率、93.3%的mAP50、71.3%的mAP和90.6%的F1-Score。

**Conclusion:** Cott-ADNet作为田间部署的精确和高效的解决方案，为自动化棉花收获和高通量表型分析提供了可靠基础。

**Abstract:** Cotton is one of the most important natural fiber crops worldwide, yet
harvesting remains limited by labor-intensive manual picking, low efficiency,
and yield losses from missing the optimal harvest window. Accurate recognition
of cotton bolls and their maturity is therefore essential for automation, yield
estimation, and breeding research. We propose Cott-ADNet, a lightweight
real-time detector tailored to cotton boll and flower recognition under complex
field conditions. Building on YOLOv11n, Cott-ADNet enhances spatial
representation and robustness through improved convolutional designs, while
introducing two new modules: a NeLU-enhanced Global Attention Mechanism to
better capture weak and low-contrast features, and a Dilated Receptive Field
SPPF to expand receptive fields for more effective multi-scale context modeling
at low computational cost. We curate a labeled dataset of 4,966 images, and
release an external validation set of 1,216 field images to support future
research. Experiments show that Cott-ADNet achieves 91.5% Precision, 89.8%
Recall, 93.3% mAP50, 71.3% mAP, and 90.6% F1-Score with only 7.5 GFLOPs,
maintaining stable performance under multi-scale and rotational variations.
These results demonstrate Cott-ADNet as an accurate and efficient solution for
in-field deployment, and thus provide a reliable basis for automated cotton
harvesting and high-throughput phenotypic analysis. Code and dataset is
available at https://github.com/SweefongWong/Cott-ADNet.

</details>


### [30] [Deep learning for 3D point cloud processing -- from approaches, tasks to its implications on urban and environmental applications](https://arxiv.org/abs/2509.12452)
*Zhenxin Zhang,Zhihua Xu,Yuwei Cao,Ningli Xu,Shuye Wang,Shen'ao Cui,Zhen Li,Rongjun Qin*

Main category: cs.CV

> 本文是对点云处理中深度学习方法和数据集的元分析，聚焦于实际应用中关键任务如场景补全、配准、语义分割和建模，识别从理论到应用的转化差距，并在算法和实用方面提出了结论性评论。

<details>
  <summary>Details</summary>

**Motivation:** 深度学习在处理点云数据上的发展虽快，但大部分仍停留在理论阶段未应用到实际中。现存的综述多集中在新型网络架构，忽视了这些方法在实际应用中的价值和现实挑战。

**Method:** 本文对深度学习在点云处理任务上的方法和数据集进行了元分析，涵盖点云处理中如场景补全、配准、语义分割和建模等关键任务。

**Result:** 通过对广泛的城市和环境应用的回顾，本文识别出了理论到实际应用转化中存在的差距。

**Conclusion:** 本文不仅从算法层面分析了当前深度学习方法在点云处理上的情况，还从实际应用的角度探讨了方法在不同场景下的适用性和挑战。

**Abstract:** Point cloud processing as a fundamental task in the field of geomatics and
computer vision, has been supporting tasks and applications at different scales
from air to ground, including mapping, environmental monitoring, urban/tree
structure modeling, automated driving, robotics, disaster responses etc. Due to
the rapid development of deep learning, point cloud processing algorithms have
nowadays been almost explicitly dominated by learning-based approaches, most of
which are yet transitioned into real-world practices. Existing surveys
primarily focus on the ever-updating network architecture to accommodate
unordered point clouds, largely ignoring their practical values in typical
point cloud processing applications, in which extra-large volume of data,
diverse scene contents, varying point density, data modality need to be
considered. In this paper, we provide a meta review on deep learning approaches
and datasets that cover a selection of critical tasks of point cloud processing
in use such as scene completion, registration, semantic segmentation, and
modeling. By reviewing a broad range of urban and environmental applications
these tasks can support, we identify gaps to be closed as these methods
transformed into applications and draw concluding remarks in both the
algorithmic and practical aspects of the surveyed methods.

</details>
