<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 18]
- [cs.CV](#cs.CV) [Total: 14]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [On GRPO Collapse in Search-R1: The Lazy Likelihood-Displacement Death Spiral](https://arxiv.org/abs/2512.04220)
*Wenlong Deng,Yushu Li,Boying Gong,Yi Ren,Christos Thrampoulidis,Xiaoxiao Li*

Main category: cs.CL

> 研究发现 GRPO 在与工具集成的多步推理中的训练崩溃是由似然性降低导致的，提出了一种轻量级的方法来解决这个问题，实验表明该方法可以显著提升性能。

<details>
  <summary>Details</summary>

**Motivation:** Tool-integrated (TI) 强化学习 (RL) 虽然具有快速收敛和价值无关的表达式优点，但在训练过程中会出现塌缩，研究目的是解决这一问题。

**Method:** 通过提出一种轻量级的似然性保持正则化方法 (LLDS) 来解决 GRPO 中的 LLD 问题，该方法仅在轨迹似然性下降时激活，并且只对负责的 tokens 进行正则化。

**Result:** 在七个开放式和多跳 QA 基准测试中，该方法稳定了训练，防止了梯度爆炸，并获得了显著的性能提升。

**Conclusion:** LLD 是 GRPO 基于 TIRL 的关键瓶颈，提出的方法提供了一条稳定和可扩展的训练工具集成大型语言模型的实用路径。

**Abstract:** Tool-integrated (TI) reinforcement learning (RL) enables large language models (LLMs) to perform multi-step reasoning by interacting with external tools such as search engines and retrievers. Group Relative Policy Optimization (GRPO), exemplified by the recent Search-R1, offers fast convergence and a value-free formulation that makes it appealing for this setting, yet consistently suffers from training collapse. We identify Lazy Likelihood Displacement (LLD), a systematic reduction or stagnation in the likelihood of both correct and incorrect responses, as the core mechanism driving this failure. LLD emerges early and triggers a self-reinforcing LLD Death Spiral, where declining likelihood leads to low-confidence responses, inflating gradients, and ultimately causing collapse. We empirically characterize this process across models on a Search-R1-style, search-integrated question answering task, revealing a consistent three-phase trajectory: early stagnation, steady decay, and accelerated collapse. To address this, we propose a lightweight likelihood-preserving regularization LLDS for GRPO that activates only when a trajectory's likelihood decreases, and regularizes only the tokens responsible. This fine-grained structure mitigates LLD with minimal interference to optimization. Across seven open-domain and multi-hop QA benchmarks, our method stabilizes training, prevents gradient explosion, and yields substantial performance improvements, including +37.8% gains on Qwen2.5-3B and +32.0% gains on Qwen2.5-7B. Our results establish LLD as a fundamental bottleneck in GRPO-based TIRL and provide a practical path toward stable, scalable training of tool-integrated LLM.

</details>


### [2] [Computational Linguistics Meets Libyan Dialect: A Study on Dialect Identification](https://arxiv.org/abs/2512.04257)
*Mansour Essgaer,Khamis Massud,Rabia Al Mamlook,Najah Ghmaid*

Main category: cs.CL

> 该研究通过逻辑回归、线性SVM、多项式朴素贝叶斯和伯努利朴素贝叶斯分类了数据集中的利比亚方言推文。结果表明多项式朴素贝叶斯是四种方法中最有效的方法，对于阿拉伯语方言NLP应用提供了实证基准和见解。

<details>
  <summary>Details</summary>

**Motivation:** 研究试图通过评估不同的特征提取方法和分类模型来提升利比亚方言在阿拉伯语方言自然语言处理应用中的识别精度。

**Method:** 该研究使用逻辑回归、线性支持向量机、多项式朴素贝叶斯和伯努利朴素贝叶斯分类利比亚方言推文中的话语。使用了包含18种阿拉伯方言540,000个句子的QADI语料库。前处理挑战包括处理不一致的正字差异和利比亚方言特有的非标准拼写。

**Result:** 分类实验显示，当使用（1，2）词元gram和（1，5）字符n-gram时，多项式朴素贝叶斯（MNB）实现了最高准确度85.89%和F1评分为0.85741。相比之下，逻辑回归和线性SVM的最高准确度分别为84.41%和84.73%。其他评估指标，如对数损失、Cohen kappa和Matthew相关系数也进一步支持了多项式朴素贝叶斯在该任务中的有效性。

**Conclusion:** 研究结果表明，通过精心选择的n-gram表示和分类模型可以在提高利比亚方言分类准确性方面起到重要作用，为未来研究提供了实证基准和洞见。

**Abstract:** This study investigates logistic regression, linear support vector machine, multinomial Naive Bayes, and Bernoulli Naive Bayes for classifying Libyan dialect utterances gathered from Twitter. The dataset used is the QADI corpus, which consists of 540,000 sentences across 18 Arabic dialects. Preprocessing challenges include handling inconsistent orthographic variations and non-standard spellings typical of the Libyan dialect. The chi-square analysis revealed that certain features, such as email mentions and emotion indicators, were not significantly associated with dialect classification and were thus excluded from further analysis. Two main experiments were conducted: (1) evaluating the significance of meta-features extracted from the corpus using the chi-square test and (2) assessing classifier performance using different word and character n-gram representations. The classification experiments showed that Multinomial Naive Bayes (MNB) achieved the highest accuracy of 85.89% and an F1-score of 0.85741 when using a (1,2) word n-gram and (1,5) character n-gram representation. In contrast, Logistic Regression and Linear SVM exhibited slightly lower performance, with maximum accuracies of 84.41% and 84.73%, respectively. Additional evaluation metrics, including log loss, Cohen kappa, and Matthew correlation coefficient, further supported the effectiveness of MNB in this task. The results indicate that carefully selected n-gram representations and classification models play a crucial role in improving the accuracy of Libyan dialect identification. This study provides empirical benchmarks and insights for future research in Arabic dialect NLP applications.

</details>


### [3] [SQuARE: Structured Query & Adaptive Retrieval Engine For Tabular Formats](https://arxiv.org/abs/2512.04292)
*Chinmay Gondhalekar,Urjitkumar Patel,Fang-Chun Yeh*

Main category: cs.CL

> SQuARE是一个基于表格复杂度的混合检索框架，它可以分别通过分块检索或SQL查询处理不同类型的问题，在精度和准确性方面表现出色，为未来的表格理解提供了一个实用的解决方案。

<details>
  <summary>Details</summary>

**Motivation:** 准确的问答系统在处理真实电子表格时面临多行表头、合并单元格、单位注释等问题，单纯基于SQL的方法无法应对缺乏一致模式的文件。因此，提出了一个能打破检索与模型选择之间耦合的系统，为更强大的表格理解提供实际桥梁。

**Method:** 我们提出了SQuARE，这是一个根据表格复杂度进行判断的混合检索框架。它通过计算头部深度和合并密度的连续分数，将查询路由到保持结构的分块检索或通过自动构建的关联表达式进行SQL检索。当置信度较低时，一个轻量级代理会监督检索、优化或合并两个路径上的结果。

**Result:** 在多级标题的公司资产负债表、高度合并的世界银行工作簿和多样化的公共数据集上进行的评估表明，SQuARE在检索精度和端到端的准确性方面都超过了单一策略的基准和ChatGPT-4o，同时保持了预测的延迟。

**Conclusion:** SQuARE这一体系不仅能维持表头层次、时间标签和单位注释，确保返回值忠实于原始单元格，并易于验证，还与新兴的表格基础模型兼容，证明其作为强大的表格理解工具的价值。

**Abstract:** Accurate question answering over real spreadsheets remains difficult due to multirow headers, merged cells, and unit annotations that disrupt naive chunking, while rigid SQL views fail on files lacking consistent schemas. We present SQuARE, a hybrid retrieval framework with sheet-level, complexity-aware routing. It computes a continuous score based on header depth and merge density, then routes queries either through structure-preserving chunk retrieval or SQL over an automatically constructed relational representation. A lightweight agent supervises retrieval, refinement, or combination of results across both paths when confidence is low. This design maintains header hierarchies, time labels, and units, ensuring that returned values are faithful to the original cells and straightforward to verify. Evaluated on multi-header corporate balance sheets, a heavily merged World Bank workbook, and diverse public datasets, SQuARE consistently surpasses single-strategy baselines and ChatGPT-4o on both retrieval precision and end-to-end answer accuracy while keeping latency predictable. By decoupling retrieval from model choice, the system is compatible with emerging tabular foundation models and offers a practical bridge toward a more robust table understanding.

</details>


### [4] [DAComp: Benchmarking Data Agents across the Full Data Intelligence Lifecycle](https://arxiv.org/abs/2512.04324)
*Fangyu Lei,Jinxiang Meng,Yiming Huang,Junjie Zhao,Yitong Zhang,Jianwen Luo,Xin Zou,Ruiyi Yang,Wenbo Shi,Yan Gao,Shizhu He,Zuo Wang,Qian Liu,Yang Wang,Ke Wang,Jun Zhao,Kang Liu*

Main category: cs.CL

> DAComp是一个包含210项任务的基准测试，旨在评估并促进自主企业数据智能工作流代理的发展，揭示了现有系统在执行复杂数据工程和开放性数据分析任务上的局限。

<details>
  <summary>Details</summary>

**Motivation:** 为了开发真正能够帮助企业场景的自主数据代理，需要一个严格的测试环境来诊断现有的技术局限。DAComp提供了这样一个平台，能够反映现实世界的复杂数据智能工作流，包括数据转换及分析。

**Method:** 介绍了DAComp，一个由210个任务组成的基准测试，其中包括数据工程和数据分析两个方面。数据工程任务需要基于工业模式，设计和构建多阶段的SQL数据管道或根据变化的需求更新现有系统。数据分析任务则要求解决开放性业务问题，并进行探索性分析、结果解读及生成行动建议。

**Result:** 实验显示，即使是最先进的代理在DAComp基准测试中表现不佳，尤其是在数据工程任务上的成功率低于20%，表现出在整体管道编排方面的瓶颈。数据分析任务得分也低于40%，显示了在开放性推理方面的重大缺陷。

**Conclusion:** 通过明确指出现有技术的局限性，DAComp为开发能够处理复杂企业场景的自主数据代理提供了严格的、现实主义的测试环境。

**Abstract:** Real-world enterprise data intelligence workflows encompass data engineering that turns raw sources into analytical-ready tables and data analysis that convert those tables into decision-oriented insights. We introduce DAComp, a benchmark of 210 tasks that mirrors these complex workflows. Data engineering (DE) tasks require repository-level engineering on industrial schemas, including designing and building multi-stage SQL pipelines from scratch and evolving existing systems under evolving requirements. Data analysis (DA) tasks pose open-ended business problems that demand strategic planning, exploratory analysis through iterative coding, interpretation of intermediate results, and the synthesis of actionable recommendations. Engineering tasks are scored through execution-based, multi-metric evaluation. Open-ended tasks are assessed by a reliable, experimentally validated LLM-judge, which is guided by hierarchical, meticulously crafted rubrics. Our experiments reveal that even state-of-the-art agents falter on DAComp. Performance on DE tasks is particularly low, with success rates under 20%, exposing a critical bottleneck in holistic pipeline orchestration, not merely code generation. Scores on DA tasks also average below 40%, highlighting profound deficiencies in open-ended reasoning and demonstrating that engineering and analysis are distinct capabilities. By clearly diagnosing these limitations, DAComp provides a rigorous and realistic testbed to drive the development of truly capable autonomous data agents for enterprise settings. Our data and code are available at https://da-comp.github.io

</details>


### [5] [ClusterFusion: Hybrid Clustering with Embedding Guidance and LLM Adaptation](https://arxiv.org/abs/2512.04350)
*Yiming Xu,Yuan Yuan,Vijay Viswanathan,Graham Neubig*

Main category: cs.CL

> 提出了ClusterFusion框架，该框架通过使用大型语言模型作为核心，在特定领域和标准任务中展示了出色的文本聚类性能。

<details>
  <summary>Details</summary>

**Motivation:** 传统的聚类算法在没有昂贵的微调的情况下，在特定领域中表现不佳。尽管大型语言模型（LLMs）提供了强大的上下文推理能力，但先前的工作主要将其作为辅助模块来细化嵌入式调整或调节聚类边界。我们想要充分利用LLM的上下文适应性，因此提出了新的框架ClusterFusion。

**Method:** ClusterFusion, 一个混合框架，将大型语言模型（LLM）作为聚类的核心，由轻量级嵌入方法引导。该框架包括三个阶段：嵌入引导的子集划分、LLM驱动的主题总结和基于LLM的主题分配。

**Result:** 实验结果表明，ClusterFusion不仅在三个公开的基准测试标准任务中达到了最先进的性能，并且在两个新的特定领域数据集中显示出了显著的改进。

**Conclusion:** ClusterFusion框架的设计能够直接纳入领域知识和用户偏好，完全发挥大型语言模型的上下文适应性，从而在文本聚类任务上达到优秀的性能。

**Abstract:** Text clustering is a fundamental task in natural language processing, yet traditional clustering algorithms with pre-trained embeddings often struggle in domain-specific contexts without costly fine-tuning. Large language models (LLMs) provide strong contextual reasoning, yet prior work mainly uses them as auxiliary modules to refine embeddings or adjust cluster boundaries. We propose ClusterFusion, a hybrid framework that instead treats the LLM as the clustering core, guided by lightweight embedding methods. The framework proceeds in three stages: embedding-guided subset partition, LLM-driven topic summarization, and LLM-based topic assignment. This design enables direct incorporation of domain knowledge and user preferences, fully leveraging the contextual adaptability of LLMs. Experiments on three public benchmarks and two new domain-specific datasets demonstrate that ClusterFusion not only achieves state-of-the-art performance on standard tasks but also delivers substantial gains in specialized domains. To support future work, we release our newly constructed dataset and results on all benchmarks.

</details>


### [6] [LangSAT: A Novel Framework Combining NLP and Reinforcement Learning for SAT Solving](https://arxiv.org/abs/2512.04374)
*Muyu Pan,Matthew Walter,Dheeraj Kodakandla,Mahfuza Farooque*

Main category: cs.CL

> 这项工作介绍了一个叫LangSAT的新框架，使用强化学习（RL）来优化子句学习（CDCL）过程中的启发式选择，可以将自然语言转换为CNF且用RL增强的算法求解SAT问题。该方法提高了SAT求解的效率和用户友好性。

<details>
  <summary>Details</summary>

**Motivation:** 该工作的动机在于通过加强自然语言处理和SAT求解之间的桥梁，提高SAT求解的效率和用户友好性。特别是，现有SAT求解平台要求CNF作为输入，限制了它们的应用。通过引入LangSAT框架，软件可以接受标准英语描述作为输入，使得SAT求解对于广大用户来说变得更加访问。

**Method:** 此论文的方法基于两个主要组成部分：其一是Lang2Logic，它将自然语言输入转化为CNF表达式；其二是SmartSAT，它利用结构化图表示和全局特征提取来增强RL的能力，以优化CDCL过程中对启发式算法的选择。

**Result:** 该研究提出了一个基于强化学习（RL）的框架，用于优化冲突驱动子句学习（CDCL）过程中启发式算法的选择，从而提高布尔可满足性（SAT）问题解决的效率。该系统名为LangSAT，它建立了自然语言输入与命题逻辑之间的桥梁，能够将英语描述转换为合取范式（CNF）表达式，并使用增强的RL CDCL SAT求解器来解决这些问题。LangSAT系统的两个关键组成部分是：Lang2Logic，用于将英语句子翻译成CNF表达式；SmartSAT，一个基于RL的SAT求解器。SmartSAT将子句-变量关系编码为结构化图表示，并提取与SAT问题相关的全局特征，给RL智能体提供更深层次的上下文信息，从而更高效地解决SAT问题。Lang2Logic在多样化的自然语言输入上进行评估，能够处理多达450词的描述。生成的CNF由SmartSAT求解，显示出与传统CDCL启发式算法相当的求解速度。整个LangSAT框架为跨推理、形式验证和调试领域的SAT问题求解提供了一个更加便捷和可扩展的解决方案。

**Conclusion:** 结论是，LangSAT框架提供了一个更易于访问和可扩展的解决方案，用于解决推理、形式验证和调试等领域的SAT问题。这种方法成功地将自然语言输入转化为CNF表达式，利用增强的RL组件提高了SAT求解的效率和性能。

**Abstract:** Our work presents a novel reinforcement learning (RL) based framework to optimize heuristic selection within the conflict-driven clause learning (CDCL) process, improving the efficiency of Boolean satisfiability (SAT) solving. The proposed system, LangSAT, bridges the gap between natural language inputs and propositional logic by converting English descriptions into Conjunctive Normal Form (CNF) expressions and solving them using an RL-enhanced CDCL SAT solver. Unlike existing SAT-solving platforms that require CNF as input, LangSAT enables users to input standard English descriptions, making SAT-solving more accessible. The framework comprises two key components: Lang2Logic, which translates English sentences into CNF expressions, and SmartSAT, an RL-based SAT solver. SmartSAT encodes clause-variable relationships as structured graph representations and extracts global features specific to the SAT problem. This implementation provides the RL agent with deeper contextual information, enabling SAT problems to be solved more efficiently. Lang2Logic was evaluated on diverse natural language inputs, processing descriptions up to 450 words. The generated CNFs were solved by SmartSAT, which demonstrated comparable performance to traditional CDCL heuristics with respect to solving time. The combined LangSAT framework offers a more accessible and scalable solution for SAT-solving tasks across reasoning, formal verification, and debugging.

</details>


### [7] [MASE: Interpretable NLP Models via Model-Agnostic Saliency Estimation](https://arxiv.org/abs/2512.04386)
*Zhou Yang,Shunyan Luo,Jiazhen Zhu,Fang Jin*

Main category: cs.CL

> 本文提出了MASE框架，通过NLGP对嵌入层的操作，为基于文本的预测模型提供不依赖于模型内部架构的局部解释，其在Delta Accuracy上的结果优于其他方法。

<details>
  <summary>Details</summary>

**Motivation:** 深度神经网络在自然语言处理中取得了显著进展，但其解释性仍然难以理解，特别是评估其复杂的决策过程时。传统的解释方法可能不适用于NLP中单词数据的离散性质。

**Method:** MASE框架通过在嵌入层使用正则化线性高斯扰动（NLGP）而不是原始单词输入，来估计输入的重要性，从而为基于文本的预测模型提供局部解释。

**Result:** 实验结果表明，MASE在Delta Accuracy方面优于其他模型无关的解释方法。

**Conclusion:** MASE作为解释NLP中基于文本模型操作的工具具有广阔的前景。

**Abstract:** Deep neural networks (DNNs) have made significant strides in Natural Language Processing (NLP), yet their interpretability remains elusive, particularly when evaluating their intricate decision-making processes. Traditional methods often rely on post-hoc interpretations, such as saliency maps or feature visualization, which might not be directly applicable to the discrete nature of word data in NLP. Addressing this, we introduce the Model-agnostic Saliency Estimation (MASE) framework. MASE offers local explanations for text-based predictive models without necessitating in-depth knowledge of a model's internal architecture. By leveraging Normalized Linear Gaussian Perturbations (NLGP) on the embedding layer instead of raw word inputs, MASE efficiently estimates input saliency. Our results indicate MASE's superiority over other model-agnostic interpretation methods, especially in terms of Delta Accuracy, positioning it as a promising tool for elucidating the operations of text-based models in NLP.

</details>


### [8] [Sarcasm Detection on Reddit Using Classical Machine Learning and Feature Engineering](https://arxiv.org/abs/2512.04396)
*Subrata Karmaker*

Main category: cs.CL

> 本研究采用传统的机器学习方法和特征工程识别 Reddit 数据库中的讽刺言论，利用词级和字符级的TF-IDF特征以及简单的文体指标，模型评估中朴素贝叶斯和逻辑回归表现最佳，F1值约为0.57。

<details>
  <summary>Details</summary>

**Motivation:** 讽刺在在线讨论中很常见但机器难以识别，因为其实际含义往往与字面意思相矛盾。本研究旨在不依赖神经网络或上下文的情况下，通过传统方法建立可理解的讽刺检测基线。

**Method:** 使用10万条评论的SARC 2.0子集，组合词级别和字符级别的TF-IDF特征以及简单风格指示器。评估四种模型：逻辑回归、线性SVM、多项式朴素贝叶斯和随机森林。

**Result:** 朴素贝叶斯和逻辑回归表现最佳，对于讽刺性评论的F1值约为0.57。

**Conclusion:** 尽管缺乏对话上下文限制了性能，结果仍为使用轻量化和可解释方法的讽刺检测提供了明确且可重复的基线。

**Abstract:** Sarcasm is common in online discussions, yet difficult for machines to identify because the intended meaning often contradicts the literal wording. In this work, I study sarcasm detection using only classical machine learning methods and explicit feature engineering, without relying on neural networks or context from parent comments. Using a 100,000-comment subsample of the Self-Annotated Reddit Corpus (SARC 2.0), I combine word-level and character-level TF-IDF features with simple stylistic indicators. Four models are evaluated: logistic regression, a linear SVM, multinomial Naive Bayes, and a random forest. Naive Bayes and logistic regression perform the strongest, achieving F1-scores around 0.57 for sarcastic comments. Although the lack of conversational context limits performance, the results offer a clear and reproducible baseline for sarcasm detection using lightweight and interpretable methods.

</details>


### [9] [RapidUn: Influence-Driven Parameter Reweighting for Efficient Large Language Model Unlearning](https://arxiv.org/abs/2512.04457)
*Guoshenghui Zhao,Huawei Lin,Weijie Zhao*

Main category: cs.CL

> The paper introduces RapidUn, an efficient unlearning framework for large language models, which uses influence-driven parameter reweighting to remove specific data influence more efficiently than full retraining.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to address the inefficiency and instability of current unlearning methods for large language models, especially when the data set for unlearning is small or imbalanced.

**Method:** RapidUn estimates per-sample influence through a fast estimation module and then adjusts parameter updates selectively to forget harmful behaviors while preserving general knowledge.

**Result:** Compared to full retraining and other unlearning methods like Fisher, GA, and LoReUn, RapidUn demonstrates up to 100 times higher efficiency and better performance across different datasets.

**Conclusion:** The paper concludes that influence-guided parameter reweighting is a scalable and interpretable approach for improving the effectiveness of unlearning in large language models.

**Abstract:** Removing specific data influence from large language models (LLMs) remains challenging, as retraining is costly and existing approximate unlearning methods are often unstable. The challenge is exacerbated when the forget set is small or imbalanced. We introduce RapidUn, an influence-driven and parameter-efficient unlearning framework. It first estimates per-sample influence through a fast estimation module, then maps these scores into adaptive update weights that guide selective parameter updates -- forgetting harmful behavior while retaining general knowledge. On Mistral-7B and Llama-3-8B across Dolly-15k and Alpaca-57k, RapidUn achieves up to 100 times higher efficiency than full retraining and consistently outperforms Fisher, GA, and LoReUn on both in-distribution and out-of-distribution forgetting. These results establish influence-guided parameter reweighting as a scalable and interpretable paradigm for LLM unlearning.

</details>


### [10] [MSME: A Multi-Stage Multi-Expert Framework for Zero-Shot Stance Detection](https://arxiv.org/abs/2512.04492)
*Yuanshuo Zhang,Aohua Li,Bo Chen,Jingbo Sun,Xiaobing Zhao*

Main category: cs.CL

> Proposes MSME for better zero-shot stance detection in complex scenarios, achieving top performance on public datasets.

<details>
  <summary>Details</summary>

**Motivation:** The motivation is to improve zero-shot stance detection in complex real-world scenarios where stance understanding requires dynamic background knowledge, and handling compound entities or events and rhetorical devices.

**Method:** MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection, includes three stages: Knowledge Preparation, Expert Reasoning with three specialized modules (Knowledge Expert, Label Expert, Pragmatic Expert), and Decision Aggregation.

**Result:** Experiments show that MSME achieves state-of-the-art performance across three public datasets.

**Conclusion:** The multi-stage and multi-expert design effectively enhances the ability of the model to handle complex scenarios in zero-shot stance detection tasks.

**Abstract:** LLM-based approaches have recently achieved impressive results in zero-shot stance detection. However, they still struggle in complex real-world scenarios, where stance understanding requires dynamic background knowledge, target definitions involve compound entities or events that must be explicitly linked to stance labels, and rhetorical devices such as irony often obscure the author's actual intent. To address these challenges, we propose MSME, a Multi-Stage, Multi-Expert framework for zero-shot stance detection. MSME consists of three stages: (1) Knowledge Preparation, where relevant background knowledge is retrieved and stance labels are clarified; (2) Expert Reasoning, involving three specialized modules-Knowledge Expert distills salient facts and reasons from a knowledge perspective, Label Expert refines stance labels and reasons accordingly, and Pragmatic Expert detects rhetorical cues such as irony to infer intent from a pragmatic angle; (3) Decision Aggregation, where a Meta-Judge integrates all expert analyses to produce the final stance prediction. Experiments on three public datasets show that MSME achieves state-of-the-art performance across the board.

</details>


### [11] [UW-BioNLP at ChemoTimelines 2025: Thinking, Fine-Tuning, and Dictionary-Enhanced LLM Systems for Chemotherapy Timeline Extraction](https://arxiv.org/abs/2512.04518)
*Tianmai M. Zhang,Zhaoyi Sun,Sihang Zeng,Chenxi Li,Neil F. Abernethy,Barbara D. Lam,Fei Xia,Meliha Yetisgen*

Main category: cs.CL

> 在ChemoTimelines共享任务中评估并描述了几种生成患者化疗时间线的方法，微调后的Qwen3-14B表现最佳。

<details>
  <summary>Details</summary>

**Motivation:** 旨在通过改进时间线提取技术，提升从电子健康记录中构建抗癌治疗时间线的准确性和效率。

**Method:** 描述了用于从患者电子健康记录中构建抗癌治疗时间线的方法。特别针对子任务2——从原始临床笔记生成患者化疗时间线，评估了包括链式思考、有监督微调、直接偏好优化和基于字典的查找等策略。所有方法都采用了两步流程：大型语言模型首先从单个临床笔记中提取化疗事件，然后算法将事件标准化并聚合形成患者级别的时间线。

**Result:** 多个方法在测试集排行榜上表现良好，其中微调后的Qwen3-14B达到了最佳官方得分0.678。

**Conclusion:** 研究结果和分析为未来尝试解决此任务以及设计类似任务提供了有价值的见解。

**Abstract:** The ChemoTimelines shared task benchmarks methods for constructing timelines of systemic anticancer treatment from electronic health records of cancer patients. This paper describes our methods, results, and findings for subtask 2 -- generating patient chemotherapy timelines from raw clinical notes. We evaluated strategies involving chain-of-thought thinking, supervised fine-tuning, direct preference optimization, and dictionary-based lookup to improve timeline extraction. All of our approaches followed a two-step workflow, wherein an LLM first extracted chemotherapy events from individual clinical notes, and then an algorithm normalized and aggregated events into patient-level timelines. Each specific method differed in how the associated LLM was utilized and trained. Multiple approaches yielded competitive performances on the test set leaderboard, with fine-tuned Qwen3-14B achieving the best official score of 0.678. Our results and analyses could provide useful insights for future attempts on this task as well as the design of similar tasks.

</details>


### [12] [EvoEdit: Lifelong Free-Text Knowledge Editing through Latent Perturbation Augmentation and Knowledge-driven Parameter Fusion](https://arxiv.org/abs/2512.04545)
*Pengfei Cao,Zeao Ji,Daojian Zeng,Jun Zhao,Kang Liu*

Main category: cs.CL

> 本文提出了一种新的任务——终身自由文本知识编辑（LF-Edit），旨在解决大型语言模型中知识编辑的难题，并设计了一种评价框架和一种名为EvoEdit的新方法，该方法显著优于现有的知识编辑方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有知识编辑方法依赖于与自由文本预训练不符的结构化三元组，且通常只支持一次性知识更新，这限制了其应用范围。因此，提出LF-Edit任务，以应对这些不足。

**Method:** 本文提出了一种称为EvoEdit的新方法，通过潜在扰动增强来提升知识注入，同时利用知识驱动的参数融合保存先前信息，以解决LF-Edit所带来的挑战。

**Result:** 实验结果表明，EvoEdit在新提出的LF-Edit任务上表现出显著的性能提升，优于现有的知识编辑方法。

**Conclusion:** 本文提出了LF-Edit任务及相应的挑战，并通过构建大规模评估基准MRLF-Bench和开发EvoEdit方法，为该领域的后续研究奠定了基础。

**Abstract:** Adjusting the outdated knowledge of large language models (LLMs) after deployment remains a major challenge. This difficulty has spurred the development of knowledge editing, which seeks to accurately and efficiently modify a model's internal (parametric) knowledge without retraining it from scratch. However, existing methods suffer from two limitations. First, they depend on structured triplets that are misaligned with the free-text nature of LLM pretraining and fail to capture the nuanced relationships among facts. Second, they typically support one-time knowledge updates, with relatively limited research on the problem of sequential or lifelong editing. To address these gaps, we propose a new task, Lifelong Free-text Knowledge Editing (LF-Edit), which enables models to incorporate updates expressed in natural language and supports continual editing over time. Despite its promise, LF-Edit faces the dual challenge of integrating new knowledge while mitigating the forgetting of prior information. To foster research on this new task, we construct a large-scale benchmark, Multi-Rank Lifelong Free-text Editing Benchmark (MRLF-Bench), containing 16,835 free-text edit requests. We further design a cognitively inspired multi-rank evaluation framework encompassing four levels: memorization, understanding, constrained comprehension, and reasoning. To tackle the challenges inherent in LF-Edit, we introduce a novel approach named EvoEdit that enhances knowledge injection through Latent Perturbation Augmentation and preserves prior information via Knowledge-driven Parameter Fusion. Experimental results demonstrate that EvoEdit substantially outperforms existing knowledge editing methods on the proposed LF-Edit task.

</details>


### [13] [AdmTree: Compressing Lengthy Context with Adaptive Semantic Trees](https://arxiv.org/abs/2512.04550)
*Yangning Li,Shaoshen Chen,Yinghui Li,Yankai Chen,Hai-Tao Zheng,Hui Wang,Wenhao Jiang,Philip S. Yu*

Main category: cs.CL

> AdmTree is proposed, an adaptive hierarchical context compression framework for Large Language Models that focuses on maintaining semantic fidelity and efficiency.

<details>
  <summary>Details</summary>

**Motivation:** The quadratic complexity of self-attention is a computational bottleneck in Large Language Models (LLMs) for processing long contexts. Existing context compression methods often lack in preserving local details or suffer from information degradation.

**Method:** AdmTree, a novel framework for adaptive, hierarchical context compression. It segments input based on information density, uses gist tokens to summarize variable-length segments, and employs a semantic binary tree structure.

**Result:** AdmTree robustly retains semantic information of long contexts by preserving fine-grained details and global semantic coherence while mitigating positional bias.

**Conclusion:** AdmTree effectively addresses challenges in context compression by providing a balance between semantic preservation and computational efficiency, crucial for long context processing in LLMs.

**Abstract:** The quadratic complexity of self-attention constrains Large Language Models (LLMs) in processing long contexts, a capability essential for many advanced applications. Context compression aims to alleviate this computational bottleneck while retaining critical semantic information. However, existing approaches often fall short: explicit methods may compromise local detail, whereas implicit methods can suffer from positional biases, information degradation, or an inability to capture long-range semantic dependencies. We propose AdmTree, a novel framework for adaptive, hierarchical context compression with a central focus on preserving high semantic fidelity while maintaining efficiency. AdmTree dynamically segments input based on information density, utilizing gist tokens to summarize variable-length segments as the leaves of a semantic binary tree. This structure, together with a lightweight aggregation mechanism and a frozen backbone LLM (thereby minimizing new trainable parameters), enables efficient hierarchical abstraction of the context. By preserving fine-grained details alongside global semantic coherence, mitigating positional bias, and dynamically adapting to content, AdmTree robustly retains the semantic information of long contexts.

</details>


### [14] [ADAPT: Learning Task Mixtures for Budget-Constrained Instruction Tuning](https://arxiv.org/abs/2512.04555)
*Pritam Kadasi,Abhishek Upperwal,Mayank SIngh*

Main category: cs.CL

> 本文提出了ADAPT算法，用于在多任务指令微调中自适应地学习任务采样比例，并通过实验展示其性能优势。

<details>
  <summary>Details</summary>

**Motivation:** 旨在解决传统多任务学习中手动分配任务权重的问题，通过自适应的方法动态调整任务的权重，使得学习过程更加高效。

**Method:** 我们提出了ADAPT，这是一种元学习算法，在显式标记预算下学习多任务指令微调的任务采样比例。ADAPT不是手动固定任务权重，而是保持一个任务的连续分布并通过平滑最差验证目标的元梯度来更新它，从而产生自适应课程，将更多的标记分配给有用的任务同时避免崩溃。

**Result:** ADAPT在三个约10亿参数的开放权重的大型语言模型上进行了实例化，分别为Gemma-3-1B，LLaMA-3.2-1B，Qwen-0.6B，在大约1%，5%，10%的可用监督标记的预算下分别进行了培训，并与具有均匀和大小比例混合方式的强大的监督精细调优基线进行了比较。实验结果显示，在11个跨推理、阅读理解、代码生成和指令跟随的跨领域评估基准上进行评估时，ADAPT匹配或略微提高了相对于最优秀的静态混合的平均下游性能，同时使用更少的有效训练标记并重新分配预算以偏向更难的、与评估基准相关的任务。

**Conclusion:** ADAPT算法能够匹配甚至略微超越静态混合方式的性能表现，同时使用较少的有效训练标记并优化分配预算到更难的、与基准相关的任务上。这表明ADAPT在多任务学习中能够实现有效的自适应任务权重调整。

**Abstract:** We propose ADAPT, a meta-learning algorithm that \emph{learns} task sampling proportions under an explicit token budget for multi-task instruction tuning. Instead of fixing task weights by hand, \adapt{} maintains a continuous distribution over tasks and updates it via meta-gradients of a smooth worst-case validation objective, inducing an adaptive curriculum that allocates more tokens to useful tasks while avoiding collapse. We instantiate ADAPT on three $\sim$1B-parameter open-weight LLMs (Gemma-3-1B, LLaMA-3.2-1B, Qwen-0.6B), training on 20 Natural Instructions task types under budgets of $1\%$, $5\%$, and $10\%$ of the available supervised tokens, and compare against strong supervised fine-tuning baselines with uniform and size-proportional mixing. We conduct evaluations on 11 out-of-domain benchmarks spanning reasoning, reading comprehension, code generation, and instruction following, we find that ADAPT matches or slightly improves average downstream performance relative to the best static mixture, while using fewer effective training tokens and reallocating budget toward harder, benchmark-aligned tasks.

</details>


### [15] [LexGenius: An Expert-Level Benchmark for Large Language Models in Legal General Intelligence](https://arxiv.org/abs/2512.04578)
*Wenjin Liu,Haoran Luo,Xin Feng,Xiang Ji,Lijuan Zhou,Rui Mao,Jiapu Wang,Shirui Pan,Erik Cambria*

Main category: cs.CL

> 提出LexGenius来评估LLM的法律通用智能，发现即使最好的模型也落后于人类专家。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准测试偏重于结果，无法系统地评估大型语言模型的法律智能，阻碍了法律通用智能的发展。为了应对这个问题，提出LexGenius。

**Method:** 提出LexGenius，这是一个专家级别的中文法律基准，用于评估大型语言模型的法律通用智能。它遵循一个维度-任务-能力框架，涵盖七个维度，十一项任务和二十种能力。

**Result:** 评估了12个最先进的大型语言模型，并进行了深入分析。发现这些模型在法律智能能力方面存在显著差距。即使是表现最好的模型也落后于人类法律专业人士。

**Conclusion:** 我们认为，LexGenius可以评估大型语言模型的法律智能能力，并促进法律通用智能的发展。

**Abstract:** Legal general intelligence (GI) refers to artificial intelligence (AI) that encompasses legal understanding, reasoning, and decision-making, simulating the expertise of legal experts across domains. However, existing benchmarks are result-oriented and fail to systematically evaluate the legal intelligence of large language models (LLMs), hindering the development of legal GI. To address this, we propose LexGenius, an expert-level Chinese legal benchmark for evaluating legal GI in LLMs. It follows a Dimension-Task-Ability framework, covering seven dimensions, eleven tasks, and twenty abilities. We use the recent legal cases and exam questions to create multiple-choice questions with a combination of manual and LLM reviews to reduce data leakage risks, ensuring accuracy and reliability through multiple rounds of checks. We evaluate 12 state-of-the-art LLMs using LexGenius and conduct an in-depth analysis. We find significant disparities across legal intelligence abilities for LLMs, with even the best LLMs lagging behind human legal professionals. We believe LexGenius can assess the legal intelligence abilities of LLMs and enhance legal GI development. Our project is available at https://github.com/QwenQKing/LexGenius.

</details>


### [16] [Geschlechtsübergreifende Maskulina im Sprachgebrauch Eine korpusbasierte Untersuchung zu lexemspezifischen Unterschieden](https://arxiv.org/abs/2512.04683)
*Carolin Mueller-Spitzer,Samira Ochs,Jan Oliver Ruediger,Sascha Wolfer*

Main category: cs.CL

> 研究分析了通用男性代词在德语报刊文本中的分布和语言特点，揭示了其在不同名词间的用法差异，强调了其主要用法发生在复数和不定名词短语中。

<details>
  <summary>Details</summary>

**Motivation:** 尽管在学术界和公众中对通用男性代词(GM)的性别中立性存在不同的观点，但仍缺乏对其实际用法的语料库分析。该研究旨在填补这一空白。

**Method:** 该研究通过手动标注了6,195个代词名词的变格形式，分析了21个个人名词在当代德语报刊文本中的用法。

**Result:** 研究发现，通用男性代词的具体用法在不同的个人名词之间存在显著差异，尤其是在被动角色名词和与威望相关的个人名词之间。GM主要出现在复数和不定名词短语中，不主要用于表示整个类的人。

**Conclusion:** 该研究为了解通用男性代词在真实书面语中的形式和表现提供了实证见解，有助于将心理语言学研究中的语言刺激与实际语言使用更加紧密地结合。

**Abstract:** This study examines the distribution and linguistic characteristics of generic masculines (GM) in contemporary German press texts. The use of masculine personal nouns to refer to mixed-gender groups or unspecified individuals has been widely debated in academia and the public, with con-flicting perspectives on its gender-neutrality. While psycholinguistic studies suggest that GM is more readily associated with male referents, corpus-based analyses of its actual use remain scarce. We investigate GM in a large corpus of press texts, focusing on lexeme-specific differences across dif-ferent types of personal nouns. We conducted manual annotations of the whole inflectional para-digm of 21 personal nouns, resulting in 6,195 annotated tokens. Our findings reveal considerable differences between lexical items, especially between passive role nouns and prestige-related per-sonal nouns. On a grammatical level, we find that GM occurs predominantly in the plural and in indefinite noun phrases. Furthermore, our data shows that GM is not primarily used to denote entire classes of people, as has been previously claimed. By providing an empirical insight into the use of GM in authentic written language, we contribute to a more nuanced understanding of its forms and manifestations. These findings provide a solid basis for aligning linguistic stimuli in psy-cholinguistic studies more closely with real-world language use.

</details>


### [17] [OsmT: Bridging OpenStreetMap Queries and Natural Language with Open-source Tag-aware Language Models](https://arxiv.org/abs/2512.04738)
*Zhuoyue Wan,Wentao Hu,Chen Jason Zhang,Yuanfeng Song,Shuaimin Li,Ruiqiang Xiao,Xiao-Yong Wei,Raymond Chi-Wing Wong*

Main category: cs.CL

> 研究开发了一种开源语言模型OsmT，能够生成准确且结构合法的OverpassQL查询，配合逆转换任务提高用户对查询的理解。实验表明，虽然参数较少，但相较于多个基线模型，其性能仍具备竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 目的是解决在数据库社区中长久以来存在的自然语言与结构化查询语言之间的桥梁问题，特别是在地理空间查询生成的背景下，强调模型的开放性、透明度和适应性。

**Method:** 文章介绍了一种名为OsmT的开源标签感知语言模型，旨在在自然语言和Overpass查询语言（OverpassQL）之间建立桥梁。为了提高生成查询的准确性和结构性，文章引入了标签检索增强（TRA）机制，该机制将上下文相关的标签知识整合到生成过程中，从而捕捉到OpenStreetMap（OSM）数据库中的层级和关系依赖。此外，文章还定义了一个逆向任务，即将OverpassQL转化为自然语言解释，以支持查询解释和提升用户可访问性。

**Result:** 在公共基准上评估OsmT，并与强基线模型进行比较，观察到在查询生成和解释方面的一致提升。尽管参数显著减少，该模型仍实现了具有竞争力的准确性，这展示了开源预训练语言模型的有效性。

**Conclusion:** OsmT模型在参数量显著少于大型封闭源模型的情况下，仍能在地理空间数据库环境中有效桥接自然语言和结构化查询语言，展示了开源预训练语言模型在这一领域的有效性。

**Abstract:** Bridging natural language and structured query languages is a long-standing challenge in the database community. While recent advances in language models have shown promise in this direction, existing solutions often rely on large-scale closed-source models that suffer from high inference costs, limited transparency, and lack of adaptability for lightweight deployment. In this paper, we present OsmT, an open-source tag-aware language model specifically designed to bridge natural language and Overpass Query Language (OverpassQL), a structured query language for accessing large-scale OpenStreetMap (OSM) data. To enhance the accuracy and structural validity of generated queries, we introduce a Tag Retrieval Augmentation (TRA) mechanism that incorporates contextually relevant tag knowledge into the generation process. This mechanism is designed to capture the hierarchical and relational dependencies present in the OSM database, addressing the topological complexity inherent in geospatial query formulation. In addition, we define a reverse task, OverpassQL-to-Text, which translates structured queries into natural language explanations to support query interpretation and improve user accessibility. We evaluate OsmT on a public benchmark against strong baselines and observe consistent improvements in both query generation and interpretation. Despite using significantly fewer parameters, our model achieves competitive accuracy, demonstrating the effectiveness of open-source pre-trained language models in bridging natural language and structured query languages within schema-rich geospatial environments.

</details>


### [18] [SignRoundV2: Closing the Performance Gap in Extremely Low-Bit Post-Training Quantization for LLMs](https://arxiv.org/abs/2512.04746)
*Wenhua Cheng,Weiwei Zhang,Heng Guo,Haihao Shen*

Main category: cs.CL

> 提出了SignRoundV2框架，它能有效解决低比特量化中性能下降的问题，实现极低比特量化的同时保持模型竞争力。

<details>
  <summary>Details</summary>

**Motivation:** 极低比特量化对大型语言模型的高效部署至关重要，但以往的量化方法在2比特和4比特时常导致性能显著下降。

**Method:** SignRoundV2 是一个后训练量化框架，包括两个部分：一个结合梯度信息和量化偏差的快速敏感性指标，用于指导逐层比特分配；另一个是轻量级预调搜索量化比例，以改善极低比特量化。

**Result:** 广泛的实验表明该方法能保持大型语言模型的竞争力，4-5比特时仅有约1%的精度变化，甚至在2比特处也显示出良好的性能。

**Conclusion:** SignRoundV2 量化框架能够在极低位宽下维持接近全精度模型的性能。

**Abstract:** Extreme low-bit quantization is critical for efficiently deploying Large Language Models (LLMs), yet it often leads to severe performance degradation at 2-bits and even 4-bits (e.g., MXFP4). We present SignRoundV2, a post-training quantization framework that is highly effective even without mixed-precision. SignRoundV2 introduces (1) a fast sensitivity metric that combines gradient information with quantization-induced deviations to guide layer-wise bit allocation, and (2) a lightweight pre-tuning search for quantization scales to improve extremely low-bit quantization. These components allow SignRoundV2 to close the gap with full-precision models. Extensive experiments indicate that our method sustains competitive accuracy for LLMs, achieving production-grade performance with about 1 percent variance at 4-5 bits and strong results even at 2 bits. The implementation is available at https://github.com/intel/auto-round.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [19] [Beyond Flicker: Detecting Kinematic Inconsistencies for Generalizable Deepfake Video Detection](https://arxiv.org/abs/2512.04175)
*Alejandro Cobo,Roberto Valle,José Miguel Buenaposada,Luis Baumela*

Main category: cs.CV

> This paper presents a method for generating synthetic video data with subtle kinematic inconsistencies, which helps to train a network that can detect sophisticated biomechanical flaws in deepfakes, achieving state-of-the-art generalization results.

<details>
  <summary>Details</summary>

**Motivation:** The motivation for this paper is the challenge of generalizing deepfake detection to unseen manipulations, particularly in the video domain where existing methods have overlooked the vulnerability of natural motion dependencies between different facial regions.

**Method:** We propose a synthetic video generation method that creates training data with subtle kinematic inconsistencies. An autoencoder is trained to decompose facial landmark configurations into motion bases, allowing us to selectively break the natural correlations in facial movements and introduce these artifacts into pristine videos via face morphing.

**Result:** The network trained on the proposed synthetic video data with kinematic inconsistencies achieves state-of-the-art generalization results on several benchmarks for deepfake detection.

**Conclusion:** The network trained on the proposed data achieves state-of-the-art generalization results on several popular benchmarks, suggesting that the method is effective for detecting deepfakes with unseen manipulations.

**Abstract:** Generalizing deepfake detection to unseen manipulations remains a key challenge. A recent approach to tackle this issue is to train a network with pristine face images that have been manipulated with hand-crafted artifacts to extract more generalizable clues. While effective for static images, extending this to the video domain is an open issue. Existing methods model temporal artifacts as frame-to-frame instabilities, overlooking a key vulnerability: the violation of natural motion dependencies between different facial regions. In this paper, we propose a synthetic video generation method that creates training data with subtle kinematic inconsistencies. We train an autoencoder to decompose facial landmark configurations into motion bases. By manipulating these bases, we selectively break the natural correlations in facial movements and introduce these artifacts into pristine videos via face morphing. A network trained on our data learns to spot these sophisticated biomechanical flaws, achieving state-of-the-art generalization results on several popular benchmarks.

</details>


### [20] [OnSight Pathology: A real-time platform-agnostic computational pathology companion for histopathology](https://arxiv.org/abs/2512.04187)
*Jinzhen Hu,Kevin Faust,Parsa Babaei Zadeh,Adrienn Bourkas,Shane Eaton,Andrew Young,Anzar Alvi,Dimitrios George Oreopoulos,Ameesha Paliwal,Assem Saleh Alrumeh,Evelyn Rose Kamski-Hennekam,Phedias Diamandis*

Main category: cs.CV

> 本文介绍了一种名为OnSight Pathology的新型平台无关病理学AI软件，其特点是成本效益高、易于部署，可在多种环境中提供实时AI分析。

<details>
  <summary>Details</summary>

**Motivation:** 为了克服现有数字病理学解决方案的专有性壁垒，该研究旨在提供一个平臺无关、成本效益高的平台，以促进AI在病理学中的实际应用。

**Method:** 介绍了一个名为OnSight Pathology的计算机视觉软件，它可以在用户查看数字切片图像时提供实时AI推断。该软件作为单个独立可执行文件运行，不需要复杂的软件集成，可以在消费级个人电脑上本地操作，无需互联网连接。

**Result:** 在超过2,500张公共全切片图像及临床病理数字设置的实际案例上，OnSight Pathology展现了在多种常规组织病理学任务中的强效性能，从脑肿瘤分类到免疫组织化学染色定量。

**Conclusion:** OnSight Pathology通过提供一个易于部署的实时AI分析解决方案，克服了现有数字病理学软件的一些主要障碍，为病理学研究和临床工作流程提供了强大的工具。

**Abstract:** The microscopic examination of surgical tissue remains a cornerstone of disease classification but relies on subjective interpretations and access to highly specialized experts, which can compromise accuracy and clinical care. While emerging breakthroughs in artificial intelligence (AI) offer promise for automated histological analysis, the growing number of proprietary digital pathology solutions has created barriers to real-world deployment. To address these challenges, we introduce OnSight Pathology, a platform-agnostic computer vision software that uses continuous custom screen captures to provide real-time AI inferences to users as they review digital slide images. Accessible as a single, self-contained executable file (https://onsightpathology.github.io/ ), OnSight Pathology operates locally on consumer-grade personal computers without complex software integration, enabling cost-effective and secure deployment in research and clinical workflows. Here we demonstrate the utility of OnSight Pathology using over 2,500 publicly available whole slide images across different slide viewers, as well as cases from our clinical digital pathology setup. The software's robustness is highlighted across routine histopathological tasks, including the classification of common brain tumor types, mitosis detection, and the quantification of immunohistochemical stains. A built-in multi-modal chat assistant provides verifiable descriptions of images, free of rigid class labels, for added quality control. Lastly, we show compatibility with live microscope camera feeds, including from personal smartphones, offering potential for deployment in more analog, inter-operative, and telepathology settings. Together, we highlight how OnSight Pathology can deliver real-time AI inferences across a broad range of pathology pipelines, removing key barriers to the adoption of AI tools in histopathology.

</details>


### [21] [Look Around and Pay Attention: Multi-camera Point Tracking Reimagined with Transformers](https://arxiv.org/abs/2512.04213)
*Bishoy Galoaa,Xiangyu Bai,Shayda Moezzi,Utsav Nandi,Sai Siddhartha Vivek Dhir Rangoju,Somaieh Amraee,Sarah Ostadabbas*

Main category: cs.CV

> LAPA, a transformer-based framework for multi-camera point tracking, shows notable improvements over traditional methods by integrating appearance-based matching and geometric constraints, achieving high performance on complex tracking scenarios.

<details>
  <summary>Details</summary>

**Motivation:** The aim is to overcome the issues of error propagation and temporal inconsistency in multi-camera point tracking by integrating appearance-based matching with geometric constraints in a unified end-to-end framework.

**Method:** The paper introduces LAPA, a transformer-based model for multi-camera point tracking that uses cross-view attention mechanisms enhanced with geometric priors to improve upon traditional methods that separate detection, association, and tracking.

**Result:** The method was tested on challenging datasets, including multi-camera versions of TAPVid-3D and PointOdyssey, showing significant performance improvements, with APDs of 37.5% and 90.3% respectively, especially in complex and occluded scenarios.

**Conclusion:** By leveraging cross-view attention and geometric constraints, LAPA achieves superior performance in multi-camera point tracking compared to existing methods, particularly in dynamic and occluded environments.

**Abstract:** This paper presents LAPA (Look Around and Pay Attention), a novel end-to-end transformer-based architecture for multi-camera point tracking that integrates appearance-based matching with geometric constraints. Traditional pipelines decouple detection, association, and tracking, leading to error propagation and temporal inconsistency in challenging scenarios. LAPA addresses these limitations by leveraging attention mechanisms to jointly reason across views and time, establishing soft correspondences through a cross-view attention mechanism enhanced with geometric priors. Instead of relying on classical triangulation, we construct 3D point representations via attention-weighted aggregation, inherently accommodating uncertainty and partial observations. Temporal consistency is further maintained through a transformer decoder that models long-range dependencies, preserving identities through extended occlusions. Extensive experiments on challenging datasets, including our newly created multi-camera (MC) versions of TAPVid-3D panoptic and PointOdyssey, demonstrate that our unified approach significantly outperforms existing methods, achieving 37.5% APD on TAPVid-3D-MC and 90.3% APD on PointOdyssey-MC, particularly excelling in scenarios with complex motions and occlusions. Code is available at https://github.com/ostadabbas/Look-Around-and-Pay-Attention-LAPA-

</details>


### [22] [Generalized Event Partonomy Inference with Structured Hierarchical Predictive Learning](https://arxiv.org/abs/2512.04219)
*Zhou Chen,Joe Lin,Sathyanarayanan N. Aakur\\*

Main category: cs.CV

> PARSE 框架通过层次递归预测器自动从流式视频中学习多尺度事件结构，展示出接近全周期基准的方法，并且在多个评估指标上都表现出色。

<details>
  <summary>Details</summary>

**Motivation:** 模仿人类可以连续感知体验为具有嵌套事件的层次结构的能力，这种结构要求计算机视觉模型能够不仅仅在事后进行事件分割，而是在预测性和层次性上也做到这一点。

**Method:** PARSE 是一个统一的框架，能够直接从流式视频中学习多尺度事件结构，无需监督。该框架通过一系列递归预测器组织感知，每个预测器在自己的时间粒度上运行：低层模型短期动态，而高层通过基于注意力的反馈整合长期上下文。事件边界自然地作为预测误差中的瞬时峰值出现，产生了与人类事件感知中的包含关系相呼应的、时间一致的嵌套部分分类。

**Result:** 在 Breakfast Actions、50 Salads 和 Assembly 101 三个基准上，PARSE 达到了流式方法的最先进性能，与全周期基线方法在时间对齐（H-GEBD）和结构一致性（TED, hF1）方面相当。

**Conclusion:** 实验结果表明，不确定条件下的预测学习为实现类似人类的时态抽象和组合事件理解提供了一条可扩展的道路。

**Abstract:** Humans naturally perceive continuous experience as a hierarchy of temporally nested events, fine-grained actions embedded within coarser routines. Replicating this structure in computer vision requires models that can segment video not just retrospectively, but predictively and hierarchically. We introduce PARSE, a unified framework that learns multiscale event structure directly from streaming video without supervision. PARSE organizes perception into a hierarchy of recurrent predictors, each operating at its own temporal granularity: lower layers model short-term dynamics while higher layers integrate longer-term context through attention-based feedback. Event boundaries emerge naturally as transient peaks in prediction error, yielding temporally coherent, nested partonomies that mirror the containment relations observed in human event perception. Evaluated across three benchmarks, Breakfast Actions, 50 Salads, and Assembly 101, PARSE achieves state-of-the-art performance among streaming methods and rivals offline baselines in both temporal alignment (H-GEBD) and structural consistency (TED, hF1). The results demonstrate that predictive learning under uncertainty provides a scalable path toward human-like temporal abstraction and compositional event understanding.

</details>


### [23] [MoReGen: Multi-Agent Motion-Reasoning Engine for Code-based Text-to-Video Synthesis](https://arxiv.org/abs/2512.04221)
*Xiangyu Bai,He Liang,Bishoy Galoaa,Utsav Nandi,Shayda Moezzi,Yuhang He,Sarah Ostadabbas*

Main category: cs.CV

> 本文介绍了一个专用于生成符合物理规则且具有连贯运动的视频的框架MoReGen，并通过MoReSet基准评估了其物理精确性，显示出优于现有T2V模型的效果。

<details>
  <summary>Details</summary>

**Motivation:** 尽管文本到视频（T2V）生成在写实性方面取得了显著进展，但生成符合物理原则的视频仍然是一项核心挑战。因此，本研究旨在系统地研究牛顿运动控制的文本到视频生成及其评估，重视物理精确度和运动连贯性。

**Method:** 研究中引入了MoReGen框架，该框架结合了多代理LLM、物理仿真器和渲染器，以从代码领域的文本提示中生成可重复且物理精确的视频。

**Result:** 通过MoReSet基准测试，研究人员发现现有的T2V模型难以保持物理有效性，而MoReGen为物理一致的视频合成提供了一个原则性的方向。

**Conclusion:** MoReGen框架和MoReSet基准测试表明，为T2V生成提供物理精确度和运动连贯性是可行的，需要进一步研究以维持物理有效性。

**Abstract:** While text-to-video (T2V) generation has achieved remarkable progress in photorealism, generating intent-aligned videos that faithfully obey physics principles remains a core challenge. In this work, we systematically study Newtonian motion-controlled text-to-video generation and evaluation, emphasizing physical precision and motion coherence. We introduce MoReGen, a motion-aware, physics-grounded T2V framework that integrates multi-agent LLMs, physics simulators, and renderers to generate reproducible, physically accurate videos from text prompts in the code domain. To quantitatively assess physical validity, we propose object-trajectory correspondence as a direct evaluation metric and present MoReSet, a benchmark of 1,275 human-annotated videos spanning nine classes of Newtonian phenomena with scene descriptions, spatiotemporal relations, and ground-truth trajectories. Using MoReSet, we conduct experiments on existing T2V models, evaluating their physical validity through both our MoRe metrics and existing physics-based evaluators. Our results reveal that state-of-the-art models struggle to maintain physical validity, while MoReGen establishes a principled direction toward physically coherent video synthesis.

</details>


### [24] [ReasonX: MLLM-Guided Intrinsic Image Decomposition](https://arxiv.org/abs/2512.04222)
*Alara Dirik,Tuanfeng Wang,Duygu Ceylan,Stefanos Zafeiriou,Anna Frühstück*

Main category: cs.CV

> ReasonX, a novel framework leveraging a multimodal large language model, significantly improves intrinsic image decomposition in real-world settings, demonstrating the efficacy of MLLM-guided comparative supervision.

<details>
  <summary>Details</summary>

**Motivation:** While recent models benefit from paired supervision from synthetic datasets, they struggle to generalize to diverse real-world scenarios effectively.

**Method:** We propose ReasonX, a multimodal large language model (MLLM) based framework that provides relative intrinsic image comparisons as rewards for fine-tuning intrinsic decomposition models on unlabeled, real-world images.

**Result:** ReasonX yields improvements of 9-25% WHDR reduction on IIW albedo and up to 46% depth accuracy gain on ETH3D compared to existing methods.

**Conclusion:** Our findings highlight the potential of using MLLM-guided comparative supervision to better generalize intrinsic image decomposition models to real-world scenarios.

**Abstract:** Intrinsic image decomposition aims to separate images into physical components such as albedo, depth, normals, and illumination. While recent diffusion- and transformer-based models benefit from paired supervision from synthetic datasets, their generalization to diverse, real-world scenarios remains challenging. We propose ReasonX, a novel framework that leverages a multimodal large language model (MLLM) as a perceptual judge providing relative intrinsic comparisons, and uses these comparisons as GRPO rewards for fine-tuning intrinsic decomposition models on unlabeled, in-the-wild images. Unlike RL methods for generative models, our framework aligns conditional intrinsic predictors by rewarding agreement between the judge's relational assessments and analytically derived relations from the model's outputs. ReasonX is model-agnostic and can be applied to different intrinsic predictors. Across multiple base architectures and modalities, ReasonX yields significant improvements, including 9-25% WHDR reduction on IIW albedo and up to 46% depth accuracy gains on ETH3D, highlighting the promise of MLLM-guided comparative supervision to bridge low- and high-level vision reasoning.

</details>


### [25] [6 Fingers, 1 Kidney: Natural Adversarial Medical Images Reveal Critical Weaknesses of Vision-Language Models](https://arxiv.org/abs/2512.04238)
*Leon Mayer,Piotr Kalinowski,Caroline Ebersbach,Marcel Knopp,Tim Rädsch,Evangelia Christodoulou,Annika Reinke,Fiona R. Kolbinger,Lena Maier-Hein*

Main category: cs.CV

> 提出了AdversarialAnatomyBench用于评估视觉语言模型在罕见解剖变体方面的性能。测试发现现有模型在面对罕见解剖变体时表现较差。

<details>
  <summary>Details</summary>

**Motivation:** 现有的基准主要评估常见解剖表现的性能，但未能捕捉罕见变体带来的挑战。为了弥补这一差距，提出了AdversarialAnatomyBench。

**Method:** 引入了AdversarialAnatomyBench，这是一个包含了多种影像模态和解剖区域中自然发生的罕见解剖变体的基准测试。

**Result:** 在AdversarialAnatomyBench的测试中发现了三个关键发现：(1) 在典型和不典型解剖结构的基本医疗感知任务中，平均准确率从74%下降到29%，即便是表现最好的模型的准确率下降幅度为41-51%；(2) 模型的错误密切反映了预期的解剖偏差；(3) 不论是模型规模扩展还是包括偏差感知提示和测试推理在内的干预措施，并未解决这些问题。

**Conclusion:** 本研究强调了一个关键且以前未量化的特点，即当前的视觉语言模型在罕见解剖表现上的泛化能力较差。AdversarialAnatomyBench为系统地测量和减少多模态医疗AI系统中的解剖偏差提供了一个基础。

**Abstract:** Vision-language models are increasingly integrated into clinical workflows. However, existing benchmarks primarily assess performance on common anatomical presentations and fail to capture the challenges posed by rare variants. To address this gap, we introduce AdversarialAnatomyBench, the first benchmark comprising naturally occurring rare anatomical variants across diverse imaging modalities and anatomical regions. We call such variants that violate learned priors about "typical" human anatomy natural adversarial anatomy. Benchmarking 22 state-of-the-art VLMs with AdversarialAnatomyBench yielded three key insights. First, when queried with basic medical perception tasks, mean accuracy dropped from 74% on typical to 29% on atypical anatomy. Even the best-performing models, GPT-5, Gemini 2.5 Pro, and Llama 4 Maverick, showed performance drops of 41-51%. Second, model errors closely mirrored expected anatomical biases. Third, neither model scaling nor interventions, including bias-aware prompting and test-time reasoning, resolved these issues. These findings highlight a critical and previously unquantified limitation in current VLM: their poor generalization to rare anatomical presentations. AdversarialAnatomyBench provides a foundation for systematically measuring and mitigating anatomical bias in multimodal medical AI systems.

</details>


### [26] [MVRoom: Controllable 3D Indoor Scene Generation with Multi-View Diffusion Models](https://arxiv.org/abs/2512.04248)
*Shaoheng Fang,Chaohui Yu,Fan Wang,Qixing Huang*

Main category: cs.CV

> MVRoom通过多视角扩散技术实现3D室内场景生成，有助于精确控制场景生成过程及提高多视角一致性。

<details>
  <summary>Details</summary>

**Motivation:** 为了实现对3D室内场景的可控新颖视图合成，本文提出了MVRoom，它利用多视图扩散并受到粗略3D布局条件的约束。

**Method:** MVRoom采用两阶段设计，第一阶段使用新颖的表示方法来有效地关联3D布局和基于图像的一致条件信号，以实现多视角生成。第二阶段在扩散过程中引入了布局感知的极线注意机制，以增强多视角一致性。此外，通过递归执行多视图生成支持文本到场景生成，实现具有不同对象数量和场景复杂度的迭代框架。

**Result:** 实验结果表明，该方法在新颖视图合成中的3D场景生成具有高保真和可控性，并在定量和定性上均超越了最新的基线方法。

**Conclusion:** MVRoom代表了一种高效的多视角一致性的3D室内场景生成方法，它既可用于定量分析也可用于定性分析，显示出优越的性能。

**Abstract:** We introduce MVRoom, a controllable novel view synthesis (NVS) pipeline for 3D indoor scenes that uses multi-view diffusion conditioned on a coarse 3D layout. MVRoom employs a two-stage design in which the 3D layout is used throughout to enforce multi-view consistency. The first stage employs novel representations to effectively bridge the 3D layout and consistent image-based condition signals for multi-view generation. The second stage performs image-conditioned multi-view generation, incorporating a layout-aware epipolar attention mechanism to enhance multi-view consistency during the diffusion process. Additionally, we introduce an iterative framework that generates 3D scenes with varying numbers of objects and scene complexities by recursively performing multi-view generation (MVRoom), supporting text-to-scene generation. Experimental results demonstrate that our approach achieves high-fidelity and controllable 3D scene generation for NVS, outperforming state-of-the-art baseline methods both quantitatively and qualitatively. Ablation studies further validate the effectiveness of key components within our generation pipeline.

</details>


### [27] [UniLight: A Unified Representation for Lighting](https://arxiv.org/abs/2512.04267)
*Zitian Zhang,Iliyan Georgiev,Michael Fischer,Yannick Hold-Geoffroy,Jean-François Lalonde,Valentin Deschaintre*

Main category: cs.CV

> 提出UniLight，统一多个照明表示模式，实现跨模式照明特征的灵活操作。

<details>
  <summary>Details</summary>

**Motivation:** 现有的照明表示方法（环境图、辐照度、球谐等）互不兼容，限制了跨模式之间的转换。

**Method:** 提出UniLight，这是一种联合潜在空间的照明表示方法，它将文本、图像、辐照度和环境图等多种模式统一在一个共享嵌入空间中。通过对比训练特定模式的编码器，使它们的表示方式对齐，并通过辅助的球谐预测任务来强化方向理解。

**Result:** 实验表明，该表示方法能够捕捉一致且可转移的照明特征，实现跨模式的灵活操作。

**Conclusion:** 通过多模式数据管道，能够在大量数据上进行训练和评估，证明了UniLight在基于光照的检索、环境图生成和基于扩散的图像合成的光照控制等方面的有效性。

**Abstract:** Lighting has a strong influence on visual appearance, yet understanding and representing lighting in images remains notoriously difficult. Various lighting representations exist, such as environment maps, irradiance, spherical harmonics, or text, but they are incompatible, which limits cross-modal transfer. We thus propose UniLight, a joint latent space as lighting representation, that unifies multiple modalities within a shared embedding. Modality-specific encoders for text, images, irradiance, and environment maps are trained contrastively to align their representations, with an auxiliary spherical-harmonics prediction task reinforcing directional understanding. Our multi-modal data pipeline enables large-scale training and evaluation across three tasks: lighting-based retrieval, environment-map generation, and lighting control in diffusion-based image synthesis. Experiments show that our representation captures consistent and transferable lighting features, enabling flexible manipulation across modalities.

</details>


### [28] [Inference-time Stochastic Refinement of GRU-Normalizing Flow for Real-time Video Motion Transfer](https://arxiv.org/abs/2512.04282)
*Tasmiah Haque,Srinjoy Das*

Main category: cs.CV

> 为解决实时视频预测中需要多样且准确的未来预测，本文通过结合GRU-NF与MCMC方法，开发出GRU-SNF模型，在保持预测准确性的同时提高预测多样性。

<details>
  <summary>Details</summary>

**Motivation:** 作者旨在解决实时视频运动传输应用中准确性与多样性预测之间的需求，尤其是在支持基于视觉的异常检测和不确定条件下的稳健决策制定时，这项工作是为了改进当前的预测技术。

**Method:** 本文提出了一种新颖的推理时改进技术，将门控循环单元-归一化流（GRU-NF）与随机抽样方法相结合，以提高未来预测的多样性。为了使模型能够探索更丰富的输出空间并更好地逼近真实数据分布，作者在GRU-NF推理过程中引入了马尔可夫链蒙特卡洛（MCMC）步骤，从而避免了重新训练的需求。

**Result:** 实验结果表明，作者开发的推理框架Gated Recurrent Unit- Stochastic Normalizing Flows（GRU-SNF），在生成多种输出的同时没有牺牲准确性，尤其在更长的预测窗口下表现出色，相较于GRU-NF有显著改善。

**Conclusion:** 该研究表明，在生成时序数据预测中，将随机动态与基于流的序列模型相结合，是一种有效的方法，这展示了这种方法潜在的应用价值。

**Abstract:** Real-time video motion transfer applications such as immersive gaming and vision-based anomaly detection require accurate yet diverse future predictions to support realistic synthesis and robust downstream decision making under uncertainty. To improve the diversity of such sequential forecasts we propose a novel inference-time refinement technique that combines Gated Recurrent Unit-Normalizing Flows (GRU-NF) with stochastic sampling methods. While GRU-NF can capture multimodal distributions through its integration of normalizing flows within a temporal forecasting framework, its deterministic transformation structure can limit expressivity. To address this, inspired by Stochastic Normalizing Flows (SNF), we introduce Markov Chain Monte Carlo (MCMC) steps during GRU-NF inference, enabling the model to explore a richer output space and better approximate the true data distribution without retraining. We validate our approach in a keypoint-based video motion transfer pipeline, where capturing temporally coherent and perceptually diverse future trajectories is essential for realistic samples and low bandwidth communication. Experiments show that our inference framework, Gated Recurrent Unit- Stochastic Normalizing Flows (GRU-SNF) outperforms GRU-NF in generating diverse outputs without sacrificing accuracy, even under longer prediction horizons. By injecting stochasticity during inference, our approach captures multimodal behavior more effectively. These results highlight the potential of integrating stochastic dynamics with flow-based sequence models for generative time series forecasting.

</details>


### [29] [Plug-and-Play Image Restoration with Flow Matching: A Continuous Viewpoint](https://arxiv.org/abs/2512.04283)
*Fan Jia,Yuhao Huang,Shih-Hsin Wang,Cristina Garcia-Cardona,Andrea L. Bertozzi,Bao Wang*

Main category: cs.CV

> 本文提出一种随机动微分方程（SDE）模型来理论化PnP-Flow，并展示了通过此模型的指导可以显著改善图像恢复的效果，尤其是在误差量化和模型优化上。

<details>
  <summary>Details</summary>

**Motivation:** 尽管基于流匹配的生成模型已被整合到插件式图像恢复框架中取得了一些实证上的成功，但对其理论理解仍显不足，因此希望通过理论分析来改进这种模型。

**Method:** 通过推导PnP-Flow的连续极限，得到一个随机动微分方程（SDE）模型，这为提高图像恢复效果提供了两点见解：量化图像恢复误差，并通过调整步长规划和规范化向量场的Lipschitz常数来实现误差减少，以及通过外推法加速现有的PnP-Flow模型。

**Result:** 提出的SDE指导下的改进PnP-Flow模型在图像去噪、去模糊、超分辨率和修复等任务上，相比基准PnP-Flow和其他最先进方法表现优越，取得了更好的性能。

**Conclusion:** 研究得出的SDE模型为PnP-Flow提供了详细的理论支持，展示了通过量化误差和优化模型参数以及使用外推法可以显著改善图像恢复的效果，并且这种方法在多项基准任务上验证了其有效性。

**Abstract:** Flow matching-based generative models have been integrated into the plug-and-play image restoration framework, and the resulting plug-and-play flow matching (PnP-Flow) model has achieved some remarkable empirical success for image restoration. However, the theoretical understanding of PnP-Flow lags its empirical success. In this paper, we derive a continuous limit for PnP-Flow, resulting in a stochastic differential equation (SDE) surrogate model of PnP-Flow. The SDE model provides two particular insights to improve PnP-Flow for image restoration: (1) It enables us to quantify the error for image restoration, informing us to improve step scheduling and regularize the Lipschitz constant of the neural network-parameterized vector field for error reduction. (2) It informs us to accelerate off-the-shelf PnP-Flow models via extrapolation, resulting in a rescaled version of the proposed SDE model. We validate the efficacy of the SDE-informed improved PnP-Flow using several benchmark tasks, including image denoising, deblurring, super-resolution, and inpainting. Numerical results show that our method significantly outperforms the baseline PnP-Flow and other state-of-the-art approaches, achieving superior performance across evaluation metrics.

</details>


### [30] [Learning Single-Image Super-Resolution in the JPEG Compressed Domain](https://arxiv.org/abs/2512.04284)
*Sruthi Srinivasan,Elham Shakibapour,Rajy Rawther,Mehdi Saeedi*

Main category: cs.CV

> This paper presents a fast approach for SISR by performing super-resolution directly on JPEG DCT coefficients, yielding significant improvements in data loading and training speed.

<details>
  <summary>Details</summary>

**Motivation:** The motivation behind this approach is to address the data loading bottleneck in deep learning training, which limits training and inference speed, especially for complex models with large data sizes.

**Method:** The paper proposes to train deep learning models directly on encoded JPEG features to improve data loading efficiency for the task of single-image super-resolution (SISR). This approach performs super-resolution using JPEG DCT coefficients in the frequency domain.

**Result:** The proposed method achieves a 2.6x speedup in data loading and a 2.5x speedup in training while maintaining comparable visual quality to traditional SISR techniques.

**Conclusion:** The work demonstrates that training directly on JPEG features without full decoding can significantly speed up the data loading and training process for SISR tasks, offering a promising avenue for improving the efficiency of deep learning pipelines.

**Abstract:** Deep learning models have grown increasingly complex, with input data sizes scaling accordingly. Despite substantial advances in specialized deep learning hardware, data loading continues to be a major bottleneck that limits training and inference speed. To address this challenge, we propose training models directly on encoded JPEG features, reducing the computational overhead associated with full JPEG decoding and significantly improving data loading efficiency. While prior works have focused on recognition tasks, we investigate the effectiveness of this approach for the restoration task of single-image super-resolution (SISR). We present a lightweight super-resolution pipeline that operates on JPEG discrete cosine transform (DCT) coefficients in the frequency domain. Our pipeline achieves a 2.6x speedup in data loading and a 2.5x speedup in training, while preserving visual quality comparable to standard SISR approaches.

</details>


### [31] [Gamma-from-Mono: Road-Relative, Metric, Self-Supervised Monocular Geometry for Vehicular Applications](https://arxiv.org/abs/2512.04303)
*Gasser Elazab,Maximilian Jansen,Michael Unterreiner,Olaf Hellwich*

Main category: cs.CV

> 一种新的单目道路几何结构估计方法 Gamma-from-Mono（GfM），解决了传统方法在估计精细道路几何特征时过度平滑的问题，提高了运动规划和稳定性，适合自监督学习，不需要大量标注数据。

<details>
  <summary>Details</summary>

**Motivation:** 传统的单目深度估计在处理精细的道路几何结构（如路面起伏、坡度和不规则性）时经常过度平滑这些特征，从而导致至关重要的运动规划和稳定性信息的丢失。为解决这一问题，研究人员开发了 Gamma-from-Mono 方法。

**Method:** Gamma-from-Mono (GfM) 是一种轻量级单目几何估计方法，通过解耦全局和局部结构解决了单摄像机重建中的投影模糊问题。GfM 预测了主导道路表面平面以及该平面上的垂直偏差（gamma），gamma 是基于平面视差几何来定义的高度与深度比值，此方法仅需摄像机离地高度就能确定性地恢复度量深度，避免了完整的外参校准。

**Result:** 在 KITTI 数据集和道路表面重建数据集（RSRD）上，GfM 达到了最先进的近场深度估计和 gamma 估计精度，并且在保持竞争性全局深度表现的同时，其轻量级的模型在多种摄像设置下表现得非常健壮。

**Conclusion:** 该研究展示了一个轻量级模型，仅以 8.88M 参数适应多样化的摄像头型号，并首次在 RSRD 上评估了自监督单目估计方法，为自动驾驶领域的感知和控制提供了一个解决方案。

**Abstract:** Accurate perception of the vehicle's 3D surroundings, including fine-scale road geometry, such as bumps, slopes, and surface irregularities, is essential for safe and comfortable vehicle control. However, conventional monocular depth estimation often oversmooths these features, losing critical information for motion planning and stability. To address this, we introduce Gamma-from-Mono (GfM), a lightweight monocular geometry estimation method that resolves the projective ambiguity in single-camera reconstruction by decoupling global and local structure. GfM predicts a dominant road surface plane together with residual variations expressed by gamma, a dimensionless measure of vertical deviation from the plane, defined as the ratio of a point's height above it to its depth from the camera, and grounded in established planar parallax geometry. With only the camera's height above ground, this representation deterministically recovers metric depth via a closed form, avoiding full extrinsic calibration and naturally prioritizing near-road detail. Its physically interpretable formulation makes it well suited for self-supervised learning, eliminating the need for large annotated datasets. Evaluated on KITTI and the Road Surface Reconstruction Dataset (RSRD), GfM achieves state-of-the-art near-field accuracy in both depth and gamma estimation while maintaining competitive global depth performance. Our lightweight 8.88M-parameter model adapts robustly across diverse camera setups and, to our knowledge, is the first self-supervised monocular approach evaluated on RSRD.

</details>


### [32] [How (Mis)calibrated is Your Federated CLIP and What To Do About It?](https://arxiv.org/abs/2512.04305)
*Mainak Singha,Masih Aminbeidokhti,Paolo Casari,Elisa Ricci,Subhankar Roy*

Main category: cs.CV

> 研究了联邦学习对CLIP校准的影响，提出了$\text{FL}^2\text{oRA}$解决方案，实验展示了其优点。

<details>
  <summary>Details</summary>

**Motivation:** 虽然CLIP的校准对于可靠预测至关重要，但它在这一领域的研究相对较少。我们试图了解在联邦学习环境中调整CLIP时，校准是否会受到影响，并提出改进的方法。

**Method:** 我们研究了联邦学习(FL)对CLIP校准的影响，并提出了改进分布式设置下可靠性的策略。我们首先分析了文本提示调整方法，发现它们在FL中的校准指标下降了。接着，我们评估了四种全局聚合方法在训练中校准技术的效果，发现这些方法改进有限。根据这些见解，我们提出了基于LoRA的简单方法$\text{FL}^2\text{oRA}$，它能自然地提高FL中的校准，并分析了其有效因素。

**Result:** 实验显示，$\text{FL}^2\text{oRA}$能够在多个基准上生成校准良好的模型，减少了对显式校准程序的需求。

**Conclusion:** 研究表明，除了聚合方式和校准方法，选择调整的组件也是影响CLIP校准的关键因素。我们提出的方法$\text{FL}^2\text{oRA}$能够有效提高FL环境中的模型校准准确性。

**Abstract:** While vision-language models like CLIP have been extensively studied, their calibration, crucial for reliable predictions, has received limited attention. Although a few prior works have examined CLIP calibration in offline settings, the impact of fine-tuning CLIP in a federated learning (FL) setup remains unexplored. In this work, we investigate how FL affects CLIP calibration and propose strategies to improve reliability in this distributed setting. We first analyze Textual Prompt Tuning approaches and show that they degrade calibration metrics when operating under FL. We also evaluate existing in-training calibration techniques across four global aggregation methods, finding that they provide limited improvements. Our results suggest that the key challenge lies not only in how we aggregate or calibrate, but in which components we choose to fine-tune. Motivated by this insight, we propose $\text{FL}^2\text{oRA}$, a straightforward LoRA-based approach that naturally improves calibration in FL, and we analyze the factors behind its effectiveness. Experiments on multiple benchmarks demonstrate that $\text{FL}^2\text{oRA}$ consistently produces well-calibrated models, reducing the need for explicit calibration procedures. Codes are available at https://github.com/mainaksingha01/FL2oRA.

</details>
