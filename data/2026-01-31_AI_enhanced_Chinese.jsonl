{"id": "2601.20975", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.20975", "abs": "https://arxiv.org/abs/2601.20975", "authors": ["Nikita Gupta", "Riju Chatterjee", "Lukas Haas", "Connie Tao", "Andrew Wang", "Chang Liu", "Hidekazu Oiwa", "Elena Gribovskaya", "Jan Ackermann", "John Blitzer", "Sasha Goldshtein", "Dipanjan Das"], "title": "DeepSearchQA: Bridging the Comprehensiveness Gap for Deep Research Agents", "comment": "DeepSearchQA can be found at https://www.kaggle.com/benchmarks/google/dsqa/leaderboard", "summary": "We introduce DeepSearchQA, a 900-prompt benchmark for evaluating agents on difficult multi-step information-seeking tasks across 17 different fields. Unlike traditional benchmarks that target single answer retrieval or broad-spectrum factuality, DeepSearchQA features a dataset of challenging, handcrafted tasks designed to evaluate an agent's ability to execute complex search plans to generate exhaustive answer lists. This shift in design explicitly tests three critical, yet under-evaluated capabilities: 1) systematic collation of fragmented information from disparate sources, 2) de-duplication and entity resolution to ensure precision, and 3) the ability to reason about stopping criteria within an open-ended search space. Each task is structured as a causal chain, where discovering information for one step is dependent on the successful completion of the previous one, stressing long-horizon planning and context retention. All tasks are grounded in the open web with objectively verifiable answer sets. Our comprehensive evaluation of state-of-the-art agent architectures reveals significant performance limitations: even the most advanced models struggle to balance high recall with precision. We observe distinct failure modes ranging from premature stopping (under-retrieval) to hedging behaviors, where agents cast an overly wide net of low-confidence answers to artificially boost recall. These findings highlight critical headroom in current agent designs and position DeepSearchQA as an essential diagnostic tool for driving future research toward more robust, deep-research capabilities.", "AI": {"tldr": "DeepSearchQA是一个包括900个提示的基准测试，用于评估智能体在复杂信息检索任务中的表现，发现现有智能体在平衡高召回率与精确度方面存在不足。", "motivation": "目标是识别当前智能体设计中的不足之处，并提供一个诊断工具，推动未来的研究向更强大的深入研究能力发展。", "method": "我们介绍了DeepSearchQA，这是一个包含900个提示的大规模基准测试，用于评估智能体在17个不同领域内面对复杂的多步骤查找任务的表现。不同于传统的针对单一答案检索或广泛事实性的基准测试，DeepSearchQA包含了一系列手工设计的挑战任务，用于评估智能体在收集碎片化信息、去重以及实体消歧以及在开放搜索空间内判断停止标准的能力。", "result": "研究结果揭示了一些最先进的智能体架构在平衡高召回率与精确度方面的显著性能瓶颈，例如过早停止（检索不足）或过宽的低信心答案范围（过度召回）。", "conclusion": "这些发现强调了当前智能体设计中的重要改进空间，以及DeepSearchQA作为推动未来研究方向的关键诊断工具的重要性。"}}
{"id": "2601.20992", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.20992", "abs": "https://arxiv.org/abs/2601.20992", "authors": ["Oleg Sedukhin", "Andrey Kostin"], "title": "asr_eval: Algorithms and tools for multi-reference and streaming speech recognition evaluation", "comment": null, "summary": "We propose several improvements to the speech recognition evaluation. First, we propose a string alignment algorithm that supports both multi-reference labeling, arbitrary-length insertions and better word alignment. This is especially useful for non-Latin languages, those with rich word formation, to label cluttered or longform speech. Secondly, we collect a novel test set DiverseSpeech-Ru of longform in-the-wild Russian speech with careful multi-reference labeling. We also perform multi-reference relabeling of popular Russian tests set and study fine-tuning dynamics on its corresponding train set. We demonstrate that the model often adopts to dataset-specific labeling, causing an illusion of metric improvement. Based on the improved word alignment, we develop tools to evaluate streaming speech recognition and to align multiple transcriptions to compare them visually. Additionally, we provide uniform wrappers for many offline and streaming speech recognition models. Our code will be made publicly available.", "AI": {"tldr": "本文提出了改进语音识别评估的几种方法，包括多参考标注的字符串对齐算法、新型测试集DiverseSpeech-Ru以及多参考重新标注的分析。", "motivation": "改进非拉丁语言和其他复杂语言的语音识别评估，并揭示了数据集标注特定性对模型的影响。", "method": "提出了支持多参考标注、任意长度插入和更好词对齐的字符串对齐算法，并开发了相关评估工具。", "result": "展示了模型对于数据集标注的适应性可能导致评估指标提升的假象，并提供了统一的离线和流式语音识别模型封装。", "conclusion": "改进了语音识别的评估方法，并提供了统一处理多种模型的工具和多样化的测试集。"}}
{"id": "2601.21000", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21000", "abs": "https://arxiv.org/abs/2601.21000", "authors": ["Muhammad Ali Shafique", "Areej Mehboob", "Layba Fiaz", "Muhammad Usman Qadeer", "Hamza Farooq"], "title": "UrduBench: An Urdu Reasoning Benchmark using Contextually Ensembled Translations with Human-in-the-Loop", "comment": null, "summary": "Recent advances in large language models (LLMs) have led to strong reasoning capabilities; however, evaluating such models in low-resource languages remains challenging due to the lack of standardized benchmarks. In particular, Urdu reasoning evaluation has been limited by the sensitivity of machine translation and an emphasis on general language tasks rather than reasoning benchmarks. In this paper, we propose a contextually ensembled translation framework with human-in-the-loop validation that leverages multiple translation systems to develop Urdu reasoning benchmarks while preserving contextual and structural integrity. Using this framework, we translate widely adopted reasoning and question-answering benchmarks, including MGSM, MATH-500, CommonSenseQA, and OpenBookQA, into Urdu, collectively referred to as UrduBench, and conduct a comprehensive evaluation of both reasoning-oriented and instruction-tuned LLMs across multiple prompting strategies. Our analysis reveals performance differences across (1) four datasets, (2) five task difficulty levels, (3) diverse model architectures, (4) multiple model scaling settings, and (5) language consistency tests. We find that multi-step and symbolic reasoning tasks pose significant challenges in Urdu, and that stable language alignment is a critical prerequisite for robust reasoning. Overall, our work establishes a scalable methodology for standardized reasoning evaluation in Urdu and provides empirical insights into multilingual reasoning failures. This experimental setup is also broadly applicable to other low-resource languages. The code and datasets will be publicly released.", "AI": {"tldr": "本文提出了一种适用于乌尔都语推理评估的方法，并构建了乌尔都语推理基准（UrduBench），对多种模型进行了综合评估，探讨了多步和符号推理在乌尔都语中的挑战。", "motivation": "乌尔都语等低资源语言中推理能力评估存在挑战，主要原因是机器翻译的敏感性和对于推理基准重视不够。本研究旨在解决这一问题。", "method": "本研究提出了一种基于上下文集成翻译框架的方法，该框架结合了多个翻译系统并引入人工验证环节，以开发保留上下文和结构完整性的乌尔都语推理基准。", "result": "研究揭示了在四个数据集、五个不同难度级别、不同模型结构、多种模型扩展配置以及语言一致性测试上的性能差异，特别发现乌尔都语在多步和符号推理任务上的挑战性。", "conclusion": "这项研究为乌尔都语推理评估提供了可扩展的方法，并提供了有关多语言推理失败的实证见解。该实验设置也适用于其他低资源语言。"}}
{"id": "2601.21084", "categories": ["cs.CL", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.21084", "abs": "https://arxiv.org/abs/2601.21084", "authors": ["Amit Meghanani", "Thomas Hain"], "title": "Position-invariant Fine-tuning of Speech Enhancement Models with Self-supervised Speech Representations", "comment": "Accepted to ICASSP 2026", "summary": "Integrating front-end speech enhancement (SE) models with self-supervised learning (SSL)-based speech models is effective for downstream tasks in noisy conditions. SE models are commonly fine-tuned using SSL representations with mean squared error (MSE) loss between enhanced and clean speech. However, MSE is prone to exploiting positional embeddings in SSL models, allowing the objective to be minimised through positional correlations instead of content-related information. This work frames the problem as a general limitation of self-supervised representation fine-tuning and investigates it through representation-guided SE. Two strategies are considered: (1) zero-padding, previously explored in SSL pre-training but here examined in the fine-tuning setting, and (2) speed perturbations with a soft-DTW loss. Experiments show that the soft-DTW-based approach achieves faster convergence and improved downstream performance, underscoring the importance of position-invariant fine-tuning in SSL-based speech modelling.", "AI": {"tldr": "This paper explores position-invariant fine-tuning strategies for enhancing the performance of self-supervised learning-based speech models in noisy conditions, highlighting the superiority of a soft-DTW-based approach.", "motivation": "To address the limitation of mean squared error (MSE) being prone to exploiting positional embeddings in self-supervised learning (SSL) models, leading the objective to minimizing through positional correlations instead of content-related information.", "method": "Representation-guided speech enhancement integrates front-end speech enhancement models with self-supervised learning-based speech models. Two strategies are examined: zero-padding and speed perturbations with a soft-DTW loss.", "result": "Experiments demonstrate that the soft-DTW-based approach reaches faster convergence and better downstream performance.", "conclusion": "The study underscores the importance of position-invariant fine-tuning in achieving robust performance in self-supervised learning-based speech models."}}
{"id": "2601.20881", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20881", "abs": "https://arxiv.org/abs/2601.20881", "authors": ["Matteo Rossi"], "title": "MA-LipNet: Multi-Dimensional Attention Networks for Robust Lipreading", "comment": null, "summary": "Lipreading, the technology of decoding spoken content from silent videos of lip movements, holds significant application value in fields such as public security. However, due to the subtle nature of articulatory gestures, existing lipreading methods often suffer from limited feature discriminability and poor generalization capabilities. To address these challenges, this paper delves into the purification of visual features from temporal, spatial, and channel dimensions. We propose a novel method named Multi-Attention Lipreading Network(MA-LipNet). The core of MA-LipNet lies in its sequential application of three dedicated attention modules. Firstly, a \\textit{Channel Attention (CA)} module is employed to adaptively recalibrate channel-wise features, thereby mitigating interference from less informative channels. Subsequently, two spatio-temporal attention modules with distinct granularities-\\textit{Joint Spatial-Temporal Attention (JSTA)} and \\textit{Separate Spatial-Temporal Attention (SSTA)}-are leveraged to suppress the influence of irrelevant pixels and video frames. The JSTA module performs a coarse-grained filtering by computing a unified weight map across the spatio-temporal dimensions, while the SSTA module conducts a more fine-grained refinement by separately modeling temporal and spatial attentions. Extensive experiments conducted on the CMLR and GRID datasets demonstrate that MA-LipNet significantly reduces the Character Error Rate (CER) and Word Error Rate (WER), validating its effectiveness and superiority over several state-of-the-art methods. Our work highlights the importance of multi-dimensional feature refinement for robust visual speech recognition.", "AI": {"tldr": "This paper introduces Multi-Attention Lipreading Network (MA-LipNet), which significantly enhances feature discriminability and generalization capabilities in lipreading by refining visual features across temporal, spatial, and channel dimensions using CA, JSTA, and SSTA modules.", "motivation": "The motivation behind this paper is to improve upon existing lipreading methods which have low feature discriminability and generalization capabilities due to the subtle nature of articulatory gestures.", "method": "MA-LipNet employs three attention modules: Channel Attention (CA) which refines channel-wise features, Joint Spatial-Temporal Attention (JSTA) which does a coarse-grained filtering, and Separate Spatial-Temporal Attention (SSTA) for more refined and separate modeling of temporal and spatial attentions.", "result": "Experiments on CMLR and GRID datasets show that MA-LipNet reduces CER and WER compared to several state-of-the-art methods, proving its effectiveness.", "conclusion": "This paper concludes that multi-dimensional feature refinement in lipreading, as executed by MA-LipNet, improves the technology's application in visual speech recognition."}}
{"id": "2601.21109", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.21109", "abs": "https://arxiv.org/abs/2601.21109", "authors": ["Ketan Thakkar", "Maitreyi Chatterjee", "Ramasubramanian Balasubramanian", "Achyuthan Jootoo", "Rajendra Ugrani"], "title": "ChunkWise LoRA: Adaptive Sequence Partitioning for Memory-Efficient Low-Rank Adaptation and Accelerated LLM Inference", "comment": "Presented at 13th IEEE International Conference on Intelligent Systems and Embedded Design", "summary": "Recent advances in low-rank adaptation (LoRA) have enabled efficient fine-tuning of large language models (LLMs) with minimal additional parameters. However, existing LoRA methods apply static rank configurations uniformly across all input tokens, ignoring variation in token complexity and computational requirements. In this work, we propose ChunkWise LoRA, a dynamic and adaptive approach that partitions sequences into variable-length chunks based on token complexity and assigns each chunk a tailored low-rank configuration. Our system introduces a runtime scheduler that estimates token difficulty, performs adaptive chunking, and selects per-chunk LoRA rank and scaling using a rank-ladder mechanism. To preserve output consistency, we further introduce a boundary-safe composition module and integrate policy-driven KV-cache strategies. Experiments on benchmark datasets such as Wikitext-103 and SQuAD demonstrate that ChunkWise LoRA achieves up to 34\\% lower latency and 38% memory reduction compared to baseline LoRA, while maintaining or improving task performance metrics like BLEU, EM, and perplexity. The proposed framework remains fully compatible with existing transformer architectures and inference frameworks, providing a practical solution for real-world deployment of parameter-efficient LLMs.", "AI": {"tldr": "本文提出了一种自适应的低秩适配方法——ChunkWise LoRA，有效降低了大型语言模型的适配时延和内存消耗，同时保持了高性能。", "motivation": "当前的低秩适配方法对所有输入token应用静态秩配置，忽略了token的复杂性和计算需求的变化。这限制了适配方法的效率与适应性。", "method": "提出了ChunkWise LoRA，一种基于token复杂度分割序列并为每个片段分配定制低秩配置的动态自适应方法。该方法包括一个在运行时估计token难度、执行自适应分块并使用秩阶梯机制选择每块的LoRA秩和缩放的调度程序，以及边界安全组合模块和策略驱动的KV缓存策略。", "result": "实验表明，与基线LoRA相比，ChunkWise LoRA可以降低最多34%的延迟和38%的内存消耗，同时保持或提高了任务性能指标，如BLEU、EM和困惑度。", "conclusion": "ChunkWise LoRA为参数高效的LLMs提供了实际的部署方案，证明了该方法在性能和效率上的优势，并且能够与现有的Transformer架构和推理框架完全兼容。"}}
{"id": "2601.20911", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.20911", "abs": "https://arxiv.org/abs/2601.20911", "authors": ["Haochen Zhang", "Animesh Sinha", "Felix Juefei-Xu", "Haoyu Ma", "Kunpeng Li", "Zhipeng Fan", "Meng Dong", "Xiaoliang Dai", "Tingbo Hou", "Peizhao Zhang", "Zecheng He"], "title": "Non-Markov Multi-Round Conversational Image Generation with History-Conditioned MLLMs", "comment": "19 pages, 19 figures, plan for TIP", "summary": "Conversational image generation requires a model to follow user instructions across multiple rounds of interaction, grounded in interleaved text and images that accumulate as chat history. While recent multimodal large language models (MLLMs) can generate and edit images, most existing multi-turn benchmarks and training recipes are effectively Markov: the next output depends primarily on the most recent image, enabling shortcut solutions that ignore long-range history. In this work we formalize and target the more challenging non-Markov setting, where a user may refer back to earlier states, undo changes, or reference entities introduced several rounds ago. We present (i) non-Markov multi-round data construction strategies, including rollback-style editing that forces retrieval of earlier visual states and name-based multi-round personalization that binds names to appearances across rounds; (ii) a history-conditioned training and inference framework with token-level caching to prevent multi-round identity drift; and (iii) enabling improvements for high-fidelity image reconstruction and editable personalization, including a reconstruction-based DiT detokenizer and a multi-stage fine-tuning curriculum. We demonstrate that explicitly training for non-Markov interactions yields substantial improvements in multi-round consistency and instruction compliance, while maintaining strong single-round editing and personalization.", "AI": {"tldr": "研究提出了一种非马尔可夫式的多轮对话图像生成方法，改进了图像局部编辑和跨轮次一致性表现。", "motivation": "现有的多轮次基准测试和训练方案大多数是马尔可夫式的，这种方案往往促使模型依赖于最近的输入，导致忽略了长距离的历史信息。在这项工作中，我们正式定义并针对更加具有挑战性的非马尔可夫场景。", "method": "我们提出了非马尔可夫多轮数据构建策略，包括回滚式编辑和基于名称的多轮个性化策略。同时，我们还提出了一种有历史条件的训练和推理框架，并采用标记级缓存来防止多轮身份漂移。此外，我们改进了高保真图像重构和可编辑个性化的能力，包括基于重构的DiT解令牌器及多阶段微调课程。", "result": "实验证明，专门训练针对非马尔可夫式交互显著提升了多轮次一致性和指令遵从性，同时也保持了强大的单轮次编辑和个性化性能。", "conclusion": "通过非马尔可夫式的数据构建策略、有历史条件的训练框架以及针对性的改进措施，显著提升了多轮对话生成图文的一致性和个性化。"}}
{"id": "2601.21115", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21115", "abs": "https://arxiv.org/abs/2601.21115", "authors": ["Mingzhi Zhu", "Boris Sobolev", "Rahul Krishna", "Raju Pavuluri", "Stacy Patterson", "Michele Merler"], "title": "Multi-task Code LLMs: Data Mix or Model Merge?", "comment": null, "summary": "Recent research advocates deploying smaller, specialized code LLMs in agentic frameworks alongside frontier models, sparking interest in efficient strategies for multi-task learning that balance performance, constraints, and costs. We compare two approaches for creating small, multi-task code LLMs: data mixing versus model merging. We conduct extensive experiments across two model families (Qwen Coder and DeepSeek Coder) at two scales (2B and 7B parameters), fine-tuning them for code generation and code summarization tasks. Our evaluation on HumanEval, MBPP, and CodeXGlue benchmarks reveals that model merging achieves the best overall performance at larger scale across model families, retaining 96% of specialized model performance on code generation tasks while maintaining summarization capabilities. Notably, merged models can even surpass individually fine-tuned models, with our best configuration of Qwen Coder 2.5 7B model achieving 92.7% Pass@1 on HumanEval compared to 90.9% for its task-specific fine-tuned equivalent. At a smaller scale we find instead data mixing to be a preferred strategy. We further introduce a weight analysis technique to understand how different tasks affect model parameters and their implications for merging strategies. The results suggest that careful merging and mixing strategies can effectively combine task-specific capabilities without significant performance degradation, making them ideal for resource-constrained deployment scenarios.", "AI": {"tldr": "本文通过两种方法（数据混合和模型合并）比较了创建小型多任务代码LLM的效果，研究发现模型合并方法在更大规模时表现更佳，而在小规模时数据混合是更优选择。", "motivation": "研究旨在探讨在代理框架中部署更小、更专业的代码LLM的有效策略，以平衡性能、约束和成本之间的关系。", "method": "本文比较了两种创建小型多任务代码LLM的方法：数据混合和模型合并。通过在两种模型家族（Qwen Coder 和 DeepSeek Coder）以两个规模（2B 和 7B 参数）进行实验，对代码生成和代码总结任务进行了细调。", "result": "评估结果显示，在更大规模和模型家族之间，模型合并达到了最佳的整体性能，保留了专注于代码生成任务的96%性能，同时保持了总结能力。数据混合方法在较小规模时更为优选。", "conclusion": "结果表明，通过精心合并和混合策略可以有效地结合任务特定的能力，不会显著降低性能，这使它们成为资源受限部署场景的理想选择。"}}
{"id": "2601.20990", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20990", "abs": "https://arxiv.org/abs/2601.20990", "authors": ["Xuehua Ye", "Hongxu Yang", "Adam J. Schwarz"], "title": "Text controllable PET denoising", "comment": "SPIE Medical Imaging 2026", "summary": "Positron Emission Tomography (PET) imaging is a vital tool in medical diagnostics, offering detailed insights into molecular processes within the human body. However, PET images often suffer from complicated noise, which can obscure critical diagnostic information. The quality of the PET image is impacted by various factors including scanner hardware, image reconstruction, tracer properties, dose/count level, and acquisition time. In this study, we propose a novel text-guided denoising method capable of enhancing PET images across a wide range of count levels within a single model. The model utilized the features from a pretrained CLIP model with a U-Net based denoising model. Experimental results demonstrate that the proposed model leads significant improvements in both qualitative and quantitative assessments. The flexibility of the model shows the potential for helping more complicated denoising demands or reducing the acquisition time.", "AI": {"tldr": "研究提出了一种基于文本引导的PET图像去噪方法，利用CLIP模型和U-Net，实验结果表明其可显著提高PET图像质量。", "motivation": "由于PET图像常因复杂的噪声而掩盖关键的诊断信息，影响了PET图像的质量。", "method": "本研究提出了一种新颖的文本引导去噪方法，该方法能够在一个单一模型中提高各种计数水平下的PET图像质量。该模型利用了预训练的CLIP模型的特征和基于U-Net的去噪模型。", "result": "实验结果表明，所提出模型在定性和定量评估中都有显著提升。", "conclusion": "该模型的灵活性显示出对于更复杂的去噪需求或减少采集时间的潜力。"}}
{"id": "2601.21132", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.21132", "abs": "https://arxiv.org/abs/2601.21132", "authors": ["Noah Dasanaike"], "title": "Large Language Models Naively Recover Ethnicity from Individual Records", "comment": null, "summary": "I demonstrate that large language models can infer ethnicity from names with accuracy exceeding that of Bayesian Improved Surname Geocoding (BISG) without additional training data, enabling inference outside the United States and to contextually appropriate classification categories. Using stratified samples from Florida and North Carolina voter files with self-reported race, LLM-based classification achieves up to 84.7% accuracy, outperforming BISG (68.2%) on balanced samples. I test six models including Gemini 3 Flash, GPT-4o, and open-source alternatives such as DeepSeek v3.2 and GLM-4.7. Enabling extended reasoning can improve accuracy by 1-3 percentage points, though effects vary across contexts; including metadata such as party registration reaches 86.7%. LLM classification also reduces the income bias inherent in BISG, where minorities in wealthier neighborhoods are systematically misclassified as White. I further validate using Lebanese voter registration with religious sect (64.3% accuracy), Indian MPs from reserved constituencies (99.2%), and Indian land records with caste classification (74.0%). Aggregate validation across India, Uganda, Nepal, Armenia, Chile, and Costa Rica using original full-count voter rolls demonstrates that the method recovers known population distributions where naming conventions are distinctive. For large-scale applications, small transformer models fine-tuned on LLM labels exceed BISG accuracy while enabling local deployment at no cost.", "AI": {"tldr": "研究使用LLM从名字推断种族，显示其在多个数据库和国家的应用有效性，大大提高了推断的准确性和适用性，并展示了其额外的应用和优点。", "motivation": "探索是否可以在没有附加训练数据的情况下，使用大型语言模型推断 ethnicity，并对比其准确性和效率。", "method": "通过使用来自佛罗里达和北卡罗来纳州选民文件中的分层样本以及自报告种族的开源模型，如DeepSeek v3.2和GLM-4.7，和专有模型，如Gemini 3 Flash和GPT-4o，展示了大型语言模型在没有额外训练数据的情况下，可以从名字推断种族。同时研究了元数据如党派注册对准确性的提升效果。", "result": "在平衡样本上，LLM分类实现了高达84.7%的准确率，超越了BISG的68.2%准确率。包含元数据可以提高准确性到86.7%。此外，在印度、乌干达、尼泊尔、亚美尼亚、智利和哥斯达黎加的选民名册上验证了该方法的有效性。", "conclusion": "大型语言模型能够在无需额外训练数据的情况下，从名字推断种族，其准确性超过BISG，并且可以减轻BISG中存在的收入偏差问题。这种方法还能在命名约定具有特征的国家和地区恢复已知的人口分布。"}}
{"id": "2601.20995", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.20995", "abs": "https://arxiv.org/abs/2601.20995", "authors": ["Hongxu Yang", "Levente Lippenszky", "Edina Timko", "Lehel Ferenczi", "Gopal Avinash"], "title": "Low performing pixel correction in computed tomography with unrolled network and synthetic data training", "comment": "ISBI 2026 accepted", "summary": "Low performance pixels (LPP) in Computed Tomography (CT) detectors would lead to ring and streak artifacts in the reconstructed images, making them clinically unusable. In recent years, several solutions have been proposed to correct LPP artifacts, either in the image domain or in the sinogram domain using supervised deep learning methods. However, these methods require dedicated datasets for training, which are expensive to collect. Moreover, existing approaches focus solely either on image-space or sinogram-space correction, ignoring the intrinsic correlations from the forward operation of the CT geometry. In this work, we propose an unrolled dual-domain method based on synthetic data to correct LPP artifacts. Specifically, the intrinsic correlations of LPP between the sinogram and image domains are leveraged through synthetic data generated from natural images, enabling the trained model to correct artifacts without requiring any real-world clinical data. In experiments simulating 1-2% detectors defect near the isocenter, the proposed method outperformed the state-of-the-art approaches by a large margin. The results indicate that our solution can correct LPP artifacts without the cost of data collection for model training, and it is adaptable to different scanner settings for software-based applications.", "AI": {"tldr": "研究提出了一种新的方法，使用合成数据来纠正CT中的低性能像素伪影，无需真实数据集，且性能优于现有方法。", "motivation": "已有的纠正LPP伪影的方法要么需要专用的数据集进行训练，成本昂贵，要么只关注图像域或投影域的修正，忽略了CT几何前向操作的内在相关性。", "method": "提出了一种基于合成数据的图像域和投影域双重领域展开方法来纠正CT成像中的低性能像素(LPP)引起的环状和条纹伪影。此方法利用从自然图像生成的合成数据来训练模型，从而无需任何真实世界的临床数据来进行伪影纠正。", "result": "实验模拟了大约1-2%的中心区域探测器缺陷的情况下，提出的方法比现有最先进的方法表现更优。", "conclusion": "该解决方案可以无需收集训练模型的数据成本来纠正LPP伪影，并且适应不同的扫描仪设置，适用于软件应用。"}}
{"id": "2601.21138", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.21138", "abs": "https://arxiv.org/abs/2601.21138", "authors": ["Noah Dasanaike"], "title": "EnsembleLink: Accurate Record Linkage Without Training Data", "comment": null, "summary": "Record linkage, the process of matching records that refer to the same entity across datasets, is essential to empirical social science but remains methodologically underdeveloped. Researchers treat it as a preprocessing step, applying ad hoc rules without quantifying the uncertainty that linkage errors introduce into downstream analyses. Existing methods either achieve low accuracy or require substantial labeled training data. I present EnsembleLink, a method that achieves high accuracy without any training labels. EnsembleLink leverages pre-trained language models that have learned semantic relationships (e.g., that \"South Ozone Park\" is a neighborhood in \"New York City\" or that \"Lutte ouvriere\" refers to the Trotskyist \"Workers' Struggle\" party) from large text corpora. On benchmarks spanning city names, person names, organizations, multilingual political parties, and bibliographic records, EnsembleLink matches or exceeds methods requiring extensive labeling. The method runs locally on open-source models, requiring no external API calls, and completes typical linkage tasks in minutes.", "AI": {"tldr": "EnsembleLink is a novel record linkage method that achieves high accuracy by using pre-trained language models without the need for training labels, making it faster and more precise than existing methods that require extensive labeling.", "motivation": "To address the limitations of current record linkage methods, which either have low accuracy or need significant amounts of labeled data, by developing a more accurate and efficient solution.", "method": "Structure", "result": "EnsembleLink performs as well as or better than methods that require extensive labeling across various benchmarks, completing linkage tasks in minutes.", "conclusion": "EnsembleLink offers an innovative approach to record linkage, providing high accuracy and efficiency without the need for labeled training data, which can be particularly useful in social science research where data linkage is crucial but often methodologically challenging."}}
{"id": "2601.21022", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.21022", "abs": "https://arxiv.org/abs/2601.21022", "authors": ["Andrea Camilloni", "Chiara Micoli", "Nita Mulliqi", "Erik Everett Palm", "Thorgerdur Palsdottir", "Kelvin Szolnoky", "Xiaoyi Ji", "Sol Erika Boman", "Andrea Discacciati", "Henrik Grönberg", "Lars Egevad", "Tobias Nordström", "Kimmo Kartasalo", "Martin Eklund"], "title": "AI-based Prediction of Biochemical Recurrence from Biopsy and Prostatectomy Samples", "comment": "39 pages, 6 tables, 11 figures", "summary": "Biochemical recurrence (BCR) after radical prostatectomy (RP) is a surrogate marker for aggressive prostate cancer with adverse outcomes, yet current prognostic tools remain imprecise. We trained an AI-based model on diagnostic prostate biopsy slides from the STHLM3 cohort (n = 676) to predict patient-specific risk of BCR, using foundation models and attention-based multiple instance learning. Generalizability was assessed across three external RP cohorts: LEOPARD (n = 508), CHIMERA (n = 95), and TCGA-PRAD (n = 379). The image-based approach achieved 5-year time-dependent AUCs of 0.64, 0.70, and 0.70, respectively. Integrating clinical variables added complementary prognostic value and enabled statistically significant risk stratification. Compared with guideline-based CAPRA-S, AI incrementally improved postoperative prognostication. These findings suggest biopsy-trained histopathology AI can generalize across specimen types to support preoperative and postoperative decision making, but the added value of AI-based multimodal approaches over simpler predictive models should be critically scrutinized in further studies.", "AI": {"tldr": "研究展示了基于AI的模型在预测前列腺癌术后生化复发风险方面的有效性及通用性，集成临床变量增强了预后价值，但AI方法的真实价值需进一步研究确认。", "motivation": "当前预测生化复发风险的工具仍不精确，该研究旨在改进对前列腺癌术后生化复发风险的预测。", "method": "使用了基于AI的模型，该模型是在STHLM3队列（n=676）的诊断性前列腺活检切片上训练的，使用基础模型和基于注意力的多实例学习来预测特定患者的生化复发（BCR）风险。", "result": "在三个外部RP队列（LEOPARD (n=508), CHIMERA (n=95), TCGA-PRAD (n=379)）上，图像方法的5年时间依赖AUC分别为0.64、0.70和0.70。集成临床变量提供了额外的预后价值，并使能够进行统计显著的风险分层。", "conclusion": "这些发现表明，通过活检训练的组织学AI可以跨样本类型进行推广，以支持术前和术后的决策，但AI的多模态方法相对于更简单的预测模型的价值应该在进一步的研究中进行严格评估。"}}
{"id": "2601.21169", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21169", "abs": "https://arxiv.org/abs/2601.21169", "authors": ["Tobias Materzok"], "title": "Output-Space Search: Targeting LLM Generations in a Frozen Encoder-Defined Output Space", "comment": null, "summary": "We introduce Output-Space Search (OS-Search), which turns LLM generation into endpoint search. An outer loop selects a target z* in a frozen encoder-defined 3D output space Z, and a retrieval-grounded policy trained with sequence-level RL generates outputs whose coordinates land near z* under standard autoregressive decoding. This enables parallel sweeps and black-box optimization in Z without path-dependent token/program search. On stories, sweeping Z (text) yields 3.1x higher LLM-scored diversity than prompt-chaining. On code, Bayesian optimization over Z (code) improves an objective withheld from the controller under matched inference budgets while preserving validity.", "AI": {"tldr": "The paper presents OS-Search, a method for LLM generation reimagined as endpoint search in a 3D output space, offering higher diversity in stories and improved performance in code generation under black-box optimization.", "motivation": "To enable more effective parallel sweeps and black-box optimization in text and code generation without the constraints of token/program search dependencies.", "method": "We introduce Output-Space Search (OS-Search), utilizing a frozen encoder-defined 3D output space Z and a retrieval-grounded policy trained with sequence-level RL to generate content by targeting coordinates in Z.", "result": "OS-Search demonstrates 3.1x increased diversity in story generation and improved code optimization performance without compromising code validity.", "conclusion": "OS-Search provides a viable and effective approach to enhance the diversity and performance of language and code generation tasks using a novel search method in an output space."}}
{"id": "2601.21066", "categories": ["cs.CV", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.21066", "abs": "https://arxiv.org/abs/2601.21066", "authors": ["Kealan Dunnett", "Reza Arablouei", "Dimity Miller", "Volkan Dedeoglu", "Raja Jurdak"], "title": "BadDet+: Robust Backdoor Attacks for Object Detection", "comment": null, "summary": "Backdoor attacks pose a severe threat to deep learning, yet their impact on object detection remains poorly understood compared to image classification. While attacks have been proposed, we identify critical weaknesses in existing detection-based methods, specifically their reliance on unrealistic assumptions and a lack of physical validation. To bridge this gap, we introduce BadDet+, a penalty-based framework that unifies Region Misclassification Attacks (RMA) and Object Disappearance Attacks (ODA). The core mechanism utilizes a log-barrier penalty to suppress true-class predictions for triggered inputs, resulting in (i) position and scale invariance, and (ii) enhanced physical robustness. On real-world benchmarks, BadDet+ achieves superior synthetic-to-physical transfer compared to existing RMA and ODA baselines while preserving clean performance. Theoretical analysis confirms the proposed penalty acts within a trigger-specific feature subspace, reliably inducing attacks without degrading standard inference. These results highlight significant vulnerabilities in object detection and the necessity for specialized defenses.", "AI": {"tldr": "BadDet+通过引入一种新的惩罚机制，增强了对象检测中的回路攻击的物理鲁棒性，并突显了该领域的脆弱性和对防御措施的需求。", "motivation": "为了填补领域内仅存在对目标检测的基于假设以及缺少物理验证的黑盒攻击方法的研究空白。", "method": "引入BadDet+，一种基于惩罚的框架，统一了区域误分类攻击(RMA)和对象消失攻击(ODA)，核心机制采用对数障碍惩罚来抑制目标类别的触发输入预测，从而实现了位置和尺度的不变性以及增强的物理鲁棒性。", "result": "在真实世界基准测试中，BadDet+实现了比现有的RMA和ODA基线更好的合成至物理传输效果，同时保持了对干净样本的良好性能。", "conclusion": "该研究揭示了目标检测中的重大漏洞，并强调需要专门的防御手段。"}}
{"id": "2601.21191", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.21191", "abs": "https://arxiv.org/abs/2601.21191", "authors": ["Xiulin Yang", "Heidi Getz", "Ethan Gotlieb Wilcox"], "title": "From Linear Input to Hierarchical Structure: Function Words as Statistical Cues for Language Learning", "comment": "Jan ARR under review", "summary": "What statistical conditions support learning hierarchical structure from linear input? In this paper, we address this question by focusing on the statistical distribution of function words. Function words have long been argued to play a crucial role in language acquisition due to their distinctive distributional properties, including high frequency, reliable association with syntactic structure, and alignment with phrase boundaries. We use cross-linguistic corpus analysis to first establish that all three properties are present across 186 studied languages. Next, we use a combination of counterfactual language modeling and ablation experiments to show that language variants preserving all three properties are more easily acquired by neural learners, with frequency and structural association contributing more strongly than boundary alignment. Follow-up probing and ablation analyses further reveal that different learning conditions lead to systematically different reliance on function words, indicating that similar performance can arise from distinct internal mechanisms.", "AI": {"tldr": "通过跨语言语料分析和实验验证功能词高频、与句法结构的关联、与短语边界的对齐特性对习得语言的层次结构的重要性，指出频率和结构性关联贡献最大，并表明不同依赖情况下的类似表现可能由不同机制产生。", "motivation": "探讨什么样的统计条件支持从线性输入中学习层次结构。功能词由于其独特的分布特性（高频、与句法结构的可靠关联、与短语边界的对齐）被认为在语言习得中扮演关键作用。", "method": "通过跨语言语料分析来验证功能词的三个特性(高频、与句法结构的可靠关联、与短语边界的对齐)在186种被研究语言中的存在。接着，通过反事实语言建模和消融实验来展示保留所有这三个特性的语言变体更容易被神经学习者习得，其中频率和结构性关联的贡献更强。进一步的探测和消融分析揭示了不同的学习条件会导致对功能词系统性的不同依赖程度，这表明类似的表现可能源自不同的内部机制。", "result": "实验结果表明所有研究的语言都存在功能词的高频、与句法结构的可靠关联和与短语边界的对齐的特性。保持这三个特性的语言变体更容易被神经学习者习得，重点是在于频率和结构性关联。", "conclusion": "不同学习条件会导致对功能词系统性不同的依赖，这表明同样水平的表现可能是由不同的内部机制产生的。"}}
