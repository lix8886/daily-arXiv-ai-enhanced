{"id": "2510.26912", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.26912", "abs": "https://arxiv.org/abs/2510.26912", "authors": ["Hyunji Lee", "Wenhao Yu", "Hongming Zhang", "Kaixin Ma", "Jiyeon Kim", "Dong Yu", "Minjoon Seo"], "title": "Understanding and Enhancing Mamba-Transformer Hybrids for Memory Recall and Language Modeling", "comment": null, "summary": "Hybrid models that combine state space models (SSMs) with attention\nmechanisms have shown strong performance by leveraging the efficiency of SSMs\nand the high recall ability of attention. However, the architectural design\nchoices behind these hybrid models remain insufficiently understood. In this\nwork, we analyze hybrid architectures through the lens of memory utilization\nand overall performance, and propose a complementary method to further enhance\ntheir effectiveness. We first examine the distinction between sequential and\nparallel integration of SSM and attention layers. Our analysis reveals several\ninteresting findings, including that sequential hybrids perform better on\nshorter contexts, whereas parallel hybrids are more effective for longer\ncontexts. We also introduce a data-centric approach of continually training on\ndatasets augmented with paraphrases, which further enhances recall while\npreserving other capabilities. It generalizes well across different base models\nand outperforms architectural modifications aimed at enhancing recall. Our\nfindings provide a deeper understanding of hybrid SSM-attention models and\noffer practical guidance for designing architectures tailored to various use\ncases. Our findings provide a deeper understanding of hybrid SSM-attention\nmodels and offer practical guidance for designing architectures tailored to\nvarious use cases.", "AI": {"tldr": "研究了SSM与注意力机制结合的混合模型，发现顺序和并行集成在不同上下文长度中的表现差异，并提出一种基于数据的方法有效提升召回率。", "motivation": "对SSM和注意力机制结合的混合模型背后的架构设计选择理解不足，该研究旨在通过内存使用和整体性能的视角来分析这种混合架构。", "method": "分析了顺序和并行集成SSM和注意力层之间的区别，并引入了一种基于数据的方法，即通过添加同义句扩充数据集进行持续训练，进一步增强召回能力。", "result": "发现顺序混合模型在较短上下文中表现更好，而并行混合模型对于较长上下文更有效。提出的基于数据的方法能够进一步提升召回率，且泛化能力强，优于旨在提升召回率的架构修改。", "conclusion": "此研究提供了对混合SSM-注意力模型的深入理解，并为设计适用于各种应用场景的架构提供了实用指导。"}}
{"id": "2510.26969", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26969", "abs": "https://arxiv.org/abs/2510.26969", "authors": ["Lívia Dutra", "Arthur Lorenzi", "Laís Berno", "Franciany Campos", "Karoline Biscardi", "Kenneth Brown", "Marcelo Viridiano", "Frederico Belcavello", "Ely Matos", "Olívia Guaranha", "Erik Santos", "Sofia Reinach", "Tiago Timponi Torrent"], "title": "Frame Semantic Patterns for Identifying Underreporting of Notifiable Events in Healthcare: The Case of Gender-Based Violence", "comment": null, "summary": "We introduce a methodology for the identification of notifiable events in the\ndomain of healthcare. The methodology harnesses semantic frames to define\nfine-grained patterns and search them in unstructured data, namely, open-text\nfields in e-medical records. We apply the methodology to the problem of\nunderreporting of gender-based violence (GBV) in e-medical records produced\nduring patients' visits to primary care units. A total of eight patterns are\ndefined and searched on a corpus of 21 million sentences in Brazilian\nPortuguese extracted from e-SUS APS. The results are manually evaluated by\nlinguists and the precision of each pattern measured. Our findings reveal that\nthe methodology effectively identifies reports of violence with a precision of\n0.726, confirming its robustness. Designed as a transparent, efficient,\nlow-carbon, and language-agnostic pipeline, the approach can be easily adapted\nto other health surveillance contexts, contributing to the broader, ethical,\nand explainable use of NLP in public health systems.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2510.26974", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26974", "abs": "https://arxiv.org/abs/2510.26974", "authors": ["Jean-Philippe Corbeil", "Asma Ben Abacha", "Jerome Tremblay", "Phillip Swazinna", "Akila Jeeson Daniel", "Miguel Del-Agua", "Francois Beaulieu"], "title": "Overview of the MEDIQA-OE 2025 Shared Task on Medical Order Extraction from Doctor-Patient Consultations", "comment": null, "summary": "Clinical documentation increasingly uses automatic speech recognition and\nsummarization, yet converting conversations into actionable medical orders for\nElectronic Health Records remains unexplored. A solution to this problem can\nsignificantly reduce the documentation burden of clinicians and directly impact\ndownstream patient care. We introduce the MEDIQA-OE 2025 shared task, the first\nchallenge on extracting medical orders from doctor-patient conversations. Six\nteams participated in the shared task and experimented with a broad range of\napproaches, and both closed- and open-weight large language models (LLMs). In\nthis paper, we describe the MEDIQA-OE task, dataset, final leaderboard ranking,\nand participants' solutions.", "AI": {"tldr": "介绍了MEDIQA-OE 2025共享任务，该任务首次尝试从医患对话中提取医疗指令，旨在通过使用大量的语言模型减轻医生的文档工作量并改进患者护理。", "motivation": "当前临床文档越来越多地采用自动语音识别和摘要技术，然而将对话转换为可用于电子健康记录的医疗指令尚待探索，解决该问题可以显著减轻临床医生的文档负担和直接改进患者的治疗。", "method": "介绍了MEDIQA-OE 2025共享任务，涉及从医患对话中提取医疗指令的挑战。任务中使用了包括大型语言模型在内的多种方法。", "result": "六支团队参与了此共享任务，实验了广泛的策略，并使用了封闭权重和开放权重的大语言模型。该任务聚焦于从医患对话中提取医疗指令，这是一个首次被探索的挑战。通过这个任务，可以显著减轻临床医生的文档负担，直接改进对患者的治疗。", "conclusion": "随着临床文档中自动语音识别和摘要的日益使用，研究尚缺乏关于将对话转换为可用于电子健康记录的医疗指令的方法。MEDIQA-OE 2025挑战赛的举行为解决这个问题提供了创新的解决方案，为减轻医生负担和改进患者治疗提供了可能。"}}
{"id": "2510.27016", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27016", "abs": "https://arxiv.org/abs/2510.27016", "authors": ["Jayden Serenari", "Stephen Lee"], "title": "Semantically-Aware LLM Agent to Enhance Privacy in Conversational AI Services", "comment": "Accepted to IEEE Big Data 2025", "summary": "With the increasing use of conversational AI systems, there is growing\nconcern over privacy leaks, especially when users share sensitive personal data\nin interactions with Large Language Models (LLMs). Conversations shared with\nthese models may contain Personally Identifiable Information (PII), which, if\nexposed, could lead to security breaches or identity theft. To address this\nchallenge, we present the Local Optimizations for Pseudonymization with\nSemantic Integrity Directed Entity Detection (LOPSIDED) framework, a\nsemantically-aware privacy agent designed to safeguard sensitive PII data when\nusing remote LLMs. Unlike prior work that often degrade response quality, our\napproach dynamically replaces sensitive PII entities in user prompts with\nsemantically consistent pseudonyms, preserving the contextual integrity of\nconversations. Once the model generates its response, the pseudonyms are\nautomatically depseudonymized, ensuring the user receives an accurate,\nprivacy-preserving output. We evaluate our approach using real-world\nconversations sourced from ShareGPT, which we further augment and annotate to\nassess whether named entities are contextually relevant to the model's\nresponse. Our results show that LOPSIDED reduces semantic utility errors by a\nfactor of 5 compared to baseline techniques, all while enhancing privacy.", "AI": {"tldr": "提出了LOPSIDED框架以保护用户在与大型语言模型交互时的个人隐私信息，实验证明该框架显著减少了语义效用错误，提升了隐私保护效果。", "motivation": "由于大型语言模型在对话中可能存在个人隐私信息泄露风险，作者提出LOPSIDED框架来保护用户隐私数据，解决隐私泄露问题。", "method": "LOPSIDED框架通过动态替换用户输入中的敏感个人隐私实体为语义一致的化名，从而保持对话的上下文完整性，同时在模型生成响应后自动去伪名化。", "result": "实验结果显示，与基线技术相比，LOPSIDED框架将语义效用错误减少了五倍，同时增强了隐私保护。", "conclusion": "LOPSIDED框架在保护用户隐私的同时，保持了对话的质量，相比于以前的方法，降低了对话中的语义效用错误。"}}
{"id": "2510.26865", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.26865", "abs": "https://arxiv.org/abs/2510.26865", "authors": ["Fenfen Lin", "Yesheng Liu", "Haiyu Xu", "Chen Yue", "Zheqi He", "Mingxuan Zhao", "Miguel Hu Chen", "Jiakang Liu", "JG Yao", "Xi Yang"], "title": "Do Vision-Language Models Measure Up? Benchmarking Visual Measurement Reading with MeasureBench", "comment": "Project page: https://flageval-baai.github.io/MeasureBenchPage/", "summary": "Reading measurement instruments is effortless for humans and requires\nrelatively little domain expertise, yet it remains surprisingly challenging for\ncurrent vision-language models (VLMs) as we find in preliminary evaluation. In\nthis work, we introduce MeasureBench, a benchmark on visual measurement reading\ncovering both real-world and synthesized images of various types of\nmeasurements, along with an extensible pipeline for data synthesis. Our\npipeline procedurally generates a specified type of gauge with controllable\nvisual appearance, enabling scalable variation in key details such as pointers,\nscales, fonts, lighting, and clutter. Evaluation on popular proprietary and\nopen-weight VLMs shows that even the strongest frontier VLMs struggle\nmeasurement reading in general. A consistent failure mode is indicator\nlocalization: models can read digits or labels but misidentify the key\npositions of pointers or alignments, leading to big numeric errors despite\nplausible textual reasoning. We have also conducted preliminary experiments\nwith reinforcement learning over synthetic data, and find encouraging results\non in-domain synthetic subset but less promising for real-world images. Our\nanalysis highlights a fundamental limitation of current VLMs in fine-grained\nspatial grounding. We hope this resource can help future advances on visually\ngrounded numeracy and precise spatial perception of VLMs, bridging the gap\nbetween recognizing numbers and measuring the world.", "AI": {"tldr": "The paper introduces MeasureBench, a benchmark for visual measurement reading, and discusses the challenges faced by vision-language models (VLMs) in accurately reading measurements due to difficulties in indicator localization.", "motivation": "The motivation is to highlight the difficulty VLMs face in reading measurements and to provide a benchmark for future research to address these challenges.", "method": "The method involves creating MeasureBench, a benchmark using both real-world and synthesized images of measurements, and a data synthesis pipeline to generate diverse images.", "result": "Results indicate that even advanced VLMs struggle with measurement reading, particularly in correctly identifying the positions of indicators.", "conclusion": "The study concludes that current VLMs exhibit a fundamental limitation in precise spatial perception, suggesting future work should focus on improving fine-grained spatial grounding for VLMs."}}
{"id": "2510.27017", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2510.27017", "abs": "https://arxiv.org/abs/2510.27017", "authors": ["Ayoub Hammal", "Pierre Zweigenbaum", "Caio Corro"], "title": "Kad: A Framework for Proxy-based Test-time Alignment with Knapsack Approximation Deferral", "comment": null, "summary": "Several previous works concluded that the largest part of generation\ncapabilities of large language models (LLM) are learned (early) during\npre-training. However, LLMs still require further alignment to adhere to\ndownstream task requirements and stylistic preferences, among other desired\nproperties. As LLMs continue to scale in terms of size, the computational cost\nof alignment procedures increase prohibitively. In this work, we propose a\nnovel approach to circumvent these costs via proxy-based test-time alignment,\ni.e. using guidance from a small aligned model. Our approach can be described\nas token-specific cascading method, where the token-specific deferral rule is\nreduced to 0-1 knapsack problem. In this setting, we derive primal and dual\napproximations of the optimal deferral decision. We experimentally show the\nbenefits of our method both in task performance and speculative decoding speed.", "AI": {"tldr": "The paper proposes a proxy-based test-time alignment approach using a small aligned model, described by a token-specific cascading method to address the high computational costs of aligning large language models.", "motivation": "to reduce the computational cost associated with aligning large language models as they scale in size, while ensuring they can still meet downstream task requirements and other desired properties.", "method": "token-specific cascading method, involving a 0-1 knapsack problem for the deferral decision in using a guidance from a smaller, aligned model during the test time to align large language models.", "result": "the proposed method shows benefits in both task performance and speculative decoding speed through experimental validation.", "conclusion": "the approach effectively mitigates the computational burden while enhancing performance and speed."}}
{"id": "2510.26903", "categories": ["cs.CV", "physics.med-ph"], "pdf": "https://arxiv.org/pdf/2510.26903", "abs": "https://arxiv.org/abs/2510.26903", "authors": ["Rochak Dhakal", "Chen Zhao", "Zixin Shi", "Joyce H. Keyak", "Tadashi S. Kaneko", "Kuan-Jui Su", "Hui Shen", "Hong-Wen Deng", "Weihua Zhou"], "title": "PF-DAformer: Proximal Femur Segmentation via Domain Adaptive Transformer for Dual-Center QCT", "comment": "22 Pages, 5 Tables, 10 Figures. The combination of GRL and MMD\n  achieved the most balanced performance, reducing contour deviations and\n  enhancing surface smoothness", "summary": "Quantitative computed tomography (QCT) plays a crucial role in assessing bone\nstrength and fracture risk by enabling volumetric analysis of bone density\ndistribution in the proximal femur. However, deploying automated segmentation\nmodels in practice remains difficult because deep networks trained on one\ndataset often fail when applied to another. This failure stems from domain\nshift, where scanners, reconstruction settings, and patient demographics vary\nacross institutions, leading to unstable predictions and unreliable\nquantitative metrics. Overcoming this barrier is essential for multi-center\nosteoporosis research and for ensuring that radiomics and structural finite\nelement analysis results remain reproducible across sites. In this work, we\ndeveloped a domain-adaptive transformer segmentation framework tailored for\nmulti-institutional QCT. Our model is trained and validated on one of the\nlargest hip fracture related research cohorts to date, comprising 1,024 QCT\nimages scans from Tulane University and 384 scans from Rochester, Minnesota for\nproximal femur segmentation. To address domain shift, we integrate two\ncomplementary strategies within a 3D TransUNet backbone: adversarial alignment\nvia Gradient Reversal Layer (GRL), which discourages the network from encoding\nsite-specific cues, and statistical alignment via Maximum Mean Discrepancy\n(MMD), which explicitly reduces distributional mismatches between institutions.\nThis dual mechanism balances invariance and fine-grained alignment, enabling\nscanner-agnostic feature learning while preserving anatomical detail.", "AI": {"tldr": "研究提出了一种针对多机构QCT图像分割的领域自适应变换框架，提高分割结果的稳定性和跨站点的可靠性。", "motivation": "克服深网在不同数据集上训练后跨应用效果下降的问题，提高多中心骨质疏松研究中放射组学和结构有限元分析结果的可重复性。", "method": "本文提出了一个基于3D TransUNet骨干网络的领域自适应变换分割框架，用于处理多机构QCT图像中的领域偏移问题。框架集成了两种互补策略：通过梯度反转层（GRL）实现对抗性对齐，以及通过最大均值差异（MMD）实现统计对齐。", "result": "为处理因不同机构的扫描设备、重建设置和患者人口统计学差异导致的领域偏移问题提供了一个解决方案，并在一个包含1,024个QCT图像扫描和384个扫描的研究队列上进行了训练和验证。", "conclusion": "该方法在多机构QCT分割任务上提高了跨站点的稳定性与定量指标的可靠性，有助于实现不依赖于扫描仪的特征学习同时保持解剖细节。"}}
{"id": "2510.27037", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2510.27037", "abs": "https://arxiv.org/abs/2510.27037", "authors": ["Shang Wang"], "title": "Elastic Architecture Search for Efficient Language Models", "comment": "ICME 2025", "summary": "As large pre-trained language models become increasingly critical to natural\nlanguage understanding (NLU) tasks, their substantial computational and memory\nrequirements have raised significant economic and environmental concerns.\nAddressing these challenges, this paper introduces the Elastic Language Model\n(ELM), a novel neural architecture search (NAS) method optimized for compact\nlanguage models. ELM extends existing NAS approaches by introducing a flexible\nsearch space with efficient transformer blocks and dynamic modules for\ndimension and head number adjustment. These innovations enhance the efficiency\nand flexibility of the search process, which facilitates more thorough and\neffective exploration of model architectures. We also introduce novel knowledge\ndistillation losses that preserve the unique characteristics of each block, in\norder to improve the discrimination between architectural choices during the\nsearch process. Experiments on masked language modeling and causal language\nmodeling tasks demonstrate that models discovered by ELM significantly\noutperform existing methods.", "AI": {"tldr": "本文提出了Elastic Language Model (ELM)，一种优化小型语言模型的NAS方法，通过灵活的搜索空间和新颖的知识蒸馏损失提升性能。实验表明其优于现有方法。", "motivation": "面对大型预训练语言模型在计算和内存方面的巨大需求导致的经济和环境担忧，本研究旨在通过提出ELM来减少这些模型的资源消耗。", "method": "该论文介绍了一种称为Elastic Language Model (ELM)的新神经架构搜索（NAS）方法，用于优化小型语言模型。ELM将现有的NAS方法扩展为一个灵活的搜索空间，其中包含高效的Transformer模块以及用于调整维度和头数的动态模块。此外，ELM引入了一种新型的知识蒸馏损失，以保留每个模块的独特性并提高架构搜索过程中的辨别能力。", "result": "实验结果表明，通过ELM搜索到的语言模型在掩码语言建模和因果语言建模任务上显著优于现有方法。", "conclusion": "ELM的新颖架构搜索方法和知识蒸馏技术能够有效提升小规模语言模型的性能，而这些改进得益于模型架构探索过程中的效率和灵活性增强。"}}
{"id": "2510.26921", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2510.26921", "abs": "https://arxiv.org/abs/2510.26921", "authors": ["Moonsoo Jeong", "Dongbeen Kim", "Minseong Kim", "Sungkil Lee"], "title": "DC4GS: Directional Consistency-Driven Adaptive Density Control for 3D Gaussian Splatting", "comment": "Accepted to NeurIPS 2025 / Project page:\n  https://github.com/cgskku/dc4gs", "summary": "We present a Directional Consistency (DC)-driven Adaptive Density Control\n(ADC) for 3D Gaussian Splatting (DC4GS). Whereas the conventional ADC bases its\nprimitive splitting on the magnitudes of positional gradients, we further\nincorporate the DC of the gradients into ADC, and realize it through the\nangular coherence of the gradients. Our DC better captures local structural\ncomplexities in ADC, avoiding redundant splitting. When splitting is required,\nwe again utilize the DC to define optimal split positions so that\nsub-primitives best align with the local structures than the conventional\nrandom placement. As a consequence, our DC4GS greatly reduces the number of\nprimitives (up to 30% in our experiments) than the existing ADC, and also\nenhances reconstruction fidelity greatly.", "AI": {"tldr": "该研究提出了方向一致性（DC）驱动的自适应密度控制（ADC），用于优化3D高斯图像合成。相比现有的ADC方法，DC4GS减少了高达30%的原始物体数量并增强了重建精度。", "motivation": "传统的自适应密度控制（ADC）方法在处理复杂的3D结构时可能引起不必要的高斯图像元素（或'原始物'）分裂，导致计算成本上升和视觉上的次优结果。", "method": "该论文提出了方向一致性（DC）驱动的自适应密度控制（ADC），用于改进3D高斯图像合成（DC4GS）。它在传统的基于位置梯度幅度的ADC基础上，进一步融入了梯度的方向一致性，通过梯度的方向相关性来实现。这样可以更准确地捕捉局部结构的复杂性，避免不必要的分割。当需要分割时，方法利用方向一致性来定义最优的分割位置，使子原始物结构能够最优地顺应局部结构，而不是随机放置。", "result": "该方法能够在减少合成结构的原始物数量的同时，提高了重建的保真度。实验显示，相比较于现有的ADC方法，新方法能够将使用到的原始物数量减少多达30%。", "conclusion": "提出的方向一致性驱动的自适应密度控制方法不仅大幅减少了所需的3D高斯图像合成中的原始物体数量，而且也显著提高了重建模型的保真度。这项研究表明，梯度的方向一致性可用于提高3D图形单元分割中的结构一致性。"}}
{"id": "2510.27038", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.27038", "abs": "https://arxiv.org/abs/2510.27038", "authors": ["Fatima Adam Muhammad", "Shamsuddeen Muhammad Hassan", "Isa Inuwa-Dutse"], "title": "Dataset Creation and Baseline Models for Sexism Detection in Hausa", "comment": "9 pages, 1 figure, 4 tables", "summary": "Sexism reinforces gender inequality and social exclusion by perpetuating\nstereotypes, bias, and discriminatory norms. Noting how online platforms enable\nvarious forms of sexism to thrive, there is a growing need for effective sexism\ndetection and mitigation strategies. While computational approaches to sexism\ndetection are widespread in high-resource languages, progress remains limited\nin low-resource languages where limited linguistic resources and cultural\ndifferences affect how sexism is expressed and perceived. This study introduces\nthe first Hausa sexism detection dataset, developed through community\nengagement, qualitative coding, and data augmentation. For cultural nuances and\nlinguistic representation, we conducted a two-stage user study (n=66) involving\nnative speakers to explore how sexism is defined and articulated in everyday\ndiscourse. We further experiment with both traditional machine learning\nclassifiers and pre-trained multilingual language models and evaluating the\neffectiveness few-shot learning in detecting sexism in Hausa. Our findings\nhighlight challenges in capturing cultural nuance, particularly with\nclarification-seeking and idiomatic expressions, and reveal a tendency for many\nfalse positives in such cases.", "AI": {"tldr": "本研究针对豪萨语，开发首个性别歧视检测数据集，并通过用户研究及传统机器学习和预训练语言模型方法评估性别歧视检测的有效性，揭示了文化细微差别方面的挑战。", "motivation": "考虑到在线平台促进性别歧视的多种形式，迫切需要有效的性别歧视检测和缓解策略。虽然计算方法在资源丰富的语言中广泛应用于性别歧视检测，但在资源贫乏的语言中进展仍然有限。这些语言由于语言资源有限和文化差异，性别歧视的表现和感知方式受到影响。", "method": "本研究引入了首个豪萨语性别歧视检测数据集，该数据集通过社区参与、定性编码和数据增强开发。为了捕捉文化细微差别和语言代表性，进行了两阶段用户研究（n=66），包括母语者的参与，以探讨豪萨语中性别歧视的定义及在日常对话中的表达方式。此外，研究了传统机器学习分类器和预训练的多语言语言模型，并评估了小样本学习在豪萨语性别歧视检测中的有效性。", "result": "研究发现挑战在于捕捉文化细微差别，尤其是寻求澄清和惯用表达时，且在这类情况下存在许多假阳性。", "conclusion": "本研究强调豪萨语中性别歧视检测的复杂性，尤其是文化细节和惯用语的表现，表明在资源有限的语言中，如何有效和准确地检测性别歧视仍然是一个挑战。"}}
