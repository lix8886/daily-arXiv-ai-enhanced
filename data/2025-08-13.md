<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Evaluation of State-of-the-Art Deep Learning Techniques for Plant Disease and Pest Detection](https://arxiv.org/abs/2508.08317)
*Saptarshi Banerjee,Tausif Mallick,Amlan Chakroborty,Himadri Nath Saha,Nityananda T. Takur*

Main category: cs.CV

> 研究了基于计算机的植物病害和害虫图像检测技术，现代AI方法如视觉变压器（HvT）在准确性和速度上优于传统方法。

<details>
  <summary>Details</summary>

**Motivation:** 提高作物产量并防止经济损失，通过人工识别的限制优化植物病害和害虫识别方法。

**Method:** 结构化分析方法，包括五大类：高光谱成像、非可视化技术、可视化方法、修改后的深度学习架构和变压器模型。

**Result:** 现代AI技术如视觉变压器（HvT）的准确率超过99.3%，展示出了超高的检测精度。

**Conclusion:** 讨论了系统设计挑战，并提出了解决方案和未来研究方向。

**Abstract:** Addressing plant diseases and pests is critical for enhancing crop production
and preventing economic losses. Recent advances in artificial intelligence
(AI), machine learning (ML), and deep learning (DL) have significantly improved
the precision and efficiency of detection methods, surpassing the limitations
of manual identification. This study reviews modern computer-based techniques
for detecting plant diseases and pests from images, including recent AI
developments. The methodologies are organized into five categories:
hyperspectral imaging, non-visualization techniques, visualization approaches,
modified deep learning architectures, and transformer models. This structured
taxonomy provides researchers with detailed, actionable insights for selecting
advanced state-of-the-art detection methods. A comprehensive survey of recent
work and comparative studies demonstrates the consistent superiority of modern
AI-based approaches, which often outperform older image analysis methods in
speed and accuracy. In particular, vision transformers such as the Hierarchical
Vision Transformer (HvT) have shown accuracy exceeding 99.3% in plant disease
detection, outperforming architectures like MobileNetV3. The study concludes by
discussing system design challenges, proposing solutions, and outlining
promising directions for future research.

</details>


### [2] [ImageDDI: Image-enhanced Molecular Motif Sequence Representation for Drug-Drug Interaction Prediction](https://arxiv.org/abs/2508.08338)
*Yuqin He,Tengfei Ma,Chaoyi Li,Pengsen Ma,Hongxin Xiang,Jianmin Wang,Yiping Liu,Bosheng Song,Xiangxiang Zeng*

Main category: cs.CV

> 本文提出了一个增强型分子基序序列表示框架ImageDDI，用于准确预测药物-药物相互作用，通过结合局部结构和全局分子图像信息来增强模型性能，实验结果表明，ImageDDI优于当前最先进的方法。

<details>
  <summary>Details</summary>

**Motivation:** 现有的药物相互作用预测方法受限于基于功能基序的表征学习，本文希望通过整合局部和全局图象信息来增强模型的表征能力，以提高预测准确性。

**Method:** 本文提出的方法ImageDDI通过药物分子的功能基序进行标记，结合局部与全局的分子图象信息，采用基于Transformer的编码器进行嵌入，并利用自适应特征融合方法将分子视觉信息与功能基序序列整合。

**Result:** 实验结果表明，ImageDDI在广泛接受的数据集上超越了现有的先进方法，在2D和3D图像增强场景中均表现出较强的竞争性能。

**Conclusion:** ImageDDI通过结合功能基序与分子的图象信息，提出了一个有效的药物药物相互作用预测框架，并展示了其在性能上的优势。

**Abstract:** To mitigate the potential adverse health effects of simultaneous multi-drug
use, including unexpected side effects and interactions, accurately identifying
and predicting drug-drug interactions (DDIs) is considered a crucial task in
the field of deep learning. Although existing methods have demonstrated
promising performance, they suffer from the bottleneck of limited functional
motif-based representation learning, as DDIs are fundamentally caused by motif
interactions rather than the overall drug structures. In this paper, we propose
an Image-enhanced molecular motif sequence representation framework for
\textbf{DDI} prediction, called ImageDDI, which represents a pair of drugs from
both global and local structures. Specifically, ImageDDI tokenizes molecules
into functional motifs. To effectively represent a drug pair, their motifs are
combined into a single sequence and embedded using a transformer-based encoder,
starting from the local structure representation. By leveraging the
associations between drug pairs, ImageDDI further enhances the spatial
representation of molecules using global molecular image information (e.g.
texture, shadow, color, and planar spatial relationships). To integrate
molecular visual information into functional motif sequence, ImageDDI employs
Adaptive Feature Fusion, enhancing the generalization of ImageDDI by
dynamically adapting the fusion process of feature representations.
Experimental results on widely used datasets demonstrate that ImageDDI
outperforms state-of-the-art methods. Moreover, extensive experiments show that
ImageDDI achieved competitive performance in both 2D and 3D image-enhanced
scenarios compared to other models.

</details>


### [3] [Designing Object Detection Models for TinyML: Foundations, Comparative Analysis, Challenges, and Emerging Solutions](https://arxiv.org/abs/2508.08352)
*Christophe EL Zeinaty,Wassim Hamidouche,Glenn Herrou,Daniel Menard*

Main category: cs.CV

> 本文着眼于优化TinyML环境下资源受限设备上目标检测模型的技术，比较了各方法的性能，并提供了公共库以追踪此领域的持续发展。

<details>
  <summary>Details</summary>

**Motivation:** 鉴于部署深度学习目标检测模型到资源受限的IoT设备上的重大挑战，以及此类设备数量的快速增长，研究优化技术变得尤为重要。

**Method:** 分析物联网设备在运行基于深度学习的目标检测模型时面临的计算负载挑战，探讨通过量化、剪枝、知识蒸馏和神经架构搜索等关键技术优化目标检测模型的方法。

**Result:** 该调查论文详细分析了在资源受限的设备上部署目标检测模型的关键优化技术，并通过性能指标（KPIs）比较现有的目标检测实现方法。

**Conclusion:** 论文填补了TinyML环境下目标检测模型部署优化挑战的分析空白，为学术研究与实际边缘人工智能部署架起了桥梁。

**Abstract:** Object detection (OD) has become vital for numerous computer vision
applications, but deploying it on resource-constrained IoT devices presents a
significant challenge. These devices, often powered by energy-efficient
microcontrollers, struggle to handle the computational load of deep
learning-based OD models. This issue is compounded by the rapid proliferation
of IoT devices, predicted to surpass 150 billion by 2030. TinyML offers a
compelling solution by enabling OD on ultra-low-power devices, paving the way
for efficient and real-time processing at the edge. Although numerous survey
papers have been published on this topic, they often overlook the optimization
challenges associated with deploying OD models in TinyML environments. To
address this gap, this survey paper provides a detailed analysis of key
optimization techniques for deploying OD models on resource-constrained
devices. These techniques include quantization, pruning, knowledge
distillation, and neural architecture search. Furthermore, we explore both
theoretical approaches and practical implementations, bridging the gap between
academic research and real-world edge artificial intelligence deployment.
Finally, we compare the key performance indicators (KPIs) of existing OD
implementations on microcontroller devices, highlighting the achieved maturity
level of these solutions in terms of both prediction accuracy and efficiency.
We also provide a public repository to continually track developments in this
fast-evolving field:
https://github.com/christophezei/Optimizing-Object-Detection-Models-for-TinyML-A-Comprehensive-Survey.

</details>
