{"id": "2512.15907", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.15907", "abs": "https://arxiv.org/abs/2512.15907", "authors": ["Tejas Anvekar", "Juhna Park", "Aparna Garimella", "Vivek Gupta"], "title": "TabReX : Tabular Referenceless eXplainable Evaluation", "comment": null, "summary": "Evaluating the quality of tables generated by large language models (LLMs) remains an open challenge: existing metrics either flatten tables into text, ignoring structure, or rely on fixed references that limit generalization. We present TabReX, a reference-less, property-driven framework for evaluating tabular generation via graph-based reasoning. TabReX converts both source text and generated tables into canonical knowledge graphs, aligns them through an LLM-guided matching process, and computes interpretable, rubric-aware scores that quantify structural and factual fidelity. The resulting metric provides controllable trade-offs between sensitivity and specificity, yielding human-aligned judgments and cell-level error traces. To systematically asses metric robustness, we introduce TabReX-Bench, a large-scale benchmark spanning six domains and twelve planner-driven perturbation types across three difficulty tiers. Empirical results show that TabReX achieves the highest correlation with expert rankings, remains stable under harder perturbations, and enables fine-grained model-vs-prompt analysis establishing a new paradigm for trustworthy, explainable evaluation of structured generation systems.", "AI": {"tldr": "本文提出 TabReX，一种无需参考、基于属性驱动的框架，用于通过图推理的方法评价表格生成。TabReX 通过将源文本和生成表格转换为知识图谱进行对齐，并计算可解释的评分。实验表明，TabReX 在专家排名相关性、稳定性方面表现优异，并且在细粒度分析方面具有优势。", "motivation": "评估大型语言模型生成表格的质量仍然是一项挑战：现有的度量标准要么将表格扁平化成文本，忽略结构，要么依赖限制泛化的固定参考。", "method": "TabReX, 一个无需参考、基于属性驱动的框架，通过图推理的方式对表格生成进行评价。TabReX 将源文本和生成的表格转换为规范的知识图谱，通过由语言模型引导的匹配过程进行对齐，并计算出可解释的、注重评分标准的分数，量化结构和事实的保真度。", "result": "实验结果显示，TabReX 跟专家排名的相关性最高，在面对更加困难的扰动时也能保持稳定，并且能够进行细粒度的模型与提示分析，确立了结构化生成系统可信赖、可解释的评估新范式。", "conclusion": "TabReX 提供了一个新范式，用于可靠的、可解释的结构化生成系统评价。"}}
{"id": "2512.15925", "categories": ["cs.CL", "cs.AI", "cs.LG", "cs.SI"], "pdf": "https://arxiv.org/pdf/2512.15925", "abs": "https://arxiv.org/abs/2512.15925", "authors": ["Joel Mire", "Maria Antoniak", "Steven R. Wilson", "Zexin Ma", "Achyutarama R. Ganti", "Andrew Piper", "Maarten Sap"], "title": "Social Story Frames: Contextual Reasoning about Narrative Intent and Reception", "comment": "Presented at IC2S2 2025; Under Review (ARR Oct 2025)", "summary": "Reading stories evokes rich interpretive, affective, and evaluative responses, such as inferences about narrative intent or judgments about characters. Yet, computational models of reader response are limited, preventing nuanced analyses. To address this gap, we introduce SocialStoryFrames, a formalism for distilling plausible inferences about reader response, such as perceived author intent, explanatory and predictive reasoning, affective responses, and value judgments, using conversational context and a taxonomy grounded in narrative theory, linguistic pragmatics, and psychology. We develop two models, SSF-Generator and SSF-Classifier, validated through human surveys (N=382 participants) and expert annotations, respectively. We conduct pilot analyses to showcase the utility of the formalism for studying storytelling at scale. Specifically, applying our models to SSF-Corpus, a curated dataset of 6,140 social media stories from diverse contexts, we characterize the frequency and interdependence of storytelling intents, and we compare and contrast narrative practices (and their diversity) across communities. By linking fine-grained, context-sensitive modeling with a generic taxonomy of reader responses, SocialStoryFrames enable new research into storytelling in online communities.", "AI": {"tldr": "引入SocialStoryFrames模型来分析读者对故事的反应，实现了对在线社群中故事叙述的新研究。", "motivation": "当前计算模型对于读者反应的理解有限，这阻碍了细致的分析。为了弥补这一差距，开发了这套新方法。", "method": "引入了SocialStoryFrames，这是一种形式化手段，能够利用对话上下文和基于叙事理论、语言学和心理学的分类体系提炼出关于读者反应的合理推断，如感知到的作者意图、解释性和预测性推理、情感反应及价值判断。开发了两种模型SSF-Generator和SSF-Classifier，分别通过人类调查（N=382参与者）和专家注释进行验证。", "result": "在包含6,140个来自多种社交平台故事的精选数据集SSF-Corpus上应用这些模型，分析了故事讲述意图的频率和相互依赖关系，并且比较了不同社区中的叙事实践（以及它们的差异性）。", "conclusion": "通过将细粒度上下文相关的建模与通用的读者反应分类体系相结合，SocialStoryFrames开启了在线社群故事叙述研究的新方向。"}}
{"id": "2512.15959", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15959", "abs": "https://arxiv.org/abs/2512.15959", "authors": ["Armağan Amcalar", "Eyup Cinar"], "title": "BRAID: Bounded Reasoning for Autonomous Inference and Decisions", "comment": null, "summary": "Large Language Models (LLMs) exhibit nonlinear relationships between performance, cost, and token usage. This paper presents a quantitative study on structured prompting using BRAID (Bounded Reasoning for Au tonomous Inference and Decisions) across multiple GPT model tiers, eval uated on the AdvancedIF, GSM-Hard, and the SCALE MultiChallenge benchmark datasets. BRAID introduces a bounded reasoning framework using Mermaid-based instruction graphs that enable models to reason struc turally rather than through unbounded natural-language token expansion. We show that structured machine-readable prompts substantially increase reasoning accuracy and cost efficiency for agents in production systems. The findings establish BRAID as an effective and scalable technique for optimizing inference efficiency in autonomous agent systems. All datasets and detailed result logs are available at https://benchmark.openserv.ai.", "AI": {"tldr": "研究展示了BRAID框架如何通过结构化提示提升GPT模型在推理准确性及成本效率上的表现。", "motivation": "目的是探索大型语言模型（LLMs）中性能、成本和令牌使用量之间的非线性关系，并展示结构化机器可读提示如何显著提高生产系统中代理的推理准确性和成本效益。", "method": "该论文通过使用BRAID（Bounded Reasoning for Autonomous Inference and Decisions）框架，在不同的GPT模型级别上进行了量化的结构化提示研究，并在AdvancedIF、GSM-Hard以及SCALE MultiChallenge基准数据集上进行了评估。BRAID使用Mermaid基础指令图来实现有界推理，使模型能够进行结构化推理而非无界的自然语言扩展。", "result": "研究结果证明，结构化提示大幅度提升了在不同GPT模型级别上的推理准确性，同时也提高了成本效率。", "conclusion": "研究确立了BRAID作为一种有效的和可扩展的技术，用于优化自主代理系统中的推理效率。"}}
{"id": "2512.16034", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16034", "abs": "https://arxiv.org/abs/2512.16034", "authors": ["Kieran Henderson", "Kian Omoomi", "Vasudha Varadarajan", "Allison Lahnala", "Charles Welch"], "title": "Examining the Utility of Self-disclosure Types for Modeling Annotators of Social Norms", "comment": null, "summary": "Recent work has explored the use of personal information in the form of persona sentences or self-disclosures to improve modeling of individual characteristics and prediction of annotator labels for subjective tasks. The volume of personal information has historically been restricted and thus little exploration has gone into understanding what kind of information is most informative for predicting annotator labels. In this work, we categorize self-disclosure sentences and use them to build annotator models for predicting judgments of social norms. We perform several ablations and analyses to examine the impact of the type of information on our ability to predict annotation patterns. We find that demographics are more impactful than attitudes, relationships, and experiences. Generally, theory-based approaches worked better than automatic clusters. Contrary to previous work, only a small number of related comments are needed. Lastly, having a more diverse sample of annotator self-disclosures leads to the best performance.", "AI": {"tldr": "本文通过分类和分析自披露句子来构建注释者模型，以预测社会规范判断。研究显示人口统计信息和理论方法更重要，较少的评论也有效，多样性重要。", "motivation": "由于个人信息的数量有限，历史上少有研究探讨何种信息对预测注释者标签最为有用。本文旨在填补这一研究空白。", "method": "本研究对自披露句子进行了分类，并利用这些类别构建了预测社会规范判断的注释者模型。通过多次消融分析来探讨不同类型的信息对预测注释模式的影响。", "result": "研究发现，人口统计学特征比态度、关系和经验更有影响力。基于理论的方法优于自动聚类。与之前的研究所不同，较少的相关评论即可达到有效的预测。最后，具有更广泛的注释者自我披露样本能够取得最佳性能。", "conclusion": "人口统计信息是预测注释模式的重要影响因素，理论方法优于自动方法，较少的相关评论亦可达成良好的预测效果，而具备多样性的自我披露样本很重要。"}}
{"id": "2512.15774", "categories": ["cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15774", "abs": "https://arxiv.org/abs/2512.15774", "authors": ["Yan Yang", "George Bebis", "Mircea Nicolescu"], "title": "Two-Step Data Augmentation for Masked Face Detection and Recognition: Turning Fake Masks to Real", "comment": "9 pages, 9 figures. Conference version", "summary": "Data scarcity and distribution shift pose major challenges for masked face detection and recognition. We propose a two-step generative data augmentation framework that combines rule-based mask warping with unpaired image-to-image translation using GANs, enabling the generation of realistic masked-face samples beyond purely synthetic transformations. Compared to rule-based warping alone, the proposed approach yields consistent qualitative improvements and complements existing GAN-based masked face generation methods such as IAMGAN. We introduce a non-mask preservation loss and stochastic noise injection to stabilize training and enhance sample diversity. Experimental observations highlight the effectiveness of the proposed components and suggest directions for future improvements in data-centric augmentation for face recognition tasks.", "AI": {"tldr": "本文提出了一种两步生成数据增强框架，结合规则基口罩变形与无配对的图像到图像翻译，以生成更真实的戴口罩人脸样本，改进了现有的口罩人脸生成方法。", "motivation": "解决数据稀缺和分布偏移问题，特别是在戴口罩人脸检测与识别领域。", "method": "提出了一种两步生成数据增强框架，结合规则基口罩变形与无配对的图像到图像翻译技术，并引入非掩模保持损失与随机噪声注入以提高样本多样性。", "result": "实验观察表明所提出的方法具有显著的定性改进，并补充了现有的GAN基口罩脸生成方法。", "conclusion": "这项研究显示出其在人脸识别任务中数据增强方面的有效性，并提供了未来改善的方向。"}}
{"id": "2512.16041", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16041", "abs": "https://arxiv.org/abs/2512.16041", "authors": ["Yuanning Feng", "Sinan Wang", "Zhengxiang Cheng", "Yao Wan", "Dongping Chen"], "title": "Are We on the Right Way to Assessing LLM-as-a-Judge?", "comment": null, "summary": "LLM-as-a-Judge has been widely adopted as an evaluation method and served as supervised rewards in model training. However, existing benchmarks for LLM-as-a-Judge are mainly relying on human-annotated ground truth, which introduces human bias that undermines the assessment of reliability and imposes scalability constraints. To overcome these limitations, we introduce Sage, a novel evaluation suite that assesses the quality of LLM judges without necessitating any human annotation. Inspired by axioms of rational choice theory, Sage introduces two new lenses for measuring LLM-as-a-Judge: local self-consistency (pair-wise preference stability) and global logical consistency (transitivity across a full set of preferences). We curate a dataset of 650 questions by combining structured benchmark problems with real-world user queries. Our experiments demonstrate both the stability of our metrics and their high correlation with supervised benchmarks like LLMBar and RewardBench2, confirming Sage's reliability as an evaluation suite for the robustness and accuracy of LLM-as-a-Judge. Based on Sage, we reveal that current state-of-the-art LLMs exhibit significant reliability problems when acting as judges in both scoring and pairwise settings; even the top-performing models, Gemini-2.5-Pro and GPT-5, fail to maintain consistent preferences in nearly a quarter of difficult cases. We attribute this to a new phenomenon called situational preference, which explains why explicit rubrics or criteria can help the model judge consistently across answer pairs. Our further analysis shows that finetuned LLM-as-a-Judge is a feasible method to boost performance, and the panel-based judge as well as deep reasoning can enhance the judging consistency. We also find substantial inconsistency in human judgments, which indicates that human annotation may not be a reliable gold standard.", "AI": {"tldr": "本文提出了Sage评估套件，无需人类标注即可评估LLM作为评判者的质量，结果显示现有LLM在评判任务中存在一致性问题，微调和合理的设计可以提升评判表现。", "motivation": "现有评估套件主要依赖人类标注的基准，这引入了人为偏差并限制了可扩展性。本文旨在开发一种无需人类标注的新评估方法，以提高评估的可靠性和可扩展性。", "method": "本文提出了一种名为Sage的新评估套件，该套件基于理性选择理论的公理，无需人类标注即可评估LLM作为评判者的质量。Sage提出了两种新视角：局部自我一致性和全局逻辑一致性。", "result": "实验表明Sage的评估指标具有稳定性，并与监督基准LLMBar和RewardBench2高度相关。研究揭示了当前最先进的LLM作为评判者时存在可靠性问题。", "conclusion": "研究显示，通过微调可以提高LLM作为评判者的表现，并且基于小组的评判和深入推理可以增强评判一致性。此外，人类标注可能并非可靠的黄金标准。"}}
{"id": "2512.15885", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.15885", "abs": "https://arxiv.org/abs/2512.15885", "authors": ["Davide Caffagni", "Sara Sarto", "Marcella Cornia", "Lorenzo Baraldi", "Pier Luigi Dovesi", "Shaghayegh Roohi", "Mark Granroth-Wilding", "Rita Cucchiara"], "title": "Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have recently demonstrated impressive capabilities in connecting vision and language, yet their proficiency in fundamental visual reasoning tasks remains limited. This limitation can be attributed to the fact that MLLMs learn visual understanding primarily from textual descriptions, which constitute a subjective and inherently incomplete supervisory signal. Furthermore, the modest scale of multimodal instruction tuning compared to massive text-only pre-training leads MLLMs to overfit language priors while overlooking visual details. To address these issues, we introduce JARVIS, a JEPA-inspired framework for self-supervised visual enhancement in MLLMs. Specifically, we integrate the I-JEPA learning paradigm into the standard vision-language alignment pipeline of MLLMs training. Our approach leverages frozen vision foundation models as context and target encoders, while training the predictor, implemented as the early layers of an LLM, to learn structural and semantic regularities from images without relying exclusively on language supervision. Extensive experiments on standard MLLM benchmarks show that JARVIS consistently improves performance on vision-centric benchmarks across different LLM families, without degrading multimodal reasoning abilities. Our source code is publicly available at: https://github.com/aimagelab/JARVIS.", "AI": {"tldr": "本文提出JARVIS框架，通过自我监督学习方法提升多模态大型语言模型在视觉推理任务的能力。实验表明，这框架在视觉相关任务上明显提升了性能。", "motivation": "多模态大型语言模型（MLLMs）在连接视觉和语言方面表现出色，但在基础视觉推理任务中的表现有限。这一局限性源于MLLMs主要通过文本描述学习视觉理解，这是一种主观且本质上不完整的监督信号。此外，由于多模态指令调整的规模相对较小，MLLMs容易过度拟合语言先验，而忽视视觉细节。", "method": "我们引入了JARVAS，这是一个受JEPA启发的框架，用于在MLLMs训练的视觉-语言对齐流水线中进行自我监督的视觉增强。该方法采用冻结的视觉基础模型作为上下文和目标编码器，并训练实现为LLM早期层的预测器，从图像中学习结构和语义规律，不完全依赖语言监督。", "result": "在标准的MLLM基准测试中进行的广泛实验表明，JARVIS在不同LLM系列中始终能提高视觉中心基准的表现，同时不降低多模态推理能力。", "conclusion": "提出的方法通过整合I-JEPA学习范式，有效缓解了MLLMs在视觉推理任务上的局限性，并在视觉中心基准测试中表现出色。"}}
{"id": "2512.16125", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16125", "abs": "https://arxiv.org/abs/2512.16125", "authors": ["Daniela N. Rim", "Heeyoul Choi"], "title": "Convolutional Lie Operator for Sentence Classification", "comment": "Proceedings of the 2024 8th International Conference on Natural Language Processing and Information Retrieval", "summary": "Traditional Convolutional Neural Networks have been successful in capturing local, position-invariant features in text, but their capacity to model complex transformation within language can be further explored. In this work, we explore a novel approach by integrating Lie Convolutions into Convolutional-based sentence classifiers, inspired by the ability of Lie group operations to capture complex, non-Euclidean symmetries. Our proposed models SCLie and DPCLie empirically outperform traditional Convolutional-based sentence classifiers, suggesting that Lie-based models relatively improve the accuracy by capturing transformations not commonly associated with language. Our findings motivate more exploration of new paradigms in language modeling.", "AI": {"tldr": "The paper investigates a new approach using Lie Convolutions to enhance the modeling of complex transformations in language, leading to improved accuracy in sentence classification tasks with models SCLie and DPCLie.", "motivation": "Traditional Convolutional Neural Networks capture local, position-invariant features in text well, but their ability to model language transformations is limited. This motivates the exploration of Lie Convolutions in sentence classification.", "method": "The paper introduces the integration of Lie Convolutions into Convolutional-based sentence classifiers to capture complex transformations in language beyond what traditional CNNs can handle. The proposed models are named SCLie and DPCLie.", "result": "SCLie and DPCLie empirically outperform traditional Convolutional-based sentence classifiers, showing Lie-based models can improve accuracy by capturing transformations not commonly modeled in language.", "conclusion": "The findings suggest that there is potential for further exploration into new paradigms for language modeling using Lie-based approaches."}}
{"id": "2512.15933", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15933", "abs": "https://arxiv.org/abs/2512.15933", "authors": ["Dwip Dalal", "Utkarsh Mishra", "Narendra Ahuja", "Nebojsa Jojic"], "title": "City Navigation in the Wild: Exploring Emergent Navigation from Web-Scale Knowledge in MLLMs", "comment": null, "summary": "Leveraging multimodal large language models (MLLMs) to develop embodied agents offers significant promise for addressing complex real-world tasks. However, current evaluation benchmarks remain predominantly language-centric or heavily reliant on simulated environments, rarely probing the nuanced, knowledge-intensive reasoning essential for practical, real-world scenarios. To bridge this critical gap, we introduce the task of Sparsely Grounded Visual Navigation, explicitly designed to evaluate the sequential decision-making abilities of MLLMs in challenging, knowledge-intensive real-world environments. We operationalize this task with CityNav, a comprehensive benchmark encompassing four diverse global cities, specifically constructed to assess raw MLLM-driven agents in city navigation. Agents are required to rely solely on visual inputs and internal multimodal reasoning to sequentially navigate 50+ decision points without additional environmental annotations or specialized architectural modifications. Crucially, agents must autonomously achieve localization through interpreting city-specific cues and recognizing landmarks, perform spatial reasoning, and strategically plan and execute routes to their destinations. Through extensive evaluations, we demonstrate that current state-of-the-art MLLMs and standard reasoning techniques (e.g., Chain-of-Thought, Reflection) significantly underperform in this challenging setting. To address this, we propose Verbalization of Path (VoP), which explicitly grounds the agent's internal reasoning by probing an explicit cognitive map (key landmarks and directions toward the destination) from the MLLMs, substantially enhancing navigation success. Project Webpage: https://dwipddalal.github.io/AgentNav/", "AI": {"tldr": "以CityNav为基准，评估MLLMs在现实世界导航任务中的表现，并提出VoP方法以提高其导航成功率。", "motivation": "现有的评估基准主要以语言为中心或过度依赖模拟环境，很少测试现实场景中必需的复杂推理能力。为填补这一空白，本研究提出了一个新的评价标准。", "method": "通过引入稀疏接地视觉导航任务来评估多模态大型语言模型（MLLMs）在复杂现实世界的决策能力。这个任务通过CityNav基准测试来实现，CityNav包含四个全球城市，旨在评估仅靠视觉输入和多模态内部推理进行导航的MLLM代理的性能。代理必须根据城市特定的线索进行自我定位，执行空间推理，并规划和执行前往目的地的路线。", "result": "实验结果表明，当前最先进的MLLMs和标准推理技术在这一具有挑战性的环境中表现不佳。", "conclusion": "我们提出了一种名为VoP（路径的表述）的方法，通过明确地引导代理内部推理，大幅提高了导航成功率。"}}
{"id": "2512.16145", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16145", "abs": "https://arxiv.org/abs/2512.16145", "authors": ["Pengyu Wang", "Shuchang Ye", "Usman Naseem", "Jinman Kim"], "title": "MRG-R1: Reinforcement Learning for Clinically Aligned Medical Report Generation", "comment": "12 pages", "summary": "Medical report generation (MRG) aims to automatically derive radiology-style reports from medical images to aid in clinical decision-making. However, existing methods often generate text that mimics the linguistic style of radiologists but fails to guarantee clinical correctness, because they are trained on token-level objectives which focus on word-choice and sentence structure rather than actual medical accuracy. We propose a semantic-driven reinforcement learning (SRL) method for medical report generation, adopted on a large vision-language model (LVLM). SRL adopts Group Relative Policy Optimization (GRPO) to encourage clinical-correctness-guided learning beyond imitation of language style. Specifically, we optimise a report-level reward: a margin-based cosine similarity (MCCS) computed between key radiological findings extracted from generated and reference reports, thereby directly aligning clinical-label agreement and improving semantic correctness. A lightweight reasoning format constraint further guides the model to generate structured \"thinking report\" outputs. We evaluate Medical Report Generation with Sematic-driven Reinforment Learning (MRG-R1), on two datasets: IU X-Ray and MIMIC-CXR using clinical efficacy (CE) metrics. MRG-R1 achieves state-of-the-art performance with CE-F1 51.88 on IU X-Ray and 40.39 on MIMIC-CXR. We found that the label-semantic reinforcement is better than conventional token-level supervision. These results indicate that optimizing a clinically grounded, report-level reward rather than token overlap,meaningfully improves clinical correctness. This work is a prior to explore semantic-reinforcement in supervising medical correctness in medical Large vision-language model(Med-LVLM) training.", "AI": {"tldr": "提出了一种基于语义驱动的强化学习方法（SRL），用于医学报告生成，通过优化报告级别的奖励来提高临床正确性，并验证了在两种数据集上的优越性能。", "motivation": "现有的医学报告生成方法虽然模仿了放射科医生的语言风格，但在临床准确性上存在不足，因为它们仅在单词选择和句子结构方面进行训练。", "method": "采用了基于组相对策略优化（GRPO）的语义驱动强化学习（SRL）方法来提高临床准确性，并引入轻量级推理格式约束以生成结构化的思考报告输出。", "result": "方法在IU X-Ray和MIMIC-CXR数据集上使用临床效率（CE）度量进行了评估，并取得了优越性能，获得了CE-F1得分分别为51.88和40.39。", "conclusion": "研究表明，通过优化基于临床的报告级别奖励而非单词重合，显著提高了临床准确性。这对监督医学大型视觉语言模型（Med-LVLM）训练中的医学正确性具有初步探索价值。"}}
{"id": "2512.15940", "categories": ["cs.CV", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.15940", "abs": "https://arxiv.org/abs/2512.15940", "authors": ["Tin Stribor Sohn", "Maximilian Dillitzer", "Jason J. Corso", "Eric Sax"], "title": "R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space", "comment": null, "summary": "Humans perceive and reason about their surroundings in four dimensions by building persistent, structured internal representations that encode semantic meaning, spatial layout, and temporal dynamics. These multimodal memories enable them to recall past events, infer unobserved states, and integrate new information into context-dependent reasoning. Inspired by this capability, we introduce R4, a training-free framework for retrieval-augmented reasoning in 4D spatio-temporal space that equips vision-language models (VLMs) with structured, lifelong memory. R4 continuously constructs a 4D knowledge database by anchoring object-level semantic descriptions in metric space and time, yielding a persistent world model that can be shared across agents. At inference, natural language queries are decomposed into semantic, spatial, and temporal keys to retrieve relevant observations, which are integrated into the VLM's reasoning. Unlike classical retrieval-augmented generation methods, retrieval in R4 operates directly in 4D space, enabling episodic and collaborative reasoning without training. Experiments on embodied question answering and navigation benchmarks demonstrate that R4 substantially improves retrieval and reasoning over spatio-temporal information compared to baselines, advancing a new paradigm for embodied 4D reasoning in dynamic environments.", "AI": {"tldr": "本文提出R4框架，专注于在无需任何训练的情况下，在4D时空中进行视觉语言模型的检索增强推理，使模型具有持续的、结构化的知识记忆，并提高了在空间和时间信息上的检索与推理能力。", "motivation": "受到人类构建持久的、结构化的内部表示以感知和推理周围环境的能力的启发，这种表示方法编码了语义含义、空间布局和时间动态，从而实现对过去事件的回忆、对未观察状态的推断以及将新的信息整合进上下文相关的推理中。", "method": "提出了一种无需训练的框架R4，用于4D时空空间中的检索增强推理，旨在赋予视觉语言模型结构化的终身记忆。R4通过将对象级别的语义描述锚定在度量空间和时间中，持续构建一个4D知识数据库，从而形成一个可以跨代理共享的持续世界模型。推理时，自然语言查询被分解为语义、空间和时间键，用于检索相关观察，并将这些观察集成到VLM的推理中。", "result": "在身体化问题回答和导航基准测试上的实验显示了R4相对于基线方法显著的提升。", "conclusion": "实验表明，R4显著提高了在空间和时间信息检索和推理方面的能力，相较于基准方法，这为动态环境中的4D认知推理提供了一个新的范式。"}}
{"id": "2512.16147", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16147", "abs": "https://arxiv.org/abs/2512.16147", "authors": ["Yash Bhaskar", "Sankalp Bahad", "Parameswari Krishnamurthy"], "title": "Decoding Fake Narratives in Spreading Hateful Stories: A Dual-Head RoBERTa Model with Multi-Task Learning", "comment": "Accepted Paper, Anthology ID: 2024.icon-fauxhate.3, 4 pages, 1 figure, 1 table", "summary": "Social media platforms, while enabling global connectivity, have become hubs for the rapid spread of harmful content, including hate speech and fake narratives \\cite{davidson2017automated, shu2017fake}. The Faux-Hate shared task focuses on detecting a specific phenomenon: the generation of hate speech driven by fake narratives, termed Faux-Hate. Participants are challenged to identify such instances in code-mixed Hindi-English social media text. This paper describes our system developed for the shared task, addressing two primary sub-tasks: (a) Binary Faux-Hate detection, involving fake and hate speech classification, and (b) Target and Severity prediction, categorizing the intended target and severity of hateful content. Our approach combines advanced natural language processing techniques with domain-specific pretraining to enhance performance across both tasks. The system achieved competitive results, demonstrating the efficacy of leveraging multi-task learning for this complex problem.", "AI": {"tldr": "本文针对社交媒体中由虚假叙事引发的仇恨言论检测问题，提出了一种基于自然语言处理技术和多任务学习的方法，并取得了优秀成绩。", "motivation": "当今社交媒体平台成为了有害内容传播的中心，包括仇恨言论和虚假叙事，文章目标是解决这一现象，特别是针对印地语-英语混编的社交媒体文本中由虚假叙事驱动的仇恨言论。", "method": "本文采用结合先进自然语言处理技术和领域特定预训练的方法来提高Faux-Hate检测和目标与严重性预测任务的表现。", "result": "系统在比赛中表现出较高水平，证明了多任务学习方法的有效性。", "conclusion": "研究显示，通过先进自然语言处理技术与领域特定预训练的结合，可以有效检测并预测社交媒体上的Faux-Hate。"}}
{"id": "2512.15949", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15949", "abs": "https://arxiv.org/abs/2512.15949", "authors": ["Tejas Anvekar", "Fenil Bardoliya", "Pavan K. Turaga", "Chitta Baral", "Vivek Gupta"], "title": "The Perceptual Observatory Characterizing Robustness and Grounding in MLLMs", "comment": "Accepted at WACV 2026", "summary": "Recent advances in multimodal large language models (MLLMs) have yielded increasingly powerful models, yet their perceptual capacities remain poorly characterized. In practice, most model families scale language component while reusing nearly identical vision encoders (e.g., Qwen2.5-VL 3B/7B/72B), which raises pivotal concerns about whether progress reflects genuine visual grounding or reliance on internet-scale textual world knowledge. Existing evaluation methods emphasize end-task accuracy, overlooking robustness, attribution fidelity, and reasoning under controlled perturbations. We present The Perceptual Observatory, a framework that characterizes MLLMs across verticals like: (i) simple vision tasks, such as face matching and text-in-vision comprehension capabilities; (ii) local-to-global understanding, encompassing image matching, grid pointing game, and attribute localization, which tests general visual grounding. Each vertical is instantiated with ground-truth datasets of faces and words, systematically perturbed through pixel-based augmentations and diffusion-based stylized illusions. The Perceptual Observatory moves beyond leaderboard accuracy to yield insights into how MLLMs preserve perceptual grounding and relational structure under perturbations, providing a principled foundation for analyzing strengths and weaknesses of current and future models.", "AI": {"tldr": "The paper introduces The Perceptual Observatory framework, a systematic approach to evaluate the perceptual grounding capabilities of multimodal large language models, addressing deficiencies in current evaluation methods.", "motivation": "The motivation for this paper is to address the lack of understanding of MLLMs' perceptual capacities, particularly given the scaling of language components and the static nature of vision encoders. It aims to offer a more rigorous evaluation method beyond the current focus on end-task accuracy.", "method": "The Perceptual Observatory framework is introduced to systematically analyze MLLMs' perceptual capabilities. It targets specific areas such as simple vision tasks and local-to-global understanding. Ground-truth datasets like faces and words are used, and perturbations are applied through pixel-based augmentations and diffusion-based stylized illusions.", "result": "The framework leads to insights into how MLLMs perform perceptual grounding under various controlled perturbations, providing a deeper analysis than mere task accuracy.", "conclusion": "The Perceptual Observatory offers a profound framework for analyzing how MLLMs maintain perceptual grounding and relational structure under perturbations. This helps in identifying the strengths and weaknesses of both current and future MLLM models."}}
{"id": "2512.16183", "categories": ["cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2512.16183", "abs": "https://arxiv.org/abs/2512.16183", "authors": ["Mengfan Shen", "Kangqi Song", "Xindi Wang", "Wei Jia", "Tao Wang", "Ziqiang Han"], "title": "A Domain-Adapted Pipeline for Structured Information Extraction from Police Incident Announcements on Social Media", "comment": "41 pages,3figures and 9 tables", "summary": "Structured information extraction from police incident announcements is crucial for timely and accurate data processing, yet presents considerable challenges due to the variability and informal nature of textual sources such as social media posts. To address these challenges, we developed a domain-adapted extraction pipeline that leverages targeted prompt engineering with parameter-efficient fine-tuning of the Qwen2.5-7B model using Low-Rank Adaptation (LoRA). This approach enables the model to handle noisy, heterogeneous text while reliably extracting 15 key fields, including location, event characteristics, and impact assessment, from a high-quality, manually annotated dataset of 4,933 instances derived from 27,822 police briefing posts on Chinese Weibo (2019-2020). Experimental results demonstrated that LoRA-based fine-tuning significantly improved performance over both the base and instruction-tuned models, achieving an accuracy exceeding 98.36% for mortality detection and Exact Match Rates of 95.31% for fatality counts and 95.54% for province-level location extraction. The proposed pipeline thus provides a validated and efficient solution for multi-task structured information extraction in specialized domains, offering a practical framework for transforming unstructured text into reliable structured data in social science research.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2512.15957", "categories": ["cs.CV", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15957", "abs": "https://arxiv.org/abs/2512.15957", "authors": ["Utsav Panchal", "Yuchen Liu", "Luigi Palmieri", "Ilche Georgievski", "Marco Aiello"], "title": "Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models", "comment": "Accepted at IEEE/CVF Winter Conference on Applications of Computer Vision (WACV) 2026", "summary": "Accurately predicting human behaviors is crucial for mobile robots operating in human-populated environments. While prior research primarily focuses on predicting actions in single-human scenarios from an egocentric view, several robotic applications require understanding multiple human behaviors from a third-person perspective. To this end, we present CAMP-VLM (Context-Aware Multi-human behavior Prediction): a Vision Language Model (VLM)-based framework that incorporates contextual features from visual input and spatial awareness from scene graphs to enhance prediction of humans-scene interactions. Due to the lack of suitable datasets for multi-human behavior prediction from an observer view, we perform fine-tuning of CAMP-VLM with synthetic human behavior data generated by a photorealistic simulator, and evaluate the resulting models on both synthetic and real-world sequences to assess their generalization capabilities. Leveraging Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), CAMP-VLM outperforms the best-performing baseline by up to 66.9% in prediction accuracy.", "AI": {"tldr": "研究提出CAMP-VLM框架，提升了基于多人类行为预测的精度，尤其是在从第三人称视角预测时的准确性。", "motivation": "鉴于先前的研究主要集中在从自我中心视角预测单人行为，而许多机器人应用需要理解多人行为，并且缺乏适合从观察者视角预测多人类行为的数据集。", "method": "我们提出CAMP-VLM（基于上下文感知的多人类行为预测的视觉语言模型），该框架综合了来自视觉输入的上下文特征和来自场景图的空间意识，以增强对人类-场景交互行为的预测。", "result": "通过使用合成人类行为数据进行微调，并在合成和真实世界序列上进行评估，结果显示CAMP-VLM在预测精度上优于最佳基线模型，提高了66.9%。", "conclusion": "实验结果表明，CAMP-VLM在多人类行为预测任务中表现优异，尤其是在理解和预测复杂的多个人类-场景交互行为方面。"}}
{"id": "2512.16189", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16189", "abs": "https://arxiv.org/abs/2512.16189", "authors": ["Musarrat Zeba", "Abdullah Al Mamun", "Kishoar Jahan Tithee", "Debopom Sutradhar", "Mohaimenul Azam Khan Raiaan", "Saddam Mukta", "Reem E. Mohamed", "Md Rafiqul Islam", "Yakub Sebastian", "Mukhtar Hussain", "Sami Azam"], "title": "Mitigating Hallucinations in Healthcare LLMs with Granular Fact-Checking and Domain-Specific Adaptation", "comment": null, "summary": "In healthcare, it is essential for any LLM-generated output to be reliable and accurate, particularly in cases involving decision-making and patient safety. However, the outputs are often unreliable in such critical areas due to the risk of hallucinated outputs from the LLMs. To address this issue, we propose a fact-checking module that operates independently of any LLM, along with a domain-specific summarization model designed to minimize hallucination rates. Our model is fine-tuned using Low-Rank Adaptation (LoRa) on the MIMIC III dataset and is paired with the fact-checking module, which uses numerical tests for correctness and logical checks at a granular level through discrete logic in natural language processing (NLP) to validate facts against electronic health records (EHRs). We trained the LLM model on the full MIMIC-III dataset. For evaluation of the fact-checking module, we sampled 104 summaries, extracted them into 3,786 propositions, and used these as facts. The fact-checking module achieves a precision of 0.8904, a recall of 0.8234, and an F1-score of 0.8556. Additionally, the LLM summary model achieves a ROUGE-1 score of 0.5797 and a BERTScore of 0.9120 for summary quality.", "AI": {"tldr": "本文提出了一种事实核查模块和特定领域的摘要模型，来提高医疗保健中LLM生成内容的可靠性和准确性。模型在MIMIC III数据集上进行微调，并通过事实核查模块验证了其有效性。", "motivation": "在医疗保健领域，任何由LLM生成的输出需要可靠准确，特别是在涉及决策制定和患者安全的情况下。然而，由于LLM有幻觉输出的风险，输出往往是不可靠的。因此，提出了这个方案以解决这个问题。", "method": "我们提出了一种独立于LLM工作的事实核查模块以及一个旨在减少幻觉率的特定领域摘要模型。该模型使用了MIMIC III数据集上的低秩自适应（LoRa）进行微调，并配有一个事实核查模块，该模块通过NLP中的离散逻辑进行数值测试和细粒度逻辑检查，以验证事实是否符合电子健康记录（EHR）。", "result": "事实核查模块在精度上达到0.8904，在召回率上达到0.8234，在F1分数上达到0.8556。此外，LLM摘要模型达到了ROUGE-1分数0.5797和BERTScore 0.9120的摘要质量。", "conclusion": "所提出的方法显著提高了LLM生成内容在医疗领域中的可靠性和准确性，尤其是通过独立的事实核查模块和特定领域摘要模型的使用。"}}
{"id": "2512.15971", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15971", "abs": "https://arxiv.org/abs/2512.15971", "authors": ["Manuel Nkegoum", "Minh-Tan Pham", "Élisa Fromont", "Bruno Avignon", "Sébastien Lefèvre"], "title": "From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection", "comment": null, "summary": "Multispectral object detection is critical for safety-sensitive applications such as autonomous driving and surveillance, where robust perception under diverse illumination conditions is essential. However, the limited availability of annotated multispectral data severely restricts the training of deep detectors. In such data-scarce scenarios, textual class information can serve as a valuable source of semantic supervision. Motivated by the recent success of Vision-Language Models (VLMs) in computer vision, we explore their potential for few-shot multispectral object detection. Specifically, we adapt two representative VLM-based detectors, Grounding DINO and YOLO-World, to handle multispectral inputs and propose an effective mechanism to integrate text, visual and thermal modalities. Through extensive experiments on two popular multispectral image benchmarks, FLIR and M3FD, we demonstrate that VLM-based detectors not only excel in few-shot regimes, significantly outperforming specialized multispectral models trained with comparable data, but also achieve competitive or superior results under fully supervised settings. Our findings reveal that the semantic priors learned by large-scale VLMs effectively transfer to unseen spectral modalities, ofFering a powerful pathway toward data-efficient multispectral perception.", "AI": {"tldr": "使用Vision-Language Models (VLMs) 处理多光谱目标检测，特别是在有限标注数据情况下，通过融合文本、视觉和热成像信息，证明了在少量样本的情况下，VLMs的优势超过了专门的多光谱模型，并在全监督设置中取得了有竞争力的结果。", "motivation": "多光谱目标检测在自动驾驶和监控等安全敏感应用中至关重要，但标注数据稀缺限制了深层检测器的训练。利用文本类信息作为语义监督的来源，基于VLM的成功经验，探索其在少量样本多光谱目标检测中的潜力。", "method": "采用Grounding DINO和YOLO-World两种代表性基于VLM的检测器来处理多光谱输入，并提出了一种有效机制，将文本、视觉和热成像模态进行融合。", "result": "实验显示，基于VLM的检测器在少量样本情况下显著优于专门的多光谱模型，甚至在全监督设置中也能达到具有竞争力或更优的结果。", "conclusion": "大规模VLM学到的语义先验知识能够有效转移到未知的光谱模态，为实现数据高效的多光谱感知提供了一条有力的途径。"}}
{"id": "2512.16227", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16227", "abs": "https://arxiv.org/abs/2512.16227", "authors": ["Qizhou Chen", "Chengyu Wang", "Taolin Zhang", "Xiaofeng He"], "title": "An Information-Theoretic Framework for Robust Large Language Model Editing", "comment": null, "summary": "Large Language Models (LLMs) have become indispensable tools in science, technology, and society, enabling transformative advances across diverse fields. However, errors or outdated information within these models can undermine their accuracy and restrict their safe deployment. Developing efficient strategies for updating model knowledge without the expense and disruption of full retraining remains a critical challenge. Current model editing techniques frequently struggle to generalize corrections beyond narrow domains, leading to unintended consequences and limiting their practical impact. Here, we introduce a novel framework for editing LLMs, grounded in information bottleneck theory. This approach precisely compresses and isolates the essential information required for generalizable knowledge correction while minimizing disruption to unrelated model behaviors. Building upon this foundation, we present the Information Bottleneck Knowledge Editor (IBKE), which leverages compact latent representations to guide gradient-based updates, enabling robust and broadly applicable model editing. We validate IBKE's effectiveness across multiple LLM architectures and standard benchmark tasks, demonstrating state-of-the-art accuracy and improved generality and specificity of edits. These findings establish a theoretically principled and practical paradigm for open-domain knowledge editing, advancing the utility and trustworthiness of LLMs in real-world applications.", "AI": {"tldr": "本文提出了一种基于信息瓶颈理论的LLM编辑框架IBKE，实现有效且受限最小的模型知识更新，通过实验验证了其在准确性、通用性和特异性方面的优越性。", "motivation": "LLMs虽然在各个领域产生了变革性进展，但模型中的错误或过时信息影响了其准确性和安全部署。目前的模型编辑技术在修正错误时常常受到领域限制，缺乏通用性和造成意外后果。因此，开发有效且不会因完全重新训练而造成耗费和中断的知识更新策略至关重要。", "method": "介绍了基于信息瓶颈理论的LLM编辑框架，该框架通过压缩和隔离必需的信息以精确修正知识，并最小化对无关模型行为的影响。提出了IBKE，利用紧凑的潜在表示来引导基于梯度的更新，实现稳健且广泛应用的模型编辑。", "result": "实验验证了IBKE在多个LLM架构和标准基准任务中的有效性，展示了其在准确性、通用性和特异性方面的先进水平。", "conclusion": "IBKE作为基于理论原则和实用性的开放领域知识编辑方法，增强了LLM在实际应用中的实用性和可信度。"}}
{"id": "2512.15977", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15977", "abs": "https://arxiv.org/abs/2512.15977", "authors": ["Earl Ranario", "Mason J. Earles"], "title": "Are vision-language models ready to zero-shot replace supervised classification models in agriculture?", "comment": "Draft version", "summary": "Vision-language models (VLMs) are increasingly proposed as general-purpose solutions for visual recognition tasks, yet their reliability for agricultural decision support remains poorly understood. We benchmark a diverse set of open-source and closed-source VLMs on 27 agricultural classification datasets from the AgML collection, spanning 162 classes across plant disease, pest and damage, and plant and weed species identification. Across all tasks, zero-shot VLMs substantially underperform a supervised task-specific baseline (YOLO11), which consistently achieves markedly higher accuracy than any foundation model. Under multiple-choice prompting, the best-performing VLM (Gemini-3 Pro) reaches approximately 62% average accuracy, while open-ended prompting yields much lower performance, with raw accuracies typically below 25%. Applying LLM-based semantic judging increases open-ended accuracy (for example, from 21% to 30% for top models) and alters model rankings, demonstrating that evaluation methodology meaningfully affects reported conclusions. Among open-source models, Qwen-VL-72B performs best, approaching closed-source performance under constrained prompting but still trailing top proprietary systems. Task-level analysis shows that plant and weed species classification is consistently easier than pest and damage identification, which remains the most challenging category across models. Overall, these results indicate that current off-the-shelf VLMs are not yet suitable as standalone agricultural diagnostic systems, but can function as assistive components when paired with constrained interfaces, explicit label ontologies, and domain-aware evaluation strategies.", "AI": {"tldr": "该研究评估了VLMs在农业分类任务上的性能，发现当前的VLMs在提供独立的农业诊断方面还不够可靠，但在特定条件下，如与约束提示和领域评估策略结合时，可以作为辅助工具使用。", "motivation": "随着视觉-语言模型（VLMs）被提出作为通用视觉识别任务解决方案，它们在农业决策支持中的可靠性尚不明确。本文旨在评估这些模型在农业分类任务上的表现，特别是在零样本和多选择提示条件下的表现。", "method": "该研究对来自AgML集合的27个农业分类数据集上的开源和闭源视觉-语言模型（VLMs）进行了性能基准测试，这些数据集涵盖了162个类别，包括植物疾病、害虫和损害，以及植物和杂草种类的识别。测试包含零样本和多种选择提示方法。", "result": "零样本VLMs在所有任务上的表现显著低于监督任务特定基线（如YOLO11）。使用多选项提示时，表现最好的VLM（Gemini-3 Pro）达到了大约62%的平均准确率，而开放式提示则显著降低了准确率，通常低于25%。当使用LLM进行语义判断时，准确率得到提升，例如从21%提高到30%。开源模型Qwen-VL-72B表现最佳，尽管在约束提示下接近闭源模型的表现，但仍然落后于顶级闭源系统。在任务级别分析中，植物和杂草种类分类相对比害虫和损害识别更加容易。", "conclusion": "当前现成的VLMs尚未作为独立的农业诊断系统适用，但在与约束界面、明确标签本体以及具有领域意识的评估策略相结合时，可以作为辅助组件发挥作用。"}}
{"id": "2512.16229", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16229", "abs": "https://arxiv.org/abs/2512.16229", "authors": ["Chenkai Xu", "Yijie Jin", "Jiajun Li", "Yi Tu", "Guoping Long", "Dandan Tu", "Tianqi Hou", "Junchi Yan", "Zhijie Deng"], "title": "LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding", "comment": null, "summary": "Diffusion Large Language Models (dLLMs) have demonstrated significant potential for high-speed inference. However, current confidence-driven decoding strategies are constrained by limited parallelism, typically achieving only 1--3 tokens per forward pass (TPF). In this work, we identify that the degree of parallelism during dLLM inference is highly sensitive to the Token Filling Order (TFO). Then, we introduce Lookahead PArallel Decoding LoPA, a training-free, plug-and-play algorithm, to identify a superior TFO and hence accelerate inference. LoPA concurrently explores distinct candidate TFOs via parallel branches, and selects the one with the highest potential for future parallelism based on branch confidence. We apply LoPA to the state-of-the-art D2F model and observe a substantial enhancement in decoding efficiency. Notably, LoPA increases the TPF of D2F-Dream to 10.1 on the GSM8K while maintaining performance superior to the Dream baseline. Furthermore, to facilitate this unprecedented degree of parallelism, we develop a specialized multi-device inference system featuring Branch Parallelism (BP), which achieves a single-sample throughput of 1073.9 tokens per second under multi-GPU deployment. The code is available at https://github.com/zhijie-group/LoPA.", "AI": {"tldr": "LoPA算法提高了dLLMs的解码效率，将D2F-Dream模型的TPF在GSM8K数据集上提升到了10.1，同时保持了优越的性能。", "motivation": "当前基于信心的解码策略受限于并行性，只达到1-3 tokens per forward pass（TPF），本研究旨在提高扩散大语言模型（dLLMs）的并行性以实现更高效的推理。", "method": "引入了LoPA算法，通过并行分支探索不同的Token填充顺序（TFO），选择未来并行潜力最大的TFO以加速推理。", "result": "应用LoPA后，D2F-Dream模型的TPF在GSM8K上达到10.1，性能超越基线Dream模型。多GPU部署下单样本吞吐量达1073.9 tokens per second。", "conclusion": "LoPA算法作为无训练、即插即用的方法，通过提高并行性显著增强了dLLMs的推理效率，展现出优秀的加速效果。"}}
{"id": "2512.15993", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.15993", "abs": "https://arxiv.org/abs/2512.15993", "authors": ["Lars Beckers", "Arno Waes", "Aaron Van Campenhout", "Toon Goedemé"], "title": "Eyes on the Grass: Biodiversity-Increasing Robotic Mowing Using Deep Visual Embeddings", "comment": null, "summary": "This paper presents a robotic mowing framework that actively enhances garden biodiversity through visual perception and adaptive decision-making. Unlike passive rewilding approaches, the proposed system uses deep feature-space analysis to identify and preserve visually diverse vegetation patches in camera images by selectively deactivating the mower blades. A ResNet50 network pretrained on PlantNet300K provides ecologically meaningful embeddings, from which a global deviation metric estimates biodiversity without species-level supervision. These estimates drive a selective mowing algorithm that dynamically alternates between mowing and conservation behavior. The system was implemented on a modified commercial robotic mower and validated both in a controlled mock-up lawn and on real garden datasets. Results demonstrate a strong correlation between embedding-space dispersion and expert biodiversity assessment, confirming the feasibility of deep visual diversity as a proxy for ecological richness and the effectiveness of the proposed mowing decision approach. Widespread adoption of such systems will turn ecologically worthless, monocultural lawns into vibrant, valuable biotopes that boost urban biodiversity.", "AI": {"tldr": "A robotic mowing system uses deep learning to promote garden biodiversity by selectively mowing areas, preserving diverse vegetation, and transforming monocultural lawns into biodiverse biotopes.", "motivation": "The motivation is to actively enhance garden biodiversity by overcoming the limitations of passive rewilding methods, which typically lead to monocultural environments. The objective is to promote a more ecologically rich landscape using smart robotic technology.", "method": "This paper integrates a deep learning approach (ResNet50 pretrained on PlantNet300K) to evaluate biodiversity through visual perception. It develops a selective mowing algorithm based on the global deviation metric estimated from the deep learning embeddings, enabling the robotic mower to switch between mowing and conservation actions.", "result": "The system was tested both in controlled environments and real garden settings. It showed a high correlation between the biodiversity estimates derived from the embeddings and the expert biodiversity assessments, validating the effectiveness of the method.", "conclusion": "The paper concludes that visual diversity embeddings can serve as an effective proxy for ecological richness and that the proposed robotic mowing system can successfully enhance urban garden biodiversity, suggesting a practical path towards ecology-friendly urban design."}}
{"id": "2512.16248", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16248", "abs": "https://arxiv.org/abs/2512.16248", "authors": ["Qingguo Hu", "Zhenghao Lin", "Ziyue Yang", "Yucheng Ding", "Xiao Liu", "Yuting Jiang", "Ruizhe Wang", "Tianyu Chen", "Zhongxin Guo", "Yifan Xiong", "Rui Gao", "Lei Qu", "Jinsong Su", "Peng Cheng", "Yeyun Gong"], "title": "Sigma-Moe-Tiny Technical Report", "comment": null, "summary": "Mixture-of-Experts (MoE) has emerged as a promising paradigm for foundation models due to its efficient and powerful scalability. In this work, we present Sigma-MoE-Tiny, an MoE language model that achieves the highest sparsity compared to existing open-source models. Sigma-MoE-Tiny employs fine-grained expert segmentation with up to 96 experts per layer, while activating only one expert for each token, resulting in 20B total parameters with just 0.5B activated. The major challenge introduced by such extreme sparsity lies in expert load balancing. We find that the widely-used load balancing loss tends to become ineffective in the lower layers under this setting. To address this issue, we propose a progressive sparsification schedule aiming to balance expert utilization and training stability. Sigma-MoE-Tiny is pre-trained on a diverse and high-quality corpus, followed by post-training to further unlock its capabilities. The entire training process remains remarkably stable, with no occurrence of irrecoverable loss spikes. Comprehensive evaluations reveal that, despite activating only 0.5B parameters, Sigma-MoE-Tiny achieves top-tier performance among counterparts of comparable or significantly larger scale. In addition, we provide an in-depth discussion of load balancing in highly sparse MoE models, offering insights for advancing sparsity in future MoE architectures.\n  Project page: https://qghuxmu.github.io/Sigma-MoE-Tiny\n  Code: https://github.com/microsoft/ltp-megatron-lm", "AI": {"tldr": "Sigma-MoE-Tiny,一种高效的大规模模型新范式，通过精细的专家分割和极端的稀疏化技术，在激活参数量仅为0.5B的情况下，实现了20B参数的高效处理。为了应对由此产生的负载均衡挑战，文章提出了一种渐进式的稀疏化调度策略。实验结果显示，尽管只激活了0.5B参数，Sigma-MoE-Tiny的性能仍与较大规模的模型相当。", "motivation": "探索更高效的模型稀疏化技术，解决传统混合专家模型在极端稀疏化条件下负载均衡失效的问题。", "method": "引入了精细的专家分割，并在每层使用多达96个专家，通过激活每个token的单个专家实现高稀疏化。为了平衡专家利用率与训练稳定性，提出了一种渐进式的稀疏化调度策略。", "result": "整个训练过程非常稳定，没有出现不可恢复的loss峰值。在各种评估中，Sigma-MoE-Tiny的性能达到顶级水平，尤其是在激活参数量仅为0.5B的情况下。", "conclusion": "文章指出了在高度稀疏的混合专家模型中实现负载均衡的重要性，并提供了关于如何进一步稀疏化未来混合专家架构的建议。"}}
{"id": "2512.16023", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2512.16023", "abs": "https://arxiv.org/abs/2512.16023", "authors": ["Liudi Yang", "Yang Bai", "George Eskandar", "Fengyi Shen", "Mohammad Altillawi", "Dong Chen", "Ziyuan Liu", "Abhinav Valada"], "title": "CoVAR: Co-generation of Video and Action for Robotic Manipulation via Multi-Modal Diffusion", "comment": "9 pages, 7 figures", "summary": "We present a method to generate video-action pairs that follow text instructions, starting from an initial image observation and the robot's joint states. Our approach automatically provides action labels for video diffusion models, overcoming the common lack of action annotations and enabling their full use for robotic policy learning. Existing methods either adopt two-stage pipelines, which limit tightly coupled cross-modal information sharing, or rely on adapting a single-modal diffusion model for a joint distribution that cannot fully leverage pretrained video knowledge. To overcome these limitations, we (1) extend a pretrained video diffusion model with a parallel, dedicated action diffusion model that preserves pretrained knowledge, (2) introduce a Bridge Attention mechanism to enable effective cross-modal interaction, and (3) design an action refinement module to convert coarse actions into precise controls for low-resolution datasets. Extensive evaluations on multiple public benchmarks and real-world datasets demonstrate that our method generates higher-quality videos, more accurate actions, and significantly outperforms existing baselines, offering a scalable framework for leveraging large-scale video data for robotic learning.", "AI": {"tldr": "提出一种生成遵循文本指令的视频-动作配对的方法，改善机器人策略学习。", "motivation": "解决视频扩散模型中缺乏动作标注的问题，提高跨模态信息共享效率，以及利用预训练视频知识。", "method": "扩展预训练的视频扩散模型，加入并行的动作扩散模型，引入Bridge Attention机制，设计动作细化模块。", "result": "在多个公开基准和实际数据集上的广泛评估表明，提出的方法生成更高质量的视频和更精确的动作，并显著优于现有基线。", "conclusion": "提出的方法为利用大规模视频数据进行机器人学习提供了一个可扩展的框架。"}}
{"id": "2512.16287", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2512.16287", "abs": "https://arxiv.org/abs/2512.16287", "authors": ["Yehor Tereshchenko", "Mika Hämäläinen", "Svitlana Myroniuk"], "title": "Evaluating OpenAI GPT Models for Translation of Endangered Uralic Languages: A Comparison of Reasoning and Non-Reasoning Architectures", "comment": "IWCLUL 2025", "summary": "The evaluation of Large Language Models (LLMs) for translation tasks has primarily focused on high-resource languages, leaving a significant gap in understanding their performance on low-resource and endangered languages. This study presents a comprehensive comparison of OpenAI's GPT models, specifically examining the differences between reasoning and non-reasoning architectures for translating between Finnish and four low-resource Uralic languages: Komi-Zyrian, Moksha, Erzya, and Udmurt. Using a parallel corpus of literary texts, we evaluate model willingness to attempt translation through refusal rate analysis across different model architectures. Our findings reveal significant performance variations between reasoning and non-reasoning models, with reasoning models showing 16 percentage points lower refusal rates. The results provide valuable insights for researchers and practitioners working with Uralic languages and contribute to the broader understanding of reasoning model capabilities for endangered language preservation.", "AI": {"tldr": "本研究通过文学文本的平行语料库，对比了GPT在翻译芬兰语和四种低资源乌拉尔语时的推理和非推理模型的性能，发现推理模型的翻译意愿更高。", "motivation": "本研究旨在填补大型语言模型（LLMs）在翻译任务中对低资源和濒危语种性能评估的空白，重点关注高资源语言之外的领域。", "method": "本研究通过分析OpenAI的GPT模型，特别是关注推理和非推理架构在芬兰语和四种低资源乌拉尔语（科米-齐良语、莫克沙语、尔齐亚语和乌德穆尔特语）之间的翻译性能差异。使用一套文学文本的平行语料库，研究通过拒绝率分析来评估不同模型架构的翻译倾向。", "result": "研究结果揭示了推理和非推理模型之间的显著性能差异：推理模型的拒绝率降低了16个百分点。", "conclusion": "研究为乌拉尔语的研究人员和从业者提供了有价值的见解，并有助于更广泛地了解推理模型在濒危语言保护方面的能力。"}}
