<div id=toc></div>

# Table of Contents

- [cs.CL](#cs.CL) [Total: 7]
- [cs.CV](#cs.CV) [Total: 3]


<div id='cs.CL'></div>

# cs.CL [[Back]](#toc)

### [1] [ASR Under the Stethoscope: Evaluating Biases in Clinical Speech Recognition across Indian Languages](https://arxiv.org/abs/2512.10967)
*Subham Kumar,Prakrithi Shivaprakash,Abhishek Manoharan,Astut Kurariya,Diptadhi Mukherjee,Lekhansh Shukla,Animesh Mukherjee,Prabhat Chand,Pratima Murthy*

Main category: cs.CL

> 研究系统地评估了几种自动语音识别模型在印度多种语言和人群中的表现，揭示了模型在不同语言、说话者角色和性别上的性能差异，强调需要开发具有文化与人口包容性的ASR模型。

<details>
  <summary>Details</summary>

**Motivation:** 评估ASR技术在多元文化和人口结构复杂的印度医疗环境中的可靠性和有效性。

**Method:** 对包括Indic Whisper、Whisper、Sarvam等在内的几种ASR模型进行比较，评估它们在印度英语、卡纳达语和印地语中的转录准确性。

**Result:** 不同ASR模型在不同语言、说话者和性别上的性能存在显著差异，有些系统在印度英语上有较好的表现，但对混杂或地方语言表现不佳。

**Conclusion:** 研究强调，为了消除在临床环境中部署所面临的不平等，需要开发更具有文化与人口包容性的ASR模型。

**Abstract:** Automatic Speech Recognition (ASR) is increasingly used to document clinical encounters, yet its reliability in multilingual and demographically diverse Indian healthcare contexts remains largely unknown. In this study, we conduct the first systematic audit of ASR performance on real world clinical interview data spanning Kannada, Hindi, and Indian English, comparing leading models including Indic Whisper, Whisper, Sarvam, Google speech to text, Gemma3n, Omnilingual, Vaani, and Gemini. We evaluate transcription accuracy across languages, speakers, and demographic subgroups, with a particular focus on error patterns affecting patients vs. clinicians and gender based or intersectional disparities. Our results reveal substantial variability across models and languages, with some systems performing competitively on Indian English but failing on code mixed or vernacular speech. We also uncover systematic performance gaps tied to speaker role and gender, raising concerns about equitable deployment in clinical settings. By providing a comprehensive multilingual benchmark and fairness analysis, our work highlights the need for culturally and demographically inclusive ASR development for healthcare ecosystem in India.

</details>


### [2] [Benchmarking Automatic Speech Recognition Models for African Languages](https://arxiv.org/abs/2512.10968)
*Alvin Nahabwe,Sulaiman Kagumire,Denis Musinguzi,Bruno Beijuka,Jonah Mubuuke Kyagaba,Peter Nabende,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CL

> 该研究对比了四种最先进的自动语音识别（ASR）模型在13种非洲语言中的表现，并探讨了在不同数据量和资源条件下模型的行为差异，为设计面向资源缺乏语言的ASR系统提供了实践指导。

<details>
  <summary>Details</summary>

**Motivation:** 当前自动语音识别技术在非洲语言上的应用受到训练数据不足和模型选择缺乏指导等因素的限制，因此旨在通过对几种最新预训练系统的比较分析，为非洲低资源语言环境下的模型选择和数据应用策略提供系统性指导。

**Method:** 研究在13种非洲语言上对四种最先进的ASR模型（Whisper, XLS-R, MMS, W2v-BERT）进行基准测试，通过在增加的数据量上进行微调，并评估外部语言模型解码的效果和限制。

**Result:** 结果显示，在非常低资源情况下，MMS和W2v-BERT模型效率更高；在中资源条件下，Whisper表现较好；随着数据增加，XLS-R模型效果提升更显著。

**Conclusion:** 研究揭示了预训练覆盖范围、模型结构、数据集领域以及资源可用性之间的交互作用，为设计面向未被充分代表语言的ASR系统提供了深入见解。

**Abstract:** Automatic speech recognition (ASR) for African languages remains constrained by limited labeled data and the lack of systematic guidance on model selection, data scaling, and decoding strategies. Large pre-trained systems such as Whisper, XLS-R, MMS, and W2v-BERT have expanded access to ASR technology, but their comparative behavior in African low-resource contexts has not been studied in a unified and systematic way. In this work, we benchmark four state-of-the-art ASR models across 13 African languages, fine-tuning them on progressively larger subsets of transcribed data ranging from 1 to 400 hours. Beyond reporting error rates, we provide new insights into why models behave differently under varying conditions. We show that MMS and W2v-BERT are more data efficient in very low-resource regimes, XLS-R scales more effectively as additional data becomes available, and Whisper demonstrates advantages in mid-resource conditions. We also analyze where external language model decoding yields improvements and identify cases where it plateaus or introduces additional errors, depending on the alignment between acoustic and text resources. By highlighting the interaction between pre-training coverage, model architecture, dataset domain, and resource availability, this study offers practical and insights into the design of ASR systems for underrepresented languages.

</details>


### [3] [MedBioRAG: Semantic Search and Retrieval-Augmented Generation with Large Language Models for Medical and Biological QA](https://arxiv.org/abs/2512.10996)
*Seonok Kim*

Main category: cs.CL

> 本文提出MedBioRAG模型，通过语义搜索和文档检索等技术显著提升了生物医学领域问答任务的性能，并在多项基准数据集上取得了优于现有最佳模型的表现。

<details>
  <summary>Details</summary>

**Motivation:** 最近检索增强生成（RAG）技术的进步显著提升了大型语言模型在复杂问答任务中的表现。本文旨在通过MedBioRAG模型进一步改善生物医学领域的问题答案准确性。

**Method:** 本文介绍了一种名为MedBioRAG的检索增强模型，该模型结合语义和词汇搜索、文档检索和监督微调，旨在提升生物医学领域的问答任务性能。

**Result:** 实验结果显示，MedBioRAG在所有评估任务中均优于之前的最优模型和GPT-4o基础模型，尤其是在文档检索的NDCG和MRR评分，以及闭合问答和长格式问答中取得了更高的准确性和ROUGE评分。

**Conclusion:** 研究结果强调了基于语义搜索的检索技术与大型语言模型的微调在生物医学应用中的有效性。

**Abstract:** Recent advancements in retrieval-augmented generation (RAG) have significantly enhanced the ability of large language models (LLMs) to perform complex question-answering (QA) tasks. In this paper, we introduce MedBioRAG, a retrieval-augmented model designed to improve biomedical QA performance through a combination of semantic and lexical search, document retrieval, and supervised fine-tuning. MedBioRAG efficiently retrieves and ranks relevant biomedical documents, enabling precise and context-aware response generation. We evaluate MedBioRAG across text retrieval, close-ended QA, and long-form QA tasks using benchmark datasets such as NFCorpus, TREC-COVID, MedQA, PubMedQA, and BioASQ. Experimental results demonstrate that MedBioRAG outperforms previous state-of-the-art (SoTA) models and the GPT-4o base model in all evaluated tasks. Notably, our approach improves NDCG and MRR scores for document retrieval, while achieving higher accuracy in close-ended QA and ROUGE scores in long-form QA. Our findings highlight the effectiveness of semantic search-based retrieval and LLM fine-tuning in biomedical applications.

</details>


### [4] [KBQA-R1: Reinforcing Large Language Models for Knowledge Base Question Answering](https://arxiv.org/abs/2512.10999)
*Xin Sun,Zhongqi Chen,Xing Zheng,Qiang Liu,Shu Wu,Bowen Song,Zilei Wang,Weiqiang Wang,Liang Wang*

Main category: cs.CL

> KBQA-R1是一种基于强化学习的框架，改进了知识图谱查询语言模型方法，有效解决了生成不合理查询和模板化推理的问题，显著提高了KBQA的性能。

<details>
  <summary>Details</summary>

**Motivation:** 现有的KBQA方法主要存在两个问题：生成无法验证的查询或者严格的模板推理，缺乏对环境的真实理解。因此，本文提出KBQA-R1框架以解决以上局限。

**Method:** 通过引入KBQA-R1框架，将KBQA视为多轮决策过程，利用强化学习优化交互，并使用Group Relative Policy Optimization (GRPO) 根据实际执行反馈调整策略。此外，提出Referenced Rejection Sampling (RRS) 方法生成与真实动作序列严格对齐的推理轨迹，以解决冷启动问题。

**Result:** 在WebQSP、GrailQA、GraphQuestions等数据集上的实验表明，KBQA-R1达到了最先进性能，有效将LLM推理锚定于可验证的执行结果。

**Conclusion:** KBQA-R1框架通过强化学习优化交互过程，解决了知识图谱查询中的冷启动问题，并提高KBQA的性能和可验证性。

**Abstract:** Knowledge Base Question Answering (KBQA) challenges models to bridge the gap between natural language and strict knowledge graph schemas by generating executable logical forms. While Large Language Models (LLMs) have advanced this field, current approaches often struggle with a dichotomy of failure: they either generate hallucinated queries without verifying schema existence or exhibit rigid, template-based reasoning that mimics synthesized traces without true comprehension of the environment. To address these limitations, we present \textbf{KBQA-R1}, a framework that shifts the paradigm from text imitation to interaction optimization via Reinforcement Learning. Treating KBQA as a multi-turn decision process, our model learns to navigate the knowledge base using a list of actions, leveraging Group Relative Policy Optimization (GRPO) to refine its strategies based on concrete execution feedback rather than static supervision. Furthermore, we introduce \textbf{Referenced Rejection Sampling (RRS)}, a data synthesis method that resolves cold-start challenges by strictly aligning reasoning traces with ground-truth action sequences. Extensive experiments on WebQSP, GrailQA, and GraphQuestions demonstrate that KBQA-R1 achieves state-of-the-art performance, effectively grounding LLM reasoning in verifiable execution.

</details>


### [5] [PIAST: Rapid Prompting with In-context Augmentation for Scarce Training data](https://arxiv.org/abs/2512.11013)
*Pawel Batorski,Paul Swoboda*

Main category: cs.CL

> 论文介绍了一种新的、自动化的提示构造算法，通过生成少量示例来提升提示质量，这种方法在多个任务上超越了现有方法，证明了精心构造的示例对于提升语言模型的有效性至关重要。

<details>
  <summary>Details</summary>

**Motivation:** 大语言模型对提示设计非常敏感，但手工制作有效的提示既困难又需要精细地设计少量示例。

**Method:** 本论文提出了一种快速自动提示构造算法，该算法通过使用蒙特卡洛夏普利估计来迭代替换/删除/保留少量示例，从而通过生成少量示例来增强人工指令。为了加速执行，该方法采用了积极的子采样和回放缓冲区进行快速评估。

**Result:** 该方法在使用不同计算时间预算时，可以超越现有的自动提示方法，在文本简化和GSM8K上取得了更好的效果，并且在分类和摘要任务上取得了第二好的效果。延长但仍有限的计算预算下，该方法在分类、简化和GSM8K上建立了新的自动提示方法的基准。

**Conclusion:** 结果表明，精心构造的示例，而不是广泛的指令搜索，是快速和数据高效的提示工程的主要杠杆。

**Abstract:** LLMs are highly sensitive to prompt design, but handcrafting effective prompts is difficult and often requires intricate crafting of few-shot examples. We propose a fast automatic prompt construction algorithm that augments human instructions by generating a small set of few shot examples. Our method iteratively replaces/drops/keeps few-shot examples using Monte Carlo Shapley estimation of example utility. For faster execution, we use aggressive subsampling and a replay buffer for faster evaluations. Our method can be run using different compute time budgets. On a limited budget, we outperform existing automatic prompting methods on text simplification and GSM8K and obtain second best results on classification and summarization. With an extended, but still modest compute budget we set a new state of the art among automatic prompting methods on classification, simplification and GSM8K. Our results show that carefully constructed examples, rather than exhaustive instruction search, are the dominant lever for fast and data efficient prompt engineering. Our code is available at https://github.com/Batorskq/PIAST.

</details>


### [6] [MultiScript30k: Leveraging Multilingual Embeddings to Extend Cross Script Parallel Data](https://arxiv.org/abs/2512.11074)
*Christopher Driggers-Ellis,Detravious Brinkley,Ray Chen,Aashish Dhawan,Daisy Zhe Wang,Christan Grant*

Main category: cs.CL

> 本文提出了MultiScript30k，这是一个新的Multi30k数据集扩展，涵盖了更多全球语言和书写系统，由NLLB200-3.3B将Multi30k的英语版本翻译成其他多种语言版本，解决了之前数据集只支持欧洲拉丁字母语言的问题。

<details>
  <summary>Details</summary>

**Motivation:** Multi30k数据集只限于四种欧洲语言，阻碍了在其他语言上的多模态机器翻译研究，作者旨在扩展Multi30k以支持更多语言和书写系统。

**Method:** 使用NLLB200-3.3B将Multi30k的英语版本翻译成其他语言版本，创建了MultiScript30k，包含超过30000句子的翻译。

**Result:** 相似性分析显示MultiScript30k的翻译质量高，尤其是在所有支持的语言上（除了Zh_Hant），评分和以前的拓展类似或优于之。

**Conclusion:** MultiScript30k是一个有用的数据集扩展，虽然在某些方面逊色于特定语言的扩展版本，但它极大地丰富了可用于多模态机器翻译研究的语言范围。

**Abstract:** Multi30k is frequently cited in the multimodal machine translation (MMT) literature, offering parallel text data for training and fine-tuning deep learning models. However, it is limited to four languages: Czech, English, French, and German. This restriction has led many researchers to focus their investigations only on these languages. As a result, MMT research on diverse languages has been stalled because the official Multi30k dataset only represents European languages in Latin scripts. Previous efforts to extend Multi30k exist, but the list of supported languages, represented language families, and scripts is still very short. To address these issues, we propose MultiScript30k, a new Multi30k dataset extension for global languages in various scripts, created by translating the English version of Multi30k (Multi30k-En) using NLLB200-3.3B. The dataset consists of over \(30000\) sentences and provides translations of all sentences in Multi30k-En into Ar, Es, Uk, Zh\_Hans and Zh\_Hant. Similarity analysis shows that Multi30k extension consistently achieves greater than \(0.8\) cosine similarity and symmetric KL divergence less than \(0.000251\) for all languages supported except Zh\_Hant which is comparable to the previous Multi30k extensions ArEnMulti30k and Multi30k-Uk. COMETKiwi scores reveal mixed assessments of MultiScript30k as a translation of Multi30k-En in comparison to the related work. ArEnMulti30k scores nearly equal MultiScript30k-Ar, but Multi30k-Uk scores $6.4\%$ greater than MultiScript30k-Uk per split.

</details>


### [7] [Applying NLP to iMessages: Understanding Topic Avoidance, Responsiveness, and Sentiment](https://arxiv.org/abs/2512.11079)
*Alan Gerber,Sam Cooperman*

Main category: cs.CL

> 研究开发了一个针对iMessage的文本信息分析器，通过该分析器可以进行主题模型的建立、回应时间分析、犹豫度评分和情感分析等研究，展示了这种分析方式在进一步研究iMessage数据中的潜力。

<details>
  <summary>Details</summary>

**Motivation:** 随着社会对短格式电子通信的日益依赖，本研究旨在探讨在用户不常考虑的自己通过消息平台所泄露的信息中，数据的潜在用途，特别是苹果公司对于iMessage数据的处理策略。

**Method:** 本研究采用了文本分析方法，包括主题建模、响应时间分析、犹豫度评分及情感分析，创建了一个iMessage文本信息分析器来回答关于这些方面的五个主要研究问题。

**Result:** 研究结果显示所创建的分析器能够有效回答关于主题建模、响应时间、犹豫度评分和情感分析等多个方面的问题，并揭示了这些分析方法在今后研究中的潜在价值。

**Conclusion:** 本研究通过开发一款用于分析iMessage的工具，展示了用户数据的分析潜力。通过对消息元数据进行分析，可揭示用户行为模式，拓展了对未来研究的见解。

**Abstract:** What is your messaging data used for? While many users do not often think about the information companies can gather based off of their messaging platform of choice, it is nonetheless important to consider as society increasingly relies on short-form electronic communication. While most companies keep their data closely guarded, inaccessible to users or potential hackers, Apple has opened a door to their walled-garden ecosystem, providing iMessage users on Mac with one file storing all their messages and attached metadata. With knowledge of this locally stored file, the question now becomes: What can our data do for us? In the creation of our iMessage text message analyzer, we set out to answer five main research questions focusing on topic modeling, response times, reluctance scoring, and sentiment analysis. This paper uses our exploratory data to show how these questions can be answered using our analyzer and its potential in future studies on iMessage data.

</details>


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [8] [Leveraging Text Guidance for Enhancing Demographic Fairness in Gender Classification](https://arxiv.org/abs/2512.11015)
*Anoop Krishnan*

Main category: cs.CV

> 該論文通過語義信息引導來改善面部圖像性別分類算法的公平性，並提出圖像文本匹配(ITM)引導和圖像文本融合兩種方法，實驗結果表明該方法能夠有效減少偏見，提高在不同性別和種族群體間的準確性。

<details>
  <summary>Details</summary>

**Motivation:** 該論文的主要動機是在人工智慧中尋求公平性，並提出通過使用文本引導的方法來增強基於面部圖像的性別分類算法的公平性。

**Method:** 分析顯示該論文採用兩種策略來改善基於面部圖像的性別分類算法的公平性：圖像文本匹配(ITM)引導和圖像文本融合。ITM引導訓練模型以分辨圖像和文本之間的細微差異，以獲得增強的多模態表示。圖像文本融合則將兩種模態融合為全面的表示，以改善公平性。

**Result:** 實驗結果顯示，這些方法可以有效地減少偏差，提高面部圖像基於性別和種族分類的準確性，相較於現有方法更具優勢。

**Conclusion:** 通過研究語義信息如何減少差異，本研究為培育更具公允性的面部分析算法提供了寶貴的見解。提出的方法學對應對面部圖像性別分類中的人口統計偏差挑戰起到了貢獻作用。

**Abstract:** In the quest for fairness in artificial intelligence, novel approaches to enhance it in facial image based gender classification algorithms using text guided methodologies are presented. The core methodology involves leveraging semantic information from image captions during model training to improve generalization capabilities. Two key strategies are presented: Image Text Matching (ITM) guidance and Image Text fusion. ITM guidance trains the model to discern fine grained alignments between images and texts to obtain enhanced multimodal representations. Image text fusion combines both modalities into comprehensive representations for improved fairness. Exensive experiments conducted on benchmark datasets demonstrate these approaches effectively mitigate bias and improve accuracy across gender racial groups compared to existing methods. Additionally, the unique integration of textual guidance underscores an interpretable and intuitive training paradigm for computer vision systems. By scrutinizing the extent to which semantic information reduces disparities, this research offers valuable insights into cultivating more equitable facial analysis algorithms. The proposed methodologies contribute to addressing the pivotal challenge of demographic bias in gender classification from facial images. Furthermore, this technique operates in the absence of demographic labels and is application agnostic.

</details>


### [9] [SoccerMaster: A Vision Foundation Model for Soccer Understanding](https://arxiv.org/abs/2512.11016)
*Haolin Yang,Jiayuan Rao,Haoning Wu,Weidi Xie*

Main category: cs.CV

> 本文提出了SoccerMaster——一种能处理多种足球视觉理解任务的最终模型，并通过一个自动化数据整理管道构建了一个全面的预训练数据资源SoccerFactory。

<details>
  <summary>Details</summary>

**Motivation:** 相比于过去的研究通常依赖于孤立的任务特定专家模型，本文旨在为足球领域的视觉理解提供一个统一的模型解决方案，应对该领域的具体复杂性与挑战。

**Method:** 本文提出了SoccerMaster，一种针对足球领域的统一视觉基础模型，通过监督多任务预训练统一处理多种足球视觉理解任务，从精细感知（例如，运动员检测）到语义推理（例如，事件分类）。同时，开发了自动化数据整理管道，以生成可扩展的空间注释，并与现有足球视频数据集结合，构建了SoccerFactory，一个全面的预训练数据资源。

**Result:** 实验结果表明，SoccerMaster在各种下游任务中持续优于任务特定的专家模型，显示出其广度和优势。

**Conclusion:** SoccerMaster在处理多种足球视觉理解任务上表现出色，优于任务特定的专家模型，证实了其在广度和性能上的优势。数据、代码和模型将会公开。

**Abstract:** Soccer understanding has recently garnered growing research interest due to its domain-specific complexity and unique challenges. Unlike prior works that typically rely on isolated, task-specific expert models, this work aims to propose a unified model to handle diverse soccer visual understanding tasks, ranging from fine-grained perception (e.g., athlete detection) to semantic reasoning (e.g., event classification). Specifically, our contributions are threefold: (i) we present SoccerMaster, the first soccer-specific vision foundation model that unifies diverse understanding tasks within a single framework via supervised multi-task pretraining; (ii) we develop an automated data curation pipeline to generate scalable spatial annotations, and integrate them with various existing soccer video datasets to construct SoccerFactory, a comprehensive pretraining data resource; and (iii) we conduct extensive evaluations demonstrating that SoccerMaster consistently outperforms task-specific expert models across diverse downstream tasks, highlighting its breadth and superiority. The data, code, and model will be publicly available.

</details>


### [10] [Weakly Supervised Tuberculosis Localization in Chest X-rays through Knowledge Distillation](https://arxiv.org/abs/2512.11057)
*Marshal Ashif Shawkat,Moidul Hasan,Taufiq Hasan*

Main category: cs.CV

> 研究提出了一种基于知识蒸馏技术的CNN模型训练方法，旨在减少非相关性，并改善在结核病影像中的异常定位。

<details>
  <summary>Details</summary>

**Motivation:** 尽管机器学习模型在结核病分类中表现出色，但它们往往依赖于非相关的关联性，并且难以泛化。此外，构建高质量标注的大型医学影像数据集需要大量资源。

**Method:** 本研究利用知识蒸馏技术训练CNN模型，减少非相关性依赖，并定位与结核病相关的异常，无需边界框注释。通过采用ResNet50架构的师生框架进行训练。

**Result:** 在TBX11k数据集上的实验表明，该方法在学生模型中获得了0.2428的mIOU得分，并且学生模型表现优于教师模型，显示出更好的鲁棒性和在多种设置中的潜在临床应用价值。

**Conclusion:** 实验结果表明，该方法在改进模型的鲁棒性和潜在的临床应用中具有明显的优势，特别是在资源有限的国家或地区。

**Abstract:** Tuberculosis (TB) remains one of the leading causes of mortality worldwide, particularly in resource-limited countries. Chest X-ray (CXR) imaging serves as an accessible and cost-effective diagnostic tool but requires expert interpretation, which is often unavailable. Although machine learning models have shown high performance in TB classification, they often depend on spurious correlations and fail to generalize. Besides, building large datasets featuring high-quality annotations for medical images demands substantial resources and input from domain specialists, and typically involves several annotators reaching agreement, which results in enormous financial and logistical expenses. This study repurposes knowledge distillation technique to train CNN models reducing spurious correlations and localize TB-related abnormalities without requiring bounding-box annotations. By leveraging a teacher-student framework with ResNet50 architecture, the proposed method trained on TBX11k dataset achieve impressive 0.2428 mIOU score. Experimental results further reveal that the student model consistently outperforms the teacher, underscoring improved robustness and potential for broader clinical deployment in diverse settings.

</details>
