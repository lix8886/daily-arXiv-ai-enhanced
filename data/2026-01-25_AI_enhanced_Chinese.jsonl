{"id": "2601.15296", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15296", "abs": "https://arxiv.org/abs/2601.15296", "authors": ["Longxuan Wei", "Yubo Zhang", "Zijiao Zhang", "Zhihu Wang", "Shiwan Zhao", "Tianyu Huang", "Huiting Zhao", "Chenfei Liu", "Shenao Zhang", "Junchi Yan"], "title": "Entropy-Tree: Tree-Based Decoding with Entropy-Guided Exploration", "comment": null, "summary": "Large language models achieve strong reasoning performance, yet existing decoding strategies either explore blindly (random sampling) or redundantly (independent multi-sampling). We propose Entropy-Tree, a tree-based decoding method that exploits entropy as a signal for branching decisions--expanding the search tree only at positions where the model exhibits genuine uncertainty. Entropy-Tree shows superior accuracy and calibration in reasoning tasks: it achieves better pass@k than Multi-chain across multiple models and datasets, and its predictive entropy demonstrates better AUROC compared to several traditional metrics. Entropy-Tree unifies efficient structured exploration and reliable uncertainty estimation within a single decoding procedure.", "AI": {"tldr": "The paper introduces Entropy-Tree, a decoding strategy that enhances the accuracy and calibration of reasoning tasks by utilizing entropy to guide its decisions.", "motivation": "To address the limitations of existing decoding strategies that either explore blindly or redundantly, leading to insufficient reasoning performance.", "method": "Entropy-Tree, a tree-based decoding method that uses entropy signals for branching decisions during the generation process.", "result": "Entropy-Tree achieves better pass@k than Multi-chain in various models and datasets and exhibits improved AUROC for predictive entropy compared to traditional evaluation methods.", "conclusion": "Entropy-Tree improves the efficiency and reliability of structured exploration and uncertainty estimation in language models."}}
{"id": "2601.15297", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.15297", "abs": "https://arxiv.org/abs/2601.15297", "authors": ["Edward Ajayi"], "title": "AfriEconQA: A Benchmark Dataset for African Economic Analysis based on World Bank Reports", "comment": null, "summary": "We introduce AfriEconQA, a specialized benchmark dataset for African economic analysis grounded in a comprehensive corpus of 236 World Bank reports. The task of AfriEconQA is to answer complex economic queries that require high-precision numerical reasoning and temporal disambiguation from specialized institutional documents. The dataset consists of 8,937 curated QA instances, rigorously filtered from a pool of 10018 synthetic questions to ensure high-quality evidence-answer alignment. Each instance is composed of: (1) a question requiring reasoning over economic indicators, (2) the corresponding evidence retrieved from the corpus, (3) a verified ground-truth answer, and (4) source metadata (e.g., URL and publication date) to ensure temporal provenance. AfriEconQA is the first benchmark focused specifically on African economic analysis, providing a unique challenge for Information Retrieval (IR) systems, as the data is largely absent from the pretraining corpora of current Large Language Models (LLMs). We operationalize this dataset through an 11-experiment matrix, benchmarking a zero-shot baseline (GPT-5 Mini) against RAG configurations using GPT-4o and Qwen 32B across five distinct embedding and ranking strategies. Our results demonstrate a severe parametric knowledge gap, where zero-shot models fail to answer over 90 percent of queries, and even state-of-the-art RAG pipelines struggle to achieve high precision. This confirms AfriEconQA as a robust and challenging benchmark for the next generation of domain-specific IR and RAG systems. The AfriEconQA dataset and code will be made publicly available upon publication.", "AI": {"tldr": "本文介绍了AfriEconQA，这是一个基于236份世界银行报告的非洲经济分析专项基准数据集，包含8,937个经过精心筛选的问题答案实例，用于测试高精度的数值推理和时间识别能力。实验表明，现有的零样本模型和先进的RAG管道在该数据集上的表现不佳，确认了AfriEconQA作为一个专有领域的信息检索和RAG系统挑战性基准的地位。数据集和代码将在出版后公开。", "motivation": "为了填补现有大型语言模型预训练语料库中非洲经济分析数据的缺失，并提供特定领域难题以推进下一时代的领域特定信息检索（IR）和检索增强生成（RAG）系统的开发。", "method": "通过筛选10018个合成问题生成8,937个高质量问题与答案对，每个问题对应从该数据集中提取的证据、验证过的答案以及源元数据，以确保时间准确性。通过配置包含GPT-5 Mini零样本基线和使用不同嵌入和排名策略的RAG配置的11个实验矩阵对数据集进行操作和测试。", "result": "实验结果显示，零样本模型对超过90%的查询无法回答，即使是使用GPT-4o和Qwen 32B的先进RAG设置也难以达到高精度。这表明存在明显的参数知识缺口。", "conclusion": "AfriEconQA作为一个专注于非洲经济分析的数据集，展现了其作为复杂领域信息检索难题的独特挑战性，推动了针对特定领域精细能力的未来的IR和RAG系统的发展。"}}
{"id": "2601.15298", "categories": ["cs.CL", "cs.AI", "cs.PF"], "pdf": "https://arxiv.org/pdf/2601.15298", "abs": "https://arxiv.org/abs/2601.15298", "authors": ["Anantha Sharma"], "title": "Embedding Retrofitting: Data Engineering for better RAG", "comment": "16 pages, 11 figures, 7 tables", "summary": "Embedding retrofitting adjusts pre-trained word vectors using knowledge graph constraints to improve domain-specific retrieval. However, the effectiveness of retrofitting depends critically on knowledge graph quality, which in turn depends on text preprocessing. This paper presents a data engineering framework that addresses data quality degradation from annotation artifacts in real-world corpora.\n  The analysis shows that hashtag annotations inflate knowledge graph density, leading to creating spurious edges that corrupt the retrofitting objective. On noisy graphs, all retrofitting techniques produce statistically significant degradation ($-3.5\\%$ to $-5.2\\%$, $p<0.05$). After preprocessing, \\acrshort{ewma} retrofitting achieves $+6.2\\%$ improvement ($p=0.0348$) with benefits concentrated in quantitative synthesis questions ($+33.8\\%$ average). The gap between clean and noisy preprocessing (10\\%+ swing) exceeds the gap between algorithms (3\\%), establishing preprocessing quality as the primary determinant of retrofitting success.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2601.15299", "categories": ["cs.CL", "cs.IR", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.15299", "abs": "https://arxiv.org/abs/2601.15299", "authors": ["Yash Sharma"], "title": "MALTopic: Multi-Agent LLM Topic Modeling Framework", "comment": "6 pages. Published in 2025 IEEE World AI-IoT Congress. \\c{opyright} 2025 IEEE. Project code and data available at: https://github.com/yash91sharma/MALTopic", "summary": "Topic modeling is a crucial technique for extracting latent themes from unstructured text data, particularly valuable in analyzing survey responses. However, traditional methods often only consider free-text responses and do not natively incorporate structured or categorical survey responses for topic modeling. And they produce abstract topics, requiring extensive human interpretation. To address these limitations, we propose the Multi-Agent LLM Topic Modeling Framework (MALTopic). This framework decomposes topic modeling into specialized tasks executed by individual LLM agents: an enrichment agent leverages structured data to enhance textual responses, a topic modeling agent extracts latent themes, and a deduplication agent refines the results. Comparative analysis on a survey dataset demonstrates that MALTopic significantly improves topic coherence, diversity, and interpretability compared to LDA and BERTopic. By integrating structured data and employing a multi-agent approach, MALTopic generates human-readable topics with enhanced contextual relevance, offering a more effective solution for analyzing complex survey data.", "AI": {"tldr": "本研究提出了一种多代理LLM主题建模框架，该框架在处理含有结构化和分类调查数据的文本时表现出色，提高了主题的连贯性、多样性和可理解性。", "motivation": "传统方法在分析调查回复时只考虑自由文本响应，不原生地整合结构化或分类调查回复，导致产生抽象的主题，需要大量的人类解释。为了解决这些问题，提出了MALTopic。", "method": "本论文提出了一种名为Multi-Agent LLM Topic Modeling Framework (MALTopic) 的框架来解决传统主题建模方法在处理结构化或分类调查响应时的问题。该框架分解了主题建模任务，由各自的LLM代理来执行：一个丰富代理使用结构化数据来增强文本响应，一个主题建模代理提取潜在主题，一个去重代理细化结果。", "result": "在对调查数据集的比较分析中，MALTopic在话题连贯性、多样性和可解释性方面显著优于LDA和BERTopic。", "conclusion": "通过结合结构化数据和多代理方法，MALTopic生成有更高语境相关性的可读主题，为分析复杂调查数据提供了更有效的解决方案。"}}
{"id": "2601.15366", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.15366", "abs": "https://arxiv.org/abs/2601.15366", "authors": ["Christina Thrainer"], "title": "AI-Based Culvert-Sewer Inspection", "comment": "Masters thesis, University of Technology Graz, 2025", "summary": "Culverts and sewer pipes are critical components of drainage systems, and their failure can lead to serious risks to public safety and the environment. In this thesis, we explore methods to improve automated defect segmentation in culverts and sewer pipes. Collecting and annotating data in this field is cumbersome and requires domain knowledge. Having a large dataset for structural defect detection is therefore not feasible. Our proposed methods are tested under conditions with limited annotated data to demonstrate applicability to real-world scenarios. Overall, this thesis proposes three methods to significantly enhance defect segmentation and handle data scarcity. This can be addressed either by enhancing the training data or by adjusting a models architecture.\n  First, we evaluate preprocessing strategies, including traditional data augmentation and dynamic label injection. These techniques significantly improve segmentation performance, increasing both Intersection over Union (IoU) and F1 score. Second, we introduce FORTRESS, a novel architecture that combines depthwise separable convolutions, adaptive Kolmogorov-Arnold Networks (KAN), and multi-scale attention mechanisms. FORTRESS achieves state-of-the-art performance on the culvert sewer pipe defect dataset, while significantly reducing the number of trainable parameters, as well as its computational cost. Finally, we investigate few-shot semantic segmentation and its applicability to defect detection. Few-shot learning aims to train models with only limited data available. By employing a bidirectional prototypical network with attention mechanisms, the model achieves richer feature representations and achieves satisfactory results across evaluation metrics.", "AI": {"tldr": "本文提出三种方法改进排水管道缺陷自动分割，包括预处理策略、FORTRESS架构和少样本学习，提高了性能并减少了计算需求。", "motivation": "排水管道是排水系统的关键组成部分，其故障可能导致严重的公共安全和环境风险。本文探索提高排水管道缺陷自动分割的方法。由于收集和注释这类领域数据的工作量大且需要专业知识，拥有大量结构缺陷检测数据集并不现实。为此，本文提出的方法在有限标注数据条件下进行测试，以展示其在实际场景中的适用性。", "method": "本论文提出三种方法来改进排水管道缺陷的自动分割。首先，评估预处理策略，包括传统的数据增强和动态标签注入，这两种技术显著提高了分割性能，增加了IoU和F1得分。其次，引入了FORTRESS架构，结合了深度可分离卷积、自适应KAN和多尺度注意力机制。FORTRESS在排水管道缺陷数据集上达到最先进的表现，同时显著减少了可训练参数数量和计算成本。最后，考察了少样本语义分割及其在缺陷检测中的适用性。采用具有注意机制的双向原型网络，模型实现了丰富的特征表示，在评估指标上取得了满意的结果。", "result": "论文提出的方法显著改善了缺陷分割性能，提高了IoU和F1得分，减少了计算成本和参数数量。FORTRESS架构在特定数据集上达到了最先进的性能。少样本学习方法在使用有限数据训练模型后，同样在评价指标上表现满意。", "conclusion": "本文通过改进预处理策略、引入FORTRESS架构和研究少样本语义分割法，显著提升了排水管道缺陷分割精度和效率。这为在数据稀缺情况下进行更高效的缺陷检测提供了解决方案。"}}
{"id": "2601.15300", "categories": ["cs.CL"], "pdf": "https://arxiv.org/pdf/2601.15300", "abs": "https://arxiv.org/abs/2601.15300", "authors": ["Weiwei Wang", "Jiyong Min", "Weijie Zou"], "title": "Intelligence Degradation in Long-Context LLMs: Critical Threshold Determination via Natural Length Distribution Analysis", "comment": "29 pages", "summary": "Large Language Models (LLMs) exhibit catastrophic performance degradation when processing contexts approaching certain critical thresholds, even when information remains relevant. This intelligence degradation-defined as over 30% drop in task performance-severely limits long-context applications. This degradation shows a common pattern: models maintain strong performance up to a critical threshold, then collapse catastrophically. We term this shallow long-context adaptation-models adapt for short to medium contexts but fail beyond critical thresholds. This paper presents three contributions: (1) Natural Length Distribution Analysis: We use each sample's natural token length without truncation or padding, providing stronger causal evidence that degradation results from context length itself. (2) Critical Threshold Determination: Through experiments on a mixed dataset (1,000 samples covering 5%-95% of context length), we identify the critical threshold for Qwen2.5-7B at 40-50% of maximum context length, where F1 scores drop from 0.55-0.56 to 0.3 (45.5% degradation), using five-method cross-validation. (3) Unified Framework: We consolidate shallow adaptation, explaining degradation patterns and providing a foundation for mitigation strategies. This work provides the first systematic characterization of intelligence degradation in open-source Qwen models, offering practical guidance for deploying LLMs in long-context scenarios.", "AI": {"tldr": "文章研究了大语言模型在处理接近某些临界阈值的上下文时表现出的性能急剧下降问题，并首次系统地描述了开源模型Qwen的智能退化现象，提出了自然长度分布分析、临界阈值确定和统一框架三个主要贡献，为解决长上下文使用中的模型降级问题提供了实际指导和基础策略。", "motivation": "研究动机在于解决大语言模型在处理长上下文时的性能急剧下降问题，这一现象普遍存在于模型处理超过一定临界阈值的上下文长度时。", "method": "研究方法包括自然长度分布分析，即使用每个样本的自然标记长度而不进行截断或填充，以及通过实验确定模型的临界阈值，例如在覆盖上下文长度5%-95%的混合数据集上的实验。", "result": "研究结果显示Qwen2.5-7B模型在上下文长度达到40-50%时性能急剧下降，F1分数从0.55-0.56降至0.3，性能下降45.5%。", "conclusion": "该研究提出了统一框架来解释性能退化的模式，为缓解策略奠定了基础，并为部署大语言模型到长上下文应用提供了实际指导。"}}
{"id": "2601.15406", "categories": ["cs.CV"], "pdf": "https://arxiv.org/pdf/2601.15406", "abs": "https://arxiv.org/abs/2601.15406", "authors": ["Hatef Otroshi Shahreza", "Anjith George", "Sébastien Marcel"], "title": "Evaluating Multimodal Large Language Models for Heterogeneous Face Recognition", "comment": null, "summary": "Multimodal Large Language Models (MLLMs) have recently demonstrated strong performance on a wide range of vision-language tasks, raising interest in their potential use for biometric applications. In this paper, we conduct a systematic evaluation of state-of-the-art MLLMs for heterogeneous face recognition (HFR), where enrollment and probe images are from different sensing modalities, including visual (VIS), near infrared (NIR), short-wave infrared (SWIR), and thermal camera. We benchmark multiple open-source MLLMs across several cross-modality scenarios, including VIS-NIR, VIS-SWIR, and VIS-THERMAL face recognition. The recognition performance of MLLMs is evaluated using biometric protocols and based on different metrics, including Acquire Rate, Equal Error Rate (EER), and True Accept Rate (TAR). Our results reveal substantial performance gaps between MLLMs and classical face recognition systems, particularly under challenging cross-spectral conditions, in spite of recent advances in MLLMs. Our findings highlight the limitations of current MLLMs for HFR and also the importance of rigorous biometric evaluation when considering their deployment in face recognition systems.", "AI": {"tldr": "本研究评估了MLLMs在异构面部识别中的性能，发现尽管有所进展，但在跨谱条件下与传统面部识别系统相比，MLLMs的表现仍有差距。强调了严格的生物识别评价以确保MLLMs在实际应用中的有效性。", "motivation": "鉴于多模态大语言模型在视觉-语言任务中的强大性能，研究者们对其在生物识别应用中的潜力产生了兴趣。这项研究旨在评估MLLMs在异构面部识别中的适应性和效果，并识别这些模型在跨谱条件下潜在的挑战和限制。", "method": "本文通过系统评估几种最先进的多模态大语言模型（MLLMs）在异构面部识别（HFR）中的表现，对MLLMs在生物识别应用中的潜力进行了探讨。实验涵盖了从不同感知模式（包括可见光（VIS）、近红外（NIR）、短波红外（SWIR）和热成像）中获取的登记和探针图像。评估了多个开源MLLMs在不同跨模态场景下的表现，包括VIS-NIR、VIS-SWIR和VIS-热成像面部识别。", "result": "研究表明，在某些具有挑战性的跨谱条件下，尽管最近在MLLMs方面有了一定的进步，不同MLLMs与传统的面部识别系统的识别性能之间仍然存在显著差距。", "conclusion": "研究结果表明，当前MLLMs用于HFR时存在局限性，并强调了在面部识别系统中部署这些模型时需要进行严格的生物识别评估的重要性。"}}
{"id": "2601.15301", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15301", "abs": "https://arxiv.org/abs/2601.15301", "authors": ["Jivnesh Sandhan", "Harshit Jaiswal", "Fei Cheng", "Yugo Murawaki"], "title": "Can We Trust LLM Detectors?", "comment": "NLP2026, Utsunomiya, Japan", "summary": "The rapid adoption of LLMs has increased the need for reliable AI text detection, yet existing detectors often fail outside controlled benchmarks. We systematically evaluate 2 dominant paradigms (training-free and supervised) and show that both are brittle under distribution shift, unseen generators, and simple stylistic perturbations. To address these limitations, we propose a supervised contrastive learning (SCL) framework that learns discriminative style embeddings. Experiments show that while supervised detectors excel in-domain, they degrade sharply out-of-domain, and training-free methods remain highly sensitive to proxy choice. Overall, our results expose fundamental challenges in building domain-agnostic detectors. Our code is available at: https://github.com/HARSHITJAIS14/DetectAI", "AI": {"tldr": "研究提出了一种新的监督对比学习框架来改善AI文本检测，结果表明现有方法在域外存在明显限制。", "motivation": "由于大型语言模型的广泛采用，对可靠AI文本检测器的需求增加，但现有检测器在非控制环境基准下经常失败。", "method": "研究采用了监督对比学习（SCL）框架，旨在学习区分性的风格嵌入，以改善AI文本检测的性能。", "result": "该研究系统评估了两种主要的AI文本检测范式（无训练和监督学习），发现它们在分布变化、未见过的生成器和简单的风格扰动下都表现脆弱。为解决这些问题，研究人员提出了一种基于监督对比学习（SCL）框架，该框架能够学习区分性的风格嵌入。实验表明，尽管监督检测器在域内表现优秀，但在域外性能大幅下降，而不依赖训练的方法仍然高度依赖代理选择。总体而言，研究结果揭示了构建域无关检测器的基本挑战。", "conclusion": "构建能够在不同环境中可靠工作的AI文本检测器面临基本挑战，现有方法在面对域外数据时性能严重下降。"}}
{"id": "2601.15408", "categories": ["cs.CV", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.15408", "abs": "https://arxiv.org/abs/2601.15408", "authors": ["Pablo Messina", "Andrés Villa", "Juan León Alcázar", "Karen Sánchez", "Carlos Hinojosa", "Denis Parra", "Álvaro Soto", "Bernard Ghanem"], "title": "CURE: Curriculum-guided Multi-task Training for Reliable Anatomy Grounded Report Generation", "comment": "31 pages, 7 figures, submitted to CVPR 2026 (under review)", "summary": "Medical vision-language models can automate the generation of radiology reports but struggle with accurate visual grounding and factual consistency. Existing models often misalign textual findings with visual evidence, leading to unreliable or weakly grounded predictions. We present CURE, an error-aware curriculum learning framework that improves grounding and report quality without any additional data. CURE fine-tunes a multimodal instructional model on phrase grounding, grounded report generation, and anatomy-grounded report generation using public datasets. The method dynamically adjusts sampling based on model performance, emphasizing harder samples to improve spatial and textual alignment. CURE improves grounding accuracy by +0.37 IoU, boosts report quality by +0.188 CXRFEScore, and reduces hallucinations by 18.6%. CURE is a data-efficient framework that enhances both grounding accuracy and report reliability. Code is available at https://github.com/PabloMessina/CURE and model weights at https://huggingface.co/pamessina/medgemma-4b-it-cure", "AI": {"tldr": "CURE框架解决了现有医学视觉语言模型在生成放射学报告时面临的视觉定位不准确和事实不一致的问题，通过动态调整采样的课程学习方法提高模型的空间和文本对齐能力，从而提高了报告的质量和可靠性。", "motivation": "现有的医学视觉语言模型在自动生成放射学报告时遇到视觉定位不准确和事实一致性的问题。这些模型往往无法正确匹配文本发现和视觉证据，导致预测结果不可靠。", "method": "CURE采用了一种错误感知的课程学习框架，通过在短语定位、基于定位的报告生成和基于解剖结构的报告生成任务上微调多模态指令模型，特别是在现有公共数据集上进行。该框架会根据模型性能动态调整采样策略，更注重训练难度较大的样本，从而改进空间和文本对齐效果。", "result": "CURE显著提升了接地准确性（+0.37 IoU）、报告质量（+0.188 CXRFEScore）并降低了幻觉（减少18.6%）。", "conclusion": "CURE是一种数据高效的框架，能有效提升基于放射学图像的文本报告的质量和接地准确性。这种方法表明，通过高效利用现有数据和动态调整训练内容，可以提升模型的表现。"}}
{"id": "2601.15330", "categories": ["cs.CL", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.15330", "abs": "https://arxiv.org/abs/2601.15330", "authors": ["Zhebo Wang", "Xiaohu Mu", "Zijie Zhou", "Mohan Li", "Wenpeng Xing", "Dezhang Kong", "Meng Han"], "title": "ICPO: Illocution-Calibrated Policy Optimization for Multi-Turn Conversation", "comment": "Accepted by ICASSP 2026", "summary": "Large Language Models (LLMs) in multi-turn conversations often suffer from a ``lost-in-conversation'' phenomenon, where they struggle to recover from early incorrect assumptions, particularly when users provide ambiguous initial instructions. We find that standard post-training techniques like Reinforcement Learning with Verifiable Rewards (RLVR) exacerbate this issue by rewarding confident, direct answers, thereby inducing overconfidence and discouraging the model from seeking clarification. To address this, we propose Illocution-Calibrated Policy Optimization (ICPO), a novel training framework that sensitizes the model to instruction ambiguity. ICPO augments the training corpus with underspecified prompts and conditions the reward signal on the user's illocutionary intent, rewarding the model for expressing uncertainty or asking for clarification when faced with ambiguity. Experiments demonstrate that ICPO fosters appropriate humility, yielding a substantial average improvement of 75\\% in multi-turn conversation, while preserving robust performance on single-turn benchmarks. Our work presents a practical path toward more robust and collaborative conversational AI that can better navigate the nuances of human interaction.", "AI": {"tldr": "为解决多轮对话中语言模型因模糊指令而固守早期错误假设的问题，本文提出ICPO框架，该框架通过增强训练语料库中的未指定提示和奖励表达不确定性的行为，促进了模型在多轮对话中的表现。", "motivation": "多轮对话中的大语言模型常出现“迷失在对话中”的现象，即从早期不正确的假设中恢复困难，特别是当用户给出模糊的初始指令时。标准的后训练技术如带有可验证奖励的强化学习(RLVR)通过奖励自信且直接的回答，反而加剧了这一问题。", "method": "提出了一种名为Illocution-Calibrated Policy Optimization (ICPO)的新训练框架，该框架通过增强训练语料库中的未指定提示并根据用户的施为意图奖励信号，来使模型对指令的模糊性更为敏感，鼓励模型在面对模糊性时表达不确定性或要求澄清。", "result": "实验表明，ICPO培养了适当的谦逊态度，在多轮对话中平均提升了75%的表现，同时在单轮对话基准上保持了强大的性能。", "conclusion": "该研究为构建更加健壮且能更好地应对人类互动细微之处的合作式对话AI提供了一条实用路径。"}}
